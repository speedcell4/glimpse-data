{
  "https://jmlr.org/papers/v22/17-570.html": {
    "title": "On the Optimality of Kernel-Embedding Based Goodness-of-Fit Tests",
    "volume": "main",
    "abstract": "The reproducing kernel Hilbert space (RKHS) embedding of distributions offers a general and flexible framework for testing problems in arbitrary domains and has attracted considerable amount of attention in recent years. To gain insights into their operating characteristics, we study here the statistical performance of such approaches within a minimax framework. Focusing on the case of goodness-of-fit tests, our analyses show that a vanilla version of the kernel embedding based test could be minimax suboptimal, {when considering $\\chi^2$ distance as the separation metric}. Hence we suggest a simple remedy by moderating the embedding. We prove that the moderated approach provides optimal tests for a wide range of deviations from the null and can also be made adaptive over a large collection of interpolation spaces. Numerical experiments are presented to further demonstrate the merits of our approach",
    "checked": true,
    "id": "8aed525b4147fc97ea14a59fd55d29fe0c5f855a",
    "semantic_title": "on the optimality of kernel-embedding based goodness-of-fit tests",
    "citation_count": 23,
    "authors": [
      "Krishnakumar Balasubramanian",
      "Tong Li",
      "Ming Yuan"
    ]
  },
  "https://jmlr.org/papers/v22/17-679.html": {
    "title": "Domain Generalization by Marginal Transfer Learning",
    "volume": "main",
    "abstract": "In the problem of domain generalization (DG), there are labeled training data sets from several related prediction problems, and the goal is to make accurate predictions on future unlabeled data sets that are not known to the learner. This problem arises in several applications where data distributions fluctuate because of environmental, technical, or other sources of variation. We introduce a formal framework for DG, and argue that it can be viewed as a kind of supervised learning problem by augmenting the original feature space with the marginal distribution of feature vectors. While our framework has several connections to conventional analysis of supervised learning algorithms, several unique aspects of DG require new methods of analysis. This work lays the learning theoretic foundations of domain generalization, building on our earlier conference paper where the problem of DG was introduced. We present two formal models of data generation, corresponding notions of risk, and distribution-free generalization error analysis. By focusing our attention on kernel methods, we also provide more quantitative results and a universally consistent algorithm. An efficient implementation is provided for this algorithm, which is experimentally compared to a pooling strategy on one synthetic and three real-world data sets",
    "checked": true,
    "id": "664aa73cda563ae5f011a6b2b91ed0f82b5bf295",
    "semantic_title": "domain generalization by marginal transfer learning",
    "citation_count": 210,
    "authors": [
      "Gilles Blanchard",
      "Aniket Anand Deshmukh",
      "Urun Dogan",
      "Gyemin Lee",
      "Clayton Scott"
    ]
  },
  "https://jmlr.org/papers/v22/17-720.html": {
    "title": "Regulating Greed Over Time in Multi-Armed Bandits",
    "volume": "main",
    "abstract": "In retail, there are predictable yet dramatic time-dependent patterns in customer behavior, such as periodic changes in the number of visitors, or increases in customers just before major holidays. The current paradigm of multi-armed bandit analysis does not take these known patterns into account. This means that for applications in retail, where prices are fixed for periods of time, current bandit algorithms will not suffice. This work provides a remedy that takes the time-dependent patterns into account, and we show how this remedy is implemented for the UCB, $\\varepsilon$-greedy, and UCB-L algorithms, and also through a new policy called the variable arm pool algorithm. In the corrected methods, exploitation (greed) is regulated over time, so that more exploitation occurs during higher reward periods, and more exploration occurs in periods of low reward. In order to understand why regret is reduced with the corrected methods, we present a set of bounds that provide insight into why we would want to exploit during periods of high reward, and discuss the impact on regret. Our proposed methods perform well in experiments, and were inspired by a high-scoring entry in the Exploration and Exploitation 3 contest using data from Yahoo$!$ Front Page. That entry heavily used time-series methods to regulate greed over time, which was substantially more effective than other contextual bandit methods",
    "checked": true,
    "id": "2c6e4068a044c39011d00a079de0d4bd2e339715",
    "semantic_title": "regulating greed over time in multi-armed bandits",
    "citation_count": 7,
    "authors": [
      "Stefano Trac√†",
      "Cynthia Rudin",
      "Weiyu Yan"
    ]
  },
  "https://jmlr.org/papers/v22/18-220.html": {
    "title": "An Empirical Study of Bayesian Optimization: Acquisition Versus Partition",
    "volume": "main",
    "abstract": "Bayesian optimization (BO) is a popular framework for black-box optimization. Two classes of BO approaches have shown promising empirical performance while providing strong theoretical guarantees. The first class optimizes an acquisition function to select points, which is typically computationally expensive and can only be done approximately. The second class of algorithms use systematic space partitioning, which is much cheaper computationally but the selection is typically less informed. This points to a potential trade-off between the computational complexity and empirical performance of these algorithms. The current literature, however, only provides a sparse sampling of empirical comparison points, giving little insight into this trade-off. The primary contribution of this work is to conduct a comprehensive, repeatable evaluation within a common software framework, which we provide as an open-source package. Our results give strong evidence about the relative performance of these methods and reveal a consistent top performer, even when accounting for overall computation time",
    "checked": true,
    "id": "67f737389db444b0f3d255f40a8007a646dfabd5",
    "semantic_title": "an empirical study of bayesian optimization: acquisition versus partition",
    "citation_count": 13,
    "authors": [
      "Erich Merrill",
      "Alan Fern",
      "Xiaoli Fern",
      "Nima Dolatnia"
    ]
  },
  "https://jmlr.org/papers/v22/18-417.html": {
    "title": "The Decoupled Extended Kalman Filter for Dynamic Exponential-Family Factorization Models",
    "volume": "main",
    "abstract": "Motivated by the needs of online large-scale recommender systems, we specialize the decoupled extended Kalman filter to factorization models, including factorization machines, matrix and tensor factorization, and illustrate the effectiveness of the approach through numerical experiments on synthetic and on real-world data. Online learning of model parameters through the decoupled extended Kalman filter makes factorization models more broadly useful by (i) allowing for more flexible observations through the entire exponential family, (ii) modeling parameter drift, and (iii) producing parameter uncertainty estimates that can enable explore/exploit and other applications. We use a different parameter dynamics than the standard decoupled extended Kalman filter, allowing parameter drift while encouraging reasonable values. We also present an alternate derivation of the extended Kalman filter and decoupled extended Kalman filter that highlights the role of the Fisher information matrix in the extended Kalman filter",
    "checked": true,
    "id": "14064f97eb6711ce80a311932d492c4ed446197a",
    "semantic_title": "the decoupled extended kalman filter for dynamic exponential-family factorization models",
    "citation_count": 5,
    "authors": [
      "Carlos A. Gomez-Uribe",
      "Brian Karrer"
    ]
  },
  "https://jmlr.org/papers/v22/18-534.html": {
    "title": "Consistent estimation of small masses in feature sampling",
    "volume": "main",
    "abstract": "Consider an (observable) random sample of size $n$ from an infinite population of individuals, each individual being endowed with a finite set of features from a collection of features $(F_{j})_{j\\geq1}$ with unknown probabilities $(p_{j})_{j \\geq 1}$, i.e., $p_{j}$ is the probability that an individual displays feature $F_{j}$. Under this feature sampling framework, in recent years there has been a growing interest in estimating the sum of the probability masses $p_{j}$'s of features observed with frequency $r\\geq0$ in the sample, here denoted by $M_{n,r}$. This is the natural feature sampling counterpart of the classical problem of estimating small probabilities in the species sampling framework, where each individual is endowed with only one feature (or \"species\"). In this paper we study the problem of consistent estimation of the small mass $M_{n,r}$. We first show that there do not exist universally consistent estimators, in the multiplicative sense, of the missing mass $M_{n,0}$. Then, we introduce an estimator of $M_{n,r}$ and identify sufficient conditions under which the estimator is consistent. In particular, we propose a nonparametric estimator $\\hat{M}_{n,r}$ of $M_{n,r}$ which has the same analytic form of the celebrated Good--Turing estimator for small probabilities, with the sole difference that the two estimators have different ranges (supports). Then, we show that $\\hat{M}_{n,r}$ is strongly consistent, in the multiplicative sense, under the assumption that $(p_{j})_{j\\geq1}$ has regularly varying heavy tails",
    "checked": true,
    "id": "e35e442c823de45622a180931bf31e42ca6fcc9c",
    "semantic_title": "consistent estimation of small masses in feature sampling",
    "citation_count": 3,
    "authors": [
      "Fadhel Ayed",
      "Marco Battiston",
      "Federico Camerlenghi",
      "Stefano Favaro"
    ]
  },
  "https://jmlr.org/papers/v22/18-546.html": {
    "title": "Preference-based Online Learning with Dueling Bandits: A Survey",
    "volume": "main",
    "abstract": "In machine learning, the notion of multi-armed bandits refers to a class of online learning problems, in which an agent is supposed to simultaneously explore and exploit a given set of choice alternatives in the course of a sequential decision process. In the standard setting, the agent learns from stochastic feedback in the form of real-valued rewards. In many applications, however, numerical reward signals are not readily available---instead, only weaker information is provided, in particular relative preferences in the form of qualitative comparisons between pairs of alternatives. This observation has motivated the study of variants of the multi-armed bandit problem, in which more general representations are used both for the type of feedback to learn from and the target of prediction. The aim of this paper is to provide a survey of the state of the art in this field, referred to as preference-based multi-armed bandits or dueling bandits. To this end, we provide an overview of problems that have been considered in the literature as well as methods for tackling them. Our taxonomy is mainly based on the assumptions made by these methods about the data-generating process and, related to this, the properties of the preference-based feedback",
    "checked": true,
    "id": "31943f1f383a4ca6ba86e172a0c9f26c901f9401",
    "semantic_title": "preference-based online learning with dueling bandits: a survey",
    "citation_count": 79,
    "authors": [
      "Viktor Bengs",
      "R√≥bert Busa-Fekete",
      "Adil El Mesaoudi-Paul",
      "Eyke H√ºllermeier"
    ]
  },
  "https://jmlr.org/papers/v22/18-558.html": {
    "title": "A Unified Framework for Random Forest Prediction Error Estimation",
    "volume": "main",
    "abstract": "We introduce a unified framework for random forest prediction error estimation based on a novel estimator of the conditional prediction error distribution function. Our framework enables simple plug-in estimation of key prediction uncertainty metrics, including conditional mean squared prediction errors, conditional biases, and conditional quantiles, for random forests and many variants. Our approach is especially well-adapted for prediction interval estimation; we show via simulations that our proposed prediction intervals are competitive with, and in some settings outperform, existing methods. To establish theoretical grounding for our framework, we prove pointwise uniform consistency of a more stringent version of our estimator of the conditional prediction error distribution function. The estimators introduced here are implemented in the R package forestError",
    "checked": true,
    "id": "45799dcb15e6aa248c05bf80e2394b78bb0113e7",
    "semantic_title": "a unified framework for random forest prediction error estimation",
    "citation_count": 19,
    "authors": [
      "Benjamin Lu",
      "Johanna Hardin"
    ]
  },
  "https://jmlr.org/papers/v22/18-694.html": {
    "title": "Convex Clustering: Model, Theoretical Guarantee and Efficient Algorithm",
    "volume": "main",
    "abstract": "Clustering is a fundamental problem in unsupervised learning. Popular methods like K-means, may suffer from poor performance as they are prone to get stuck in its local minima. Recently, the sum-of-norms (SON) model (also known as the convex clustering model) has been proposed by Pelckmans et al. (2005), Lindsten et al. (2011) and Hocking et al. (2011). The perfect recovery properties of the convex clustering model with uniformly weighted all-pairwise-differences regularization have been proved by Zhu et al. (2014) and Panahi et al. (2017). However, no theoretical guarantee has been established for the general weighted convex clustering model, where better empirical results have been observed. In the numerical optimization aspect, although algorithms like the alternating direction method of multipliers (ADMM) and the alternating minimization algorithm (AMA) have been proposed to solve the convex clustering model (Chi and Lange, 2015), it still remains very challenging to solve large-scale problems. In this paper, we establish sufficient conditions for the perfect recovery guarantee of the general weighted convex clustering model, which include and improve existing theoretical results in (Zhu et al., 2014; Panahi et al., 2017) as special cases. In addition, we develop a semismooth Newton based augmented Lagrangian method for solving large-scale convex clustering problems. Extensive numerical experiments on both simulated and real data demonstrate that our algorithm is highly efficient and robust for solving large-scale problems. Moreover, the numerical results also show the superior performance and scalability of our algorithm comparing to the existing first-order methods. In particular, our algorithm is able to solve a convex clustering problem with 200,000 points in $\\mathbb{R}^3$ in about 6 minutes",
    "checked": true,
    "id": "419b4f55867c1a2c465faf8f9fe1b6153550f69d",
    "semantic_title": "convex clustering: model, theoretical guarantee and efficient algorithm",
    "citation_count": 52,
    "authors": [
      "Defeng Sun",
      "Kim-Chuan Toh",
      "Yancheng Yuan"
    ]
  },
  "https://jmlr.org/papers/v22/18-770.html": {
    "title": "Mixing Time of Metropolis-Hastings for Bayesian Community Detection",
    "volume": "main",
    "abstract": "We study the computational complexity of a Metropolis-Hastings algorithm for Bayesian community detection. We first establish a posterior strong consistency result for a natural prior distribution on stochastic block models under the optimal signal-to-noise ratio condition in the literature. We then give a set of conditions that guarantee rapidly mixing of a simple Metropolis-Hastings algorithm. The mixing time analysis is based on a careful study of posterior ratios and a canonical path argument to control the spectral gap of the Markov chain",
    "checked": true,
    "id": "49a4416d328e44659f47448a300ecb1e92f74e0d",
    "semantic_title": "mixing time of metropolis-hastings for bayesian community detection",
    "citation_count": 5,
    "authors": [
      "Bumeng Zhuo",
      "Chao Gao"
    ]
  },
  "https://jmlr.org/papers/v22/18-846.html": {
    "title": "Unfolding-Model-Based Visualization: Theory, Method and Applications",
    "volume": "main",
    "abstract": "Multidimensional unfolding methods are widely used for visualizing item response data. Such methods project respondents and items simultaneously onto a low-dimensional Euclidian space, in which respondents and items are represented by ideal points, with person-person, item-item, and person-item similarities being captured by the Euclidian distances between the points. In this paper, we study the visualization of multidimensional unfolding from a statistical perspective. We cast multidimensional unfolding into an estimation problem, where the respondent and item ideal points are treated as parameters to be estimated. An estimator is then proposed for the simultaneous estimation of these parameters. Asymptotic theory is provided for the recovery of the ideal points, shedding lights on the validity of model-based visualization. An alternating projected gradient descent algorithm is proposed for the parameter estimation. We provide two illustrative examples, one on users' movie rating and the other on senate roll call voting",
    "checked": true,
    "id": "322e1d02684dfcb6f9fed17a13fc2c0e197ede1e",
    "semantic_title": "unfolding-model-based visualization: theory, method and applications",
    "citation_count": 2,
    "authors": [
      "Yunxiao Chen",
      "Zhiliang Ying",
      "Haoran Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/19-026.html": {
    "title": "Global and Quadratic Convergence of Newton Hard-Thresholding Pursuit",
    "volume": "main",
    "abstract": "Algorithms based on the hard thresholding principle have been well studied with sounding theoretical guarantees in the compressed sensing and more general sparsity-constrained optimization. It is widely observed in existing empirical studies that when a restricted Newton step was used (as the debiasing step), the hard-thresholding algorithms tend to meet halting conditions in a significantly low number of iterations and are very efficient. Hence, the thus obtained Newton hard-thresholding algorithms call for stronger theoretical guarantees than for their simple hard-thresholding counterparts. This paper provides a theoretical justification for the use of the restricted Newton step. We build our theory and algorithm, Newton Hard-Thresholding Pursuit (NHTP), for the sparsity-constrained optimization. Our main result shows that NHTP is quadratically convergent under the standard assumption of restricted strong convexity and smoothness. We also establish its global convergence to a stationary point under a weaker assumption. In the special case of the compressive sensing, NHTP effectively reduces to some of the existing hard-thresholding algorithms with a Newton step. Consequently, our fast convergence result justifies why those algorithms perform better than without the Newton step. The efficiency of NHTP was demonstrated on both synthetic and real data in compressed sensing and sparse logistic regression",
    "checked": true,
    "id": "c2154808236441b0957890724ed42094e77a39ee",
    "semantic_title": "global and quadratic convergence of newton hard-thresholding pursuit",
    "citation_count": 51,
    "authors": [
      "Shenglong Zhou",
      "Naihua Xiu",
      "Hou-Duo Qi"
    ]
  },
  "https://jmlr.org/papers/v22/19-1018.html": {
    "title": "Homogeneity Structure Learning in Large-scale Panel Data with Heavy-tailed Errors",
    "volume": "main",
    "abstract": "Large-scale panel data is ubiquitous in many modern data science applications. Conventional panel data analysis methods fail to address the new challenges, like individual impacts of covariates, endogeneity, embedded low-dimensional structure, and heavy-tailed errors, arising from the innovation of data collection platforms on which applications operate. In response to these challenges, this paper studies large-scale panel data with an interactive effects model. This model takes into account the individual impacts of covariates on each spatial node and removes the exogenous condition by allowing latent factors to affect both covariates and errors. Besides, we waive the sub-Gaussian assumption and allow the errors to be heavy-tailed. Further, we propose a data-driven procedure to learn a parsimonious yet flexible homogeneity structure embedded in high-dimensional individual impacts of covariates. The homogeneity structure assumes that there exists a partition of regression coefficients where the coefficients are the same within each group but different between the groups. The homogeneity structure is flexible as it contains many widely assumed low-dimensional structures (sparsity, global impact, etc.) as its special cases. Non-asymptotic properties are established to justify the proposed learning procedure. Extensive numerical experiments demonstrate the advantage of the proposed learning procedure over conventional methods especially when the data are generated from heavy-tailed distributions",
    "checked": true,
    "id": "81634fe092a3f678e097aacd228f54d0967b7bab",
    "semantic_title": "homogeneity structure learning in large-scale panel data with heavy-tailed errors",
    "citation_count": 5,
    "authors": [
      "Di Xiao",
      "Yuan Ke",
      "Runze Li"
    ]
  },
  "https://jmlr.org/papers/v22/19-228.html": {
    "title": "On Multi-Armed Bandit Designs for Dose-Finding Trials",
    "volume": "main",
    "abstract": "We study the problem of finding the optimal dosage in early stage clinical trials through the multi-armed bandit lens. We advocate the use of the Thompson Sampling principle, a flexible algorithm that can accommodate different types of monotonicity assumptions on the toxicity and efficacy of the doses. For the simplest version of Thompson Sampling, based on a uniform prior distribution for each dose, we provide finite-time upper bounds on the number of sub-optimal dose selections, which is unprecedented for dose-finding algorithms. Through a large simulation study, we then show that variants of Thompson Sampling based on more sophisticated prior distributions outperform state-of-the-art dose identification algorithms in different types of dose-finding studies that occur in phase I or phase I/II trials",
    "checked": true,
    "id": "09133d3db66bf2fe0a9f89234ec58e802097aa20",
    "semantic_title": "on multi-armed bandit designs for dose-finding trials",
    "citation_count": 3,
    "authors": [
      "Maryam Aziz",
      "Emilie Kaufmann",
      "Marie-Karelle Riviere"
    ]
  },
  "https://jmlr.org/papers/v22/19-372.html": {
    "title": "Simple and Fast Algorithms for Interactive Machine Learning with Random Counter-examples",
    "volume": "main",
    "abstract": "This work describes simple and efficient algorithms for interactively learning non-binary concepts in the learning from random counter-examples (LRC) model. Here, learning takes place from random counter-examples that the learner receives in response to their proper equivalence queries, and the learning time is the number of counter-examples needed by the learner to identify the target concept. Such learning is particularly suited for online ranking, classification, clustering, etc., where machine learning models must be used before they are fully trained. We provide two simple LRC algorithms, deterministic and randomized, for exactly learning concepts from any concept class $H$. We show that both these algorithms have an $\\mathcal{O}(\\log{}|H|)$ asymptotically optimal average learning time. This solves an open problem on the existence of an efficient LRC randomized algorithm while also simplifying previous results and improving their computational efficiency. We also show that the expected learning time of any Arbitrary LRC algorithm can be upper bounded by $\\mathcal{O}(\\frac{1}{\\epsilon}\\log{\\frac{|H|}{\\delta}})$, where $\\epsilon$ and $\\delta$ are the allowed learning error and failure probability respectively. This shows that LRC interactive learning is at least as efficient as non-interactive Probably Approximately Correct (PAC) learning. Our simulations also show that these algorithms outperform their theoretical bounds",
    "checked": true,
    "id": "4531990a5313e75680731033aaae0376b756a4a6",
    "semantic_title": "simple and fast algorithms for interactive machine learning with random counter-examples",
    "citation_count": 1,
    "authors": [
      "Jagdeep Singh Bhatia"
    ]
  },
  "https://jmlr.org/papers/v22/19-433.html": {
    "title": "Pykg2vec: A Python Library for Knowledge Graph Embedding",
    "volume": "MLOSS",
    "abstract": "Pykg2vec is a Python library for learning the representations of the entities and relations in knowledge graphs. Pykg2vec's flexible and modular software architecture currently implements 25 state-of-the-art knowledge graph embedding algorithms, and is designed to easily incorporate new algorithms.The goal of pykg2vec is to provide a practical and educational platform to accelerate research in knowledge graph representation learning. Pykg2vec is built on top of PyTorch and Python's multiprocessing framework and provides modules for batch generation, Bayesian hyperparameter optimization, evaluation of KGE tasks, embedding, and result visualization. Pykg2vec is released under the MIT License and is also available in the Python Package Index (PyPI). The source code of pykg2vec is available at https://github.com/Sujit-O/pykg2vec",
    "checked": true,
    "id": "021cbcd59c0438ac8a50c511be7634b0c00a1b89",
    "semantic_title": "pykg2vec: a python library for knowledge graph embedding",
    "citation_count": 30,
    "authors": [
      "Shih-Yuan Yu",
      "Sujit Rokka Chhetri",
      "Arquimedes Canedo",
      "Palash Goyal",
      "Mohammad Abdullah Al Faruque"
    ]
  },
  "https://jmlr.org/papers/v22/19-466.html": {
    "title": "Continuous Time Analysis of Momentum Methods",
    "volume": "main",
    "abstract": "Gradient descent-based optimization methods underpin the parameter training of neural networks, and hence comprise a significant component in the impressive test results found in a number of applications. Introducing stochasticity is key to their success in practical problems, and there is some understanding of the role of stochastic gradient descent in this context. Momentum modifications of gradient descent such as Polyak's Heavy Ball method (HB) and Nesterov's method of accelerated gradients (NAG), are also widely adopted. In this work our focus is on understanding the role of momentum in the training of neural networks, concentrating on the common situation in which the momentum contribution is fixed at each step of the algorithm. To expose the ideas simply we work in the deterministic setting. Our approach is to derive continuous time approximations of the discrete algorithms; these continuous time approximations provide insights into the mechanisms at play within the discrete algorithms. We prove three such approximations. Firstly we show that standard implementations of fixed momentum methods approximate a time-rescaled gradient descent flow, asymptotically as the learning rate shrinks to zero; this result does not distinguish momentum methods from pure gradient descent, in the limit of vanishing learning rate. We then proceed to prove two results aimed at understanding the observed practical advantages of fixed momentum methods over gradient descent, when implemented in the non-asymptotic regime with fixed small, but non-zero, learning rate. We achieve this by proving approximations to continuous time limits in which the small but fixed learning rate appears as a parameter; this is known as the method of modified equations in the numerical analysis literature, recently rediscovered as the high resolution ODE approximation in the machine learning context. In our second result we show that the momentum method is approximated by a continuous time gradient flow, with an additional momentum-dependent second order time-derivative correction, proportional to the learning rate; this may be used to explain the stabilizing effect of momentum algorithms in their transient phase. Furthermore in a third result we show that the momentum methods admit an exponentially attractive invariant manifold on which the dynamics reduces, approximately, to a gradient flow with respect to a modified loss function, equal to the original loss function plus a small perturbation proportional to the learning rate; this small correction provides convexification of the loss function and encodes additional robustness present in momentum methods, beyond the transient phase",
    "checked": true,
    "id": "bf2605606cd6c6bb5d29ca77a52ece4dce0a764a",
    "semantic_title": "continuous time analysis of momentum methods",
    "citation_count": 23,
    "authors": [
      "Nikola B. Kovachki",
      "Andrew M. Stuart"
    ]
  },
  "https://jmlr.org/papers/v22/19-498.html": {
    "title": "A Unified Sample Selection Framework for Output Noise Filtering: An Error-Bound Perspective",
    "volume": "main",
    "abstract": "The existence of output noise will bring difficulties to supervised learning. Noise filtering, aiming to detect and remove polluted samples, is one of the main ways to deal with the noise on outputs. However, most of the filters are heuristic and could not explain the filtering influence on the generalization error (GE) bound. The hyper-parameters in various filters are specified manually or empirically, and they are usually unable to adapt to the data environment. The filter with an improper hyper-parameter may overclean, leading to a weak generalization ability. This paper proposes a unified framework of optimal sample selection (OSS) for the output noise filtering from the perspective of error bound. The covering distance filter (CDF) under the framework is presented to deal with noisy outputs in regression and ordinal classification problems. Firstly, two necessary and sufficient conditions for a fixed goodness of fit in regression are deduced from the perspective of GE bound. They provide the unified theoretical framework for determining the filtering effectiveness and optimizing the size of removed samples. The optimal sample size has the adaptability to the environmental changes in the sample size, the noise ratio, and noise variance. It offers a choice of tuning the hyper-parameter and could prevent filters from overcleansing. Meanwhile, the OSS framework can be integrated with any noise estimator and produces a new filter. Then the covering interval is proposed to separate low-noise and high-noise samples, and the effectiveness is proved in regression. The covering distance is introduced as an unbiased estimator of high noises. Further, the CDF algorithm is designed by integrating the cover distance with the OSS framework. Finally, it is verified that the CDF not only recognizes noise labels correctly but also brings down the prediction errors on real apparent age data set. Experimental results on benchmark regression and ordinal classification data sets demonstrate that the CDF outperforms the state-of-the-art filters in terms of prediction ability, noise recognition, and efficiency",
    "checked": true,
    "id": "6eab0641c605096d0c017f5d4c58ba42733c72a1",
    "semantic_title": "a unified sample selection framework for output noise filtering: an error-bound perspective",
    "citation_count": 8,
    "authors": [
      "Gaoxia Jiang",
      "Wenjian Wang",
      "Yuhua Qian",
      "Jiye Liang"
    ]
  },
  "https://jmlr.org/papers/v22/19-542.html": {
    "title": "Ranking and synchronization from pairwise measurements via SVD",
    "volume": "main",
    "abstract": "Given a measurement graph $G= (V,E)$ and an unknown signal $r \\in \\mathbb{R}^n$, we investigate algorithms for recovering $r$ from pairwise measurements of the form $r_i - r_j$; $\\{i,j\\} \\in E$. This problem arises in a variety of applications, such as ranking teams in sports data and time synchronization of distributed networks. Framed in the context of ranking, the task is to recover the ranking of $n$ teams (induced by $r$) given a small subset of noisy pairwise rank offsets. We propose a simple SVD-based algorithmic pipeline for both the problem of time synchronization and ranking. We provide a detailed theoretical analysis in terms of robustness against both sampling sparsity and noise perturbations with outliers, using results from matrix perturbation and random matrix theory. Our theoretical findings are complemented by a detailed set of numerical experiments on both synthetic and real data, showcasing the competitiveness of our proposed algorithms with other state-of-the-art methods",
    "checked": true,
    "id": "6539e43f7b3f1d9764ecb3fd44dca8595c1c4167",
    "semantic_title": "ranking and synchronization from pairwise measurements via svd",
    "citation_count": 20,
    "authors": [
      "Alexandre d'Aspremont",
      "Mihai Cucuringu",
      "Hemant Tyagi"
    ]
  },
  "https://jmlr.org/papers/v22/19-624.html": {
    "title": "Aggregated Hold-Out",
    "volume": "main",
    "abstract": "Aggregated hold-out (agghoo) is a method which averages learning rules selected by hold-out (that is, cross-validation with a single split). We provide the first theoretical guarantees on agghoo, ensuring that it can be used safely: Agghoo performs at worst like the hold-out when the risk is convex. The same holds true in classification with the 0--1 risk, with an additional constant factor. For the hold-out, oracle inequalities are known for bounded losses, as in binary classification. We show that similar results can be proved, under appropriate assumptions, for other risk-minimization problems. In particular, we obtain an oracle inequality for regularized kernel regression with a Lipschitz loss, without requiring that the $Y$ variable or the regressors be bounded. Numerical experiments show that aggregation brings a significant improvement over the hold-out and that agghoo is competitive with cross-validation",
    "checked": true,
    "id": "ec9d163abbd20c019dce4a45831dc950b45c039f",
    "semantic_title": "aggregated hold-out",
    "citation_count": 7,
    "authors": [
      "Guillaume Maillard",
      "Sylvain Arlot",
      "Matthieu Lerasle"
    ]
  },
  "https://jmlr.org/papers/v22/19-629.html": {
    "title": "A Fast Globally Linearly Convergent Algorithm for the Computation of Wasserstein Barycenters",
    "volume": "main",
    "abstract": "We consider the problem of computing a Wasserstein barycenter for a set of discrete probability distributions with finite supports, which finds many applications in areas such as statistics, machine learning and image processing. When the support points of the barycenter are pre-specified, this problem can be modeled as a linear programming (LP) problem whose size can be extremely large. To handle this large-scale LP, we analyse the structure of its dual problem, which is conceivably more tractable and can be reformulated as a well-structured convex problem with 3 kinds of block variables and a coupling linear equality constraint. We then adapt a symmetric Gauss-Seidel based alternating direction method of multipliers (sGS-ADMM) to solve the resulting dual problem and establish its global convergence and global linear convergence rate. As a critical component for efficient computation, we also show how all the subproblems involved can be solved exactly and efficiently. This makes our method suitable for computing a Wasserstein barycenter on a large-scale data set, without introducing an entropy regularization term as is commonly practiced. In addition, our sGS-ADMM can be used as a subroutine in an alternating minimization method to compute a barycenter when its support points are not pre-specified. Numerical results on synthetic data sets and image data sets demonstrate that our method is highly competitive for solving large-scale Wasserstein barycenter problems, in comparison to two existing representative methods and the commercial software Gurobi",
    "checked": true,
    "id": "71d9433e92b33fd0cb023065a7386037ad0959d1",
    "semantic_title": "a fast globally linearly convergent algorithm for the computation of wasserstein barycenters",
    "citation_count": 34,
    "authors": [
      "Lei Yang",
      "Jia Li",
      "Defeng Sun",
      "Kim-Chuan Toh"
    ]
  },
  "https://jmlr.org/papers/v22/19-630.html": {
    "title": "When random initializations help: a study of variational inference for community detection",
    "volume": "main",
    "abstract": "Variational approximation has been widely used in large-scale Bayesian inference recently, the simplest kind of which involves imposing a mean field assumption to approximate complicated latent structures. Despite the computational scalability of mean field, theoretical studies of its loss function surface and the convergence behavior of iterative updates for optimizing the loss are far from complete. In this paper, we focus on the problem of community detection for a simple two-class Stochastic Blockmodel (SBM) with equal class sizes. Using batch co-ordinate ascent (BCAVI) for updates, we show different convergence behavior with respect to different initializations. When the parameters are known or estimated within a reasonable range and held fixed, we characterize conditions under which an initialization can converge to the ground truth. On the other hand, when the parameters need to be estimated iteratively, a random initialization will converge to an uninformative local optimum",
    "checked": true,
    "id": "31a7e34322790bd72d6edd61b588bb97941199cd",
    "semantic_title": "when random initializations help: a study of variational inference for community detection",
    "citation_count": 6,
    "authors": [
      "Purnamrita Sarkar",
      "Y. X. Rachel Wang",
      "Soumendu S. Mukherjee"
    ]
  },
  "https://jmlr.org/papers/v22/19-632.html": {
    "title": "A Two-Level Decomposition Framework Exploiting First and Second Order Information for SVM Training Problems",
    "volume": "main",
    "abstract": "In this work we present a novel way to solve the sub-problems that originate when using decomposition algorithms to train Support Vector Machines (SVMs). State-of-the-art Sequential Minimization Optimization (SMO) solvers reduce the original problem to a sequence of sub-problems of two variables for which the solution is analytical. Although considering more than two variables at a time usually results in a lower number of iterations needed to train an SVM model, solving the sub-problem becomes much harder and the overall computational gains are limited, if any. We propose to apply the two-variables decomposition method to solve the sub-problems themselves and experimentally show that it is a viable and efficient way to deal with sub-problems of up to 50 variables. As a second contribution we explore different ways to select the working set and its size, combining first-order and second-order working set selection rules together with a strategy for exploiting cached elements of the Hessian matrix. An extensive numerical comparison shows that the method performs considerably better than state-of-the-art software",
    "checked": true,
    "id": "fba6f325a2b3db8687ce8ef3a32ef83b351b3c74",
    "semantic_title": "a two-level decomposition framework exploiting first and second order information for svm training problems",
    "citation_count": 2,
    "authors": [
      "Giulio Galvan",
      "Matteo Lapucci",
      "Chih-Jen Lin",
      "Marco Sciandrone"
    ]
  },
  "https://jmlr.org/papers/v22/19-665.html": {
    "title": "Entangled Kernels - Beyond Separability",
    "volume": "main",
    "abstract": "We consider the problem of operator-valued kernel learning and investigate the possibility of going beyond the well-known separable kernels. Borrowing tools and concepts from the field of quantum computing, such as partial trace and entanglement, we propose a new view on operator-valued kernels and define a general family of kernels that encompasses previously known operator-valued kernels, including separable and transformable kernels. Within this framework, we introduce another novel class of operator-valued kernels called entangled kernels that are not separable. We propose an efficient two-step algorithm for this framework, where the entangled kernel is learned based on a novel extension of kernel alignment to operator-valued kernels. We illustrate our algorithm with an application to supervised dimensionality reduction, and demonstrate its effectiveness with both artificial and real data for multi-output regression",
    "checked": true,
    "id": "6d847fd3b33426bfc031109c57d34630c5e34eda",
    "semantic_title": "entangled kernels - beyond separability",
    "citation_count": 7,
    "authors": [
      "Riikka Huusari",
      "Hachem Kadri"
    ]
  },
  "https://jmlr.org/papers/v22/19-716.html": {
    "title": "Generalization Performance of Multi-pass Stochastic Gradient Descent with Convex Loss Functions",
    "volume": "main",
    "abstract": "Stochastic gradient descent (SGD) has become the method of choice to tackle large-scale datasets due to its low computational cost and good practical performance. Learning rate analysis, either capacity-independent or capacity-dependent, provides a unifying viewpoint to study the computational and statistical properties of SGD, as well as the implicit regularization by tuning the number of passes. Existing capacity-independent learning rates require a nontrivial bounded subgradient assumption and a smoothness assumption to be optimal. Furthermore, existing capacity-dependent learning rates are only established for the specific least squares loss with a special structure. In this paper, we provide both optimal capacity-independent and capacity-dependent learning rates for SGD with general convex loss functions. Our results require neither bounded subgradient assumptions nor smoothness assumptions, and are stated with high probability. We achieve this improvement by a refined estimate on the norm of SGD iterates based on a careful martingale analysis and concentration inequalities on empirical processes",
    "checked": true,
    "id": "3d1c05497c2a9d96019061677a10355c75087e5c",
    "semantic_title": "generalization performance of multi-pass stochastic gradient descent with convex loss functions",
    "citation_count": 12,
    "authors": [
      "Yunwen Lei",
      "Ting Hu",
      "Ke Tang"
    ]
  },
  "https://jmlr.org/papers/v22/19-725.html": {
    "title": "Finite Time LTI System Identification",
    "volume": "main",
    "abstract": "We address the problem of learning the parameters of a stable linear time invariant (LTI) system with unknown latent space dimension, or order, from a single time--series of noisy input-output data. We focus on learning the best lower order approximation allowed by finite data. Motivated by subspace algorithms in systems theory, where the doubly infinite system Hankel matrix captures both order and good lower order approximations, we construct a Hankel-like matrix from noisy finite data using ordinary least squares. This circumvents the non-convexities that arise in system identification, and allows accurate estimation of the underlying LTI system. Our results rely on careful analysis of self-normalized martingale difference terms that helps bound identification error up to logarithmic factors of the lower bound. We provide a data-dependent scheme for order selection and find an accurate realization of system parameters, corresponding to that order, by an approach that is closely related to the Ho-Kalman subspace algorithm. We demonstrate that the proposed model order selection procedure is not overly conservative, i.e., for the given data length it is not possible to estimate higher order models or find higher order approximations with reasonable accuracy",
    "checked": true,
    "id": "15a657f1b4e5853af06aeaad578d7798e136a168",
    "semantic_title": "finite time lti system identification",
    "citation_count": 50,
    "authors": [
      "Tuhin Sarkar",
      "Alexander Rakhlin",
      "Munther A. Dahleh"
    ]
  },
  "https://jmlr.org/papers/v22/19-744.html": {
    "title": "Inference In High-dimensional Single-Index Models Under Symmetric Designs",
    "volume": "main",
    "abstract": "The problem of statistical inference for regression coefficients in a high-dimensional single-index model is considered. Under elliptical symmetry, the single index model can be reformulated as a proxy linear model whose regression parameter is identifiable. We construct estimates of the regression coefficients of interest that are similar to the debiased lasso estimates in the standard linear model and exhibit similar properties: $\\sqrt{n}$-consistency and asymptotic normality. The procedure completely bypasses the estimation of the unknown link function, which can be extremely challenging depending on the underlying structure of the problem. Furthermore, under Gaussianity, we propose more efficient estimates of the coefficients by expanding the link function in the Hermite polynomial basis. Finally, we illustrate our approach via carefully designed simulation experiments",
    "checked": true,
    "id": "b53fe066bde4c13cbef69df9dda29b9341aba5eb",
    "semantic_title": "inference in high-dimensional single-index models under symmetric designs",
    "citation_count": 15,
    "authors": [
      "Hamid Eftekhari",
      "Moulinath Banerjee",
      "Ya'acov Ritov"
    ]
  },
  "https://jmlr.org/papers/v22/19-753.html": {
    "title": "Tsallis-INF: An Optimal Algorithm for Stochastic and Adversarial Bandits",
    "volume": "main",
    "abstract": "We derive an algorithm that achieves the optimal (within constants) pseudo-regret in both adversarial and stochastic multi-armed bandits without prior knowledge of the regime and time horizon. The algorithm is based on online mirror descent (OMD) with Tsallis entropy regularization with power $\\alpha=1/2$ and reduced-variance loss estimators. More generally, we define an adversarial regime with a self-bounding constraint, which includes stochastic regime, stochastically constrained adversarial regime, and stochastic regime with adversarial corruptions as special cases, and show that the algorithm achieves logarithmic regret guarantee in this regime and all of its special cases simultaneously with the optimal regret guarantee in the adversarial regime. The algorithm also achieves adversarial and stochastic optimality in the utility-based dueling bandit setting. We provide empirical evaluation of the algorithm demonstrating that it significantly outperforms UCB1 and EXP3 in stochastic environments. We also provide examples of adversarial environments, where UCB1 and Thompson Sampling exhibit almost linear regret, whereas our algorithm suffers only logarithmic regret. To the best of our knowledge, this is the first example demonstrating vulnerability of Thompson Sampling in adversarial environments. Last but not least, we present a general stochastic analysis and a general adversarial analysis of OMD algorithms with Tsallis entropy regularization for $\\alpha\\in[0,1]$ and explain the reason why $\\alpha=1/2$ works best",
    "checked": true,
    "id": "5693554a1d4cf34bf804915d8affd2acaafb454a",
    "semantic_title": "tsallis-inf: an optimal algorithm for stochastic and adversarial bandits",
    "citation_count": 173,
    "authors": [
      "Julian Zimmert",
      "Yevgeny Seldin"
    ]
  },
  "https://jmlr.org/papers/v22/19-770.html": {
    "title": "Single and Multiple Change-Point Detection with Differential Privacy",
    "volume": "main",
    "abstract": "The change-point detection problem seeks to identify distributional changes at an unknown change-point $k^*$ in a stream of data. This problem appears in many important practical settings involving personal data, including biosurveillance, fault detection, finance, signal detection, and security systems. The field of differential privacy offers data analysis tools that provide powerful worst-case privacy guarantees. We study the statistical problem of change-point detection through the lens of differential privacy. We give private algorithms for both online and offline change-point detection, analyze these algorithms theoretically, and provide empirical validation of our results",
    "checked": true,
    "id": "1ce3bf39466221798d3fda44472d5ccc633f9b1a",
    "semantic_title": "single and multiple change-point detection with differential privacy",
    "citation_count": 4,
    "authors": [
      "Wanrong Zhang",
      "Sara Krehbiel",
      "Rui Tuo",
      "Yajun Mei",
      "Rachel Cummings"
    ]
  },
  "https://jmlr.org/papers/v22/19-804.html": {
    "title": "A Review of Robot Learning for Manipulation: Challenges, Representations, and Algorithms",
    "volume": "main",
    "abstract": "A key challenge in intelligent robotics is creating robots that are capable of directly interacting with the world around them to achieve their goals. The last decade has seen substantial growth in research on the problem of robot manipulation, which aims to exploit the increasing availability of affordable robot arms and grippers to create robots capable of directly interacting with the world to achieve their goals. Learning will be central to such autonomous systems, as the real world contains too much variation for a robot to expect to have an accurate model of its environment, the objects in it, or the skills required to manipulate them, in advance. We aim to survey a representative subset of that research which uses machine learning for manipulation. We describe a formalization of the robot manipulation learning problem that synthesizes existing research into a single coherent framework and highlight the many remaining research opportunities and challenges",
    "checked": true,
    "id": "f33ae3a6f47ff3897a7ff12c6a0bacec2223d6d6",
    "semantic_title": "a review of robot learning for manipulation: challenges, representations, and algorithms",
    "citation_count": 265,
    "authors": [
      "Oliver Kroemer",
      "Scott Niekum",
      "George Konidaris"
    ]
  },
  "https://jmlr.org/papers/v22/19-853.html": {
    "title": "FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference",
    "volume": "main",
    "abstract": "A classical problem in causal inference is that of matching, where treatment units need to be matched to control units based on covariate information. In this work, we propose a method that computes high quality almost-exact matches for high-dimensional categorical datasets. This method, called FLAME (Fast Large-scale Almost Matching Exactly), learns a distance metric for matching using a hold-out training data set. In order to perform matching efficiently for large datasets, FLAME leverages techniques that are natural for query processing in the area of database management, and two implementations of FLAME are provided: the first uses SQL queries and the second uses bit-vector techniques. The algorithm starts by constructing matches of the highest quality (exact matches on all covariates), and successively eliminates variables in order to match exactly on as many variables as possible, while still maintaining interpretable high-quality matches and balance between treatment and control groups. We leverage these high quality matches to estimate conditional average treatment effects (CATEs). Our experiments show that FLAME scales to huge datasets with millions of observations where existing state-of-the-art methods fail, and that it achieves significantly better performance than other matching methods",
    "checked": true,
    "id": "5f6e51e21d3ed600731911e1edda9e99b38bad71",
    "semantic_title": "flame: a fast large-scale almost matching exactly approach to causal inference",
    "citation_count": 42,
    "authors": [
      "Tianyu Wang",
      "Marco Morucci",
      "M. Usaid Awan",
      "Yameng Liu",
      "Sudeepa Roy",
      "Cynthia Rudin",
      "Alexander Volfovsky"
    ]
  },
  "https://jmlr.org/papers/v22/19-861.html": {
    "title": "Learning interaction kernels in heterogeneous systems of agents from multiple trajectories",
    "volume": "main",
    "abstract": "Systems of interacting particles, or agents, have wide applications in many disciplines, including Physics, Chemistry, Biology and Economics. These systems are governed by interaction laws, which are often unknown: estimating them from observation data is a fundamental task that can provide meaningful insights and accurate predictions of the behaviour of the agents. In this paper, we consider the inverse problem of learning interaction laws given data from multiple trajectories, in a nonparametric fashion, when the interaction kernels depend on pairwise distances. We establish a condition for learnability of interaction kernels, and construct an estimator based on the minimization of a suitably regularized least squares functional, that is guaranteed to converge, in a suitable $L^2$ space, at the optimal min-max rate for 1-dimensional nonparametric regression. We propose an efficient learning algorithm to construct such estimator, which can be implemented in parallel for multiple trajectories and is therefore well-suited for the high dimensional, big data regime. Numerical simulations on a variety examples, including opinion dynamics, predator-prey and swarm dynamics and heterogeneous particle dynamics, suggest that the learnability condition is satisfied in models used in practice, and the rate of convergence of our estimator is consistent with the theory. These simulations also suggest that our estimators are robust to noise in the observations, and can produce accurate predictions of trajectories in large time intervals, even when they are learned from observations in short time intervals",
    "checked": true,
    "id": "422814376b5e56cf89722eff3f42ce07c6b2d312",
    "semantic_title": "learning interaction kernels in heterogeneous systems of agents from multiple trajectories",
    "citation_count": 40,
    "authors": [
      "Fei Lu",
      "Mauro Maggioni",
      "Sui Tang"
    ]
  },
  "https://jmlr.org/papers/v22/19-910.html": {
    "title": "Asynchronous Online Testing of Multiple Hypotheses",
    "volume": "main",
    "abstract": "We consider the problem of asynchronous online testing, aimed at providing control of the false discovery rate (FDR) during a continual stream of data collection and testing, where each test may be a sequential test that can start and stop at arbitrary times. This setting increasingly characterizes real-world applications in science and industry, where teams of researchers across large organizations may conduct tests of hypotheses in a decentralized manner. The overlap in time and space also tends to induce dependencies among test statistics, a challenge for classical methodology, which either assumes (overly optimistically) independence or (overly pessimistically) arbitrary dependence between test statistics. We present a general framework that addresses both of these issues via a unified computational abstraction that we refer to as \"conflict sets.\" We show how this framework yields algorithms with formal FDR guarantees under a more intermediate, local notion of dependence. We illustrate our algorithms in simulations by comparing to existing algorithms for online FDR control",
    "checked": true,
    "id": "52afbc1e9c1b16d9365d25ebe7f60bb973282bcb",
    "semantic_title": "asynchronous online testing of multiple hypotheses",
    "citation_count": 29,
    "authors": [
      "Tijana Zrnic",
      "Aaditya Ramdas",
      "Michael I. Jordan"
    ]
  },
  "https://jmlr.org/papers/v22/19-924.html": {
    "title": "Neighborhood Structure Assisted Non-negative Matrix Factorization and Its Application in Unsupervised Point-wise Anomaly Detection",
    "volume": "main",
    "abstract": "Dimensionality reduction is considered as an important step for ensuring competitive performance in unsupervised learning such as anomaly detection. Non-negative matrix factorization (NMF) is a widely used method to accomplish this goal. But NMF do not have the provision to include the neighborhood structure information and, as a result, may fail to provide satisfactory performance in presence of nonlinear manifold structure. To address this shortcoming, we propose to consider the neighborhood structural similarity information within the NMF framework and do so by modeling the data through a minimum spanning tree. We label the resulting method as the neighborhood structure-assisted NMF. We further develop both offline and online algorithms for implementing the proposed method. Empirical comparisons using twenty benchmark data sets as well as an industrial data set extracted from a hydropower plant demonstrate the superiority of the neighborhood structure-assisted NMF. Looking closer into the formulation and properties of the proposed NMF method and comparing it with several NMF variants reveal that inclusion of the MST-based neighborhood structure plays a key role in attaining the enhanced performance in anomaly detection",
    "checked": true,
    "id": "ddb47653b6b36fa1f72345b97506f93f4c4d5df6",
    "semantic_title": "neighborhood structure assisted non-negative matrix factorization and its application in unsupervised point anomaly detection",
    "citation_count": 8,
    "authors": [
      "Imtiaz Ahmed",
      "Xia Ben Hu",
      "Mithun P. Acharya",
      "Yu Ding"
    ]
  },
  "https://jmlr.org/papers/v22/20-006.html": {
    "title": "Learning and Planning for Time-Varying MDPs Using Maximum Likelihood Estimation",
    "volume": "main",
    "abstract": "This paper proposes a formal approach to online learning and planning for agents operating in a priori unknown, time-varying environments. The proposed method computes the maximally likely model of the environment, given the observations about the environment made by an agent earlier in the system run and assuming knowledge of a bound on the maximal rate of change of system dynamics. Such an approach generalizes the estimation method commonly used in learning algorithms for unknown Markov decision processes with time-invariant transition probabilities, but is also able to quickly and correctly identify the system dynamics following a change. Based on the proposed method, we generalize the exploration bonuses used in learning for time-invariant Markov decision processes by introducing a notion of uncertainty in a learned time-varying model, and develop a control policy for time-varying Markov decision processes based on the exploitation and exploration trade-off. We demonstrate the proposed methods on four numerical examples: a patrolling task with a change in system dynamics, a two-state MDP with periodically changing outcomes of actions, a wind flow estimation task, and a multi-armed bandit problem with periodically changing probabilities of different rewards",
    "checked": true,
    "id": "6974cc7ae07cd40c488cfac12da50f7deb933113",
    "semantic_title": "learning and planning for time-varying mdps using maximum likelihood estimation",
    "citation_count": 12,
    "authors": [
      "Melkior Ornik",
      "Ufuk Topcu"
    ]
  },
  "https://jmlr.org/papers/v22/20-107.html": {
    "title": "Multi-class Gaussian Process Classification with Noisy Inputs",
    "volume": "main",
    "abstract": "It is a common practice in the machine learning community to assume that the observed data are noise-free in the input attributes. Nevertheless, scenarios with input noise are common in real problems, as measurements are never perfectly accurate. If this input noise is not taken into account, a supervised machine learning method is expected to perform sub-optimally. In this paper, we focus on multi-class classification problems and use Gaussian processes (GPs) as the underlying classifier. Motivated by a data set coming from the astrophysics domain, we hypothesize that the observed data may contain noise in the inputs. Therefore, we devise several multi-class GP classifiers that can account for input noise. Such classifiers can be efficiently trained using variational inference to approximate the posterior distribution of the latent variables of the model. Moreover, in some situations, the amount of noise can be known before-hand. If this is the case, it can be readily introduced in the proposed methods. This prior information is expected to lead to better performance results. We have evaluated the proposed methods by carrying out several experiments, involving synthetic and real data. These include several data sets from the UCI repository, the MNIST data set and a data set coming from astrophysics. The results obtained show that, although the classification error is similar across methods, the predictive distribution of the proposed methods is better, in terms of the test log-likelihood, than the predictive distribution of a classifier based on GPs that ignores input noise",
    "checked": true,
    "id": "21727715e22d298cca108e5e42eec18a6c6d4971",
    "semantic_title": "multi-class gaussian process classification with noisy inputs",
    "citation_count": 17,
    "authors": [
      "Carlos Villacampa-Calvo",
      "Bryan Zald√≠var",
      "Eduardo C. Garrido-Merch√°n",
      "Daniel Hern√°ndez-Lobato"
    ]
  },
  "https://jmlr.org/papers/v22/20-136.html": {
    "title": "A Bayesian Contiguous Partitioning Method for Learning Clustered Latent Variables",
    "volume": "main",
    "abstract": "This article develops a Bayesian partitioning prior model from spanning trees of a graph, by first assigning priors on spanning trees, and then the number and the positions of removed edges given a spanning tree. The proposed method guarantees contiguity in clustering and allows to detect clusters with arbitrary shapes and sizes, whereas most existing partition models such as binary trees and Voronoi tessellations do not possess such properties. We embed this partition model within a hierarchical modeling framework to detect a clustered pattern in latent variables. We focus on illustrating the method through a clustered regression coefficient model for spatial data and propose extensions to other hierarchical models. We prove Bayesian posterior concentration results under an asymptotic framework with random graphs. We design an efficient collapsed Reversible Jump Markov chain Monte Carlo (RJ-MCMC) algorithm to estimate the clustered coefficient values and their uncertainty measures. Finally, we illustrate the performance of the model with simulation studies and a real data analysis of detecting the temperature-salinity relationship from water masses in the Atlantic Ocean",
    "checked": true,
    "id": "6517cb260e98916bfb4bd7dee1ce2b2a605932e7",
    "semantic_title": "a bayesian contiguous partitioning method for learning clustered latent variables",
    "citation_count": 27,
    "authors": [
      "Zhao Tang Luo",
      "Huiyan Sang",
      "Bani Mallick"
    ]
  },
  "https://jmlr.org/papers/v22/20-168.html": {
    "title": "Risk-Averse Learning by Temporal Difference Methods with Markov Risk Measures",
    "volume": "main",
    "abstract": "We propose a novel reinforcement learning methodology where the system performance is evaluated by a Markov coherent dynamic risk measure with the use of linear value function approximations. We construct projected risk-averse dynamic programming equations and study their properties. We propose new risk-averse counterparts of the basic and multi-step methods of temporal differences and we prove their convergence with probability one. We also perform an empirical study on a complex transportation problem",
    "checked": false,
    "id": "0221d36e9a128c48145c68ed856ccb7beede5f7a",
    "semantic_title": "risk-averse learning by temporal difference methods",
    "citation_count": 19,
    "authors": [
      "Umit K√∂se",
      "Andrzej Ruszczy≈Ñski"
    ]
  },
  "https://jmlr.org/papers/v22/20-325.html": {
    "title": "giotto-tda: : A Topological Data Analysis Toolkit for Machine Learning and Data Exploration",
    "volume": "MLOSS",
    "abstract": "We introduce giotto-tda, a Python library that integrates high-performance topological data analysis with machine learning via a scikit-learn-compatible API and state-of-the-art C++ implementations. The library's ability to handle various types of data is rooted in a wide range of preprocessing techniques, and its strong focus on data exploration and interpretability is aided by an intuitive plotting API. Source code, binaries, examples, and documentation can be found at https://github.com/giotto-ai/giotto-tda",
    "checked": true,
    "id": "43e2c8ad47d0f00ed0cfbe884917f158cf600300",
    "semantic_title": "giotto-tda: a topological data analysis toolkit for machine learning and data exploration",
    "citation_count": 138,
    "authors": [
      "Guillaume Tauzin",
      "Umberto Lupo",
      "Lewis Tunstall",
      "Julian Burella P√©rez",
      "Matteo Caorsi",
      "Anibal M. Medina-Mardones",
      "Alberto Dassatti",
      "Kathryn Hess"
    ]
  },
  "https://jmlr.org/papers/v22/20-326.html": {
    "title": "Residual Energy-Based Models for Text",
    "volume": "main",
    "abstract": "Current large-scale auto-regressive language models display impressive fluency and can generate convincing text. In this work we start by asking the question: Can the generations of these models be reliably distinguished from real text by statistical discriminators? We find experimentally that the answer is affirmative when we have access to the training data for the model, and guardedly affirmative even if we do not. This suggests that the auto-regressive models can be improved by incorporating the (globally normalized) discriminators into the generative process. We give a formalism for this using the Energy-Based Model framework, and show that it indeed improves the results of the generative models, measured both in terms of perplexity and in terms of human evaluation",
    "checked": true,
    "id": "9a53971b0098801d1e50b9df6557f759ceef4c48",
    "semantic_title": "residual energy-based models for text",
    "citation_count": 29,
    "authors": [
      "Anton Bakhtin",
      "Yuntian Deng",
      "Sam Gross",
      "Myle Ott",
      "Marc'Aurelio Ranzato",
      "Arthur Szlam"
    ]
  },
  "https://jmlr.org/papers/v22/20-406.html": {
    "title": "From Fourier to Koopman: Spectral Methods for Long-term Time Series Prediction",
    "volume": "main",
    "abstract": "We propose spectral methods for long-term forecasting of temporal signals stemming from linear and nonlinear quasi-periodic dynamical systems. For linear signals, we introduce an algorithm with similarities to the Fourier transform but which does not rely on periodicity assumptions, allowing for forecasting given potentially arbitrary sampling intervals. We then extend this algorithm to handle nonlinearities by leveraging Koopman theory. The resulting algorithm performs a spectral decomposition in a nonlinear, data-dependent basis. The optimization objective for both algorithms is highly non-convex. However, expressing the objective in the frequency domain allows us to compute global optima of the error surface in a scalable and efficient manner, partially by exploiting the computational properties of the Fast Fourier Transform. Because of their close relation to Bayesian Spectral Analysis, uncertainty quantification metrics are a natural byproduct of the spectral forecasting methods. We extensively benchmark these algorithms against other leading forecasting methods on a range of synthetic experiments as well as in the context of real-world power systems and fluid flows",
    "checked": true,
    "id": "11df7f23f72703ceefccc6367a6a18719850c53e",
    "semantic_title": "from fourier to koopman: spectral methods for long-term time series prediction",
    "citation_count": 52,
    "authors": [
      "Henning Lange",
      "Steven L. Brunton",
      "J. Nathan Kutz"
    ]
  },
  "https://jmlr.org/papers/v22/20-576.html": {
    "title": "High-Order Langevin Diffusion Yields an Accelerated MCMC Algorithm",
    "volume": "main",
    "abstract": "We propose a Markov chain Monte Carlo (MCMC) algorithm based on third-order Langevin dynamics for sampling from distributions with smooth, log-concave densities. The higher-order dynamics allow for more flexible discretization schemes, and we develop a specific method that combines splitting with more accurate integration. For a broad class of $d$-dimensional distributions arising from generalized linear models, we prove that the resulting third-order algorithm produces samples from a distribution that is at most $\\varepsilon > 0$ in Wasserstein distance from the target distribution in $O\\left(\\frac{d^{1/4}}{ \\varepsilon^{1/2}} \\right)$ steps. This result requires only Lipschitz conditions on the gradient. For general strongly convex potentials with $\\alpha$-th order smoothness, we prove that the mixing time scales as $O \\left( \\frac{d^{1/4}}{\\varepsilon^{1/2}} + \\frac{d^{1/2}}{ \\varepsilon^{1/(\\alpha - 1)}} \\right)$",
    "checked": true,
    "id": "f791c51e2b051a11bb61bcafc13ce0e9906731b5",
    "semantic_title": "high-order langevin diffusion yields an accelerated mcmc algorithm",
    "citation_count": 71,
    "authors": [
      "Wenlong Mou",
      "Yi-An Ma",
      "Martin J. Wainwright",
      "Peter L. Bartlett",
      "Michael I. Jordan"
    ]
  },
  "https://jmlr.org/papers/v22/20-583.html": {
    "title": "Banach Space Representer Theorems for Neural Networks and Ridge Splines",
    "volume": "main",
    "abstract": "We develop a variational framework to understand the properties of the functions learned by neural networks fit to data. We propose and study a family of continuous-domain linear inverse problems with total variation-like regularization in the Radon domain subject to data fitting constraints. We derive a representer theorem showing that finite-width, single-hidden layer neural networks are solutions to these inverse problems. We draw on many techniques from variational spline theory and so we propose the notion of polynomial ridge splines, which correspond to single-hidden layer neural networks with truncated power functions as the activation function. The representer theorem is reminiscent of the classical reproducing kernel Hilbert space representer theorem, but we show that the neural network problem is posed over a non-Hilbertian Banach space. While the learning problems are posed in the continuous-domain, similar to kernel methods, the problems can be recast as finite-dimensional neural network training problems. These neural network training problems have regularizers which are related to the well-known weight decay and path-norm regularizers. Thus, our result gives insight into functional characteristics of trained neural networks and also into the design neural network regularizers. We also show that these regularizers promote neural network solutions with desirable generalization properties",
    "checked": true,
    "id": "5aaf7b92fdee9968dcbebd9b7d45460a1c0c94a2",
    "semantic_title": "banach space representer theorems for neural networks and ridge splines",
    "citation_count": 83,
    "authors": [
      "Rahul Parhi",
      "Robert D. Nowak"
    ]
  },
  "https://jmlr.org/papers/v22/20-588.html": {
    "title": "Wasserstein barycenters can be computed in polynomial time in fixed dimension",
    "volume": "main",
    "abstract": "Computing Wasserstein barycenters is a fundamental geometric problem with widespread applications in machine learning, statistics, and computer graphics. However, it is unknown whether Wasserstein barycenters can be computed in polynomial time, either exactly or to high precision (i.e., with $\\textrm{polylog}(1/\\varepsilon)$ runtime dependence). This paper answers these questions in the affirmative for any fixed dimension. Our approach is to solve an exponential-size linear programming formulation by efficiently implementing the corresponding separation oracle using techniques from computational geometry",
    "checked": true,
    "id": "2c43343f18eb8b29ad419ade2c12b5c9c101d14d",
    "semantic_title": "wasserstein barycenters can be computed in polynomial time in fixed dimension",
    "citation_count": 36,
    "authors": [
      "Jason M Altschuler",
      "Enric Boix-Adsera"
    ]
  },
  "https://jmlr.org/papers/v22/20-600.html": {
    "title": "RaSE: Random Subspace Ensemble Classification",
    "volume": "main",
    "abstract": "We propose a flexible ensemble classification framework, Random Subspace Ensemble (RaSE), for sparse classification. In the RaSE algorithm, we aggregate many weak learners, where each weak learner is a base classifier trained in a subspace optimally selected from a collection of random subspaces. To conduct subspace selection, we propose a new criterion, ratio information criterion (RIC), based on weighted Kullback-Leibler divergence. The theoretical analysis includes the risk and Monte-Carlo variance of the RaSE classifier, establishing the screening consistency and weak consistency of RIC, and providing an upper bound for the misclassification rate of the RaSE classifier. In addition, we show that in a high-dimensional framework, the number of random subspaces needs to be very large to guarantee that a subspace covering signals is selected. Therefore, we propose an iterative version of the RaSE algorithm and prove that under some specific conditions, a smaller number of generated random subspaces are needed to find a desirable subspace through iteration. An array of simulations under various models and real-data applications demonstrate the effectiveness and robustness of the RaSE classifier and its iterative version in terms of low misclassification rate and accurate feature ranking. The RaSE algorithm is implemented in the R package RaSEn on CRAN",
    "checked": true,
    "id": "96be9b2e87178c819be6252003449906147c6362",
    "semantic_title": "rase: random subspace ensemble classification",
    "citation_count": 21,
    "authors": [
      "Ye Tian",
      "Yang Feng"
    ]
  },
  "https://jmlr.org/papers/v22/20-610.html": {
    "title": "Optimal Structured Principal Subspace Estimation: Metric Entropy and Minimax Rates",
    "volume": "main",
    "abstract": "Driven by a wide range of applications, several principal subspace estimation problems have been studied individually under different structural constraints. This paper presents a unified framework for the statistical analysis of a general structured principal subspace estimation problem which includes as special cases sparse PCA/SVD, non-negative PCA/SVD, subspace constrained PCA/SVD, and spectral clustering. General minimax lower and upper bounds are established to characterize the interplay between the information-geometric complexity of the constraint set for the principal subspaces, the signal-to-noise ratio (SNR), and the dimensionality. The results yield interesting phase transition phenomena concerning the rates of convergence as a function of the SNRs and the fundamental limit for consistent estimation. Applying the general results to the specific settings yields the minimax rates of convergence for those problems, including the previous unknown optimal rates for sparse SVD, non-negative PCA/SVD and subspace constrained PCA/SVD",
    "checked": true,
    "id": "012eda1e8dac302e0e4919728ddd0c2f779be802",
    "semantic_title": "optimal structured principal subspace estimation: metric entropy and minimax rates",
    "citation_count": 11,
    "authors": [
      "Tony Cai",
      "Hongzhe Li",
      "Rong Ma"
    ]
  },
  "https://jmlr.org/papers/v22/20-620.html": {
    "title": "Understanding Recurrent Neural Networks Using Nonequilibrium Response Theory",
    "volume": "main",
    "abstract": "Recurrent neural networks (RNNs) are brain-inspired models widely used in machine learning for analyzing sequential data. The present work is a contribution towards a deeper understanding of how RNNs process input signals using the response theory from nonequilibrium statistical mechanics. For a class of continuous-time stochastic RNNs (SRNNs) driven by an input signal, we derive a Volterra type series representation for their output. This representation is interpretable and disentangles the input signal from the SRNN architecture. The kernels of the series are certain recursively defined correlation functions with respect to the unperturbed dynamics that completely determine the output. Exploiting connections of this representation and its implications to rough paths theory, we identify a universal feature -- the response feature, which turns out to be the signature of tensor product of the input signal and a natural support basis. In particular, we show that SRNNs, with only the weights in the readout layer optimized and the weights in the hidden layer kept fixed and not optimized, can be viewed as kernel machines operating on a reproducing kernel Hilbert space associated with the response feature",
    "checked": true,
    "id": "5e6eee9be7311be9dc2167843ef2fa7130f4f559",
    "semantic_title": "understanding recurrent neural networks using nonequilibrium response theory",
    "citation_count": 13,
    "authors": [
      "Soon Hoe Lim"
    ]
  },
  "https://jmlr.org/papers/v22/20-755.html": {
    "title": "Optimal Feedback Law Recovery by Gradient-Augmented Sparse Polynomial Regression",
    "volume": "main",
    "abstract": "A sparse regression approach for the computation of high-dimensional optimal feedback laws arising in deterministic nonlinear control is proposed. The approach exploits the control-theoretical link between Hamilton-Jacobi-Bellman PDEs characterizing the value function of the optimal control problems, and first-order optimality conditions via Pontryagin's Maximum Principle. The latter is used as a representation formula to recover the value function and its gradient at arbitrary points in the space-time domain through the solution of a two-point boundary value problem. After generating a dataset consisting of different state-value pairs, a hyperbolic cross polynomial model for the value function is fitted using a LASSO regression. An extended set of low and high-dimensional numerical tests in nonlinear optimal control reveal that enriching the dataset with gradient information reduces the number of training samples, and that the sparse polynomial regression consistently yields a feedback law of lower complexity",
    "checked": true,
    "id": "4e19d9bf3432e7b376e96c365aa4d11b9650e096",
    "semantic_title": "optimal feedback law recovery by gradient-augmented sparse polynomial regression",
    "citation_count": 31,
    "authors": [
      "Behzad Azmi",
      "Dante Kalise",
      "Karl Kunisch"
    ]
  },
  "https://jmlr.org/papers/v22/20-821.html": {
    "title": "From Low Probability to High Confidence in Stochastic Convex Optimization",
    "volume": "main",
    "abstract": "Standard results in stochastic convex optimization bound the number of samples that an algorithm needs to generate a point with small function value in expectation. More nuanced high probability guarantees are rare, and typically either rely on light-tail noise assumptions or exhibit worse sample complexity. In this work, we show that a wide class of stochastic optimization algorithms for strongly convex problems can be augmented with high confidence bounds at an overhead cost that is only logarithmic in the confidence level and polylogarithmic in the condition number. The procedure we propose, called proxBoost, is elementary and builds on two well-known ingredients: robust distance estimation and the proximal point method. We discuss consequences for both streaming (online) algorithms and offline algorithms based on empirical risk minimization",
    "checked": true,
    "id": "15c195e0d639973bb6c167a84107ecbbfac1cae8",
    "semantic_title": "from low probability to high confidence in stochastic convex optimization",
    "citation_count": 32,
    "authors": [
      "Damek Davis",
      "Dmitriy Drusvyatskiy",
      "Lin Xiao",
      "Junyu Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/18-401.html": {
    "title": "Structure Learning of Undirected Graphical Models for Count Data",
    "volume": "main",
    "abstract": "Mainly motivated by the problem of modelling biological processes underlying the basic functions of a cell -that typically involve complex interactions between genes- we present a new algorithm, called PC-LPGM, for learning the structure of undirected graphical models over discrete variables. We prove theoretical consistency of PC-LPGM in the limit of infinite observations and discuss its robustness to model misspecification. To evaluate the performance of PC-LPGM in recovering the true structure of the graphs in situations where relatively moderate sample sizes are available, extensive simulation studies are conducted, that also allow to compare our proposal with its main competitors. A biological validation of the algorithm is presented through the analysis of two real data sets",
    "checked": true,
    "id": "547747c3083489675f0d504cb1243d3a06c12e01",
    "semantic_title": "structure learning of undirected graphical models for count data",
    "citation_count": 5,
    "authors": [
      "Nguyen Thi Kim Hue",
      "Monica Chiogna"
    ]
  },
  "https://jmlr.org/papers/v22/18-407.html": {
    "title": "Projection-free Decentralized Online Learning for Submodular Maximization over Time-Varying Networks",
    "volume": "main",
    "abstract": "This paper considers a decentralized online submodular maximization problem over time-varying networks, where each agent only utilizes its own information and the received information from its neighbors. To address the problem, we propose a decentralized Meta-Frank-Wolfe online learning method in the adversarial online setting by using local communication and local computation. Moreover, we show that an expected regret bound of $O(\\sqrt{T})$ is achieved with $(1-1/e)$ approximation guarantee, where $T$ is a time horizon. In addition, we also propose a decentralized one-shot Frank-Wolfe online learning method in the stochastic online setting. Furthermore, we also show that an expected regret bound $O(T^{2/3})$ is obtained with $(1-1/e)$ approximation guarantee. Finally, we confirm the theoretical results via various experiments on different datasets",
    "checked": true,
    "id": "59fe38217f2c61fab1d347b80d2f1b34e4389d21",
    "semantic_title": "projection-free decentralized online learning for submodular maximization over time-varying networks",
    "citation_count": 9,
    "authors": [
      "Junlong Zhu",
      "Qingtao Wu",
      "Mingchuan Zhang",
      "Ruijuan Zheng",
      "Keqin Li"
    ]
  },
  "https://jmlr.org/papers/v22/18-745.html": {
    "title": "Sparse and Smooth Signal Estimation: Convexification of L0-Formulations",
    "volume": "main",
    "abstract": "Signal estimation problems with smoothness and sparsity priors can be naturally modeled as quadratic optimization with $\\ell_0$-\"norm\" constraints. Since such problems are non-convex and hard-to-solve, the standard approach is, instead, to tackle their convex surrogates based on $\\ell_1$-norm relaxations. In this paper, we propose new iterative (convex) conic quadratic relaxations that exploit not only the $\\ell_0$-\"norm\" terms, but also the fitness and smoothness functions. The iterative convexification approach substantially closes the gap between the $\\ell_0$-\"norm\" and its $\\ell_1$ surrogate. These stronger relaxations lead to significantly better estimators than $\\ell_1$-norm approaches and also allow one to utilize affine sparsity priors. In addition, the parameters of the model and the resulting estimators are easily interpretable. Experiments with a tailored Lagrangian decomposition method indicate that the proposed iterative convex relaxations yield solutions within 1\\% of the exact $\\ell_0$-approach, and can tackle instances with up to 100,000 variables under one minute",
    "checked": true,
    "id": "d7b0cf239306b2866812f4d7e8ee5f9f851c6ea7",
    "semantic_title": "",
    "citation_count": 35,
    "authors": [
      "Alper Atamturk",
      "Andres Gomez",
      "Shaoning Han"
    ]
  },
  "https://jmlr.org/papers/v22/18-780.html": {
    "title": "Subspace Clustering through Sub-Clusters",
    "volume": "main",
    "abstract": "The problem of dimension reduction is of increasing importance in modern data analysis. In this paper, we consider modeling the collection of points in a high dimensional space as a union of low dimensional subspaces. In particular we propose a highly scalable sampling based algorithm that clusters the entire data via first spectral clustering of a small random sample followed by classifying or labeling the remaining out-of-sample points. The key idea is that this random subset borrows information across the entire dataset and that the problem of clustering points can be replaced with the more efficient problem of \"clustering sub-clusters\". We provide theoretical guarantees for our procedure. The numerical results indicate that for large datasets the proposed algorithm outperforms other state-of-the-art subspace clustering algorithms with respect to accuracy and speed",
    "checked": true,
    "id": "d8d1605fba911a06d502142ab8ef32d14bc35058",
    "semantic_title": "subspace clustering through sub-clusters",
    "citation_count": 4,
    "authors": [
      "Weiwei Li",
      "Jan Hannig",
      "Sayan Mukherjee"
    ]
  },
  "https://jmlr.org/papers/v22/19-1006.html": {
    "title": "GemBag: Group Estimation of Multiple Bayesian Graphical Models",
    "volume": "main",
    "abstract": "In this paper, we propose a novel hierarchical Bayesian model and an efficient estimation method for the problem of joint estimation of multiple graphical models, which have similar but different sparsity structures and signal strength. Our proposed hierarchical Bayesian model is well suited for sharing of sparsity structures, and our procedure, called as GemBag, is shown to enjoy optimal theoretical properties in terms of sup-norm estimation accuracy and correct recovery of the graphical structure even when some of the signals are weak. Although optimization of the posterior distribution required for obtaining our proposed estimator is a non-convex optimization problem, we show that it turns out to be convex in a large constrained space facilitating the use of computationally efficient algorithms. Through extensive simulation studies and an application to a bike sharing data set, we demonstrate that the proposed GemBag procedure has strong empirical performance in comparison with alternative methods",
    "checked": true,
    "id": "70324d6aa1fe06df63715fbe70c05d8a7fa2fef9",
    "semantic_title": "gembag: group estimation of multiple bayesian graphical models",
    "citation_count": 8,
    "authors": [
      "Xinming Yang",
      "Lingrui Gan",
      "Naveen N. Narisetty",
      "Feng Liang"
    ]
  },
  "https://jmlr.org/papers/v22/19-1012.html": {
    "title": "Integrative Generalized Convex Clustering Optimization and Feature Selection for Mixed Multi-View Data",
    "volume": "main",
    "abstract": "In mixed multi-view data, multiple sets of diverse features are measured on the same set of samples. By integrating all available data sources, we seek to discover common group structure among the samples that may be hidden in individualistic cluster analyses of a single data view. While several techniques for such integrative clustering have been explored, we propose and develop a convex formalization that enjoys strong empirical performance and inherits the mathematical properties of increasingly popular convex clustering methods. Specifically, our Integrative Generalized Convex Clustering Optimization (iGecco) method employs different convex distances, losses, or divergences for each of the different data views with a joint convex fusion penalty that leads to common groups. Additionally, integrating mixed multi-view data is often challenging when each data source is high-dimensional. To perform feature selection in such scenarios, we develop an adaptive shifted group-lasso penalty that selects features by shrinking them towards their loss-specific centers. Our so-called iGecco+ approach selects features from each data view that are best for determining the groups, often leading to improved integrative clustering. To solve our problem, we develop a new type of generalized multi-block ADMM algorithm using sub-problem approximations that more efficiently fits our model for big data sets. Through a series of numerical experiments and real data examples on text mining and genomics, we show that iGecco+ achieves superior empirical performance for high-dimensional mixed multi-view data",
    "checked": true,
    "id": "73e90eb0ceb15441e761a2335e2cdffe3054c0af",
    "semantic_title": "integrative generalized convex clustering optimization and feature selection for mixed multi-view data",
    "citation_count": 24,
    "authors": [
      "Minjie Wang",
      "Genevera I. Allen"
    ]
  },
  "https://jmlr.org/papers/v22/19-1023.html": {
    "title": "Incorporating Unlabeled Data into Distributionally Robust Learning",
    "volume": "main",
    "abstract": "We study a robust alternative to empirical risk minimization called distributionally robust learning (DRL), in which one learns to perform against an adversary who can choose the data distribution from a specified set of distributions. We illustrate a problem with current DRL formulations, which rely on an overly broad definition of allowed distributions for the adversary, leading to learned classifiers that are unable to predict with any confidence. We propose a solution that incorporates unlabeled data into the DRL problem to further constrain the adversary. We show that this new formulation is tractable for stochastic gradient-based optimization and yields a computable guarantee on the future performance of the learned classifier, analogous to -- but tighter than -- guarantees from conventional DRL. We examine the performance of this new formulation on 14 real data sets and find that it often yields effective classifiers with nontrivial performance guarantees in situations where conventional DRL produces neither. Inspired by these results, we extend our DRL formulation to active learning with a novel, distributionally-robust version of the standard model-change heuristic. Our active learning algorithm often achieves superior learning performance to the original heuristic on real data sets",
    "checked": true,
    "id": "1d26ab851edfe193213ab4dd7fa91167f14ff8d4",
    "semantic_title": "incorporating unlabeled data into distributionally robust learning",
    "citation_count": 23,
    "authors": [
      "Charlie Frogner",
      "Sebastian Claici",
      "Edward Chien",
      "Justin Solomon"
    ]
  },
  "https://jmlr.org/papers/v22/19-1028.html": {
    "title": "Normalizing Flows for Probabilistic Modeling and Inference",
    "volume": "main",
    "abstract": "Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning",
    "checked": true,
    "id": "501c02c7caa7fc2c7077405299b4cbe7d294b170",
    "semantic_title": "normalizing flows for probabilistic modeling and inference",
    "citation_count": 1199,
    "authors": [
      "George Papamakarios",
      "Eric Nalisnick",
      "Danilo Jimenez Rezende",
      "Shakir Mohamed",
      "Balaji Lakshminarayanan"
    ]
  },
  "https://jmlr.org/papers/v22/19-132.html": {
    "title": "Estimation and Inference for High Dimensional Generalized Linear Models: A Splitting and Smoothing Approach",
    "volume": "main",
    "abstract": "The focus of modern biomedical studies has gradually shifted to explanation and estimation of joint effects of high dimensional predictors on disease risks. Quantifying uncertainty in these estimates may provide valuable insight into prevention strategies or treatment decisions for both patients and physicians. High dimensional inference, including confidence intervals and hypothesis testing, has sparked much interest. While much work has been done in the linear regression setting, there is lack of literature on inference for high dimensional generalized linear models. We propose a novel and computationally feasible method, which accommodates a variety of outcome types, including normal, binomial, and Poisson data. We use a \"splitting and smoothing\" approach, which splits samples into two parts, performs variable selection using one part and conducts partial regression with the other part. Averaging the estimates over multiple random splits, we obtain the smoothed estimates, which are numerically stable. We show that the estimates are consistent, asymptotically normal, and construct confidence intervals with proper coverage probabilities for all predictors. We examine the finite sample performance of our method by comparing it with the existing methods and applying it to analyze a lung cancer cohort study",
    "checked": true,
    "id": "25a1363f94a16f6457db49b6b1ea5c935e55e3e8",
    "semantic_title": "estimation and inference for high dimensional generalized linear models: a splitting and smoothing approach",
    "citation_count": 16,
    "authors": [
      "Zhe Fei",
      "Yi Li"
    ]
  },
  "https://jmlr.org/papers/v22/19-149.html": {
    "title": "Predictive Learning on Hidden Tree-Structured Ising Models",
    "volume": "main",
    "abstract": "We provide high-probability sample complexity guarantees for exact structure recovery and accurate predictive learning using noise-corrupted samples from an acyclic (tree-shaped) graphical model. The hidden variables follow a tree-structured Ising model distribution, whereas the observable variables are generated by a binary symmetric channel taking the hidden variables as its input (flipping each bit independently with some constant probability $q\\in [0,1/2)$). In the absence of noise, predictive learning on Ising models was recently studied by Bresler and Karzand (2020); this paper quantifies how noise in the hidden model impacts the tasks of structure recovery and marginal distribution estimation by proving upper and lower bounds on the sample complexity. Our results generalize state-of-the-art bounds reported in prior work, and they exactly recover the noiseless case ($q=0$). In fact, for any tree with $p$ vertices and probability of incorrect recovery $\\delta>0$, the sufficient number of samples remains logarithmic as in the noiseless case, i.e., $\\mathcal{O}(\\log(p/\\delta))$, while the dependence on $q$ is $\\mathcal{O}\\big( 1/(1-2q)^{4} \\big)$, for both aforementioned tasks. We also present a new equivalent of Isserlis' Theorem for sign-valued tree-structured distributions, yielding a new low-complexity algorithm for higher-order moment estimation",
    "checked": false,
    "id": "5583e891436c849d2e83d8a71c23fae3598e13cf",
    "semantic_title": "fea and machine learning techniques for hidden structure analysis",
    "citation_count": 0,
    "authors": [
      "Konstantinos E. Nikolakakis",
      "Dionysios S. Kalogerias",
      "Anand D. Sarwate"
    ]
  },
  "https://jmlr.org/papers/v22/19-345.html": {
    "title": "A Distributed Method for Fitting Laplacian Regularized Stratified Models",
    "volume": "main",
    "abstract": "Stratified models are models that depend in an arbitrary way on a set of selected categorical features, and depend linearly on the other features. In a basic and traditional formulation a separate model is fit for each value of the categorical feature, using only the data that has the specific categorical value. To this formulation we add Laplacian regularization, which encourages the model parameters for neighboring categorical values to be similar. Laplacian regularization allows us to specify one or more weighted graphs on the stratification feature values. For example, stratifying over the days of the week, we can specify that the Sunday model parameter should be close to the Saturday and Monday model parameters. The regularization improves the performance of the model over the traditional stratified model, since the model for each value of the categorical `borrows strength' from its neighbors. In particular, it produces a model even for categorical values that did not appear in the training data set. We propose an efficient distributed method for fitting stratified models, based on the alternating direction method of multipliers (ADMM). When the fitting loss functions are convex, the stratified model fitting problem is convex, and our method computes the global minimizer of the loss plus regularization; in other cases it computes a local minimizer. The method is very efficient, and naturally scales to large data sets or numbers of stratified feature values. We illustrate our method with a variety of examples",
    "checked": true,
    "id": "30038069e9065185fe8f77db32644d6f4ae3d3c2",
    "semantic_title": "a distributed method for fitting laplacian regularized stratified models",
    "citation_count": 21,
    "authors": [
      "Jonathan Tuck",
      "Shane Barratt",
      "Stephen Boyd"
    ]
  },
  "https://jmlr.org/papers/v22/19-418.html": {
    "title": "Stochastic Proximal AUC Maximization",
    "volume": "main",
    "abstract": "In this paper we consider the problem of maximizing the Area under the ROC curve (AUC) which is a widely used performance metric in imbalanced classification and anomaly detection. Due to the pairwise nonlinearity of the objective function, classical SGD algorithms do not apply to the task of AUC maximization. We propose a novel stochastic proximal algorithm for AUC maximization which is scalable to large scale streaming data. Our algorithm can accommodate general penalty terms and is easy to implement with favorable $O(d)$ space and per-iteration time complexities. We establish a high-probability convergence rate $O(1/\\sqrt{T})$ for the general convex setting, and improve it to a fast convergence rate $O(1/T)$ for the cases of strongly convex regularizers and no regularization term (without strong convexity). Our proof does not need the uniform boundedness assumption on the loss function or the iterates which is more fidelity to the practice. Finally, we perform extensive experiments over various benchmark data sets from real-world application domains which show the superior performance of our algorithm over the existing AUC maximization algorithms",
    "checked": true,
    "id": "c4af7a8b6c8f78e664b955511bc7083befaffb40",
    "semantic_title": "stochastic proximal auc maximization",
    "citation_count": 22,
    "authors": [
      "Yunwen Lei",
      "Yiming Ying"
    ]
  },
  "https://jmlr.org/papers/v22/19-600.html": {
    "title": "How to Gain on Power: Novel Conditional Independence Tests Based on Short Expansion of Conditional Mutual Information",
    "volume": "main",
    "abstract": "Conditional independence tests play a crucial role in many machine learning procedures such as feature selection, causal discovery, and structure learning of dependence networks. They are used in most of the existing algorithms for Markov Blanket discovery such as Grow-Shrink or Incremental Association Markov Blanket. One of the most frequently used tests for categorical variables is based on the conditional mutual information ($CMI$) and its asymptotic distribution. However, it is known that the power of such test dramatically decreases when the size of the conditioning set grows, i.e. the test fails to detect true significant variables, when the set of already selected variables is large. To overcome this drawback for discrete data, we propose to replace the conditional mutual information by Short Expansion of Conditional Mutual Information (called $SECMI$), obtained by truncating the M√∂bius representation of $CMI$. We prove that the distribution of $SECMI$ converges to either a normal distribution or to a distribution of some quadratic form in normal random variables. This property is crucial for the construction of a novel test of conditional independence which uses one of these distributions, chosen in a data dependent way, as a reference under the null hypothesis. The proposed methods have significantly larger power for discrete data than the standard asymptotic tests of conditional independence based on $CMI$ while retaining control of the probability of type I error",
    "checked": true,
    "id": "3d1a0a2c8c3fa2c3fcb4b76a335691771259d8b0",
    "semantic_title": "how to gain on power: novel conditional independence tests based on short expansion of conditional mutual information",
    "citation_count": 11,
    "authors": [
      "Mariusz Kubkowski",
      "Jan Mielniczuk",
      "Pawe≈Ç Teisseyre"
    ]
  },
  "https://jmlr.org/papers/v22/19-683.html": {
    "title": "Geometric structure of graph Laplacian embeddings",
    "volume": "main",
    "abstract": "We analyze the spectral clustering procedure for identifying coarse structure in a data set $\\mathbf{x}_1, \\dots, \\mathbf{x}_n$, and in particular study the geometry of graph Laplacian embeddings which form the basis for spectral clustering algorithms. More precisely, we assume that the data are sampled from a mixture model supported on a manifold $\\mathcal{M}$ embedded in $\\mathbb{R}^d$, and pick a connectivity length-scale $\\varepsilon>0$ to construct a kernelized graph Laplacian. We introduce a notion of a well-separated mixture model which only depends on the model itself, and prove that when the model is well separated, with high probability the embedded data set concentrates on cones that are centered around orthogonal vectors. Our results are meaningful in the regime where $\\varepsilon = \\varepsilon(n)$ is allowed to decay to zero at a slow enough rate as the number of data points grows. This rate depends on the intrinsic dimension of the manifold on which the data is supported",
    "checked": true,
    "id": "2c551b0b009b5a4dba643b0e9730ee0d80d4f081",
    "semantic_title": "geometric structure of graph laplacian embeddings",
    "citation_count": 18,
    "authors": [
      "Nicol√°s Garc√≠a Trillos",
      "Franca Hoffmann",
      "Bamdad Hosseini"
    ]
  },
  "https://jmlr.org/papers/v22/19-769.html": {
    "title": "Sparse Tensor Additive Regression",
    "volume": "main",
    "abstract": "Tensors are becoming prevalent in modern applications such as medical imaging and digital marketing. In this paper, we propose a sparse tensor additive regression (STAR) that models a scalar response as a flexible nonparametric function of tensor covariates. The proposed model effectively exploits the sparse and low-rank structures in the tensor additive regression. We formulate the parameter estimation as a non-convex optimization problem, and propose an efficient penalized alternating minimization algorithm. We establish a non-asymptotic error bound for the estimator obtained from each iteration of the proposed algorithm, which reveals an interplay between the optimization error and the statistical rate of convergence. We demonstrate the efficacy of STAR through extensive comparative simulation studies, and an application to the click-through-rate prediction in online advertising",
    "checked": true,
    "id": "e702da6dd47efa254743aacc90aa690a35e614cc",
    "semantic_title": "sparse tensor additive regression",
    "citation_count": 21,
    "authors": [
      "Botao Hao",
      "Boxiang Wang",
      "Pengyuan Wang",
      "Jingfei Zhang",
      "Jian Yang",
      "Will Wei Sun"
    ]
  },
  "https://jmlr.org/papers/v22/19-792.html": {
    "title": "Dynamic Tensor Recommender Systems",
    "volume": "main",
    "abstract": "Recommender systems have been extensively used by the entertainment industry, business marketing and the biomedical industry. In addition to its capacity of providing preference based recommendations as an unsupervised learning methodology, it has been also proven useful in sales forecasting, product introduction and other production related businesses. Since some consumers and companies need a recommendation or prediction for future budget, labor and supply chain coordination, dynamic recommender systems for precise forecasting have become extremely necessary. In this article, we propose a new recommendation method, namely the dynamic tensor recommender system (DTRS), which aims particularly at forecasting future recommendation. The proposed method utilizes a tensor-valued function of time to integrate time and contextual information, and creates a time-varying coefficient model for temporal tensor factorization through a polynomial spline approximation. Major advantages of the proposed method include competitive future recommendation predictions and effective prediction interval estimations. In theory, we establish the convergence rate of the proposed tensor factorization and asymptotic normality of the spline coefficient estimator. The proposed method is applied to simulations, IRI marketing data and Last.fm data. Numerical studies demonstrate that the proposed method outperforms existing methods in terms of future time forecasting",
    "checked": true,
    "id": "e8b33e67073fcba1a4002144eba2dbcd795059e4",
    "semantic_title": "dynamic tensor recommender systems",
    "citation_count": 22,
    "authors": [
      "Yanqing Zhang",
      "Xuan Bi",
      "Niansheng Tang",
      "Annie Qu"
    ]
  },
  "https://jmlr.org/papers/v22/19-870.html": {
    "title": "Approximate Newton Methods",
    "volume": "main",
    "abstract": "Many machine learning models involve solving optimization problems. Thus, it is important to address a large-scale optimization problem in big data applications. Recently, subsampled Newton methods have emerged to attract much attention due to their efficiency at each iteration, rectified a weakness in the ordinary Newton method of suffering a high cost in each iteration while commanding a high convergence rate. Other efficient stochastic second order methods have been also proposed. However, the convergence properties of these methods are still not well understood. There are also several important gaps between the current convergence theory and the empirical performance in real applications. In this paper, we aim to fill these gaps. We propose a unifying framework to analyze both local and global convergence properties of second order methods. Accordingly, we present our theoretical results which match the empirical performance in real applications well",
    "checked": true,
    "id": "3390bfd875fe6c1e617eaedadaf35f50a047d721",
    "semantic_title": "approximate newton methods",
    "citation_count": 6,
    "authors": [
      "Haishan Ye",
      "Luo Luo",
      "Zhihua Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/19-873.html": {
    "title": "A General Framework for Empirical Bayes Estimation in Discrete Linear Exponential Family",
    "volume": "main",
    "abstract": "We develop a Nonparametric Empirical Bayes (NEB) framework for compound estimation in the discrete linear exponential family, which includes a wide class of discrete distributions frequently arising from modern big data applications. We propose to directly estimate the Bayes shrinkage factor in the generalized Robbins' formula via solving a convex program, which is carefully developed based on a RKHS representation of the Stein's discrepancy measure. The new NEB estimation framework is flexible for incorporating various structural constraints into the data driven rule, and provides a unified approach to compound estimation with both regular and scaled squared error losses. We develop theory to show that the class of NEB estimators enjoys strong asymptotic properties. Comprehensive simulation studies as well as analyses of real data examples are carried out to demonstrate the superiority of the NEB estimator over competing methods",
    "checked": true,
    "id": "e00fcf83c15dcec9e75039a249dc5920449feeec",
    "semantic_title": "a general framework for empirical bayes estimation in discrete linear exponential family",
    "citation_count": 7,
    "authors": [
      "Trambak Banerjee",
      "Qiang Liu",
      "Gourab Mukherjee",
      "Wengunag Sun"
    ]
  },
  "https://jmlr.org/papers/v22/19-979.html": {
    "title": "Path Length Bounds for Gradient Descent and Flow",
    "volume": "main",
    "abstract": "We derive bounds on the path length $\\zeta$ of gradient descent (GD) and gradient flow (GF) curves for various classes of smooth convex and nonconvex functions. Among other results, we prove that: (a) if the iterates are linearly convergent with factor $(1-c)$, then $\\zeta$ is at most $\\mathcal{O}(1/c)$; (b) under the Polyak-Kurdyka-\\L ojasiewicz (PKL) condition, $\\zeta$ is at most $\\mathcal{O}(\\sqrt{\\kappa})$, where $\\kappa$ is the condition number, and at least $\\widetilde\\Omega(\\sqrt{d} \\wedge \\kappa^{1/4})$; (c) for quadratics, $\\zeta$ is $\\Theta(\\min\\{\\sqrt{d},\\sqrt{\\log \\kappa}\\})$ and in some cases can be independent of $\\kappa$; (d) assuming just convexity, $\\zeta$ can be at most $2^{4d\\log d}$; (e) for separable quasiconvex functions, $\\zeta$ is ${\\Theta}(\\sqrt{d})$. Thus, we advance current understanding of the properties of GD and GF curves beyond rates of convergence. We expect our techniques to facilitate future studies for other algorithms",
    "checked": true,
    "id": "206b67ab54571b4e6c7f4de77af0941184e1e101",
    "semantic_title": "path length bounds for gradient descent and flow",
    "citation_count": 14,
    "authors": [
      "Chirag Gupta",
      "Sivaraman Balakrishnan",
      "Aaditya Ramdas"
    ]
  },
  "https://jmlr.org/papers/v22/20-037.html": {
    "title": "Determining the Number of Communities in Degree-corrected Stochastic Block Models",
    "volume": "main",
    "abstract": "We propose to estimate the number of communities in degree-corrected stochastic block models based on a pseudo likelihood ratio statistic. To this end, we introduce a method that combines spectral clustering with binary segmentation. This approach guarantees an upper bound for the pseudo likelihood ratio statistic when the model is over-fitted. We also derive its limiting distribution when the model is under-fitted. Based on these properties, we establish the consistency of our estimator for the true number of communities. Developing these theoretical properties require a mild condition on the average degrees - growing at a rate no slower than log(n), where n is the number of nodes. Our proposed method is further illustrated by simulation studies and analysis of real-world networks. The numerical results show that our approach has satisfactory performance when the network is semi-dense",
    "checked": false,
    "id": "f657864b5ccd6c05ccdc4eebbe16b9bd164178cf",
    "semantic_title": "adjusted chi-square test for degree-corrected block models",
    "citation_count": 2,
    "authors": [
      "Shujie Ma",
      "Liangjun Su",
      "Yichong Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/20-1074.html": {
    "title": "Testing Conditional Independence via Quantile Regression Based Partial Copulas",
    "volume": "main",
    "abstract": "The partial copula provides a method for describing the dependence between two random variables $X$ and $Y$ conditional on a third random vector $Z$ in terms of nonparametric residuals $U_1$ and $U_2$. This paper develops a nonparametric test for conditional independence by combining the partial copula with a quantile regression based method for estimating the nonparametric residuals. We consider a test statistic based on generalized correlation between $U_1$ and $U_2$ and derive its large sample properties under consistency assumptions on the quantile regression procedure. We demonstrate through a simulation study that the resulting test is sound under complicated data generating distributions. Moreover, in the examples considered the test is competitive to other state-of-the-art conditional independence tests in terms of level and power, and it has superior power in cases with conditional variance heterogeneity of $X$ and $Y$ given $Z$",
    "checked": true,
    "id": "ee6caed589f0da3f385cd0684fc48fefd8ee7bcf",
    "semantic_title": "testing conditional independence via quantile regression based partial copulas",
    "citation_count": 13,
    "authors": [
      "Lasse Petersen",
      "Niels Richard Hansen"
    ]
  },
  "https://jmlr.org/papers/v22/20-1123.html": {
    "title": "Phase Diagram for Two-layer ReLU Neural Networks at Infinite-width Limit",
    "volume": "main",
    "abstract": "How neural network behaves during the training over different choices of hyperparameters is an important question in the study of neural networks. In this work, inspired by the phase diagram in statistical mechanics, we draw the phase diagram for the two-layer ReLU neural network at the infinite-width limit for a complete characterization of its dynamical regimes and their dependence on hyperparameters related to initialization. Through both experimental and theoretical approaches, we identify three regimes in the phase diagram, i.e., linear regime, critical regime and condensed regime, based on the relative change of input weights as the width approaches infinity, which tends to $0$, $O(1)$ and $+\\infty$, respectively. In the linear regime, NN training dynamics is approximately linear similar to a random feature model with an exponential loss decay. In the condensed regime, we demonstrate through experiments that active neurons are condensed at several discrete orientations. The critical regime serves as the boundary between above two regimes, which exhibits an intermediate nonlinear behavior with the mean-field model as a typical example. Overall, our phase diagram for the two-layer ReLU NN serves as a map for the future studies and is a first step towards a more systematical investigation of the training behavior and the implicit regularization of NNs of different structures",
    "checked": true,
    "id": "f4843386f4d922b1526f9c0b557a30bdb9cec38f",
    "semantic_title": "phase diagram for two-layer relu neural networks at infinite-width limit",
    "citation_count": 39,
    "authors": [
      "Tao Luo",
      "Zhi-Qin John Xu",
      "Zheng Ma",
      "Yaoyu Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/20-1234.html": {
    "title": "Prediction against a limited adversary",
    "volume": "main",
    "abstract": "We study the problem of prediction with expert advice with adversarial corruption where the adversary can at most corrupt one expert. Using tools from viscosity theory, we characterize the long-time behavior of the value function of the game between the forecaster and the adversary. We provide lower and upper bounds for the growth rate of regret without relying on a comparison result. We show that depending on the description of regret, the limiting behavior of the game can significantly differ",
    "checked": true,
    "id": "3254f36f14bc4856019c5a84a914788dde224613",
    "semantic_title": "prediction against limited adversary",
    "citation_count": 4,
    "authors": [
      "Erhan Bayraktar",
      "Ibrahim Ekren",
      "Xin Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/20-207.html": {
    "title": "Optimization with Momentum: Dynamical, Control-Theoretic, and Symplectic Perspectives",
    "volume": "main",
    "abstract": "We analyze the convergence rate of various momentum-based optimization algorithms from a dynamical systems point of view. Our analysis exploits fundamental topological properties, such as the continuous dependence of iterates on their initial conditions, to provide a simple characterization of convergence rates. In many cases, closed-form expressions are obtained that relate algorithm parameters to the convergence rate. The analysis encompasses discrete time and continuous time, as well as time-invariant and time-variant formulations, and is not limited to a convex or Euclidean setting. In addition, the article rigorously establishes why symplectic discretization schemes are important for momentum-based optimization algorithms, and provides a characterization of algorithms that exhibit accelerated convergence",
    "checked": true,
    "id": "cc2f82503f7c26bb57daba3fdc8de6b446fb2bfb",
    "semantic_title": "optimization with momentum: dynamical, control-theoretic, and symplectic perspectives",
    "citation_count": 52,
    "authors": [
      "Michael Muehlebach",
      "Michael I. Jordan"
    ]
  },
  "https://jmlr.org/papers/v22/20-275.html": {
    "title": "Kernel Operations on the GPU, with Autodiff, without Memory Overflows",
    "volume": "MLOSS",
    "abstract": "The KeOps library provides a fast and memory-efficient GPU support for tensors whose entries are given by a mathematical formula, such as kernel and distance matrices. KeOps alleviates the main bottleneck of tensor-centric libraries for kernel and geometric applications: memory consumption. It also supports automatic differentiation and outperforms standard GPU baselines, including PyTorch CUDA tensors or the Halide and TVM libraries. KeOps combines optimized C++/CUDA schemes with binders for high-level languages: Python (Numpy and PyTorch), Matlab and GNU R. As a result, high-level \"quadratic\" codes can now scale up to large data sets with millions of samples processed in seconds. KeOps brings graphics-like performances for kernel methods and is freely available on standard repositories (PyPi, CRAN). To showcase its versatility, we provide tutorials in a wide range of settings online at www.kernel-operations.io",
    "checked": true,
    "id": "3f172dffae897113062fc0198f6b05c0195bf5fc",
    "semantic_title": "kernel operations on the gpu, with autodiff, without memory overflows",
    "citation_count": 138,
    "authors": [
      "Benjamin Charlier",
      "Jean Feydy",
      "Joan Alexis Glaun√®s",
      "Fran√ßois-David Collin",
      "Ghislain Durif"
    ]
  },
  "https://jmlr.org/papers/v22/20-302.html": {
    "title": "Attention is Turing-Complete",
    "volume": "main",
    "abstract": "Alternatives to recurrent neural networks, in particular, architectures based on self-attention, are gaining momentum for processing input sequences. In spite of their relevance, the computational properties of such networks have not yet been fully explored.We study the computational power of the Transformer, one of the most paradigmatic architectures exemplifying self-attention. We show that the Transformer with hard-attention is Turing complete exclusively based on their capacity to compute and access internal dense representations of the data.Our study also reveals some minimal sets of elements needed to obtain this completeness result",
    "checked": true,
    "id": "c4cb90a67f45e7cbacb5286e934b309e89843922",
    "semantic_title": "attention is turing-complete",
    "citation_count": 63,
    "authors": [
      "Jorge P√©rez",
      "Pablo Barcel√≥",
      "Javier Marinkovic"
    ]
  },
  "https://jmlr.org/papers/v22/20-358.html": {
    "title": "Analyzing the discrepancy principle for kernelized spectral filter learning algorithms",
    "volume": "main",
    "abstract": "We investigate the construction of early stopping rules in the nonparametric regression problem where iterative learning algorithms are used and the optimal iteration number is unknown. More precisely, we study the discrepancy principle, as well as modifications based on smoothed residuals, for kernelized spectral filter learning algorithms including Tikhonov regularization and gradient descent. Our main theoretical bounds are oracle inequalities established for the empirical estimation error (fixed design), and for the prediction error (random design). From these finite-sample bounds it follows that the classical discrepancy principle is statistically adaptive for slow rates occurring in the hard learning scenario, while the smoothed discrepancy principles are adaptive over ranges of faster rates (resp. higher smoothness parameters). Our approach relies on deviation inequalities for the stopping rules in the fixed design setting, combined with change-of-norm arguments to deal with the random design setting",
    "checked": true,
    "id": "ace9502679bca5baec6f6f2a1df9298dde31f466",
    "semantic_title": "analyzing the discrepancy principle for kernelized spectral filter learning algorithms",
    "citation_count": 14,
    "authors": [
      "Alain Celisse",
      "Martin Wahl"
    ]
  },
  "https://jmlr.org/papers/v22/20-376.html": {
    "title": "ChainerRL: A Deep Reinforcement Learning Library",
    "volume": "MLOSS",
    "abstract": "In this paper, we introduce ChainerRL, an open-source deep reinforcement learning (DRL) library built using Python and the Chainer deep learning framework. ChainerRL implements a comprehensive set of DRL algorithms and techniques drawn from state-of-the-art research in the field. To foster reproducible research, and for instructional purposes, ChainerRL provides scripts that closely replicate the original papers' experimental settings and reproduce published benchmark results for several algorithms. Lastly, ChainerRL offers a visualization tool that enables the qualitative inspection of trained agents. The ChainerRL source code can be found on GitHub: https://github.com/chainer/chainerrl",
    "checked": true,
    "id": "8a191a0ccec5f4d060db3ddf5e9ea852d53d3f34",
    "semantic_title": "chainerrl: a deep reinforcement learning library",
    "citation_count": 99,
    "authors": [
      "Yasuhiro Fujita",
      "Prabhat Nagarajan",
      "Toshiki Kataoka",
      "Takahiro Ishikawa"
    ]
  },
  "https://jmlr.org/papers/v22/20-451.html": {
    "title": "POT: Python Optimal Transport",
    "volume": "MLOSS",
    "abstract": "Optimal transport has recently been reintroduced to the machine learning community thanks in part to novel efficient optimization procedures allowing for medium to large scale applications. We propose a Python toolbox that implements several key optimal transport ideas for the machine learning community. The toolbox contains implementations of a number of founding works of OT for machine learning such as Sinkhorn algorithm and Wasserstein barycenters, but also provides generic solvers that can be used for conducting novel fundamental research. This toolbox, named POT for Python Optimal Transport, is open source with an MIT license",
    "checked": true,
    "id": "2be40f5336afa68b49fef41e009b7172c2c9fdeb",
    "semantic_title": "pot: python optimal transport",
    "citation_count": 517,
    "authors": [
      "R√©mi Flamary",
      "Nicolas Courty",
      "Alexandre Gramfort",
      "Mokhtar Z. Alaya",
      "Aur√©lie Boisbunon",
      "Stanislas Chambon",
      "Laetitia Chapel",
      "Adrien Corenflos",
      "Kilian Fatras",
      "Nemo Fournier",
      "L√©o Gautheron",
      "Nathalie T.H. Gayraud",
      "Hicham Janati",
      "Alain Rakotomamonjy",
      "Ievgen Redko",
      "Antoine Rolet",
      "Antony Schutz",
      "Vivien Seguy",
      "Danica J. Sutherland",
      "Romain Tavenard",
      "Alexander Tong",
      "Titouan Vayer"
    ]
  },
  "https://jmlr.org/papers/v22/20-676.html": {
    "title": "Is SGD a Bayesian sampler? Well, almost",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) generalise remarkably well in the overparameterised regime, suggesting a strong inductive bias towards functions with low generalisation error. We empirically investigate this bias by calculating, for a range of architectures and datasets, the probability $P_{SGD}(f\\mid S)$ that an overparameterised DNN, trained with stochastic gradient descent (SGD) or one of its variants, converges on a function $f$ consistent with a training set $S$. We also use Gaussian processes to estimate the Bayesian posterior probability $P_{B}(f\\mid S)$ that the DNN expresses $f$ upon random sampling of its parameters, conditioned on $S$. Our main findings are that $P_{SGD}(f\\mid S)$ correlates remarkably well with $P_{B}(f\\mid S)$ and that $P_{B}(f\\mid S)$ is strongly biased towards low-error and low complexity functions. These results imply that strong inductive bias in the parameter-function map (which determines $P_{B}(f\\mid S)$), rather than a special property of SGD, is the primary explanation for why DNNs generalise so well in the overparameterised regime. While our results suggest that the Bayesian posterior $P_{B}(f\\mid S)$ is the first order determinant of $P_{SGD}(f\\mid S)$, there remain second order differences that are sensitive to hyperparameter tuning. A function probability picture, based on $P_{SGD}(f\\mid S)$ and/or $P_{B}(f\\mid S)$, can shed light on the way that variations in architecture or hyperparameter settings such as batch size, learning rate, and optimiser choice, affect DNN performance",
    "checked": true,
    "id": "45eed86953cfe055342b68d13b913789d24e1ad9",
    "semantic_title": "is sgd a bayesian sampler? well, almost",
    "citation_count": 31,
    "authors": [
      "Chris Mingard",
      "Guillermo Valle-P√©rez",
      "Joar Skalse",
      "Ard A. Louis"
    ]
  },
  "https://jmlr.org/papers/v22/20-705.html": {
    "title": "Communication-Efficient Distributed Covariance Sketch, with Application to Distributed PCA",
    "volume": "main",
    "abstract": "A sketch of a large data set captures vital properties of the original data while typically occupying much less space. In this paper, we consider the problem of computing a sketch of a massive data matrix $A\\in\\mathbb{R}^{n\\times d}$ that is distributed across $s$ machines. Our goal is to output a matrix $B\\in\\mathbb{R}^{\\ell\\times d}$ which is significantly smaller than but still approximates $A$ well in terms of {covariance error}, i.e., $\\|{A^TA-B^TB}\\|_2$. Such a matrix $B$ is called a covariance sketch of $A$. We are mainly focused on minimizing the communication cost, which is arguably the most valuable resource in distributed computations. We show that there is a nontrivial gap between deterministic and randomized communication complexity for computing a covariance sketch. More specifically, we first prove an almost tight deterministic communication lower bound, then provide a new randomized algorithm with communication cost smaller than the deterministic lower bound. Based on a well-known connection between covariance sketch and approximate principle component analysis, we obtain better communication bounds for the distributed PCA problem. Moreover, we also give an improved distributed PCA algorithm for sparse input matrices, which uses our distributed sketching algorithm as a key building block",
    "checked": true,
    "id": "7411682f8dc79ece4c3e561bf4a150b1ea1229ad",
    "semantic_title": "communication-efficient distributed covariance sketch, with application to distributed pca",
    "citation_count": 4,
    "authors": [
      "Zengfeng Huang",
      "Xuemin Lin",
      "Wenjie Zhang",
      "Ying Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/20-753.html": {
    "title": "Knowing what You Know: valid and validated confidence sets in multiclass and multilabel prediction",
    "volume": "main",
    "abstract": "We develop conformal prediction methods for constructing valid predictive confidence sets in multiclass and multilabel problems without assumptions on the data generating distribution. A challenge here is that typical conformal prediction methods---which give marginal validity (coverage) guarantees---provide uneven coverage, in that they address easy examples at the expense of essentially ignoring difficult examples. By leveraging ideas from quantile regression, we build methods that always guarantee correct coverage but additionally provide (asymptotically consistent) conditional coverage for both multiclass and multilabel prediction problems. To address the potential challenge of exponentially large confidence sets in multilabel prediction, we build tree-structured classifiers that efficiently account for interactions between labels. Our methods can be bolted on top of any classification model---neural network, random forest, boosted tree---to guarantee its validity. We also provide an empirical evaluation, simultaneously providing new validation methods, that suggests the more robust coverage of our confidence sets",
    "checked": true,
    "id": "0fb5497440833a838b3d08840fddeedef25b2f72",
    "semantic_title": "knowing what you know: valid and validated confidence sets in multiclass and multilabel prediction",
    "citation_count": 65,
    "authors": [
      "Maxime Cauchois",
      "Suyash Gupta",
      "John C. Duchi"
    ]
  },
  "https://jmlr.org/papers/v22/20-825.html": {
    "title": "PyKEEN 1.0: A Python Library for Training and Evaluating Knowledge Graph Embeddings",
    "volume": "main",
    "abstract": "Recently, knowledge graph embeddings (KGEs) have received significant attention, and several software libraries have been developed for training and evaluation. While each of them addresses specific needs, we report on a community effort to a re-design and re-implementation of PyKEEN, one of the early KGE libraries. PyKEEN 1.0 enables users to compose knowledge graph embedding models based on a wide range of interaction models, training approaches, loss functions, and permits the explicit modeling of inverse relations. It allows users to measure each component's influence individually on the model's performance. Besides, an automatic memory optimization has been realized in order to optimally exploit the provided hardware. Through the integration of Optuna, extensive hyper-parameter optimization (HPO) functionalities are provided",
    "checked": true,
    "id": "7c008e9f16a9457a630eae049a4bebdec9f608db",
    "semantic_title": "pykeen 1.0: a python library for training and evaluating knowledge graph embeddings",
    "citation_count": 107,
    "authors": [
      "Mehdi Ali",
      "Max Berrendorf",
      "Charles Tapley Hoyt",
      "Laurent Vermue",
      "Sahand Sharifzadeh",
      "Volker Tresp",
      "Jens Lehmann"
    ]
  },
  "https://jmlr.org/papers/v22/20-837.html": {
    "title": "Statistical Query Lower Bounds for Tensor PCA",
    "volume": "main",
    "abstract": "In the Tensor PCA problem introduced by Richard and Montanari (2014), one is given a dataset consisting of $n$ samples $\\mathbf{T}_{1:n}$ of i.i.d. Gaussian tensors of order $k$ with the promise that $\\mathbb{E}\\mathbf{T}_1$ is a rank-1 tensor and $\\|\\mathbb{E} \\mathbf{T}_1\\| = 1$. The goal is to estimate $\\mathbb{E} \\mathbf{T}_1$. This problem exhibits a large conjectured hard phase when $k>2$: When $d \\lesssim n \\ll d^{\\frac{k}{2}}$ it is information theoretically possible to estimate $\\mathbb{E} \\mathbf{T}_1$, but no polynomial time estimator is known. We provide a sharp analysis of the optimal sample complexity in the Statistical Query (SQ) model and show that SQ algorithms with polynomial query complexity not only fail to solve Tensor PCA in the conjectured hard phase, but also have a strictly sub-optimal sample complexity compared to some polynomial time estimators such as the Richard-Montanari spectral estimator. Our analysis reveals that the optimal sample complexity in the SQ model depends on whether $\\mathbb{E} \\mathbf{T}_1$ is symmetric or not. For symmetric, even order tensors, we also isolate a sample size regime in which it is possible to test if $\\mathbb{E} \\mathbf{T}_1 = \\mathbf{0}$ or $\\mathbb{E}\\mathbf{T}_1 \\neq \\mathbf{0}$ with polynomially many queries but not estimate $\\mathbb{E}\\mathbf{T}_1$. Our proofs rely on the Fourier analytic approach of Feldman, Perkins and Vempala (2018) to prove sharp SQ lower bounds",
    "checked": true,
    "id": "1ef0d3a19fb2a9063e803fa97bbaca94ee518565",
    "semantic_title": "statistical query lower bounds for tensor pca",
    "citation_count": 17,
    "authors": [
      "Rishabh Dudeja",
      "Daniel Hsu"
    ]
  },
  "https://jmlr.org/papers/v22/20-950.html": {
    "title": "Variance Reduced Median-of-Means Estimator for Byzantine-Robust Distributed Inference",
    "volume": "main",
    "abstract": "This paper develops an efficient distributed inference algorithm, which is robust against a moderate fraction of Byzantine nodes, namely arbitrary and possibly adversarial machines in a distributed learning system. In robust statistics, the median-of-means (MOM) has been a popular approach to hedge against Byzantine failures due to its ease of implementation and computational efficiency. However, the MOM estimator has the shortcoming in terms of statistical efficiency. The first main contribution of the paper is to propose a variance reduced median-of-means (VRMOM) estimator, which improves the statistical efficiency over the vanilla MOM estimator and is computationally as efficient as the MOM. Based on the proposed VRMOM estimator, we develop a general distributed inference algorithm that is robust against Byzantine failures. Theoretically, our distributed algorithm achieves a fast convergence rate with only a constant number of rounds of communications. We also provide the asymptotic normality result for the purpose of statistical inference. To the best of our knowledge, this is the first normality result in the setting of Byzantine-robust distributed learning. The simulation results are also presented to illustrate the effectiveness of our method",
    "checked": true,
    "id": "6798ba786beece1bf497176d1078d13cbd6c9d82",
    "semantic_title": "variance reduced median-of-means estimator for byzantine-robust distributed inference",
    "citation_count": 16,
    "authors": [
      "Jiyuan Tu",
      "Weidong Liu",
      "Xiaojun Mao",
      "Xi Chen"
    ]
  },
  "https://jmlr.org/papers/v22/20-997.html": {
    "title": "Gradient Methods Never Overfit On Separable Data",
    "volume": "main",
    "abstract": "A line of recent works established that when training linear predictors over separable data, using gradient methods and exponentially-tailed losses, the predictors asymptotically converge in direction to the max-margin predictor. As a consequence, the predictors asymptotically do not overfit. However, this does not address the question of whether overfitting might occur non-asymptotically, after some bounded number of iterations. In this paper, we formally show that standard gradient methods (in particular, gradient flow, gradient descent and stochastic gradient descent) *never* overfit on separable data: If we run these methods for $T$ iterations on a dataset of size $m$, both the empirical risk and the generalization error decrease at an essentially optimal rate of $\\tilde{\\mathcal{O}}(1/\\gamma^2 T)$ up till $T\\approx m$, at which point the generalization error remains fixed at an essentially optimal level of $\\tilde{\\mathcal{O}}(1/\\gamma^2 m)$ regardless of how large $T$ is. Along the way, we present non-asymptotic bounds on the number of margin violations over the dataset, and prove their tightness",
    "checked": true,
    "id": "725fa9a0449c46a146898599f6f91232219ed42b",
    "semantic_title": "gradient methods never overfit on separable data",
    "citation_count": 28,
    "authors": [
      "Ohad Shamir"
    ]
  },
  "https://jmlr.org/papers/v22/16-179.html": {
    "title": "Multi-view Learning as a Nonparametric Nonlinear Inter-Battery Factor Analysis",
    "volume": "main",
    "abstract": "Factor analysis aims to determine latent factors, or traits, which summarize a given data set. Inter-battery factor analysis extends this notion to multiple views of the data. In this paper we show how a nonlinear, nonparametric version of these models can be recovered through the Gaussian process latent variable model. This gives us a flexible formalism for multi-view learning where the latent variables can be used both for exploratory purposes and for learning representations that enable efficient inference for ambiguous estimation tasks. Learning is performed in a Bayesian manner through the formulation of a variational compression scheme which gives a rigorous lower bound on the log likelihood. Our Bayesian framework provides strong regularization during training, allowing the structure of the latent space to be determined efficiently and automatically. We demonstrate this by producing the first (to our knowledge) published results of learning from dozens of views, even when data is scarce. We further show experimental results on several different types of multi-view data sets and for different kinds of tasks, including exploratory data analysis, generation, ambiguity modelling through latent priors and classification",
    "checked": true,
    "id": "f45702c5df2917af90aa955780c0163b9868e2a8",
    "semantic_title": "multi-view learning as a nonparametric nonlinear inter-battery factor analysis",
    "citation_count": 11,
    "authors": [
      "Andreas Damianou",
      "Neil D. Lawrence",
      "Carl Henrik Ek"
    ]
  },
  "https://jmlr.org/papers/v22/17-474.html": {
    "title": "On Solving Probabilistic Linear Diophantine Equations",
    "volume": "main",
    "abstract": "Multiple methods exist for computing marginals involving a linear Diophantine constraint on random variables. Each of these extant methods has some limitation on the dimension and support or on the type of marginal computed (e.g., sum-product inference, max-product inference, maximum a posteriori, etc.). Here, we introduce the \"trimmed $p$-convolution tree'\" an approach that generalizes the applicability of the existing methods and achieves a runtime within a $\\log$-factor or better compared to the best existing methods. A second form of trimming we call underflow/overflow trimming is introduced which aggregates events which land outside the supports for a random variable into the nearest support. Trimmed $p$-convolution trees with and without underflow/overflow trimming are used in different protein inference models. Then two different methods of approximating max-convolution using Cartesian product trees are introduced",
    "checked": true,
    "id": "83e0847b74c8f7b6427f8cf67dd8c4fd7612896a",
    "semantic_title": "on solving probabilistic linear diophantine equations",
    "citation_count": 1,
    "authors": [
      "Patrick Kreitzberg",
      "Oliver Serang"
    ]
  },
  "https://jmlr.org/papers/v22/18-240.html": {
    "title": "Edge Sampling Using Local Network Information",
    "volume": "main",
    "abstract": "Edge sampling is an important topic in network analysis. It provides a natural way to reduce network size while retaining desired features of the original network. Sampling methods that only use local information are common in practice as they do not require access to the entire network and can be easily parallelized. Despite promising empirical performances, most of these methods are derived from heuristic considerations and lack theoretical justification. In this paper, we study a simple and efficient edge sampling method that uses local network information. We show that when the local connectivity is sufficiently strong, the sampled network satisfies a strong spectral property. We measure the strength of local connectivity by a global parameter and relate it to more common network statistics such as the clustering coefficient and network curvature. Based on this result, we also provide sufficient conditions under which random networks and hypergraphs can be efficiently sampled",
    "checked": true,
    "id": "cad6b7317f1e179ded3e6d0b72eefd3d30988c80",
    "semantic_title": "edge sampling using local network information",
    "citation_count": 3,
    "authors": [
      "Can M. Le"
    ]
  },
  "https://jmlr.org/papers/v22/18-332.html": {
    "title": "Bayesian Text Classification and Summarization via A Class-Specified Topic Model",
    "volume": "main",
    "abstract": "We propose the class-specified topic model (CSTM) to deal with the tasks of text classification and class-specific text summarization. The model assumes that in addition to a set of latent topics that are shared across classes, there is a set of class-specific latent topics for each class. Each document is a probabilistic mixture of the class-specific topics associated with its class and the shared topics. Each class-specific or shared topic has its own probability distribution over a given dictionary. We develop a Bayesian inference of CSTM in the semisupervised scenario, with the supervised scenario as a special case. We analyze in detail the 20 Newsgroups dataset, a benchmark dataset for text classification, and demonstrate that CSTM has better performance than a two stage approach based on latent Dirichlet allocation (LDA), several existing supervised extensions of LDA, and an $L^1$ penalized logistic regression. The favorable performance of CSTM is also demonstrated through Monte Carlo simulations and an analysis of the Reuters dataset",
    "checked": true,
    "id": "ff073e2fa5ae614da56518a747dd3d1081e7a994",
    "semantic_title": "bayesian text classification and summarization via a class-specified topic model",
    "citation_count": 9,
    "authors": [
      "Feifei Wang",
      "Junni L. Zhang",
      "Yichao Li",
      "Ke Deng",
      "Jun S. Liu"
    ]
  },
  "https://jmlr.org/papers/v22/18-489.html": {
    "title": "Risk Bounds for Unsupervised Cross-Domain Mapping with IPMs",
    "volume": "main",
    "abstract": "The recent empirical success of unsupervised cross-domain mapping algorithms, in mapping between two domains that share common characteristics, is not well-supported by theoretical justifications. This lacuna is especially troubling, given the clear ambiguity in such mappings. We work with adversarial training methods based on integral probability metrics (IPMs) and derive a novel risk bound, which upper bounds the risk between the learned mapping $h$ and the target mapping $y$, by a sum of three terms: (i) the risk between $h$ and the most distant alternative mapping that was learned by the same cross-domain mapping algorithm, (ii) the minimal discrepancy between the target domain and the domain obtained by applying a hypothesis $h^*$ on the samples of the source domain, where $h^*$ is a hypothesis selectable by the same algorithm, and (iii) an approximation error term that decreases as the capacity of the class of discriminators increases and is empirically shown to be small. The bound is directly related to Occam's razor and encourages the selection of the minimal architecture that supports a small mapping discrepancy. The bound leads to multiple algorithmic consequences, including a method for hyperparameter selection and early stopping in cross-domain mapping",
    "checked": true,
    "id": "c89adee820d98888a85515632842c0e7104085d7",
    "semantic_title": "risk bounds for unsupervised cross-domain mapping with ipms",
    "citation_count": 4,
    "authors": [
      "Tomer Galanti",
      "Sagie Benaim",
      "Lior Wolf"
    ]
  },
  "https://jmlr.org/papers/v22/18-651.html": {
    "title": "Analysis of high-dimensional Continuous Time Markov Chains using the Local Bouncy Particle Sampler",
    "volume": "main",
    "abstract": "Sampling the parameters of high-dimensional Continuous Time Markov Chains (CTMC) is a challenging problem with important applications in many fields of applied statistics. In this work a recently proposed type of non-reversible rejection-free Markov Chain Monte Carlo (MCMC) sampler, the Bouncy Particle Sampler (BPS), is brought to bear to this problem. BPS has demonstrated its favourable computational efficiency compared with state-of-the-art MCMC algorithms, however to date applications to real-data scenario were scarce. An important aspect of practical implementation of BPS is the simulation of event times. Default implementations use conservative thinning bounds. Such bounds can slow down the algorithm and limit the computational performance. Our paper develops an algorithm with exact analytical solution to the random event times in the context of CTMCs. Our local version of BPS algorithm takes advantage of the sparse structure in the target factor graph and we also provide a graph-theoretic tool for assessing the computational complexity of local BPS algorithms",
    "checked": true,
    "id": "19faa462b14624e4c26249bf5c69a6c7ceede515",
    "semantic_title": "analysis of high-dimensional continuous time markov chains using the local bouncy particle sampler",
    "citation_count": 4,
    "authors": [
      "Tingting Zhao",
      "Alexandre Bouchard-C√¥t√©"
    ]
  },
  "https://jmlr.org/papers/v22/18-803.html": {
    "title": "NEU: A Meta-Algorithm for Universal UAP-Invariant Feature Representation",
    "volume": "main",
    "abstract": "Effective feature representation is key to the predictive performance of any algorithm. This paper introduces a meta-procedure, called Non-Euclidean Upgrading (NEU), which learns feature maps that are expressive enough to embed the universal approximation property (UAP) into most model classes while only outputting feature maps that preserve any model class's UAP. We show that NEU can learn any feature map with these two properties if that feature map is asymptotically deformable into the identity. We also find that the feature-representations learned by NEU are always submanifolds of the feature space. NEU's properties are derived from a new deep neural model that is universal amongst all orientation-preserving homeomorphisms on the input space. We derive qualitative and quantitative approximation guarantees for this architecture. We quantify the number of parameters required for this new architecture to memorize any set of input-output pairs while simultaneously fixing every point of the input space lying outside some compact set, and we quantify the size of this set as a function of our model's depth. Moreover, we show that deep feedforward networks with most commonly used activation functions typically do not have all these properties. NEU's performance is evaluated against competing machine learning methods on various regression and dimension reduction tasks both with financial and simulated data",
    "checked": true,
    "id": "9c77b5287e10ebf46f70aaaaf56b77ab8a34b735",
    "semantic_title": "neu: a meta-algorithm for universal uap-invariant feature representation",
    "citation_count": 16,
    "authors": [
      "Anastasis Kratsios",
      "Cody Hyndman"
    ]
  },
  "https://jmlr.org/papers/v22/19-042.html": {
    "title": "Flexible Signal Denoising via Flexible Empirical Bayes Shrinkage",
    "volume": "main",
    "abstract": "Signal denoising‚Äîalso known as non-parametric regression‚Äîis often performed through shrinkage estimation in a transformed (e.g., wavelet) domain; shrinkage in the transformed domain corresponds to smoothing in the original domain. A key question in such applications is how much to shrink, or, equivalently, how much to smooth. Empirical Bayes shrinkage methods provide an attractive solution to this problem; they use the data to estimate a distribution of underlying \"effects,\" hence automatically select an appropriate amount of shrinkage. However, most existing implementations of empirical Bayes shrinkage are less flexible than they could be‚Äîboth in their assumptions on the underlying distribution of effects, and in their ability to handle heteroskedasticity‚Äîwhich limits their signal denoising applications. Here we address this by adopting a particularly flexible, stable and computationally convenient empirical Bayes shrinkage method and applying it to several signal denoising problems. These applications include smoothing of Poisson data and heteroskedastic Gaussian data. We show through empirical comparisons that the results are competitive with other methods, including both simple thresholding rules and purpose-built empirical Bayes procedures. Our methods are implemented in the R package smashr, \"SMoothing by Adaptive SHrinkage in R,\" available at https://www.github.com/stephenslab/smashr",
    "checked": true,
    "id": "ce21f90bb9d4d9411ecbe1cdc0e135b96a139a31",
    "semantic_title": "flexible signal denoising via flexible empirical bayes shrinkage",
    "citation_count": 4,
    "authors": [
      "Zhengrong Xing",
      "Peter Carbonetto",
      "Matthew Stephens"
    ]
  },
  "https://jmlr.org/papers/v22/19-081.html": {
    "title": "Consistent Semi-Supervised Graph Regularization for High Dimensional Data",
    "volume": "main",
    "abstract": "Semi-supervised Laplacian regularization, a standard graph-based approach for learning from both labelled and unlabelled data, was recently demonstrated to have an insignificant high dimensional learning efficiency with respect to unlabelled data, causing it to be outperformed by its unsupervised counterpart, spectral clustering, given sufficient unlabelled data. Following a detailed discussion on the origin of this inconsistency problem, a novel regularization approach involving centering operation is proposed as solution, supported by both theoretical analysis and empirical results",
    "checked": true,
    "id": "e498143611a9999fa5b9d501d9df2bbba1907cba",
    "semantic_title": "consistent semi-supervised graph regularization for high dimensional data",
    "citation_count": 15,
    "authors": [
      "Xiaoyi Mai",
      "Romain Couillet"
    ]
  },
  "https://jmlr.org/papers/v22/19-1004.html": {
    "title": "Histogram Transform Ensembles for Large-scale Regression",
    "volume": "main",
    "abstract": "In this paper, we propose a novel algorithm for large-scale regression problems named Histogram Transform Ensembles (HTE), composed of random rotations, stretchings, and translations. Our HTE method first implements a histogram transformed partition to the random affine mapped data, then adaptively leverages constant functions or SVMs to obtain the individual regression estimates, and eventually builds the ensemble predictor through an average strategy. First of all, in this paper, we investigate the theoretical properties of HTE when the regression function lies in the H\\\"{o}lder space $C^{k,\\alpha}$, $k \\in \\mathbb{N}_0$, $\\alpha \\in (0,1]$. In the case that $k=0, 1$, we adopt the constant regressors and develop the na\\\"{i}ve histogram transforms (NHT). Within the space $C^{0,\\alpha}$, although almost optimal convergence rates can be derived for both single and ensemble NHT, we fail to show the benefits of ensembles over single estimators theoretically. In contrast, in the subspace $C^{1,\\alpha}$, we prove that if $d \\geq 2(1+\\alpha)/\\alpha$, the lower bound of the convergence rates for single NHT turns out to be worse than the upper bound of the convergence rates for ensemble NHT. In the other case when $k \\geq 2$, the NHT may no longer be appropriate in predicting smoother regression functions. Instead, we circumvent this issue by applying kernel histogram transforms (KHT) equipped with smoother regressors, such as support vector machines (SVMs). Accordingly, it turns out that both single and ensemble KHT enjoy almost optimal convergence rates. Then, we validate the above theoretical results with extensive numerical experiments. On the one hand, simulations are conducted to elucidate that ensemble NHT outperforms single NHT. On the other hand, the effects of bin sizes on the accuracy of both NHT and KHT are also in accord with the theoretical analysis. Last but not least, in the real-data experiments, comparisons between the ensemble KHT, equipped with adaptive histogram transforms, and other state-of-the-art large-scale regression estimators verify the effectiveness and precision of the proposed algorithm",
    "checked": true,
    "id": "160880e9844e9e204d88c1e31d615e704f29ddf4",
    "semantic_title": "histogram transform ensembles for large-scale regression",
    "citation_count": 2,
    "authors": [
      "Hanyuan Hang",
      "Zhouchen Lin",
      "Xiaoyu Liu",
      "Hongwei Wen"
    ]
  },
  "https://jmlr.org/papers/v22/19-364.html": {
    "title": "Guided Visual Exploration of Relations in Data Sets",
    "volume": "main",
    "abstract": "Efficient explorative data analysis systems must take into account both what a user knows and wants to know. This paper proposes a principled framework for interactive visual exploration of relations in data, through views most informative given the user's current knowledge and objectives. The user can input pre-existing knowledge of relations in the data and also formulate specific exploration interests, which are then taken into account in the exploration. The idea is to steer the exploration process towards the interests of the user, instead of showing uninteresting or already known relations. The user's knowledge is modelled by a distribution over data sets parametrised by subsets of rows and columns of data, called tile constraints. We provide a computationally efficient implementation of this concept based on constrained randomisation. Furthermore, we describe a novel dimensionality reduction method for finding the views most informative to the user, which at the limit of no background knowledge and with generic objectives reduces to PCA. We show that the method is suitable for interactive use and is robust to noise, outperforms standard projection pursuit visualisation methods, and gives understandable and useful results in analysis of real-world data. We provide an open-source implementation of the framework",
    "checked": true,
    "id": "70f33e6dfa98f3162b0ebb4777ff86e85399f778",
    "semantic_title": "guided visual exploration of relations in data sets",
    "citation_count": 4,
    "authors": [
      "Kai Puolam√§ki",
      "Emilia Oikarinen",
      "Andreas Henelius"
    ]
  },
  "https://jmlr.org/papers/v22/19-707.html": {
    "title": "Safe Policy Iteration: A Monotonically Improving Approximate Policy Iteration Approach",
    "volume": "main",
    "abstract": "This paper presents a study of the policy improvement step that can be usefully exploited by approximate policy-iteration algorithms. When either the policy evaluation step or the policy improvement step returns an approximated result, the sequence of policies produced by policy iteration may not be monotonically increasing, and oscillations may occur. To address this issue, we consider safe policy improvements, i.e., at each iteration, we search for a policy that maximizes a lower bound to the policy improvement w.r.t. the current policy, until no improving policy can be found. We propose three safe policy-iteration schemas that differ in the way the next policy is chosen w.r.t. the estimated greedy policy. Besides being theoretically derived and discussed, the proposed algorithms are empirically evaluated and compared on some chain-walk domains, the prison domain, and on the Blackjack card game",
    "checked": false,
    "id": "0063701c9af8dcb781dbc70dbf3a324dfe951082",
    "semantic_title": "dynamic fleet management for autonomous vehicles: learning- and optimization-based strategies",
    "citation_count": 0,
    "authors": [
      "Alberto Maria Metelli",
      "Matteo Pirotta",
      "Daniele Calandriello",
      "Marcello Restelli"
    ]
  },
  "https://jmlr.org/papers/v22/19-736.html": {
    "title": "On the Theory of Policy Gradient Methods: Optimality, Approximation, and Distribution Shift",
    "volume": "main",
    "abstract": "Policy gradient methods are among the most effective methods in challenging reinforcement learning problems with large state and/or action spaces. However, little is known about even their most basic theoretical convergence properties, including: if and how fast they converge to a globally optimal solution or how they cope with approximation error due to using a restricted class of parametric policies. This work provides provable characterizations of the computational, approximation, and sample size properties of policy gradient methods in the context of discounted Markov Decision Processes (MDPs). We focus on both: \"tabular\" policy parameterizations, where the optimal policy is contained in the class and where we show global convergence to the optimal policy; and parametric policy classes (considering both log-linear and neural policy classes), which may not contain the optimal policy and where we provide agnostic learning results. One central contribution of this work is in providing approximation guarantees that are average case --- which avoid explicit worst-case dependencies on the size of state space --- by making a formal connection to supervised learning under distribution shift. This characterization shows an important interplay between estimation error, approximation error, and exploration (as characterized through a precisely defined condition number)",
    "checked": true,
    "id": "c63f320e4f8403d8fb36433f74bc159389494485",
    "semantic_title": "on the theory of policy gradient methods: optimality, approximation, and distribution shift",
    "citation_count": 374,
    "authors": [
      "Alekh Agarwal",
      "Sham M. Kakade",
      "Jason D. Lee",
      "Gaurav Mahajan"
    ]
  },
  "https://jmlr.org/papers/v22/19-892.html": {
    "title": "Adaptive estimation of nonparametric functionals",
    "volume": "main",
    "abstract": "We provide general adaptive upper bounds for estimating nonparametric functionals based on second-order U-statistics arising from finite-dimensional approximation of the infinite-dimensional models. We then provide examples of functionals for which the theory produces rate optimally matching adaptive upper and lower bounds. Our results are automatically adaptive in both parametric and nonparametric regimes of estimation and are automatically adaptive and semiparametric efficient in the regime of parametric convergence rate",
    "checked": true,
    "id": "8777c4105e40097914bac62ee0f782beca89dffa",
    "semantic_title": "adaptive estimation of nonparametric functionals",
    "citation_count": 14,
    "authors": [
      "Lin Liu",
      "Rajarshi Mukherjee",
      "James M. Robins",
      "Eric Tchetgen Tchetgen"
    ]
  },
  "https://jmlr.org/papers/v22/19-920.html": {
    "title": "OpenML-Python: an extensible Python API for OpenML",
    "volume": "MLOSS",
    "abstract": "OpenML is an online platform for open science collaboration in machine learning, used to share datasets and results of machine learning experiments. In this paper, we introduce OpenML-Python, a client API for Python, which opens up the OpenML platform for a wide range of Python-based machine learning tools. It provides easy access to all datasets, tasks and experiments on OpenML from within Python. It also provides functionality to conduct machine learning experiments, upload the results to OpenML, and reproduce results which are stored on OpenML. Furthermore, it comes with a scikit-learn extension and an extension mechanism to easily integrate other machine learning libraries written in Python into the OpenML ecosystem. Source code and documentation are available at https://github.com/openml/openml-python/",
    "checked": true,
    "id": "65e536448b7f3763f399841e65a6973cdb170239",
    "semantic_title": "openml-python: an extensible python api for openml",
    "citation_count": 70,
    "authors": [
      "Matthias Feurer",
      "Jan N. van Rijn",
      "Arlind Kadra",
      "Pieter Gijsbers",
      "Neeratyoy Mallik",
      "Sahithya Ravi",
      "Andreas M√ºller",
      "Joaquin Vanschoren",
      "Frank Hutter"
    ]
  },
  "https://jmlr.org/papers/v22/20-052.html": {
    "title": "LocalGAN: Modeling Local Distributions for Adversarial Response Generation",
    "volume": "main",
    "abstract": "This paper presents a new methodology for modeling the local semantic distribution of responses to a given query in the human-conversation corpus, and on this basis, explores a specified adversarial learning mechanism for training Neural Response Generation (NRG) models to build conversational agents. Our investigation begins with the thorough discus- sions upon the objective function of general Generative Adversarial Nets (GAN) architectures, and the training instability problem is proved to be highly relative with the special local distributions of conversational corpora. Consequently, an energy function is employed to estimate the status of a local area restricted by the query and its responses in the semantic space, and the mathematical approximation of this energy-based distribution is finally found. Building on this foundation, a local distribution oriented objective is proposed and combined with the original objective, working as a hybrid loss for the adversarial training of response generation models, named as LocalGAN. Our experimental results demonstrate that the reasonable local distribution modeling of the query-response corpus is of great importance to adversarial NRG, and our proposed LocalGAN is promising for improving both the training stability and the quality of generated results",
    "checked": true,
    "id": "488ca584e06e10a3b3009c8e93d5720c13c39af9",
    "semantic_title": "localgan: modeling local distributions for adversarial response generation",
    "citation_count": 0,
    "authors": [
      "Baoxun Wang",
      "Zhen Xu",
      "Huan Zhang",
      "Kexin Qiu",
      "Deyuan Zhang",
      "Chengjie Sun"
    ]
  },
  "https://jmlr.org/papers/v22/20-1005.html": {
    "title": "Learning a High-dimensional Linear Structural Equation Model via l1-Regularized Regression",
    "volume": "main",
    "abstract": "This paper develops a new approach to learning high-dimensional linear structural equation models (SEMs) without the commonly assumed faithfulness, Gaussian error distribution, and equal error distribution conditions. A key component of the algorithm is component-wise ordering and parent estimations, where both problems can be efficiently addressed using l1-regularized regression. This paper proves that sample sizes n = Omega( d^{2} \\log p) and n = \\Omega( d^2 p^{2/m} ) are sufficient for the proposed algorithm to recover linear SEMs with sub-Gaussian and (4m)-th bounded-moment error distributions, respectively, where p is the number of nodes and d is the maximum degree of the moralized graph. Further shown is the worst-case computational complexity O(n (p^3 + p^2 d^2 ) ), and hence, the proposed algorithm is statistically consistent and computationally feasible for learning a high-dimensional linear SEM when its moralized graph is sparse. Through simulations, we verify that the proposed algorithm is statistically consistent and computationally feasible, and it performs well compared to the state-of-the-art US, GDS, LISTEN and TD algorithms with our settings. We also demonstrate through real COVID-19 data that the proposed algorithm is well-suited to estimating a virus-spread map in China",
    "checked": true,
    "id": "e4ff18aeb8f3a1a1a140c432ca14881baf7ca020",
    "semantic_title": "learning a high-dimensional linear structural equation model via l1-regularized regression",
    "citation_count": 5,
    "authors": [
      "Gunwoong Park",
      "Sang Jun Moon",
      "Sion Park",
      "Jong-June Jeon"
    ]
  },
  "https://jmlr.org/papers/v22/20-1068.html": {
    "title": "A Unified Analysis of First-Order Methods for Smooth Games via Integral Quadratic Constraints",
    "volume": "main",
    "abstract": "The theory of integral quadratic constraints (IQCs) allows the certification of exponential convergence of interconnected systems containing nonlinear or uncertain elements. In this work, we adapt the IQC theory to study first-order methods for smooth and strongly-monotone games and show how to design tailored quadratic constraints to get tight upper bounds of convergence rates. Using this framework, we recover the existing bound for the gradient method~(GD), derive sharper bounds for the proximal point method~(PPM) and optimistic gradient method~(OG), and provide for the first time a global convergence rate for the negative momentum method~(NM) with an iteration complexity $\\mathcal{O}(\\kappa^{1.5})$, which matches its known lower bound. In addition, for time-varying systems, we prove that the gradient method with optimal step size achieves the fastest provable worst-case convergence rate with quadratic Lyapunov functions. Finally, we further extend our analysis to stochastic games and study the impact of multiplicative noise on different algorithms. We show that it is impossible for an algorithm with one step of memory to achieve acceleration if it only queries the gradient once per batch (in contrast with the stochastic strongly-convex optimization setting, where such acceleration has been demonstrated). However, we exhibit an algorithm which achieves acceleration with two gradient queries per batch",
    "checked": true,
    "id": "4b631bfab27a6a379f7bf31c408354645e72d853",
    "semantic_title": "a unified analysis of first-order methods for smooth games via integral quadratic constraints",
    "citation_count": 21,
    "authors": [
      "Guodong Zhang",
      "Xuchan Bao",
      "Laurent Lessard",
      "Roger Grosse"
    ]
  },
  "https://jmlr.org/papers/v22/20-1223.html": {
    "title": "Explaining Explanations: Axiomatic Feature Interactions for Deep Networks",
    "volume": "main",
    "abstract": "Recent work has shown great promise in explaining neural network behavior. In particular, feature attribution methods explain the features that are important to a model's prediction on a given input. However, for many tasks, simply identifying significant features may be insufficient for understanding model behavior. The interactions between features within the model may better explain not only the model, but why certain features outrank others in importance. In this work, we present Integrated Hessians, an extension of Integrated Gradients that explains pairwise feature interactions in neural networks. Integrated Hessians overcomes several theoretical limitations of previous methods, and unlike them, is not limited to a specific architecture or class of neural network. Additionally, we find that our method is faster than existing methods when the number of features is large, and outperforms previous methods on existing quantitative benchmarks",
    "checked": true,
    "id": "798ea191aad9401462b405fde1a6cefb4fe53fd5",
    "semantic_title": "explaining explanations: axiomatic feature interactions for deep networks",
    "citation_count": 116,
    "authors": [
      "Joseph D. Janizek",
      "Pascal Sturmfels",
      "Su-In Lee"
    ]
  },
  "https://jmlr.org/papers/v22/20-1260.html": {
    "title": "Pathwise Conditioning of Gaussian Processes",
    "volume": "main",
    "abstract": "As Gaussian processes are used to answer increasingly complex questions, analytic solutions become scarcer and scarcer. Monte Carlo methods act as a convenient bridge for connecting intractable mathematical expressions with actionable estimates via sampling. Conventional approaches for simulating Gaussian process posteriors view samples as draws from marginal distributions of process values at finite sets of input locations. This distribution-centric characterization leads to generative strategies that scale cubically in the size of the desired random vector. These methods are prohibitively expensive in cases where we would, ideally, like to draw high-dimensional vectors or even continuous sample paths. In this work, we investigate a different line of reasoning: rather than focusing on distributions, we articulate Gaussian conditionals at the level of random variables. We show how this pathwise interpretation of conditioning gives rise to a general family of approximations that lend themselves to efficiently sampling Gaussian process posteriors. Starting from first principles, we derive these methods and analyze the approximation errors they introduce. We, then, ground these results by exploring the practical implications of pathwise conditioning in various applied settings, such as global optimization and reinforcement learning",
    "checked": true,
    "id": "9049d836ad24ab55c4bbb0455790f17eb3da4cb7",
    "semantic_title": "pathwise conditioning of gaussian processes",
    "citation_count": 39,
    "authors": [
      "James T. Wilson",
      "Viacheslav Borovitskiy",
      "Alexander Terenin",
      "Peter Mostowsky",
      "Marc Peter Deisenroth"
    ]
  },
  "https://jmlr.org/papers/v22/20-1288.html": {
    "title": "Online stochastic gradient descent on non-convex losses from high-dimensional inference",
    "volume": "main",
    "abstract": "Stochastic gradient descent (SGD) is a popular algorithm for optimization problems arising in high-dimensional inference tasks. Here one produces an estimator of an unknown parameter from independent samples of data by iteratively optimizing a loss function. This loss function is random and often non-convex. We study the performance of the simplest version of SGD, namely online SGD, from a random start in the setting where the parameter space is high-dimensional. We develop nearly sharp thresholds for the number of samples needed for consistent estimation as one varies the dimension. Our thresholds depend only on an intrinsic property of the population loss which we call the information exponent. In particular, our results do not assume uniform control on the loss itself, such as convexity or uniform derivative bounds. The thresholds we obtain are polynomial in the dimension and the precise exponent depends explicitly on the information exponent. As a consequence of our results, we find that except for the simplest tasks, almost all of the data is used simply in the initial search phase to obtain non-trivial correlation with the ground truth. Upon attaining non-trivial correlation, the descent is rapid and exhibits law of large numbers type behavior. We illustrate our approach by applying it to a wide set of inference tasks such as phase retrieval, and parameter estimation for generalized linear models, online PCA, and spiked tensor models, as well as to supervised learning for single-layer networks with general activation functions",
    "checked": true,
    "id": "1b650f53bc1fd963c7790832d8706e1af0333d3c",
    "semantic_title": "online stochastic gradient descent on non-convex losses from high-dimensional inference",
    "citation_count": 47,
    "authors": [
      "Gerard Ben Arous",
      "Reza Gheissari",
      "Aukosh Jagannath"
    ]
  },
  "https://jmlr.org/papers/v22/20-1307.html": {
    "title": "Beyond English-Centric Multilingual Machine Translation",
    "volume": "main",
    "abstract": "Existing work in translation demonstrated the potential of massively multilingual machine translation by training a single model able to translate between any pair of languages. However, much of this work is English-Centric, training only on data which was translated from or to English.While this is supported by large sources of training data, it does not reflect translation needs worldwide. In this work, we create a true Many-to-Many multilingual translation model that can translate directly between any pair of 100 languages. We build and open-source a training data set that covers thousands of language directions with parallel data, created through large-scale mining. Then, we explore how to effectively increase model capacity through a combination of dense scaling and language-specific sparse parameters to create high quality models. Our focus on non-English-Centric models brings gains of more than 10 BLEU when directly translating between non-English directions while performing competitively to the best single systems from the Workshop on Machine Translation (WMT). We open-source our scripts so that others may reproduce the data, evaluation, and final M2M-100 model",
    "checked": true,
    "id": "687b13c44f849d23c2496996b5da83e706094db9",
    "semantic_title": "beyond english-centric multilingual machine translation",
    "citation_count": 615,
    "authors": [
      "Angela Fan",
      "Shruti Bhosale",
      "Holger Schwenk",
      "Zhiyi Ma",
      "Ahmed El-Kishky",
      "Siddharth Goyal",
      "Mandeep Baines",
      "Onur Celebi",
      "Guillaume Wenzek",
      "Vishrav Chaudhary",
      "Naman Goyal",
      "Tom Birch",
      "Vitaliy Liptchinsky",
      "Sergey Edunov",
      "Michael Auli",
      "Armand Joulin"
    ]
  },
  "https://jmlr.org/papers/v22/20-1369.html": {
    "title": "Towards a Unified Analysis of Random Fourier Features",
    "volume": "main",
    "abstract": "Random Fourier features is a widely used, simple, and effective technique for scaling up kernel methods. The existing theoretical analysis of the approach, however, remains focused on specific learning tasks and typically gives pessimistic bounds which are at odds with the empirical results. We tackle these problems and provide the first unified risk analysis of learning with random Fourier features using the squared error and Lipschitz continuous loss functions. In our bounds, the trade-off between the computational cost and the learning risk convergence rate is problem specific and expressed in terms of the regularization parameter and the number of effective degrees of freedom. We study both the standard random Fourier features method for which we improve the existing bounds on the number of features required to guarantee the corresponding minimax risk convergence rate of kernel ridge regression, as well as a data-dependent modification which samples features proportional to ridge leverage scores and further reduces the required number of features. As ridge leverage scores are expensive to compute, we devise a simple approximation scheme which provably reduces the computational cost without loss of statistical efficiency. Our empirical results illustrate the effectiveness of the proposed scheme relative to the standard random Fourier features method",
    "checked": true,
    "id": "a4347c48b9ac5ed5bc521e30694f752c87d07c83",
    "semantic_title": "towards a unified analysis of random fourier features",
    "citation_count": 132,
    "authors": [
      "Zhu Li",
      "Jean-Francois Ton",
      "Dino Oglic",
      "Dino Sejdinovic"
    ]
  },
  "https://jmlr.org/papers/v22/20-1370.html": {
    "title": "mvlearn: Multiview Machine Learning in Python",
    "volume": "MLOSS",
    "abstract": "As data are generated more and more from multiple disparate sources, multiview data sets, where each sample has features in distinct views, have grown in recent years. However, no comprehensive package exists that enables non-specialists to use these methods easily. mvlearn is a Python library which implements the leading multiview machine learning methods. Its simple API closely follows that of scikit-learn for increased ease-of-use. The package can be installed from Python Package Index (PyPI) and the conda package manager and is released under the MIT open-source license. The documentation, detailed examples, and all releases are available at https://mvlearn.github.io/",
    "checked": true,
    "id": "63ef37f8686c751cde0d2ad67bee5236588402de",
    "semantic_title": "mvlearn: multiview machine learning in python",
    "citation_count": 18,
    "authors": [
      "Ronan Perry",
      "Gavin Mischler",
      "Richard Guo",
      "Theodore Lee",
      "Alexander Chang",
      "Arman Koul",
      "Cameron Franz",
      "Hugo Richard",
      "Iain Carmichael",
      "Pierre Ablin",
      "Alexandre Gramfort",
      "Joshua T. Vogelstein"
    ]
  },
  "https://jmlr.org/papers/v22/20-1380.html": {
    "title": "River: machine learning for streaming data in Python",
    "volume": "MLOSS",
    "abstract": "River is a machine learning library for dynamic data streams and continual learning. It provides multiple state-of-the-art learning methods, data generators/transformers, performance metrics and evaluators for different stream learning problems. It is the result from the merger of two popular packages for stream learning in Python: Creme and scikit-multiflow. River introduces a revamped architecture based on the lessons learnt from the seminal packages. River's ambition is to be the go-to library for doing machine learning on streaming data. Additionally, this open source package brings under the same umbrella a large community of practitioners and researchers. The source code is available at https://github.com/online-ml/river",
    "checked": true,
    "id": "e7924a71ff89f37f66298a6b42bcd26fa7c0f33b",
    "semantic_title": "river: machine learning for streaming data in python",
    "citation_count": 130,
    "authors": [
      "Jacob Montiel",
      "Max Halford",
      "Saulo Martiello Mastelini",
      "Geoffrey Bolmier",
      "Raphael Sourty",
      "Robin Vaysse",
      "Adil Zouitine",
      "Heitor Murilo Gomes",
      "Jesse Read",
      "Talel Abdessalem",
      "Albert Bifet"
    ]
  },
  "https://jmlr.org/papers/v22/20-1462.html": {
    "title": "Non-parametric Quantile Regression via the K-NN Fused Lasso",
    "volume": "main",
    "abstract": "Quantile regression is a statistical method for estimating conditional quantiles of a response variable. In addition, for mean estimation, it is well known that quantile regression is more robust to outliers than $l_2$-based methods. By using the fused lasso penalty over a $K$-nearest neighbors graph, we propose an adaptive quantile estimator in a non-parametric setup. We show that the estimator attains optimal rate of $n^{-1/d}$ up to a logarithmic factor, under mild assumptions on the data generation mechanism of the $d$-dimensional data. We develop algorithms to compute the estimator and discuss methodology for model selection. Numerical experiments on simulated and real data demonstrate clear advantages of the proposed estimator over state of the art methods",
    "checked": true,
    "id": "1ab7d65777e8272607894846b2aaaa9782344c4e",
    "semantic_title": "non-parametric quantile regression via the k-nn fused lasso",
    "citation_count": 8,
    "authors": [
      "Steven Siwei Ye",
      "Oscar Hernan Madrid Padilla"
    ]
  },
  "https://jmlr.org/papers/v22/20-156.html": {
    "title": "L-SVRG and L-Katyusha with Arbitrary Sampling",
    "volume": "main",
    "abstract": "We develop and analyze a new family of nonaccelerated and accelerated loopless variance-reduced methods for finite-sum optimization problems. Our convergence analysis relies on a novel expected smoothness condition which upper bounds the variance of the stochastic gradient estimation by a constant times a distance-like function. This allows us to handle with ease arbitrary sampling schemes as well as the nonconvex case. We perform an in-depth estimation of these expected smoothness parameters and propose new importance samplings which allow linear speedup when the expected minibatch size is in a certain range. Furthermore, a connection between these expected smoothness parameters and expected separable overapproximation (ESO) is established, which allows us to exploit data sparsity as well. Our general methods and results recover as special cases the loopless SVRG and loopless Katyusha methods",
    "checked": true,
    "id": "f6da15036bc0fbc3884b23e90fe39896865d4bfc",
    "semantic_title": "l-svrg and l-katyusha with arbitrary sampling",
    "citation_count": 29,
    "authors": [
      "Xun Qian",
      "Zheng Qu",
      "Peter Richt√°rik"
    ]
  },
  "https://jmlr.org/papers/v22/20-195.html": {
    "title": "A Lyapunov Analysis of Accelerated Methods in Optimization",
    "volume": "main",
    "abstract": "Accelerated optimization methods, such as Nesterov's accelerated gradient method, play a significant role in optimization. Several accelerated methods are provably optimal under standard oracle models. Such optimality results are obtained using a technique known as \"estimate sequences,\" which yields upper bounds on convergence properties. The technique of estimate sequences has long been considered difficult to understand and deploy, leading many researchers to generate alternative, more intuitive methods and analyses. We show there is an equivalence between the technique of estimate sequences and a family of Lyapunov functions in both continuous and discrete time. This connection allows us to develop a unified analysis of many existing accelerated algorithms, introduce new algorithms, and strengthen the connection between accelerated algorithms and continuous-time dynamical systems",
    "checked": true,
    "id": "6e30dc28406015391c37531ebd956b523f61f569",
    "semantic_title": "a lyapunov analysis of accelerated methods in optimization",
    "citation_count": 84,
    "authors": [
      "Ashia C. Wilson",
      "Ben Recht",
      "Michael I. Jordan"
    ]
  },
  "https://jmlr.org/papers/v22/20-255.html": {
    "title": "NUQSGD: Provably Communication-efficient Data-parallel SGD via Nonuniform Quantization",
    "volume": "main",
    "abstract": "As the size and complexity of models and datasets grow, so does the need for communication-efficient variants of stochastic gradient descent that can be deployed to perform parallel model training. One popular communication-compression method for data-parallel SGD is QSGD (Alistarh et al., 2017), which quantizes and encodes gradients to reduce communication costs. The baseline variant of QSGD provides strong theoretical guarantees, however, for practical purposes, the authors proposed a heuristic variant which we call QSGDinf, which demonstrated impressive empirical gains for distributed training of large neural networks. In this paper, we build on this work to propose a new gradient quantization scheme, and show that it has both stronger theoretical guarantees than QSGD, and matches and exceeds the empirical performance of the QSGDinf heuristic and of other compression methods",
    "checked": true,
    "id": "1955dcdd21eeaf0f275ecfbd8266766957d77468",
    "semantic_title": "nuqsgd: provably communication-efficient data-parallel sgd via nonuniform quantization",
    "citation_count": 27,
    "authors": [
      "Ali Ramezani-Kebrya",
      "Fartash Faghri",
      "Ilya Markov",
      "Vitalii Aksenov",
      "Dan Alistarh",
      "Daniel M. Roy"
    ]
  },
  "https://jmlr.org/papers/v22/20-287.html": {
    "title": "Stochastic Proximal Methods for Non-Smooth Non-Convex Constrained Sparse Optimization",
    "volume": "main",
    "abstract": "This paper focuses on stochastic proximal gradient methods for optimizing a smooth non-convex loss function with a non-smooth non-convex regularizer and convex constraints. To the best of our knowledge we present the first non-asymptotic convergence bounds for this class of problem. We present two simple stochastic proximal gradient algorithms, for general stochastic and finite-sum optimization problems. In a numerical experiment we compare our algorithms with the current state-of-the-art deterministic algorithm and find our algorithms to exhibit superior convergence",
    "checked": true,
    "id": "a28ef118d6ec5db6676361eb2991356e3618122d",
    "semantic_title": "stochastic proximal methods for non-smooth non-convex constrained sparse optimization",
    "citation_count": 5,
    "authors": [
      "Michael R. Metel",
      "Akiko Takeda"
    ]
  },
  "https://jmlr.org/papers/v22/20-366.html": {
    "title": "An Importance Weighted Feature Selection Stability Measure",
    "volume": "main",
    "abstract": "Current feature selection methods, especially applied to high dimensional data, tend to suffer from instability since marginal modifications in the data may result in largely distinct selected feature sets. Such instability strongly limits a sound interpretation of the selected variables by domain experts. Defining an adequate stability measure is also a research question. In this work, we propose to incorporate into the stability measure the importances of the selected features in predictive models. Such feature importances are directly proportional to feature weights in a linear model. We also consider the generalization to a non-linear setting. We illustrate, theoretically and experimentally, that current stability measures are subject to undesirable behaviors, for example, when they are jointly optimized with predictive accuracy. Results on micro-array and mass-spectrometric data show that our novel stability measure corrects for overly optimistic stability estimates in such a bi-objective context, which leads to improved decision-making. It is also shown to be less prone to the under- or over-estimation of the stability value in feature spaces with groups of highly correlated variables",
    "checked": true,
    "id": "20773035e767c535f1fb1c6d9b8989fe87846a44",
    "semantic_title": "an importance weighted feature selection stability measure",
    "citation_count": 6,
    "authors": [
      "Victor Hamer",
      "Pierre Dupont"
    ]
  },
  "https://jmlr.org/papers/v22/20-391.html": {
    "title": "Strong Consistency, Graph Laplacians, and the Stochastic Block Model",
    "volume": "main",
    "abstract": "Spectral clustering has become one of the most popular algorithms in data clustering and community detection. We study the performance of classical two-step spectral clustering via the graph Laplacian to learn the stochastic block model. Our aim is to answer the following question: when is spectral clustering via the graph Laplacian able to achieve strong consistency, i.e., the exact recovery of the underlying hidden communities? Our work provides an entrywise analysis (an $\\ell_{\\infty}$-norm perturbation bound) of the Fiedler eigenvector of both the unnormalized and the normalized Laplacian associated with the adjacency matrix sampled from the stochastic block model. We prove that spectral clustering is able to achieve exact recovery of the planted community structure under conditions that match the information-theoretic limits",
    "checked": true,
    "id": "7e0eadffa8aa0af709d948a58270d22587e8569d",
    "semantic_title": "strong consistency, graph laplacians, and the stochastic block model",
    "citation_count": 21,
    "authors": [
      "Shaofeng Deng",
      "Shuyang Ling",
      "Thomas Strohmer"
    ]
  },
  "https://jmlr.org/papers/v22/20-537.html": {
    "title": "A General Framework for Adversarial Label Learning",
    "volume": "main",
    "abstract": "We consider the task of training classifiers without fully labeled data. We propose a weakly supervised method---adversarial label learning---that trains classifiers to perform well when noisy and possibly correlated labels are provided. Our framework allows users to provide different weak labels and multiple constraints on these labels. Our model then attempts to learn parameters for the data by solving a zero-sum game for the binary problems and a non-zero sum game optimization for multi-class problems. The game is between an adversary that chooses labels for the data and a model that minimizes the error made by the adversarial labels. The weak supervision constrains what labels the adversary can choose. The method therefore minimizes an upper bound of the classifier's error rate using projected primal-dual subgradient descent. Minimizing this bound protects against bias and dependencies in the weak supervision. We first show the performance of our framework on binary classification tasks then we extend our algorithm to show its performance on multiclass datasets. Our experiments show that our method can train without labels and outperforms other approaches for weakly supervised learning",
    "checked": true,
    "id": "2c90790b8d61b0811728378f4807bdd6839cf712",
    "semantic_title": "a general framework for adversarial label learning",
    "citation_count": 12,
    "authors": [
      "Chidubem Arachie",
      "Bert Huang"
    ]
  },
  "https://jmlr.org/papers/v22/20-553.html": {
    "title": "Some Theoretical Insights into Wasserstein GANs",
    "volume": "main",
    "abstract": "Generative Adversarial Networks (GANs) have been successful in producing outstanding results in areas as diverse as image, video, and text generation. Building on these successes, a large number of empirical studies have validated the benefits of the cousin approach called Wasserstein GANs (WGANs), which brings stabilization in the training process. In the present paper, we add a new stone to the edifice by proposing some theoretical advances in the properties of WGANs. First, we properly define the architecture of WGANs in the context of integral probability metrics parameterized by neural networks and highlight some of their basic mathematical features. We stress in particular interesting optimization properties arising from the use of a parametric 1-Lipschitz discriminator. Then, in a statistically-driven approach, we study the convergence of empirical WGANs as the sample size tends to infinity, and clarify the adversarial effects of the generator and the discriminator by underlining some trade-off properties. These features are finally illustrated with experiments using both synthetic and real-world datasets",
    "checked": true,
    "id": "7908d0e1bb918ea5c9289a572cb7b5dcb63e5f21",
    "semantic_title": "some theoretical insights into wasserstein gans",
    "citation_count": 35,
    "authors": [
      "G√©rard Biau",
      "Maxime Sangnier",
      "Ugo Tanielian"
    ]
  },
  "https://jmlr.org/papers/v22/20-589.html": {
    "title": "Empirical Bayes Matrix Factorization",
    "volume": "main",
    "abstract": "Matrix factorization methods, which include Factor analysis (FA) and Principal Components Analysis (PCA), are widely used for inferring and summarizing structure in multivariate data. Many such methods use a penalty or prior distribution to achieve sparse representations (\"Sparse FA/PCA\"), and a key question is how much sparsity to induce. Here we introduce a general Empirical Bayes approach to matrix factorization (EBMF), whose key feature is that it estimates the appropriate amount of sparsity by estimating prior distributions from the observed data. The approach is very flexible: it allows for a wide range of different prior families and allows that each component of the matrix factorization may exhibit a different amount of sparsity. The key to this flexibility is the use of a variational approximation, which we show effectively reduces fitting the EBMF model to solving a simpler problem, the so-called \"normal means\" problem. We demonstrate the benefits of EBMF with sparse priors through both numerical comparisons with competing methods and through analysis of data from the GTEx (Genotype Tissue Expression) project on genetic associations across 44 human tissues. In numerical comparisons EBMF often provides more accurate inferences than other methods. In the GTEx data, EBMF identifies interpretable structure that agrees with known relationships among human tissues. Software implementing our approach is available at https://github.com/stephenslab/flashr",
    "checked": true,
    "id": "5fc0543c84367e0ba07b31fca6b0f40452f6963c",
    "semantic_title": "empirical bayes matrix factorization",
    "citation_count": 36,
    "authors": [
      "Wei Wang",
      "Matthew Stephens"
    ]
  },
  "https://jmlr.org/papers/v22/20-625.html": {
    "title": "Langevin Dynamics for Adaptive Inverse Reinforcement Learning of Stochastic Gradient Algorithms",
    "volume": "main",
    "abstract": "Inverse reinforcement learning (IRL) aims to estimate the reward function of optimizing agents by observing their response (estimates or actions). This paper considers IRL when noisy estimates of the gradient of a reward function generated by multiple stochastic gradient agents are observed. We present a generalized Langevin dynamics algorithm to estimate the reward function $R(\\theta)$; specifically, the resulting Langevin algorithm asymptotically generates samples from the distribution proportional to $\\exp(R(\\theta))$. The proposed adaptive IRL algorithms use kernel-based passive learning schemes. We also construct multi-kernel passive Langevin algorithms for IRL which are suitable for high dimensional data. The performance of the proposed IRL algorithms are illustrated on examples in adaptive Bayesian learning, logistic regression (high dimensional problem) and constrained Markov decision processes. We prove weak convergence of the proposed IRL algorithms using martingale averaging methods. We also analyze the tracking performance of the IRL algorithms in non-stationary environments where the utility function $R(\\theta)$ has a hyper-parameter that jump changes over time as a slow Markov chain which is not known to the inverse learner. In this case, martingale averaging yields a Markov switched diffusion limit as the asymptotic behavior of the IRL algorithm",
    "checked": true,
    "id": "fcd6ce91df791c2172721010fe8f2c6deb7786d2",
    "semantic_title": "langevin dynamics for adaptive inverse reinforcement learning of stochastic gradient algorithms",
    "citation_count": 2,
    "authors": [
      "Vikram Krishnamurthy",
      "George Yin"
    ]
  },
  "https://jmlr.org/papers/v22/20-661.html": {
    "title": "Sparse Convex Optimization via Adaptively Regularized Hard Thresholding",
    "volume": "main",
    "abstract": "The goal of Sparse Convex Optimization is to optimize a convex function f under a sparsity constraint s <= s* Œ≥, where s* is the target number of non-zero entries in a feasible solution (sparsity) and Œ≥ >= 1 is an approximation factor. There has been a lot of work to analyze the sparsity guarantees of various algorithms (LASSO, Orthogonal Matching Pursuit (OMP), Iterative Hard Thresholding (IHT)) in terms of the Restricted Condition Number Œ∫. The best known algorithms guarantee to find an approximate solution of value f(x*)+Œµ with the sparsity bound of Œ≥ = O(Œ∫ min{log ((f(x0)-f(x*)) / Œµ), Œ∫}), where x* is the target solution. We present a new Adaptively Regularized Hard Thresholding (ARHT) algorithm that makes significant progress on this problem by bringing the bound down to Œ≥=O(Œ∫), which has been shown to be tight for a general class of algorithms including LASSO, OMP, and IHT. This is achieved without significant sacrifice in the runtime efficiency compared to the fastest known algorithms. We also provide a new analysis of OMP with Replacement (OMPR) for general f, under the condition s > s* Œ∫^2 / 4, which yields compressed sensing bounds under the Restricted Isometry Property (RIP). When compared to other compressed sensing approaches, it has the advantage of providing a strong tradeoff between the RIP condition and the solution sparsity, while working for any general function f that meets the RIP condition",
    "checked": true,
    "id": "a0be3cc21ffe87fa5d7d37d688b548e096a8f720",
    "semantic_title": "sparse convex optimization via adaptively regularized hard thresholding",
    "citation_count": 12,
    "authors": [
      "Kyriakos Axiotis",
      "Maxim Sviridenko"
    ]
  },
  "https://jmlr.org/papers/v22/20-662.html": {
    "title": "Convergence Guarantees for Gaussian Process Means With Misspecified Likelihoods and Smoothness",
    "volume": "main",
    "abstract": "Gaussian processes are ubiquitous in machine learning, statistics, and applied mathematics. They provide a flexible modelling framework for approximating functions, whilst simultaneously quantifying uncertainty. However, this is only true when the model is well-specified, which is often not the case in practice. In this paper, we study the properties of Gaussian process means when the smoothness of the model and the likelihood function are misspecified. In this setting, an important theoretical question of practical relevance is how accurate the Gaussian process approximations will be given the chosen model and the extent of the misspecification. The answer to this problem is particularly useful since it can inform our choice of model and experimental design. In particular, we describe how the experimental design and choice of kernel and kernel hyperparameters can be adapted to alleviate model misspecification",
    "checked": true,
    "id": "799abcb74a43ee8c9323175c05f2e2fbab0f549e",
    "semantic_title": "convergence guarantees for gaussian process means with misspecified likelihoods and smoothness",
    "citation_count": 46,
    "authors": [
      "George Wynne",
      "Fran√ßois-Xavier Briol",
      "Mark Girolami"
    ]
  },
  "https://jmlr.org/papers/v22/20-673.html": {
    "title": "A flexible model-free prediction-based framework for feature ranking",
    "volume": "main",
    "abstract": "Despite the availability of numerous statistical and machine learning tools for joint feature modeling, many scientists investigate features marginally, i.e., one feature at a time. This is partly due to training and convention but also roots in scientists' strong interests in simple visualization and interpretability. As such, marginal feature ranking for some predictive tasks, e.g., prediction of cancer driver genes, is widely practiced in the process of scientific discoveries. In this work, we focus on marginal ranking for binary classification, one of the most common predictive tasks. We argue that the most widely used marginal ranking criteria, including the Pearson correlation, the two-sample $t$ test, and two-sample Wilcoxon rank-sum test, do not fully take feature distributions and prediction objectives into account. To address this gap in practice, we propose two ranking criteria corresponding to two prediction objectives: the classical criterion (CC) and the Neyman-Pearson criterion (NPC), both of which use model-free nonparametric implementations to accommodate diverse feature distributions. Theoretically, we show that under regularity conditions, both criteria achieve sample-level ranking that is consistent with their population-level counterpart with high probability. Moreover, NPC is robust to sampling bias when the two class proportions in a sample deviate from those in the population. This property endows NPC good potential in biomedical research where sampling biases are ubiquitous. We demonstrate the use and relative advantages of CC and NPC in simulation and real data studies. Our model-free objective-based ranking idea is extendable to ranking feature subsets and generalizable to other prediction tasks and learning objectives",
    "checked": true,
    "id": "1e51050e1edf9215b74cd978bc9ab7152984cd3d",
    "semantic_title": "a flexible model-free prediction-based framework for feature ranking",
    "citation_count": 3,
    "authors": [
      "Jingyi Jessica Li",
      "Yiling Elaine Chen",
      "Xin Tong"
    ]
  },
  "https://jmlr.org/papers/v22/20-763.html": {
    "title": "Bandit Convex Optimization in Non-stationary Environments",
    "volume": "main",
    "abstract": "Bandit Convex Optimization (BCO) is a fundamental framework for modeling sequential decision-making with partial information, where the only feedback available to the player is the one-point or two-point function values. In this paper, we investigate BCO in non-stationary environments and choose the dynamic regret as the performance measure, which is defined as the difference between the cumulative loss incurred by the algorithm and that of any feasible comparator sequence. Let $T$ be the time horizon and $P_T$ be the path-length of the comparator sequence that reflects the non-stationarity of environments. We propose a novel algorithm that achieves $O(T^{3/4}(1+P_T)^{1/2})$ and $O(T^{1/2}(1+P_T)^{1/2})$ dynamic regret respectively for the one-point and two-point feedback models. The latter result is optimal, matching the $\\Omega(T^{1/2}(1+P_T)^{1/2})$ lower bound established in this paper. Notably, our algorithm is adaptive to the non-stationary environments since it does not require prior knowledge of the path-length $P_T$ ahead of time, which is generally unknown. We further extend the algorithm to an anytime version that does not require to know the time horizon $T$ in advance. Moreover, we study the adaptive regret, another widely used performance measure for online learning in non-stationary environments, and design an algorithm that provably enjoys the adaptive regret guarantees for BCO problems. Finally, we present empirical studies to validate the effectiveness of the proposed approach",
    "checked": true,
    "id": "2efb8da9ba9f436d283474eab9cc3dbda6cacede",
    "semantic_title": "bandit convex optimization in non-stationary environments",
    "citation_count": 36,
    "authors": [
      "Peng Zhao",
      "Guanghui Wang",
      "Lijun Zhang",
      "Zhi-Hua Zhou"
    ]
  },
  "https://jmlr.org/papers/v22/20-774.html": {
    "title": "Integrative High Dimensional Multiple Testing with Heterogeneity under Data Sharing Constraints",
    "volume": "main",
    "abstract": "Identifying informative predictors in a high-dimensional regression model is a critical step for association analysis and predictive modeling. Signal detection in the high dimensional setting often fails due to the limited sample size. One approach to improving power is through meta-analyzing multiple studies which address the same scientific question. However, integrative analysis of high dimensional data from multiple studies is challenging in the presence of between-study heterogeneity. The challenge is even more pronounced with additional data sharing constraints under which only summary data can be shared across different sites. In this paper, we propose a novel data shielding integrative large--scale testing (DSILT) approach to signal detection allowing between-study heterogeneity and not requiring the sharing of individual-level data. Assuming the underlying high dimensional regression models of the data differ across studies yet share similar support, the proposed method incorporates proper integrative estimation and debiasing procedures to construct test statistics for the overall effects of specific covariates. We also develop a multiple testing procedure to identify significant effects while controlling the false discovery rate (FDR) and false discovery proportion (FDP). Theoretical comparisons of the new testing procedure with the ideal individual-level meta-analysis (ILMA) approach and other distributed inference methods are investigated. Simulation studies demonstrate that the proposed testing procedure performs well in both controlling false discovery and attaining power. The new method is applied to a real example detecting interaction effects of the genetic variants for statins and obesity on the risk for type II diabetes",
    "checked": true,
    "id": "9b37105a9c1dff352aea2fa419ce55a74b4c50e5",
    "semantic_title": "integrative high dimensional multiple testing with heterogeneity under data sharing constraints",
    "citation_count": 18,
    "authors": [
      "Molei Liu",
      "Yin Xia",
      "Kelly Cho",
      "Tianxi Cai"
    ]
  },
  "https://jmlr.org/papers/v22/20-848.html": {
    "title": "LassoNet: A Neural Network with Feature Sparsity",
    "volume": "main",
    "abstract": "Much work has been done recently to make neural networks more interpretable, and one approach is to arrange for the network to use only a subset of the available features. In linear models, Lasso (or $\\ell_1$-regularized) regression assigns zero weights to the most irrelevant or redundant features, and is widely used in data science. However the Lasso only applies to linear models. Here we introduce LassoNet, a neural network framework with global feature selection. Our approach achieves feature sparsity by adding a skip (residual) layer and allowing a feature to participate in any hidden layer only if its skip-layer representative is active. Unlike other approaches to feature selection for neural nets, our method uses a modified objective function with constraints, and so integrates feature selection with the parameter learning directly. As a result, it delivers an entire regularization path of solutions with a range of feature sparsity. We apply LassoNet to a number of real-data problems and find that it significantly outperforms state-of-the-art methods for feature selection and regression. LassoNet uses projected proximal gradient descent, and generalizes directly to deep networks. It can be implemented by adding just a few lines of code to a standard neural network",
    "checked": true,
    "id": "0ac17248c8e62ad539f53a84ed47a2409d06707b",
    "semantic_title": "lassonet: a neural network with feature sparsity",
    "citation_count": 70,
    "authors": [
      "Ismael Lemhadri",
      "Feng Ruan",
      "Louis Abraham",
      "Robert Tibshirani"
    ]
  },
  "https://jmlr.org/papers/v22/20-867.html": {
    "title": "Optimal Bounds between f-Divergences and Integral Probability Metrics",
    "volume": "main",
    "abstract": "The families of $f$-divergences (e.g. the Kullback-Leibler divergence) and Integral Probability Metrics (e.g. total variation distance or maximum mean discrepancies) are widely used to quantify the similarity between probability distributions. In this work, we systematically study the relationship between these two families from the perspective of convex duality. Starting from a tight variational representation of the $f$-divergence, we derive a generalization of the moment-generating function, which we show exactly characterizes the best lower bound of the $f$-divergence as a function of a given IPM. Using this characterization, we obtain new bounds while also recovering in a unified manner well-known results, such as Hoeffding's lemma, Pinsker's inequality and its extension to subgaussian functions, and the Hammersley-Chapman-Robbins bound. This characterization also allows us to prove new results on topological properties of the divergence which may be of independent interest",
    "checked": true,
    "id": "b62a02eecddbf94a1a6a837852c4dde053d02812",
    "semantic_title": "optimal bounds between $f$-divergences and integral probability metrics",
    "citation_count": 30,
    "authors": [
      "Rohit Agrawal",
      "Thibaut Horel"
    ]
  },
  "https://jmlr.org/papers/v22/20-974.html": {
    "title": "Finite-sample Analysis of Interpolating Linear Classifiers in the Overparameterized Regime",
    "volume": "main",
    "abstract": "We prove bounds on the population risk of the maximum margin algorithm for two-class linear classification. For linearly separable training data, the maximum margin algorithm has been shown in previous work to be equivalent to a limit of training with logistic loss using gradient descent, as the training error is driven to zero. We analyze this algorithm applied to random data including misclassification noise. Our assumptions on the clean data include the case in which the class-conditional distributions are standard normal distributions. The misclassification noise may be chosen by an adversary, subject to a limit on the fraction of corrupted labels. Our bounds show that, with sufficient over-parameterization, the maximum margin algorithm trained on noisy data can achieve nearly optimal population risk",
    "checked": true,
    "id": "351d449fcc85b41caedf52b0a2af5cc0ca779eb2",
    "semantic_title": "finite-sample analysis of interpolating linear classifiers in the overparameterized regime",
    "citation_count": 94,
    "authors": [
      "Niladri S. Chatterji",
      "Philip M. Long"
    ]
  },
  "https://jmlr.org/papers/v22/17-298.html": {
    "title": "Learning Whenever Learning is Possible: Universal Learning under General Stochastic Processes",
    "volume": "main",
    "abstract": "This work initiates a general study of learning and generalization without the i.i.d. assumption, starting from first principles. While the traditional approach to statistical learning theory typically relies on standard assumptions from probability theory (e.g., i.i.d. or stationary ergodic), in this work we are interested in developing a theory of learning based only on the most fundamental and necessary assumptions implicit in the requirements of the learning problem itself. We specifically study universally consistent function learning, where the objective is to obtain low long-run average loss for any target function, when the data follow a given stochastic process. We are then interested in the question of whether there exist learning rules guaranteed to be universally consistent given only the assumption that universally consistent learning is possible for the given data process. The reasoning that motivates this criterion emanates from a kind of optimist's decision theory, and so we refer to such learning rules as being optimistically universal. We study this question in three natural learning settings: inductive, self-adaptive, and online. Remarkably, as our strongest positive result, we find that optimistically universal learning rules do indeed exist in the self-adaptive learning setting. Establishing this fact requires us to develop new approaches to the design of learning algorithms. Along the way, we also identify concise characterizations of the family of processes under which universally consistent learning is possible in the inductive and self-adaptive settings. We additionally pose a number of enticing open problems, particularly for the online learning setting",
    "checked": true,
    "id": "f26a36fd2b8049e2c1adee36ac939adc5de26120",
    "semantic_title": "learning whenever learning is possible: universal learning under general stochastic processes",
    "citation_count": 26,
    "authors": [
      "Steve Hanneke"
    ]
  },
  "https://jmlr.org/papers/v22/18-056.html": {
    "title": "MushroomRL: Simplifying Reinforcement Learning Research",
    "volume": "MLOSS",
    "abstract": "MushroomRL is an open-source Python library developed to simplify the process of implementing and running Reinforcement Learning (RL) experiments. Compared to other available libraries, MushroomRL has been created with the purpose of providing a comprehensive and flexible framework to minimize the effort in implementing and testing novel RL methodologies. The architecture of MushroomRL is built in such a way that every component of a typical RL experiment is already provided, and most of the time users can only focus on the implementation of their own algorithms. MushroomRL is accompanied by a benchmarking suite collecting experimental results of state-of-the-art deep RL algorithms, and allowing to benchmark new ones. The result is a library from which RL researchers can significantly benefit in the critical phase of the empirical analysis of their works. MushroomRL stable code, tutorials, and documentation can be found at https://github.com/MushroomRL/mushroom-rl",
    "checked": true,
    "id": "fa3e3b3ae026a226351ab988374319e0cde010e6",
    "semantic_title": "mushroomrl: simplifying reinforcement learning research",
    "citation_count": 71,
    "authors": [
      "Carlo D'Eramo",
      "Davide Tateo",
      "Andrea Bonarini",
      "Marcello Restelli",
      "Jan Peters"
    ]
  },
  "https://jmlr.org/papers/v22/18-726.html": {
    "title": "Locally Differentially-Private Randomized Response for Discrete Distribution Learning",
    "volume": "main",
    "abstract": "We consider a setup in which confidential i.i.d. samples $X_1,\\dotsc,X_n$ from an unknown finite-support distribution $\\boldsymbol{p}$ are passed through $n$ copies of a discrete privatization channel (a.k.a. mechanism) producing outputs $Y_1,\\dotsc,Y_n$. The channel law guarantees a local differential privacy of $\\epsilon$. Subject to a prescribed privacy level $\\epsilon$, the optimal channel should be designed such that an estimate of the source distribution based on the channel outputs $Y_1,\\dotsc,Y_n$ converges as fast as possible to the exact value $\\boldsymbol{p}$. For this purpose we study the convergence to zero of three distribution distance metrics: $f$-divergence, mean-squared error and total variation. We derive the respective normalized first-order terms of convergence (as $n \\to \\infty$), which for a given target privacy $\\epsilon$ represent a rule-of-thumb factor by which the sample size must be augmented so as to achieve the same estimation accuracy as that of a non-randomizing channel. We formulate the privacy-fidelity trade-off problem as being that of minimizing said first-order term under a privacy constraint $\\epsilon$. We further identify a scalar quantity that captures the essence of this trade-off, and prove bounds and data-processing inequalities on this quantity. For some specific instances of the privacy-fidelity trade-off problem, we derive inner and outer bounds on the optimal trade-off curve",
    "checked": true,
    "id": "99e215460e04aa71da5909eb1cb426805fe1d648",
    "semantic_title": "locally differentially-private randomized response for discrete distribution learning",
    "citation_count": 8,
    "authors": [
      "Adriano Pastore",
      "Michael Gastpar"
    ]
  },
  "https://jmlr.org/papers/v22/18-863.html": {
    "title": "A Contextual Bandit Bake-off",
    "volume": "main",
    "abstract": "Contextual bandit algorithms are essential for solving many real-world interactive machine learning problems. Despite multiple recent successes on statistically optimal and computationally efficient methods, the practical behavior of these algorithms is still poorly understood. We leverage the availability of large numbers of supervised learning datasets to empirically evaluate contextual bandit algorithms, focusing on practical methods that learn by relying on optimization oracles from supervised learning. We find that a recent method (Foster et al., 2018) using optimism under uncertainty works the best overall. A surprisingly close second is a simple greedy baseline that only explores implicitly through the diversity of contexts, followed by a variant of Online Cover (Agarwal et al., 2014) which tends to be more conservative but robust to problem specification by design. Along the way, we also evaluate various components of contextual bandit algorithm design such as loss estimators. Overall, this is a thorough study and review of contextual bandit methodology",
    "checked": true,
    "id": "eb3caabde41ce45f895b60e59ef88d66eeaf9711",
    "semantic_title": "a contextual bandit bake-off",
    "citation_count": 95,
    "authors": [
      "Alberto Bietti",
      "Alekh Agarwal",
      "John Langford"
    ]
  },
  "https://jmlr.org/papers/v22/19-1024.html": {
    "title": "An Inertial Newton Algorithm for Deep Learning",
    "volume": "main",
    "abstract": "We introduce a new second-order inertial optimization method for machine learning called INNA. It exploits the geometry of the loss function while only requiring stochastic approximations of the function values and the generalized gradients. This makes INNA fully implementable and adapted to large-scale optimization problems such as the training of deep neural networks. The algorithm combines both gradient-descent and Newton-like behaviors as well as inertia. We prove the convergence of INNA for most deep learning problems. To do so, we provide a well-suited framework to analyze deep learning loss functions involving tame optimization in which we study a continuous dynamical system together with its discrete stochastic approximations. We prove sublinear convergence for the continuous-time differential inclusion which underlies our algorithm. Additionally, we also show how standard optimization mini-batch methods applied to non-smooth non-convex problems can yield a certain type of spurious stationary points never discussed before. We address this issue by providing a theoretical framework around the new idea of $D$-criticality; we then give a simple asymptotic analysis of INNA. Our algorithm allows for using an aggressive learning rate of $o(1/\\log k)$. From an empirical viewpoint, we show that INNA returns competitive results with respect to state of the art (stochastic gradient descent, ADAGRAD, ADAM) on popular deep learning benchmark problems",
    "checked": true,
    "id": "9a03bfda0ad9b8469f93fdcf304156e982c9a2ff",
    "semantic_title": "an inertial newton algorithm for deep learning",
    "citation_count": 54,
    "authors": [
      "Camille Castera",
      "J√©r√¥me Bolte",
      "C√©dric F√©votte",
      "Edouard Pauwels"
    ]
  },
  "https://jmlr.org/papers/v22/19-1049.html": {
    "title": "Learning Sparse Classifiers: Continuous and Mixed Integer Optimization Perspectives",
    "volume": "main",
    "abstract": "We consider a discrete optimization formulation for learning sparse classifiers, where the outcome depends upon a linear combination of a small subset of features. Recent work has shown that mixed integer programming (MIP) can be used to solve (to optimality) $\\ell_0$-regularized regression problems at scales much larger than what was conventionally considered possible. Despite their usefulness, MIP-based global optimization approaches are significantly slower than the relatively mature algorithms for $\\ell_1$-regularization and heuristics for nonconvex regularized problems. We aim to bridge this gap in computation times by developing new MIP-based algorithms for $\\ell_0$-regularized classification. We propose two classes of scalable algorithms: an exact algorithm that can handle $p\\approx 50,000$ features in a few minutes, and approximate algorithms that can address instances with $p\\approx 10^6$ in times comparable to the fast $\\ell_1$-based algorithms. Our exact algorithm is based on the novel idea of \\textsl{integrality generation}, which solves the original problem (with $p$ binary variables) via a sequence of mixed integer programs that involve a small number of binary variables. Our approximate algorithms are based on coordinate descent and local combinatorial search. In addition, we present new estimation error bounds for a class of $\\ell_0$-regularized estimators. Experiments on real and synthetic data demonstrate that our approach leads to models with considerably improved statistical performance (especially variable selection) compared to competing methods",
    "checked": true,
    "id": "3b26c5ff78f1acc092b3f0636d77561ddf17447e",
    "semantic_title": "learning sparse classifiers: continuous and mixed integer optimization perspectives",
    "citation_count": 31,
    "authors": [
      "Antoine Dedieu",
      "Hussein Hazimeh",
      "Rahul Mazumder"
    ]
  },
  "https://jmlr.org/papers/v22/19-292.html": {
    "title": "Implicit Langevin Algorithms for Sampling From Log-concave Densities",
    "volume": "main",
    "abstract": "For sampling from a log-concave density, we study implicit integrators resulting from $\\theta$-method discretization of the overdamped Langevin diffusion stochastic differential equation. Theoretical and algorithmic properties of the resulting sampling methods for $ \\theta \\in [0,1] $ and a range of step sizes are established. Our results generalize and extend prior works in several directions. In particular, for $\\theta\\ge 1/2$, we prove geometric ergodicity and stability of the resulting methods for all step sizes. We show that obtaining subsequent samples amounts to solving a strongly-convex optimization problem, which is readily achievable using one of numerous existing methods. Numerical examples supporting our theoretical analysis are also presented",
    "checked": true,
    "id": "bd2a698cbeb939c4f28348a98d254a476337f2b6",
    "semantic_title": "implicit langevin algorithms for sampling from log-concave densities",
    "citation_count": 7,
    "authors": [
      "Liam Hodgkinson",
      "Robert Salomone",
      "Fred Roosta"
    ]
  },
  "https://jmlr.org/papers/v22/19-325.html": {
    "title": "Hybrid Predictive Models: When an Interpretable Model Collaborates with a Black-box Model",
    "volume": "main",
    "abstract": "Interpretable machine learning has become a strong competitor for black-box models. However, the possible loss of the predictive performance for gaining understandability is often inevitable, especially when it needs to satisfy users with diverse backgrounds or high standards for what is considered interpretable. This tension puts practitioners in a dilemma of choosing between high accuracy (black-box models) and interpretability (interpretable models). In this work, we propose a novel framework for building a Hybrid Predictive Model that integrates an interpretable model with any pre-trained black-box model to combine their strengths. The interpretable model substitutes the black-box model on a subset of data where the interpretable model is most competent, gaining transparency at a low cost of the predictive accuracy. We design a principled objective function that considers predictive accuracy, model interpretability, and model transparency (defined as the percentage of data processed by the interpretable substitute.) Under this framework, we propose two hybrid models, one substituting with association rules and the other with linear models, and design customized training algorithms for both models. We test the hybrid models on structured data and text data where interpretable models collaborate with various state-of-the-art black-box models. Results show that hybrid models obtain an efficient trade-off between transparency and predictive performance, characterized by pareto frontiers. Finally, we apply the proposed model on a real-world patients dataset for predicting cardiovascular disease and propose multi-model Pareto frontiers to assist model selection in real applications",
    "checked": true,
    "id": "803c5cb9196ac4f4dfa5ddc89313f2099529bbad",
    "semantic_title": "hybrid predictive model: when an interpretable model collaborates with a black-box model",
    "citation_count": 19,
    "authors": [
      "Tong Wang",
      "Qihang Lin"
    ]
  },
  "https://jmlr.org/papers/v22/19-477.html": {
    "title": "An algorithmic view of L2 regularization and some path-following algorithms",
    "volume": "main",
    "abstract": "We establish an equivalence between the $\\ell_2$-regularized solution path for a convex loss function, and the solution of an ordinary differentiable equation (ODE). Importantly, this equivalence reveals that the solution path can be viewed as the flow of a hybrid of gradient descent and Newton method applying to the empirical loss, which is similar to a widely used optimization technique called trust region method. This provides an interesting algorithmic view of $\\ell_2$ regularization, and is in contrast to the conventional view that the $\\ell_2$ regularization solution path is similar to the gradient flow of the empirical loss. New path-following algorithms based on homotopy methods and numerical ODE solvers are proposed to numerically approximate the solution path. In particular, we consider respectively Newton method and gradient descent method as the basis algorithm for the homotopy method, and establish their approximation error rates over the solution path. Importantly, our theory suggests novel schemes to choose grid points that guarantee an arbitrarily small suboptimality for the solution path. In terms of computational cost, we prove that in order to achieve an $\\epsilon$-suboptimality for the entire solution path, the number of Newton steps required for the Newton method is $\\mathcal O(\\epsilon^{-1/2})$, while the number of gradient steps required for the gradient descent method is $\\mathcal O\\left(\\epsilon^{-1} \\ln(\\epsilon^{-1})\\right)$. Finally, we use $\\ell_2$-regularized logistic regression as an illustrating example to demonstrate the effectiveness of the proposed path-following algorithms",
    "checked": true,
    "id": "1d19dfdcaa0edcc93e59de74bf0ae05a11760ccd",
    "semantic_title": "an algorithmic view of ùìÅ2 regularization and some path-following algorithms",
    "citation_count": 1,
    "authors": [
      "Yunzhang Zhu",
      "Renxiong Liu"
    ]
  },
  "https://jmlr.org/papers/v22/19-479.html": {
    "title": "Hoeffding's Inequality for General Markov Chains and Its Applications to Statistical Learning",
    "volume": "main",
    "abstract": "This paper establishes Hoeffding's lemma and inequality for bounded functions of general-state-space and not necessarily reversible Markov chains. The sharpness of these results is characterized by the optimality of the ratio between variance proxies in the Markov-dependent and independent settings. The boundedness of functions is shown necessary for such results to hold in general. To showcase the usefulness of the new results, we apply them for non-asymptotic analyses of MCMC estimation, respondent-driven sampling and high-dimensional covariance matrix estimation on time series data with a Markovian nature. In addition to statistical problems, we also apply them to study the time-discounted rewards in econometric models and the multi-armed bandit problem with Markovian rewards arising from the field of machine learning",
    "checked": true,
    "id": "a5f2704a7c5bc9ceb7b89541443719c7f33ae00b",
    "semantic_title": "hoeffding's inequality for general markov chains and its applications to statistical learning",
    "citation_count": 30,
    "authors": [
      "Jianqing Fan",
      "Bai Jiang",
      "Qiang Sun"
    ]
  },
  "https://jmlr.org/papers/v22/19-482.html": {
    "title": "Generalization Properties of hyper-RKHS and its Applications",
    "volume": "main",
    "abstract": "This paper generalizes regularized regression problems in a hyper-reproducing kernel Hilbert space (hyper-RKHS), illustrates its utility for kernel learning and out-of-sample extensions, and proves asymptotic convergence results for the introduced regression models in an approximation theory view. Algorithmically, we consider two regularized regression models with bivariate forms in this space, including kernel ridge regression (KRR) and support vector regression (SVR) endowed with hyper-RKHS, and further combine divide-and-conquer with Nystr\\\"{o}m approximation for scalability in large sample cases. This framework is general: the underlying kernel is learned from a broad class, and can be positive definite or not, which adapts to various requirements in kernel learning. Theoretically, we study the convergence behavior of regularized regression algorithms in hyper-RKHS and derive the learning rates, which goes beyond the classical analysis on RKHS due to the non-trivial independence of pairwise samples and the characterisation of hyper-RKHS. Experimentally, results on several benchmarks suggest that the employed framework is able to learn a general kernel function form an arbitrary similarity matrix, and thus achieves a satisfactory performance on classification tasks",
    "checked": true,
    "id": "6a8bbd0615a8fa250a705a36b5f02c8552ad4280",
    "semantic_title": "generalization properties of hyper-rkhs and its applications",
    "citation_count": 1,
    "authors": [
      "Fanghui Liu",
      "Lei Shi",
      "Xiaolin Huang",
      "Jie Yang",
      "Johan A.K. Suykens"
    ]
  },
  "https://jmlr.org/papers/v22/19-486.html": {
    "title": "Pseudo-Marginal Hamiltonian Monte Carlo",
    "volume": "main",
    "abstract": "Bayesian inference in the presence of an intractable likelihood function is computationally challenging. When following a Markov chain Monte Carlo (MCMC) approach to approximate the posterior distribution in this context, one typically either uses MCMC schemes which target the joint posterior of the parameters and some auxiliary latent variables, or pseudo-marginal Metropolis-Hastings (MH) schemes. The latter mimic a MH algorithm targeting the marginal posterior of the parameters by approximating unbiasedly the intractable likelihood. However, in scenarios where the parameters and auxiliary variables are strongly correlated under the posterior and/or this posterior is multimodal, Gibbs sampling or Hamiltonian Monte Carlo (HMC) will perform poorly and the pseudo-marginal MH algorithm, as any other MH scheme, will be inefficient for high-dimensional parameters. We propose here an original MCMC algorithm, termed pseudo-marginal HMC, which combines the advantages of both HMC and pseudo-marginal schemes. Specifically, the PM-HMC method is controlled by a precision parameter $N$, controlling the approximation of the likelihood and, for any $N$, it samples the marginal posterior of the parameters. Additionally, as $N$ tends to infinity, its sample trajectories and acceptance probability converge to those of an ideal, but intractable, HMC algorithm which would have access to the intractable likelihood and its gradient. We demonstrate through experiments that PM-HMC can outperform significantly both standard HMC and pseudo-marginal MH schemes",
    "checked": false,
    "id": "40e96aa92a32e7378eac632e8c19e77260102d4f",
    "semantic_title": "bayesian elastic full‚Äêwaveform inversion using hamiltonian monte carlo",
    "citation_count": 62,
    "authors": [
      "Johan Alenl√∂v",
      "Arnoud Doucet",
      "Fredrik Lindsten"
    ]
  },
  "https://jmlr.org/papers/v22/19-558.html": {
    "title": "Inference for Multiple Heterogeneous Networks with a Common Invariant Subspace",
    "volume": "main",
    "abstract": "The development of models and methodology for the analysis of data from multiple heterogeneous networks is of importance both in statistical network theory and across a wide spectrum of application domains. Although single-graph analysis is well-studied, multiple graph inference is largely unexplored, in part because of the challenges inherent in appropriately modeling graph differences and yet retaining sufficient model simplicity to render estimation feasible. This paper addresses exactly this gap, by introducing a new model, the common subspace independent-edge multiple random graph model, which describes a heterogeneous collection of networks with a shared latent structure on the vertices but potentially different connectivity patterns for each graph. The model encompasses many popular network representations, including the stochastic blockmodel. The model is both flexible enough to meaningfully account for important graph differences, and tractable enough to allow for accurate inference in multiple networks. In particular, a joint spectral embedding of adjacency matrices---the multiple adjacency spectral embedding---leads to simultaneous consistent estimation of underlying parameters for each graph. Under mild additional assumptions, the estimates satisfy asymptotic normality and yield improvements for graph eigenvalue estimation. In both simulated and real data, the model and the embedding can be deployed for a number of subsequent network inference tasks, including dimensionality reduction, classification, hypothesis testing, and community detection. Specifically, when the embedding is applied to a data set of connectomes constructed through diffusion magnetic resonance imaging, the result is an accurate classification of brain scans by human subject and a meaningful determination of heterogeneity across scans of different individuals",
    "checked": true,
    "id": "bd6840a43794eea8059f78cf522d372cb4c94ba3",
    "semantic_title": "inference for multiple heterogeneous networks with a common invariant subspace",
    "citation_count": 91,
    "authors": [
      "Jes√∫s Arroyo",
      "Avanti Athreya",
      "Joshua Cape",
      "Guodong Chen",
      "Carey E. Priebe",
      "Joshua T. Vogelstein"
    ]
  },
  "https://jmlr.org/papers/v22/19-586.html": {
    "title": "Non-attracting Regions of Local Minima in Deep and Wide Neural Networks",
    "volume": "main",
    "abstract": "Understanding the loss surface of neural networks is essential for the design of models with predictable performance and their success in applications. Experimental results suggest that sufficiently deep and wide neural networks are not negatively impacted by suboptimal local minima. Despite recent progress, the reason for this outcome is not fully understood. Could deep networks have very few, if at all, suboptimal local optima? or could all of them be equally good? We provide a construction to show that suboptimal local minima (i.e., non-global ones), even though degenerate, exist for fully connected neural networks with sigmoid activation functions. The local minima obtained by our construction belong to a connected set of local solutions that can be escaped from via a non-increasing path on the loss curve. For extremely wide neural networks of decreasing width after the wide layer, we prove that every suboptimal local minimum belongs to such a connected set. This provides a partial explanation for the successful application of deep neural networks. In addition, we also characterize under what conditions the same construction leads to saddle points instead of local minima for deep neural networks",
    "checked": true,
    "id": "055090a9808083af5ae79ea42b35bd4ca84a7c8a",
    "semantic_title": "non-attracting regions of local minima in deep and wide neural networks",
    "citation_count": 8,
    "authors": [
      "Henning Petzka",
      "Cristian Sminchisescu"
    ]
  },
  "https://jmlr.org/papers/v22/19-658.html": {
    "title": "Individual Fairness in Hindsight",
    "volume": "main",
    "abstract": "The pervasive prevalence of algorithmic decision-making in societal domains necessitates that these algorithms satisfy reasonable notions of fairness. One compelling notion is that of individual fairness (IF), which advocates that similar individuals should be treated similarly. In this paper, we extend the notion of IF to online contextual decision-making in settings where there exists a common notion of conduciveness of decisions as perceived by the affected individuals. We introduce two definitions: (i) fairness-across-time (FT) and (ii) fairness-in-hindsight (FH). FT requires the treatment of individuals to be individually fair relative to the past as well as future, while FH only requires individual fairness of a decision at the time of the decision. We show that these two definitions can have drastically different implications when the principal needs to learn the utility model. Linear regret relative to optimal individually fair decisions is generally unavoidable under FT. On the other hand, we design a new algorithm: Cautious Fair Exploration (CaFE), which satisfies FH and achieves order-optimal sublinear regret guarantees for a broad range of settings",
    "checked": true,
    "id": "a70cbb8539d903bf19a400d436bc2773c5fc7bec",
    "semantic_title": "individual fairness in hindsight",
    "citation_count": 58,
    "authors": [
      "Swati Gupta",
      "Vijay Kamble"
    ]
  },
  "https://jmlr.org/papers/v22/19-782.html": {
    "title": "On efficient multilevel Clustering via Wasserstein distances",
    "volume": "main",
    "abstract": "We propose a novel approach to the problem of multilevel clustering, which aims to simultaneously partition data in each group and discover grouping patterns among groups in a potentially large hierarchically structured corpus of data. Our method involves a joint optimization formulation over several spaces of discrete probability measures, which are endowed with Wasserstein distance metrics. We propose several variants of this problem, which admit fast optimization algorithms, by exploiting the connection to the problem of finding Wasserstein barycenters. Consistency properties are established for the estimates of both local and global clusters. Finally, experimental results with both synthetic and real data are presented to demonstrate the flexibility and scalability of the proposed approach",
    "checked": true,
    "id": "3abfa4e6098ce7a0c17e9e2152fbd578799b6776",
    "semantic_title": "on efficient multilevel clustering via wasserstein distances",
    "citation_count": 7,
    "authors": [
      "Viet Huynh",
      "Nhat Ho",
      "Nhan Dam",
      "XuanLong Nguyen",
      "Mikhail Yurochkin",
      "Hung Bui",
      "Dinh Phung"
    ]
  },
  "https://jmlr.org/papers/v22/19-941.html": {
    "title": "Nonparametric Modeling of Higher-Order Interactions via Hypergraphons",
    "volume": "main",
    "abstract": "We study statistical and algorithmic aspects of using hypergraphons, that are limits of large hypergraphs, for modeling higher-order interactions. Although hypergraphons are extremely powerful from a modeling perspective, we consider a restricted class of Simple Lipschitz Hypergraphons (SLH), that are amenable to practically efficient estimation. We also provide rates of convergence for our estimator that are optimal for the class of SLH. Simulation results are provided to corroborate the theory",
    "checked": true,
    "id": "fe56bf55ef38b862f47d742d961a4a853c951c05",
    "semantic_title": "nonparametric modeling of higher-order interactions via hypergraphons",
    "citation_count": 12,
    "authors": [
      "Krishnakumar Balasubramanian"
    ]
  },
  "https://jmlr.org/papers/v22/19-969.html": {
    "title": "Optimal Minimax Variable Selection for Large-Scale Matrix Linear Regression Model",
    "volume": "main",
    "abstract": "Large-scale matrix linear regression models with high-dimensional responses and high-dimensional variables have been widely employed in various large-scale biomedical studies. In this article, we propose an optimal minimax variable selection approach for the matrix linear regression model when the dimensions of both the response matrix and predictors diverge at the exponential rate of the sample size. We develop an iterative hard-thresholding algorithm for fast computation and establish an optimal minimax theory for the parameter estimates. The finite sample performance of the method is examined via extensive simulation studies and a real data application from the Alzheimer's Disease Neuroimaging Initiative study is provided",
    "checked": true,
    "id": "613e9d51a17e3d5854db458f46a50f311500e3a6",
    "semantic_title": "optimal minimax variable selection for large-scale matrix linear regression model",
    "citation_count": 4,
    "authors": [
      "Meiling Hao",
      "Lianqiang Qu",
      "Dehan Kong",
      "Liuquan Sun",
      "Hongtu Zhu"
    ]
  },
  "https://jmlr.org/papers/v22/20-029.html": {
    "title": "Statistical guarantees for local graph clustering",
    "volume": "main",
    "abstract": "Local graph clustering methods aim to find small clusters in very large graphs. These methods take as input a graph and a seed node, and they return as output a good cluster in a running time that depends on the size of the output cluster but that is independent of the size of the input graph. In this paper, we adopt a statistical perspective on local graph clustering, and we analyze the performance of the $\\ell_1$-regularized PageRank method (Fountoulakis et al., 2019) for the recovery of a single target cluster, given a seed node inside the cluster. Assuming the target cluster has been generated by a random model, we present two results. In the first, we show that the optimal support of $\\ell_1$-regularized PageRank recovers the full target cluster, with bounded false positives. In the second, we show that if the seed node is connected solely to the target cluster then the optimal support of $\\ell_1$-regularized PageRank recovers exactly the target cluster. We also show empirically that $\\ell_1$-regularized PageRank has a state-of-the-art performance on many real graphs, demonstrating the superiority of the method. From a computational perspective, we show that the solution path of $\\ell_1$-regularized PageRank is monotonic. This allows for the application of the forward stagewise algorithm, which approximates the entire solution path in running time that does not depend on the size of the whole graph. Finally, we show that $\\ell_1$-regularized PageRank and approximate personalized PageRank (APPR) (Andersen et al., 2006), another very popular method for local graph clustering, are equivalent in the sense that we can lower and upper bound the output of one with the output of the other. Based on this relation, we establish for APPR similar results to those we establish for $\\ell_1$-regularized PageRank",
    "checked": true,
    "id": "1f96e0fa38322aac5623aa513c65a8175c2da6ab",
    "semantic_title": "statistical guarantees for local graph clustering",
    "citation_count": 9,
    "authors": [
      "Wooseok Ha",
      "Kimon Fountoulakis",
      "Michael W. Mahoney"
    ]
  },
  "https://jmlr.org/papers/v22/20-058.html": {
    "title": "Hyperparameter Optimization via Sequential Uniform Designs",
    "volume": "main",
    "abstract": "Hyperparameter optimization (HPO) plays a central role in the automated machine learning (AutoML). It is a challenging task as the response surfaces of hyperparameters are generally unknown, hence essentially a global optimization problem. This paper reformulates HPO as a computer experiment and proposes a novel sequential uniform design (SeqUD) strategy with three-fold advantages: a) the hyperparameter space is adaptively explored with evenly spread design points, without the need of expensive meta-modeling and acquisition optimization; b) the batch-by-batch design points are sequentially generated with parallel processing support; c) a new augmented uniform design algorithm is developed for the efficient real-time generation of follow-up design points. Extensive experiments are conducted on both global optimization tasks and HPO applications. The numerical results show that the proposed SeqUD strategy outperforms benchmark HPO methods, and it can be therefore a promising and competitive alternative to existing AutoML tools",
    "checked": true,
    "id": "a2ac52f0431a8f53b3a1993857a76e2c8accd15e",
    "semantic_title": "hyperparameter optimization via sequential uniform designs",
    "citation_count": 4,
    "authors": [
      "Zebin Yang",
      "Aijun Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/20-1067.html": {
    "title": "Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled Gradient Descent",
    "volume": "main",
    "abstract": "Low-rank matrix estimation is a canonical problem that finds numerous applications in signal processing, machine learning and imaging science. A popular approach in practice is to factorize the matrix into two compact low-rank factors, and then optimize these factors directly via simple iterative methods such as gradient descent and alternating minimization. Despite nonconvexity, recent literatures have shown that these simple heuristics in fact achieve linear convergence when initialized properly for a growing number of problems of interest. However, upon closer examination, existing approaches can still be computationally expensive especially for ill-conditioned matrices: the convergence rate of gradient descent depends linearly on the condition number of the low-rank matrix, while the per-iteration cost of alternating minimization is often prohibitive for large matrices. The goal of this paper is to set forth a competitive algorithmic approach dubbed Scaled Gradient Descent (ScaledGD) which can be viewed as preconditioned or diagonally-scaled gradient descent, where the preconditioners are adaptive and iteration-varying with a minimal computational overhead. With tailored variants for low-rank matrix sensing, robust principal component analysis and matrix completion, we theoretically show that ScaledGD achieves the best of both worlds: it converges linearly at a rate independent of the condition number of the low-rank matrix similar as alternating minimization, while maintaining the low per-iteration cost of gradient descent. Our analysis is also applicable to general loss functions that are restricted strongly convex and smooth over low-rank matrices. To the best of our knowledge, ScaledGD is the first algorithm that provably has such properties over a wide range of low-rank matrix estimation tasks. At the core of our analysis is the introduction of a new distance function that takes account of the preconditioners when measuring the distance between the iterates and the ground truth. Finally, numerical examples are provided to demonstrate the effectiveness of ScaledGD in accelerating the convergence rate of ill-conditioned low-rank matrix estimation in a wide number of applications",
    "checked": true,
    "id": "3488c2962e5e2ff30a12e550f2b11eb3de8feef1",
    "semantic_title": "accelerating ill-conditioned low-rank matrix estimation via scaled gradient descent",
    "citation_count": 71,
    "authors": [
      "Tian Tong",
      "Cong Ma",
      "Yuejie Chi"
    ]
  },
  "https://jmlr.org/papers/v22/20-1081.html": {
    "title": "Universal consistency and rates of convergence of multiclass prototype algorithms in metric spaces",
    "volume": "main",
    "abstract": "We study universal consistency and convergence rates of simple nearest-neighbor prototype rules for the problem of multiclass classification in metric spaces. We first show that a novel data-dependent partitioning rule, named Proto-NN, is universally consistent in any metric space that admits a universally consistent rule. Proto-NN is a significant simplification of OptiNet, a recently proposed compression-based algorithm that, to date, was the only algorithm known to be universally consistent in such a general setting. Practically, Proto-NN is simpler to implement and enjoys reduced computational complexity. We then proceed to study convergence rates of the excess error probability. We first obtain rates for the standard $k$-NN rule under a margin condition and a new generalized-Lipschitz condition. The latter is an extension of a recently proposed modified-Lipschitz condition from $\\mathbb R^d$ to metric spaces. Similarly to the modified-Lipschitz condition, the new condition avoids any boundness assumptions on the data distribution. While obtaining rates for Proto-NN is left open, we show that a second prototype rule that hybridizes between $k$-NN and Proto-NN achieves the same rates as $k$-NN while enjoying similar computational advantages as Proto-NN. However, as $k$-NN, this hybrid rule is not consistent in general",
    "checked": true,
    "id": "199a1859b24dd6e604f8d9a0b7b47ee492b22a62",
    "semantic_title": "universal consistency and rates of convergence of multiclass prototype algorithms in metric spaces",
    "citation_count": 20,
    "authors": [
      "L√°szl√≥ Gy√∂rfi",
      "Roi Weiss"
    ]
  },
  "https://jmlr.org/papers/v22/20-1162.html": {
    "title": "Hardness of Identity Testing for Restricted Boltzmann Machines and Potts models",
    "volume": "main",
    "abstract": "We study the identity testing problem for restricted Boltzmann machines (RBMs), and more generally, for undirected graphical models. In this problem, given sample access to the Gibbs distribution corresponding to an unknown or hidden model $M^*$ and given an explicit model $M$, the goal is to distinguish if either $M = M^*$ or if the models are (statistically) far apart. We establish the computational hardness of identity testing for RBMs (i.e., mixed Ising models on bipartite graphs), even when there are no latent variables or an external field. Specifically, we show that unless $RP=NP$, there is no polynomial-time identity testing algorithm for RBMs when $\\beta d=\\omega(\\log{n})$, where $d$ is the maximum degree of the visible graph and $\\beta$ is the largest edge weight (in absolute value); when $\\beta d =O(\\log{n})$ there is an efficient identity testing algorithm that utilizes the structure learning algorithm of Klivans and Meka (2017). We prove similar lower bounds for purely ferromagnetic RBMs with inconsistent external fields and for the ferromagnetic Potts model. To prove our results, we introduce a novel methodology to reduce the corresponding approximate counting problem to testing utilizing the phase transition exhibited by these models",
    "checked": true,
    "id": "a06b3842a347ffeb8602753d2991ac853217ad1f",
    "semantic_title": "hardness of identity testing for restricted boltzmann machines and potts models",
    "citation_count": 3,
    "authors": [
      "Antonio Blanca",
      "Zongchen Chen",
      "Daniel ≈†tefankoviƒç",
      "Eric Vigoda"
    ]
  },
  "https://jmlr.org/papers/v22/20-1170.html": {
    "title": "Factorization Machines with Regularization for Sparse Feature Interactions",
    "volume": "main",
    "abstract": "Factorization machines (FMs) are machine learning predictive models based on second-order feature interactions and FMs with sparse regularization are called sparse FMs. Such regularizations enable feature selection, which selects the most relevant features for accurate prediction, and therefore they can contribute to the improvement of the model accuracy and interpretability. However, because FMs use second-order feature interactions, the selection of features often causes the loss of many relevant feature interactions in the resultant models. In such cases, FMs with regularization specially designed for feature interaction selection trying to achieve interaction-level sparsity may be preferred instead of those just for feature selection trying to achieve feature-level sparsity. In this paper, we present a new regularization scheme for feature interaction selection in FMs. For feature interaction selection, our proposed regularizer makes the feature interaction matrix sparse without a restriction on sparsity patterns imposed by the existing methods. We also describe efficient proximal algorithms for the proposed FMs and how our ideas can be applied or extended to feature selection and other related models such as higher-order FMs and the all-subsets model. The analysis and experimental results on synthetic and real-world datasets show the effectiveness of the proposed methods",
    "checked": true,
    "id": "1a8031f5ed2ee10fb640f240006d52b543a36e15",
    "semantic_title": "factorization machines with regularization for sparse feature interactions",
    "citation_count": 2,
    "authors": [
      "Kyohei Atarashi",
      "Satoshi Oyama",
      "Masahito Kurihara"
    ]
  },
  "https://jmlr.org/papers/v22/20-1194.html": {
    "title": "Kernel Smoothing, Mean Shift, and Their Learning Theory with Directional Data",
    "volume": "main",
    "abstract": "Directional data consist of observations distributed on a (hyper)sphere, and appear in many applied fields, such as astronomy, ecology, and environmental science. This paper studies both statistical and computational problems of kernel smoothing for directional data. We generalize the classical mean shift algorithm to directional data, which allows us to identify local modes of the directional kernel density estimator (KDE). The statistical convergence rates of the directional KDE and its derivatives are derived, and the problem of mode estimation is examined. We also prove the ascending property of the directional mean shift algorithm and investigate a general problem of gradient ascent on the unit hypersphere. To demonstrate the applicability of the algorithm, we evaluate it as a mode clustering method on both simulated and real-world data sets",
    "checked": true,
    "id": "532ac9ccef5c8f3fbd9ceb9af564c6a2a4881129",
    "semantic_title": "kernel smoothing, mean shift, and their learning theory with directional data",
    "citation_count": 9,
    "authors": [
      "Yikun Zhang",
      "Yen-Chi Chen"
    ]
  },
  "https://jmlr.org/papers/v22/20-1211.html": {
    "title": "What Causes the Test Error? Going Beyond Bias-Variance via ANOVA",
    "volume": "main",
    "abstract": "Modern machine learning methods are often overparametrized, allowing adaptation to the data at a fine level. This can seem puzzling; in the worst case, such models do not need to generalize. This puzzle inspired a great amount of work, arguing when overparametrization reduces test error, in a phenomenon called `double descent'. Recent work aimed to understand in greater depth why overparametrization is helpful for generalization. This lead to discovering the unimodality of variance as a function of the level of parametrization, and to decomposing the variance into that arising from label noise, initialization, and randomness in the training data to understand the sources of the error. In this work we develop a deeper understanding of this area. Specifically, we propose using the analysis of variance (ANOVA) to decompose the variance in the test error in a symmetric way, for studying the generalization performance of certain two-layer linear and non-linear networks. The advantage of the analysis of variance is that it reveals the effects of initialization, label noise, and training data more clearly than prior approaches. Moreover, we also study the monotonicity and unimodality of the variance components. While prior work studied the unimodality of the overall variance, we study the properties of each term in the variance decomposition. One of our key insights is that often, the interaction between training samples and initialization can dominate the variance; surprisingly being larger than their marginal effect. Also, we characterize `phase transitions' where the variance changes from unimodal to monotone. On a technical level, we leverage advanced deterministic equivalent techniques for Haar random matrices, that---to our knowledge---have not yet been used in the area. We verify our results in numerical simulations and on empirical data examples",
    "checked": true,
    "id": "4c1454cc0e7f74697cfc65bdc321593202942d4c",
    "semantic_title": "what causes the test error? going beyond bias-variance via anova",
    "citation_count": 26,
    "authors": [
      "Licong Lin",
      "Edgar Dobriban"
    ]
  },
  "https://jmlr.org/papers/v22/20-1233.html": {
    "title": "A Greedy Algorithm for Quantizing Neural Networks",
    "volume": "main",
    "abstract": "We propose a new computationally efficient method for quantizing the weights of pre- trained neural networks that is general enough to handle both multi-layer perceptrons and convolutional neural networks. Our method deterministically quantizes layers in an iterative fashion with no complicated re-training required. Specifically, we quantize each neuron, or hidden unit, using a greedy path-following algorithm. This simple algorithm is equivalent to running a dynamical system, which we prove is stable for quantizing a single-layer neural network (or, alternatively, for quantizing the first layer of a multi-layer network) when the training data are Gaussian. We show that under these assumptions, the quantization error decays with the width of the layer, i.e., its level of over-parametrization. We provide numerical experiments, on multi-layer networks, to illustrate the performance of our methods on MNIST and CIFAR10 data, as well as for quantizing the VGG16 network using ImageNet data",
    "checked": true,
    "id": "8262c5fe1d30cbb92764790e2b23e225758c8b2a",
    "semantic_title": "a greedy algorithm for quantizing neural networks",
    "citation_count": 19,
    "authors": [
      "Eric Lybrand",
      "Rayan Saab"
    ]
  },
  "https://jmlr.org/papers/v22/20-1300.html": {
    "title": "The Ridgelet Prior: A Covariance Function Approach to Prior Specification for Bayesian Neural Networks",
    "volume": "main",
    "abstract": "Bayesian neural networks attempt to combine the strong predictive performance of neural networks with formal quantification of uncertainty associated with the predictive output in the Bayesian framework. However, it remains unclear how to endow the parameters of the network with a prior distribution that is meaningful when lifted into the output space of the network. A possible solution is proposed that enables the user to posit an appropriate Gaussian process covariance function for the task at hand. Our approach constructs a prior distribution for the parameters of the network, called a ridgelet prior, that approximates the posited Gaussian process in the output space of the network. In contrast to existing work on the connection between neural networks and Gaussian processes, our analysis is non-asymptotic, with finite sample-size error bounds provided. This establishes the universality property that a Bayesian neural network can approximate any Gaussian process whose covariance function is sufficiently regular. Our experimental assessment is limited to a proof-of-concept, where we demonstrate that the ridgelet prior can out-perform an unstructured prior on regression problems for which a suitable Gaussian process prior can be provided",
    "checked": true,
    "id": "641202270cecc46e29c54b345408e20347e98a96",
    "semantic_title": "the ridgelet prior: a covariance function approach to prior specification for bayesian neural networks",
    "citation_count": 12,
    "authors": [
      "Takuo Matsubara",
      "Chris J. Oates",
      "Fran√ßois-Xavier Briol"
    ]
  },
  "https://jmlr.org/papers/v22/20-1366.html": {
    "title": "Information criteria for non-normalized models",
    "volume": "main",
    "abstract": "Many statistical models are given in the form of non-normalized densities with an intractable normalization constant. Since maximum likelihood estimation is computationally intensive for these models, several estimation methods have been developed which do not require explicit computation of the normalization constant, such as noise contrastive estimation (NCE) and score matching. However, model selection methods for general nonnormalized models have not been proposed so far. In this study, we develop information criteria for non-normalized models estimated by NCE or score matching. They are approximately unbiased estimators of discrepancy measures for non-normalized models. Simulation results and applications to real data demonstrate that the proposed criteria enable selection of the appropriate non-normalized model in a data-driven manner",
    "checked": true,
    "id": "97eaa9f0de6c085821d8e302cb7f6488fad2cb93",
    "semantic_title": "information criteria for non-normalized models",
    "citation_count": 7,
    "authors": [
      "Takeru Matsuda",
      "Masatoshi Uehara",
      "Aapo Hyvarinen"
    ]
  },
  "https://jmlr.org/papers/v22/20-1372.html": {
    "title": "When Does Gradient Descent with Logistic Loss Find Interpolating Two-Layer Networks?",
    "volume": "main",
    "abstract": "We study the training of finite-width two-layer smoothed ReLU networks for binary classification using the logistic loss. We show that gradient descent drives the training loss to zero if the initial loss is small enough. When the data satisfies certain cluster and separation conditions and the network is wide enough, we show that one step of gradient descent reduces the loss sufficiently that the first result applies",
    "checked": true,
    "id": "ee32bd67e59c0154da93c539d630a32b35099c5a",
    "semantic_title": "when does gradient descent with logistic loss find interpolating two-layer networks?",
    "citation_count": 14,
    "authors": [
      "Niladri S. Chatterji",
      "Philip M. Long",
      "Peter L. Bartlett"
    ]
  },
  "https://jmlr.org/papers/v22/20-1422.html": {
    "title": "Are We Forgetting about Compositional Optimisers in Bayesian Optimisation?",
    "volume": "main",
    "abstract": "Bayesian optimisation presents a sample-efficient methodology for global optimisation. Within this framework, a crucial performance-determining subroutine is the maximisation of the acquisition function, a task complicated by the fact that acquisition functions tend to be non-convex and thus nontrivial to optimise. In this paper, we undertake a comprehensive empirical study of approaches to maximise the acquisition function. Additionally, by deriving novel, yet mathematically equivalent, compositional forms for popular acquisition functions, we recast the maximisation task as a compositional optimisation problem, allowing us to benefit from the extensive literature in this field. We highlight the empirical advantages of the compositional approach to acquisition function maximisation across 3958 individual experiments comprising synthetic optimisation tasks as well as tasks from Bayesmark. Given the generality of the acquisition function maximisation subroutine, we posit that the adoption of compositional optimisers has the potential to yield performance improvements across all domains in which Bayesian optimisation is currently being applied. An open-source implementation is made available at https://github.com/huawei-noah/noah-research/tree/CompBO/BO/HEBO/CompBO",
    "checked": true,
    "id": "cf54fc89971c67ce45627b934e449a3bc8e9a060",
    "semantic_title": "are we forgetting about compositional optimisers in bayesian optimisation?",
    "citation_count": 12,
    "authors": [
      "Antoine Grosnit",
      "Alexander I. Cowen-Rivers",
      "Rasul Tutunov",
      "Ryan-Rhys Griffiths",
      "Jun Wang",
      "Haitham Bou-Ammar"
    ]
  },
  "https://jmlr.org/papers/v22/20-1444.html": {
    "title": "MetaGrad: Adaptation using Multiple Learning Rates in Online Learning",
    "volume": "main",
    "abstract": "We provide a new adaptive method for online convex optimization, MetaGrad, that is robust to general convex losses but achieves faster rates for a broad class of special functions, including exp-concave and strongly convex functions, but also various types of stochastic and non-stochastic functions without any curvature. We prove this by drawing a connection to the Bernstein condition, which is known to imply fast rates in offline statistical learning. MetaGrad further adapts automatically to the size of the gradients. Its main feature is that it simultaneously considers multiple learning rates, which are weighted directly proportional to their empirical performance on the data using a new meta-algorithm. We provide three versions of MetaGrad. The full matrix version maintains a full covariance matrix and is applicable to learning tasks for which we can afford update time quadratic in the dimension. The other two versions provide speed-ups for high-dimensional learning tasks with an update time that is linear in the dimension: one is based on sketching, the other on running a separate copy of the basic algorithm per coordinate. We evaluate all versions of MetaGrad on benchmark online classification and regression tasks, on which they consistently outperform both online gradient descent and AdaGrad",
    "checked": true,
    "id": "d52ebf9d77193017b3df249c965774f0527c6bac",
    "semantic_title": "metagrad: adaptation using multiple learning rates in online learning",
    "citation_count": 13,
    "authors": [
      "Tim van Erven",
      "Wouter M. Koolen",
      "Dirk van der Hoeven"
    ]
  },
  "https://jmlr.org/papers/v22/20-185.html": {
    "title": "Counterfactual Mean Embeddings",
    "volume": "main",
    "abstract": "Counterfactual inference has become a ubiquitous tool in online advertisement, recommendation systems, medical diagnosis, and econometrics. Accurate modelling of outcome distributions associated with different interventions---known as counterfactual distributions---is crucial for the success of these applications. In this work, we propose to model counterfactual distributions using a novel Hilbert space representation called counterfactual mean embedding (CME). The CME embeds the associated counterfactual distribution into a reproducing kernel Hilbert space (RKHS) endowed with a positive definite kernel, which allows us to perform causal inference over the entire landscape of the counterfactual distribution. Based on this representation, we propose a distributional treatment effect (DTE) which can quantify the causal effect over entire outcome distributions. Our approach is nonparametric as the CME can be estimated under the unconfoundedness assumption from observational data without requiring any parametric assumption about the underlying distributions. We also establish a rate of convergence of the proposed estimator which depends on the smoothness of the conditional mean and the Radon-Nikodym derivative of the underlying marginal distributions. Furthermore, our framework allows for more complex outcomes such as images, sequences, and graphs. Our experimental results on synthetic data and off-policy evaluation tasks demonstrate the advantages of the proposed estimator",
    "checked": true,
    "id": "071ffc1a0bc1008b1000144e76bf50fa36e5c73d",
    "semantic_title": "counterfactual mean embeddings",
    "citation_count": 34,
    "authors": [
      "Krikamol Muandet",
      "Motonobu Kanagawa",
      "Sorawit Saengkyongam",
      "Sanparith Marukatat"
    ]
  },
  "https://jmlr.org/papers/v22/20-190.html": {
    "title": "PeerReview4All: Fair and Accurate Reviewer Assignment in Peer Review",
    "volume": "main",
    "abstract": "We consider the problem of automated assignment of papers to reviewers in conference peer review, with a focus on fairness and statistical accuracy. Our fairness objective is to maximize the review quality of the most disadvantaged paper, in contrast to the commonly used objective of maximizing the total quality over all papers. We design an assignment algorithm based on an incremental max-flow procedure that we prove is near-optimally fair. Our statistical accuracy objective is to ensure correct recovery of the papers that should be accepted. We provide a sharp minimax analysis of the accuracy of the peer-review process for a popular objective-score model as well as for a novel subjective-score model that we propose in the paper. Our analysis proves that our proposed assignment algorithm also leads to a near-optimal statistical accuracy. Finally, we design a novel experiment that allows for an objective comparison of various assignment algorithms, and overcomes the inherent difficulty posed by the absence of a ground truth in experiments on peer-review. The results of this experiment as well as of other experiments on synthetic and real data corroborate the theoretical guarantees of our algorithm",
    "checked": true,
    "id": "f32c67daa6a93281bd8645fc2fa423dca67aea00",
    "semantic_title": "peerreview4all: fair and accurate reviewer assignment in peer review",
    "citation_count": 82,
    "authors": [
      "Ivan Stelmakh",
      "Nihar Shah",
      "Aarti Singh"
    ]
  },
  "https://jmlr.org/papers/v22/20-303.html": {
    "title": "Improving Reproducibility in Machine Learning Research(A Report from the NeurIPS 2019 Reproducibility Program)",
    "volume": "main",
    "abstract": "One of the challenges in machine learning research is to ensure that presented and published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper or talk, using the same code and data (when available), is a necessary step to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workflows, which potentially reduce unintentional errors. In 2019, the Neural Information Processing Systems (NeurIPS) conference, the premier international conference for research in machine learning, introduced a reproducibility program, designed to improve the standards across the community for how we conduct, communicate, and evaluate machine learning research. The program contained three components: a code submission policy, a community-wide reproducibility challenge, and the inclusion of the Machine Learning Reproducibility checklist as part of the paper submission process. In this paper, we describe each of these components, how it was deployed, as well as what we were able to learn from this initiative",
    "checked": true,
    "id": "5e331bf7887e2e634bf5b12788849d2d2b74bc7f",
    "semantic_title": "improving reproducibility in machine learning research (a report from the neurips 2019 reproducibility program)",
    "citation_count": 231,
    "authors": [
      "Joelle Pineau",
      "Philippe Vincent-Lamarre",
      "Koustuv Sinha",
      "Vincent Lariviere",
      "Alina Beygelzimer",
      "Florence d'Alche-Buc",
      "Emily Fox",
      "Hugo Larochelle"
    ]
  },
  "https://jmlr.org/papers/v22/20-410.html": {
    "title": "Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning",
    "volume": "main",
    "abstract": "Random Matrix Theory (RMT) is applied to analyze the weight matrices of Deep Neural Networks (DNNs), including both production quality, pre-trained models such as AlexNet and Inception, and smaller models trained from scratch, such as LeNet5 and a miniature-AlexNet. Empirical and theoretical results clearly indicate that the DNN training process itself implicitly implements a form of Self-Regularization, implicitly sculpting a more regularized energy or penalty landscape. In particular, the empirical spectral density (ESD) of DNN layer matrices displays signatures of traditionally-regularized statistical models, even in the absence of exogenously specifying traditional forms of explicit regularization, such as Dropout or Weight Norm constraints. Building on relatively recent results in RMT, most notably its extension to Universality classes of Heavy-Tailed matrices, and applying them to these empirical results, we develop a theory to identify 5+1 Phases of Training, corresponding to increasing amounts of Implicit Self-Regularization. These phases can be observed during the training process as well as in the final learned DNNs. For smaller and/or older DNNs, this Implicit Self-Regularization is like traditional Tikhonov regularization, in that there is a \"size scale\" separating signal from noise. For state-of-the-art DNNs, however, we identify a novel form of Heavy-Tailed Self-Regularization, similar to the self-organization seen in the statistical physics of disordered systems (such as classical models of actual neural activity). This results from correlations arising at all size scales, which for DNNs arises implicitly due to the training process itself. This implicit Self-Regularization can depend strongly on the many knobs of the training process. In particular, we demonstrate that we can cause a small model to exhibit all 5+1 phases of training simply by changing the batch size. Our results suggest that large, well-trained DNN architectures should exhibit Heavy-Tailed Self-Regularization, and we discuss the theoretical and practical implications of this",
    "checked": true,
    "id": "97d6efc6b524bff216c5a77f243821c2980b2073",
    "semantic_title": "implicit self-regularization in deep neural networks: evidence from random matrix theory and implications for learning",
    "citation_count": 132,
    "authors": [
      "Charles H. Martin",
      "Michael W. Mahoney"
    ]
  },
  "https://jmlr.org/papers/v22/20-416.html": {
    "title": "The ensmallen library for flexible numerical optimization",
    "volume": "MLOSS",
    "abstract": "We overview the ensmallen numerical optimization library, which provides a flexible C++ framework for mathematical optimization of user-supplied objective functions. Many types of objective functions are supported, including general, differentiable, separable, constrained, and categorical. A diverse set of pre-built optimizers is provided, including Quasi-Newton optimizers and many variants of Stochastic Gradient Descent. The underlying framework facilitates the implementation of new optimizers. Optimization of an objective function typically requires supplying only one or two C++ functions. Custom behavior can be easily specified via callback functions. Empirical comparisons show that ensmallen outperforms other frameworks while providing more functionality. The library is available at https://ensmallen.org and is distributed under the permissive BSD license",
    "checked": true,
    "id": "8916a932004a3ca720faf1445f4623d5d7f153db",
    "semantic_title": "the ensmallen library for flexible numerical optimization",
    "citation_count": 10,
    "authors": [
      "Ryan R. Curtin",
      "Marcus Edel",
      "Rahul Ganesh Prabhu",
      "Suryoday Basak",
      "Zhihao Lou",
      "Conrad Sanderson"
    ]
  },
  "https://jmlr.org/papers/v22/20-429.html": {
    "title": "Estimation and Optimization of Composite Outcomes",
    "volume": "main",
    "abstract": "There is tremendous interest in precision medicine as a means to improve patient outcomes by tailoring treatment to individual characteristics. An individualized treatment rule formalizes precision medicine as a map from patient information to a recommended treatment. A treatment rule is defined to be optimal if it maximizes the mean of a scalar outcome in a population of interest, e.g., symptom reduction. However, clinical and intervention scientists often seek to balance multiple and possibly competing outcomes, e.g., symptom reduction and the risk of an adverse event. One approach to precision medicine in this setting is to elicit a composite outcome which balances all competing outcomes; unfortunately, eliciting a composite outcome directly from patients is difficult without a high-quality instrument, and an expert-derived composite outcome may not account for heterogeneity in patient preferences. We propose a new paradigm for the study of precision medicine using observational data that relies solely on the assumption that clinicians are approximately (i.e., imperfectly) making decisions to maximize individual patient utility. Estimated composite outcomes are subsequently used to construct an estimator of an individualized treatment rule which maximizes the mean of patient-specific composite outcomes. The estimated composite outcomes and estimated optimal individualized treatment rule provide new insights into patient preference heterogeneity, clinician behavior, and the value of precision medicine in a given domain. We derive inference procedures for the proposed estimators under mild conditions and demonstrate their finite sample performance through a suite of simulation experiments and an illustrative application to data from a study of bipolar depression",
    "checked": true,
    "id": "23c679f8d7f723be507cc4fbb043bba4178f01ad",
    "semantic_title": "estimation and optimization of composite outcomes",
    "citation_count": 5,
    "authors": [
      "Daniel J. Luckett",
      "Eric B. Laber",
      "Siyeon Kim",
      "Michael R. Kosorok"
    ]
  },
  "https://jmlr.org/papers/v22/20-469.html": {
    "title": "Asymptotic Normality, Concentration, and Coverage of Generalized Posteriors",
    "volume": "main",
    "abstract": "Generalized likelihoods are commonly used to obtain consistent estimators with attractive computational and robustness properties. Formally, any generalized likelihood can be used to define a generalized posterior distribution, but an arbitrarily defined \"posterior\" cannot be expected to appropriately quantify uncertainty in any meaningful sense. In this article, we provide sufficient conditions under which generalized posteriors exhibit concentration, asymptotic normality (Bernstein-von Mises), an asymptotically correct Laplace approximation, and asymptotically correct frequentist coverage. We apply our results in detail to generalized posteriors for a wide array of generalized likelihoods, including pseudolikelihoods in general, the Gaussian Markov random field pseudolikelihood, the fully observed Boltzmann machine pseudolikelihood, the Ising model pseudolikelihood, the Cox proportional hazards partial likelihood, and a median-based likelihood for robust inference of location. Further, we show how our results can be used to easily establish the asymptotics of standard posteriors for exponential families and generalized linear models. We make no assumption of model correctness so that our results apply with or without misspecification",
    "checked": true,
    "id": "23af2d124b52288d1172558e45199c87e7fa8892",
    "semantic_title": "asymptotic normality, concentration, and coverage of generalized posteriors",
    "citation_count": 49,
    "authors": [
      "Jeffrey W. Miller"
    ]
  },
  "https://jmlr.org/papers/v22/20-533.html": {
    "title": "First-order Convergence Theory for Weakly-Convex-Weakly-Concave Min-max Problems",
    "volume": "main",
    "abstract": "In this paper, we consider first-order convergence theory and algorithms for solving a class of non-convex non-concave min-max saddle-point problems, whose objective function is weakly convex in the variables of minimization and weakly concave in the variables of maximization. It has many important applications in machine learning including training Generative Adversarial Nets (GANs). We propose an algorithmic framework motivated by the inexact proximal point method, where the weakly monotone variational inequality (VI) corresponding to the original min-max problem is solved through approximately solving a sequence of strongly monotone VIs constructed by adding a strongly monotone mapping to the original gradient mapping. We prove first-order convergence to a nearly stationary solution of the original min-max problem of the generic algorithmic framework and establish different rates by employing different algorithms for solving each strongly monotone VI. Experiments verify the convergence theory and also demonstrate the effectiveness of the proposed methods on training GANs",
    "checked": true,
    "id": "05d4c2c4dcde2375f217eb8cdc255089c344d0a3",
    "semantic_title": "first-order convergence theory for weakly-convex-weakly-concave min-max problems",
    "citation_count": 39,
    "authors": [
      "Mingrui Liu",
      "Hassan Rafique",
      "Qihang Lin",
      "Tianbao Yang"
    ]
  },
  "https://jmlr.org/papers/v22/20-611.html": {
    "title": "Black-Box Reductions for Zeroth-Order Gradient Algorithms to Achieve Lower Query Complexity",
    "volume": "main",
    "abstract": "Zeroth-order (ZO) optimization has been the key technique for various machine learning applications especially for black-box adversarial attack, where models need to be learned in a gradient-free manner. Although many ZO algorithms have been proposed, the high function query complexities hinder their applications seriously. To address this challenging problem, we propose two stagewise black-box reduction frameworks for ZO algorithms under convex and non-convex settings respectively, which lower down the function query complexities of ZO algorithms. Moreover, our frameworks can directly derive the convergence results of ZO algorithms under convex and non-convex settings without extra analyses, as long as convergence results under strongly convex setting are given. To illustrate the advantages, we further study ZO-SVRG, ZO-SAGA and ZO-Varag under strongly-convex setting and use our frameworks to directly derive the convergence results under convex and non-convex settings. The function query complexities of these algorithms derived by our frameworks are lower than that of their vanilla counterparts without frameworks, or even lower than that of state-of-the-art algorithms. Finally we conduct numerical experiments to illustrate the superiority of our frameworks",
    "checked": true,
    "id": "866f4de5df6414be0376813960985ed4389c2410",
    "semantic_title": "black-box reductions for zeroth-order gradient algorithms to achieve lower query complexity",
    "citation_count": 1,
    "authors": [
      "Bin Gu",
      "Xiyuan Wei",
      "Shangqian Gao",
      "Ziran Xiong",
      "Cheng Deng",
      "Heng Huang"
    ]
  },
  "https://jmlr.org/papers/v22/20-627.html": {
    "title": "Optimal Rates of Distributed Regression with Imperfect Kernels",
    "volume": "main",
    "abstract": "Distributed machine learning systems have been receiving increasing attentions for their efficiency to process large scale data. Many distributed frameworks have been proposed for different machine learning tasks. In this paper, we study the distributed kernel regression via the divide and conquer approach. The learning process consists of three stages. Firstly, the data is partitioned into multiple subsets. Then a base kernel regression algorithm is applied to each subset to learn a local regression model. Finally the local models are averaged to generate the final regression model for the purpose of predictive analytics or statistical inference. This approach has been proved asymptotically minimax optimal if the kernel is perfectly selected so that the true regression function lies in the associated reproducing kernel Hilbert space. However, this is usually, if not always, impractical because kernels that can only be selected via prior knowledge or a tuning process are hardly perfect. Instead it is more common that the kernel is good enough but imperfect in the sense that the true regression can be well approximated by but does not lie exactly in the kernel space. We show distributed kernel regression can still achieve capacity independent optimal rate in this case. To this end, we first establish a general framework that allows to analyze distributed regression with response weighted base algorithms by bounding the error of such algorithms on a single data set, provided that the error bounds have factored the impact of unexplained variance of the response variable. Then we perform a leave one out analysis of the kernel ridge regression and bias corrected kernel ridge regression, which in combination with the aforementioned framework allows us to derive sharp error bounds and capacity independent optimal rates for the associated distributed kernel regression algorithms. As a byproduct of the thorough analysis, we also prove the kernel ridge regression can achieve rates faster than $O(N^{-1})$ (where $N$ is the sample size) in the noise free setting which, to our best knowledge, are first observed and novel in regression learning",
    "checked": true,
    "id": "4fbdfa148b4f8a523f1b3ff086852073f7082c01",
    "semantic_title": "optimal rates of distributed regression with imperfect kernels",
    "citation_count": 10,
    "authors": [
      "Hongwei Sun",
      "Qiang Wu"
    ]
  },
  "https://jmlr.org/papers/v22/20-689.html": {
    "title": "Unlinked Monotone Regression",
    "volume": "main",
    "abstract": "We consider so-called univariate unlinked (sometimes \"decoupled,\" or \"shuffled\") regression when the unknown regression curve is monotone. In standard monotone regression, one observes a pair $(X,Y)$ where a response $Y$ is linked to a covariate $X$ through the model $Y= m_0(X) + \\epsilon$, with $m_0$ the (unknown) monotone regression function and $\\epsilon$ the unobserved error (assumed to be independent of $X$). In the unlinked regression setting one gets only to observe a vector of realizations from both the response $Y$ and from the covariate $X$ where now $Y \\stackrel{d}{=} m_0(X) + \\epsilon$. There is no (observed) pairing of $X$ and $Y$. Despite this, it is actually still possible to derive a consistent non-parametric estimator of $m_0$ under the assumption of monotonicity of $m_0$ and knowledge of the distribution of the noise $\\epsilon$. In this paper, we establish an upper bound on the rate of convergence of such an estimator under minimal assumption on the distribution of the covariate $X$. We discuss extensions to the case in which the distribution of the noise is unknown. We develop a second order algorithm for its computation, and we demonstrate its use on synthetic data. Finally, we apply our method (in a fully data driven way, without knowledge of the error distribution) on longitudinal data from the US Consumer Expenditure Survey",
    "checked": true,
    "id": "77e0314368328f32949f02b9f73f3057669e7a55",
    "semantic_title": "unlinked monotone regression",
    "citation_count": 9,
    "authors": [
      "Fadoua Balabdaoui",
      "Charles R. Doss",
      "C√©cile Durot"
    ]
  },
  "https://jmlr.org/papers/v22/20-697.html": {
    "title": "Replica Exchange for Non-Convex Optimization",
    "volume": "main",
    "abstract": "Gradient descent (GD) is known to converge quickly for convex objective functions, but it can be trapped at local minima. On the other hand, Langevin dynamics (LD) can explore the state space and find global minima, but in order to give accurate estimates, LD needs to run with a small discretization step size and weak stochastic force, which in general slow down its convergence. This paper shows that these two algorithms can \"collaborate\" through a simple exchange mechanism, in which they swap their current positions if LD yields a lower objective function. This idea can be seen as the singular limit of the replica-exchange technique from the sampling literature. We show that this new algorithm converges to the global minimum linearly with high probability, assuming the objective function is strongly convex in a neighborhood of the unique global minimum. By replacing gradients with stochastic gradients, and adding a proper threshold to the exchange mechanism, our algorithm can also be used in online settings. We also study non-swapping variants of the algorithm, which achieve similar performance. We further verify our theoretical results through some numerical experiments and observe superior performances of the proposed algorithm over running GD or LD alone",
    "checked": true,
    "id": "2917fcdd8cda508b31f85be04b33068559da4ded",
    "semantic_title": "replica exchange for non-convex optimization",
    "citation_count": 18,
    "authors": [
      "Jing Dong",
      "Xin T. Tong"
    ]
  },
  "https://jmlr.org/papers/v22/20-704.html": {
    "title": "Achieving Fairness in the Stochastic Multi-Armed Bandit Problem",
    "volume": "main",
    "abstract": "We study an interesting variant of the stochastic multi-armed bandit problem, which we call the Fair-MAB problem, where, in addition to the objective of maximizing the sum of expected rewards, the algorithm also needs to ensure that at any time, each arm is pulled at least a pre-specified fraction of times. We investigate the interplay between learning and fairness in terms of a pre-specified vector denoting the fractions of guaranteed pulls. We define a fairness-aware regret, which we call $r$-Regret, that takes into account the above fairness constraints and extends the conventional notion of regret in a natural way. Our primary contribution is to obtain a complete characterization of a class of Fair-MAB algorithms via two parameters: the unfairness tolerance and the learning algorithm used as a black-box. For this class of algorithms, we provide a fairness guarantee that holds uniformly over time, irrespective of the chosen learning algorithm. Further, when the learning algorithm is UCB1, we show that our algorithm achieves constant $r$-Regret for a large enough time horizon. Finally, we analyze the cost of fairness in terms of the conventional notion of regret. We conclude by experimentally validating our theoretical results",
    "checked": true,
    "id": "e28fe7bb6adf5882a707a24c64a276e4bcd08b2f",
    "semantic_title": "achieving fairness in the stochastic multi-armed bandit problem",
    "citation_count": 85,
    "authors": [
      "Vishakha Patil",
      "Ganesh Ghalme",
      "Vineet Nair",
      "Y. Narahari"
    ]
  },
  "https://jmlr.org/papers/v22/20-706.html": {
    "title": "Doubly infinite residual neural networks: a diffusion process approach",
    "volume": "main",
    "abstract": "Modern neural networks featuring a large number of layers (depth) and units per layer (width) have achieved a remarkable performance across many domains. While there exists a vast literature on the interplay between infinitely wide neural networks and Gaussian processes, a little is known about analogous interplays with respect to infinitely deep neural networks. Neural networks with independent and identically distributed (i.i.d.) initializations exhibit undesirable forward and backward propagation properties as the number of layers increases, e.g., vanishing dependency on the input, and perfectly correlated outputs for any two inputs. To overcome these drawbacks, Peluchetti and Favaro (2020) considered fully-connected residual networks (ResNets) with network's parameters initialized by means of distributions that shrink as the number of layers increases, thus establishing an interplay between infinitely deep ResNets and solutions to stochastic differential equations, i.e. diffusion processes, and showing that infinitely deep ResNets does not suffer from undesirable forward-propagation properties. In this paper, we review the results of Peluchetti and Favaro (2020), extending them to convolutional ResNets, and we establish analogous backward-propagation results, which directly relate to the problem of training fully-connected deep ResNets. Then, we investigate the more general setting of doubly infinite neural networks, where both network's width and network's depth grow unboundedly. We focus on doubly infinite fully-connected ResNets, for which we consider i.i.d. initializations. Under this setting, we show that the dynamics of quantities of interest converge, at initialization, to deterministic limits. This allow us to provide analytical expressions for inference, both in the case of weakly trained and fully trained ResNets. Our results highlight a limited expressive power of doubly infinite ResNets when the unscaled network's parameters are i.i.d. and the residual blocks are shallow",
    "checked": true,
    "id": "b1dfa4f823202c508dbcf97a07d7cbb85f9e5530",
    "semantic_title": "doubly infinite residual neural networks: a diffusion process approach",
    "citation_count": 1,
    "authors": [
      "Stefano Peluchetti",
      "Stefano Favaro"
    ]
  },
  "https://jmlr.org/papers/v22/20-721.html": {
    "title": "Locally Private k-Means Clustering",
    "volume": "main",
    "abstract": "We design a new algorithm for the Euclidean $k$-means problem that operates in the local model of differential privacy. Unlike in the non-private literature, differentially private algorithms for the $k$-means objective incur both additive and multiplicative errors. Our algorithm significantly reduces the additive error while keeping the multiplicative error the same as in previous state-of-the-art results. Specifically, on a database of size $n$, our algorithm guarantees $O(1)$ multiplicative error and $\\approx n^{1/2+a}$ additive error for an arbitrarily small constant $a>0$. All previous algorithms in the local model had additive error $\\approx n^{2/3+a}$. Our techniques extend to $k$-median clustering. We show that the additive error we obtain is almost optimal in terms of its dependency on the database size $n$. Specifically, we give a simple lower bound showing that every locally-private algorithm for the $k$-means objective must have additive error at least $\\approx\\sqrt{n}$",
    "checked": true,
    "id": "af389455d0fe5015a22b15974b14e56e605f44b2",
    "semantic_title": "locally private k-means clustering",
    "citation_count": 46,
    "authors": [
      "Uri Stemmer"
    ]
  },
  "https://jmlr.org/papers/v22/20-768.html": {
    "title": "Prediction Under Latent Factor Regression: Adaptive PCR, Interpolating Predictors and Beyond",
    "volume": "main",
    "abstract": "This work is devoted to the finite sample prediction risk analysis of a class of linear predictors of a response $Y\\in \\mathbb{R}$ from a high-dimensional random vector $X\\in \\mathbb{R}^p$ when $(X,Y)$ follows a latent factor regression model generated by a unobservable latent vector $Z$ of dimension less than $p$. Our primary contribution is in establishing finite sample risk bounds for prediction with the ubiquitous Principal Component Regression (PCR) method, under the factor regression model, with the number of principal components adaptively selected from the data---a form of theoretical guarantee that is surprisingly lacking from the PCR literature. To accomplish this, we prove a master theorem that establishes a risk bound for a large class of predictors, including the PCR predictor as a special case. This approach has the benefit of providing a unified framework for the analysis of a wide range of linear prediction methods, under the factor regression setting. In particular, we use our main theorem to recover known risk bounds for the minimum-norm interpolating predictor, which has received renewed attention in the past two years, and a prediction method tailored to a subclass of factor regression models with identifiable parameters. This model-tailored method can be interpreted as prediction via clusters with latent centers. To address the problem of selecting among a set of candidate predictors, we analyze a simple model selection procedure based on data-splitting, providing an oracle inequality under the factor model to prove that the performance of the selected predictor is close to the optimal candidate. We conclude with a detailed simulation study to support and complement our theoretical results",
    "checked": true,
    "id": "6f7751664f89b4dfb857340a8f3052784895bfcb",
    "semantic_title": "prediction under latent factor regression: adaptive pcr, interpolating predictors and beyond",
    "citation_count": 10,
    "authors": [
      "Xin Bing",
      "Florentina Bunea",
      "Seth Strimas-Mackey",
      "Marten Wegkamp"
    ]
  },
  "https://jmlr.org/papers/v22/20-863.html": {
    "title": "Conditional independences and causal relations implied by sets of equations",
    "volume": "main",
    "abstract": "Real-world complex systems are often modelled by sets of equations with endogenous and exogenous variables. What can we say about the causal and probabilistic aspects of variables that appear in these equations without explicitly solving the equations? We make use of Simon's causal ordering algorithm (Simon, 1953) to construct a causal ordering graph and prove that it expresses the effects of soft and perfect interventions on the equations under certain unique solvability assumptions. We further construct a Markov ordering graph and prove that it encodes conditional independences in the distribution implied by the equations with independent random exogenous variables, under a similar unique solvability assumption. We discuss how this approach reveals and addresses some of the limitations of existing causal modelling frameworks, such as causal Bayesian networks and structural causal models",
    "checked": true,
    "id": "1ed0aa9628614219927a50f32976eb32d18a5150",
    "semantic_title": "conditional independences and causal relations implied by sets of equations",
    "citation_count": 6,
    "authors": [
      "Tineke Blom",
      "Mirthe M. van Diepen",
      "Joris M. Mooij"
    ]
  },
  "https://jmlr.org/papers/v22/20-919.html": {
    "title": "A Sharp Blockwise Tensor Perturbation Bound for Orthogonal Iteration",
    "volume": "main",
    "abstract": "In this paper, we develop novel perturbation bounds for the higher-order orthogonal iteration (HOOI). Under mild regularity conditions, we establish blockwise tensor perturbation bounds for HOOI with guarantees for both tensor reconstruction in Hilbert-Schmidt norm $\\|\\widehat{\\mathcal{T}} - \\mathcal{T} \\|_{\\rm HS}$ and mode-$k$ singular subspace estimation in Schatten-$q$ norm $\\| \\sin \\Theta (\\widehat{U}_k, U_k) \\|_q$ for any $q \\geq 1$. We show the upper bounds of mode-$k$ singular subspace estimation are unilateral and converge linearly to a quantity characterized by blockwise errors of the perturbation and signal strength. For the tensor reconstruction error bound, we express the bound through a simple quantity $\\xi$, which depends only on perturbation and the multilinear rank of the underlying signal. Rate matching deterministic lower bound for tensor reconstruction, which demonstrates the optimality of HOOI, is also provided. Furthermore, we prove that one-step HOOI (i.e., HOOI with only a single iteration) is also optimal in terms of tensor reconstruction and can be used to lower the computational cost. The perturbation results are also extended to the case that only partial modes of $\\mathcal{T}$ have low-rank structure. We support our theoretical results by extensive numerical studies. Finally, we apply the novel perturbation bounds of HOOI on two applications, tensor denoising and tensor co-clustering, from machine learning and statistics, which demonstrates the superiority of the new perturbation results",
    "checked": true,
    "id": "1e6ffbea5217e12f6252d4e8970ecdc932e36341",
    "semantic_title": "a sharp blockwise tensor perturbation bound for orthogonal iteration",
    "citation_count": 7,
    "authors": [
      "Yuetian Luo",
      "Garvesh Raskutti",
      "Ming Yuan",
      "Anru R. Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/21-0006.html": {
    "title": "Improved Shrinkage Prediction under a Spiked Covariance Structure",
    "volume": "main",
    "abstract": "We develop a novel shrinkage rule for prediction in a high-dimensional non-exchangeable hierarchical Gaussian model with an unknown spiked covariance structure. We propose a family of priors for the mean parameter, governed by a power hyper-parameter, which encompasses independent to highly dependent scenarios. Corresponding to popular loss functions such as quadratic, generalized absolute, and Linex losses, these prior models induce a wide class of shrinkage predictors that involve quadratic forms of smooth functions of the unknown covariance. By using uniformly consistent estimators of these quadratic forms, we propose an efficient procedure for evaluating these predictors which outperforms factor model based direct plug-in approaches. We further improve our predictors by considering possible reduction in their variability through a novel coordinate-wise shrinkage policy that only uses covariance level information and can be adaptively tuned using the sample eigen structure. Finally, we extend our disaggregate model based methodology to prediction in aggregate models. We propose an easy-to-implement functional substitution method for predicting linearly aggregated targets and establish asymptotic optimality of our proposed procedure. We present simulation experiments as well as real data examples illustrating the efficacy of the proposed method",
    "checked": true,
    "id": "8e44cd81445c865b4ac6b0db889e93c052d2b1dc",
    "semantic_title": "improved shrinkage prediction under a spiked covariance structure",
    "citation_count": 2,
    "authors": [
      "Trambak Banerjee",
      "Gourab Mukherjee",
      "Debashis Paul"
    ]
  },
  "https://jmlr.org/papers/v22/21-0017.html": {
    "title": "Alibi Explain: Algorithms for Explaining Machine Learning Models",
    "volume": "MLOSS",
    "abstract": "We introduce Alibi Explain, an open-source Python library for explaining predictions of machine learning models (https://github.com/SeldonIO/alibi). The library features state-of-the-art explainability algorithms for classification and regression models. The algorithms cover both the model-agnostic (black-box) and model-specific (white-box) setting, cater for multiple data types (tabular, text, images) and explanation scope (local and global explanations). The library exposes a unified API enabling users to work with explanations in a consistent way. Alibi adheres to best development practices featuring extensive testing of code correctness and algorithm convergence in a continuous integration environment. The library comes with extensive documentation of both usage and theoretical background of methods, and a suite of worked end-to-end use cases. Alibi aims to be a production-ready toolkit with integrations into machine learning deployment platforms such as Seldon Core and KFServing, and distributed explanation capabilities using Ray",
    "checked": true,
    "id": "6d9774d937f190afcff768058a8292b8b383ce7b",
    "semantic_title": "alibi explain: algorithms for explaining machine learning models",
    "citation_count": 57,
    "authors": [
      "Janis Klaise",
      "Arnaud Van Looveren",
      "Giovanni Vacanti",
      "Alexandru Coca"
    ]
  },
  "https://jmlr.org/papers/v22/21-0112.html": {
    "title": "A Probabilistic Interpretation of Self-Paced Learning with Applications to Reinforcement Learning",
    "volume": "main",
    "abstract": "Across machine learning, the use of curricula has shown strong empirical potential to improve learning from data by avoiding local optima of training objectives. For reinforcement learning (RL), curricula are especially interesting, as the underlying optimization has a strong tendency to get stuck in local optima due to the exploration-exploitation trade-off. Recently, a number of approaches for an automatic generation of curricula for RL have been shown to increase performance while requiring less expert knowledge compared to manually designed curricula. However, these approaches are seldomly investigated from a theoretical perspective, preventing a deeper understanding of their mechanics. In this paper, we present an approach for automated curriculum generation in RL with a clear theoretical underpinning. More precisely, we formalize the well-known self-paced learning paradigm as inducing a distribution over training tasks, which trades off between task complexity and the objective to match a desired task distribution. Experiments show that training on this induced distribution helps to avoid poor local optima across RL algorithms in different tasks with uninformative rewards and challenging exploration requirements",
    "checked": true,
    "id": "01fb33418d53423c835e6b698f6c4bf6d185bbc8",
    "semantic_title": "a probabilistic interpretation of self-paced learning with applications to reinforcement learning",
    "citation_count": 16,
    "authors": [
      "Pascal Klink",
      "Hany Abdulsamad",
      "Boris Belousov",
      "Carlo D'Eramo",
      "Jan Peters",
      "Joni Pajarinen"
    ]
  },
  "https://jmlr.org/papers/v22/21-0199.html": {
    "title": "Benchmarking Unsupervised Object Representations for Video Sequences",
    "volume": "main",
    "abstract": "Perceiving the world in terms of objects and tracking them through time is a crucial prerequisite for reasoning and scene understanding. Recently, several methods have been proposed for unsupervised learning of object-centric representations. However, since these models were evaluated on different downstream tasks, it remains unclear how they compare in terms of basic perceptual abilities such as detection, figure-ground segmentation and tracking of objects. To close this gap, we design a benchmark with four data sets of varying complexity and seven additional test sets featuring challenging tracking scenarios relevant for natural videos. Using this benchmark, we compare the perceptual abilities of four object-centric approaches: ViMON, a video-extension of MONet, based on recurrent spatial attention, OP3, which exploits clustering via spatial mixture models, as well as TBA and SCALOR, which use explicit factorization via spatial transformers. Our results suggest that the architectures with unconstrained latent representations learn more powerful representations in terms of object detection, segmentation and tracking than the spatial transformer based architectures. We also observe that none of the methods are able to gracefully handle the most challenging tracking scenarios despite their synthetic nature, suggesting that our benchmark may provide fruitful guidance towards learning more robust object-centric video representations",
    "checked": true,
    "id": "3786fbf393c04f8d1ffba38dd45655a40220f799",
    "semantic_title": "benchmarking unsupervised object representations for video sequences",
    "citation_count": 24,
    "authors": [
      "Marissa A. Weis",
      "Kashyap Chitta",
      "Yash Sharma",
      "Wieland Brendel",
      "Matthias Bethge",
      "Andreas Geiger",
      "Alexander S. Ecker"
    ]
  },
  "https://jmlr.org/papers/v22/21-0281.html": {
    "title": "mlr3pipelines - Flexible Machine Learning Pipelines in R",
    "volume": "MLOSS",
    "abstract": "Recent years have seen a proliferation of ML frameworks. Such systems make ML accessible to non-experts, especially when combined with powerful parameter tuning and AutoML techniques. Modern, applied ML extends beyond direct learning on clean data, however, and needs an expressive language for the construction of complex ML workflows beyond simple pre- and post-processing. We present mlr3pipelines, an R framework which can be used to define linear and complex non-linear ML workflows as directed acyclic graphs. The framework is part of the mlr3 ecosystem, leveraging convenient resampling, benchmarking, and tuning components",
    "checked": true,
    "id": "cab9cad9aee873a99d601c292498d43438911bda",
    "semantic_title": "mlr3pipelines - flexible machine learning pipelines in r",
    "citation_count": 15,
    "authors": [
      "Martin Binder",
      "Florian Pfisterer",
      "Michel Lang",
      "Lennart Schneider",
      "Lars Kotthoff",
      "Bernd Bischl"
    ]
  },
  "https://jmlr.org/papers/v22/21-0287.html": {
    "title": "Mode-wise Tensor Decompositions: Multi-dimensional Generalizations of CUR Decompositions",
    "volume": "main",
    "abstract": "Low rank tensor approximation is a fundamental tool in modern machine learning and data science. In this paper, we study the characterization, perturbation analysis, and an efficient sampling strategy for two primary tensor CUR approximations, namely Chidori and Fiber CUR. We characterize exact tensor CUR decompositions for low multilinear rank tensors. We also present theoretical error bounds of the tensor CUR approximations when (adversarial or Gaussian) noise appears. Moreover, we show that low cost uniform sampling is sufficient for tensor CUR approximations if the tensor has an incoherent structure. Empirical performance evaluations, with both synthetic and real-world datasets, establish the speed advantage of the tensor CUR approximations over other state-of-the-art low multilinear rank tensor approximations",
    "checked": true,
    "id": "3a7f2556d4543ca4624b679e306cb6b2038b37a4",
    "semantic_title": "mode-wise tensor decompositions: multi-dimensional generalizations of cur decompositions",
    "citation_count": 14,
    "authors": [
      "HanQin Cai",
      "Keaton Hamm",
      "Longxiu Huang",
      "Deanna Needell"
    ]
  },
  "https://jmlr.org/papers/v22/18-105.html": {
    "title": "As You Like It: Localization via Paired Comparisons",
    "volume": "main",
    "abstract": "Suppose that we wish to estimate a vector $\\mathbf{x}$ from a set of binary paired comparisons of the form \"$\\mathbf{x}$ is closer to $\\mathbf{p}$ than to $\\mathbf{q}$\" for various choices of vectors $\\mathbf{p}$ and $\\mathbf{q}$. The problem of estimating $\\mathbf{x}$ from this type of observation arises in a variety of contexts, including nonmetric multidimensional scaling, \"unfolding,\" and ranking problems, often because it provides a powerful and flexible model of preference. We describe theoretical bounds for how well we can expect to estimate $\\mathbf{x}$ under a randomized model for $\\mathbf{p}$ and $\\mathbf{q}$. We also present results for the case where the comparisons are noisy and subject to some degree of error. Additionally, we show that under a randomized model for $\\mathbf{p}$ and $\\mathbf{q}$, a suitable number of binary paired comparisons yield a stable embedding of the space of target vectors. Finally, we also show that we can achieve significant gains by adaptively changing the distribution for choosing $\\mathbf{p}$ and $\\mathbf{q}$",
    "checked": true,
    "id": "f2debd7a1a2c510c34277132ad8f61d96ada2ae7",
    "semantic_title": "as you like it: localization via paired comparisons",
    "citation_count": 11,
    "authors": [
      "Andrew K. Massimino",
      "Mark A. Davenport"
    ]
  },
  "https://jmlr.org/papers/v22/18-431.html": {
    "title": "Matrix Product States for Inference in Discrete Probabilistic Models",
    "volume": "main",
    "abstract": "When faced with problems involving inference in discrete domains, solutions often involve appeals to conditional independence structure or mean-field approximations. We argue that this is insufficient for a number of interesting Bayesian problems, including mixture assignment posteriors and probabilistic relational models (e.g. the stochastic block model). These posteriors exhibit no conditional independence structure, precluding the use of graphical model methods, yet exhibit dependency between every single element of the posterior, making mean-field methods a poor fit. We propose using an expressive yet tractable approximation inspired by tensor factorization methods, alternately known as the tensor train or the matrix product state, and which can be construed of as a direct extension of the mean-field approximation to higher-order dependencies. We give a comprehensive introduction to the application of matrix product state in probabilistic inference, and illustrate how to efficiently perform marginalization, conditioning, sampling, normalization, some expectations, and approximate variational inference in our proposed model",
    "checked": true,
    "id": "284bfcb5fdc16397559dcf0b14f9a15d6497f89e",
    "semantic_title": "matrix product states for inference in discrete probabilistic models",
    "citation_count": 3,
    "authors": [
      "Rasmus Bonnevie",
      "Mikkel N. Schmidt"
    ]
  },
  "https://jmlr.org/papers/v22/19-017.html": {
    "title": "Differentially Private Regression and Classification with Sparse Gaussian Processes",
    "volume": "main",
    "abstract": "A continuing challenge for machine learning is providing methods to perform computation on data while ensuring the data remains private. In this paper we build on the provable privacy guarantees of differential privacy which has been combined with Gaussian processes through the previously published cloaking method, an approach that tackles the problem of providing privacy for the outputs of a training set. In this paper we solve several shortcomings of this method, starting with the problem of predictions in regions with low data density. We experiment with the use of inducing points to provide a sparse approximation and show that these can provide robust differential privacy in outlier areas and at higher dimensions. We then look at classification, and modify the Laplace approximation approach to provide differentially private predictions. We then combine this with the sparse approximation and demonstrate the capability to perform classification in high dimensions. We finally explore the issue of hyperparameter selection and develop a method for their private selection. This paper and associated libraries provide a robust toolkit for combining differential privacy and Gaussian processes in a practical manner",
    "checked": true,
    "id": "a3dfb275d1589e3122047cd70bb47fbf2a10247d",
    "semantic_title": "differentially private regression and classification with sparse gaussian processes",
    "citation_count": 3,
    "authors": [
      "Michael Thomas Smith",
      "Mauricio A. Alvarez",
      "Neil D. Lawrence"
    ]
  },
  "https://jmlr.org/papers/v22/19-1048.html": {
    "title": "One-Shot Federated Learning: Theoretical Limits and Algorithms to Achieve Them",
    "volume": "main",
    "abstract": "We consider distributed statistical optimization in one-shot setting, where there are $m$ machines each observing $n$ i.i.d. samples. Based on its observed samples, each machine sends a $B$-bit-long message to a server. The server then collects messages from all machines, and estimates a parameter that minimizes an expected convex loss function. We investigate the impact of communication constraint, $B$, on the expected error and derive a tight lower bound on the error achievable by any algorithm. We then propose an estimator, which we call Multi-Resolution Estimator (MRE), whose expected error (when $B\\ge d\\log mn$ where $d$ is the dimension of parameter) meets the aforementioned lower bound up to a poly-logarithmic factor in $mn$. The expected error of MRE, unlike existing algorithms, tends to zero as the number of machines ($m$) goes to infinity, even when the number of samples per machine ($n$) remains upper bounded by a constant. We also address the problem of learning under tiny communication budget, and present lower and upper error bounds for the case that the budget $B$ is a constant",
    "checked": true,
    "id": "5a10f7e9b8220082f81872f208f43d403bbbc916",
    "semantic_title": "one-shot federated learning: theoretical limits and algorithms to achieve them",
    "citation_count": 28,
    "authors": [
      "Saber Salehkaleybar",
      "Arsalan Sharifnassab",
      "S. Jamaloddin Golestani"
    ]
  },
  "https://jmlr.org/papers/v22/19-373.html": {
    "title": "Collusion Detection and Ground Truth Inference in Crowdsourcing for Labeling Tasks",
    "volume": "main",
    "abstract": "Crowdsourcing has been a prompt and cost-effective way of obtaining labels in many machine learning applications. In the literature, a number of algorithms have been developed to infer the ground truth based on the collected labels. However, most existing studies assume workers to be independent and are vulnerable to worker collusion. This paper aims at detecting the collusive behaviors of workers in labeling tasks. Specifically, we consider collusion in a pairwise manner and propose a penalized pairwise profile likelihood method based on the adaptive LASSO penalty for collusion detection. Many models that describe the behavior of independent workers can be incorporated into our proposed framework as the baseline model. We further investigate the theoretical properties of the proposed method that guarantee the asymptotic performance. An algorithm based on expectation-maximization algorithm and coordinate descent is proposed to numerically maximize the penalized pairwise profile likelihood function for parameter estimation. To the best of our knowledge, this is the first statistical model that simultaneously detects collusion, learns workers' capabilities, and infers the ground true labels. Numerical studies using synthetic and real data sets are also conducted to verify the performance of the method",
    "checked": true,
    "id": "27f322a9c9450ab9cc2733fad1494f2756efcb09",
    "semantic_title": "collusion detection and ground truth inference in crowdsourcing for labeling tasks",
    "citation_count": 2,
    "authors": [
      "Changyue Song",
      "Kaibo Liu",
      "Xi Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/19-747.html": {
    "title": "On the Estimation of Network Complexity: Dimension of Graphons",
    "volume": "main",
    "abstract": "Network complexity has been studied for over half a century and has found a wide range of applications. Many methods have been developed to characterize and estimate the complexity of networks. However, there has been little research with statistical guarantees. In this paper, we develop a statistical theory of graph complexity in a general model of random graphs, the so-called graphon model. Given a graphon, we endow the latent space of the nodes with the neighborhood distance. Our complexity index is then based on the covering number and the Minkowksi dimension of this metric space. Although the latent space is not identifiable, these indices turn out to be identifiable. This notion of complexity has simple interpretations on popular examples: it matches the number of communities in stochastic block models; the dimension of the Euclidean space in random geometric graphs; the regularity of the link function in H\\\"older graphons. From a single observation of the graph, we construct an estimator of the neighborhood-distance and show universal non-asymptotic bounds for its risk, matching minimax lower bounds. Based on this estimated distance, we compute the corresponding covering number and Minkowski dimension and we provide optimal non-asymptotic error bounds for these two plug-in estimators",
    "checked": true,
    "id": "8bcaac2e1ca8f948fa21add9ca589b4ca196e2b1",
    "semantic_title": "on the estimation of network complexity: dimension of graphons",
    "citation_count": 0,
    "authors": [
      "Yann Issartel"
    ]
  },
  "https://jmlr.org/papers/v22/19-776.html": {
    "title": "Method of Contraction-Expansion (MOCE) for Simultaneous Inference in Linear Models",
    "volume": "main",
    "abstract": "Simultaneous inference after model selection is of critical importance to address scientific hypotheses involving a set of parameters. In this paper, we consider a high-dimensional linear regression model in which a regularization procedure such as LASSO is applied to yield a sparse model. To establish a simultaneous post-model selection inference, we propose a method of contraction and expansion (MOCE) along the line of debiasing estimation in that we investigate a desirable trade-off between model selection variability and sample variability by the means of forward screening. We establish key theoretical results for the inference from the proposed MOCE procedure. Once the expanded model is properly selected, the theoretical guarantees and simultaneous confidence regions can be constructed by the joint asymptotic normal distribution. In comparison with existing methods, our proposed method exhibits stable and reliable coverage at a nominal significance level and enjoys substantially less computational burden. Thus, our MOCE approach is trustworthy in solving real-world problems",
    "checked": true,
    "id": "80b779e72f97197692c9762d343090396d44c6e7",
    "semantic_title": "method of contraction-expansion (moce) for simultaneous inference in linear models",
    "citation_count": 2,
    "authors": [
      "Fei Wang",
      "Ling Zhou",
      "Lu Tang",
      "Peter X.K. Song"
    ]
  },
  "https://jmlr.org/papers/v22/19-835.html": {
    "title": "Sparse Popularity Adjusted Stochastic Block Model",
    "volume": "main",
    "abstract": "In the present paper we study a sparse stochastic network enabled with a block structure. The popular Stochastic Block Model (SBM) and the Degree Corrected Block Model (DCBM) address sparsity by placing an upper bound on the maximum probability of connections between any pair of nodes. As a result, sparsity describes only the behavior of network as a whole, without distinguishing between the block-dependent sparsity patterns. To the best of our knowledge, the recently introduced Popularity Adjusted Block Model (PABM) is the only block model that allows to introduce a structural sparsity where some probabilities of connections are identically equal to zero while the rest of them remain above a certain threshold. The latter presents a more nuanced view of the network",
    "checked": true,
    "id": "1d5924760f33672bf814321872ddd92f951673ab",
    "semantic_title": "sparse popularity adjusted stochastic block model",
    "citation_count": 5,
    "authors": [
      "Majid Noroozi",
      "Marianna Pensky",
      "Ramchandra Rimal"
    ]
  },
  "https://jmlr.org/papers/v22/19-852.html": {
    "title": "Limit theorems for out-of-sample extensions of the adjacency and Laplacian spectral embeddings",
    "volume": "main",
    "abstract": "Graph embeddings, a class of dimensionality reduction techniques designed for relational data, have proven useful in exploring and modeling network structure. Most dimensionality reduction methods allow out-of-sample extensions, by which an embedding can be applied to observations not present in the training set. Applied to graphs, the out-of-sample extension problem concerns how to compute the embedding of a vertex that is added to the graph after an embedding has already been computed. In this paper, we consider the out-of-sample extension problem for two graph embedding procedures: the adjacency spectral embedding and the Laplacian spectral embedding. In both cases, we prove that when the underlying graph is generated according to a latent space model called the random dot product graph, which includes the popular stochastic block model as a special case, an out-of-sample extension based on a least-squares objective obeys a central limit theorem. In addition, we prove a concentration inequality for the out-of-sample extension of the adjacency spectral embedding based on a maximum-likelihood objective. Our results also yield a convenient framework in which to analyze trade-offs between estimation accuracy and computational expenses, which we explore briefly. Finally, we explore the performance of these out-of-sample extensions as applied to both simulated and real-world data. We observe significant computational savings with minimal losses to the quality of the learned embeddings, in keeping with our theoretical results",
    "checked": true,
    "id": "761e66565bb80b8ba9599872c284b63326633810",
    "semantic_title": "limit theorems for out-of-sample extensions of the adjacency and laplacian spectral embeddings",
    "citation_count": 4,
    "authors": [
      "Keith D. Levin",
      "Fred Roosta",
      "Minh Tang",
      "Michael W. Mahoney",
      "Carey E. Priebe"
    ]
  },
  "https://jmlr.org/papers/v22/19-944.html": {
    "title": "Learning Laplacian Matrix from Graph Signals with Sparse Spectral Representation",
    "volume": "main",
    "abstract": "In this paper, we consider the problem of learning a graph structure from multivariate signals, known as graph signals. Such signals are multivariate observations carrying measurements corresponding to the nodes of an unknown graph, which we desire to infer. They are assumed to enjoy a sparse representation in the graph spectral domain, a feature which is known to carry information related to the cluster structure of a graph. The signals are also assumed to behave smoothly with respect to the underlying graph structure. For the graph learning problem, we propose a new optimization program to learn the Laplacian of this graph and provide two algorithms to solve it, called IGL-3SR and FGL-3SR. Based on a 3-step alternating procedure, both algorithms rely on standard minimization methods --such as manifold gradient descent or linear programming-- and have lower complexity compared to state-of-the-art algorithms. While IGL-3SR ensures convergence, FGL-3SR acts as a relaxation and is significantly faster since its alternating process relies on multiple closed-form solutions. Both algorithms are evaluated on synthetic and real data. They are shown to perform as good or better than their competitors in terms of both numerical performance and scalability. Finally, we present a probabilistic interpretation of the proposed optimization program as a Factor Analysis Model",
    "checked": true,
    "id": "af31f72a5f8a1555907715eaf0bb3aa8ca2362f4",
    "semantic_title": "learning laplacian matrix from graph signals with sparse spectral representation",
    "citation_count": 10,
    "authors": [
      "Pierre Humbert",
      "Batiste Le Bars",
      "Laurent Oudre",
      "Argyris Kalogeratos",
      "Nicolas Vayatis"
    ]
  },
  "https://jmlr.org/papers/v22/20-070.html": {
    "title": "COKE: Communication-Censored Decentralized Kernel Learning",
    "volume": "main",
    "abstract": "This paper studies the decentralized optimization and learning problem where multiple interconnected agents aim to learn an optimal decision function defined over a reproducing kernel Hilbert space by jointly minimizing a global objective function, with access to their own locally observed dataset. As a non-parametric approach, kernel learning faces a major challenge in distributed implementation: the decision variables of local objective functions are data-dependent and thus cannot be optimized under the decentralized consensus framework without any raw data exchange among agents. To circumvent this major challenge, we leverage the random feature (RF) approximation approach to enable consensus on the function modeled in the RF space by data-independent parameters across different agents. We then design an iterative algorithm, termed DKLA, for fast-convergent implementation via ADMM. Based on DKLA, we further develop a communication-censored kernel learning (COKE) algorithm that reduces the communication load of DKLA by preventing an agent from transmitting at every iteration unless its local updates are deemed informative. Theoretical results in terms of linear convergence guarantee and generalization performance analysis of DKLA and COKE are provided. Comprehensive tests on both synthetic and real datasets are conducted to verify the communication efficiency and learning effectiveness of COKE",
    "checked": true,
    "id": "634eeef8d5aad3ed95d78af2b899cb96b9c2d416",
    "semantic_title": "coke: communication-censored decentralized kernel learning",
    "citation_count": 10,
    "authors": [
      "Ping Xu",
      "Yue Wang",
      "Xiang Chen",
      "Zhi Tian"
    ]
  },
  "https://jmlr.org/papers/v22/20-082.html": {
    "title": "Particle-Gibbs Sampling for Bayesian Feature Allocation Models",
    "volume": "main",
    "abstract": "Bayesian feature allocation models are a popular tool for modelling data with a combinatorial latent structure. Exact inference in these models is generally intractable and so practitioners typically apply Markov Chain Monte Carlo (MCMC) methods for posterior inference. The most widely used MCMC strategies rely on a single variable Gibbs update of the feature allocation matrix. These updates can be inefficient as features are typically strongly correlated. To overcome this problem we have developed a block sampler that can update an entire row of the feature allocation matrix in a single move. In the context of feature allocation models, naive block Gibbs sampling is impractical for models with a large number of features as the computational complexity scales exponentially in the number of features. We develop a Particle Gibbs (PG) sampler that targets the same distribution as the row wise Gibbs updates, but has computational complexity that only grows linearly in the number of features. We compare the performance of our proposed methods to the standard Gibbs sampler using synthetic and real data from a range of feature allocation models. Our results suggest that row wise updates using the PG methodology can significantly improve the performance of samplers for feature allocation models",
    "checked": true,
    "id": "85184c7d71843ed92d362ff1271856bf983e5968",
    "semantic_title": "particle-gibbs sampling for bayesian feature allocation models",
    "citation_count": 0,
    "authors": [
      "Alexandre Bouchard-C√¥t√©",
      "Andrew Roth"
    ]
  },
  "https://jmlr.org/papers/v22/20-084.html": {
    "title": "Integrated Principal Components Analysis",
    "volume": "main",
    "abstract": "Data integration, or the strategic analysis of multiple sources of data simultaneously, can often lead to discoveries that may be hidden in individualistic analyses of a single data source. We develop a new unsupervised data integration method named Integrated Principal Components Analysis (iPCA), which is a model-based generalization of PCA and serves as a practical tool to find and visualize common patterns that occur in multiple data sets. The key idea driving iPCA is the matrix-variate normal model, whose Kronecker product covariance structure captures both individual patterns within each data set and joint patterns shared by multiple data sets. Building upon this model, we develop several penalized (sparse and non-sparse) covariance estimators for iPCA, and using geodesic convexity, we prove that our non-sparse iPCA estimator converges to the global solution of a non-convex problem. We also demonstrate the practical advantages of iPCA through extensive simulations and a case study application to integrative genomics for Alzheimer's disease. In particular, we show that the joint patterns extracted via iPCA are highly predictive of a patient's cognition and Alzheimer's diagnosis",
    "checked": true,
    "id": "04f1e69af1af9bf6c284d6f902f27fc692255ea2",
    "semantic_title": "integrated principal components analysis",
    "citation_count": 18,
    "authors": [
      "Tiffany M. Tang",
      "Genevera I. Allen"
    ]
  },
  "https://jmlr.org/papers/v22/20-1006.html": {
    "title": "On ADMM in Deep Learning: Convergence and Saturation-Avoidance",
    "volume": "main",
    "abstract": "In this paper, we develop an alternating direction method of multipliers (ADMM) for deep neural networks training with sigmoid-type activation functions (called sigmoid-ADMM pair), mainly motivated by the gradient-free nature of ADMM in avoiding the saturation of sigmoid-type activations and the advantages of deep neural networks with sigmoid-type activations (called deep sigmoid nets) over their rectified linear unit (ReLU) counterparts (called deep ReLU nets) in terms of approximation. In particular, we prove that the approximation capability of deep sigmoid nets is not worse than that of deep ReLU nets by showing that ReLU activation fucntion can be well approximated by deep sigmoid nets with two hidden layers and finitely many free parameters but not vice-verse. We also establish the global convergence of the proposed ADMM for the nonlinearly constrained formulation of the deep sigmoid nets training from arbitrary initial points to a Karush-Kuhn-Tucker (KKT) point at a rate of order O(1/k). Besides sigmoid activation, such a convergence theorem holds for a general class of smooth activations. Compared with the widely used stochastic gradient descent (SGD) algorithm for the deep ReLU nets training (called ReLU-SGD pair), the proposed sigmoid-ADMM pair is practically stable with respect to the algorithmic hyperparameters including the learning rate, initial schemes and the pro-processing of the input data. Moreover, we find that to approximate and learn simple but important functions the proposed sigmoid-ADMM pair numerically outperforms the ReLU-SGD pair",
    "checked": true,
    "id": "4ded1f561fde10d5c01b2e9a0250144325094e71",
    "semantic_title": "on admm in deep learning: convergence and saturation-avoidance",
    "citation_count": 14,
    "authors": [
      "Jinshan Zeng",
      "Shao-Bo Lin",
      "Yuan Yao",
      "Ding-Xuan Zhou"
    ]
  },
  "https://jmlr.org/papers/v22/20-1019.html": {
    "title": "Refined approachability algorithms and application to regret minimization with global costs",
    "volume": "main",
    "abstract": "Blackwell's approachability is a framework where two players, the Decision Maker and the Environment, play a repeated game with vector-valued payoffs. The goal of the Decision Maker is to make the average payoff converge to a given set called the target. When this is indeed possible, simple algorithms which guarantee the convergence are known. This abstract tool was successfully used for the construction of optimal strategies in various repeated games, but also found several applications in online learning. By extending an approach proposed by (Abernethy et al., 2011), we construct and analyze a class of Follow the Regularized Leader algorithms (FTRL) for Blackwell's approachability which are able to minimize not only the Euclidean distance to the target set (as it is often the case in the context of Blackwell's approachability) but a wide range of distance-like quantities. This flexibility enables us to apply these algorithms to closely minimize the quantity of interest in various online learning problems. In particular, for regret minimization with ‚Ñìp global costs, we obtain the first bounds with explicit dependence in p and the dimension d",
    "checked": true,
    "id": "a5f2ed4e2ca42a33587a5891c3821600eec48ec7",
    "semantic_title": "refined approachability algorithms and application to regret minimization with global costs",
    "citation_count": 2,
    "authors": [
      "Joon Kwon"
    ]
  },
  "https://jmlr.org/papers/v22/20-1061.html": {
    "title": "Understanding How Dimension Reduction Tools Work: An Empirical Approach to Deciphering t-SNE, UMAP, TriMap, and PaCMAP for Data Visualization",
    "volume": "main",
    "abstract": "Dimension reduction (DR) techniques such as t-SNE, UMAP, and TriMap have demonstrated impressive visualization performance on many real-world datasets. One tension that has always faced these methods is the trade-off between preservation of global structure and preservation of local structure: these methods can either handle one or the other, but not both. In this work, our main goal is to understand what aspects of DR methods are important for preserving both local and global structure: it is difficult to design a better method without a true understanding of the choices we make in our algorithms and their empirical impact on the low-dimensional embeddings they produce. Towards the goal of local structure preservation, we provide several useful design principles for DR loss functions based on our new understanding of the mechanisms behind successful DR methods. Towards the goal of global structure preservation, our analysis illuminates that the choice of which components to preserve is important. We leverage these insights to design a new algorithm for DR, called Pairwise Controlled Manifold Approximation Projection (PaCMAP), which preserves both local and global structure. Our work provides several unexpected insights into what design choices both to make and avoid when constructing DR algorithms",
    "checked": true,
    "id": "14475a5aafee6ee60d8592f6000f179f18edf29a",
    "semantic_title": "understanding how dimension reduction tools work: an empirical approach to deciphering t-sne, umap, trimap, and pacmap for data visualization",
    "citation_count": 155,
    "authors": [
      "Yingfan Wang",
      "Haiyang Huang",
      "Cynthia Rudin",
      "Yaron Shaposhnik"
    ]
  },
  "https://jmlr.org/papers/v22/20-1098.html": {
    "title": "Interpretable Deep Generative Recommendation Models",
    "volume": "main",
    "abstract": "User preference modeling in recommendation system aims to improve customer experience through discovering users' intrinsic preference based on prior user behavior data. This is a challenging issue because user preferences usually have complicated structure, such as inter-user preference similarity and intra-user preference diversity. Among them, inter-user similarity indicates different users may share similar preference, while intra-user diversity indicates one user may have several preferences. In literatures, deep generative models have been successfully applied in recommendation systems due to its flexibility on statistical distributions and strong ability for non-linear representation learning. However, they suffer from the simple generative process when handling complex user preferences. Meanwhile, the latent representations learned by deep generative models are usually entangled, and may range from observed-level ones that dominate the complex correlations between users, to latent-level ones that characterize a user's preference, which makes the deep model hard to explain and unfriendly for recommendation. Thus, in this paper, we propose an Interpretable Deep Generative Recommendation Model (InDGRM) to characterize inter-user preference similarity and intra-user preference diversity, which will simultaneously disentangle the learned representation from observed-level and latent-level. In InDGRM, the observed-level disentanglement on users is achieved by modeling the user-cluster structure (i.e., inter-user preference similarity) in a rich multimodal space, so that users with similar preferences are assigned into the same cluster. The observed-level disentanglement on items is achieved by modeling the intra-user preference diversity in a prototype learning strategy, where different user intentions are captured by item groups (one group refers to one intention). To promote disentangled latent representations, InDGRM adopts structure and sparsity-inducing penalty and integrates them into the generative procedure, which has ability to enforce each latent factor focus on a limited subset of items (e.g., one item group) and benefit latent-level disentanglement. Meanwhile, it can be efficiently inferred by minimizing its penalized upper bound with the aid of local variational optimization technique. Theoretically, we analyze the generalization error bound of InDGRM to guarantee its performance. A series of experimental results on four widely-used benchmark datasets demonstrates the superiority of InDGRM on recommendation performance and interpretability",
    "checked": true,
    "id": "5141d0822cd2e5c5e1b8b761fe31049d91ad65b1",
    "semantic_title": "interpretable deep generative recommendation models",
    "citation_count": 5,
    "authors": [
      "Huafeng Liu",
      "Liping Jing",
      "Jingxuan Wen",
      "Pengyu Xu",
      "Jiaqi Wang",
      "Jian Yu",
      "Michael K. Ng"
    ]
  },
  "https://jmlr.org/papers/v22/20-1137.html": {
    "title": "Learning partial correlation graphs and graphical models by covariance queries",
    "volume": "main",
    "abstract": "We study the problem of recovering the structure underlying large Gaussian graphical models or, more generally, partial correlation graphs. In high-dimensional problems it is often too costly to store the entire sample covariance matrix. We propose a new input model in which one can query single entries of the covariance matrix. We prove that it is possible to recover the support of the inverse covariance matrix with low query and computational complexity. Our algorithms work in a regime when this support is represented by tree-like graphs and, more generally, for graphs of small treewidth. Our results demonstrate that for large classes of graphs, the structure of the corresponding partial correlation graphs can be determined much faster than even computing the empirical covariance matrix",
    "checked": true,
    "id": "10232b999a471fa3d079539bc6b0d498ac735afb",
    "semantic_title": "learning partial correlation graphs and graphical models by covariance queries",
    "citation_count": 6,
    "authors": [
      "G√°bor Lugosi",
      "Jakub Truszkowski",
      "Vasiliki Velona",
      "Piotr Zwiernik"
    ]
  },
  "https://jmlr.org/papers/v22/20-1164.html": {
    "title": "Failures of Model-dependent Generalization Bounds for Least-norm Interpolation",
    "volume": "main",
    "abstract": "We consider bounds on the generalization performance of the least-norm linear regressor, in the over-parameterized regime where it can interpolate the data. We describe a sense in which any generalization bound of a type that is commonly proved in statistical learning theory must sometimes be very loose when applied to analyze the least-norm interpolant. In particular, for a variety of natural joint distributions on training examples, any valid generalization bound that depends only on the output of the learning algorithm, the number of training examples, and the confidence parameter, and that satisfies a mild condition (substantially weaker than monotonicity in sample size), must sometimes be very loose - it can be bounded below by a constant when the true excess risk goes to zero",
    "checked": true,
    "id": "3bd4d95de5aafc4b85ad48ca38cf5b90b9001902",
    "semantic_title": "failures of model-dependent generalization bounds for least-norm interpolation",
    "citation_count": 27,
    "authors": [
      "Peter L. Bartlett",
      "Philip M. Long"
    ]
  },
  "https://jmlr.org/papers/v22/20-1205.html": {
    "title": "Langevin Monte Carlo: random coordinate descent and variance reduction",
    "volume": "main",
    "abstract": "Langevin Monte Carlo (LMC) is a popular Bayesian sampling method. For the log-concave distribution function, the method converges exponentially fast, up to a controllable discretization error. However, the method requires the evaluation of a full gradient in each iteration, and for a problem on $\\mathbb{R}^d$, this amounts to $d$ times partial derivative evaluations per iteration. The cost is high when $d\\gg1$. In this paper, we investigate how to enhance computational efficiency through the application of RCD (random coordinate descent) on LMC. There are two sides of the theory: 1. By blindly applying RCD to LMC, one surrogates the full gradient by a randomly selected directional derivative per iteration. Although the cost is reduced per iteration, the total number of iteration is increased to achieve a preset error tolerance. Ultimately there is no computational gain; 2. We then incorporate variance reduction techniques, such as SAGA (stochastic average gradient) and SVRG (stochastic variance reduced gradient), into RCD-LMC. It will be proved that the cost is reduced compared with the classical LMC, and in the underdamped case, convergence is achieved with the same number of iterations, while each iteration requires merely one-directional derivative. This means we obtain the best possible computational cost in the underdamped-LMC framework",
    "checked": true,
    "id": "3126eadd70ef9a9e97baf1b07e31177d501c291b",
    "semantic_title": "langevin monte carlo: random coordinate descent and variance reduction",
    "citation_count": 5,
    "authors": [
      "Zhiyan Ding",
      "Qin Li"
    ]
  },
  "https://jmlr.org/papers/v22/20-1235.html": {
    "title": "Hamilton-Jacobi Deep Q-Learning for Deterministic Continuous-Time Systems with Lipschitz Continuous Controls",
    "volume": "main",
    "abstract": "In this paper, we propose Q-learning algorithms for continuous-time deterministic optimal control problems with Lipschitz continuous controls. A new class of Hamilton-Jacobi-Bellman (HJB) equations is derived from applying the dynamic programming principle to continuous-time Q-functions. Our method is based on a novel semi-discrete version of the HJB equation, which is proposed to design a Q-learning algorithm that uses data collected in discrete time without discretizing or approximating the system dynamics. We identify the conditions under which the Q-function estimated by this algorithm converges to the optimal Q-function. For practical implementation, we propose the Hamilton-Jacobi DQN, which extends the idea of deep Q-networks (DQN) to our continuous control setting. This approach does not require actor networks or numerical solutions to optimization problems for greedy actions since the HJB equation provides a simple characterization of optimal controls via ordinary differential equations. We empirically demonstrate the performance of our method through benchmark tasks and high-dimensional linear-quadratic problems",
    "checked": true,
    "id": "acb6445cd840e1b724c384f90556f3321ea31969",
    "semantic_title": "hamilton-jacobi deep q-learning for deterministic continuous-time systems with lipschitz continuous controls",
    "citation_count": 18,
    "authors": [
      "Jeongho Kim",
      "Jaeuk Shin",
      "Insoon Yang"
    ]
  },
  "https://jmlr.org/papers/v22/20-1238.html": {
    "title": "A Unified Convergence Analysis for Shuffling-Type Gradient Methods",
    "volume": "main",
    "abstract": "In this paper, we propose a unified convergence analysis for a class of generic shuffling-type gradient methods for solving finite-sum optimization problems. Our analysis works with any sampling without replacement strategy and covers many known variants such as randomized reshuffling, deterministic or randomized single permutation, and cyclic and incremental gradient schemes. We focus on two different settings: strongly convex and nonconvex problems, but also discuss the non-strongly convex case. Our main contribution consists of new non-asymptotic and asymptotic convergence rates for a wide class of shuffling-type gradient methods in both nonconvex and convex settings. We also study uniformly randomized shuffling variants with different learning rates and model assumptions. While our rate in the nonconvex case is new and significantly improved over existing works under standard assumptions, the rate on the strongly convex one matches the existing best-known rates prior to this paper up to a constant factor without imposing a bounded gradient condition. Finally, we empirically illustrate our theoretical results via two numerical examples: nonconvex logistic regression and neural network training examples. As byproducts, our results suggest some appropriate choices for diminishing learning rates in certain shuffling variants",
    "checked": true,
    "id": "248d7f8d410ac1dae5afe54bba7a67bc2e394bea",
    "semantic_title": "a unified convergence analysis for shuffling-type gradient methods",
    "citation_count": 55,
    "authors": [
      "Lam M. Nguyen",
      "Quoc Tran-Dinh",
      "Dzung T. Phan",
      "Phuong Ha Nguyen",
      "Marten van Dijk"
    ]
  },
  "https://jmlr.org/papers/v22/20-1311.html": {
    "title": "Oblivious Data for Fairness with Kernels",
    "volume": "main",
    "abstract": "We investigate the problem of algorithmic fairness in the case where sensitive and non-sensitive features are available and one aims to generate new, `oblivious', features that closely approximate the non-sensitive features, and are only minimally dependent on the sensitive ones. We study this question in the context of kernel methods. We analyze a relaxed version of the Maximum Mean Discrepancy criterion which does not guarantee full independence but makes the optimization problem tractable. We derive a closed-form solution for this relaxed optimization problem and complement the result with a study of the dependencies between the newly generated features and the sensitive ones. Our key ingredient for generating such oblivious features is a Hilbert-space-valued conditional expectation, which needs to be estimated from data. We propose a plug-in approach and demonstrate how the estimation errors can be controlled. While our techniques help reduce the bias, we would like to point out that no post-processing of any dataset could possibly serve as an alternative to well-designed experiments",
    "checked": true,
    "id": "748d909fce0e8514f5a0d1f7b0a0ca1018c4ae65",
    "semantic_title": "oblivious data for fairness with kernels",
    "citation_count": 5,
    "authors": [
      "Steffen Gr√ºnew√§lder",
      "Azadeh Khaleghi"
    ]
  },
  "https://jmlr.org/papers/v22/20-1316.html": {
    "title": "Explaining by Removing: A Unified Framework for Model Explanation",
    "volume": "main",
    "abstract": "Researchers have proposed a wide variety of model explanation approaches, but it remains unclear how most methods are related or when one method is preferable to another. We describe a new unified class of methods, removal-based explanations, that are based on the principle of simulating feature removal to quantify each feature's influence. These methods vary in several respects, so we develop a framework that characterizes each method along three dimensions: 1) how the method removes features, 2) what model behavior the method explains, and 3) how the method summarizes each feature's influence. Our framework unifies 26 existing methods, including several of the most widely used approaches: SHAP, LIME, Meaningful Perturbations, and permutation tests. This newly understood class of explanation methods has rich connections that we examine using tools that have been largely overlooked by the explainability literature. To anchor removal-based explanations in cognitive psychology, we show that feature removal is a simple application of subtractive counterfactual reasoning. Ideas from cooperative game theory shed light on the relationships and trade-offs among different methods, and we derive conditions under which all removal-based explanations have information-theoretic interpretations. Through this analysis, we develop a unified framework that helps practitioners better understand model explanation tools, and that offers a strong theoretical foundation upon which future explainability research can build",
    "checked": true,
    "id": "c3871d9f7039a118a14a3a115d52f3326efa6992",
    "semantic_title": "explaining by removing: a unified framework for model explanation",
    "citation_count": 161,
    "authors": [
      "Ian Covert",
      "Scott Lundberg",
      "Su-In Lee"
    ]
  },
  "https://jmlr.org/papers/v22/20-1329.html": {
    "title": "Policy Teaching in Reinforcement Learning via Environment Poisoning Attacks",
    "volume": "main",
    "abstract": "We study a security threat to reinforcement learning where an attacker poisons the learning environment to force the agent into executing a target policy chosen by the attacker. As a victim, we consider RL agents whose objective is to find a policy that maximizes reward in infinite-horizon problem settings. The attacker can manipulate the rewards and the transition dynamics in the learning environment at training-time, and is interested in doing so in a stealthy manner. We propose an optimization framework for finding an optimal stealthy attack for different measures of attack cost. We provide lower/upper bounds on the attack cost, and instantiate our attacks in two settings: (i) an offline setting where the agent is doing planning in the poisoned environment, and (ii) an online setting where the agent is learning a policy with poisoned feedback. Our results show that the attacker can easily succeed in teaching any target policy to the victim under mild conditions and highlight a significant security threat to reinforcement learning agents in practice",
    "checked": true,
    "id": "3cbf5c0e2e0c14607128c6512803d0624ab0a359",
    "semantic_title": "policy teaching in reinforcement learning via environment poisoning attacks",
    "citation_count": 21,
    "authors": [
      "Amin Rakhsha",
      "Goran Radanovic",
      "Rati Devidze",
      "Xiaojin Zhu",
      "Adish Singla"
    ]
  },
  "https://jmlr.org/papers/v22/20-1429.html": {
    "title": "Bandit Learning in Decentralized Matching Markets",
    "volume": "main",
    "abstract": "We study two-sided matching markets in which one side of the market (the players) does not have a priori knowledge about its preferences for the other side (the arms) and is required to learn its preferences from experience. Also, we assume the players have no direct means of communication. This model extends the standard stochastic multi-armed bandit framework to a decentralized multiple player setting with competition. We introduce a new algorithm for this setting that, over a time horizon $T$, attains $\\mathcal{O}(\\log(T))$ stable regret when preferences of the arms over players are shared, and $\\mathcal{O}(\\log(T)^2)$ regret when there are no assumptions on the preferences on either side. Moreover, in the setting where a single player may deviate, we show that the algorithm is incentive-compatible whenever the arms' preferences are shared, but not necessarily so when preferences are fully general",
    "checked": true,
    "id": "11c9ce906d43928b6c67c5263a4d340dd1332787",
    "semantic_title": "bandit learning in decentralized matching markets",
    "citation_count": 39,
    "authors": [
      "Lydia T. Liu",
      "Feng Ruan",
      "Horia Mania",
      "Michael I. Jordan"
    ]
  },
  "https://jmlr.org/papers/v22/20-1447.html": {
    "title": "Convex Geometry and Duality of Over-parameterized Neural Networks",
    "volume": "main",
    "abstract": "We develop a convex analytic approach to analyze finite width two-layer ReLU networks. We first prove that an optimal solution to the regularized training problem can be characterized as extreme points of a convex set, where simple solutions are encouraged via its convex geometrical properties. We then leverage this characterization to show that an optimal set of parameters yield linear spline interpolation for regression problems involving one dimensional or rank-one data. We also characterize the classification decision regions in terms of a kernel matrix and minimum $\\ell_1$-norm solutions. This is in contrast to Neural Tangent Kernel which is unable to explain predictions of finite width networks. Our convex geometric characterization also provides intuitive explanations of hidden neurons as auto-encoders. In higher dimensions, we show that the training problem can be cast as a finite dimensional convex problem with infinitely many constraints. Then, we apply certain convex relaxations and introduce a cutting-plane algorithm to globally optimize the network. We further analyze the exactness of the relaxations to provide conditions for the convergence to a global optimum. Our analysis also shows that optimal network parameters can be also characterized as interpretable closed-form formulas in some practically relevant special cases",
    "checked": true,
    "id": "fd9517a8d258dfb91a9b07141485f7cdfd38fa6b",
    "semantic_title": "convex geometry and duality of over-parameterized neural networks",
    "citation_count": 50,
    "authors": [
      "Tolga Ergen",
      "Mert Pilanci"
    ]
  },
  "https://jmlr.org/papers/v22/20-147.html": {
    "title": "Cooperative SGD: A Unified Framework for the Design and Analysis of Local-Update SGD Algorithms",
    "volume": "main",
    "abstract": "When training machine learning models using stochastic gradient descent (SGD) with a large number of nodes or massive edge devices, the communication cost of synchronizing gradients at every iteration is a key bottleneck that limits the scalability of the system and hinders the benefit of parallel computation. Local-update SGD algorithms, where worker nodes perform local iterations of SGD and periodically synchronize their local models, can effectively reduce the communication frequency and save the communication delay. In this paper, we propose a powerful framework, named Cooperative SGD, that subsumes a variety of local-update SGD algorithms (such as local SGD, elastic averaging SGD, and decentralized parallel SGD) and provides a unified convergence analysis. Notably, special cases of the unified convergence analysis provided by the cooperative SGD framework yield 1) the first convergence analysis of elastic averaging SGD for general non-convex objectives, and 2) improvements upon previous analyses of local SGD and decentralized parallel SGD. Moreover, we design new algorithms such as elastic averaging SGD with overlapped computation and communication, and decentralized periodic averaging which are shown to be 4x or more faster than the baseline in reaching the same training loss",
    "checked": true,
    "id": "167530160d46955035172f1b90ed2a94d6e13f72",
    "semantic_title": "cooperative sgd: a unified framework for the design and analysis of local-update sgd algorithms",
    "citation_count": 114,
    "authors": [
      "Jianyu Wang",
      "Gauri Joshi"
    ]
  },
  "https://jmlr.org/papers/v22/20-1473.html": {
    "title": "dalex: Responsible Machine Learning with Interactive Explainability and Fairness in Python",
    "volume": "MLOSS",
    "abstract": "In modern machine learning, we observe the phenomenon of opaqueness debt, which manifests itself by an increased risk of discrimination, lack of reproducibility, and deflated performance due to data drift. An increasing amount of available data and computing power results in the growing complexity of black-box predictive models. To manage these issues, good MLOps practice asks for better validation of model performance and fairness, higher explainability, and continuous monitoring. The necessity for deeper model transparency comes from both scientific and social domains and is also caused by emerging laws and regulations on artificial intelligence. To facilitate the responsible development of machine learning models, we introduce dalex, a Python package which implements a model-agnostic interface for interactive explainability and fairness. It adopts the design crafted through the development of various tools for explainable machine learning; thus, it aims at the unification of existing solutions. This library's source code and documentation are available under open license at https://python.drwhy.ai",
    "checked": true,
    "id": "033f5eb9b4e2c8a95702f7ac49f5c0912188c7a1",
    "semantic_title": "dalex: responsible machine learning with interactive explainability and fairness in python",
    "citation_count": 57,
    "authors": [
      "Hubert Baniecki",
      "Wojciech Kretowicz",
      "Piotr PiƒÖtyszek",
      "Jakub Wi≈õniewski",
      "Przemys≈Çaw Biecek"
    ]
  },
  "https://jmlr.org/papers/v22/20-225.html": {
    "title": "TensorHive: Management of Exclusive GPU Access for Distributed Machine Learning Workloads",
    "volume": "MLOSS",
    "abstract": "TensorHive is a tool for organizing work of research and engineering teams that use servers with GPUs for machine learning workloads. In a comprehensive web interface, it supports reservation of GPUs for exclusive usage, hardware monitoring, as well as configuring, executing and queuing distributed computational jobs. Focusing on easy installation and simple configuration, the tool automatically detects the available computing resources and monitors their utilization. Reservations granted on the basis of flexible access control settings are protected by pluggable violation hooks. The job execution module includes auto-configuration templates for distributed neural network training jobs in frameworks such as TensorFlow and PyTorch. Documentation, source code, usage examples and issue tracking are available at the project page: https://github.com/roscisz/TensorHive/",
    "checked": true,
    "id": "a0816035466bd17473cd9e7a818d40da5bb632a4",
    "semantic_title": "tensorhive: management of exclusive gpu access for distributed machine learning workloads",
    "citation_count": 0,
    "authors": [
      "Pawe≈Ç Ro≈õciszewski",
      "Micha≈Ç Martyniak",
      "Filip Schodowski"
    ]
  },
  "https://jmlr.org/papers/v22/20-244.html": {
    "title": "Context-dependent Networks in Multivariate Time Series: Models, Methods, and Risk Bounds in High Dimensions",
    "volume": "main",
    "abstract": "High-dimensional autoregressive generalized linear models arise naturally for capturing how current events trigger or inhibit future events, such as activity by one member of a social network can affect the future activities of his or her neighbors. While past work has focused on estimating the underlying network structure based solely on the times at which events occur on each node of the network, this paper examines the more nuanced problem of estimating context-dependent networks that reflect how features associated with an event (such as the content of a social media post) modulate the strength of influences among nodes. Specifically, we leverage ideas from compositional time series and regularization methods in machine learning to conduct context-dependent network estimation for high-dimensional autoregressive time series of annotated event data. Two models and corresponding estimators are considered in detail: an autoregressive multinomial model suited to categorical features and a logistic-normal model suited to features with mixed membership in different categories. Importantly, the logistic-normal model leads to a convex negative log-likelihood objective and captures dependence across categories. We provide theoretical guarantees for both estimators that are supported by simulations. We further validate our methods and demonstrate the advantages and disadvantages of both approaches through two real data examples and a synthetic data-generating model. Finally, a mixture approach enjoying both approaches' merits is proposed and illustrated on synthetic and real data examples",
    "checked": true,
    "id": "a0826df6771f586c7ea34e4de6cd144eae1dfb96",
    "semantic_title": "context-dependent networks in multivariate time series: models, methods, and risk bounds in high dimensions",
    "citation_count": 0,
    "authors": [
      "Lili Zheng",
      "Garvesh Raskutti",
      "Rebecca Willett",
      "Benjamin Mark"
    ]
  },
  "https://jmlr.org/papers/v22/20-261.html": {
    "title": "A Unified Framework for Spectral Clustering in Sparse Graphs",
    "volume": "main",
    "abstract": "This article considers spectral community detection in the regime of sparse networks with heterogeneous degree distributions, for which we devise an algorithm to efficiently retrieve communities. Specifically, we demonstrate that a well parametrized form of regularized Laplacian matrices can be used to perform spectral clustering in sparse networks without suffering from its degree heterogeneity. Besides, we exhibit important connections between this proposed matrix and the now popular non-backtracking matrix, the Bethe-Hessian matrix, as well as the standard Laplacian matrix. Interestingly, as opposed to competitive methods, our proposed improved parametrization inherently accounts for the hardness of the classification problem. These findings are summarized under the form of an algorithm capable of both estimating the number of communities and achieving high-quality community reconstruction",
    "checked": true,
    "id": "b69bcb50918370a3a11070284dd82b79700e7ddb",
    "semantic_title": "a unified framework for spectral clustering in sparse graphs",
    "citation_count": 12,
    "authors": [
      "Lorenzo Dall'Amico",
      "Romain Couillet",
      "Nicolas Tremblay"
    ]
  },
  "https://jmlr.org/papers/v22/20-447.html": {
    "title": "Thompson Sampling Algorithms for Cascading Bandits",
    "volume": "main",
    "abstract": "Motivated by the important and urgent need for efficient optimization in online recommender systems, we revisit the cascading bandit model proposed by Kveton et al. (2015a). While Thompson sampling (TS) algorithms have been shown to be empirically superior to Upper Confidence Bound (UCB) algorithms for cascading bandits, theoretical guarantees are only known for the latter. In this paper, we first provide a problem-dependent upper bound on the regret of a TS algorithm with Beta-Bernoulli updates; this upper bound is tighter than a recent derivation under a more general setting by Huyuk and Tekin (2019). Next, we design and analyze another TS algorithm with Gaussian updates, TS-Cascade. TS-Cascade achieves the state-of-the-art problem-independent regret bound for cascading bandits. Complementarily, we consider a linear generalization of the cascading bandit model, which allows efficient learning in large-scale cascading bandit problem instances. We introduce and analyze a TS algorithm, which enjoys a regret bound that depends on the dimension of the linear model but not the number of items. Finally, by using information-theoretic techniques and a judicious construction of cascading bandit instances, we derive a nearly-matching lower bound on the expected regret for the standard model. Our paper establishes the first theoretical guarantees on TS algorithms for a stochastic combinatorial bandit problem model with partial feedback. Numerical experiments demonstrate the superiority of the proposed TS algorithms compared to existing UCB-based ones",
    "checked": true,
    "id": "aac98c575b1d103acf93cbb748adc6abc1b0928a",
    "semantic_title": "thompson sampling algorithms for cascading bandits",
    "citation_count": 9,
    "authors": [
      "Zixin Zhong",
      "Wang Chi Chueng",
      "Vincent Y. F. Tan"
    ]
  },
  "https://jmlr.org/papers/v22/20-476.html": {
    "title": "Soft Tensor Regression",
    "volume": "main",
    "abstract": "Statistical methods relating tensor predictors to scalar outcomes in a regression model generally vectorize the tensor predictor and estimate the coefficients of its entries employing some form of regularization, use summaries of the tensor covariate, or use a low dimensional approximation of the coefficient tensor. However, low rank approximations of the coefficient tensor can suffer if the true rank is not small. We propose a tensor regression framework which assumes a soft version of the parallel factors (PARAFAC) approximation. In contrast to classic PARAFAC where each entry of the coefficient tensor is the sum of products of row-specific contributions across the tensor modes, the soft tensor regression (Softer) framework allows the row-specific contributions to vary around an overall mean. We follow a Bayesian approach to inference, and show that softening the PARAFAC increases model flexibility, leads to improved estimation of coefficient tensors, more accurate identification of important predictor entries, and more precise predictions, even for a low approximation rank. From a theoretical perspective, we show that employing Softer leads to a weakly consistent posterior distribution of the coefficient tensor, irrespective of the true or approximation tensor rank, a result that is not true when employing the classic PARAFAC for tensor regression. In the context of our motivating application, we adapt Softer to symmetric and semi-symmetric tensor predictors and analyze the relationship between brain network characteristics and human traits",
    "checked": true,
    "id": "d3e90bb4493a58ed0e050aa262a870f42fe79926",
    "semantic_title": "soft tensor regression",
    "citation_count": 6,
    "authors": [
      "Georgia Papadogeorgou",
      "Zhengwu Zhang",
      "David B. Dunson"
    ]
  },
  "https://jmlr.org/papers/v22/20-513.html": {
    "title": "Shape-Enforcing Operators for Generic Point and Interval Estimators of Functions",
    "volume": "main",
    "abstract": "A common problem in econometrics, statistics, and machine learning is to estimate and make inference on functions that satisfy shape restrictions. For example, distribution functions are nondecreasing and range between zero and one, height growth charts are nondecreasing in age, and production functions are nondecreasing and quasi-concave in input quantities. We propose a method to enforce these restrictions ex post on generic unconstrained point and interval estimates of the target function by applying functional operators. The interval estimates could be either frequentist confidence bands or Bayesian credible regions. If an operator has reshaping, invariance, order-preserving, and distance-reducing properties, the shape-enforced point estimates are closer to the target function than the original point estimates and the shape-enforced interval estimates have greater coverage and shorter length than the original interval estimates. We show that these properties hold for six different operators that cover commonly used shape restrictions in practice: range, convexity, monotonicity, monotone convexity, quasi-convexity, and monotone quasi-convexity, with the latter two restrictions being of paramount importance. The main attractive property of the post-processing approach is that it works in conjunction with any generic initial point or interval estimate, obtained using any of parametric, semi-parametric or nonparametric learning methods, including recent methods that are able to exploit either smoothness, sparsity, or other forms of structured parsimony of target functions. The post-processed point and interval estimates automatically inherit and provably improve these properties in finite samples, while also enforcing qualitative shape restrictions brought by scientific reasoning. We illustrate the results with two empirical applications to the estimation of a height growth chart for infants in India and a production function for chemical firms in China",
    "checked": true,
    "id": "35a5766d63c528130b1b0501aba24d3c21903b33",
    "semantic_title": "shape-enforcing operators for generic point and interval estimators of functions",
    "citation_count": 2,
    "authors": [
      "Xi Chen",
      "Victor Chernozhukov",
      "Ivan Fernandez-Val",
      "Scott Kostyshak",
      "Ye Luo"
    ]
  },
  "https://jmlr.org/papers/v22/20-567.html": {
    "title": "A Bayes-Optimal View on Adversarial Examples",
    "volume": "main",
    "abstract": "Since the discovery of adversarial examples - the ability to fool modern CNN classifiers with tiny perturbations of the input, there has been much discussion whether they are a \"bug\" that is specific to current neural architectures and training methods or an inevitable \"feature\" of high dimensional geometry. In this paper, we argue for examining adversarial examples from the perspective of Bayes-Optimal classification. We construct realistic image datasets for which the Bayes-Optimal classifier can be efficiently computed and derive analytic conditions on the distributions under which these classifiers are provably robust against any adversarial attack even in high dimensions. Our results show that even when these \"gold standard\" optimal classifiers are robust, CNNs trained on the same datasets consistently learn a vulnerable classifier, indicating that adversarial examples are often an avoidable \"bug\". We further show that RBF SVMs trained on the same data consistently learn a robust classifier. The same trend is observed in experiments with real images in different datasets",
    "checked": true,
    "id": "1af7dbc1c458ab9bc53ccd432dba56103a46edf2",
    "semantic_title": "a bayes-optimal view on adversarial examples",
    "citation_count": 11,
    "authors": [
      "Eitan Richardson",
      "Yair Weiss"
    ]
  },
  "https://jmlr.org/papers/v22/20-603.html": {
    "title": "Classification vs regression in overparameterized regimes: Does the loss function matter?",
    "volume": "main",
    "abstract": "We compare classification and regression tasks in an overparameterized linear model with Gaussian features. On the one hand, we show that with sufficient overparameterization all training points are support vectors: solutions obtained by least-squares minimum-norm interpolation, typically used for regression, are identical to those produced by the hard-margin support vector machine (SVM) that minimizes the hinge loss, typically used for training classifiers. On the other hand, we show that there exist regimes where these interpolating solutions generalize well when evaluated by the 0-1 test loss function, but do not generalize if evaluated by the square loss function, i.e. they approach the null risk. Our results demonstrate the very different roles and properties of loss functions used at the training phase (optimization) and the testing phase (generalization)",
    "checked": true,
    "id": "cd95817a31d7d991d5b861de81843e7d35f5584b",
    "semantic_title": "classification vs regression in overparameterized regimes: does the loss function matter?",
    "citation_count": 117,
    "authors": [
      "Vidya Muthukumar",
      "Adhyyan Narang",
      "Vignesh Subramanian",
      "Mikhail Belkin",
      "Daniel Hsu",
      "Anant Sahai"
    ]
  },
  "https://jmlr.org/papers/v22/20-618.html": {
    "title": "Stochastic Online Optimization using Kalman Recursion",
    "volume": "main",
    "abstract": "We study the Extended Kalman Filter in constant dynamics, offering a bayesian perspective of stochastic optimization. For generalized linear models, we obtain high probability bounds on the cumulative excess risk in an unconstrained setting, under the assumption that the algorithm reaches a local phase. In order to avoid any projection step we propose a two-phase analysis. First, for linear and logistic regressions, we prove that the algorithm enters a local phase where the estimate stays in a small region around the optimum. We provide explicit bounds with high probability on this convergence time, slightly modifying the Extended Kalman Filter in the logistic setting. Second, for generalized linear regressions, we provide a martingale analysis of the excess risk in the local phase, improving existing ones in bounded stochastic optimization. The algorithm appears as a parameter-free online procedure that optimally solves some unconstrained optimization problems",
    "checked": true,
    "id": "cfe373d89fe9ab88db055a8f792ecbc332a1910c",
    "semantic_title": "stochastic online optimization using kalman recursion",
    "citation_count": 6,
    "authors": [
      "Joseph de Vilmarest",
      "Olivier Wintenberger"
    ]
  },
  "https://jmlr.org/papers/v22/20-688.html": {
    "title": "Bayesian Distance Clustering",
    "volume": "main",
    "abstract": "Model-based clustering is widely used in a variety of application areas. However, fundamental concerns remain about robustness. In particular, results can be sensitive to the choice of kernel representing the within-cluster data density. Leveraging on properties of pairwise differences between data points, we propose a class of Bayesian distance clustering methods, which rely on modeling the likelihood of the pairwise distances in place of the original data. Although some information in the data is discarded, we gain substantial robustness to modeling assumptions. The proposed approach represents an appealing middle ground between distance- and model-based clustering, drawing advantages from each of these canonical approaches. We illustrate dramatic gains in the ability to infer clusters that are not well represented by the usual choices of kernel. A simulation study is included to assess performance relative to competitors, and we apply the approach to clustering of brain genome expression data",
    "checked": true,
    "id": "0fe4f443d3650b005636b4acee6c86379f4647a2",
    "semantic_title": "bayesian distance clustering",
    "citation_count": 14,
    "authors": [
      "Leo L. Duan",
      "David B. Dunson"
    ]
  },
  "https://jmlr.org/papers/v22/20-751.html": {
    "title": "Representer Theorems in Banach Spaces: Minimum Norm Interpolation, Regularized Learning and Semi-Discrete Inverse Problems",
    "volume": "main",
    "abstract": "Learning a function from a finite number of sampled data points (measurements) is a fundamental problem in science and engineering. This is often formulated as a minimum norm interpolation (MNI) problem, a regularized learning problem or, in general, a semi-discrete inverse problem (SDIP), in either Hilbert spaces or Banach spaces. The goal of this paper is to systematically study solutions of these problems in Banach spaces. We aim at obtaining explicit representer theorems for their solutions, on which convenient solution methods can then be developed. For the MNI problem, the explicit representer theorems enable us to express the infimum in terms of the norm of the linear combination of the interpolation functionals. For the purpose of developing efficient computational algorithms, we establish the fixed-point equation formulation of solutions of these problems. We reveal that unlike in a Hilbert space, in general, solutions of these problems in a Banach space may not be able to be reduced to truly finite dimensional problems (with certain infinite dimensional components hidden). We demonstrate how this obstacle can be removed, reducing the original problem to a truly finite dimensional one, in the special case when the Banach space is $\\ell_1(\\mathbb{N})$",
    "checked": true,
    "id": "ef5d5aee80a2129720336ff62297d25055b94544",
    "semantic_title": "representer theorems in banach spaces: minimum norm interpolation, regularized learning and semi-discrete inverse problems",
    "citation_count": 7,
    "authors": [
      "Rui Wang",
      "Yuesheng Xu"
    ]
  },
  "https://jmlr.org/papers/v22/20-815.html": {
    "title": "FATE: An Industrial Grade Platform for Collaborative Learning With Data Protection",
    "volume": "MLOSS",
    "abstract": "Collaborative and federated learning has become an emerging solution to many industrial applications where data values from different sites are exploit jointly with privacy protection. We introduce FATE, an industrial-grade project that supports enterprises and institutions to build machine learning models collaboratively at large-scale in a distributed manner. FATE supports a variety of secure computation protocols and machine learning algorithms, and features out-of-box usability with end-to-end building modules and visualization tools. Documentations are available at https://github.com/FederatedAI/FATE. Case studies and other information are available at https://www.fedai.org",
    "checked": true,
    "id": "3d73e21af71bde8dc7984bd72f7077fb691b2523",
    "semantic_title": "fate: an industrial grade platform for collaborative learning with data protection",
    "citation_count": 101,
    "authors": [
      "Yang Liu",
      "Tao Fan",
      "Tianjian Chen",
      "Qian Xu",
      "Qiang Yang"
    ]
  },
  "https://jmlr.org/papers/v22/20-879.html": {
    "title": "Tighter Risk Certificates for Neural Networks",
    "volume": "main",
    "abstract": "This paper presents an empirical study regarding training probabilistic neural networks using training objectives derived from PAC-Bayes bounds. In the context of probabilistic neural networks, the output of training is a probability distribution over network weights. We present two training objectives, used here for the first time in connection with training neural networks. These two training objectives are derived from tight PAC-Bayes bounds. We also re-implement a previously used training objective based on a classical PAC-Bayes bound, to compare the properties of the predictors learned using the different training objectives. We compute risk certificates for the learnt predictors, based on part of the data used to learn the predictors. We further experiment with different types of priors on the weights (both data-free and data-dependent priors) and neural network architectures. Our experiments on MNIST and CIFAR-10 show that our training methods produce competitive test set errors and non-vacuous risk bounds with much tighter values than previous results in the literature, showing promise not only to guide the learning algorithm through bounding the risk but also for model selection. These observations suggest that the methods studied here might be good candidates for self-certified learning, in the sense of using the whole data set for learning a predictor and certifying its risk on any unseen data (from the same distribution as the training data) potentially without the need for holding out test data",
    "checked": true,
    "id": "4a2a3ecaab200750a3717283ded3ba64381390ee",
    "semantic_title": "tighter risk certificates for neural networks",
    "citation_count": 75,
    "authors": [
      "Mar√≠a P√©rez-Ortiz",
      "Omar Rivasplata",
      "John Shawe-Taylor",
      "Csaba Szepesv√°ri"
    ]
  },
  "https://jmlr.org/papers/v22/20-911.html": {
    "title": "How Well Generative Adversarial Networks Learn Distributions",
    "volume": "main",
    "abstract": "This paper studies the rates of convergence for learning distributions implicitly with the adversarial framework and Generative Adversarial Networks (GANs), which subsume Wasserstein, Sobolev, MMD GAN, and Generalized/Simulated Method of Moments (GMM/SMM) as special cases. We study a wide range of parametric and nonparametric target distributions under a host of objective evaluation metrics. We investigate how to obtain valid statistical guarantees for GANs through the lens of regularization. On the nonparametric end, we derive the optimal minimax rates for distribution estimation under the adversarial framework. On the parametric end, we establish a theory for general neural network classes (including deep leaky ReLU networks) that characterizes the interplay on the choice of generator and discriminator pair. We discover and isolate a new notion of regularization, called the generator-discriminator-pair regularization, that sheds light on the advantage of GANs compared to classical parametric and nonparametric approaches for explicit distribution estimation. We develop novel oracle inequalities as the main technical tools for analyzing GANs, which are of independent interest",
    "checked": true,
    "id": "e3d2518c02485dd3c8cc84e9bd671f9ed5f48c4f",
    "semantic_title": "how well generative adversarial networks learn distributions",
    "citation_count": 66,
    "authors": [
      "Tengyuan Liang"
    ]
  },
  "https://jmlr.org/papers/v22/21-0019.html": {
    "title": "Convolutional Neural Networks Are Not Invariant to Translation, but They Can Learn to Be",
    "volume": "main",
    "abstract": "When seeing a new object, humans can immediately recognize it across different retinal locations: the internal object representation is invariant to translation. It is commonly believed that Convolutional Neural Networks (CNNs) are architecturally invariant to translation thanks to the convolution and/or pooling operations they are endowed with. In fact, several studies have found that these networks systematically fail to recognise new objects on untrained locations. In this work, we test a wide variety of CNNs architectures showing how, apart from DenseNet-121, none of the models tested was architecturally invariant to translation. Nevertheless, all of them could learn to be invariant to translation. We show how this can be achieved by pretraining on ImageNet, and it is sometimes possible with much simpler data sets when all the items are fully translated across the input canvas. At the same time, this invariance can be disrupted by further training due to catastrophic forgetting/interference. These experiments show how pretraining a network on an environment with the right 'latent' characteristics (a more naturalistic environment) can result in the network learning deep perceptual rules which would dramatically improve subsequent generalization",
    "checked": true,
    "id": "bd7fa03b870dedafa18d18f4549fcb9c4251697e",
    "semantic_title": "convolutional neural networks are not invariant to translation, but they can learn to be",
    "citation_count": 15,
    "authors": [
      "Valerio Biscione",
      "Jeffrey S. Bowers"
    ]
  },
  "https://jmlr.org/papers/v22/21-0021.html": {
    "title": "Learning with semi-definite programming: statistical bounds based on fixed point analysis and excess risk curvature",
    "volume": "main",
    "abstract": "Many statistical learning problems have recently been shown to be amenable to Semi-Definite Programming (SDP), with community detection and clustering in Gaussian mixture models as the most striking instances Javanmard et al. (2016). Given the growing range of applications of SDP-based techniques to machine learning problems, and the rapid progress in the design of efficient algorithms for solving SDPs, an intriguing question is to understand how the recent advances from empirical process theory and Statistical Learning Theory can be leveraged for providing a precise statistical analysis of SDP estimators. In the present paper, we borrow cutting edge techniques and concepts from the Learning Theory literature, such as fixed point equations and excess risk curvature arguments, which yield general estimation and prediction results for a wide class of SDP estimators. From this perspective, we revisit some classical results in community detection from Gu√©don and Vershynin (2016) and Fei and Chen (2019), and we obtain statistical guarantees for SDP estimators used in signed clustering, angular group synchronization (for both multiplicative and additive models) and MAX-CUT. Our theoretical findings are complemented by numerical experiments for each of the three problems considered, showcasing the competitiveness of the SDP estimators",
    "checked": true,
    "id": "c45d5a2a99886a3074ed062845ddf57fd22e23ab",
    "semantic_title": "learning with semi-definite programming: statistical bounds based on fixed point analysis and excess risk curvature",
    "citation_count": 4,
    "authors": [
      "St√©phane Chr√©tien",
      "Mihai Cucuringu",
      "Guillaume Lecu√©",
      "Lucie Neirac"
    ]
  },
  "https://jmlr.org/papers/v22/21-0029.html": {
    "title": "sklvq: Scikit Learning Vector Quantization",
    "volume": "MLOSS",
    "abstract": "The sklvq package is an open-source Python implementation of a set of learning vector quantization (LVQ) algorithms. In addition to providing the core functionality for the GLVQ, GMLVQ, and LGMLVQ algorithms, sklvq is distinctive by putting emphasis on its modular and customizable design. Not only resulting in a feature-rich implementation for users but enabling easy extensions of the algorithms for researchers. The theory behind this design is described in this paper. To facilitate adoptions and inspire future contributions, sklvq is publicly available on Github (under the BSD license) and can be installed through the Python package index (PyPI). Next to being well-covered by automated testing to ensure code quality, it is accompanied by detailed online documentation. The documentation covers usage examples and provides an in-depth API including theory and scientific references",
    "checked": true,
    "id": "d265bcd6919efe87ebaffc57f719720331391a32",
    "semantic_title": "sklvq: scikit learning vector quantization",
    "citation_count": 6,
    "authors": [
      "Rick van Veen",
      "Michael Biehl",
      "Gert-Jan de Vries"
    ]
  },
  "https://jmlr.org/papers/v22/21-0031.html": {
    "title": "Probabilistic Iterative Methods for Linear Systems",
    "volume": "main",
    "abstract": "This paper presents a probabilistic perspective on iterative methods for approximating the solution $\\mathbf{x} \\in \\mathbb{R}^d$ of a nonsingular linear system $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$. Classically, an iterative method produces a sequence $\\mathbf{x}_m$ of approximations that converge to $\\mathbf{x}$ in $\\mathbb{R}^d$. Our approach, instead, lifts a standard iterative method to act on the set of probability distributions, $\\mathcal{P}(\\mathbb{R}^d)$, outputting a sequence of probability distributions $\\mu_m \\in \\mathcal{P}(\\mathbb{R}^d)$. The output of a probabilistic iterative method can provide both a \"best guess\" for $\\mathbf{x}$, for example by taking the mean of $\\mu_m$, and also probabilistic uncertainty quantification for the value of $\\mathbf{x}$ when it has not been exactly determined. A comprehensive theoretical treatment is presented in the case of a stationary linear iterative method, where we characterise both the rate of contraction of $\\mu_m$ to an atomic measure on $\\mathbf{x}$ and the nature of the uncertainty quantification being provided. We conclude with an empirical illustration that highlights the potential for probabilistic iterative methods to provide insight into solution uncertainty",
    "checked": true,
    "id": "0329b849a1911517b0f5724fce76a90ff2a7b859",
    "semantic_title": "probabilistic iterative methods for linear systems",
    "citation_count": 7,
    "authors": [
      "Jon Cockayne",
      "Ilse C.F. Ipsen",
      "Chris J. Oates",
      "Tim W. Reid"
    ]
  },
  "https://jmlr.org/papers/v22/21-0037.html": {
    "title": "A Generalised Linear Model Framework for Œ≤-Variational Autoencoders based on Exponential Dispersion Families",
    "volume": "main",
    "abstract": "Although variational autoencoders (VAE) are successfully used to obtain meaningful low-dimensional representations for high-dimensional data, the characterization of critical points of the loss function for general observation models is not fully understood. We introduce a theoretical framework that is based on a connection between Œ≤-VAE and generalized linear models (GLM). The equality between the activation function of a Œ≤-VAE and the inverse of the link function of a GLM enables us to provide a systematic generalization of the loss analysis for Œ≤-VAE based on the assumption that the observation model distribution belongs to an exponential dispersion family (EDF). As a result, we can initialize Œ≤-VAE nets by maximum likelihood estimates (MLE) that enhance the training performance on both synthetic and real world data sets. As a further consequence, we analytically describe the auto-pruning property inherent in the Œ≤-VAE objective and reason for posterior collapse",
    "checked": true,
    "id": "6496297e48f0367d2d431dce6e0c5b6f0529414a",
    "semantic_title": "a generalised linear model framework for variational autoencoders based on exponential dispersion families",
    "citation_count": 9,
    "authors": [
      "Robert Sicks",
      "Ralf Korn",
      "Stefanie Schwaar"
    ]
  },
  "https://jmlr.org/papers/v22/21-0072.html": {
    "title": "A general linear-time inference method for Gaussian Processes on one dimension",
    "volume": "main",
    "abstract": "Gaussian Processes (GPs) provide powerful probabilistic frameworks for interpolation, forecasting, and smoothing, but have been hampered by computational scaling issues. Here we investigate data sampled on one dimension (e.g., a scalar or vector time series sampled at arbitrarily-spaced intervals), for which state-space models are popular due to their linearly-scaling computational costs. It has long been conjectured that state-space models are general, able to approximate any one-dimensional GP. We provide the first general proof of this conjecture, showing that any stationary GP on one dimension with vector-valued observations governed by a Lebesgue-integrable continuous kernel can be approximated to any desired precision using a specifically-chosen statespace model: the Latent Exponentially Generated (LEG) family. This new family offers several advantages compared to the general state-space model: it is always stable (no unbounded growth), the covariance can be computed in closed form, and its parameter space is unconstrained (allowing straightforward estimation via gradient descent). The theorem's proof also draws connections to Spectral Mixture Kernels, providing insight about this popular family of kernels. We develop parallelized algorithms for performing inference and learning in the LEG model, test the algorithm on real and synthetic data, and demonstrate scaling to datasets with billions of samples",
    "checked": true,
    "id": "bede99a33904742db2abe4f3b93cae70f4fdbe91",
    "semantic_title": "a general linear-time inference method for gaussian processes on one dimension",
    "citation_count": 4,
    "authors": [
      "Jackson Loper",
      "David Blei",
      "John P. Cunningham",
      "Liam Paninski"
    ]
  },
  "https://jmlr.org/papers/v22/21-0120.html": {
    "title": "GIBBON: General-purpose Information-Based Bayesian Optimisation",
    "volume": "main",
    "abstract": "This paper describes a general-purpose extension of max-value entropy search, a popular approach for Bayesian Optimisation (BO). A novel approximation is proposed for the information gain -- an information-theoretic quantity central to solving a range of BO problems, including noisy, multi-fidelity and batch optimisations across both continuous and highly-structured discrete spaces. Previously, these problems have been tackled separately within information-theoretic BO, each requiring a different sophisticated approximation scheme, except for batch BO, for which no computationally-lightweight information-theoretic approach has previously been proposed. GIBBON (General-purpose Information-Based Bayesian OptimisatioN) provides a single principled framework suitable for all the above, out-performing existing approaches whilst incurring substantially lower computational overheads. In addition, GIBBON does not require the problem's search space to be Euclidean and so is the first high-performance yet computationally light-weight acquisition function that supports batch BO over general highly structured input spaces like molecular search and gene design. Moreover, our principled derivation of GIBBON yields a natural interpretation of a popular batch BO heuristic based on determinantal point processes. Finally, we analyse GIBBON across a suite of synthetic benchmark tasks, a molecular search loop, and as part of a challenging batch multi-fidelity framework for problems with controllable experimental noise",
    "checked": true,
    "id": "7c91b7e847dce9444f4c37530a85e941dd87140c",
    "semantic_title": "gibbon: general-purpose information-based bayesian optimisation",
    "citation_count": 31,
    "authors": [
      "Henry B. Moss",
      "David S. Leslie",
      "Javier Gonzalez",
      "Paul Rayson"
    ]
  },
  "https://jmlr.org/papers/v22/21-0179.html": {
    "title": "Expanding Boundaries of Gap Safe Screening",
    "volume": "main",
    "abstract": "Sparse optimization problems are ubiquitous in many fields such as statistics, signal/image processing and machine learning. This has led to the birth of many iterative algorithms to solve them. A powerful strategy to boost the performance of these algorithms is known as safe screening: it allows the early identification of zero coordinates in the solution, which can then be eliminated to reduce the problem's size and accelerate convergence. In this work, we extend the existing Gap Safe screening framework by relaxing the global strong-concavity assumption on the dual cost function. Instead, we exploit local regularity properties, that is, strong concavity on well-chosen subsets of the domain. The non-negativity constraint is also integrated to the existing framework. Besides making safe screening possible to a broader class of functions that includes $\\beta$-divergences (e.g., the Kullback-Leibler divergence), the proposed approach also improves upon the existing Gap Safe screening rules on previously applicable cases (e.g., logistic regression). The proposed general framework is exemplified by some notable particular cases: logistic function, $\\beta=1.5$ and Kullback-Leibler divergences. Finally, we showcase the effectiveness of the proposed screening rules with different solvers (coordinate descent, multiplicative-update and proximal gradient algorithms) and different datasets (binary classification, hyperspectral and count data)",
    "checked": true,
    "id": "f558d06be42a25c91049caaf6568b5c68872f246",
    "semantic_title": "expanding boundaries of gap safe screening",
    "citation_count": 10,
    "authors": [
      "Cassio F. Dantas",
      "Emmanuel Soubies",
      "C√©dric F√©votte"
    ]
  },
  "https://jmlr.org/papers/v22/21-0259.html": {
    "title": "Consensus-Based Optimization on the Sphere: Convergence to Global Minimizers and Machine Learning",
    "volume": "main",
    "abstract": "We investigate the implementation of a new stochastic Kuramoto-Vicsek-type model for global optimization of nonconvex functions on the sphere. This model belongs to the class of Consensus-Based Optimization. In fact, particles move on the sphere driven by a drift towards an instantaneous consensus point, which is computed as a convex combination of particle locations, weighted by the cost function according to Laplace's principle, and it represents an approximation to a global minimizer. The dynamics is further perturbed by a random vector field to favor exploration, whose variance is a function of the distance of the particles to the consensus point. In particular, as soon as the consensus is reached the stochastic component vanishes. The main results of this paper are about the proof of convergence of the numerical scheme to global minimizers provided conditions of well-preparation of the initial datum. The proof combines previous results of mean-field limit with a novel asymptotic analysis, and classical convergence results of numerical methods for SDE. We present several numerical experiments, which show that the algorithm proposed in the present paper scales well with the dimension and is extremely versatile. To quantify the performances of the new approach, we show that the algorithm is able to perform essentially as good as ad hoc state of the art methods in challenging problems in signal processing and machine learning, namely the phase retrieval problem and the robust subspace detection",
    "checked": true,
    "id": "0b3a9113f2ce54c931fd038576cd34087685adff",
    "semantic_title": "consensus-based optimization on the sphere ii: convergence to global minimizers and machine learning",
    "citation_count": 44,
    "authors": [
      "Massimo Fornasier",
      "Lorenzo Pareschi",
      "Hui Huang",
      "Philippe S√ºnnen"
    ]
  },
  "https://jmlr.org/papers/v22/21-0298.html": {
    "title": "DeEPCA: Decentralized Exact PCA with Linear Convergence Rate",
    "volume": "main",
    "abstract": "Due to the rapid growth of smart agents such as weakly connected computational nodes and sensors, developing decentralized algorithms that can perform computations on local agents becomes a major research direction. This paper considers the problem of decentralized principal components analysis (PCA), which is a statistical method widely used for data analysis. We introduce a technique called subspace tracking to reduce the communication cost, and apply it to power iterations. This leads to a decentralized PCA algorithm called DeEPCA, which has a convergence rate similar to that of the centralized PCA, while achieving the best communication complexity among existing decentralized PCA algorithms. DeEPCA is the first decentralized PCA algorithm with the number of communication rounds for each power iteration independent of target precision. Compared to existing algorithms, the proposed method is easier to tune in practice, with an improved overall communication cost. Our experiments validate the advantages of DeEPCA empirically",
    "checked": true,
    "id": "51046803d620c905431e70cff2a5667f283acaef",
    "semantic_title": "deepca: decentralized exact pca with linear convergence rate",
    "citation_count": 17,
    "authors": [
      "Haishan Ye",
      "Tong Zhang"
    ]
  },
  "https://jmlr.org/papers/v22/21-0307.html": {
    "title": "Decentralized Stochastic Gradient Langevin Dynamics and Hamiltonian Monte Carlo",
    "volume": "main",
    "abstract": "Stochastic gradient Langevin dynamics (SGLD) and stochastic gradient Hamiltonian Monte Carlo (SGHMC) are two popular Markov Chain Monte Carlo (MCMC) algorithms for Bayesian inference that can scale to large datasets, allowing to sample from the posterior distribution of the parameters of a statistical model given the input data and the prior distribution over the model parameters. However, these algorithms do not apply to the decentralized learning setting, when a network of agents are working collaboratively to learn the parameters of a statistical model without sharing their individual data due to privacy reasons or communication constraints. We study two algorithms: Decentralized SGLD (DE-SGLD) and Decentralized SGHMC (DE-SGHMC) which are adaptations of SGLD and SGHMC methods that allow scaleable Bayesian inference in the decentralized setting for large datasets. We show that when the posterior distribution is strongly log-concave and smooth, the iterates of these algorithms converge linearly to a neighborhood of the target distribution in the 2-Wasserstein distance if their parameters are selected appropriately. We illustrate the efficiency of our algorithms on decentralized Bayesian linear regression and Bayesian logistic regression problems",
    "checked": true,
    "id": "08cae5e27fec687159b468ad204bcced001b0805",
    "semantic_title": "decentralized stochastic gradient langevin dynamics and hamiltonian monte carlo",
    "citation_count": 16,
    "authors": [
      "Mert G√ºrb√ºzbalaban",
      "Xuefeng Gao",
      "Yuanhan Hu",
      "Lingjiong Zhu"
    ]
  },
  "https://jmlr.org/papers/v22/21-0343.html": {
    "title": "DIG: A Turnkey Library for Diving into Graph Deep Learning Research",
    "volume": "MLOSS",
    "abstract": "Although there exist several libraries for deep learning on graphs, they are aiming at implementing basic operations for graph deep learning. In the research community, implementing and benchmarking various advanced tasks are still painful and time-consuming with existing libraries. To facilitate graph deep learning research, we introduce DIG: Dive into Graphs, a turnkey library that provides a unified testbed for higher level, research-oriented graph deep learning tasks. Currently, we consider graph generation, self-supervised learning on graphs, explainability of graph neural networks, and deep learning on 3D graphs. For each direction, we provide unified implementations of data interfaces, common algorithms, and evaluation metrics. Altogether, DIG is an extensible, open-source, and turnkey library for researchers to develop new methods and effortlessly compare with common baselines using widely used datasets and evaluation metrics. Source code is available at https://github.com/divelab/DIG",
    "checked": true,
    "id": "323ca85c5c1ebd0ec9bf74897d8c8e8fbf203ae6",
    "semantic_title": "dig: a turnkey library for diving into graph deep learning research",
    "citation_count": 86,
    "authors": [
      "Meng Liu",
      "Youzhi Luo",
      "Limei Wang",
      "Yaochen Xie",
      "Hao Yuan",
      "Shurui Gui",
      "Haiyang Yu",
      "Zhao Xu",
      "Jingtun Zhang",
      "Yi Liu",
      "Keqiang Yan",
      "Haoran Liu",
      "Cong Fu",
      "Bora M Oztekin",
      "Xuan Zhang",
      "Shuiwang Ji"
    ]
  },
  "https://jmlr.org/papers/v22/21-0366.html": {
    "title": "Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks",
    "volume": "main",
    "abstract": "The growing energy and performance costs of deep learning have driven the community to reduce the size of neural networks by selectively pruning components. Similarly to their biological counterparts, sparse networks generalize just as well, sometimes even better than, the original dense networks. Sparsity promises to reduce the memory footprint of regular networks to fit mobile devices, as well as shorten training time for ever growing networks. In this paper, we survey prior work on sparsity in deep learning and provide an extensive tutorial of sparsification for both inference and training. We describe approaches to remove and add elements of neural networks, different training strategies to achieve model sparsity, and mechanisms to exploit sparsity in practice. Our work distills ideas from more than 300 research papers and provides guidance to practitioners who wish to utilize sparsity today, as well as to researchers whose goal is to push the frontier forward. We include the necessary background on mathematical methods in sparsification, describe phenomena such as early structure adaptation, the intricate relations between sparsity and the training process, and show techniques for achieving acceleration on real hardware. We also define a metric of pruned parameter efficiency that could serve as a baseline for comparison of different sparse networks. We close by speculating on how sparsity can improve future workloads and outline major open problems in the field",
    "checked": true,
    "id": "9d6acac70b2d1fdb861a08b00766ef263109cd7f",
    "semantic_title": "sparsity in deep learning: pruning and growth for efficient inference and training in neural networks",
    "citation_count": 396,
    "authors": [
      "Torsten Hoefler",
      "Dan Alistarh",
      "Tal Ben-Nun",
      "Nikoli Dryden",
      "Alexandra Peste"
    ]
  },
  "https://jmlr.org/papers/v22/21-0453.html": {
    "title": "Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations",
    "volume": "main",
    "abstract": "We present a framework that allows for the non-asymptotic study of the $2$-Wasserstein distance between the invariant distribution of an ergodic stochastic differential equation and the distribution of its numerical approximation in the strongly log-concave case. This allows us to study in a unified way a number of different integrators proposed in the literature for the overdamped and underdamped Langevin dynamics. In addition, we analyze a novel splitting method for the underdamped Langevin dynamics which only requires one gradient evaluation per time step. Under an additional smoothness assumption on a $d$--dimensional strongly log-concave distribution with condition number $\\kappa$, the algorithm is shown to produce with an $\\mathcal{O}\\big(\\kappa^{5/4} d^{1/4}\\epsilon^{-1/2} \\big)$ complexity samples from a distribution that, in Wasserstein distance, is at most $\\epsilon>0$ away from the target distribution",
    "checked": true,
    "id": "ec3a77370185ad4ee8eaa7ec5f8d93eca02766b5",
    "semantic_title": "wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations",
    "citation_count": 14,
    "authors": [
      "Jesus Maria Sanz-Serna",
      "Konstantinos C. Zygalakis"
    ]
  },
  "https://jmlr.org/papers/v22/21-0498.html": {
    "title": "Quasi-Monte Carlo Quasi-Newton in Variational Bayes",
    "volume": "main",
    "abstract": "Many machine learning problems optimize an objective that must be measured with noise. The primary method is a first order stochastic gradient descent using one or more Monte Carlo (MC) samples at each step. There are settings where ill-conditioning makes second order methods such as limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) more effective. We study the use of randomized quasi-Monte Carlo (RQMC) sampling for such problems. When MC sampling has a root mean squared error (RMSE) of $O(n^{-1/2})$ then RQMC has an RMSE of $o(n^{-1/2})$ that can be close to $O(n^{-3/2})$ in favorable settings. We prove that improved sampling accuracy translates directly to improved optimization. In our empirical investigations for variational Bayes, using RQMC with stochastic quasi-Newton method greatly speeds up the optimization, and sometimes finds a better parameter value than MC does",
    "checked": true,
    "id": "21d88d5b0b6df43b26e8ccf2ad0c8702712d2c69",
    "semantic_title": "quasi-newton quasi-monte carlo for variational bayes",
    "citation_count": 7,
    "authors": [
      "Sifan Liu",
      "Art B. Owen"
    ]
  },
  "https://jmlr.org/papers/v22/21-0853.html": {
    "title": "Consistency of Gaussian Process Regression in Metric Spaces",
    "volume": "main",
    "abstract": "Gaussian process (GP) regressors are used in a wide variety of regression tasks, and many recent applications feature domains that are non-Euclidean manifolds or other metric spaces. In this paper, we examine formal consistency of GP regression on general metric spaces. Specifically, we consider a GP prior on an unknown real-valued function with a metric domain space and examine consistency of the resulting posterior distribution. If the kernel is continuous and the sequence of sampling points lies sufficiently dense, then the variance of the posterior GP is shown to converge to zero almost surely monotonically and in $L^p$ for all $p > 1$, uniformly on compact sets. Moreover, we prove that if the difference between the observed function and the mean function of the prior lies in the reproducing kernel Hilbert space of the prior's kernel, then the posterior mean converges pointwise in $L^2$ to the unknown function, and, under an additional assumption on the kernel, uniformly on compacts in $L^1$. This paper provides an important step towards the theoretical legitimization of GP regression on manifolds and other non-Euclidean metric spaces",
    "checked": true,
    "id": "b63e57cf92ad3462a6d445a2096b560191d9bd23",
    "semantic_title": "consistency of gaussian process regression in metric spaces",
    "citation_count": 11,
    "authors": [
      "Peter Koepernik",
      "Florian Pfaff"
    ]
  },
  "https://jmlr.org/papers/v22/18-485.html": {
    "title": "On lp-hyperparameter Learning via Bilevel Nonsmooth Optimization",
    "volume": "main",
    "abstract": "We propose a bilevel optimization strategy for selecting the best hyperparameter value for the nonsmooth $\\ell_p$ regularizer with $0",
    "checked": true,
    "id": "3104b7ea1c51fcdee466eb9e7bd6f8cfc571c249",
    "semantic_title": "on lp-hyperparameter learning via bilevel nonsmooth optimization",
    "citation_count": 15,
    "authors": [
      "Takayuki Okuno",
      "Akiko Takeda",
      "Akihiro Kawana",
      "Motokazu Watanabe"
    ]
  },
  "https://jmlr.org/papers/v22/18-798.html": {
    "title": "Mixture Martingales Revisited with Applications to Sequential Tests and Confidence Intervals",
    "volume": "main",
    "abstract": "This paper presents new deviation inequalities that are valid uniformly in time under adaptive sampling in a multi-armed bandit model. The deviations are measured using the Kullback-Leibler divergence in a given one-dimensional exponential family, and take into account multiple arms at a time. They are obtained by constructing for each arm a mixture martingale based on a hierarchical prior, and by multiplying those martingales. Our deviation inequalities allow us to analyze stopping rules based on generalized likelihood ratios for a large class of sequential identification problems. We establish asymptotic optimality of sequential tests generalising the track-and-stop method to problems beyond best arm identification. We further derive sharper stopping thresholds, where the number of arms is replaced by the newly introduced pure exploration problem rank. We construct tight confidence intervals for linear functions and minima/maxima of the vector of arm means",
    "checked": true,
    "id": "db622407a839649760405a342046b930ce297335",
    "semantic_title": "mixture martingales revisited with applications to sequential tests and confidence intervals",
    "citation_count": 85,
    "authors": [
      "Emilie Kaufmann",
      "Wouter M. Koolen"
    ]
  },
  "https://jmlr.org/papers/v22/19-1016.html": {
    "title": "Statistical Guarantees for Local Spectral Clustering on Random Neighborhood Graphs",
    "volume": "main",
    "abstract": "We study the Personalized PageRank (PPR) algorithm, a local spectral method for clustering, which extracts clusters using locally-biased random walks around a given seed node. In contrast to previous work, we adopt a classical statistical learning setup, where we obtain samples from an unknown nonparametric distribution, and aim to identify sufficiently salient clusters. We introduce a trio of population-level functionals---the normalized cut, conductance, and local spread, analogous to graph-based functionals of the same name---and prove that PPR, run on a neighborhood graph, recovers clusters with small population normalized cut and large conductance and local spread. We apply our general theory to establish that PPR identifies connected regions of high density (density clusters) that satisfy a set of natural geometric conditions. We also show a converse result, that PPR can fail to recover geometrically poorly-conditioned density clusters, even asymptotically. Finally, we provide empirical support for our theory",
    "checked": true,
    "id": "ae22b6438ba3ff488038d6f8cd9938c0722755a1",
    "semantic_title": "statistical guarantees for local spectral clustering on random neighborhood graphs",
    "citation_count": 0,
    "authors": [
      "Alden Green",
      "Sivaraman Balakrishnan",
      "Ryan J. Tibshirani"
    ]
  },
  "https://jmlr.org/papers/v22/19-531.html": {
    "title": "Statistically and Computationally Efficient Change Point Localization in Regression Settings",
    "volume": "main",
    "abstract": "Detecting when the underlying distribution changes for the observed time series is a fundamental problem arising in a broad spectrum of applications. In this paper, we study multiple change-point localization in the high-dimensional regression setting, which is particularly challenging as no direct observations of the parameter of interest is available. Specifically, we assume we observe $\\{ x_t, y_t\\}_{t=1}^n$ where $ \\{ x_t\\}_{t=1}^n $ are $p$-dimensional covariates, $\\{y_t\\}_{t=1}^n$ are the univariate responses satisfying $\\mathbb{E}(y_t) = x_t^\\top \\beta_t^* \\text{ for } 1\\le t \\le n $ and $\\{\\beta_t^*\\}_{t=1}^n $ are the unobserved regression coefficients that change over time in a piecewise constant manner. We propose a novel projection-based algorithm, Variance Projected Wild Binary Segmentation~(VPWBS), which transforms the original (difficult) problem of change-point detection in $p$-dimensional regression to a simpler problem of change-point detection in mean of a one-dimensional time series. VPWBS is shown to achieve sharp localization rate $O_p(1/n)$ up to a log factor, a significant improvement from the best rate $O_p(1/\\sqrt{n})$ known in the existing literature for multiple change-point localization in high-dimensional regression. Extensive numerical experiments are conducted to demonstrate the robust and favorable performance of VPWBS over two state-of-the-art algorithms, especially when the size of change in the regression coefficients $\\{\\beta_t^*\\}_{t=1}^n $ is small",
    "checked": true,
    "id": "397b240fa7f3e7ce7204d8ec094189678e8c265b",
    "semantic_title": "statistically and computationally efficient change point localization in regression settings",
    "citation_count": 1,
    "authors": [
      "Daren Wang",
      "Zifeng Zhao",
      "Kevin Z. Lin",
      "Rebecca Willett"
    ]
  },
  "https://jmlr.org/papers/v22/20-033.html": {
    "title": "On the Riemannian Search for Eigenvector Computation",
    "volume": "main",
    "abstract": "Eigenvector computation is central to numerical algebra and often critical to many data analysis tasks nowadays. Most research on this problem has been focusing on projection methods like power iterations, such that this category of algorithms can achieve both optimal convergence rates and cheap per-iteration costs. In contrast, search methods belonging to another main category are less understood in this respect. In this work, we consider the leading eigenvector computation as a non-convex optimization problem on the (generalized) Stiefel manifold and covers the cases for both standard and generalized eigenvectors. It is shown that the inexact Riemannian gradient method induced by the shift-and-invert preconditioning is guaranteed to converge to one of the ground-truth eigenvectors at an optimal rate, e.g., $O(\\sqrt{\\kappa_{\\mathbf{B}}\\frac{\\lambda_{1}}{\\lambda_{1}-\\lambda_{p+1}}}\\log\\frac{1}{\\epsilon})$ for a pair of real symmetric matrices $(\\mathbf{A},\\mathbf{B})$ with $\\mathbf{B}$ being positive definite, where $\\lambda_{i}$ represents the $i$-th largest generalized eigenvalue of the matrix pair, $p$ is the multiplicity of $\\lambda_{1}$, and $\\kappa_{\\mathbf{B}}$ stands for the condition number of $\\mathbf{B}$. The standard eigenvector computation is recovered by setting $\\mathbf{B}$ to an identity matrix. Our analysis reduces the dependence on the eigengap, making it the first Riemannian eigensolver that achieves the optimal rate. Experiments demonstrate that the proposed search method is able to deliver significantly better performance than projection methods by taking advantages of step-size schemes",
    "checked": true,
    "id": "e3c26364ca9691de47da24371e879afaef20cf6a",
    "semantic_title": "on the riemannian search for eigenvector computation",
    "citation_count": 4,
    "authors": [
      "Zhiqiang Xu",
      "Ping Li"
    ]
  },
  "https://jmlr.org/papers/v22/20-048.html": {
    "title": "Bayesian time-aligned factor analysis of paired multivariate time series",
    "volume": "main",
    "abstract": "Many modern data sets require inference methods that can estimate the shared and individual-specific components of variability in collections of matrices that change over time. Promising methods have been developed to analyze these types of data in static cases, but only a few approaches are available for dynamic settings. To address this gap, we consider novel models and inference methods for pairs of matrices in which the columns correspond to multivariate observations at different time points. In order to characterize common and individual features, we propose a Bayesian dynamic factor modeling framework called Time Aligned Common and Individual Factor Analysis (TACIFA) that includes uncertainty in time alignment through an unknown warping function. We provide theoretical support for the proposed model, showing identifiability and posterior concentration. The structure enables efficient computation through a Hamiltonian Monte Carlo (HMC) algorithm. We show excellent performance in simulations, and illustrate the method through application to a social mimicry experiment",
    "checked": true,
    "id": "9b1f469280b1b8bd78bdf01e370cdd92eb73b48f",
    "semantic_title": "bayesian time-aligned factor analysis of paired multivariate time series",
    "citation_count": 4,
    "authors": [
      "Arkaprava Roy",
      "Jana Schaich Borg",
      "David B Dunson"
    ]
  },
  "https://jmlr.org/papers/v22/20-1009.html": {
    "title": "Tractable Approximate Gaussian Inference for Bayesian Neural Networks",
    "volume": "main",
    "abstract": "In this paper, we propose an analytical method for performing tractable approximate Gaussian inference (TAGI) in Bayesian neural networks. The method enables the analytical Gaussian inference of the posterior mean vector and diagonal covariance matrix for weights and biases. The method proposed has a computational complexity of $\\mathcal{O}(n)$ with respect to the number of parameters $n$, and the tests performed on regression and classification benchmarks confirm that, for a same network architecture, it matches the performance of existing methods relying on gradient backpropagation",
    "checked": true,
    "id": "53a25fb1acd0f21bc8a4c20dbe467cfe89e7d944",
    "semantic_title": "tractable approximate gaussian inference for bayesian neural networks",
    "citation_count": 8,
    "authors": [
      "James-A. Goulet",
      "Luong Ha Nguyen",
      "Saeid Amiri"
    ]
  },
  "https://jmlr.org/papers/v22/20-1023.html": {
    "title": "Batch greedy maximization of non-submodular functions: Guarantees and applications to experimental design",
    "volume": "main",
    "abstract": "We propose and analyze batch greedy heuristics for cardinality constrained maximization of non-submodular non-decreasing set functions. We consider the standard greedy paradigm, along with its distributed greedy and stochastic greedy variants. Our theoretical guarantees are characterized by the combination of submodularity and supermodularity ratios. We argue how these parameters define tight modular bounds based on incremental gains, and provide a novel reinterpretation of the classical greedy algorithm using the minorize-maximize (MM) principle. Based on that analogy, we propose a new class of methods exploiting any plausible modular bound. In the context of optimal experimental design for linear Bayesian inverse problems, we bound the submodularity and supermodularity ratios when the underlying objective is based on mutual information. We also develop novel modular bounds for the mutual information in this setting, and describe certain connections to polyhedral combinatorics. We discuss how algorithms using these modular bounds relate to established statistical notions such as leverage scores and to more recent efforts such as volume sampling. We demonstrate our theoretical findings on synthetic problems and on a real-world climate monitoring example",
    "checked": true,
    "id": "269a8af8454145763aa8e04e42e64f814a0e4cb8",
    "semantic_title": "batch greedy maximization of non-submodular functions: guarantees and applications to experimental design",
    "citation_count": 17,
    "authors": [
      "Jayanth Jagalur-Mohan",
      "Youssef Marzouk"
    ]
  },
  "https://jmlr.org/papers/v22/20-1031.html": {
    "title": "Bifurcation Spiking Neural Network",
    "volume": "main",
    "abstract": "Spiking neural networks (SNNs) have attracted much attention due to their great potential for modeling time-dependent signals. The performance of SNNs depends not only on picking an apposite architecture and searching optimal connection weights as well as conventional deep neural networks, but also on the careful tuning of many hyper-parameters within fundamental spiking neural models. However, so far, there has been less systematic work on analyzing SNNs' dynamical characteristics, especially ones relative to these internal hyper-parameters, which leads to whether SNNs are adequate for modeling actual data relies on fortune. In this work, we provide a theoretical framework for investigating spiking neural models from the perspective of dynamical systems. As a result, we point out that the LIF model with control rate hyper-parameters is a bifurcation dynamical system. This point explains why the performance of SNNs is so sensitive to the setting of control rate hyper-parameters, leading to a recommendation that diverse and adaptive eigenvalues are beneficial to improve the performance of SNNs. Inspired by this insight, we develop the Bifurcation Spiking Neural Network (BSNN) with supervised implementation, and theoretically show that BSNN is an adaptive dynamical system. Experiments validate the effectiveness of BSNN on several benchmark data sets, showing that BSNN achieves superior performance to existing SNNs and is robust to the setting of control rates",
    "checked": true,
    "id": "022f35370fad08ca449f93080ea27b1e91a6db91",
    "semantic_title": "bifurcation spiking neural network",
    "citation_count": 6,
    "authors": [
      "Shao-Qun Zhang",
      "Zhao-Yu Zhang",
      "Zhi-Hua Zhou"
    ]
  },
  "https://jmlr.org/papers/v22/20-1050.html": {
    "title": "Inference for the Case Probability in High-dimensional Logistic Regression",
    "volume": "main",
    "abstract": "Labeling patients in electronic health records with respect to their statuses of having a disease or condition, i.e. case or control statuses, has increasingly relied on prediction models using high-dimensional variables derived from structured and unstructured electronic health record data. A major hurdle currently is a lack of valid statistical inference methods for the case probability. In this paper, considering high-dimensional sparse logistic regression models for prediction, we propose a novel bias-corrected estimator for the case probability through the development of linearization and variance enhancement techniques. We establish asymptotic normality of the proposed estimator for any loading vector in high dimensions. We construct a confidence interval for the case probability and propose a hypothesis testing procedure for patient case-control labelling. We demonstrate the proposed method via extensive simulation studies and application to real-world electronic health record data",
    "checked": true,
    "id": "111796639a8294bb05ff743aede674b2b7dfe443",
    "semantic_title": "inference for the case probability in high-dimensional logistic regression",
    "citation_count": 14,
    "authors": [
      "Zijian Guo",
      "Prabrisha Rakshit",
      "Daniel S. Herman",
      "Jinbo Chen"
    ]
  },
  "https://jmlr.org/papers/v22/20-1065.html": {
    "title": "Adversarial Monte Carlo Meta-Learning of Optimal Prediction Procedures",
    "volume": "main",
    "abstract": "We frame the meta-learning of prediction procedures as a search for an optimal strategy in a two-player game. In this game, Nature selects a prior over distributions that generate labeled data consisting of features and an associated outcome, and the Predictor observes data sampled from a distribution drawn from this prior. The Predictor's objective is to learn a function that maps from a new feature to an estimate of the associated outcome. We establish that, under reasonable conditions, the Predictor has an optimal strategy that is equivariant to shifts and rescalings of the outcome and is invariant to permutations of the observations and to shifts, rescalings, and permutations of the features. We introduce a neural network architecture that satisfies these properties. The proposed strategy performs favorably compared to standard practice in both parametric and nonparametric experiments",
    "checked": true,
    "id": "1e2dec02197db68c7552f6a56e533009eb76600e",
    "semantic_title": "adversarial monte carlo meta-learning of optimal prediction procedures",
    "citation_count": 3,
    "authors": [
      "Alex Luedtke",
      "Incheoul Chung",
      "Oleg Sofrygin"
    ]
  },
  "https://jmlr.org/papers/v22/20-1078.html": {
    "title": "Model Linkage Selection for Cooperative Learning",
    "volume": "main",
    "abstract": "We consider the distributed learning setting where each agent or learner holds a specific parametric model and a data source. The goal is to integrate information across a set of learners and data sources to enhance the prediction accuracy of a given learner. A natural way to integrate information is to build a joint model across a group of learners that shares common parameters of interest. However, the underlying parameter sharing patterns across a set of learners may not be known a priori. Misspecifying the parameter sharing patterns or the parametric model for each learner often yields a biased estimator that degrades the prediction accuracy. We propose a general method to integrate information across a set of learners that is robust against misspecification of both models and parameter sharing patterns. The main crux of our proposed method is to sequentially incorporate additional learners that can enhance the prediction accuracy of an existing joint model based on user- specified parameter sharing patterns across a set of learners. Theoretically, we show that the proposed method can data-adaptively select a parameter sharing pattern that enhances the predictive performance of a given learner. Extensive numerical studies are conducted to assess the performance of the proposed method",
    "checked": true,
    "id": "3041a58c59d0902d0c0655650cb0dfa8ce47d820",
    "semantic_title": "model linkage selection for cooperative learning",
    "citation_count": 4,
    "authors": [
      "Jiaying Zhou",
      "Jie Ding",
      "Kean Ming Tan",
      "Vahid Tarokh"
    ]
  },
  "https://jmlr.org/papers/v22/20-1100.html": {
    "title": "Estimating Uncertainty Intervals from Collaborating Networks",
    "volume": "main",
    "abstract": "Effective decision making requires understanding the uncertainty inherent in a prediction. In regression, this uncertainty can be estimated by a variety of methods; however, many of these methods are laborious to tune, generate overconfident uncertainty intervals, or lack sharpness (give imprecise intervals). We address these challenges by proposing a novel method to capture predictive distributions in regression by defining two neural networks with two distinct loss functions. Specifically, one network approximates the cumulative distribution function, and the second network approximates its inverse. We refer to this method as Collaborating Networks (CN). Theoretical analysis demonstrates that a fixed point of the optimization is at the idealized solution, and that the method is asymptotically consistent to the ground truth distribution. Empirically, learning is straightforward and robust. We benchmark CN against several common approaches on two synthetic and six real-world datasets, including forecasting A1c values in diabetic patients from electronic health records, where uncertainty is critical. In the synthetic data, the proposed approach essentially matches ground truth. In the real-world datasets, CN improves results on many performance metrics, including log-likelihood estimates, mean absolute errors, coverage estimates, and prediction interval widths",
    "checked": true,
    "id": "83373f1bf2d5366caa4b44107ea5d6df3dc3a471",
    "semantic_title": "estimating uncertainty intervals from collaborating networks",
    "citation_count": 10,
    "authors": [
      "Tianhui Zhou",
      "Yitong Li",
      "Yuan Wu",
      "David Carlson"
    ]
  },
  "https://jmlr.org/papers/v22/20-1143.html": {
    "title": "Optimized Score Transformation for Consistent Fair Classification",
    "volume": "main",
    "abstract": "This paper considers fair probabilistic binary classification where the outputs of primary interest are predicted probabilities, commonly referred to as scores. We formulate the problem of transforming scores to satisfy fairness constraints that are linear in conditional means of scores while minimizing a cross-entropy objective. The formulation can be applied directly to post-process classifier outputs and we also explore a pre-processing extension, thus allowing maximum freedom in selecting a classification algorithm. We derive a closed-form expression for the optimal transformed scores and a convex optimization problem for the transformation parameters. In the population limit, the transformed score function is the fairness-constrained minimizer of cross-entropy with respect to the true conditional probability of the outcome. In the finite sample setting, we propose a method called FairScoreTransformer to approach this solution using a combination of standard probabilistic classifiers and ADMM. We provide several consistency and finite-sample guarantees for FairScoreTransformer, relating to the transformation parameters and transformed score function that it obtains. Comprehensive experiments comparing to 10 existing methods show that FairScoreTransformer has advantages for score-based metrics such as Brier score and AUC while remaining competitive for binary label-based metrics such as accuracy",
    "checked": true,
    "id": "9de258015b1797da97a9de4a439ded1f0733422b",
    "semantic_title": "optimized score transformation for consistent fair classification",
    "citation_count": 11,
    "authors": [
      "Dennis Wei",
      "Karthikeyan Natesan Ramamurthy",
      "Flavio P. Calmon"
    ]
  },
  "https://jmlr.org/papers/v22/20-1176.html": {
    "title": "ROOTS: Object-Centric Representation and Rendering of 3D Scenes",
    "volume": "main",
    "abstract": "A crucial ability of human intelligence is to build up models of individual 3D objects from partial scene observations. Recent works either achieve object-centric generation but without the ability to infer the representation, or achieve 3D scene representation learning but without object-centric compositionality. Therefore, learning to both represent and render 3D scenes with object-centric compositionality remains elusive. In this paper, we propose a probabilistic generative model for learning to build modular and compositional 3D object models from partial observations of a multi-object scene. The proposed model can (i) infer the 3D object representations by learning to search and group object areas, and also (ii) render from an arbitrary viewpoint not only individual objects but also the full scene by compositing the objects. The entire learning process is unsupervised and end-to-end. In experiments, in addition to generation quality, we also demonstrate that the learned representation permits object-wise manipulation and novel scene generation, and generalizes to various settings. Results can be found on our project website: https://sites.google.com/view/roots3d",
    "checked": true,
    "id": "46eb6c7cf0c154f09edcf2397749c8241b49e899",
    "semantic_title": "roots: object-centric representation and rendering of 3d scenes",
    "citation_count": 37,
    "authors": [
      "Chang Chen",
      "Fei Deng",
      "Sungjin Ahn"
    ]
  },
  "https://jmlr.org/papers/v22/20-1221.html": {
    "title": "Learning Strategies in Decentralized Matching Markets under Uncertain Preferences",
    "volume": "main",
    "abstract": "We study the problem of decision-making in the setting of a scarcity of shared resources when the preferences of agents are unknown a priori and must be learned from data. Taking the two-sided matching market as a running example, we focus on the decentralized setting, where agents do not share their learned preferences with a central authority. Our approach is based on the representation of preferences in a reproducing kernel Hilbert space, and a learning algorithm for preferences that accounts for uncertainty due to the competition among the agents in the market. Under regularity conditions, we show that our estimator of preferences converges at a minimax optimal rate. Given this result, we derive optimal strategies that maximize agents' expected payoffs and we calibrate the uncertain state by taking opportunity costs into account. We also derive an incentive-compatibility property and show that the outcome from the learned strategies has a stability property. Finally, we prove a fairness property that asserts that there exists no justified envy according to the learned strategies",
    "checked": true,
    "id": "82ebc7a23807d6d5fdb64eb94a55bf8000d7135e",
    "semantic_title": "learning strategies in decentralized matching markets under uncertain preferences",
    "citation_count": 17,
    "authors": [
      "Xiaowu Dai",
      "Michael I. Jordan"
    ]
  },
  "https://jmlr.org/papers/v22/20-1227.html": {
    "title": "Domain adaptation under structural causal models",
    "volume": "main",
    "abstract": "Domain adaptation (DA) arises as an important problem in statistical machine learning when the source data used to train a model is different from the target data used to test the model. Recent advances in DA have mainly been application-driven and have largely relied on the idea of a common subspace for source and target data. To understand the empirical successes and failures of DA methods, we propose a theoretical framework via structural causal models that enables analysis and comparison of the prediction performance of DA methods. This framework also allows us to itemize the assumptions needed for the DA methods to have a low target error. Additionally, with insights from our theory, we propose a new DA method called CIRM that outperforms existing DA methods when both the covariates and label distributions are perturbed in the target data. We complement the theoretical analysis with extensive simulations to show the necessity of the devised assumptions. Reproducible synthetic and real data experiments are also provided to illustrate the strengths and weaknesses of DA methods when parts of the assumptions in our theory are violated",
    "checked": true,
    "id": "b856e7c617e0b96f316e9889c7d16f25940abe71",
    "semantic_title": "domain adaptation under structural causal models",
    "citation_count": 24,
    "authors": [
      "Yuansi Chen",
      "Peter B√ºhlmann"
    ]
  },
  "https://jmlr.org/papers/v22/20-1251.html": {
    "title": "Revisiting Model-Agnostic Private Learning: Faster Rates and Active Learning",
    "volume": "main",
    "abstract": "The Private Aggregation of Teacher Ensembles (PATE) framework is one of the most promising recent approaches in differentially private learning. Existing theoretical analysis shows that PATE consistently learns any VC-classes in the realizable setting, but falls short in explaining its success in more general cases where the error rate of the optimal classifier is bounded away from zero. We fill in this gap by introducing the Tsybakov Noise Condition (TNC) and establish stronger and more interpretable learning bounds. These bounds provide new insights into when PATE works and improve over existing results even in the narrower realizable setting. We also investigate the compelling idea of using active learning for saving privacy budget, and empirical studies show the effectiveness of this new idea. The novel components in the proofs include a more refined analysis of the majority voting classifier --- which could be of independent interest --- and an observation that the synthetic \"student\" learning problem is nearly realizable by construction under the Tsybakov noise condition",
    "checked": true,
    "id": "6278b922ce1f240385902c3987b43b62cca9a822",
    "semantic_title": "revisiting model-agnostic private learning: faster rates and active learning",
    "citation_count": 5,
    "authors": [
      "Chong Liu",
      "Yuqing Zhu",
      "Kamalika Chaudhuri",
      "Yu-Xiang Wang"
    ]
  },
  "https://jmlr.org/papers/v22/20-1259.html": {
    "title": "On the Stability Properties and the Optimization Landscape of Training Problems with Squared Loss for Neural Networks and General Nonlinear Conic Approximation Schemes",
    "volume": "main",
    "abstract": "We study the optimization landscape and the stability properties of training problems with squared loss for neural networks and general nonlinear conic approximation schemes in a deterministic setting. It is demonstrated that, if a nonlinear conic approximation scheme is considered that is (in an appropriately defined sense) more expressive than a classical linear approximation approach and if there exist unrealizable label vectors, then a training problem with squared loss is necessarily unstable in the sense that its solution set depends discontinuously on the label vector in the training data. We further prove that the same effects that are responsible for these instability properties are also the reason for the emergence of saddle points and spurious local minima, which may be arbitrarily far away from global solutions, and that neither the instability of the training problem nor the existence of spurious local minima can, in general, be overcome by adding a regularization term to the objective function that penalizes the size of the parameters in the approximation scheme. The latter results are shown to be true regardless of whether the assumption of realizability is satisfied or not. It is further established that there exists a direct and quantifiable relationship between the analyzed instability properties and the expressiveness of the considered approximation instrument and that the set of training label vectors and, in the regularized case, Tikhonov regularization parameters that give rise to spurious local minima has a nonempty interior. We demonstrate that our analysis in particular applies to training problems for free-knot interpolation schemes and deep and shallow neural networks with variable widths that involve an arbitrary mixture of various activation functions (e.g., binary, sigmoid, tanh, arctan, soft-sign, ISRU, soft-clip, SQNL, ReLU, leaky ReLU, soft-plus, bent identity, SILU, ISRLU, and ELU). In summary, the findings of this paper illustrate that the improved approximation properties of neural networks and general nonlinear conic approximation instruments come at a price and are linked in a direct and quantifiable way to undesirable properties of the optimization problems that have to be solved in order to train them",
    "checked": true,
    "id": "62097f6a9599def3e3ef7b0484e5ab782d9d2131",
    "semantic_title": "on the stability properties and the optimization landscape of training problems with squared loss for neural networks and general nonlinear conic approximation schemes",
    "citation_count": 2,
    "authors": [
      "Constantin Christof"
    ]
  },
  "https://jmlr.org/papers/v22/20-1289.html": {
    "title": "Regularized spectral methods for clustering signed networks",
    "volume": "main",
    "abstract": "We study the problem of k-way clustering in signed graphs. Considerable attention in recent years has been devoted to analyzing and modeling signed graphs, where the affinity measure between nodes takes either positive or negative values. Recently, Cucuringu et al. (2019) proposed a spectral method, namely SPONGE (Signed Positive over Negative Generalized Eigenproblem), which casts the clustering task as a generalized eigenvalue problem optimizing a suitably defined objective function. This approach is motivated by social balance theory, where the clustering task aims to decompose a given network into disjoint groups, such that individuals within the same group are connected by as many positive edges as possible, while individuals from different groups are mainly connected by negative edges. Through extensive numerical experiments, SPONGE was shown to achieve state-of-the-art empirical performance. On the theoretical front, Cucuringu et al. (2019) analyzed SPONGE, as well as the popular Signed Laplacian based spectral method under the setting of a Signed Stochastic Block Model, for k=2 equal-sized clusters, in the regime where the graph is moderately dense. In this work, we build on the results in Cucuringu et al. (2019) on two fronts for the normalized versions of SPONGE and the Signed Laplacian. Firstly, for both algorithms, we extend the theoretical analysis in Cucuringu et al. (2019) to the general setting of k >= 2 unequal-sized clusters in the moderately dense regime. Secondly, we introduce regularized versions of both methods to handle sparse graphs -- a regime where standard spectral methods are known to underperform -- and provide theoretical guarantees under the same setting of a Signed Stochastic Block Model. To the best of our knowledge, regularized spectral methods have so far not been considered in the setting of clustering signed graphs. We complement our theoretical results with an extensive set of numerical experiments on synthetic data, and three real world data sets standard in the signed networks literature",
    "checked": true,
    "id": "1d067ca27ec8b4d016f872c11cc426cf0ff31eb8",
    "semantic_title": "regularized spectral methods for clustering signed networks",
    "citation_count": 12,
    "authors": [
      "Mihai Cucuringu",
      "Apoorv Vikram Singh",
      "D√©borah Sulem",
      "Hemant Tyagi"
    ]
  },
  "https://jmlr.org/papers/v22/20-1292.html": {
    "title": "Exact Asymptotics for Linear Quadratic Adaptive Control",
    "volume": "main",
    "abstract": "Recent progress in reinforcement learning has led to remarkable performance in a range of applications, but its deployment in high-stakes settings remains quite rare. One reason is a limited understanding of the behavior of reinforcement algorithms, both in terms of their regret and their ability to learn the underlying system dynamics---existing work is focused almost exclusively on characterizing rates, with little attention paid to the constants multiplying those rates that can be critically important in practice. To start to address this challenge, we study perhaps the simplest non-bandit reinforcement learning problem: linear quadratic adaptive control (LQAC). By carefully combining recent finite-sample performance bounds for the LQAC problem with a particular (less-recent) martingale central limit theorem, we are able to derive asymptotically exact expressions for the regret, estimation error, and prediction error of a rate-optimal stepwise-updating LQAC algorithm. In simulations on both stable and unstable systems, we find that our asymptotic theory also describes the algorithm's finite-sample behavior remarkably well",
    "checked": true,
    "id": "4fed680b41a3725ab2f8b241c31a73497bd0a86b",
    "semantic_title": "exact asymptotics for linear quadratic adaptive control",
    "citation_count": 8,
    "authors": [
      "Feicheng Wang",
      "Lucas Janson"
    ]
  },
  "https://jmlr.org/papers/v22/20-1338.html": {
    "title": "Learning Bayesian Networks from Ordinal Data",
    "volume": "main",
    "abstract": "Bayesian networks are a powerful framework for studying the dependency structure of variables in a complex system. The problem of learning Bayesian networks is tightly associated with the given data type. Ordinal data, such as stages of cancer, rating scale survey questions, and letter grades for exams, are ubiquitous in applied research. However, existing solutions are mainly for continuous and nominal data. In this work, we propose an iterative score-and-search method - called the Ordinal Structural EM (OSEM) algorithm - for learning Bayesian networks from ordinal data. Unlike traditional approaches designed for nominal data, we explicitly respect the ordering amongst the categories. More precisely, we assume that the ordinal variables originate from marginally discretizing a set of Gaussian variables, whose structural dependence in the latent space follows a directed acyclic graph. Then, we adopt the Structural EM algorithm and derive closed-form scoring functions for efficient graph searching. Through simulation studies, we illustrate the superior performance of the OSEM algorithm compared to the alternatives and analyze various factors that may influence the learning accuracy. Finally, we demonstrate the practicality of our method with a real-world application on psychological survey data from 408 patients with co-morbid symptoms of obsessive-compulsive disorder and depression",
    "checked": true,
    "id": "018a310d067052be3d96398e79dd8b8dc523425d",
    "semantic_title": "learning bayesian networks from ordinal data",
    "citation_count": 4,
    "authors": [
      "Xiang Ge Luo",
      "Giusi Moffa",
      "Jack Kuipers"
    ]
  },
  "https://jmlr.org/papers/v22/20-1346.html": {
    "title": "Reproducing kernel Hilbert C*-module and kernel mean embeddings",
    "volume": "main",
    "abstract": "Kernel methods have been among the most popular techniques in machine learning, where learning tasks are solved using the property of reproducing kernel Hilbert space (RKHS). In this paper, we propose a novel data analysis framework with reproducing kernel Hilbert $C^*$-module (RKHM) and kernel mean embedding (KME) in RKHM. Since RKHM contains richer information than RKHS or vector-valued RKHS (vvRKHS), analysis with RKHM enables us to capture and extract structural properties in such as functional data. We show a branch of theories for RKHM to apply to data analysis, including the representer theorem, and the injectivity and universality of the proposed KME. We also show RKHM generalizes RKHS and vvRKHS. Then, we provide concrete procedures for employing RKHM and the proposed KME to data analysis",
    "checked": true,
    "id": "a10f925edeb977f26efde48c5371cf152465417d",
    "semantic_title": "reproducing kernel hilbert c*-module and kernel mean embeddings",
    "citation_count": 4,
    "authors": [
      "Yuka Hashimoto",
      "Isao Ishikawa",
      "Masahiro Ikeda",
      "Fuyuta Komura",
      "Takeshi Katsura",
      "Yoshinobu Kawahara"
    ]
  },
  "https://jmlr.org/papers/v22/20-1364.html": {
    "title": "Stable-Baselines3: Reliable Reinforcement Learning Implementations",
    "volume": "MLOSS",
    "abstract": "Stable-Baselines3 provides open-source implementations of deep reinforcement learning (RL) algorithms in Python. The implementations have been benchmarked against reference codebases, and automated unit tests cover 95% of the code. The algorithms follow a consistent interface and are accompanied by extensive documentation, making it simple to train and compare different RL algorithms. Our documentation, examples, and source-code are available at https://github.com/DLR-RM/stable-baselines3",
    "checked": true,
    "id": "e3fc5b5627af62ee6981a02090cf6bae368202d7",
    "semantic_title": "stable-baselines3: reliable reinforcement learning implementations",
    "citation_count": 809,
    "authors": [
      "Antonin Raffin",
      "Ashley Hill",
      "Adam Gleave",
      "Anssi Kanervisto",
      "Maximilian Ernestus",
      "Noah Dormann"
    ]
  },
  "https://jmlr.org/papers/v22/20-1374.html": {
    "title": "CAT: Compression-Aware Training for bandwidth reduction",
    "volume": "main",
    "abstract": "One major obstacle hindering the ubiquitous use of CNNs for inference is their relatively high memory bandwidth requirements, which can be the primary energy consumer and throughput bottleneck in hardware accelerators. Inspired by quantization-aware training approaches, we propose a compression-aware training (CAT) method that involves training the model to allow better compression of weights and feature maps during neural network deployment. Our method trains the model to achieve low-entropy feature maps, enabling efficient compression at inference time using classical transform coding methods. CAT significantly improves the state-of-the-art results reported for quantization evaluated on various vision and NLP tasks, such as image classification (ImageNet), image detection (Pascal VOC), sentiment analysis (CoLa), and textual entailment (MNLI). For example, on ResNet-18, we achieve near baseline ImageNet accuracy with an average representation of only 1.5 bits per value with 5-bit quantization. Moreover, we show that entropy reduction of weights and activations can be applied together, further improving bandwidth reduction. Reference implementation is available",
    "checked": true,
    "id": "41a3eee922c90ecb221c1665490b0eaca4c683d5",
    "semantic_title": "cat: compression-aware training for bandwidth reduction",
    "citation_count": 9,
    "authors": [
      "Chaim Baskin",
      "Brian Chmiel",
      "Evgenii Zheltonozhskii",
      "Ron Banner",
      "Alex M. Bronstein",
      "Avi Mendelson"
    ]
  },
  "https://jmlr.org/papers/v22/20-1413.html": {
    "title": "Further results on latent discourse models and word embeddings",
    "volume": "main",
    "abstract": "We discuss some properties of generative models for word embeddings. Namely, (Arora & Al., 2016) proposed a latent discourse model implying the concentration of the partition function of the word vectors. This concentration phenomenon led to an asymptotic linear relation between the pointwise mutual information (PMI) of pairs of words and the scalar product of their vectors. Here, we first revisit this concentration phenomenon and prove it under slightly weaker assumptions, for a set of random vectors symmetrically distributed around the origin. Second, we empirically evaluate the relation between PMI and scalar products of word vectors satisfying the concentration property. Our empirical results indicate that, in practice, this relation does not hold with arbitrarily small error. This observation is further supported by two theoretical results: (i) the error cannot be exactly zero because the corresponding shifted PMI matrix cannot be positive semidefinite; (ii) under mild assumptions, there exist pairs of words for which the error cannot be close to zero. We deduce that either natural language does not follow the assumptions of the considered generative model, or the current word vector generation methods do not allow the construction of the hypothesized word embeddings",
    "checked": true,
    "id": "f2a17f186c677296f7221103d8baf87f6e1bfd99",
    "semantic_title": "further results on latent discourse models and word embeddings",
    "citation_count": 1,
    "authors": [
      "Sammy Khalife",
      "Douglas Gon√ßalves",
      "Youssef Allouah",
      "Leo Liberti"
    ]
  },
  "https://jmlr.org/papers/v22/20-1468.html": {
    "title": "Nonparametric Continuous Sensor Registration",
    "volume": "main",
    "abstract": "This paper develops a new mathematical framework that enables nonparametric joint semantic and geometric representation of continuous functions using data. The joint embedding is modeled by representing the processes in a reproducing kernel Hilbert space. The functions can be defined on arbitrary smooth manifolds where the action of a Lie group aligns them. The continuous functions allow the registration to be independent of a specific signal resolution. The framework is fully analytical with a closed-form derivation of the Riemannian gradient and Hessian. We study a more specialized but widely used case where the Lie group acts on functions isometrically. We solve the problem by maximizing the inner product between two functions defined over data, while the continuous action of the rigid body motion Lie group is captured through the integration of the flow in the corresponding Lie algebra. Low-dimensional cases are derived with numerical examples to show the generality of the proposed framework. The high-dimensional derivation for the special Euclidean group acting on the Euclidean space showcases the point cloud registration and bird's-eye view map registration abilities. An implementation of this framework for RGB-D cameras outperforms the state-of-the-art robust visual odometry and performs well in texture and structure-scarce environments",
    "checked": true,
    "id": "a15dc05b4810823bb42a234d9cfe180a0df4dfa1",
    "semantic_title": "nonparametric continuous sensor registration",
    "citation_count": 11,
    "authors": [
      "William Clark",
      "Maani Ghaffari",
      "Anthony Bloch"
    ]
  },
  "https://jmlr.org/papers/v22/20-213.html": {
    "title": "Transferability of Spectral Graph Convolutional Neural Networks",
    "volume": "main",
    "abstract": "This paper focuses on spectral graph convolutional neural networks (ConvNets), where filters are defined as elementwise multiplication in the frequency domain of a graph. In machine learning settings where the data set consists of signals defined on many different graphs, the trained ConvNet should generalize to signals on graphs unseen in the training set. It is thus important to transfer ConvNets between graphs. Transferability, which is a certain type of generalization capability, can be loosely defined as follows: if two graphs describe the same phenomenon, then a single filter or ConvNet should have similar repercussions on both graphs. This paper aims at debunking the common misconception that spectral filters are not transferable. We show that if two graphs discretize the same \"continuous\" space, then a spectral filter or ConvNet has approximately the same repercussion on both graphs. Our analysis is more permissive than the standard analysis. Transferability is typically described as the robustness of the filter to small graph perturbations and re-indexing of the vertices. Our analysis accounts also for large graph perturbations. We prove transferability between graphs that can have completely different dimensions and topologies, only requiring that both graphs discretize the same underlying space in some generic sense",
    "checked": true,
    "id": "c22ecb56b1b3d54acb8793df1ae6a526cf621449",
    "semantic_title": "transferability of spectral graph convolutional neural networks",
    "citation_count": 103,
    "authors": [
      "Ron Levie",
      "Wei Huang",
      "Lorenzo Bucci",
      "Michael Bronstein",
      "Gitta Kutyniok"
    ]
  },
  "https://jmlr.org/papers/v22/20-285.html": {
    "title": "On the Hardness of Robust Classification",
    "volume": "main",
    "abstract": "It is becoming increasingly important to understand the vulnerability of machine learning models to adversarial attacks. In this paper we study the feasibility of adversarially robust learning from the perspective of computational learning theory, considering both sample and computational complexity. In particular, our definition of robust learnability requires polynomial sample complexity. We start with two negative results. We show that no non-trivial concept class can be robustly learned in the distribution-free setting against an adversary who can perturb just a single input bit. We show, moreover, that the class of monotone conjunctions cannot be robustly learned under the uniform distribution against an adversary who can perturb $\\omega(\\log n)$ input bits. However, we also show that if the adversary is restricted to perturbing $O(\\log n)$ bits, then one can robustly learn the class of $1$-decision lists (which subsumes monotone conjunctions) with respect to the class of log-Lipschitz distributions. We then extend this result to show learnability of 2-decision lists and monotone $k$-decision lists in the same distributional and adversarial setting. Finally, we provide a simple proof of the computational hardness of robust learning on the boolean hypercube. Unlike previous results of this nature, our result does not rely on a more restricted model of learning, such as the statistical query model, nor on any hardness assumption other than the existence of an (average-case) hard learning problem in the PAC framework; this allows us to have a clean proof of the reduction, and the assumption is no stronger than assumptions that are used to build cryptographic primitives",
    "checked": true,
    "id": "6df3eb2ab642e8917e8e0e7208ba6f81cf4bdf80",
    "semantic_title": "on the hardness of robust classification",
    "citation_count": 37,
    "authors": [
      "Pascale Gourdeau",
      "Varun Kanade",
      "Marta Kwiatkowska",
      "James Worrell"
    ]
  },
  "https://jmlr.org/papers/v22/20-327.html": {
    "title": "Simultaneous Change Point Inference and Structure Recovery for High Dimensional Gaussian Graphical Models",
    "volume": "main",
    "abstract": "In this article, we investigate the problem of simultaneous change point inference and structure recovery in the context of high dimensional Gaussian graphical models with possible abrupt changes. In particular, motivated by neighborhood selection, we incorporate a threshold variable and an unknown threshold parameter into a joint sparse regression model which combines p l1-regularized node-wise regression problems together. The change point estimator and the corresponding estimated coefficients of precision matrices are obtained together. Based on that, a classifier is introduced to distinguish whether a change point exists. To recover the graphical structure correctly, a data-driven thresholding procedure is proposed. In theory, under some sparsity conditions and regularity assumptions, our method can correctly choose a homogeneous or heterogeneous model with high accuracy. Furthermore, in the latter case with a change point, we establish estimation consistency of the change point estimator, by allowing the number of nodes being much larger than the sample size. Moreover, it is shown that, in terms of structure recovery of Gaussian graphical models, the proposed thresholding procedure achieves model selection consistency and controls the number of false positives. The validity of our proposed method is justified via extensive numerical studies. Finally, we apply our proposed method to the S&P 500 dataset to show its empirical usefulness",
    "checked": true,
    "id": "504ad0701421c182e13c4887f7ba50db897eb4f5",
    "semantic_title": "simultaneous change point inference and structure recovery for high dimensional gaussian graphical models",
    "citation_count": 5,
    "authors": [
      "Bin Liu",
      "Xinsheng Zhang",
      "Yufeng Liu"
    ]
  },
  "https://jmlr.org/papers/v22/20-445.html": {
    "title": "Partial Policy Iteration for L1-Robust Markov Decision Processes",
    "volume": "main",
    "abstract": "Robust Markov decision processes (MDPs) compute reliable solutions for dynamic decision problems with partially-known transition probabilities. Unfortunately, accounting for uncertainty in the transition probabilities significantly increases the computational complexity of solving robust MDPs, which limits their scalability. This paper describes new, efficient algorithms for solving the common class of robust MDPs with s- and sa-rectangular ambiguity sets defined by weighted L1 norms. We propose partial policy iteration, a new, efficient, flexible, and general policy iteration scheme for robust MDPs. We also propose fast methods for computing the robust Bellman operator in quasi-linear time, nearly matching the ordinary Bellman operator's linear complexity. Our experimental results indicate that the proposed methods are many orders of magnitude faster than the state-of-the-art approach, which uses linear programming solvers combined with a robust value iteration",
    "checked": true,
    "id": "db4b49f27bfd0506917720f9ab3ed4bc850fc6ec",
    "semantic_title": "partial policy iteration for l1-robust markov decision processes",
    "citation_count": 38,
    "authors": [
      "Chin Pang Ho",
      "Marek Petrik",
      "Wolfram Wiesemann"
    ]
  },
  "https://jmlr.org/papers/v22/20-539.html": {
    "title": "Estimating the Lasso's Effective Noise",
    "volume": "main",
    "abstract": "Much of the theory for the lasso in the linear model $Y = \\boldsymbol{X} \\beta^* + \\varepsilon$ hinges on the quantity $2\\| \\boldsymbol{X}^\\top \\varepsilon \\|_\\infty / n$, which we call the lasso's effective noise. Among other things, the effective noise plays an important role in finite-sample bounds for the lasso, the calibration of the lasso's tuning parameter, and inference on the parameter vector $\\beta^*$. In this paper, we develop a bootstrap-based estimator of the quantiles of the effective noise. The estimator is fully data-driven, that is, does not require any additional tuning parameters. We equip our estimator with finite-sample guarantees and apply it to tuning parameter calibration for the lasso and to high-dimensional inference on the parameter vector $\\beta^*$",
    "checked": true,
    "id": "ff3b622a4ca59ce1784ad1b100c51fc7d27ee283",
    "semantic_title": "estimating the lasso's effective noise",
    "citation_count": 14,
    "authors": [
      "Johannes Lederer",
      "Michael Vogt"
    ]
  },
  "https://jmlr.org/papers/v22/20-633.html": {
    "title": "Gaussian Approximation for Bias Reduction in Q-Learning",
    "volume": "main",
    "abstract": "Temporal-Difference off-policy algorithms are among the building blocks of reinforcement learning (RL). Within this family, Q-Learning is arguably the most famous one, which has been widely studied and extended. The update rule of Q-learning involves the use of the maximum operator to estimate the maximum expected value of the return. However, this estimate is positively biased, and may hinder the learning process, especially in stochastic environments and when function approximation is used. We introduce the Weighted Estimator as an effective solution to mitigate the negative effects of overestimation in Q-Learning. The Weighted Estimator estimates the maximum expected value as a weighted sum of the action values, with the weights being the probabilities that each action value is the maximum. In this work, we study the problem from the statistical perspective of estimating the maximum expected value of a set of random variables and provide bounds to the bias and the variance of the Weighted Estimator, showing its advantages over other estimators present in literature. Then, we derive algorithms to enable the use of the Weighted Estimator, in place of the Maximum Estimator, in online and batch RL, and we introduce a novel algorithm for deep RL. Finally, we empirically evaluate our algorithms in a large set of heterogeneous problems, encompassing discrete and continuous, low and high dimensional, deterministic and stochastic environments. Experimental results show the effectiveness of the Weighted Estimator in controlling the bias of the estimate, resulting in better performance than representative baselines and robust learning w.r.t. a large set of diverse environments",
    "checked": true,
    "id": "5a55921a9d83049fb0a2c138c706095c1028770d",
    "semantic_title": "gaussian approximation for bias reduction in q-learning",
    "citation_count": 4,
    "authors": [
      "Carlo D'Eramo",
      "Andrea Cini",
      "Alessandro Nuara",
      "Matteo Pirotta",
      "Cesare Alippi",
      "Jan Peters",
      "Marcello Restelli"
    ]
  },
  "https://jmlr.org/papers/v22/20-653.html": {
    "title": "Multilevel Monte Carlo Variational Inference",
    "volume": "main",
    "abstract": "We propose a variance reduction framework for variational inference using the Multilevel Monte Carlo (MLMC) method. Our framework is built on reparameterized gradient estimators and \"recycles\" parameters obtained from past update history in optimization. In addition, our framework provides a new optimization algorithm based on stochastic gradient descent (SGD) that adaptively estimates the sample size used for gradient estimation according to the ratio of the gradient variance. We theoretically show that, with our method, the variance of the gradient estimator decreases as optimization proceeds and that a learning rate scheduler function helps improve the convergence. We also show that, in terms of the signal-to-noise ratio, our method can improve the quality of gradient estimation by the learning rate scheduler function without increasing the initial sample size. Finally, we confirm that our method achieves faster convergence and reduces the variance of the gradient estimator compared with other methods through experimental comparisons with baseline methods using several benchmark datasets",
    "checked": true,
    "id": "f862385577094c4e6f419d7dd6cf0a57a364d606",
    "semantic_title": "multilevel monte carlo variational inference",
    "citation_count": 5,
    "authors": [
      "Masahiro Fujisawa",
      "Issei Sato"
    ]
  },
  "https://jmlr.org/papers/v22/20-813.html": {
    "title": "Fast Learning for Renewal Optimization in Online Task Scheduling",
    "volume": "main",
    "abstract": "This paper considers online optimization of a renewal-reward system. A controller performs a sequence of tasks back-to-back. Each task has a random vector of parameters, called the task type vector, that affects the task processing options and also affects the resulting reward and time duration of the task. The probability distribution for the task type vector is unknown and the controller must learn to make efficient decisions so that time-average reward converges to optimality. Prior work on such renewal optimization problems leaves open the question of optimal convergence time. This paper develops an algorithm with an optimality gap that decays like $O(1/\\sqrt{k})$, where $k$ is the number of tasks processed. The same algorithm is shown to have faster $O(\\log(k)/k)$ performance when the system satisfies a strong concavity property. The proposed algorithm uses an auxiliary variable that is updated according to a classic Robbins-Monro iteration. It makes online scheduling decisions at the start of each renewal frame based on this variable and the observed task type. A matching converse is obtained for the strongly concave case by constructing an example system for which all algorithms have performance at best $\\Omega(\\log(k)/k)$. A matching $\\Omega(1/\\sqrt{k})$ converse is also shown for the general case without strong concavity",
    "checked": true,
    "id": "405d7a22b2eb47d904c3dd78e0b274f7cc042e14",
    "semantic_title": "fast learning for renewal optimization in online task scheduling",
    "citation_count": 8,
    "authors": [
      "Michael J. Neely"
    ]
  },
  "https://jmlr.org/papers/v22/21-0020.html": {
    "title": "Graph Matching with Partially-Correct Seeds",
    "volume": "main",
    "abstract": "Graph matching aims to find the latent vertex correspondence between two edge-correlated graphs and has found numerous applications across different fields. In this paper, we study a seeded graph matching problem, which assumes that a set of seeds, i.e., pre-mapped vertex-pairs, is given in advance. While most previous work requires all seeds to be correct, we focus on the setting where the seeds are partially correct. Specifically, consider two correlated graphs whose edges are sampled independently from a parent Erdos-Renyi graph $\\mathcal{G}(n,p)$. A mapping between the vertices of the two graphs is provided as seeds, of which an unknown $\\beta$ fraction is correct. We first analyze a simple algorithm that matches vertices based on the number of common seeds in the $1$-hop neighborhoods, and then further propose a new algorithm that uses seeds in the $2$-hop neighborhoods. We establish non-asymptotic performance guarantees of perfect matching for both $1$-hop and $2$-hop algorithms, showing that our new $2$-hop algorithm requires substantially fewer correct seeds than the $1$-hop algorithm when graphs are sparse. Moreover, by combining our new performance guarantees for the $1$-hop and $2$-hop algorithms, we attain the best-known results (in terms of the required fraction of correct seeds) across the entire range of graph sparsity and significantly improve the previous results when $p\\ge n^{-5/6}$. For instance, when $p$ is a constant or $p=n^{-3/4}$, we show that only $\\Omega(\\sqrt{n\\log n})$ correct seeds suffice for perfect matching, while the previously best-known results demand $\\Omega(n)$ and $\\Omega(n^{3/4}\\log n)$ correct seeds, respectively. Numerical experiments corroborate our theoretical findings, demonstrating the superiority of our $2$-hop algorithm on a variety of synthetic and real graphs",
    "checked": true,
    "id": "2ed0d80a9bc17f5a9e91f46f83eef46369edd0f4",
    "semantic_title": "graph matching with partially-correct seeds",
    "citation_count": 14,
    "authors": [
      "Liren Yu",
      "Jiaming Xu",
      "Xiaojun Lin"
    ]
  },
  "https://jmlr.org/papers/v22/21-0089.html": {
    "title": "Contrastive Estimation Reveals Topic Posterior Information to Linear Models",
    "volume": "main",
    "abstract": "Contrastive learning is an approach to representation learning that utilizes naturally occurring similar and dissimilar pairs of data points to find useful embeddings of data. In the context of document classification under topic modeling assumptions, we prove that contrastive learning is capable of recovering a representation of documents that reveals their underlying topic posterior information to linear models. We apply this procedure in a semi-supervised setup and demonstrate empirically that linear classifiers trained on these representations perform well in document classification tasks with very few training examples",
    "checked": true,
    "id": "4815e465f223ce66e6eea29b5b12bb39fc531538",
    "semantic_title": "contrastive estimation reveals topic posterior information to linear models",
    "citation_count": 53,
    "authors": [
      "Christopher Tosh",
      "Akshay Krishnamurthy",
      "Daniel Hsu"
    ]
  },
  "https://jmlr.org/papers/v22/21-0131.html": {
    "title": "LDLE: Low Distortion Local Eigenmaps",
    "volume": "main",
    "abstract": "We present Low Distortion Local Eigenmaps (LDLE), a manifold learning technique which constructs a set of low distortion local views of a data set in lower dimension and registers them to obtain a global embedding. The local views are constructed using the global eigenvectors of the graph Laplacian and are registered using Procrustes analysis. The choice of these eigenvectors may vary across the regions. In contrast to existing techniques, LDLE can embed closed and non-orientable manifolds into their intrinsic dimension by tearing them apart. It also provides gluing instruction on the boundary of the torn embedding to help identify the topology of the original manifold. Our experimental results will show that LDLE largely preserved distances up to a constant scale while other techniques produced higher distortion. We also demonstrate that LDLE produces high quality embeddings even when the data is noisy or sparse",
    "checked": true,
    "id": "40691b340e2e7ea08af5dc2eb1bf564f8d7f87bc",
    "semantic_title": "ldle: low distortion local eigenmaps",
    "citation_count": 14,
    "authors": [
      "Dhruv Kohli",
      "Alexander Cloninger",
      "Gal Mishne"
    ]
  },
  "https://jmlr.org/papers/v22/21-0203.html": {
    "title": "Non-linear, Sparse Dimensionality Reduction via Path Lasso Penalized Autoencoders",
    "volume": "main",
    "abstract": "High-dimensional data sets are often analyzed and explored via the construction of a latent low-dimensional space which enables convenient visualization and efficient predictive modeling or clustering. For complex data structures, linear dimensionality reduction techniques like PCA may not be sufficiently flexible to enable low-dimensional representation. Non-linear dimension reduction techniques, like kernel PCA and autoencoders, suffer from loss of interpretability since each latent variable is dependent of all input dimensions. To address this limitation, we here present path lasso penalized autoencoders. This structured regularization enhances interpretability by penalizing each path through the encoder from an input to a latent variable, thus restricting how many input variables are represented in each latent dimension. Our algorithm uses a group lasso penalty and non-negative matrix factorization to construct a sparse, non-linear latent representation. We compare the path lasso regularized autoencoder to PCA, sparse PCA, autoencoders and sparse autoencoders on real and simulated data sets. We show that the algorithm exhibits much lower reconstruction errors than sparse PCA and parameter-wise lasso regularized autoencoders for low-dimensional representations. Moreover, path lasso representations provide a more accurate reconstruction match, i.e. preserved relative distance between objects in the original and reconstructed spaces",
    "checked": true,
    "id": "9c4307fb50bd6886f1417811f90754cbfa136f35",
    "semantic_title": "non-linear, sparse dimensionality reduction via path lasso penalized autoencoders",
    "citation_count": 0,
    "authors": [
      "Oskar Allerbo",
      "Rebecka J√∂rnsten"
    ]
  },
  "https://jmlr.org/papers/v22/21-0277.html": {
    "title": "Linear Bandits on Uniformly Convex Sets",
    "volume": "main",
    "abstract": "Linear bandit algorithms yield $\\tilde{\\mathcal{O}}(n\\sqrt{T})$ pseudo-regret bounds on compact convex action sets $\\mathcal{K}\\subset\\mathbb{R}^n$ and two types of structural assumptions lead to better pseudo-regret bounds. When $\\mathcal{K}$ is the simplex or an $\\ell_p$ ball with $p\\in]1,2]$, there exist bandits algorithms with $\\tilde{\\mathcal{O}}(\\sqrt{nT})$ pseudo-regret bounds. Here, we derive bandit algorithms for some strongly convex sets beyond $\\ell_p$ balls that enjoy pseudo-regret bounds of $\\tilde{\\mathcal{O}}(\\sqrt{nT})$. This result provides new elements for the open question in Bubeck and Cesa-Bianchi, 2012. When the action set is $q$-uniformly convex but not necessarily strongly convex ($q >2$), we obtain pseudo-regret bounds $\\tilde{\\mathcal{O}}(n^{1/q}T^{1/p})$ with $p$ s.t. $1/p + 1/q=1$. These pseudo-regret bounds are competitive with the general $\\tilde{\\mathcal{O}}(n\\sqrt{T})$ for a time horizon range that depends on the degree $q>2$ of the set's uniform convexity and the dimension $n$ of the problem",
    "checked": true,
    "id": "7fffa2f0fe608e807940aa0267e55a66b8a8f8fa",
    "semantic_title": "linear bandits on uniformly convex sets",
    "citation_count": 6,
    "authors": [
      "Thomas Kerdreux",
      "Christophe Roux",
      "Alexandre d'Aspremont",
      "Sebastian Pokutta"
    ]
  },
  "https://jmlr.org/papers/v22/21-0294.html": {
    "title": "Double Generative Adversarial Networks for Conditional Independence Testing",
    "volume": "main",
    "abstract": "In this article, we study the problem of high-dimensional conditional independence testing, a key building block in statistics and machine learning. We propose an inferential procedure based on double generative adversarial networks (GANs). Specifically, we first introduce a double GANs framework to learn two generators of the conditional distributions. We then integrate the two generators to construct a test statistic, which takes the form of the maximum of generalized covariance measures of multiple transformation functions. We also employ data-splitting and cross-fitting to minimize the conditions on the generators to achieve the desired asymptotic properties, and employ multiplier bootstrap to obtain the corresponding p-value. We show that the constructed test statistic is doubly robust, and the resulting test both controls type-I error and has the power approaching one asymptotically. Also notably, we establish those theoretical guarantees under much weaker and practically more feasible conditions compared to the existing tests, and our proposal gives a concrete example of how to utilize some state-of-the-art deep learning tools, such as GANs, to help address a classical but challenging statistical problem. We demonstrate the efficacy of our test through both simulations and an application to an anti-cancer drug dataset. A Python implementation of the proposed procedure is available at https://github.com/tianlinxu312/dgcit",
    "checked": true,
    "id": "edad980b33f1c44759c2fedd6d8090e20abf7223",
    "semantic_title": "double generative adversarial networks for conditional independence testing",
    "citation_count": 18,
    "authors": [
      "Chengchun Shi",
      "Tianlin Xu",
      "Wicher Bergsma",
      "Lexin Li"
    ]
  },
  "https://jmlr.org/papers/v22/21-0383.html": {
    "title": "An Online Sequential Test for Qualitative Treatment Effects",
    "volume": "main",
    "abstract": "Tech companies (e.g., Google or Facebook) often use randomized online experiments and/or A/B testing primarily based on the average treatment effects to compare their new product with an old one. However, it is also critically important to detect qualitative treatment effects such that the new one may significantly outperform the existing one only under some specific circumstances. The aim of this paper is to develop a powerful testing procedure to efficiently detect such qualitative treatment effects. We propose a scalable online updating algorithm to implement our test procedure. It has three novelties including adaptive randomization, sequential monitoring, and online updating with guaranteed type-I error control. We also thoroughly examine the theoretical properties of our testing procedure including the limiting distribution of test statistics and the justification of an efficient bootstrap method. Extensive empirical studies are conducted to examine the finite sample performance of our test procedure",
    "checked": true,
    "id": "751cd2292ac723dccd1e3181b4ef1cfbf45c66f2",
    "semantic_title": "an online sequential test for qualitative treatment effects",
    "citation_count": 4,
    "authors": [
      "Chengchun Shi",
      "Shikai Luo",
      "Hongtu Zhu",
      "Rui Song"
    ]
  },
  "https://jmlr.org/papers/v22/21-0575.html": {
    "title": "V-statistics and Variance Estimation",
    "volume": "main",
    "abstract": "As machine learning procedures become an increasingly popular modeling option among applied researchers, there has been a corresponding interest in developing valid tools for understanding their statistical properties and uncertainty. Tree-based ensembles like random forests remain one such popular option for which several important theoretical advances have been made in recent years by drawing upon a connection between their natural subsampled structure and the classical theory of $U$-statistics. Unfortunately, the procedures for estimating predictive variance resulting from these studies are plagued by severe bias and extreme computational overhead. Here, we argue that the root of these problems lies in the use of subsampling without replacement and that with-replacement subsamples, resulting in $V$-statistics, substantially alleviates these problems. We develop a general framework for analyzing the asymptotic behavior of $V$-statistics, demonstrating asymptotic normality under precise regularity conditions and establishing previously unreported connections to $U$-statistics. Importantly, these findings allow us to produce a natural and efficient means of estimating the variance of a conditional expectation, a problem of wide interest across multiple scientific domains that also lies at the heart of uncertainty quantification for supervised learning ensembles",
    "checked": true,
    "id": "04fcb615608e95b453ba39006f6935e7a3292ccd",
    "semantic_title": "v-statistics and variance estimation",
    "citation_count": 10,
    "authors": [
      "Zhengze Zhou",
      "Lucas Mentch",
      "Giles Hooker"
    ]
  },
  "https://jmlr.org/papers/v22/21-0641.html": {
    "title": "A Theory of the Risk for Optimization with Relaxation and its Application to Support Vector Machines",
    "volume": "main",
    "abstract": "In this paper we consider optimization with relaxation, an ample paradigm to make data-driven designs. This approach was previously considered by the same authors of this work in Garatti and Campi (2019), a study that revealed a deep-seated connection between two concepts: risk (probability of not satisfying a new, out-of-sample, constraint) and complexity (according to a definition introduced in paper Garatti and Campi, 2019). This connection was shown to have profound implications in applications because it implied that the risk can be estimated from the complexity, a quantity that can be measured from the data without any knowledge of the data-generation mechanism. In the present work we establish new results. First, we expand the scope of Garatti and Campi (2019) so as to embrace a more general setup that covers various algorithms in machine learning. Then, we study classical support vector methods ‚Äì including SVM (Support Vector Machine), SVR (Support Vector Regression) and SVDD (Support Vector Data Description) ‚Äì and derive new results for the ability of these methods to generalize. All results are valid for any finite size of the data set. When the sample size tends to infinity, we establish the unprecedented result that the risk approaches the ratio between the complexity and the cardinality of the data sample, regardless of the value of the complexity",
    "checked": true,
    "id": "64a4a3cf08ce1b233f2cb0452d0971e945151914",
    "semantic_title": "a theory of the risk for optimization with relaxation and its application to support vector machines",
    "citation_count": 15,
    "authors": [
      "Marco C. Campi",
      "Simone Garatti"
    ]
  },
  "https://jmlr.org/papers/v22/21-0657.html": {
    "title": "VariBAD: Variational Bayes-Adaptive Deep RL via Meta-Learning",
    "volume": "main",
    "abstract": "Trading off exploration and exploitation in an unknown environment is key to maximising expected online return during learning. A Bayes-optimal policy, which does so optimally, conditions its actions not only on the environment state but also on the agent's uncertainty about the environment. Computing a Bayes-optimal policy is however intractable for all but the smallest tasks. In this paper, we introduce variational Bayes-Adaptive Deep RL (variBAD), a way to meta-learn approximately Bayes-optimal policies for complex tasks. VariBAD simultaneously meta-learns a variational auto-encoder to perform approximate inference, and a policy that incorporates task uncertainty directly during action selection by conditioning on both the environment state and the approximate belief. In two toy domains, we illustrate how variBAD performs structured online exploration as a function of task uncertainty. We further evaluate variBAD on MuJoCo tasks widely used in meta-RL and show that it achieves higher online return than existing methods. On the recently proposed Meta-World ML1 benchmark, variBAD achieves state of the art results by a large margin, fully solving two out of the three ML1 tasks for the first time",
    "checked": true,
    "id": "c7629a4d7e1c87fd1ea73850bcb800538fd0aa4b",
    "semantic_title": "varibad: variational bayes-adaptive deep rl via meta-learning",
    "citation_count": 19,
    "authors": [
      "Luisa Zintgraf",
      "Sebastian Schulze",
      "Cong Lu",
      "Leo Feng",
      "Maximilian Igl",
      "Kyriacos Shiarlis",
      "Yarin Gal",
      "Katja Hofmann",
      "Shimon Whiteson"
    ]
  },
  "https://jmlr.org/papers/v22/21-0806.html": {
    "title": "On Universal Approximation and Error Bounds for Fourier Neural Operators",
    "volume": "main",
    "abstract": "Fourier neural operators (FNOs) have recently been proposed as an effective framework for learning operators that map between infinite-dimensional spaces. We prove that FNOs are universal, in the sense that they can approximate any continuous operator to desired accuracy. Moreover, we suggest a mechanism by which FNOs can approximate operators associated with PDEs efficiently. Explicit error bounds are derived to show that the size of the FNO, approximating operators associated with a Darcy type elliptic PDE and with the incompressible Navier-Stokes equations of fluid dynamics, only increases sub (log)-linearly in terms of the reciprocal of the error. Thus, FNOs are shown to efficiently approximate operators arising in a large class of PDEs",
    "checked": true,
    "id": "d15a11a7be64ccc52b709b44b9fac1e4d6302062",
    "semantic_title": "on universal approximation and error bounds for fourier neural operators",
    "citation_count": 147,
    "authors": [
      "Nikola Kovachki",
      "Samuel Lanthaler",
      "Siddhartha Mishra"
    ]
  },
  "https://jmlr.org/papers/v12/hahsler11a.html": {
    "title": "The arules R-Package Ecosystem: Analyzing Interesting Patterns from Large Transaction Data Sets",
    "volume": "MLOSS",
    "abstract": "This paper describes the ecosystem of R add-on packages developed around the infrastructure provided by the package arules. The packages provide comprehensive functionality for analyzing interesting patterns including frequent itemsets, association rules, frequent sequences and for building applications like associative classification. After discussing the ecosystem's design we illustrate the ease of mining and visualizing rules with a short example",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Hahsler",
      "Sudheer Chelluboina",
      "Kurt Hornik",
      "Christian Buchta"
    ]
  }
}