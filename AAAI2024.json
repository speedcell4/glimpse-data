{
  "https://ojs.aaai.org/index.php/AAAI/article/view/27749": {
    "title": "A Multi-Modal Contrastive Diffusion Model for Therapeutic Peptide Generation",
    "volume": "main",
    "abstract": "Therapeutic peptides represent a unique class of pharmaceutical agents crucial for the treatment of human diseases. Recently, deep generative models have exhibited remarkable potential for generating therapeutic peptides, but they only utilize sequence or structure information alone, which hinders the performance in generation. In this study, we propose a Multi-Modal Contrastive Diffusion model (MMCD), fusing both sequence and structure modalities in a diffusion framework to co-generate novel peptide sequences and structures. Specifically, MMCD constructs the sequence-modal and structure-modal diffusion models, respectively, and devises a multi-modal contrastive learning strategy with inter-contrastive and intra-contrastive in each diffusion timestep, aiming to capture the consistency between two modalities and boost model performance. The inter-contrastive aligns sequences and structures of peptides by maximizing the agreement of their embeddings, while the intra-contrastive differentiates therapeutic and non-therapeutic peptides by maximizing the disagreement of their sequence/structure embeddings simultaneously. The extensive experiments demonstrate that MMCD performs better than other state-of-the-art deep generative methods in generating therapeutic peptides across various metrics, including antimicrobial/anticancer score, diversity, and peptide-docking",
    "checked": true,
    "id": "7bff7fd6b87f5ff024b86a52e98bf92acc893e2e",
    "semantic_title": "a multi-modal contrastive diffusion model for therapeutic peptide generation",
    "citation_count": 4,
    "authors": [
      "Yongkang  Wang",
      "Xuan Liu",
      "Feng Huang",
      "Zhankun Xiong",
      "Wen Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27750": {
    "title": "Towards Automated RISC-V Microarchitecture Design with Reinforcement Learning",
    "volume": "main",
    "abstract": "Microarchitecture determines the implementation of a microprocessor. Designing a microarchitecture to achieve better performance, power, and area (PPA) trade-off has been increasingly difficult. Previous data-driven methodologies hold inappropriate assumptions and lack more tightly coupling with expert knowledge. This paper proposes a novel reinforcement learning-based (RL) solution that addresses these limitations. With the integration of microarchitecture scaling graph, PPA preference space embedding, and proposed lightweight environment in RL, experiments using commercial electronic design automation (EDA) tools show that our method achieves an average PPA trade-off improvement of 16.03% than previous state-of-the-art approaches with 4.07× higher efficiency. The solution qualities outperform human implementations by at most 2.03× in the PPA trade-off",
    "checked": true,
    "id": "e40663dc5ab53bf665cec97d2d916332ca1aac9f",
    "semantic_title": "towards automated risc-v microarchitecture design with reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Chen Bai",
      "Jianwang Zhai",
      "Yuzhe Ma",
      "Bei Yu",
      "Martin D. F. Wong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27751": {
    "title": "Generating Novel Leads for Drug Discovery Using LLMs with Logical Feedback",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) can be used as repositories of biological and chemical information to generate pharmacological lead compounds. However, for LLMs to focus on specific drug targets typically requires experimentation with progressively more refined prompts. Results thus become dependent not just on what is known about the target, but also on what is known about the prompt- engineering. In this paper, we separate the prompt into domain-constraints that can be written in a standard logical form and a simple text-based query. We investigate whether LLMs can be guided, not by refining prompts manually, but by refining the logical component automatically, keeping the query unchanged. We describe an iterative procedure LMLF (\"Language Model with Logical Feedback\") in which the constraints are progressively refined using a logical notion of generalisation. On any iteration, newly generated instances are verified against the constraint, providing \"logical-feedback\" for the next iteration's refinement of the constraints. We evaluate LMLF using two well-known targets (inhibition of the Janus Kinase 2; and Dopamine Receptor D2); and two different LLMs (GPT-3 and PaLM). We show that LMLF, starting with the same logical constraints and query text, can be used to guide both LLMs to generate potential leads. We find: (a) Binding affinities of LMLF-generated molecules are skewed towards higher binding affinities than those from existing baselines; (b) LMLF results in generating molecules that are skewed towards higher binding affinities than without logical feedback; (c) Assessment by a computational chemist suggests that LMLF generated compounds may be novel inhibitors. These findings suggest that LLMs with logical feedback may provide a mechanism for generating new leads without requiring the domain-specialist to acquire sophisticated skills in prompt-engineering",
    "checked": true,
    "id": "3613299c54bbea66dd6db1b00573f7ade021a5a9",
    "semantic_title": "generating novel leads for drug discovery using llms with logical feedback",
    "citation_count": 1,
    "authors": [
      "Shreyas Bhat Brahmavar",
      "Ashwin Srinivasan",
      "Tirtharaj Dash",
      "Sowmya Ramaswamy Krishnan",
      "Lovekesh Vig",
      "Arijit Roy",
      "Raviprasad Aduri"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27752": {
    "title": "SeGA: Preference-Aware Self-Contrastive Learning with Prompts for Anomalous User Detection on Twitter",
    "volume": "main",
    "abstract": "In the dynamic and rapidly evolving world of social media, detecting anomalous users has become a crucial task to address malicious activities such as misinformation and cyberbullying. As the increasing number of anomalous users improves the ability to mimic normal users and evade detection, existing methods only focusing on bot detection are ineffective in terms of capturing subtle distinctions between users. To address these challenges, we proposed SeGA, preference-aware self-contrastive learning for anomalous user detection, which leverages heterogeneous entities and their relations in the Twittersphere to detect anomalous users with different malicious strategies. SeGA utilizes the knowledge of large language models to summarize user preferences via posts. In addition, integrating user preferences with prompts as pseudo-labels for preference-aware self-contrastive learning enables the model to learn multifaceted aspects for describing the behaviors of users. Extensive experiments on the proposed TwBNT benchmark demonstrate that SeGA significantly outperforms the state-of-the-art methods (+3.5% ∼ 27.6%) and empirically validate the effectiveness of the model design and pre-training strategies. Our code and data are publicly available at https://github.com/ying0409/SeGA",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ying-Ying Chang",
      "Wei-Yao Wang",
      "Wen-Chih Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27753": {
    "title": "Neural Embeddings for kNN Search in Biological Sequence",
    "volume": "main",
    "abstract": "Biological sequence nearest neighbor search plays a fundamental role in bioinformatics. To alleviate the pain of quadratic complexity for conventional distance computation, neural distance embeddings, which project sequences into geometric space, have been recognized as a promising paradigm. To maintain the distance order between sequences, these models all deploy triplet loss and use intuitive methods to select a subset of triplets for training from a vast selection space. However, we observed that such training often enables models to distinguish only a fraction of distance orders, leaving others unrecognized. Moreover, naively selecting more triplets for training under the state-of-the-art network not only adds costs but also hampers model performance. In this paper, we introduce Bio-kNN: a kNN search framework for biological sequences. It includes a systematic triplet selection method and a multi-head network, enhancing the discernment of all distance orders without increasing training expenses. Initially, we propose a clustering-based approach to partition all triplets into several clusters with similar properties, and then select triplets from these clusters using an innovative strategy. Meanwhile, we noticed that simultaneously training different types of triplets in the same network cannot achieve the expected performance, thus we propose a multi-head network to tackle this. Our network employs a convolutional neural network(CNN) to extract local features shared by all clusters, and then learns a multi-layer perception(MLP) head for each cluster separately. Besides, we treat CNN as a special head, thereby integrating crucial local features which are neglected in previous models into our model for similarity recognition. Extensive experiments show that our Bio-kNN significantly outperforms the state-of-the-art methods on two large-scale datasets without increasing the training cost",
    "checked": true,
    "id": "085a22b48db569992b1c900fccfa3fa8e276aaf7",
    "semantic_title": "neural embeddings for knn search in biological sequence",
    "citation_count": 1,
    "authors": [
      "Zhihao Chang",
      "Linzhu Yu",
      "Yanchao Xu",
      "Wentao Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27754": {
    "title": "i-Rebalance: Personalized Vehicle Repositioning for Supply Demand Balance",
    "volume": "main",
    "abstract": "Ride-hailing platforms have been facing the challenge of balancing demand and supply. Existing vehicle reposition techniques often treat drivers as homogeneous agents and relocate them deterministically, assuming compliance with the reposition. In this paper, we consider a more realistic and driver-centric scenario where drivers have unique cruising preferences and can decide whether to take the recommendation or not on their own. We propose i-Rebalance, a personalized vehicle reposition technique with deep reinforcement learning (DRL). i-Rebalance estimates drivers' decisions on accepting reposition recommendations through an on-field user study involving 99 real drivers. To optimize supply-demand balance and enhance preference satisfaction simultaneously, i-Rebalance has a sequential reposition strategy with dual DRL agents: Grid Agent to determine the reposition order of idle vehicles, and Vehicle Agent to provide personalized recommendations to each vehicle in the pre-defined order. This sequential learning strategy facilitates more effective policy training within a smaller action space compared to traditional joint-action methods. Evaluation of real-world trajectory data shows that i-Rebalance improves driver acceptance rate by 38.07% and total driver income by 9.97%",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyang Chen",
      "Peiyan Sun",
      "Qiyuan Song",
      "Wanyuan Wang",
      "Weiwei Wu",
      "Wencan Zhang",
      "Guanyu Gao",
      "Yan Lyu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27755": {
    "title": "GIN-SD: Source Detection in Graphs with Incomplete Nodes via Positional Encoding and Attentive Fusion",
    "volume": "main",
    "abstract": "Source detection in graphs has demonstrated robust efficacy in the domain of rumor source identification. Although recent solutions have enhanced performance by leveraging deep neural networks, they often require complete user data. In this paper, we address a more challenging task, rumor source detection with incomplete user data, and propose a novel framework, i.e., Source Detection in Graphs with Incomplete Nodes via Positional Encoding and Attentive Fusion (GIN-SD), to tackle this challenge. Specifically, our approach utilizes a positional embedding module to distinguish nodes that are incomplete and employs a self-attention mechanism to focus on nodes with greater information transmission capacity. To mitigate the prediction bias caused by the significant disparity between the numbers of source and non-source nodes, we also introduce a class-balancing mechanism. Extensive experiments validate the effectiveness of GIN-SD and its superiority to state-of-the-art methods",
    "checked": true,
    "id": "8f94d67d73e005ffd2a92fe3715c571bac8ddb6e",
    "semantic_title": "gin-sd: source detection in graphs with incomplete nodes via positional encoding and attentive fusion",
    "citation_count": 4,
    "authors": [
      "Le Cheng",
      "Peican Zhu",
      "Keke Tang",
      "Chao Gao",
      "Zhen Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27756": {
    "title": "Deep Quantum Error Correction",
    "volume": "main",
    "abstract": "Quantum error correction codes (QECC) are a key component for realizing the potential of quantum computing. QECC, as its classical counterpart (ECC), enables the reduction of error rates, by distributing quantum logical information across redundant physical qubits, such that errors can be detected and corrected. In this work, we efficiently train novel end-to-end deep quantum error decoders. We resolve the quantum measurement collapse by augmenting syndrome decoding to predict an initial estimate of the system noise, which is then refined iteratively through a deep neural network. The logical error rates calculated over finite fields are directly optimized via a differentiable objective, enabling efficient decoding under the constraints imposed by the code. Finally, our architecture is extended to support faulty syndrome measurement, by efficient decoding of repeated syndrome sampling. The proposed method demonstrates the power of neural decoders for QECC by achieving state-of-the-art accuracy, outperforming for small distance topological codes, the existing end-to-end neural and classical decoders, which are often computationally prohibitive",
    "checked": true,
    "id": "4ac64275768197f8cc4fce6df29e4b95b2fe23b1",
    "semantic_title": "deep quantum error correction",
    "citation_count": 5,
    "authors": [
      "Yoni Choukroun",
      "Lior Wolf"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27757": {
    "title": "Propagation Tree Is Not Deep: Adaptive Graph Contrastive Learning Approach for Rumor Detection",
    "volume": "main",
    "abstract": "Rumor detection on social media has become increasingly important. Most existing graph-based models presume rumor propagation trees (RPTs) have deep structures and learn sequential stance features along branches. However, through statistical analysis on real-world datasets, we find RPTs exhibit wide structures, with most nodes being shallow 1-level replies. To focus learning on intensive substructures, we propose Rumor Adaptive Graph Contrastive Learning (RAGCL) method with adaptive view augmentation guided by node centralities. We summarize three principles for RPT augmentation: 1) exempt root nodes, 2) retain deep reply nodes, 3) preserve lower-level nodes in deep sections. We employ node dropping, attribute masking and edge dropping with probabilities from centrality-based importance scores to generate views. A graph contrastive objective then learns robust rumor representations. Extensive experiments on four benchmark datasets demonstrate RAGCL outperforms state-of-the-art methods. Our work reveals the wide-structure nature of RPTs and contributes an effective graph contrastive learning approach tailored for rumor detection through principled adaptive augmentation. The proposed principles and augmentation techniques can potentially benefit other applications involving tree-structured graphs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoqun Cui",
      "Caiyan Jia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27758": {
    "title": "Prompt to Transfer: Sim-to-Real Transfer for Traffic Signal Control with Prompt Learning",
    "volume": "main",
    "abstract": "Numerous solutions are proposed for the Traffic Signal Control (TSC) tasks aiming to provide efficient transportation and alleviate traffic congestion. Recently, promising results have been attained by Reinforcement Learning (RL) methods through trial and error in simulators, bringing confidence in solving cities' congestion problems. However, performance gaps still exist when simulator-trained policies are deployed to the real world. This issue is mainly introduced by the system dynamic difference between the training simulators and the real-world environments. In this work, we leverage the knowledge of Large Language Models (LLMs) to understand and profile the system dynamics by a prompt-based grounded action transformation to bridge the performance gap. Specifically, this paper exploits the pre-trained LLM's inference ability to understand how traffic dynamics change with weather conditions, traffic states, and road types. Being aware of the changes, the policies' action is taken and grounded based on realistic dynamics, thus helping the agent learn a more realistic policy. We conduct experiments on four different scenarios to show the effectiveness of the proposed PromptGAT's ability to mitigate the performance gap of reinforcement learning from simulation to reality (sim-to-real)",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longchao Da",
      "Minquan Gao",
      "Hao Mei",
      "Hua Wei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27759": {
    "title": "Multitarget Device-Free Localization via Cross-Domain Wi-Fi RSS Training Data and Attentional Prior Fusion",
    "volume": "main",
    "abstract": "Device-free localization (DFL) using easily-obtained Wi-Fi received signal strength (RSS) has wide real-world applications for not requiring people to carry trackable devices. However, accurate multitarget DFL remains challenging due to the unknown number of targets, multipath interference (MPI), especially between nearby targets, and limited real-world data. In this study, we pioneeringly propose a transformer-based learning method with Wi-Fi RSS as input, and an attentional prior fusion module, to simultaneously locate an unknown number of people at random positions. To overcome the multitarget data collection challenges, we contribute a large-scale cross-domain real-simulation-augmentation training dataset with one and two real-world nearby non-person objects at limited positions and up to five simulated and augmented randomly distributed targets. Experimental results demonstrate our method's improved accuracy, generalization ability, and robustness with fewer Wi-Fi nodes than previous methods",
    "checked": true,
    "id": "149668484ebc0523ee24ac700fca8f3fcd7c06ba",
    "semantic_title": "multitarget device-free localization via cross-domain wi-fi rss training data and attentional prior fusion",
    "citation_count": 0,
    "authors": [
      "Na Fan",
      "Zeyue Tian",
      "Amartansh Dubey",
      "Samruddhi Deshmukh",
      "Ross Murch",
      "Qifeng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27760": {
    "title": "Heterogeneous Graph Reasoning for Fact Checking over Texts and Tables",
    "volume": "main",
    "abstract": "Fact checking aims to predict claim veracity by reasoning over multiple evidence pieces. It usually involves evidence retrieval and veracity reasoning. In this paper, we focus on the latter, reasoning over unstructured text and structured table information. Previous works have primarily relied on fine-tuning pretrained language models or training homogeneous-graph-based models. Despite their effectiveness, we argue that they fail to explore the rich semantic information underlying the evidence with different structures. To address this, we propose a novel word-level Heterogeneous-graph-based model for Fact Checking over unstructured and structured information, namely HeterFC. Our approach leverages a heterogeneous evidence graph, with words as nodes and thoughtfully designed edges representing different evidence properties. We perform information propagation via a relational graph neural network, facilitating interactions between claims and evidence. An attention-based method is utilized to integrate information, combined with a language model for generating predictions. We introduce a multitask loss function to account for potential inaccuracies in evidence retrieval. Comprehensive experiments on the large fact checking dataset FEVEROUS demonstrate the effectiveness of HeterFC. Code will be released at: https://github.com/Deno-V/HeterFC",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haisong Gong",
      "Weizhi Xu",
      "Shu Wu",
      "Qiang Liu",
      "Liang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27761": {
    "title": "Text-Guided Molecule Generation with Diffusion Language Model",
    "volume": "main",
    "abstract": "Text-guided molecule generation is a task where molecules are generated to match specific textual descriptions. Recently, most existing SMILES-based molecule generation methods rely on an autoregressive architecture. In this work, we propose the Text-Guided Molecule Generation with Diffusion Language Model (TGM-DLM), a novel approach that leverages diffusion models to address the limitations of autoregressive methods. TGM-DLM updates token embeddings within the SMILES string collectively and iteratively, using a two-phase diffusion generation process. The first phase optimizes embeddings from random noise, guided by the text description, while the second phase corrects invalid SMILES strings to form valid molecular representations. We demonstrate that TGM-DLM outperforms MolT5-Base, an autoregressive model, without the need for additional data resources. Our findings underscore the remarkable effectiveness of TGM-DLM in generating coherent and precise molecules with specific properties, opening new avenues in drug discovery and related scientific domains. Code will be released at: https://github.com/Deno-V/tgm-dlm",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haisong Gong",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27762": {
    "title": "Adversarial Robust Safeguard for Evading Deep Facial Manipulation",
    "volume": "main",
    "abstract": "The non-consensual exploitation of facial manipulation has emerged as a pressing societal concern. In tandem with the identification of such fake content, recent research endeavors have advocated countering manipulation techniques through proactive interventions, specifically the incorporation of adversarial noise to impede the manipulation in advance. Nevertheless, with insufficient consideration of robustness, we show that current methods falter in providing protection after simple perturbations, e.g., blur. In addition, traditional optimization-based methods face limitations in scalability as they struggle to accommodate the substantial expansion of data volume, a consequence of the time-intensive iterative pipeline. To solve these challenges, we propose a learning-based model, Adversarial Robust Safeguard (ARS), to generate desirable protection noise in a single forward process, concurrently exhibiting a heightened resistance against prevalent perturbations. Specifically, our method involves a two-way protection design, characterized by a basic protection component responsible for generating efficacious noise features, coupled with robust protection for further enhancement. In robust protection, we first fuse image features with spatially duplicated noise embedding, thereby accounting for inherent information redundancy. Subsequently, a combination comprising a differentiable perturbation module and an adversarial network is devised to simulate potential information degradation during the training process. To evaluate it, we conduct experiments on four manipulation methods and compare recent works comprehensively. The results of our method exhibit good visual effects with pronounced robustness against varied perturbations at different levels",
    "checked": true,
    "id": "14d3e2fb72ccec10a802a80abef043f627d7c9f7",
    "semantic_title": "adversarial robust safeguard for evading deep facial manipulation",
    "citation_count": 0,
    "authors": [
      "Jiazhi Guan",
      "Yi Zhao",
      "Zhuoer Xu",
      "Changhua Meng",
      "Ke Xu",
      "Youjian Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27763": {
    "title": "FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory Prediction Framework",
    "volume": "main",
    "abstract": "Flight Trajectory Prediction (FTP) is an essential task in Air Traffic Control (ATC), which can assist air traffic controllers in managing airspace more safely and efficiently. Existing approaches generally perform multi-horizon FTP tasks in an autoregressive manner, thereby suffering from error accumulation and low-efficiency problems. In this paper, a novel framework, called FlightBERT++, is proposed to i) forecast multi-horizon flight trajectories directly in a non-autoregressive way, and ii) improve the limitation of the binary encoding (BE) representation in the FlightBERT. Specifically, the FlightBERT++ is implemented by a generalized encoder-decoder architecture, in which the encoder learns the temporal-spatial patterns from historical observations and the decoder predicts the flight status for the future horizons. Compared with conventional architecture, an innovative horizon-aware contexts generator is dedicatedly designed to consider the prior horizon information, which further enables non-autoregressive multi-horizon prediction. Moreover, a differential prompted decoder is proposed to enhance the capability of the differential predictions by leveraging the stationarity of the differential sequence. The experimental results on a real-world dataset demonstrated that the FlightBERT++ outperformed the competitive baselines in both FTP performance and computational efficiency",
    "checked": false,
    "id": "23f20241ae62e8e882d4c835b2af746fd3f0a0f8",
    "semantic_title": "a non-autoregressive multi-horizon flight trajectory prediction framework with gray code representation",
    "citation_count": 0,
    "authors": [
      "Dongyue Guo",
      "Zheng Zhang",
      "Zhen Yan",
      "Jianwei Zhang",
      "Yi Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27764": {
    "title": "LogFormer: A Pre-train and Tuning Pipeline for Log Anomaly Detection",
    "volume": "main",
    "abstract": "Log anomaly detection is a key component in the field of artificial intelligence for IT operations (AIOps). Considering log data of variant domains, retraining the whole network for unknown domains is inefficient in real industrial scenarios. However, previous deep models merely focused on extracting the semantics of log sequences in the same domain, leading to poor generalization on multi-domain logs. To alleviate this issue, we propose a unified Transformer-based framework for Log anomaly detection (LogFormer) to improve the generalization ability across different domains, where we establish a two-stage process including the pre-training and adapter-based tuning stage. Specifically, our model is first pre-trained on the source domain to obtain shared semantic knowledge of log data. Then, we transfer such knowledge to the target domain via shared parameters. Besides, the Log-Attention module is proposed to supplement the information ignored by the log-paring. The proposed method is evaluated on three public datasets and one real-world dataset. Experimental results on multiple benchmarks demonstrate the effectiveness of our LogFormer with fewer trainable parameters and lower training costs",
    "checked": true,
    "id": "c08a65e47b13c52744b6564e39c0e7c8f32a2074",
    "semantic_title": "logformer: a pre-train and tuning pipeline for log anomaly detection",
    "citation_count": 5,
    "authors": [
      "Hongcheng Guo",
      "Jian Yang",
      "Jiaheng Liu",
      "Jiaqi Bai",
      "Boyang Wang",
      "Zhoujun Li",
      "Tieqiao Zheng",
      "Bo Zhang",
      "Junran Peng",
      "Qi Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27765": {
    "title": "ContraNovo: A Contrastive Learning Approach to Enhance De Novo Peptide Sequencing",
    "volume": "main",
    "abstract": "De novo peptide sequencing from mass spectrometry (MS) data is a critical task in proteomics research. Traditional de novo algorithms have encountered a bottleneck in accuracy due to the inherent complexity of proteomics data. While deep learning-based methods have shown progress, they reduce the problem to a translation task, potentially overlooking critical nuances between spectra and peptides. In our research, we present ContraNovo, a pioneering algorithm that leverages contrastive learning to extract the relationship between spectra and peptides and incorporates the mass information into peptide decoding, aiming to address these intricacies more efficiently. Through rigorous evaluations on two benchmark datasets, ContraNovo consistently outshines contemporary state-of-the-art solutions, underscoring its promising potential in enhancing de novo peptide sequencing",
    "checked": true,
    "id": "8c75eeee40678d237b421d0a86ac735519f12052",
    "semantic_title": "contranovo: a contrastive learning approach to enhance de novo peptide sequencing",
    "citation_count": 3,
    "authors": [
      "Zhi Jin",
      "Sheng Xu",
      "Xiang Zhang",
      "Tianze Ling",
      "Nanqing Dong",
      "Wanli Ouyang",
      "Zhiqiang Gao",
      "Cheng Chang",
      "Siqi Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27766": {
    "title": "Inducing Point Operator Transformer: A Flexible and Scalable Architecture for Solving PDEs",
    "volume": "main",
    "abstract": "Solving partial differential equations (PDEs) by learning the solution operators has emerged as an attractive alternative to traditional numerical methods. However, implementing such architectures presents two main challenges: flexibility in handling irregular and arbitrary input and output formats and scalability to large discretizations. Most existing architectures are limited by their desired structure or infeasible to scale large inputs and outputs. To address these issues, we introduce an attention-based model called an inducing point operator transformer (IPOT). Inspired by inducing points methods, IPOT is designed to handle any input function and output query while capturing global interactions in a computationally efficient way. By detaching the inputs/outputs discretizations from the processor with a smaller latent bottleneck, IPOT offers flexibility in processing arbitrary discretizations and scales linearly with the size of inputs/outputs. Our experimental results demonstrate that IPOT achieves strong performances with manageable computational complexity on an extensive range of PDE benchmarks and real-world weather forecasting scenarios, compared to state-of-the-art methods. Our code is publicly available at https://github.com/7tl7qns7ch/IPOT",
    "checked": true,
    "id": "746a06cd30f62841f9b5ff6d276bee5bb7171fc0",
    "semantic_title": "inducing point operator transformer: a flexible and scalable architecture for solving pdes",
    "citation_count": 1,
    "authors": [
      "Seungjun Lee",
      "TaeiL Oh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27767": {
    "title": "MASTER: Market-Guided Stock Transformer for Stock Price Forecasting",
    "volume": "main",
    "abstract": "Stock price forecasting has remained an extremely challenging problem for many decades due to the high volatility of the stock market. Recent efforts have been devoted to modeling complex stock correlations toward joint stock price forecasting. Existing works share a common neural architecture that learns temporal patterns from individual stock series and then mixes up temporal representations to establish stock correlations. However, they only consider time-aligned stock correlations stemming from all the input stock features, which suffer from two limitations. First, stock correlations often occur momentarily and in a cross-time manner. Second, the feature effectiveness is dynamic with market variation, which affects both the stock sequential patterns and their correlations. To address the limitations, this paper introduces MASTER, a MArkert-guided Stock TransformER, which models the momentary and cross-time stock correlation and leverages market information for automatic feature selection. MASTER elegantly tackles the complex stock correlation by alternatively engaging in intra-stock and inter-stock information aggregation. Experiments show the superiority of MASTER compared with previous works and visualize the captured realistic stock correlation to provide valuable insights",
    "checked": true,
    "id": "39e25ace0b75852b33b2d34f9d99ed77f959060f",
    "semantic_title": "master: market-guided stock transformer for stock price forecasting",
    "citation_count": 0,
    "authors": [
      "Tong Li",
      "Zhaoyang Liu",
      "Yanyan Shen",
      "Xue Wang",
      "Haokun Chen",
      "Sen Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27768": {
    "title": "Learning from Polar Representation: An Extreme-Adaptive Model for Long-Term Time Series Forecasting",
    "volume": "main",
    "abstract": "In the hydrology field, time series forecasting is crucial for efficient water resource management, improving flood and drought control and increasing the safety and quality of life for the general population. However, predicting long-term streamflow is a complex task due to the presence of extreme events. It requires the capture of long-range dependencies and the modeling of rare but important extreme values. Existing approaches often struggle to tackle these dual challenges simultaneously. In this paper, we specifically delve into these issues and propose Distance-weighted Auto-regularized Neural network (DAN), a novel extreme-adaptive model for long-range forecasting of stremflow enhanced by polar representation learning. DAN utilizes a distance-weighted multi-loss mechanism and stackable blocks to dynamically refine indicator sequences from exogenous data, while also being able to handle uni-variate time-series by employing Gaussian Mixture probability modeling to improve robustness to severe events. We also introduce Kruskal-Wallis sampling and gate control vectors to handle imbalanced extreme data. On four real-life hydrologic streamflow datasets, we demonstrate that DAN significantly outperforms both state-of-the-art hydrologic time series prediction methods and general methods designed for long-term time series prediction",
    "checked": true,
    "id": "68f99f76e8d12a92a23a1fc2c489753b50aa481f",
    "semantic_title": "learning from polar representation: an extreme-adaptive model for long-term time series forecasting",
    "citation_count": 2,
    "authors": [
      "Yanhong Li",
      "Jack Xu",
      "David Anastasiu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27769": {
    "title": "The Causal Impact of Credit Lines on Spending Distributions",
    "volume": "main",
    "abstract": "Consumer credit services offered by electronic commerce platforms provide customers with convenient loan access during shopping and have the potential to stimulate sales. To understand the causal impact of credit lines on spending, previous studies have employed causal estimators, (e.g., direct regression (DR), inverse propensity weighting (IPW), and double machine learning (DML)) to estimate the treatment effect. However, these estimators do not treat the spending of each individual as a distribution that can capture the range and pattern of amounts spent across different orders. By disregarding the outcome as a distribution, valuable insights embedded within the outcome distribution might be overlooked. This paper thus develops distribution valued estimators which extend from existing real valued DR, IPW, and DML estimators within Rubin's causal framework. We establish their consistency and apply them to a real dataset from a large electronic commerce platform. Our findings reveal that credit lines generally have a positive impact on spending across all quantiles, but consumers would allocate more to luxuries (higher quantiles) than necessities (lower quantiles) as credit lines increase",
    "checked": true,
    "id": "779717183d8acf988605e7418f30a0708c455b6e",
    "semantic_title": "the causal impact of credit lines on spending distributions",
    "citation_count": 0,
    "authors": [
      "Yijun Li",
      "Cheuk Hang Leung",
      "Xiangqian Sun",
      "Chaoqun Wang",
      "Yiyan Huang",
      "Xing Yan",
      "Qi Wu",
      "Dongdong Wang",
      "Zhixiang Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27770": {
    "title": "Improving PTM Site Prediction by Coupling of Multi-Granularity Structure and Multi-Scale Sequence Representation",
    "volume": "main",
    "abstract": "Protein post-translational modification (PTM) site prediction is a fundamental task in bioinformatics. Several computational methods have been developed to predict PTM sites. However, existing methods ignore the structure information and merely utilize protein sequences. Furthermore, designing a more fine-grained structure representation learning method is urgently needed as PTM is a biological event that occurs at the atom granularity. In this paper, we propose a PTM site prediction method by Coupling of Multi-Granularity structure and Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically, multigranularity structure-aware representation learning is designed to learn neighborhood structure representations at the amino acid, atom, and whole protein granularity from AlphaFold predicted structures, followed by utilizing contrastive learning to optimize the structure representations. Additionally, multi-scale sequence representation learning is used to extract context sequence information, and motif generated by aligning all context sequences of PTM sites assists the prediction. Extensive experiments on three datasets show that PTM-CMGMS outperforms the state-of-the-art methods. Source code can be found at https://github.com/LZY-HZAU/PTM-CMGMS",
    "checked": true,
    "id": "a2a1041ddb2b46ef315dcb3658981fdf6b5ab242",
    "semantic_title": "improving ptm site prediction by coupling of multi-granularity structure and multi-scale sequence representation",
    "citation_count": 0,
    "authors": [
      "Zhengyi Li",
      "Menglu Li",
      "Lida Zhu",
      "Wen Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27771": {
    "title": "Joint Learning Neuronal Skeleton and Brain Circuit Topology with Permutation Invariant Encoders for Neuron Classification",
    "volume": "main",
    "abstract": "Determining the types of neurons within a nervous system plays a significant role in the analysis of brain connectomics and the investigation of neurological diseases. However, the efficiency of utilizing anatomical, physiological, or molecular characteristics of neurons is relatively low and costly. With the advancements in electron microscopy imaging and analysis techniques for brain tissue, we are able to obtain whole-brain connectome consisting neuronal high-resolution morphology and connectivity information. However, few models are built based on such data for automated neuron classification. In this paper, we propose NeuNet, a framework that combines morphological information of neurons obtained from skeleton and topological information between neurons obtained from neural circuit. Specifically, NeuNet consists of three components, namely Skeleton Encoder, Connectome Encoder, and Readout Layer. Skeleton Encoder integrates the local information of neurons in a bottom-up manner, with a one-dimensional convolution in neural skeleton's point data; Connectome Encoder uses a graph neural network to capture the topological information of neural circuit; finally, Readout Layer fuses the above two information and outputs classification results. We reprocess and release two new datasets for neuron classification task from volume electron microscopy(VEM) images of human brain cortex and Drosophila brain. Experiments on these two datasets demonstrated the effectiveness of our model with accuracies of 0.9169 and 0.9363, respectively. Code and data are available at: https://github.com/WHUminghui/NeuNet",
    "checked": true,
    "id": "4e514969bdf8fe28825d7497eedd562f37ba866b",
    "semantic_title": "joint learning neuronal skeleton and brain circuit topology with permutation invariant encoders for neuron classification",
    "citation_count": 0,
    "authors": [
      "Minghui Liao",
      "Guojia Wan",
      "Bo Du"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27772": {
    "title": "Root Cause Analysis in Microservice Using Neural Granger Causal Discovery",
    "volume": "main",
    "abstract": "In recent years, microservices have gained widespread adoption in IT operations due to their scalability, maintenance, and flexibility. However, it becomes challenging for site reliability engineers (SREs) to pinpoint the root cause due to the complex relationship in microservices when facing system malfunctions. Previous research employed structure learning methods (e.g., PC-algorithm) to establish causal relationships and derive root causes from causal graphs. Nevertheless, they ignored the temporal order of time series data and failed to leverage the rich information inherent in the temporal relationships. For instance, in cases where there is a sudden spike in CPU utilization, it can lead to an increase in latency for other microservices. However, in this scenario, the anomaly in CPU utilization occurs before the latency increases, rather than simultaneously. As a result, the PC-algorithm fails to capture such characteristics. To address these challenges, we propose RUN, a novel approach for root cause analysis using neural Granger causal discovery with contrastive learning. RUN enhances the backbone encoder by integrating contextual information from time series and leverages a time series forecasting model to conduct neural Granger causal discovery. In addition, RUN incorporates Pagerank with a personalization vector to efficiently recommend the top-k root causes. Extensive experiments conducted on the synthetic and real-world microservice-based datasets demonstrate that RUN noticeably outperforms the state-of-the-art root cause analysis methods. Moreover, we provide an analysis scenario for the sock-shop case to showcase the practicality and efficacy of RUN in microservice-based applications. Our code is publicly available at https://github.com/zmlin1998/RUN",
    "checked": true,
    "id": "6c21d49b193b59f84168d02f86db8b8c4c3290a7",
    "semantic_title": "root cause analysis in microservice using neural granger causal discovery",
    "citation_count": 2,
    "authors": [
      "Cheng-Ming Lin",
      "Ching Chang",
      "Wei-Yao Wang",
      "Kuang-Da Wang",
      "Wen-Chih Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27773": {
    "title": "Model-Driven Deep Neural Network for Enhanced AoA Estimation Using 5G gNB",
    "volume": "main",
    "abstract": "High-accuracy positioning has become a fundamental enabler for intelligent connected devices. Nevertheless, the present wireless networks still rely on model-driven approaches to achieve positioning functionality, which are susceptible to performance degradation in practical scenarios, primarily due to hardware impairments. Integrating artificial intelligence into the positioning framework presents a promising solution to revolutionize the accuracy and robustness of location-based services. In this study, we address this challenge by reformulating the problem of angle-of-arrival (AoA) estimation into image reconstruction of spatial spectrum. To this end, we design a model-driven deep neural network (MoD-DNN), which can automatically calibrate the angular-dependent phase error. The proposed MoD-DNN approach employs an iterative optimization scheme between a convolutional neural network and a sparse conjugate gradient algorithm. Simulation and experimental results are presented to demonstrate the effectiveness of the proposed method in enhancing spectrum calibration and AoA estimation",
    "checked": true,
    "id": "3ce02e3d620a5c2c3c94d20a9a344d380e4be86c",
    "semantic_title": "model-driven deep neural network for enhanced aoa estimation using 5g gnb",
    "citation_count": 1,
    "authors": [
      "Shengheng Liu",
      "Xingkang Li",
      "Zihuan Mao",
      "Peng Liu",
      "Yongming Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27774": {
    "title": "MID-FiLD: MIDI Dataset for Fine-Level Dynamics",
    "volume": "main",
    "abstract": "One of the challenges in generating human-like music is articulating musical expressions such as dynamics, phrasing, and timbre, which are difficult for computational models to mimic. Previous efforts to tackle this problem have been insufficient due to a fundamental lack of data containing information about musical expressions. In this paper, we introduce MID-FiLD, a MIDI dataset for learning fine-level dynamics control. Notable properties of MID-FiLD are as follows: (1) All 4,422 MIDI samples are constructed by professional music writers with a strong understanding of composition and musical expression. (2) Each MIDI sample contains four different musical metadata and control change \\#1 (CC\\#1) value. We verify that our metadata is a key factor in MID-FiLD, exerting a substantial influence over produced CC\\#1 values. In addition, we demonstrate the applicability of MID-FiLD to deep learning models by suggesting a token-based encoding methodology and reveal the potential for generating controllable, human-like musical expressions",
    "checked": true,
    "id": "b728b5b082a6a615001f23a993051cca7a7d39ba",
    "semantic_title": "mid-fild: midi dataset for fine-level dynamics",
    "citation_count": 0,
    "authors": [
      "Jesung Ryu",
      "Seungyeon Rhyu",
      "Hong-Gyu Yoon",
      "Eunchong Kim",
      "Ju Young Yang",
      "Taehyun Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27775": {
    "title": "PosDiffNet: Positional Neural Diffusion for Point Cloud Registration in a Large Field of View with Perturbations",
    "volume": "main",
    "abstract": "Point cloud registration is a crucial technique in 3D computer vision with a wide range of applications. However, this task can be challenging, particularly in large fields of view with dynamic objects, environmental noise, or other perturbations. To address this challenge, we propose a model called PosDiffNet. Our approach performs hierarchical registration based on window-level, patch-level, and point-level correspondence. We leverage a graph neural partial differential equation (PDE) based on Beltrami flow to obtain high-dimensional features and position embeddings for point clouds. We incorporate position embeddings into a Transformer module based on a neural ordinary differential equation (ODE) to efficiently represent patches within points. We employ the multi-level correspondence derived from the high feature similarity scores to facilitate alignment between point clouds. Subsequently, we use registration methods such as SVD-based algorithms to predict the transformation using corresponding point pairs. We evaluate PosDiffNet on several 3D point cloud datasets, verifying that it achieves state-of-the-art (SOTA) performance for point cloud registration in large fields of view with perturbations. The implementation code of experiments is available at https://github.com/AI-IT-AVs/PosDiffNet",
    "checked": true,
    "id": "f2b0748a078578c89e6d34c681c494960adf9200",
    "semantic_title": "posdiffnet: positional neural diffusion for point cloud registration in a large field of view with perturbations",
    "citation_count": 1,
    "authors": [
      "Rui She",
      "Sijie Wang",
      "Qiyu Kang",
      "Kai Zhao",
      "Yang Song",
      "Wee Peng Tay",
      "Tianyu Geng",
      "Xingchao Jian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27776": {
    "title": "StegaStyleGAN: Towards Generic and Practical Generative Image Steganography",
    "volume": "main",
    "abstract": "The recent advances in generative image steganography have drawn increasing attention due to their potential for provable security and bulk embedding capacity. However, existing generative steganographic schemes are usually tailored for specific tasks and are hardly applied to applications with practical constraints. To address this issue, this paper proposes a generic generative image steganography scheme called Steganography StyleGAN (StegaStyleGAN) that meets the practical objectives of security, capacity, and robustness within the same framework. In StegaStyleGAN, a novel Distribution-Preserving Secret Data Modulator (DP-SDM) is used to achieve provably secure generative image steganography by preserving the data distribution of the model inputs. Additionally, a generic and efficient Secret Data Extractor (SDE) is invented for accurate secret data extraction. By choosing whether to incorporate the Image Attack Simulator (IAS) during the training process, one can obtain two models with different parameters but the same structure (both generator and extractor) for lossless and lossy channel covert communication, namely StegaStyleGAN-Ls and StegaStyleGAN-Ly. Furthermore, by mating with GAN inversion, conditional generative steganography can be achieved as well. Experimental results demonstrate that, whether for lossless or lossy communication channels, the proposed StegaStyleGAN can significantly outperform the corresponding state-of-the-art schemes",
    "checked": true,
    "id": "252144c3d461ee85eda8327f6d8a3bd2562e8ee4",
    "semantic_title": "stegastylegan: towards generic and practical generative image steganography",
    "citation_count": 2,
    "authors": [
      "Wenkang Su",
      "Jiangqun Ni",
      "Yiyan Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27777": {
    "title": "Dual-Channel Learning Framework for Drug-Drug Interaction Prediction via Relation-Aware Heterogeneous Graph Transformer",
    "volume": "main",
    "abstract": "Identifying novel drug-drug interactions (DDIs) is a crucial task in pharmacology, as the interference between pharmacological substances can pose serious medical risks. In recent years, several network-based techniques have emerged for predicting DDIs. However, they primarily focus on local structures within DDI-related networks, often overlooking the significance of indirect connections between pairwise drug nodes from a global perspective. Additionally, effectively handling heterogeneous information present in both biomedical knowledge graphs and drug molecular graphs remains a challenge for improved performance of DDI prediction. To address these limitations, we propose a Transformer-based relatIon-aware Graph rEpresentation leaRning framework (TIGER) for DDI prediction. TIGER leverages the Transformer architecture to effectively exploit the structure of heterogeneous graph, which allows it direct learning of long dependencies and high-order structures. Furthermore, TIGER incorporates a relation-aware self-attention mechanism, capturing a diverse range of semantic relations that exist between pairs of nodes in heterogeneous graph. In addition to these advancements, TIGER enhances predictive accuracy by modeling DDI prediction task using a dual-channel network, where drug molecular graph and biomedical knowledge graph are fed into two respective channels. By incorporating embeddings obtained at graph and node levels, TIGER can benefit from structural properties of drugs as well as rich contextual information provided by biomedical knowledge graph. Extensive experiments conducted on three real-world datasets demonstrate the effectiveness of TIGER in DDI prediction. Furthermore, case studies highlight its ability to provide a deeper understanding of underlying mechanisms of DDIs",
    "checked": true,
    "id": "89e5bf14cc692c44e1bb58c31d4ed7ad5f72ce5e",
    "semantic_title": "dual-channel learning framework for drug-drug interaction prediction via relation-aware heterogeneous graph transformer",
    "citation_count": 0,
    "authors": [
      "Xiaorui Su",
      "Pengwei Hu",
      "Zhu-Hong You",
      "Philip S. Yu",
      "Lun Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27778": {
    "title": "Molecular Optimization Model with Patentability Constraint",
    "volume": "main",
    "abstract": "In drug development, molecular optimization is a crucial challenge that involves generating novel molecules given a lead molecule as input. The task requires maintaining molecular similarity to the original molecule while simultaneously optimizing multiple chemical attributes. To aid in this process, numerous generative models have been proposed. However, in practical applications, it is crucial for these models not only to generate novel molecules with the above constraints but also to generate molecules that significantly differ from any existing patented compounds. In this work, we present a multi-optimization molecular framework to address this challenge. Our framework trains a model to prioritize both enhanced properties and substantial dissimilarity from patented compounds. By jointly learning continuous representations of optimized and patentable molecules, we ensure that the generated molecules are significantly distant from any patented compounds while improving chemical properties. Through empirical evaluation, we demonstrate the superior performance of our approach compared to state-of-the-art molecular optimization methods both in chemical property optimization and patentability",
    "checked": true,
    "id": "6be7d6083e11f5c6b105d78b349998fc4c536af9",
    "semantic_title": "molecular optimization model with patentability constraint",
    "citation_count": 0,
    "authors": [
      "Sally Turutov",
      "Kira Radinsky"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27779": {
    "title": "Generalizable Sleep Staging via Multi-Level Domain Alignment",
    "volume": "main",
    "abstract": "Automatic sleep staging is essential for sleep assessment and disorder diagnosis. Most existing methods depend on one specific dataset and are limited to be generalized to other unseen datasets, for which the training data and testing data are from the same dataset. In this paper, we introduce domain generalization into automatic sleep staging and propose the task of generalizable sleep staging which aims to improve the model generalization ability to unseen datasets. Inspired by existing domain generalization methods, we adopt the feature alignment idea and propose a framework called SleepDG to solve it. Considering both of local salient features and sequential features are important for sleep staging, we propose a Multi-level Feature Alignment combining epoch-level and sequence-level feature alignment to learn domain-invariant feature representations. Specifically, we design an Epoch-level Feature Alignment to align the feature distribution of each single sleep epoch among different domains, and a Sequence-level Feature Alignment to minimize the discrepancy of sequential features among different domains. SleepDG is validated on five public datasets, achieving the state-of-the-art performance",
    "checked": true,
    "id": "286804dedf5a8d954b1858f39f67ec9ac8a138e0",
    "semantic_title": "generalizable sleep staging via multi-level domain alignment",
    "citation_count": 3,
    "authors": [
      "Jiquan Wang",
      "Sha Zhao",
      "Haiteng Jiang",
      "Shijian Li",
      "Tao Li",
      "Gang Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27780": {
    "title": "Inspecting Prediction Confidence for Detecting Black-Box Backdoor Attacks",
    "volume": "main",
    "abstract": "Backdoor attacks have been shown to be a serious security threat against deep learning models, and various defenses have been proposed to detect whether a model is backdoored or not. However, as indicated by a recent black-box attack, existing defenses can be easily bypassed by implanting the backdoor in the frequency domain. To this end, we propose a new defense DTInspector against black-box backdoor attacks, based on a new observation related to the prediction confidence of learning models. That is, to achieve a high attack success rate with a small amount of poisoned data, backdoor attacks usually render a model exhibiting statistically higher prediction confidences on the poisoned samples. We provide both theoretical and empirical evidence for the generality of this observation. DTInspector then carefully examines the prediction confidences of data samples, and decides the existence of backdoor using the shortcut nature of backdoor triggers. Extensive evaluations on six backdoor attacks, four datasets, and three advanced attacking types demonstrate the effectiveness of the proposed defense",
    "checked": true,
    "id": "8675b3c6725d148a72c61c59d890b0624941cfda",
    "semantic_title": "inspecting prediction confidence for detecting black-box backdoor attacks",
    "citation_count": 2,
    "authors": [
      "Tong Wang",
      "Yuan Yao",
      "Feng Xu",
      "Miao Xu",
      "Shengwei An",
      "Ting Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27781": {
    "title": "Conformal Crystal Graph Transformer with Robust Encoding of Periodic Invariance",
    "volume": "main",
    "abstract": "Machine learning techniques, especially in the realm of materials design, hold immense promise in predicting the properties of crystal materials and aiding in the discovery of novel crystals with desirable traits. However, crystals possess unique geometric constraints—namely, E(3) invariance for primitive cell and periodic invariance—which need to be accurately reflected in crystal representations. Though past research has explored various construction techniques to preserve periodic invariance in crystal representations, their robustness remains inadequate. Furthermore, effectively capturing angular information within 3D crystal structures continues to pose a significant challenge for graph-based approaches. This study introduces novel solutions to these challenges. We first present a graph construction method that robustly encodes periodic invariance and a strategy to capture angular information in neural networks without compromising efficiency. We further introduce CrystalFormer, a pioneering graph transformer architecture that emphasizes angle preservation and enhances long-range information. Through comprehensive evaluation, we verify our model's superior performance in 5 crystal prediction tasks, reaffirming the efficiency of our proposed methods",
    "checked": true,
    "id": "602e4b2301d49f5cbe310b64381ccca81cbc8236",
    "semantic_title": "conformal crystal graph transformer with robust encoding of periodic invariance",
    "citation_count": 0,
    "authors": [
      "Yingheng Wang",
      "Shufeng Kong",
      "John M. Gregoire",
      "Carla P. Gomes"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27782": {
    "title": "SuperJunction: Learning-Based Junction Detection for Retinal Image Registration",
    "volume": "main",
    "abstract": "Keypoints-based approaches have shown to be promising for retinal image registration, which superimpose two or more images from different views based on keypoint detection and description. However, existing approaches suffer from ineffective keypoint detector and descriptor training. Meanwhile, the non-linear mapping from 3D retinal structure to 2D images is often neglected. In this paper, we propose a novel learning-based junction detection approach for retinal image registration, which enhances both the keypoint detector and descriptor training. To improve the keypoint detection, it uses a multi-task vessel detection to regularize the model training, which helps to learn more representative features and reduce the risk of over-fitting. To achieve effective training for keypoints description, a new constrained negative sampling approach is proposed to compute the descriptor loss. Moreover, we also consider the non-linearity between retinal images from different views during matching. Experimental results on FIRE dataset show that our method achieves mean area under curve of 0.850, which is 12.6% higher than 0.755 by the state-of-the-art method. All the codes are available at https://github.com/samjcheng/SuperJunction",
    "checked": true,
    "id": "751cddda211f515ea023476f462efffa71af574b",
    "semantic_title": "superjunction: learning-based junction detection for retinal image registration",
    "citation_count": 0,
    "authors": [
      "Yu Wang",
      "Xiaoye Wang",
      "Zaiwang Gu",
      "Weide Liu",
      "Wee Siong Ng",
      "Weimin Huang",
      "Jun Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27783": {
    "title": "Explore 3D Dance Generation via Reward Model from Automatically-Ranked Demonstrations",
    "volume": "main",
    "abstract": "This paper presents an Exploratory 3D Dance generation framework, E3D2, designed to address the exploration capability deficiency in existing music-conditioned 3D dance generation models. Current models often generate monotonous and simplistic dance sequences that misalign with human preferences because they lack exploration capabilities.The E3D2 framework involves a reward model trained from automatically-ranked dance demonstrations, which then guides the reinforcement learning process. This approach encourages the agent to explore and generate high quality and diverse dance movement sequences. The soundness of the reward model is both theoretically and experimentally validated. Empirical experiments demonstrate the effectiveness of E3D2 on the AIST++ dataset",
    "checked": true,
    "id": "fc877df6237b38ed90aa022a1b373c64c21dbd0c",
    "semantic_title": "explore 3d dance generation via reward model from automatically-ranked demonstrations",
    "citation_count": 2,
    "authors": [
      "Zilin Wang",
      "Haolin Zhuang",
      "Lu Li",
      "Yinmin Zhang",
      "Junjie Zhong",
      "Jun Chen",
      "Yu Yang",
      "Boshi Tang",
      "Zhiyong Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27784": {
    "title": "PSC-CPI: Multi-Scale Protein Sequence-Structure Contrasting for Efficient and Generalizable Compound-Protein Interaction Prediction",
    "volume": "main",
    "abstract": "Compound-Protein Interaction (CPI) prediction aims to predict the pattern and strength of compound-protein interactions for rational drug discovery. Existing deep learning-based methods utilize only the single modality of protein sequences or structures and lack the co-modeling of the joint distribution of the two modalities, which may lead to significant performance drops in complex real-world scenarios due to various factors, e.g., modality missing and domain shifting. More importantly, these methods only model protein sequences and structures at a single fixed scale, neglecting more fine-grained multi-scale information, such as those embedded in key protein fragments. In this paper, we propose a novel multi-scale Protein Sequence-structure Contrasting framework for CPI prediction (PSC-CPI), which captures the dependencies between protein sequences and structures through both intra-modality and cross-modality contrasting. We further apply length-variable protein augmentation to allow contrasting to be performed at different scales, from the amino acid level to the sequence level. Finally, in order to more fairly evaluate the model generalizability, we split the test data into four settings based on whether compounds and proteins have been observed during the training stage. Extensive experiments have shown that PSC-CPI generalizes well in all four settings, particularly in the more challenging ``Unseen-Both\" setting, where neither compounds nor proteins have been observed during training. Furthermore, even when encountering a situation of modality missing, i.e., inference with only single-modality protein data, PSC-CPI still exhibits comparable or even better performance than previous approaches",
    "checked": true,
    "id": "a97a09ed17da5aa3499cb5b72a6b7b1ecbd7a0f9",
    "semantic_title": "psc-cpi: multi-scale protein sequence-structure contrasting for efficient and generalizable compound-protein interaction prediction",
    "citation_count": 7,
    "authors": [
      "Lirong Wu",
      "Yufei Huang",
      "Cheng Tan",
      "Zhangyang Gao",
      "Bozhen Hu",
      "Haitao Lin",
      "Zicheng Liu",
      "Stan Z. Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27785": {
    "title": "Uncertainty Quantification for Forward and Inverse Problems of PDEs via Latent Global Evolution",
    "volume": "main",
    "abstract": "Deep learning-based surrogate models have demonstrated remarkable advantages over classical solvers in terms of speed, often achieving speedups of 10 to 1000 times over traditional partial differential equation (PDE) solvers. However, a significant challenge hindering their widespread adoption in both scientific and industrial domains is the lack of understanding about their prediction uncertainties, particularly in scenarios that involve critical decision making. To address this limitation, we propose a method that integrates efficient and precise uncertainty quantification into a deep learning-based surrogate model. Our method, termed Latent Evolution of PDEs with Uncertainty Quantification (LE-PDE-UQ), endows deep learning-based surrogate models with robust and efficient uncertainty quantification capabilities for both forward and inverse problems. LE-PDE-UQ leverages latent vectors within a latent space to evolve both the system's state and its corresponding uncertainty estimation. The latent vectors are decoded to provide predictions for the system's state as well as estimates of its uncertainty. In extensive experiments, we demonstrate the accurate uncertainty quantification performance of our approach, surpassing that of strong baselines including deep ensembles, Bayesian neural network layers, and dropout. Our method excels at propagating uncertainty over extended auto-regressive rollouts, making it suitable for scenarios involving long-term predictions. Our code is available at: https://github.com/AI4Science-WestlakeU/le-pde-uq",
    "checked": true,
    "id": "6f97392e270b594cbc3e8e1b28df9f5df3644017",
    "semantic_title": "uncertainty quantification for forward and inverse problems of pdes via latent global evolution",
    "citation_count": 0,
    "authors": [
      "Tailin Wu",
      "Willie Neiswanger",
      "Hongtao Zheng",
      "Stefano Ermon",
      "Jure Leskovec"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27786": {
    "title": "Multilevel Attention Network with Semi-supervised Domain Adaptation for Drug-Target Prediction",
    "volume": "main",
    "abstract": "Prediction of drug-target interactions (DTIs) is a crucial step in drug discovery, and deep learning methods have shown great promise on various DTI datasets. However, existing approaches still face several challenges, including limited labeled data, hidden bias issue, and a lack of generalization ability to out-of-domain data. These challenges hinder the model's capacity to learn truly informative interaction features, leading to shortcut learning and inferior predictive performance on novel drug-target pairs. To address these issues, we propose MlanDTI, a semi-supervised domain adaptive multilevel attention network (Mlan) for DTI prediction. We utilize two pre-trained BERT models to acquire bidirectional representations enriched with information from unlabeled data. Then, we introduce a multilevel attention mechanism, enabling the model to learn domain-invariant DTIs at different hierarchical levels. Moreover, we present a simple yet effective semi-supervised pseudo-labeling method to further enhance our model's predictive ability in cross-domain scenarios. Experiments on four datasets show that MlanDTI achieves state-of-the-art performances over other methods under intra-domain settings and outperforms all other approaches under cross-domain settings. The source code is available at https://github.com/CMACH508/MlanDTI",
    "checked": true,
    "id": "da523e004d5375958f0c7bb4b2559aa7e43dd84c",
    "semantic_title": "multilevel attention network with semi-supervised domain adaptation for drug-target prediction",
    "citation_count": 0,
    "authors": [
      "Zhousan Xie",
      "Shikui Tu",
      "Lei Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27787": {
    "title": "Geometric-Facilitated Denoising Diffusion Model for 3D Molecule Generation",
    "volume": "main",
    "abstract": "Denoising diffusion models have shown great potential in multiple research areas. Existing diffusion-based generative methods on de novo 3D molecule generation face two major challenges. Since majority heavy atoms in molecules allow connections to multiple atoms through single bonds, solely using pair-wise distance to model molecule geometries is insufficient. Therefore, the first one involves proposing an effective neural network as the denoising kernel that is capable to capture complex multi-body interatomic relationships and learn high-quality features. Due to the discrete nature of graphs, mainstream diffusion-based methods for molecules heavily rely on predefined rules and generate edges in an indirect manner. The second challenge involves accommodating molecule generation to diffusion and accurately predicting the existence of bonds. In our research, we view the iterative way of updating molecule conformations in diffusion process is consistent with molecular dynamics and introduce a novel molecule generation method named Geometric-Facilitated Molecular Diffusion (GFMDiff). For the first challenge, we introduce a Dual-track Transformer Network (DTN) to fully excevate global spatial relationships and learn high quality representations which contribute to accurate predictions of features and geometries. As for the second challenge, we design Geometric-facilitated Loss (GFLoss) which intervenes the formation of bonds during the training period, instead of directly embedding edges into the latent space. Comprehensive experiments on current benchmarks demonstrate the superiority of GFMDiff",
    "checked": true,
    "id": "cb5af772ea66ff572db4a35c0dc86b26d81acf4d",
    "semantic_title": "geometric-facilitated denoising diffusion model for 3d molecule generation",
    "citation_count": 3,
    "authors": [
      "Can Xu",
      "Haosen Wang",
      "Weigang Wang",
      "Pengfei Zheng",
      "Hongyang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27788": {
    "title": "GAMC: An Unsupervised Method for Fake News Detection Using Graph Autoencoder with Masking",
    "volume": "main",
    "abstract": "With the rise of social media, the spread of fake news has become a significant concern, potentially misleading public perceptions and impacting social stability. Although deep learning methods like CNNs, RNNs, and Transformer-based models like BERT have enhanced fake news detection. However, they primarily focus on content and do not consider social context during news propagation. Graph-based techniques have incorporated the social context but are limited by the need for large labeled datasets. To address these challenges, this paper introduces GAMC, an unsupervised fake news detection technique using the Graph Autoencoder with Masking and Contrastive learning. By leveraging both the context and content of news propagation as self-supervised signals, our method reduces the dependency on labeled datasets. Specifically, GAMC begins by applying data augmentation to the original news propagation graphs. Subsequently, these augmented graphs are encoded using a graph encoder and subsequently reconstructed via a graph decoder. Finally, a composite loss function that encompasses both reconstruction error and contrastive loss is designed. Firstly, it ensures the model can effectively capture the latent features, based on minimizing the discrepancy between reconstructed and original graph representations. Secondly, it aligns the representations of augmented graphs that originate from the same source. Experiments on the real-world dataset validate the effectiveness of our method",
    "checked": true,
    "id": "c2c92a8e58aa8fdf5f1b76c4dfa5e15024d70b54",
    "semantic_title": "gamc: an unsupervised method for fake news detection using graph autoencoder with masking",
    "citation_count": 1,
    "authors": [
      "Shu Yin",
      "Peican Zhu",
      "Lianwei Wu",
      "Chao Gao",
      "Zhen Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27789": {
    "title": "Unsupervised Gene-Cell Collective Representation Learning with Optimal Transport",
    "volume": "main",
    "abstract": "Cell type identification plays a vital role in single-cell RNA sequencing (scRNA-seq) data analysis. Although many deep embedded methods to cluster scRNA-seq data have been proposed, they still fail in elucidating the intrinsic properties of cells and genes. Here, we present a novel end-to-end deep graph clustering model for single-cell transcriptomics data based on unsupervised Gene-Cell Collective representation learning and Optimal Transport (scGCOT) which integrates both cell and gene correlations. Specifically, scGCOT learns the latent embedding of cells and genes simultaneously and reconstructs the cell graph, the gene graph, and the gene expression count matrix. A zero-inflated negative binomial (ZINB) model is estimated via the reconstructed count matrix to capture the essential properties of scRNA-seq data. By leveraging the optimal transport-based joint representation alignment, scGCOT learns the clustering process and the latent representations through a mutually supervised self optimization strategy. Extensive experiments with 14 competing methods on 15 real scRNA-seq datasets demonstrate the competitive edges of scGCOT",
    "checked": true,
    "id": "3eff0e0d38e0be0bff0b536abc4718142f84d3df",
    "semantic_title": "unsupervised gene-cell collective representation learning with optimal transport",
    "citation_count": 0,
    "authors": [
      "Jixiang Yu",
      "Nanjun Chen",
      "Ming Gao",
      "Xiangtao Li",
      "Ka-Chun  Wong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27790": {
    "title": "MCSSME: Multi-Task Contrastive Learning for Semi-supervised Singing Melody Extraction from Polyphonic Music",
    "volume": "main",
    "abstract": "Singing melody extraction is an important task in the field of music information retrieval (MIR). The development of data-driven models for this task have achieved great successes. However, the existing models have two major limitations: firstly, most of the existing singing melody extraction models have formulated this task as a pixel-level prediction task. The lack of labeling data has limited the model for further improvements. Secondly, the generalization of the existing models are prone to be disturbed by the music genres. To address the issues mentioned above, in this paper, we propose a multi-Task contrastive learning framework for semi-supervised singing melody extraction, termed as MCSSME. Specifically, to deal with data scarcity limitation, we propose a self-consistency regularization (SCR) method to train the model on the unlabeled data. Transformations are applied to the raw signal of polyphonic music, which makes the network to improve its representation capability via recognizing the transformations. We further propose a novel multi-task learning (MTL) approach to jointly learn singing melody extraction and classification of transformed data. To deal with generalization limitation, we also propose a contrastive embedding learning, which strengthens the intra-class compactness and inter-class separability. To improve the generalization on different music genres, we also propose a domain classification method to learn task-dependent features by mapping data from different music genres to shared subspace. MCSSME evaluates on a set of well-known public melody extraction datasets with promising performances. The experimental results demonstrate the effectiveness of the MCSSME framework for singing melody extraction from polyphonic music using very limited labeled data scenarios",
    "checked": true,
    "id": "51dfe652c6fc8120c38e01c3ac62ec5fad6be60a",
    "semantic_title": "mcssme: multi-task contrastive learning for semi-supervised singing melody extraction from polyphonic music",
    "citation_count": 0,
    "authors": [
      "Shuai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27791": {
    "title": "RetroOOD: Understanding Out-of-Distribution Generalization in Retrosynthesis Prediction",
    "volume": "main",
    "abstract": "Machine learning-assisted retrosynthesis prediction models have been gaining widespread adoption, though their performances oftentimes degrade significantly when deployed in real-world applications embracing out-of-distribution (OOD) molecules or reactions. Despite steady progress on standard benchmarks, our understanding of existing retrosynthesis prediction models under the premise of distribution shifts remains stagnant. To this end, we first formally sort out two types of distribution shifts in retrosynthesis prediction and construct two groups of benchmark datasets. Next, through comprehensive experiments, we systematically compare state-of-the-art retrosynthesis prediction models on the two groups of benchmarks, revealing the limitations of previous in-distribution evaluation and re-examining the advantages of each model. More remarkably, we are motivated by the above empirical insights to propose two model-agnostic techniques that can improve the OOD generalization of arbitrary off-the-shelf retrosynthesis prediction algorithms. Our preliminary experiments show their high potential with an average performance improvement of 4.6%, and the established benchmarks serve as a foothold for further retrosynthesis prediction research towards OOD generalization",
    "checked": true,
    "id": "9947402dae7238243f29496fc00451606eb151c7",
    "semantic_title": "retroood: understanding out-of-distribution generalization in retrosynthesis prediction",
    "citation_count": 1,
    "authors": [
      "Yemin Yu",
      "Luotian Yuan",
      "Ying Wei",
      "Hanyu Gao",
      "Fei Wu",
      "Zhihua Wang",
      "Xinhai Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27792": {
    "title": "Designing Biological Sequences without Prior Knowledge Using Evolutionary Reinforcement Learning",
    "volume": "main",
    "abstract": "Designing novel biological sequences with desired properties is a significant challenge in biological science because of the extra large search space. The traditional design process usually involves multiple rounds of costly wet lab evaluations. To reduce the need for expensive wet lab experiments, machine learning methods are used to aid in designing biological sequences. However, the limited availability of biological sequences with known properties hinders the training of machine learning models, significantly restricting their applicability and performance. To fill this gap, we present ERLBioSeq, an Evolutionary Reinforcement Learning algorithm for BIOlogical SEQuence design. ERLBioSeq leverages the capability of reinforcement learning to learn without prior knowledge and the potential of evolutionary algorithms to enhance the exploration of reinforcement learning in the large search space of biological sequences. Additionally, to enhance the efficiency of biological sequence design, we developed a predictor for sequence screening in the biological sequence design process, which incorporates both the local and global sequence information. We evaluated the proposed method on three main types of biological sequence design tasks, including the design of DNA, RNA, and protein. The results demonstrate that the proposed method achieves significant improvement compared to the existing state-of-the-art methods",
    "checked": true,
    "id": "a13fbf12c13cf217db50252c4a8b959e734ff377",
    "semantic_title": "designing biological sequences without prior knowledge using evolutionary reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Xi Zeng",
      "Xiaotian Hao",
      "Hongyao Tang",
      "Zhentao Tang",
      "Shaoqing Jiao",
      "Dazhi Lu",
      "Jiajie Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27793": {
    "title": "Adversarial Socialbots Modeling Based on Structural Information Principles",
    "volume": "main",
    "abstract": "The importance of effective detection is underscored by the fact that socialbots imitate human behavior to propagate misinformation, leading to an ongoing competition between socialbots and detectors. Despite the rapid advancement of reactive detectors, the exploration of adversarial socialbot modeling remains incomplete, significantly hindering the development of proactive detectors. To address this issue, we propose a mathematical Structural Information principles-based Adversarial Socialbots Modeling framework, namely SIASM, to enable more accurate and effective modeling of adversarial behaviors. First, a heterogeneous graph is presented to integrate various users and rich activities in the original social network and measure its dynamic uncertainty as structural entropy. By minimizing the high-dimensional structural entropy, a hierarchical community structure of the social network is generated and referred to as the optimal encoding tree. Secondly, a novel method is designed to quantify influence by utilizing the assigned structural entropy, which helps reduce the computational cost of SIASM by filtering out uninfluential users. Besides, a new conditional structural entropy is defined between the socialbot and other users to guide the follower selection for network influence maximization. Extensive and comparative experiments on both homogeneous and heterogeneous social networks demonstrate that, compared with state-of-the-art baselines, the proposed SIASM framework yields substantial performance improvements in terms of network influence (up to 16.32%) and sustainable stealthiness (up to 16.29%) when evaluated against a robust detector with 90% accuracy",
    "checked": true,
    "id": "3c05e98a77a29fd880b7ff998c34cfe7cc34a721",
    "semantic_title": "adversarial socialbots modeling based on structural information principles",
    "citation_count": 4,
    "authors": [
      "Xianghua Zeng",
      "Hao Peng",
      "Angsheng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27794": {
    "title": "NondBREM: Nondeterministic Offline Reinforcement Learning for Large-Scale Order Dispatching",
    "volume": "main",
    "abstract": "One of the most important tasks in ride-hailing is order dispatching, i.e., assigning unserved orders to available drivers. Recent order dispatching has achieved a significant improvement due to the advance of reinforcement learning, which has been approved to be able to effectively address sequential decision-making problems like order dispatching. However, most existing reinforcement learning methods require agents to learn the optimal policy by interacting with environments online, which is challenging or impractical for real-world deployment due to high costs or safety concerns. For example, due to the spatiotemporally unbalanced supply and demand, online reinforcement learning-based order dispatching may significantly impact the revenue of the ride-hailing platform and passenger experience during the policy learning period. Hence, in this work, we develop an offline deep reinforcement learning framework called NondBREM for large-scale order dispatching, which learns policy from only the accumulated logged data to avoid costly and unsafe interactions with the environment. In NondBREM, a Nondeterministic Batch-Constrained Q-learning (NondBCQ) module is developed to reduce the algorithm extrapolation error and a Random Ensemble Mixture (REM) module that integrates multiple value networks with multi-head networks is utilized to improve the model generalization and robustness. Extensive experiments on large-scale real-world ride-hailing datasets show the superiority of our design",
    "checked": true,
    "id": "90895a914b4df1aabd7a5dacbd7bc72fbdc25cd9",
    "semantic_title": "nondbrem: nondeterministic offline reinforcement learning for large-scale order dispatching",
    "citation_count": 1,
    "authors": [
      "Hongbo Zhang",
      "Guang Wang",
      "Xu Wang",
      "Zhengyang Zhou",
      "Chen Zhang",
      "Zheng Dong",
      "Yang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27795": {
    "title": "Scale Optimization Using Evolutionary Reinforcement Learning for Object Detection on Drone Imagery",
    "volume": "main",
    "abstract": "Object detection in aerial imagery presents a significant challenge due to large scale variations among objects. This paper proposes an evolutionary reinforcement learning agent, integrated within a coarse-to-fine object detection framework, to optimize the scale for more effective detection of objects in such images. Specifically, a set of patches potentially containing objects are first generated. A set of rewards measuring the localization accuracy, the accuracy of predicted labels, and the scale consistency among nearby patches are designed in the agent to guide the scale optimization. The proposed scale-consistency reward ensures similar scales for neighboring objects of the same category. Furthermore, a spatial-semantic attention mechanism is designed to exploit the spatial semantic relations between patches. The agent employs the proximal policy optimization strategy in conjunction with the evolutionary strategy, effectively utilizing both the current patch status and historical experience embedded in the agent. The proposed model is compared with state-of-the-art methods on two benchmark datasets for object detection on drone imagery. It significantly outperforms all the compared methods. Code is available at https://github.com/UNNC-CV/EvOD/",
    "checked": true,
    "id": "ea85f8d412c6d6cfae90dd54623fcb5ebe80cf42",
    "semantic_title": "scale optimization using evolutionary reinforcement learning for object detection on drone imagery",
    "citation_count": 1,
    "authors": [
      "Jialu Zhang",
      "Xiaoying Yang",
      "Wentao He",
      "Jianfeng Ren",
      "Qian Zhang",
      "Yitian Zhao",
      "Ruibin Bai",
      "Xiangjian He",
      "Jiang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27796": {
    "title": "Adversarial Attacks on Federated-Learned Adaptive Bitrate Algorithms",
    "volume": "main",
    "abstract": "Learning-based adaptive bitrate (ABR) algorithms have revolutionized video streaming solutions. With the growing demand for data privacy and the rapid development of mobile devices, federated learning (FL) has emerged as a popular training method for neural ABR algorithms in both academia and industry. However, we have discovered that FL-based ABR models are vulnerable to model-poisoning attacks as local updates remain unseen during global aggregation. In response, we propose MAFL (Malicious ABR model based on Federated Learning) to prove that backdooring the learning-based ABR model via FL is practical. Instead of attacking the global policy, MAFL only targets a single ``target client''. Moreover, the unique challenges brought by deep reinforcement learning (DRL) make the attack even more challenging. To address these challenges, MAFL is designed with a two-stage attacking mechanism. Using two representative attack cases with real-world traces, we show that MAFL significantly degrades the model performance on the target client (i.e., increasing rebuffering penalty by 2x and 5x) with a minimal negative impact on benign clients",
    "checked": true,
    "id": "9858cc69abd8b042e8891e68c12bbc08aebbbea0",
    "semantic_title": "adversarial attacks on federated-learned adaptive bitrate algorithms",
    "citation_count": 0,
    "authors": [
      "Rui-Xiao Zhang",
      "Tianchi Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27797": {
    "title": "Generalize for Future: Slow and Fast Trajectory Learning for CTR Prediction",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) have achieved significant advancements in click-through rate (CTR) prediction by demonstrating strong generalization on training data. However, in real-world scenarios, the assumption of independent and identically distributed (i.i.d.) conditions, which is fundamental to this problem, is often violated due to temporal distribution shifts. This violation can lead to suboptimal model performance when optimizing empirical risk without access to future data, resulting in overfitting on the training data and convergence to a single sharp minimum. To address this challenge, we propose a novel model updating framework called Slow and Fast Trajectory Learning (SFTL) network. SFTL aims to mitigate the discrepancy between past and future domains while quickly adapting to recent changes in small temporal drifts. This mechanism entails two interactions among three complementary learners: (i) the Working Learner, which updates model parameters using modern optimizers (e.g., Adam, Adagrad) and serves as the primary learner in the recommendation system, (ii) the Slow Learner, which is updated in each temporal domain by directly assigning the model weights of the working learner, and (iii) the Fast Learner, which is updated in each iteration by assigning exponentially moving average weights of the working learner. Additionally, we propose a novel rank-based trajectory loss to facilitate interaction between the working learner and trajectory learner, aiming to adapt to temporal drift and enhance performance in the current domain compared to the past. We provide theoretical understanding and conduct extensive experiments on real-world CTR prediction datasets to validate the effectiveness and efficiency of SFTL in terms of both convergence speed and model performance. The results demonstrate the superiority of SFTL over existing approaches",
    "checked": true,
    "id": "30170172a98512badd6b1e6ad2ccb3e7d97e116e",
    "semantic_title": "generalize for future: slow and fast trajectory learning for ctr prediction",
    "citation_count": 0,
    "authors": [
      "Jian Zhu",
      "Congcong Liu",
      "Xue Jiang",
      "Changping Peng",
      "Zhangang Lin",
      "Jingping Shao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27798": {
    "title": "Hot or Cold? Adaptive Temperature Sampling for Code Generation with Large Language Models",
    "volume": "main",
    "abstract": "Recently, Large Language Models (LLMs) have shown impressive abilities in code generation. However, existing LLMs' decoding strategies are designed for Natural Language (NL) generation, overlooking the differences between NL and programming languages (PL). Due to this oversight, a better decoding strategy for code generation remains an open question. In this paper, we conduct the first systematic study to explore a decoding strategy specialized in code generation. With an analysis of loss distributions of code tokens, we find that code tokens can be divided into two categories: challenging tokens that are difficult to predict and confident tokens that can be easily inferred. Among them, the challenging tokens mainly appear at the beginning of a code block. Inspired by the above findings, we propose a simple yet effective method: Adaptive Temperature (AdapT) sampling, which dynamically adjusts the temperature coefficient when decoding different tokens. We apply a larger temperature when sampling for challenging tokens, allowing LLMs to explore diverse choices. We employ a smaller temperature for confident tokens avoiding the influence of tail randomness noises. We apply AdapT sampling to LLMs with different sizes and conduct evaluations on two popular datasets. Results show that AdapT sampling significantly outperforms state-of-the-art decoding strategy",
    "checked": true,
    "id": "4a12c3e9dc9dfab3173f357615e0a5320ce2bf48",
    "semantic_title": "hot or cold? adaptive temperature sampling for code generation with large language models",
    "citation_count": 5,
    "authors": [
      "Yuqi Zhu",
      "Jia Li",
      "Ge Li",
      "YunFei Zhao",
      "Jia Li",
      "Zhi Jin",
      "Hong Mei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27799": {
    "title": "Operationalizing Essential Characteristics of Creativity in a Computational System for Music Composition",
    "volume": "main",
    "abstract": "We address the problem of building and evaluating a computational system whose primary objective is creativity. We illustrate seven characteristics for computational creativity in the context of a system that autonomously composes Western lyrical music. We conduct an external evaluation of the system in which respondents rated the system with regard to each characteristic as well as with regard to overall creativity. Average scores for overall creativity exceeded the ratings for any single characteristic, suggesting that creativity may be an emergent property and that unique research opportunities exist for building CC systems whose design attempts to comprehend all known characteristics of creativity",
    "checked": true,
    "id": "6a013129353f34bd74d02844e155e66ce20b8d1c",
    "semantic_title": "operationalizing essential characteristics of creativity in a computational system for music composition",
    "citation_count": 0,
    "authors": [
      "Paul M. Bodily",
      "Dan Ventura"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27800": {
    "title": "Neural Reasoning about Agents' Goals, Preferences, and Actions",
    "volume": "main",
    "abstract": "We propose the Intuitive Reasoning Network (IRENE) - a novel neural model for intuitive psychological reasoning about agents' goals, preferences, and actions that can generalise previous experiences to new situations. IRENE combines a graph neural network for learning agent and world state representations with a transformer to encode the task context. When evaluated on the challenging Baby Intuitions Benchmark, IRENE achieves new state-of-the-art performance on three out of its five tasks - with up to 48.9% improvement. In contrast to existing methods, IRENE is able to bind preferences to specific agents, to better distinguish between rational and irrational agents, and to better understand the role of blocking obstacles. We also investigate, for the first time, the influence of the training tasks on test performance. Our analyses demonstrate the effectiveness of IRENE in combining prior knowledge gained during training for unseen evaluation tasks",
    "checked": true,
    "id": "b0abbbb104d74cd4bf0e3e3e9753265b26ce3154",
    "semantic_title": "neural reasoning about agents' goals, preferences, and actions",
    "citation_count": 4,
    "authors": [
      "Matteo Bortoletto",
      "Lei Shi",
      "Andreas Bulling"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27801": {
    "title": "An Empirical Study of CLIP for Text-Based Person Search",
    "volume": "main",
    "abstract": "Text-based Person Search (TBPS) aims to retrieve the person images using natural language descriptions. Recently, Contrastive Language Image Pretraining (CLIP), a universal large cross-modal vision-language pre-training model, has remarkably performed over various cross-modal downstream tasks due to its powerful cross-modal semantic learning capacity. TPBS, as a fine-grained cross-modal retrieval task, is also facing the rise of research on the CLIP-based TBPS. In order to explore the potential of the visual-language pre-training model for downstream TBPS tasks, this paper makes the first attempt to conduct a comprehensive empirical study of CLIP for TBPS and thus contribute a straightforward, incremental, yet strong TBPS-CLIP baseline to the TBPS community. We revisit critical design considerations under CLIP, including data augmentation and loss function. The model, with the aforementioned designs and practical training tricks, can attain satisfactory performance without any sophisticated modules. Also, we conduct the probing experiments of TBPS-CLIP in model generalization and model compression, demonstrating the effectiveness of TBPS-CLIP from various aspects. This work is expected to provide empirical insights and highlight future CLIP-based TBPS research",
    "checked": true,
    "id": "8fa4800425121b885ef9e03ec5332b6b5bfcc8bc",
    "semantic_title": "an empirical study of clip for text-based person search",
    "citation_count": 6,
    "authors": [
      "Min Cao",
      "Yang Bai",
      "Ziyin Zeng",
      "Mang Ye",
      "Min Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27802": {
    "title": "Social Physics Informed Diffusion Model for Crowd Simulation",
    "volume": "main",
    "abstract": "Crowd simulation holds crucial applications in various domains, such as urban planning, architectural design, and traffic arrangement. In recent years, physics-informed machine learning methods have achieved state-of-the-art performance in crowd simulation but fail to model the heterogeneity and multi-modality of human movement comprehensively. In this paper, we propose a social physics-informed diffusion model named SPDiff to mitigate the above gap. SPDiff takes both the interactive and historical information of crowds in the current timeframe to reverse the diffusion process, thereby generating the distribution of pedestrian movement in the subsequent timeframe. Inspired by the well-known social physics model, i.e., Social Force, regarding crowd dynamics, we design a crowd interaction encoder to guide the denoising process and further enhance this module with the equivariant properties of crowd interactions. To mitigate error accumulation in long-term simulations, we propose a multi-frame rollout training algorithm for diffusion modeling. Experiments conducted on two real-world datasets demonstrate the superior performance of SPDiff in terms of both macroscopic and microscopic evaluation metrics. Code and appendix are available at https://github.com/tsinghua-fib-lab/SPDiff",
    "checked": true,
    "id": "ad8d9ce3e2ee35e765827a11bc15918362459a35",
    "semantic_title": "social physics informed diffusion model for crowd simulation",
    "citation_count": 1,
    "authors": [
      "Hongyi Chen",
      "Jingtao Ding",
      "Yong Li",
      "Yue Wang",
      "Xiao-Ping Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27803": {
    "title": "Trend-Aware Supervision: On Learning Invariance for Semi-supervised Facial Action Unit Intensity Estimation",
    "volume": "main",
    "abstract": "With the increasing need for facial behavior analysis, semi-supervised AU intensity estimation using only keyframe annotations has emerged as a practical and effective solution to relieve the burden of annotation. However, the lack of annotations makes the spurious correlation problem caused by AU co-occurrences and subject variation much more prominent, leading to non-robust intensity estimation that is entangled among AUs and biased among subjects. We observe that trend information inherent in keyframe annotations could act as extra supervision and raising the awareness of AU-specific facial appearance changing trends during training is the key to learning invariant AU-specific features. To this end, we propose Trend-AwareSupervision (TAS), which pursues three kinds of trend awareness, including intra-trend ranking awareness, intra-trend speed awareness, and inter-trend subject awareness. TAS alleviates the spurious correlation problem by raising trend awareness during training to learn AU-specific features that represent the corresponding facial appearance changes, to achieve intensity estimation invariance. Experiments conducted on two commonly used AU benchmark datasets, BP4D and DISFA, show the effectiveness of each kind of awareness. And under trend-aware supervision, the performance can be improved without extra computational or storage costs during inference",
    "checked": true,
    "id": "be07fe74e59996ba4e44bed1cb56c3dc4cdbd7bb",
    "semantic_title": "trend-aware supervision: on learning invariance for semi-supervised facial action unit intensity estimation",
    "citation_count": 0,
    "authors": [
      "Yingjie Chen",
      "Jiarui Zhang",
      "Tao Wang",
      "Yun Liang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27804": {
    "title": "Enhancing the Robustness of Spiking Neural Networks with Stochastic Gating Mechanisms",
    "volume": "main",
    "abstract": "Spiking neural networks (SNNs) exploit neural spikes to provide solutions for low-power intelligent applications on neuromorphic hardware. Although SNNs have high computational efficiency due to spiking communication, they still lack resistance to adversarial attacks and noise perturbations. In the brain, neuronal responses generally possess stochasticity induced by ion channels and synapses, while the role of stochasticity in computing tasks is poorly understood. Inspired by this, we elaborate a stochastic gating spiking neural model for layer-by-layer spike communication, introducing stochasticity to SNNs. Through theoretical analysis, our gating model can be viewed as a regularizer that prevents error amplification under attacks. Meanwhile, our work can explain the robustness of Poisson coding. Experimental results prove that our method can be used alone or with existing robust enhancement algorithms to improve SNN robustness and reduce SNN energy consumption. We hope our work will shed new light on the role of stochasticity in the computation of SNNs. Our code is available at https://github.com/DingJianhao/StoG-meets-SNN/",
    "checked": true,
    "id": "3302584d6f892d00dc9e013d67714abde34fc931",
    "semantic_title": "enhancing the robustness of spiking neural networks with stochastic gating mechanisms",
    "citation_count": 2,
    "authors": [
      "Jianhao Ding",
      "Zhaofei Yu",
      "Tiejun Huang",
      "Jian K. Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27805": {
    "title": "Imitation of Life: A Search Engine for Biologically Inspired Design",
    "volume": "main",
    "abstract": "Biologically Inspired Design (BID), or Biomimicry, is a problem-solving methodology that applies analogies from nature to solve engineering challenges. For example, Speedo engineers designed swimsuits based on shark skin. Finding relevant biological solutions for real-world problems poses significant challenges, both due to the limited biological knowledge engineers and designers typically possess and to the limited BID resources. Existing BID datasets are hand-curated and small, and scaling them up requires costly human annotations. In this paper, we introduce BARcode (Biological Analogy Retriever), a search engine for automatically mining bio-inspirations from the web at scale. Using advances in natural language understanding and data programming, BARcode identifies potential inspirations for engineering challenges. Our experiments demonstrate that BARcode can retrieve inspirations that are valuable to engineers and designers tackling real-world problems, as well as recover famous historical BID examples. We release data and code; we view BARcode as a step towards addressing the challenges that have historically hindered the practical application of BID to engineering innovation",
    "checked": true,
    "id": "3f0736c8d2e5418b5ef077c4218c2790a4823765",
    "semantic_title": "imitation of life: a search engine for biologically inspired design",
    "citation_count": 0,
    "authors": [
      "Hen Emuna",
      "Nadav Borenstein",
      "Xin Qian",
      "Hyeonsu Kang",
      "Joel Chan",
      "Aniket  Kittur",
      "Dafna Shahaf"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27806": {
    "title": "An Efficient Knowledge Transfer Strategy for Spiking Neural Networks from Static to Event Domain",
    "volume": "main",
    "abstract": "Spiking neural networks (SNNs) are rich in spatio-temporal dynamics and are suitable for processing event-based neuromorphic data. However, event-based datasets are usually less annotated than static datasets. This small data scale makes SNNs prone to overfitting and limits their performance. In order to improve the generalization ability of SNNs on event-based datasets, we use static images to assist SNN training on event data. In this paper, we first discuss the domain mismatch problem encountered when directly transferring networks trained on static datasets to event data. We argue that the inconsistency of feature distributions becomes a major factor hindering the effective transfer of knowledge from static images to event data. To address this problem, we propose solutions in terms of two aspects: feature distribution and training strategy. Firstly, we propose a knowledge transfer loss, which consists of domain alignment loss and spatio-temporal regularization. The domain alignment loss learns domain-invariant spatial features by reducing the marginal distribution distance between the static image and the event data. Spatio-temporal regularization provides dynamically learnable coefficients for domain alignment loss by using the output features of the event data at each time step as a regularization term. In addition, we propose a sliding training strategy, which gradually replaces static image inputs probabilistically with event data, resulting in a smoother and more stable training for the network. We validate our method on neuromorphic datasets, including N-Caltech101, CEP-DVS, and N-Omniglot. The experimental results show that our proposed method achieves better performance on all datasets compared to the current state-of-the-art methods. Code is available at https://github.com/Brain-Cog-Lab/Transfer-for-DVS",
    "checked": true,
    "id": "4bd7de4aa8c6c3d5b6e3f37fc73cfb6abc6a2623",
    "semantic_title": "an efficient knowledge transfer strategy for spiking neural networks from static to event domain",
    "citation_count": 0,
    "authors": [
      "Xiang He",
      "Dongcheng Zhao",
      "Yang Li",
      "Guobin Shen",
      "Qingqun Kong",
      "Yi Zeng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27807": {
    "title": "Responding to the Call: Exploring Automatic Music Composition Using a Knowledge-Enhanced Model",
    "volume": "main",
    "abstract": "Call-and-response is a musical technique that enriches the creativity of music, crafting coherent musical ideas that mirror the back-and-forth nature of human dialogue with distinct musical characteristics. Although this technique is integral to numerous musical compositions, it remains largely uncharted in automatic music composition. To enhance the creativity of machine-composed music, we first introduce the Call-Response Dataset (CRD) containing 19,155 annotated musical pairs and crafted comprehensive objective evaluation metrics for musical assessment. Then, we design a knowledge-enhanced learning-based method to bridge the gap between human and machine creativity. Specifically, we train the composition module using the call-response pairs, supplementing it with musical knowledge in terms of rhythm, melody, and harmony. Our experimental results underscore that our proposed model adeptly produces a wide variety of creative responses for various musical calls",
    "checked": true,
    "id": "01781d9669355576968e0f7c148bdd98fd7be1ba",
    "semantic_title": "responding to the call: exploring automatic music composition using a knowledge-enhanced model",
    "citation_count": 0,
    "authors": [
      "Zhejing Hu",
      "Yan Liu",
      "Gong Chen",
      "Xiao Ma",
      "Shenghua Zhong",
      "Qianwen Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27808": {
    "title": "Neural Amortized Inference for Nested Multi-Agent Reasoning",
    "volume": "main",
    "abstract": "Multi-agent interactions, such as communication, teaching, and bluffing, often rely on higher-order social inference, i.e., understanding how others infer oneself. Such intricate reasoning can be effectively modeled through nested multi-agent reasoning. Nonetheless, the computational complexity escalates exponentially with each level of reasoning, posing a significant challenge. However, humans effortlessly perform complex social inferences as part of their daily lives. To bridge the gap between human-like inference capabilities and computational limitations, we propose a novel approach: leveraging neural networks to amortize high-order social inference, thereby expediting nested multi-agent reasoning. We evaluate our method in two challenging multi-agent interaction domains. The experimental results demonstrate that our method is computationally efficient while exhibiting minimal degradation in accuracy",
    "checked": true,
    "id": "15f18b7bfd822e9c924477bb951d45a0eeb2486b",
    "semantic_title": "neural amortized inference for nested multi-agent reasoning",
    "citation_count": 1,
    "authors": [
      "Kunal Jha",
      "Tuan Anh Le",
      "Chuanyang Jin",
      "Yen-Ling Kuo",
      "Joshua B. Tenenbaum",
      "Tianmin Shu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27809": {
    "title": "Hidden Follower Detection: How Is the Gaze-Spacing Pattern Embodied in Frequency Domain?",
    "volume": "main",
    "abstract": "Spatiotemporal social behavior analysis is a technique that studies the social behavior patterns of objects and estimates their risks based on their trajectories. In social public scenarios such as train stations, hidden following behavior has become one of the most challenging issues due to its probability of evolving into violent events, which is more than 25%. In recent years, research on hidden following detection (HFD) has focused on differences in time series between hidden followers and normal pedestrians under two temporal characteristics: gaze and spatial distance. However, the time-domain representation for time series is irreversible and usually causes the loss of critical information. In this paper, we deeply study the expression efficiency of time/frequency domain features of time series, by exploring the recovery mechanism of features to source time series, we establish a fidelity estimation method for feature expression and a selection model for frequency-domain features based on the signal-to-distortion ratio (SDR). Experimental results demonstrate the feature fidelity of time series and HFD performance are positively correlated, and the fidelity of frequency-domain features and HFD performance are significantly better than the time-domain features. On both real and simulated datasets, the accuracy of the proposed method is increased by 3%, and the gaze-only module is improved by 10%. Related research has explored new methods for optimal feature selection based on fidelity, new patterns for efficient feature expression of hidden following behavior, and the mechanism of multimodal collaborative identification",
    "checked": true,
    "id": "e1b28ba6a6a3ffd5ae3ab5fd5f53eeb85399f301",
    "semantic_title": "hidden follower detection: how is the gaze-spacing pattern embodied in frequency domain?",
    "citation_count": 1,
    "authors": [
      "Shu Li",
      "Ruimin Hu",
      "Suhui Li",
      "Liang Liao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27810": {
    "title": "Music Style Transfer with Time-Varying Inversion of Diffusion Models",
    "volume": "main",
    "abstract": "With the development of diffusion models, text-guided image style transfer has demonstrated great controllable and high-quality results. However, the utilization of text for diverse music style transfer poses significant challenges, primarily due to the limited availability of matched audio-text datasets. Music, being an abstract and complex art form, exhibits variations and intricacies even within the same genre, thereby making accurate textual descriptions challenging. This paper presents a music style transfer approach that effectively captures musical attributes using minimal data. We introduce a novel time-varying textual inversion module to precisely capture mel-spectrogram features at different levels. During inference, we utilize a bias-reduced stylization technique to get stable results. Experimental results demonstrate that our method can transfer the style of specific instruments, as well as incorporate natural sounds to compose melodies. Samples and code are available at https://lsfhuihuiff.github.io/MusicTI/",
    "checked": true,
    "id": "66c72f9d18b3a996c491f62937543072ef382d6b",
    "semantic_title": "music style transfer with time-varying inversion of diffusion models",
    "citation_count": 2,
    "authors": [
      "Sifei Li",
      "Yuxin Zhang",
      "Fan Tang",
      "Chongyang Ma",
      "Weiming Dong",
      "Changsheng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27811": {
    "title": "A Brain-Inspired Way of Reducing the Network Complexity via Concept-Regularized Coding for Emotion Recognition",
    "volume": "main",
    "abstract": "The human brain can effortlessly and reliably perceive emotions, whereas existing facial emotion recognition (FER) methods suffer from drawbacks such as complex model structures, high storage requirements, and poor interpretability. Inspired by the role of emotion concepts in visual perception coding within the human brain, we propose a dual-pathway framework emulating the neural computation of emotion recognition. Specifically, these two pathways are designed to model the representation of emotion concepts in the brain and the visual perception process, respectively. For the former, we adopt a disentangled approach to extract emotion concepts from complex facial geometric attributes; for the latter, we employ an emotional confidence evaluation strategy to determine which concept is optimal for regularizing the perceptual coding. The proposed concept-regularized coding strategy endows the framework with flexibility and interpretability as well as good performances on several benchmarking FER datasets",
    "checked": true,
    "id": "02029178c63a96d9165ee33062ef8d179d5a9ad4",
    "semantic_title": "a brain-inspired way of reducing the network complexity via concept-regularized coding for emotion recognition",
    "citation_count": 0,
    "authors": [
      "Han Lu",
      "Xiahai Zhuang",
      "Qiang Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27812": {
    "title": "Multi-Energy Guided Image Translation with Stochastic Differential Equations for Near-Infrared Facial Expression Recognition",
    "volume": "main",
    "abstract": "Illumination variation has been a long-term challenge in real-world facial expression recognition (FER). Under uncontrolled or non-visible light conditions, near-infrared (NIR) can provide a simple and alternative solution to obtain high-quality images and supplement the geometric and texture details that are missing in the visible (VIS) domain. Due to the lack of large-scale NIR facial expression datasets, directly extending VIS FER methods to the NIR spectrum may be ineffective. Additionally, previous heterogeneous image synthesis methods are restricted by low controllability without prior task knowledge. To tackle these issues, we present the first approach, called for NIR-FER Stochastic Differential Equations (NFER-SDE), that transforms face expression appearance between heterogeneous modalities to the overfitting problem on small-scale NIR data. NFER-SDE can take the whole VIS source image as input and, together with domain-specific knowledge, guide the preservation of modality-invariant information in the high-frequency content of the image. Extensive experiments and ablation studies show that NFER-SDE significantly improves the performance of NIR FER and achieves state-of-the-art results on the only two available NIR FER datasets, Oulu-CASIA and Large-HFE",
    "checked": true,
    "id": "21eef3fadc380934f19d1283f36e0dbcec8dc90b",
    "semantic_title": "multi-energy guided image translation with stochastic differential equations for near-infrared facial expression recognition",
    "citation_count": 0,
    "authors": [
      "Bingjun Luo",
      "Zewen Wang",
      "Jinpeng Wang",
      "Junjie Zhu",
      "Xibin Zhao",
      "Yue Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27813": {
    "title": "Successive POI Recommendation via Brain-Inspired Spatiotemporal Aware Representation",
    "volume": "main",
    "abstract": "Existing approaches usually perform spatiotemporal representation in the spatial and temporal dimensions, respectively, which isolates the spatial and temporal natures of the target and leads to sub-optimal embeddings. Neuroscience research has shown that the mammalian brain entorhinal-hippocampal system provides efficient graph representations for general knowledge. Moreover, entorhinal grid cells present concise spatial representations, while hippocampal place cells represent perception conjunctions effectively. Thus, the entorhinal-hippocampal system provides a novel angle for spatiotemporal representation, which inspires us to propose the SpatioTemporal aware Embedding framework (STE) and apply it to POIs (STEP). STEP considers two types of POI-specific representations: sequential representation and spatiotemporal conjunctive representation, learned using sparse unlabeled data based on the proposed graph-building policies. Notably, STEP jointly represents the spatiotemporal natures of POIs using both observations and contextual information from integrated spatiotemporal dimensions by constructing a spatiotemporal context graph. Furthermore, we introduce a successive POI recommendation method using STEP, which achieves state-of-the-art performance on two benchmarks. In addition, we demonstrate the excellent performance of the STE representation approach in other spatiotemporal representation-centered tasks through a case study of the traffic flow prediction problem. Therefore, this work provides a novel solution to spatiotemporal representation and paves a new way for spatiotemporal modeling-related tasks",
    "checked": true,
    "id": "3e79febc340e80eaf61e00f36bb7ee00c0449372",
    "semantic_title": "successive poi recommendation via brain-inspired spatiotemporal aware representation",
    "citation_count": 1,
    "authors": [
      "Gehua Ma",
      "He Wang",
      "Jingyuan Zhao",
      "Rui Yan",
      "Huajin Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27814": {
    "title": "BDIQA: A New Dataset for Video Question Answering to Explore Cognitive Reasoning through Theory of Mind",
    "volume": "main",
    "abstract": "As a foundational component of cognitive intelligence, theory of mind (ToM) can make AI more closely resemble human thought processes, thereby enhancing their interaction and collaboration with human. In particular, it can significantly improve a model's comprehension of videos in complex scenes. However, current video question answer (VideoQA) datasets focus on studying causal reasoning within events, few of them genuinely incorporating human ToM. Consequently, there is a lack of development in ToM reasoning tasks within the area of VideoQA. This paper presents BDIQA, the first benchmark to explore the cognitive reasoning capabilities of VideoQA models in the context of ToM. BDIQA is inspired by the cognitive development of children's ToM and addresses the current deficiencies in machine ToM within datasets and tasks. Specifically, it offers tasks at two difficulty levels, assessing Belief, Desire and Intention (BDI) reasoning in both simple and complex scenarios. We conduct evaluations on several mainstream methods of VideoQA and diagnose their capabilities with zero-shot, few-shot and supervised learning. We find that the performance of pre-trained models on cognitive reasoning tasks remains unsatisfactory. To counter this challenge, we undertake thorough analysis and experimentation, ultimately presenting two guidelines to enhance cognitive reasoning derived from ablation analysis",
    "checked": true,
    "id": "825663ac1457fd9f5bbd23568f955af579ff0a4d",
    "semantic_title": "bdiqa: a new dataset for video question answering to explore cognitive reasoning through theory of mind",
    "citation_count": 0,
    "authors": [
      "Yuanyuan Mao",
      "Xin Lin",
      "Qin Ni",
      "Liang He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27815": {
    "title": "Unveiling the Significance of Toddler-Inspired Reward Transition in Goal-Oriented Reinforcement Learning",
    "volume": "main",
    "abstract": "Toddlers evolve from free exploration with sparse feedback to exploiting prior experiences for goal-directed learning with denser rewards. Drawing inspiration from this Toddler-Inspired Reward Transition, we set out to explore the implications of varying reward transitions when incorporated into Reinforcement Learning (RL) tasks. Central to our inquiry is the transition from sparse to potential-based dense rewards, which share optimal strategies regardless of reward changes. Through various experiments, including those in egocentric navigation and robotic arm manipulation tasks, we found that proper reward transitions significantly influence sample efficiency and success rates. Of particular note is the efficacy of the toddler-inspired Sparse-to-Dense (S2D) transition. Beyond these performance metrics, using Cross-Density Visualizer technique, we observed that transitions, especially the S2D, smooth the policy loss landscape, promoting wide minima that enhance generalization in RL models",
    "checked": true,
    "id": "740e69d93e9dbcb78b987c2955f709c07b578266",
    "semantic_title": "unveiling the significance of toddler-inspired reward transition in goal-oriented reinforcement learning",
    "citation_count": 1,
    "authors": [
      "Junseok Park",
      "Yoonsung Kim",
      "Hee bin Yoo",
      "Min Whoo Lee",
      "Kibeom Kim",
      "Won-Seok Choi",
      "Minsu Lee",
      "Byoung-Tak Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27816": {
    "title": "Gated Attention Coding for Training High-Performance and Efficient Spiking Neural Networks",
    "volume": "main",
    "abstract": "Spiking neural networks (SNNs) are emerging as an energy-efficient alternative to traditional artificial neural networks (ANNs) due to their unique spike-based event-driven nature. Coding is crucial in SNNs as it converts external input stimuli into spatio-temporal feature sequences. However, most existing deep SNNs rely on direct coding that generates powerless spike representation and lacks the temporal dynamics inherent in human vision. Hence, we introduce Gated Attention Coding (GAC), a plug-and-play module that leverages the multi-dimensional gated attention unit to efficiently encode inputs into powerful representations before feeding them into the SNN architecture. GAC functions as a preprocessing layer that does not disrupt the spike-driven nature of the SNN, making it amenable to efficient neuromorphic hardware implementation with minimal modifications. Through an observer model theoretical analysis, we demonstrate GAC's attention mechanism improves temporal dynamics and coding efficiency. Experiments on CIFAR10/100 and ImageNet datasets demonstrate that GAC achieves state-of-the-art accuracy with remarkable efficiency. Notably, we improve top-1 accuracy by 3.10% on CIFAR100 with only 6-time steps and 1.07% on ImageNet while reducing energy usage to 66.9% of the previous works. To our best knowledge, it is the first time to explore the attention-based dynamic coding scheme in deep SNNs, with exceptional effectiveness and efficiency on large-scale datasets. Code is available at https://github.com/bollossom/GAC",
    "checked": true,
    "id": "b9a6a6dee5803d9d4c6a6d4bb3da59fe512459ca",
    "semantic_title": "gated attention coding for training high-performance and efficient spiking neural networks",
    "citation_count": 8,
    "authors": [
      "Xuerui Qiu",
      "Rui-Jie Zhu",
      "Yuhong Chou",
      "Zhaorui Wang",
      "Liang-Jian Deng",
      "Guoqi Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27817": {
    "title": "Efficient Spiking Neural Networks with Sparse Selective Activation for Continual Learning",
    "volume": "main",
    "abstract": "The next generation of machine intelligence requires the capability of continual learning to acquire new knowledge without forgetting the old one while conserving limited computing resources. Spiking neural networks (SNNs), compared to artificial neural networks (ANNs), have more characteristics that align with biological neurons, which may be helpful as a potential gating function for knowledge maintenance in neural networks. Inspired by the selective sparse activation principle of context gating in biological systems, we present a novel SNN model with selective activation to achieve continual learning. The trace-based K-Winner-Take-All (K-WTA) and variable threshold components are designed to form the sparsity in selective activation in spatial and temporal dimensions of spiking neurons, which promotes the subpopulation of neuron activation to perform specific tasks. As a result, continual learning can be maintained by routing different tasks via different populations of neurons in the network. The experiments are conducted on MNIST and CIFAR10 datasets under the class incremental setting. The results show that the proposed SNN model achieves competitive performance similar to and even surpasses the other regularization-based methods deployed under traditional ANNs",
    "checked": true,
    "id": "bf6aa1317cdebcd7a2e60f12c5071ab08aa84335",
    "semantic_title": "efficient spiking neural networks with sparse selective activation for continual learning",
    "citation_count": 3,
    "authors": [
      "Jiangrong Shen",
      "Wenyao Ni",
      "Qi Xu",
      "Huajin Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27818": {
    "title": "Boosting Neural Cognitive Diagnosis with Student's Affective State Modeling",
    "volume": "main",
    "abstract": "Cognitive Diagnosis Modeling aims to infer students' proficiency level on knowledge concepts from their response logs. Existing methods typically model students' response processes as the interaction between students and exercises or concepts based on hand-crafted or deeply-learned interaction functions. Despite their promising achievements, they fail to consider the relationship between students' cognitive states and affective states in learning, e.g., the feelings of frustration, boredom, or confusion with the learning content, which is insufficient for comprehensive cognitive diagnosis in intelligent education. To fill the research gap, we propose a novel Affect-aware Cognitive Diagnosis (ACD) model which can effectively diagnose the knowledge proficiency levels of students by taking into consideration the affective factors. Specifically, we first design a student affect perception module under the assumption that the affective state is jointly influenced by the student's affect trait and the difficulty of the exercise. Then, our inferred affective distribution is further used to estimate the student's subjective factors, i.e., guessing and slipping, respectively. Finally, we integrate the estimated guessing and slipping parameters with the basic neural cognitive diagnosis framework based on the DINA model, which facilitates the modeling of complex exercising interactions in a more accurate and interpretable fashion. Besides, we also extend our affect perception module in an unsupervised learning setting based on contrastive learning, thus significantly improving the compatibility of our ACD. To the best of our knowledge, we are the first to unify the cognition modeling and affect modeling into the same framework for student cognitive diagnosis. Extensive experiments on real-world datasets clearly demonstrate the effectiveness of our ACD. Our code is available at https://github.com/zeng-zhen/ACD",
    "checked": true,
    "id": "275c962a5d5f9e1b36e5a20fea01edec14a3e085",
    "semantic_title": "boosting neural cognitive diagnosis with student's affective state modeling",
    "citation_count": 2,
    "authors": [
      "Shanshan Wang",
      "Zhen Zeng",
      "Xun Yang",
      "Ke Xu",
      "Xingyi Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27819": {
    "title": "DMMR: Cross-Subject Domain Generalization for EEG-Based Emotion Recognition via Denoising Mixed Mutual Reconstruction",
    "volume": "main",
    "abstract": "Electroencephalography (EEG) has proven to be effective in emotion analysis. However, current methods struggle with individual variations, complicating the generalization of models trained on data from source subjects to unseen target subjects. To tackle this issue, we propose the Denoising Mixed Mutual Reconstruction (DMMR) model, employing a two-stage pre-training followed by fine-tuning approach. During the pre-training phase, DMMR leverages self-supervised learning through a multi-decoder autoencoder, which encodes and reconstructs features of one subject, aiming to generate features resembling those from other subjects within the same category, thereby encouraging the encoder to learn subject-invariant features. We introduce a hidden-layer mixed data augmentation approach to mitigate the limitations posed by the scarcity of source data, thereby extending the method to a two-stage process. To bolster stability against noise, we incorporate a noise injection method, named \"Time Steps Shuffling\", into the input data. During the fine-tuning phase, an emotion classifier is integrated to extract emotion-related features. Experimental accuracy on the SEED and SEED-IV datasets reached 88.27% (±5.62) and 72.70% (±8.01), respectively, demonstrating state-of-the-art and comparable performance, thereby showcasing the superiority of DMMR. The proposed data augmentation and noise injection methods were observed to complementarily enhance accuracy and stability, thus alleviating the aforementioned issues",
    "checked": true,
    "id": "227e7709ea488d205fe8f87c321afc7a8570bf4e",
    "semantic_title": "dmmr: cross-subject domain generalization for eeg-based emotion recognition via denoising mixed mutual reconstruction",
    "citation_count": 0,
    "authors": [
      "Yiming Wang",
      "Bin Zhang",
      "Yujiao Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27820": {
    "title": "Transient Glimpses: Unveiling Occluded Backgrounds through the Spike Camera",
    "volume": "main",
    "abstract": "The de-occlusion problem, involving extracting clear background images by removing foreground occlusions, holds significant practical importance but poses considerable challenges. Most current research predominantly focuses on generating discrete images from calibrated camera arrays, but this approach often struggles with dense occlusions and fast motions due to limited perspectives and motion blur. To overcome these limitations, an effective solution requires the integration of multi-view visual information. The spike camera, as an innovative neuromorphic sensor, shows promise with its ultra-high temporal resolution and dynamic range. In this study, we propose a novel approach that utilizes a single spike camera for continuous multi-view imaging to address occlusion removal. By rapidly moving the spike camera, we capture a dense stream of spikes from occluded scenes. Our model, SpkOccNet, processes these spikes by integrating multi-view spatial-temporal information via long-short-window feature extractor (LSW) and employs a novel cross-view mutual attention-based module (CVA) for effective fusion and refinement. Additionally, to facilitate research in occlusion removal, we introduce the S-OCC dataset, which consists of real-world spike-based data. Experimental results demonstrate the efficiency and generalization capabilities of our model in effectively removing dense occlusions across diverse scenes. Public project page: https://github.com/Leozhangjiyuan/SpikeDeOcclusion",
    "checked": true,
    "id": "d60ba069365512f4203c4e72e5741a19d0a55f4c",
    "semantic_title": "transient glimpses: unveiling occluded backgrounds through the spike camera",
    "citation_count": 0,
    "authors": [
      "Jiyuan Zhang",
      "Shiyan Chen",
      "Yajing Zheng",
      "Zhaofei Yu",
      "Tiejun Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27821": {
    "title": "Open-Set Facial Expression Recognition",
    "volume": "main",
    "abstract": "Facial expression recognition (FER) models are typically trained on datasets with a fixed number of seven basic classes. However, recent research works (Cowen et al. 2021; Bryant et al. 2022; Kollias 2023) point out that there are far more expressions than the basic ones. Thus, when these models are deployed in the real world, they may encounter unknown classes, such as compound expressions that cannot be classified into existing basic classes. To address this issue, we propose the open-set FER task for the first time. Though there are many existing open-set recognition methods, we argue that they do not work well for open-set FER because FER data are all human faces with very small inter-class distances, which makes the open-set samples very similar to close-set samples. In this paper, we are the first to transform the disadvantage of small inter-class distance into an advantage by proposing a new way for open-set FER. Specifically, we find that small inter-class distance allows for sparsely distributed pseudo labels of open-set samples, which can be viewed as symmetric noisy labels. Based on this novel observation, we convert the open-set FER to a noisy label detection problem. We further propose a novel method that incorporates attention map consistency and cycle training to detect the open-set samples. Extensive experiments on various FER datasets demonstrate that our method clearly outperforms state-of-the-art open-set recognition methods by large margins. Code is available at https://github.com/zyh-uaiaaaa",
    "checked": true,
    "id": "43f02c665e1f1b8638dc567f185c27588e39889b",
    "semantic_title": "open-set facial expression recognition",
    "citation_count": 1,
    "authors": [
      "Yuhang Zhang",
      "Yue Yao",
      "Xuannan Liu",
      "Lixiong Qin",
      "Wenjing Wang",
      "Weihong Deng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27822": {
    "title": "Bootstrapping Cognitive Agents with a Large Language Model",
    "volume": "main",
    "abstract": "Large language models contain noisy general knowledge of the world, yet are hard to train or fine-tune. In contrast cognitive architectures have excellent interpretability and are flexible to update but require a lot of manual work to instantiate. In this work, we combine the best of both worlds: bootstrapping a cognitive-based model with the noisy knowledge encoded in large language models. Through an embodied agent doing kitchen tasks, we show that our proposed framework yields better efficiency compared to an agent entirely based on large language models. Our experiments also indicate that the cognitive agent bootstrapped using this framework can generalize to novel environments and be scaled to complex tasks",
    "checked": true,
    "id": "99988640d3926f85c589a0bf96fa5487c218af3b",
    "semantic_title": "bootstrapping cognitive agents with a large language model",
    "citation_count": 1,
    "authors": [
      "Feiyu Zhu",
      "Reid Simmons"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27823": {
    "title": "Data Augmented Graph Neural Networks for Personality Detection",
    "volume": "main",
    "abstract": "Personality detection is a fundamental task for user psychology research. One of the biggest challenges in personality detection lies in the quantitative limitation of labeled data collected by completing the personality questionnaire, which is very time-consuming and labor-intensive. Most of the existing works are mainly devoted to learning the rich representations of posts based on labeled data. However, they still suffer from the inherent weakness of the amount limitation of labels, which potentially restricts the capability of the model to deal with unseen data. In this paper, we construct a heterogeneous personality graph for each labeled and unlabeled user and develop a novel psycholinguistic augmented graph neural network to detect personality in a semi-supervised manner, namely Semi-PerGCN. Specifically, our model first explores a supervised Personality Graph Neural Network (PGNN) to refine labeled user representation on the heterogeneous graph. For the remaining massive unlabeled users, we utilize the empirical psychological knowledge of the Linguistic Inquiry and Word Count (LIWC) lexicon for multi-view graph augmentation and perform unsupervised graph consistent constraints on the parameters shared PGNN. During the learning process of finite labeled users, noise-invariant learning on a large scale of unlabeled users is combined to enhance the generalization ability. Extensive experiments on three real-world datasets, Youtube, PAN2015, and MyPersonality demonstrate the effectiveness of our Semi-PerGCN in personality detection, especially in scenarios with limited labeled users",
    "checked": true,
    "id": "7189401cb3a6a6f8e0fe7b16fb05f2abe2ff9fc7",
    "semantic_title": "data augmented graph neural networks for personality detection",
    "citation_count": 1,
    "authors": [
      "Yangfu Zhu",
      "Yue Xia",
      "Meiling Li",
      "Tingting Zhang",
      "Bin Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27824": {
    "title": "DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "Recent progresses in large-scale text-to-image models have yielded remarkable accomplishments, finding various applications in art domain. However, expressing unique characteristics of an artwork (e.g. brushwork, colortone, or composition) with text prompts alone may encounter limitations due to the inherent constraints of verbal description. To this end, we introduce DreamStyle, a novel framework designed for artistic image synthesis, proficient in both text-to-image synthesis and style transfer. DreamStyle optimizes a multi-stage textual embedding with a context-aware text prompt, resulting in prominent image quality. In addition, with content and style guidance, DreamStyle exhibits flexibility to accommodate a range of style references. Experimental results demonstrate its superior performance across multiple scenarios, suggesting its promising potential in artistic product creation. Project page: https://nmhkahn.github.io/dreamstyler/",
    "checked": true,
    "id": "68708ea853006387537df85f4b811f7aeab6c4f5",
    "semantic_title": "dreamstyler: paint by style inversion with text-to-image diffusion models",
    "citation_count": 11,
    "authors": [
      "Namhyuk Ahn",
      "Junsoo Lee",
      "Chunggi Lee",
      "Kunhee Kim",
      "Daesik Kim",
      "Seung-Hun Nam",
      "Kibeom Hong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27825": {
    "title": "Context Enhanced Transformer for Single Image Object Detection in Video Data",
    "volume": "main",
    "abstract": "With the increasing importance of video data in real-world applications, there is a rising need for efficient object detection methods that utilize temporal information. While existing video object detection (VOD) techniques employ various strategies to address this challenge, they typically depend on locally adjacent frames or randomly sampled images within a clip. Although recent Transformer-based VOD methods have shown promising results, their reliance on multiple inputs and additional network complexity to incorporate temporal information limits their practical applicability. In this paper, we propose a novel approach to single image object detection, called Context Enhanced TRansformer (CETR), by incorporating temporal context into DETR using a newly designed memory module. To efficiently store temporal information, we construct a class-wise memory that collects contextual information across data. Additionally, we present a classification-based sampling technique to selectively utilize the relevant memory for the current image. In the testing, We introduce a test-time memory adaptation method that updates individual memory functions by considering the test distribution. Experiments with CityCam and ImageNet VID datasets exhibit the efficiency of the framework on various video systems. The project page and code will be made available at: https://ku-cvlab.github.io/CETR",
    "checked": false,
    "id": "914e54c4c7a54d593f5f88332ca4b3ab4c71abe9",
    "semantic_title": "context enhanced transformer for single image object detection",
    "citation_count": 0,
    "authors": [
      "Seungjun An",
      "Seonghoon Park",
      "Gyeongnyeon Kim",
      "Jeongyeol Baek",
      "Byeongwon Lee",
      "Seungryong Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27826": {
    "title": "SHaRPose: Sparse High-Resolution Representation for Human Pose Estimation",
    "volume": "main",
    "abstract": "High-resolution representation is essential for achieving good performance in human pose estimation models. To obtain such features, existing works utilize high-resolution input images or fine-grained image tokens. However, this dense high-resolution representation brings a significant computational burden. In this paper, we address the following question: \"Only sparse human keypoint locations are detected for human pose estimation, is it really necessary to describe the whole image in a dense, high-resolution manner?\" Based on dynamic transformer models, we propose a framework that only uses Sparse High-resolution Representations for human Pose estimation (SHaRPose). In detail, SHaRPose consists of two stages. At the coarse stage, the relations between image regions and keypoints are dynamically mined while a coarse estimation is generated. Then, a quality predictor is applied to decide whether the coarse estimation results should be refined. At the fine stage, SHaRPose builds sparse high-resolution representations only on the regions related to the keypoints and provides refined high-precision human pose estimations. Extensive experiments demonstrate the outstanding performance of the proposed method. Specifically, compared to the state-of-the-art method ViTPose, our model SHaRPose-Base achieves 77.4 AP (+0.5 AP) on the COCO validation set and 76.7 AP (+0.5 AP) on the COCO test-dev set, and infers at a speed of 1.4x faster than ViTPose-Base. Code is available at https://github.com/AnxQ/sharpose",
    "checked": true,
    "id": "3aa878e0b792f3c220ec58f26cebca4d32b27b3d",
    "semantic_title": "sharpose: sparse high-resolution representation for human pose estimation",
    "citation_count": 2,
    "authors": [
      "Xiaoqi An",
      "Lin Zhao",
      "Chen Gong",
      "Nannan Wang",
      "Di Wang",
      "Jian Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27827": {
    "title": "Comparing the Robustness of Modern No-Reference Image- and Video-Quality Metrics to Adversarial Attacks",
    "volume": "main",
    "abstract": "Nowadays, neural-network-based image- and video-quality metrics perform better than traditional methods. However, they also became more vulnerable to adversarial attacks that increase metrics' scores without improving visual quality. The existing benchmarks of quality metrics compare their performance in terms of correlation with subjective quality and calculation time. Nonetheless, the adversarial robustness of image-quality metrics is also an area worth researching. This paper analyses modern metrics' robustness to different adversarial attacks. We adapted adversarial attacks from computer vision tasks and compared attacks' efficiency against 15 no-reference image- and video-quality metrics. Some metrics showed high resistance to adversarial attacks, which makes their usage in benchmarks safer than vulnerable metrics. The benchmark accepts submissions of new metrics for researchers who want to make their metrics more robust to attacks or to find such metrics for their needs. The latest results can be found online: https://videoprocessing.ai/benchmarks/metrics-robustness.html",
    "checked": true,
    "id": "228eeb5e74cfa52761434a125998bc5c2a674859",
    "semantic_title": "comparing the robustness of modern no-reference image- and video-quality metrics to adversarial attacks",
    "citation_count": 4,
    "authors": [
      "Anastasia Antsiferova",
      "Khaled Abud",
      "Aleksandr Gushchin",
      "Ekaterina Shumitskaya",
      "Sergey Lavrushkin",
      "Dmitriy Vatolin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27828": {
    "title": "DocFormerv2: Local Features for Document Understanding",
    "volume": "main",
    "abstract": "We propose DocFormerv2, a multi-modal transformer for Visual Document Understanding (VDU). The VDU domain entails understanding documents (beyond mere OCR predictions) e.g., extracting information from a form, VQA for documents and other tasks. VDU is challenging as it needs a model to make sense of multiple modalities (visual, language and spatial) to make a prediction. Our approach, termed DocFormerv2 is an encoder-decoder transformer which takes as input - vision, language and spatial features. DocFormerv2 is pre-trained with unsupervised tasks employed asymmetrically i.e., two novel document tasks on encoder and one on the auto-regressive decoder. The unsupervised tasks have been carefully designed to ensure that the pre-training encourages local-feature alignment between multiple modalities. DocFormerv2 when evaluated on nine challenging datasets shows state-of-the-art performance on all over strong baselines - On TabFact (+4.3%), InfoVQA (+1.4%), FUNSD (+1.0%). Furthermore, to show generalization capabilities, on three VQA tasks involving scene-text, DocFormerv2 outperforms previous comparably-sized models and even does better than much larger models (such as GIT2, PaLI and Flamingo) on these tasks. Extensive ablations show that due to its novel pre-training tasks, DocFormerv2 understands multiple modalities better than prior-art in VDU",
    "checked": true,
    "id": "c4b39dd45e64324198d2f47bc191b12ab7eeafae",
    "semantic_title": "docformerv2: local features for document understanding",
    "citation_count": 17,
    "authors": [
      "Srikar Appalaraju",
      "Peng Tang",
      "Qi Dong",
      "Nishant Sankaran",
      "Yichu Zhou",
      "R. Manmatha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27829": {
    "title": "Exposing the Deception: Uncovering More Forgery Clues for Deepfake Detection",
    "volume": "main",
    "abstract": "Deepfake technology has given rise to a spectrum of novel and compelling applications. Unfortunately, the widespread proliferation of high-fidelity fake videos has led to pervasive confusion and deception, shattering our faith that seeing is believing. One aspect that has been overlooked so far is that current deepfake detection approaches may easily fall into the trap of overfitting, focusing only on forgery clues within one or a few local regions. Moreover, existing works heavily rely on neural networks to extract forgery features, lacking theoretical constraints guaranteeing that sufficient forgery clues are extracted and superfluous features are eliminated. These deficiencies culminate in unsatisfactory accuracy and limited generalizability in real-life scenarios. In this paper, we try to tackle these challenges through three designs: (1) We present a novel framework to capture broader forgery clues by extracting multiple non-overlapping local representations and fusing them into a global semantic-rich feature. (2) Based on the information bottleneck theory, we derive Local Information Loss to guarantee the orthogonality of local representations while preserving comprehensive task-relevant information. (3) Further, to fuse the local representations and remove task-irrelevant information, we arrive at a Global Information Loss through the theoretical analysis of mutual information. Empirically, our method achieves state-of-the-art performance on five benchmark datasets. Our code is available at https://github.com/QingyuLiu/Exposing-the-Deception, hoping to inspire researchers",
    "checked": true,
    "id": "a963409107c15b9148e1fedbce20c136f34e2ecc",
    "semantic_title": "exposing the deception: uncovering more forgery clues for deepfake detection",
    "citation_count": 4,
    "authors": [
      "Zhongjie Ba",
      "Qingyu Liu",
      "Zhenguang Liu",
      "Shuang Wu",
      "Feng Lin",
      "Li Lu",
      "Kui Ren"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27830": {
    "title": "Prompt-Based Distribution Alignment for Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "Recently, despite the unprecedented success of large pre-trained visual-language models (VLMs) on a wide range of downstream tasks, the real-world unsupervised domain adaptation (UDA) problem is still not well explored. Therefore, in this paper, we first experimentally demonstrate that the unsupervised-trained VLMs can significantly reduce the distribution discrepancy between source and target domains, thereby improving the performance of UDA. However, a major challenge for directly deploying such models on downstream UDA tasks is prompt engineering, which requires aligning the domain knowledge of source and target domains, since the performance of UDA is severely influenced by a good domain-invariant representation. We further propose a Prompt-based Distribution Alignment (PDA) method to incorporate the domain knowledge into prompt learning. Specifically, PDA employs a two-branch prompt-tuning paradigm, namely base branch and alignment branch. The base branch focuses on integrating class-related representation into prompts, ensuring discrimination among different classes. To further minimize domain discrepancy, for the alignment branch, we construct feature banks for both the source and target domains and propose image-guided feature tuning (IFT) to make the input attend to feature banks, which effectively integrates self-enhanced and cross-domain features into the model. In this way, these two branches can be mutually promoted to enhance the adaptation of VLMs for UDA. We conduct extensive experiments on three benchmarks to demonstrate that our proposed PDA achieves state-of-the-art performance. The code is available at https://github.com/BaiShuanghao/Prompt-based-Distribution-Alignment",
    "checked": true,
    "id": "bd46cb09425c1eb8e2d2e7dd612d839cdf4d0f39",
    "semantic_title": "prompt-based distribution alignment for unsupervised domain adaptation",
    "citation_count": 9,
    "authors": [
      "Shuanghao Bai",
      "Min Zhang",
      "Wanqi Zhou",
      "Siteng Huang",
      "Zhirong Luan",
      "Donglin Wang",
      "Badong Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27831": {
    "title": "Local-Global Multi-Modal Distillation for Weakly-Supervised Temporal Video Grounding",
    "volume": "main",
    "abstract": "This paper for the first time leverages multi-modal videos for weakly-supervised temporal video grounding. As labeling the video moment is labor-intensive and subjective, the weakly-supervised approaches have gained increasing attention in recent years. However, these approaches could inherently compromise performance due to inadequate supervision. Therefore, to tackle this challenge, we for the first time pay attention to exploiting complementary information extracted from multi-modal videos (e.g., RGB frames, optical flows), where richer supervision is naturally introduced in the weaklysupervised context. Our motivation is that by integrating different modalities of the videos, the model is learned from synergic supervision and thereby can attain superior generalization capability. However, addressing multiple modalities† would also inevitably introduce additional computational overhead, and might become inapplicable if a particular modality is inaccessible. To solve this issue, we adopt a novel route: building a multi-modal distillation algorithm to capitalize on the multi-modal knowledge as supervision for model training, while still being able to work with only the single modal input during inference. As such, we can utilize the benefits brought by the supplementary nature of multiple modalities, without compromising the applicability in practical scenarios. Specifically, we first propose a cross-modal mutual learning framework and train a sophisticated teacher model to learn collaboratively from the multi-modal videos. Then we identify two sorts of knowledge from the teacher model, i.e., temporal boundaries and semantic activation map. And we devise a local-global distillation algorithm to transfer this knowledge to a student model of single-modal input at both local and global levels. Extensive experiments on large-scale datasets demonstrate that our method achieves state-of-the-art performance with/without multi-modal inputs",
    "checked": true,
    "id": "d00324945509fc9fe109153457512b66044e43dc",
    "semantic_title": "local-global multi-modal distillation for weakly-supervised temporal video grounding",
    "citation_count": 0,
    "authors": [
      "Peijun Bao",
      "Yong Xia",
      "Wenhan Yang",
      "Boon Poh Ng",
      "Meng Hwa Er",
      "Alex C. Kot"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27832": {
    "title": "Omnipotent Distillation with LLMs for Weakly-Supervised Natural Language Video Localization: When Divergence Meets Consistency",
    "volume": "main",
    "abstract": "Natural language video localization plays a pivotal role in video understanding, and leveraging weakly-labeled data is considered a promising approach to circumvent the laborintensive process of manual annotations. However, this approach encounters two significant challenges: 1) limited input distribution, namely that the limited writing styles of the language query, annotated by human annotators, hinder the model's generalization to real-world scenarios with diverse vocabularies and sentence structures; 2) the incomplete ground truth, whose supervision guidance is insufficient. To overcome these challenges, we propose an omnipotent distillation algorithm with large language models (LLM). The distribution of the input sample is enriched to obtain diverse multi-view versions while a consistency then comes to regularize the consistency of their results for distillation. Specifically, we first train our teacher model with the proposed intra-model agreement, where multiple sub-models are supervised by each other. Then, we leverage the LLM to paraphrase the language query and distill the teacher model to a lightweight student model by enforcing the consistency between the localization results of the paraphrased sentence and the original one. In addition, to assess the generalization of the model across different dimensions of language variation, we create extensive datasets by building upon existing datasets. Our experiments demonstrate substantial performance improvements adaptively to diverse kinds of language queries",
    "checked": true,
    "id": "ea0da979d3232ddaf922c11a04a1d0dfda04661f",
    "semantic_title": "omnipotent distillation with llms for weakly-supervised natural language video localization: when divergence meets consistency",
    "citation_count": 0,
    "authors": [
      "Peijun Bao",
      "Zihao Shao",
      "Wenhan Yang",
      "Boon Poh Ng",
      "Meng Hwa Er",
      "Alex C. Kot"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27833": {
    "title": "Improving Diffusion-Based Image Restoration with Error Contraction and Error Correction",
    "volume": "main",
    "abstract": "Generative diffusion prior captured from the off-the-shelf denoising diffusion generative model has recently attained significant interest. However, several attempts have been made to adopt diffusion models to noisy inverse problems either fail to achieve satisfactory results or require a few thousand iterations to achieve high-quality reconstructions. In this work, we propose a diffusion-based image restoration with error contraction and error correction (DiffECC) method. Two strategies are introduced to contract the restoration error in the posterior sampling process. First, we combine existing CNN-based approaches with diffusion models to ensure data consistency from the beginning. Second, to amplify the error contraction effects of the noise, a restart sampling algorithm is designed. In the error correction strategy, the estimation-correction idea is proposed on both the data term and the prior term. Solving them iteratively within the diffusion sampling framework leads to superior image generation results. Experimental results for image restoration tasks such as super-resolution (SR), Gaussian deblurring, and motion deblurring demonstrate that our approach can reconstruct high-quality images compared with state-of-the-art sampling-based diffusion models",
    "checked": true,
    "id": "5f417528149d7a5e1a00acb24b9d63cd7f7e123b",
    "semantic_title": "improving diffusion-based image restoration with error contraction and error correction",
    "citation_count": 1,
    "authors": [
      "Qiqi Bao",
      "Zheng Hui",
      "Rui Zhu",
      "Peiran Ren",
      "Xuansong Xie",
      "Wenming Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27834": {
    "title": "Relevant Intrinsic Feature Enhancement Network for Few-Shot Semantic Segmentation",
    "volume": "main",
    "abstract": "For few-shot semantic segmentation, the primary task is to extract class-specific intrinsic information from limited labeled data. However, the semantic ambiguity and inter-class similarity of previous methods limit the accuracy of pixel-level foreground-background classification. To alleviate these issues, we propose the Relevant Intrinsic Feature Enhancement Network (RiFeNet). To improve the semantic consistency of foreground instances, we propose an unlabeled branch as an efficient data utilization method, which teaches the model how to extract intrinsic features robust to intra-class differences. Notably, during testing, the proposed unlabeled branch is excluded without extra unlabeled data and computation. Furthermore, we extend the inter-class variability between foreground and background by proposing a novel multi-level prototype generation and interaction module. The different-grained complementarity between global and local prototypes allows for better distinction between similar categories. The qualitative and quantitative performance of RiFeNet surpasses the state-of-the-art methods on PASCAL-5i and COCO benchmarks",
    "checked": true,
    "id": "b4103ca231ce058122304b64d62aa67de8e32e70",
    "semantic_title": "relevant intrinsic feature enhancement network for few-shot semantic segmentation",
    "citation_count": 1,
    "authors": [
      "Xiaoyi Bao",
      "Jie Qin",
      "Siyang Sun",
      "Xingang Wang",
      "Yun Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27835": {
    "title": "Image Safeguarding: Reasoning with Conditional Vision Language Model and Obfuscating Unsafe Content Counterfactually",
    "volume": "main",
    "abstract": "Social media platforms are being increasingly used by malicious actors to share unsafe content, such as images depicting sexual activity, cyberbullying, and self-harm. Consequently, major platforms use artificial intelligence (AI) and human moderation to obfuscate such images to make them safer. Two critical needs for obfuscating unsafe images is that an accurate rationale for obfuscating image regions must be provided, and the sensitive regions should be obfuscated (e.g. blurring) for users' safety. This process involves addressing two key problems: (1) the reason for obfuscating unsafe images demands the platform to provide an accurate rationale that must be grounded in unsafe image-specific attributes, and (2) the unsafe regions in the image must be minimally obfuscated while still depicting the safe regions. In this work, we address these key issues by first performing visual reasoning by designing a visual reasoning model (VLM) conditioned on pre-trained unsafe image classifiers to provide an accurate rationale grounded in unsafe image attributes, and then proposing a counterfactual explanation algorithm that minimally identifies and obfuscates unsafe regions for safe viewing, by first utilizing an unsafe image classifier attribution matrix to guide segmentation for a more optimal subregion segmentation followed by an informed greedy search to determine the minimum number of subregions required to modify the classifier's output based on attribution score. Extensive experiments on uncurated data from social networks emphasize the efficacy of our proposed method. We make our code available at: https://github.com/SecureAIAutonomyLab/ConditionalVLM",
    "checked": true,
    "id": "dc8a42d67258d6811506406056406fe31800bbed",
    "semantic_title": "image safeguarding: reasoning with conditional vision language model and obfuscating unsafe content counterfactually",
    "citation_count": 1,
    "authors": [
      "Mazal Bethany",
      "Brandon Wherry",
      "Nishant Vishwamitra",
      "Peyman  Najafirad"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27836": {
    "title": "DanceAnyWay: Synthesizing Beat-Guided 3D Dances with Randomized Temporal Contrastive Learning",
    "volume": "main",
    "abstract": "We present DanceAnyWay, a generative learning method to synthesize beat-guided dances of 3D human characters synchronized with music. Our method learns to disentangle the dance movements at the beat frames from the dance movements at all the remaining frames by operating at two hierarchical levels. At the coarser \"beat\" level, it encodes the rhythm, pitch, and melody information of the input music via dedicated feature representations only at the beat frames. It leverages them to synthesize the beat poses of the target dances using a sequence-to-sequence learning framework. At the finer \"repletion\" level, our method encodes similar rhythm, pitch, and melody information from all the frames of the input music via dedicated feature representations. It generates the full dance sequences by combining the synthesized beat and repletion poses and enforcing plausibility through an adversarial learning framework. Our training paradigm also enforces fine-grained diversity in the synthesized dances through a randomized temporal contrastive loss, which ensures different segments of the dance sequences have different movements and avoids motion freezing or collapsing to repetitive movements. We evaluate the performance of our approach through extensive experiments on the benchmark AIST++ dataset and observe improvements of about 7%-12% in motion quality metrics and 1.5%-4% in motion diversity metrics over the current baselines, respectively. We also conducted a user study to evaluate the visual quality of our synthesized dances. We noted that, on average, the samples generated by our method were about 9-48% more preferred by the participants and had a 4-27% better five-point Likert-scale score over the best available current baseline in terms of motion quality and synchronization. Our source code and project page are available at https://github.com/aneeshbhattacharya/DanceAnyWay",
    "checked": true,
    "id": "c5381cc8c5eb95fa67afcae1e3849bda186e296d",
    "semantic_title": "danceanyway: synthesizing beat-guided 3d dances with randomized temporal contrastive learning",
    "citation_count": 1,
    "authors": [
      "Aneesh Bhattacharya",
      "Manas Paranjape",
      "Uttaran Bhattacharya",
      "Aniket Bera"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27837": {
    "title": "DiffSED: Sound Event Detection with Denoising Diffusion",
    "volume": "main",
    "abstract": "Sound Event Detection (SED) aims to predict the temporal boundaries of all the events of interest and their class labels, given an unconstrained audio sample. Taking either the split-and-classify (i.e., frame-level) strategy or the more principled event-level modeling approach, all existing methods consider the SED problem from the discriminative learning perspective. In this work, we reformulate the SED problem by taking a generative learning perspective. Specifically, we aim to generate sound temporal boundaries from noisy proposals in a denoising diffusion process, conditioned on a target audio sample. During training, our model learns to reverse the noising process by converting noisy latent queries to the ground-truth versions in the elegant Transformer decoder framework. Doing so enables the model generate accurate event boundaries from even noisy queries during inference. Extensive experiments on the Urban-SED and EPIC-Sounds datasets demonstrate that our model significantly outperforms existing alternatives, with 40+% faster convergence in training. Code: https://github.com/Surrey-UPLab/DiffSED",
    "checked": true,
    "id": "33cd70c6e1cd4c9b504d40c9f170ca95af479272",
    "semantic_title": "diffsed: sound event detection with denoising diffusion",
    "citation_count": 3,
    "authors": [
      "Swapnil Bhosale",
      "Sauradip Nag",
      "Diptesh Kanojia",
      "Jiankang Deng",
      "Xiatian Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27838": {
    "title": "Learning Generalized Segmentation for Foggy-Scenes by Bi-directional Wavelet Guidance",
    "volume": "main",
    "abstract": "Learning scene semantics that can be well generalized to foggy conditions is important for safety-crucial applications such as autonomous driving. Existing methods need both annotated clear images and foggy images to train a curriculum domain adaptation model. Unfortunately, these methods can only generalize to the target foggy domain that has seen in the training stage, but the foggy domains vary a lot in both urban-scene styles and fog styles. In this paper, we propose to learn scene segmentation well generalized to foggy-scenes under the domain generalization setting, which does not involve any foggy images in the training stage and can generalize to any arbitrary unseen foggy scenes. We argue that an ideal segmentation model that can be well generalized to foggy-scenes need to simultaneously enhance the content, de-correlate the urban-scene style and de-correlate the fog style. As the content (e.g., scene semantic) rests more in low-frequency features while the style of urban-scene and fog rests more in high-frequency features, we propose a novel bi-directional wavelet guidance (BWG) mechanism to realize the above three objectives in a divide-and-conquer manner. With the aid of Haar wavelet transformation, the low frequency component is concentrated on the content enhancement self-attention, while the high frequency component is shifted to the style and fog self-attention for de-correlation purpose. It is integrated into existing mask-level Transformer segmentation pipelines in a learnable fashion. Large-scale experiments are conducted on four foggy-scene segmentation datasets under a variety of interesting settings. The proposed method significantly outperforms existing directly-supervised, curriculum domain adaptation and domain generalization segmentation methods. Source code is available at https://github.com/BiQiWHU/BWG",
    "checked": true,
    "id": "337c08ff7f17f03fffb6acb82be1a12982fe003a",
    "semantic_title": "learning generalized segmentation for foggy-scenes by bi-directional wavelet guidance",
    "citation_count": 1,
    "authors": [
      "Qi Bi",
      "Shaodi You",
      "Theo Gevers"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27839": {
    "title": "Learning Generalized Medical Image Segmentation from Decoupled Feature Queries",
    "volume": "main",
    "abstract": "Domain generalized medical image segmentation requires models to learn from multiple source domains and generalize well to arbitrary unseen target domain. Such a task is both technically challenging and clinically practical, due to the domain shift problem (i.e., images are collected from different hospitals and scanners). Existing methods focused on either learning shape-invariant representation or reaching consensus among the source domains. An ideal generalized representation is supposed to show similar pattern responses within the same channel for cross-domain images. However, to deal with the significant distribution discrepancy, the network tends to capture similar patterns by multiple channels, while different cross-domain patterns are also allowed to rest in the same channel. To address this issue, we propose to leverage channel-wise decoupled deep features as queries. With the aid of cross-attention mechanism, the long-range dependency between deep and shallow features can be fully mined via self-attention and then guides the learning of generalized representation. Besides, a relaxed deep whitening transformation is proposed to learn channel-wise decoupled features in a feasible way. The proposed decoupled fea- ture query (DFQ) scheme can be seamlessly integrate into the Transformer segmentation model in an end-to-end manner. Extensive experiments show its state-of-the-art performance, notably outperforming the runner-up by 1.31% and 1.98% with DSC metric on generalized fundus and prostate benchmarks, respectively. Source code is available at https://github.com/BiQiWHU/DFQ",
    "checked": true,
    "id": "daea96370b8cb1ec555f2610307de83c8a9ee1bf",
    "semantic_title": "learning generalized medical image segmentation from decoupled feature queries",
    "citation_count": 0,
    "authors": [
      "Qi Bi",
      "Jingjun Yi",
      "Hao Zheng",
      "Wei Ji",
      "Yawen Huang",
      "Yuexiang Li",
      "Yefeng Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27840": {
    "title": "Learning Content-Enhanced Mask Transformer for Domain Generalized Urban-Scene Segmentation",
    "volume": "main",
    "abstract": "Domain-generalized urban-scene semantic segmentation (USSS) aims to learn generalized semantic predictions across diverse urban-scene styles. Unlike generic domain gap challenges, USSS is unique in that the semantic categories are often similar in different urban scenes, while the styles can vary significantly due to changes in urban landscapes, weather conditions, lighting, and other factors. Existing approaches typically rely on convolutional neural networks (CNNs) to learn the content of urban scenes. In this paper, we propose a Content-enhanced Mask TransFormer (CMFormer) for domain-generalized USSS. The main idea is to enhance the focus of the fundamental component, the mask attention mechanism, in Transformer segmentation models on content information. We have observed through empirical analysis that a mask representation effectively captures pixel segments, albeit with reduced robustness to style variations. Conversely, its lower-resolution counterpart exhibits greater ability to accommodate style variations, while being less proficient in representing pixel segments. To harness the synergistic attributes of these two approaches, we introduce a novel content-enhanced mask attention mechanism. It learns mask queries from both the image feature and its down-sampled counterpart, aiming to simultaneously encapsulate the content and address stylistic variations. These features are fused into a Transformer decoder and integrated into a multi-resolution content-enhanced mask attention learning scheme. Extensive experiments conducted on various domain-generalized urban-scene segmentation datasets demonstrate that the proposed CMFormer significantly outperforms existing CNN-based methods by up to 14.0% mIoU and the contemporary HGFormer by up to 1.7% mIoU. The source code is publicly available at https://github.com/BiQiWHU/CMFormer",
    "checked": true,
    "id": "efc16345ea3f7fef1a823486ce0c26a3d2c9ccaf",
    "semantic_title": "learning content-enhanced mask transformer for domain generalized urban-scene segmentation",
    "citation_count": 7,
    "authors": [
      "Qi Bi",
      "Shaodi You",
      "Theo Gevers"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27841": {
    "title": "ShapeBoost: Boosting Human Shape Estimation with Part-Based Parameterization and Clothing-Preserving Augmentation",
    "volume": "main",
    "abstract": "Accurate human shape recovery from a monocular RGB image is a challenging task because humans come in different shapes and sizes and wear different clothes. In this paper, we propose ShapeBoost, a new human shape recovery framework that achieves pixel-level alignment even for rare body shapes and high accuracy for people wearing different types of clothes. Unlike previous approaches that rely on the use of PCA-based shape coefficients, we adopt a new human shape parameterization that decomposes the human shape into bone lengths and the mean width of each part slice. This part-based parameterization technique achieves a balance between flexibility and validity using a semi-analytical shape reconstruction algorithm. Based on this new parameterization, a clothing-preserving data augmentation module is proposed to generate realistic images with diverse body shapes and accurate annotations. Experimental results show that our method outperforms other state-of-the-art methods in diverse body shape situations as well as in varied clothing situations",
    "checked": true,
    "id": "1890ed951ffdcf46e93a31c79fe6e882f3c4c5ce",
    "semantic_title": "shapeboost: boosting human shape estimation with part-based parameterization and clothing-preserving augmentation",
    "citation_count": 0,
    "authors": [
      "Siyuan Bian",
      "Jiefeng Li",
      "Jiasheng Tang",
      "Cewu Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27842": {
    "title": "MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level Image-Concept Alignment",
    "volume": "main",
    "abstract": "Black-box deep learning approaches have showcased significant potential in the realm of medical image analysis. However, the stringent trustworthiness requirements intrinsic to the medical field have catalyzed research into the utilization of Explainable Artificial Intelligence (XAI), with a particular focus on concept-based methods. Existing concept-based methods predominantly apply concept annotations from a single perspective (e.g., global level), neglecting the nuanced semantic relationships between sub-regions and concepts embedded within medical images. This leads to underutilization of the valuable medical information and may cause models to fall short in harmoniously balancing interpretability and performance when employing inherently interpretable architectures such as Concept Bottlenecks. To mitigate these shortcomings, we propose a multi-modal explainable disease diagnosis framework that meticulously aligns medical images and clinical-related concepts semantically at multiple strata, encompassing the image level, token level, and concept level. Moreover, our method allows for model intervention and offers both textual and visual explanations in terms of human-interpretable concepts. Experimental results on three skin image datasets demonstrate that our method, while preserving model interpretability, attains high performance and label efficiency for concept detection and disease diagnosis. The code is available at https://github.com/Tommy-Bie/MICA",
    "checked": true,
    "id": "445a5d47b0cc0958ab4d539c829fd8d4400ce8f3",
    "semantic_title": "mica: towards explainable skin lesion diagnosis via multi-level image-concept alignment",
    "citation_count": 3,
    "authors": [
      "Yequan Bie",
      "Luyang Luo",
      "Hao Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27843": {
    "title": "VIXEN: Visual Text Comparison Network for Image Difference Captioning",
    "volume": "main",
    "abstract": "We present VIXEN - a technique that succinctly summarizes in text the visual differences between a pair of images in order to highlight any content manipulation present. Our proposed network linearly maps image features in a pairwise manner, constructing a soft prompt for a pretrained large language model. We address the challenge of low volume of training data and lack of manipulation variety in existing image difference captioning (IDC) datasets by training on synthetically manipulated images from the recent InstructPix2Pix dataset generated via prompt-to-prompt editing framework. We augment this dataset with change summaries produced via GPT-3. We show that VIXEN produces state-of-the-art, comprehensible difference captions for diverse image contents and edit types, offering a potential mitigation against misinformation disseminated via manipulated image content. Code and data are available at http://github.com/alexblck/vixen",
    "checked": true,
    "id": "f478e096d7802179765f5bc0d4f46da2f82b816d",
    "semantic_title": "vixen: visual text comparison network for image difference captioning",
    "citation_count": 2,
    "authors": [
      "Alexander Black",
      "Jing Shi",
      "Yifei Fan",
      "Tu Bui",
      "John Collomosse"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27844": {
    "title": "SRFormer: Text Detection Transformer with Incorporated Segmentation and Regression",
    "volume": "main",
    "abstract": "Existing techniques for text detection can be broadly classified into two primary groups: segmentation-based and regression-based methods. Segmentation models offer enhanced robustness to font variations but require intricate post-processing, leading to high computational overhead. Regression-based methods undertake instance-aware prediction but face limitations in robustness and data efficiency due to their reliance on high-level representations. In our academic pursuit, we propose SRFormer, a unified DETR-based model with amalgamated Segmentation and Regression, aiming at the synergistic harnessing of the inherent robustness in segmentation representations, along with the straightforward post-processing of instance-level regression. Our empirical analysis indicates that favorable segmentation predictions can be obtained at the initial decoder layers. In light of this, we constrain the incorporation of segmentation branches to the first few decoder layers and employ progressive regression refinement in subsequent layers, achieving performance gains while minimizing computational load from the mask. Furthermore, we propose a Mask-informed Query Enhancement module. We take the segmentation result as a natural soft-ROI to pool and extract robust pixel representations, which are then employed to enhance and diversify instance queries. Extensive experimentation across multiple benchmarks has yielded compelling findings, highlighting our method's exceptional robustness, superior training and data efficiency, as well as its state-of-the-art performance. Our code is available at https://github.com/retsuh-bqw/SRFormer-Text-Det",
    "checked": true,
    "id": "6ecf9ea86f4187c3438c87e5e9774abbaf9c83b3",
    "semantic_title": "srformer: text detection transformer with incorporated segmentation and regression",
    "citation_count": 0,
    "authors": [
      "Qingwen Bu",
      "Sungrae Park",
      "Minsoo Khang",
      "Yichuan Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27845": {
    "title": "Orthogonal Dictionary Guided Shape Completion Network for Point Cloud",
    "volume": "main",
    "abstract": "Point cloud shape completion, which aims to reconstruct the missing regions of the incomplete point clouds with plausible shapes, is an ill-posed and challenging task that benefits many downstream 3D applications. Prior approaches achieve this goal by employing a two-stage completion framework, generating a coarse yet complete seed point cloud through an encoder-decoder network, followed by refinement and upsampling. However, the encoded features suffer from information loss of the missing portion, leading to an inability of the decoder to reconstruct seed points with detailed geometric clues. To tackle this issue, we propose a novel Orthogonal Dictionary Guided Shape Completion Network (ODGNet). The proposed ODGNet consists of a Seed Generation U-Net, which leverages multi-level feature extraction and concatenation to significantly enhance the representation capability of seed points, and Orthogonal Dictionaries that can learn shape priors from training samples and thus compensate for the information loss of the missing portions during inference. Our design is simple but to the point, extensive experiment results indicate that the proposed method can reconstruct point clouds with more details and outperform previous state-of-the-art counterparts. The implementation code is available at https://github.com/corecai163/ODGNet",
    "checked": true,
    "id": "383fc37cce012859d7a1f7d7e42bf0275e4299ea",
    "semantic_title": "orthogonal dictionary guided shape completion network for point cloud",
    "citation_count": 1,
    "authors": [
      "Pingping Cai",
      "Deja Scott",
      "Xiaoguang Li",
      "Song Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27846": {
    "title": "Spherical Pseudo-Cylindrical Representation for Omnidirectional Image Super-resolution",
    "volume": "main",
    "abstract": "Omnidirectional images have attracted significant attention in recent years due to the rapid development of virtual reality technologies. Equirectangular projection (ERP), a naive form to store and transfer omnidirectional images, however, is challenging for existing two-dimensional (2D) image super-resolution (SR) methods due to its inhomogeneous distributed sampling density and distortion across latitude. In this paper, we make one of the first attempts to design a spherical pseudo-cylindrical representation, which not only allows pixels at different latitudes to adaptively adopt the best distinct sampling density but also is model-agnostic to most off-the-shelf SR methods, enhancing their performances. Specifically, we start by upsampling each latitude of the input ERP image and design a computationally tractable optimization algorithm to adaptively obtain a (sub)-optimal sampling density for each latitude of the ERP image. Addressing the distortion of ERP, we introduce a new viewport-based training loss based on the original 3D sphere format of the omnidirectional image, which inherently lacks distortion. Finally, we present a simple yet effective recursive progressive omnidirectional SR network to showcase the feasibility of our idea. The experimental results on public datasets demonstrate the effectiveness of the proposed method as well as the consistently superior performance of our method over most state-of-the-art methods both quantitatively and qualitatively",
    "checked": true,
    "id": "64c399890dabacc78a556fe19616732864e812f8",
    "semantic_title": "spherical pseudo-cylindrical representation for omnidirectional image super-resolution",
    "citation_count": 2,
    "authors": [
      "Qing Cai",
      "Mu Li",
      "Dongwei Ren",
      "Jun Lyu",
      "Haiyong Zheng",
      "Junyu Dong",
      "Yee-Hong Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27847": {
    "title": "Disentangled Diffusion-Based 3D Human Pose Estimation with Hierarchical Spatial and Temporal Denoiser",
    "volume": "main",
    "abstract": "Recently, diffusion-based methods for monocular 3D human pose estimation have achieved state-of-the-art (SOTA) performance by directly regressing the 3D joint coordinates from the 2D pose sequence. Although some methods decompose the task into bone length and bone direction prediction based on the human anatomical skeleton to explicitly incorporate more human body prior constraints, the performance of these methods is significantly lower than that of the SOTA diffusion-based methods. This can be attributed to the tree structure of the human skeleton. Direct application of the disentangled method could amplify the accumulation of hierarchical errors, propagating through each hierarchy. Meanwhile, the hierarchical information has not been fully explored by the previous methods. To address these problems, a Disentangled Diffusion-based 3D human Pose Estimation method with Hierarchical Spatial and Temporal Denoiser is proposed, termed DDHPose. In our approach: (1) We disentangle the 3d pose and diffuse the bone length and bone direction during the forward process of the diffusion model to effectively model the human pose prior. A disentanglement loss is proposed to supervise diffusion model learning. (2) For the reverse process, we propose Hierarchical Spatial and Temporal Denoiser (HSTDenoiser) to improve the hierarchical modelling of each joint. Our HSTDenoiser comprises two components: the Hierarchical-Related Spatial Transformer (HRST) and the Hierarchical-Related Temporal Transformer (HRTT). HRST exploits joint spatial information and the influence of the parent joint on each joint for spatial modeling, while HRTT utilizes information from both the joint and its hierarchical adjacent joints to explore the hierarchical temporal correlations among joints. Extensive experiments on the Human3.6M and MPI-INF-3DHP datasets show that our method outperforms the SOTA disentangled-based, non-disentangled based, and probabilistic approaches by 10.0%, 2.0%, and 1.3%, respectively",
    "checked": true,
    "id": "4ca1c9bdbd0b4170c6e1d0799b105145e34ab3bf",
    "semantic_title": "disentangled diffusion-based 3d human pose estimation with hierarchical spatial and temporal denoiser",
    "citation_count": 0,
    "authors": [
      "Qingyuan Cai",
      "Xuecai  Hu",
      "Saihui Hou",
      "Li Yao",
      "Yongzhen Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27848": {
    "title": "Rethinking the Paradigm of Content Constraints in Unpaired Image-to-Image Translation",
    "volume": "main",
    "abstract": "In an unpaired setting, lacking sufficient content constraints for image-to-image translation (I2I) tasks, GAN-based approaches are usually prone to model collapse. Current solutions can be divided into two categories, reconstruction-based and Siamese network-based. The former requires that the transformed or transforming image can be perfectly converted back to the original image, which is sometimes too strict and limits the generative performance. The latter involves feeding the original and generated images into a feature extractor and then matching their outputs. This is not efficient enough, and a universal feature extractor is not easily available. In this paper, we propose EnCo, a simple but efficient way to maintain the content by constraining the representational similarity in the latent space of patch-level features from the same stage of the encoder and decoder of the generator. For the similarity function, we use a simple MSE loss instead of contrastive loss, which is currently widely used in I2I tasks. Benefits from the design, EnCo training is extremely efficient, while the features from the encoder produce a more positive effect on the decoding, leading to more satisfying generations. In addition, we rethink the role played by discriminators in sampling patches and propose a discriminative attention-guided (DAG) patch sampling strategy to replace random sampling. DAG is parameter-free and only requires negligible computational overhead, while significantly improving the performance of the model. Extensive experiments on multiple datasets demonstrate the effectiveness and advantages of EnCo, and we achieve multiple state-of-the-art compared to previous methods",
    "checked": true,
    "id": "44a7061092a40b93996f0f3d8a1f0d91d1949549",
    "semantic_title": "rethinking the paradigm of content constraints in unpaired image-to-image translation",
    "citation_count": 0,
    "authors": [
      "Xiuding Cai",
      "Yaoyao Zhu",
      "Dong Miao",
      "Linjie Fu",
      "Yu Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27849": {
    "title": "FusionFormer: A Concise Unified Feature Fusion Transformer for 3D Pose Estimation",
    "volume": "main",
    "abstract": "Depth uncertainty is a core challenge in 3D human pose estimation, especially when the camera parameters are unknown. Previous methods try to reduce the impact of depth uncertainty by multi-view and/or multi-frame feature fusion to utilize more spatial and temporal information. However, they generally lead to marginal improvements and their performance still cannot match the camera-parameter-required methods. The reason is that their handcrafted fusion schemes cannot fuse the features flexibly, e.g., the multi-view and/or multi-frame features are fused separately. Moreover, the diverse and complicated fusion schemes make the principle for developing effective fusion schemes unclear and also raises an open problem that whether there exist more simple and elegant fusion schemes. To address these issues, this paper proposes an extremely concise unified feature fusion transformer (FusionFormer) with minimized handcrafted design for 3D pose estimation. FusionFormer fuses both the multi-view and multi-frame features in a unified fusion scheme, in which all the features are accessible to each other and thus can be fused flexibly. Experimental results on several mainstream datasets demonstrate that FusionFormer achieves state-of-the-art performance. To our best knowledge, this is the first camera-parameter-free method to outperform the existing camera-parameter-required methods, revealing the tremendous potential of camera-parameter-free models. These impressive experimental results together with our concise feature fusion scheme resolve the above open problem. Another appealing feature of FusionFormer we observe is that benefiting from its effective fusion scheme, we can achieve impressive performance with smaller model size and less FLOPs",
    "checked": true,
    "id": "f618e5599d5ed5e43cf76b418abe764cb341229c",
    "semantic_title": "fusionformer: a concise unified feature fusion transformer for 3d pose estimation",
    "citation_count": 1,
    "authors": [
      "Yanlu Cai",
      "Weizhong Zhang",
      "Yuan Wu",
      "Cheng Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27850": {
    "title": "Decoupled Textual Embeddings for Customized Image Generation",
    "volume": "main",
    "abstract": "Customized text-to-image generation, which aims to learn user-specified concepts with a few images, has drawn significant attention recently. However, existing methods usually suffer from overfitting issues and entangle the subject-unrelated information (e.g., background and pose) with the learned concept, limiting the potential to compose concept into new scenes. To address these issues, we propose the DETEX, a novel approach that learns the disentangled concept embedding for flexible customized text-to-image generation. Unlike conventional methods that learn a single concept embedding from the given images, our DETEX represents each image using multiple word embeddings during training, i.e., a learnable image-shared subject embedding and several image-specific subject-unrelated embeddings. To decouple irrelevant attributes (i.e., background and pose) from the subject embedding, we further present several attribute mappers that encode each image as several image-specific subject-unrelated embeddings. To encourage these unrelated embeddings to capture the irrelevant information, we incorporate them with corresponding attribute words and propose a joint training strategy to facilitate the disentanglement. During inference, we only use the subject embedding for image generation, while selectively using image-specific embeddings to retain image-specified attributes. Extensive experiments demonstrate that the subject embedding obtained by our method can faithfully represent the target concept, while showing superior editability compared to the state-of-the-art methods. Our code will be available at https://github.com/PrototypeNx/DETEX",
    "checked": true,
    "id": "f2832c8404f9dd823667e2cc6ffd39076c473369",
    "semantic_title": "decoupled textual embeddings for customized image generation",
    "citation_count": 7,
    "authors": [
      "Yufei Cai",
      "Yuxiang Wei",
      "Zhilong Ji",
      "Jinfeng Bai",
      "Hu Han",
      "Wangmeng Zuo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27851": {
    "title": "Disguise without Disruption: Utility-Preserving Face De-identification",
    "volume": "main",
    "abstract": "With the rise of cameras and smart sensors, humanity generates an exponential amount of data. This valuable information, including underrepresented cases like AI in medical settings, can fuel new deep-learning tools. However, data scientists must prioritize ensuring privacy for individuals in these untapped datasets, especially for images or videos with faces, which are prime targets for identification methods. Proposed solutions to de-identify such images often compromise non-identifying facial attributes relevant to downstream tasks. In this paper, we introduce Disguise, a novel algorithm that seamlessly de-identifies facial images while ensuring the usability of the modified data. Unlike previous approaches, our solution is firmly grounded in the domains of differential privacy and ensemble-learning research. Our method involves extracting and substituting depicted identities with synthetic ones, generated using variational mechanisms to maximize obfuscation and non-invertibility. Additionally, we leverage supervision from a mixture-of-experts to disentangle and preserve other utility attributes. We extensively evaluate our method using multiple datasets, demonstrating a higher de-identification rate and superior consistency compared to prior approaches in various downstream tasks",
    "checked": true,
    "id": "f866c0e457496fe5855b229ff9ba96972a5efa0c",
    "semantic_title": "disguise without disruption: utility-preserving face de-identification",
    "citation_count": 2,
    "authors": [
      "Zikui Cai",
      "Zhongpai Gao",
      "Benjamin Planche",
      "Meng Zheng",
      "Terrence Chen",
      "M. Salman Asif",
      "Ziyan Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27852": {
    "title": "Bi-directional Adapter for Multimodal Tracking",
    "volume": "main",
    "abstract": "Due to the rapid development of computer vision, single-modal (RGB) object tracking has made significant progress in recent years. Considering the limitation of single imaging sensor, multi-modal images (RGB, infrared, etc.) are introduced to compensate for this deficiency for all-weather object tracking in complex environments. However, as acquiring sufficient multi-modal tracking data is hard while the dominant modality changes with the open environment, most existing techniques fail to extract multi-modal complementary information dynamically, yielding unsatisfactory tracking performance. To handle this problem, we propose a novel multi-modal visual prompt tracking model based on a universal bi-directional adapter, cross-prompting multiple modalities mutually. Our model consists of a universal bi-directional adapter and multiple modality-specific transformer encoder branches with sharing parameters. The encoders extract features of each modality separately by using a frozen, pre-trained foundation model. We develop a simple but effective light feature adapter to transfer modality-specific information from one modality to another, performing visual feature prompt fusion in an adaptive manner. With adding fewer (0.32M) trainable parameters, our model achieves superior tracking performance in comparison with both the full fine-tuning methods and the prompt learning-based methods. Our code is available: https://github.com/SparkTempest/BAT",
    "checked": true,
    "id": "2e80336f5a72a47ca2c3c8fdd7a9dc3ab5253140",
    "semantic_title": "bi-directional adapter for multimodal tracking",
    "citation_count": 3,
    "authors": [
      "Bing Cao",
      "Junliang Guo",
      "Pengfei Zhu",
      "Qinghua Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27853": {
    "title": "Domain-Controlled Prompt Learning",
    "volume": "main",
    "abstract": "Large pre-trained vision-language models, such as CLIP, have shown remarkable generalization capabilities across various tasks when appropriate text prompts are provided. However, adapting these models to specific domains, like remote sensing images (RSIs), medical images, etc, remains unexplored and challenging. Existing prompt learning methods often lack domain-awareness or domain-transfer mechanisms, leading to suboptimal performance due to the misinterpretation of specific images in natural image patterns. To tackle this dilemma, we proposed a Domain-Controlled Prompt Learning for the specific domains. Specifically, the large-scale specific domain foundation model (LSDM) is first introduced to provide essential specific domain knowledge. Using lightweight neural networks, we transfer this knowledge into domain biases, which control both the visual and language branches to obtain domain-adaptive prompts in a directly incorporating manner. Simultaneously, to overcome the existing overfitting challenge, we propose a novel noisy-adding strategy, without extra trainable parameters, to help the model escape the suboptimal solution in a global domain oscillation manner. Experimental results show our method achieves state-of-the-art performance in specific domain image recognition datasets. Our code is available at https://github.com/caoql98/DCPL",
    "checked": true,
    "id": "b8874ac74a5de32522e7e93c7541ca229ad89f0d",
    "semantic_title": "domain-controlled prompt learning",
    "citation_count": 3,
    "authors": [
      "Qinglong Cao",
      "Zhengqin Xu",
      "Yuntian Chen",
      "Chao Ma",
      "Xiaokang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27854": {
    "title": "LogoStyleFool: Vitiating Video Recognition Systems via Logo Style Transfer",
    "volume": "main",
    "abstract": "Video recognition systems are vulnerable to adversarial examples. Recent studies show that style transfer-based and patch-based unrestricted perturbations can effectively improve attack efficiency. These attacks, however, face two main challenges: 1) Adding large stylized perturbations to all pixels reduces the naturalness of the video and such perturbations can be easily detected. 2) Patch-based video attacks are not extensible to targeted attacks due to the limited search space of reinforcement learning that has been widely used in video attacks recently. In this paper, we focus on the video black-box setting and propose a novel attack framework named LogoStyleFool by adding a stylized logo to the clean video. We separate the attack into three stages: style reference selection, reinforcement-learning-based logo style transfer, and perturbation optimization. We solve the first challenge by scaling down the perturbation range to a regional logo, while the second challenge is addressed by complementing an optimization stage after reinforcement learning. Experimental results substantiate the overall superiority of LogoStyleFool over three state-of-the-art patch-based attacks in terms of attack performance and semantic preservation. Meanwhile, LogoStyleFool still maintains its performance against two existing patch-based defense methods. We believe that our research is beneficial in increasing the attention of the security community to such subregional style transfer attacks",
    "checked": true,
    "id": "217c6a8d5e872964b19f25a4247fe936103c027a",
    "semantic_title": "logostylefool: vitiating video recognition systems via logo style transfer",
    "citation_count": 2,
    "authors": [
      "Yuxin Cao",
      "Ziyu Zhao",
      "Xi Xiao",
      "Derui Wang",
      "Minhui Xue",
      "Jin Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27855": {
    "title": "Descanning: From Scanned to the Original Images with a Color Correction Diffusion Model",
    "volume": "main",
    "abstract": "A significant volume of analog information, i.e., documents and images, have been digitized in the form of scanned copies for storing, sharing, and/or analyzing in the digital world. However, the quality of such contents is severely degraded by various distortions caused by printing, storing, and scanning processes in the physical world. Although restoring high-quality content from scanned copies has become an indispensable task for many products, it has not been systematically explored, and to the best of our knowledge, no public datasets are available. In this paper, we define this problem as Descanning and introduce a new high-quality and large-scale dataset named DESCAN-18K. It contains 18K pairs of original and scanned images collected in the wild containing multiple complex degradations. In order to eliminate such complex degradations, we propose a new image restoration model called DescanDiffusion consisting of a color encoder that corrects the global color degradation and a conditional denoising diffusion probabilistic model (DDPM) that removes local degradations. To further improve the generalization ability of DescanDiffusion, we also design a synthetic data generation scheme by reproducing prominent degradations in scanned images. We demonstrate that our DescanDiffusion outperforms other baselines including commercial restoration products, objectively and subjectively, via comprehensive experiments and analyses",
    "checked": true,
    "id": "e2e493678e6bda55c1c44114bbd58c3b863a8dc7",
    "semantic_title": "descanning: from scanned to the original images with a color correction diffusion model",
    "citation_count": 0,
    "authors": [
      "Junghun Cha",
      "Ali Haider",
      "Seoyun Yang",
      "Hoeyeong Jin",
      "Subin Yang",
      "A. F. M. Shahab Uddin",
      "Jaehyoung Kim",
      "Soo Ye Kim",
      "Sung-Ho Bae"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27856": {
    "title": "Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction",
    "volume": "main",
    "abstract": "Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for single-view clothed human reconstruction. These models need to be trained using a sampling training scheme. Existing sampling training schemes either fail to capture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in reconstructed meshes. To address these problems, we introduce Fine Structured-Aware Sampling (FSS), a new sampling training scheme to train pixel-aligned implicit models for single-view human reconstruction. FSS resolves the aforementioned problems by proactively adapting to the thickness and complexity of surfaces. In addition, unlike existing sampling training schemes, FSS shows how normals of sample points can be capitalized in the training process to improve results. Lastly, to further improve the training process, FSS proposes a mesh thickness loss signal for pixel-aligned implicit models. It becomes computationally feasible to introduce this loss once a slight reworking of the pixel-aligned implicit function framework is carried out. Our results show that our methods significantly outperform SOTA methods qualitatively and quantitatively. Our code is publicly available at https://github.com/kcyt/FSS",
    "checked": true,
    "id": "f75695db8893b38d9bd61f6901f8524ee9ec9645",
    "semantic_title": "fine structure-aware sampling: a new sampling training scheme for pixel-aligned implicit models in single-view human reconstruction",
    "citation_count": 1,
    "authors": [
      "Kennard Yanting Chan",
      "Fayao Liu",
      "Guosheng Lin",
      "Chuan Sheng Foo",
      "Weisi Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27857": {
    "title": "CMDA: Cross-Modal and Domain Adversarial Adaptation for LiDAR-Based 3D Object Detection",
    "volume": "main",
    "abstract": "Recent LiDAR-based 3D Object Detection (3DOD) methods show promising results, but they often do not generalize well to target domains outside the source (or training) data distribution. To reduce such domain gaps and thus to make 3DOD models more generalizable, we introduce a novel unsupervised domain adaptation (UDA) method, called CMDA, which (i) leverages visual semantic cues from an image modality (i.e., camera images) as an effective semantic bridge to close the domain gap in the cross-modal Bird's Eye View (BEV) representations. Further, (ii) we also introduce a self-training-based learning strategy, wherein a model is adversarially trained to generate domain-invariant features, which disrupt the discrimination of whether a feature instance comes from a source or an unseen target domain. Overall, our CMDA framework guides the 3DOD model to generate highly informative and domain-adaptive features for novel data distributions. In our extensive experiments with large-scale benchmarks, such as nuScenes, Waymo, and KITTI, those mentioned above provide significant performance gains for UDA tasks, achieving state-of-the-art performance",
    "checked": true,
    "id": "6fb888c542dd50d28b78c71df0d13dcb2148d8e6",
    "semantic_title": "cmda: cross-modal and domain adversarial adaptation for lidar-based 3d object detection",
    "citation_count": 0,
    "authors": [
      "Gyusam Chang",
      "Wonseok Roh",
      "Sujin Jang",
      "Dongwook Lee",
      "Daehyun Ji",
      "Gyeongrok Oh",
      "Jinsun Park",
      "Jinkyu Kim",
      "Sangpil Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27858": {
    "title": "A Hybrid Global-Local Perception Network for Lane Detection",
    "volume": "main",
    "abstract": "Lane detection is a critical task in autonomous driving, which requires accurately predicting the complex topology of lanes in various scenarios. While previous methods of lane detection have shown success, challenges still exist, especially in scenarios where lane markings are absent. In this paper, we analyze the role of global and local features in accurately detecting lanes and propose a Hybrid Global-Local Perception Network (HGLNet) to leverage them. Global and local features play distinct roles in lane detection by respectively aiding in the detection of lane instances and the localization of corresponding lanes. HGLNet extracts global semantic context by utilizing a global extraction head that aggregates information about adaptive sampling points around lanes, achieving an optimal trade-off between performance and efficiency. Moreover, we introduce a Multi-hierarchy feature aggregator (MFA) to capture feature hierarchies in both regional and local ranges, elevating the representation of local features. The proposed Hybrid architecture can simultaneously focus on global and local features at different depth levels and efficiently integrate them to sense the global presence of lanes and accurately regress their locations. Experimental results demonstrate that our proposed method improves detection accuracy in various challenging scenarios, outperforming the state-of-the-art lane detection methods",
    "checked": true,
    "id": "248aec86f74aac91cb056fd803ede9f6e0beb3e8",
    "semantic_title": "a hybrid global-local perception network for lane detection",
    "citation_count": 0,
    "authors": [
      "Qing Chang",
      "Yifei Tong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27859": {
    "title": "Improving Robustness for Joint Optimization of Camera Pose and Decomposed Low-Rank Tensorial Radiance Fields",
    "volume": "main",
    "abstract": "In this paper, we propose an algorithm that allows joint refinement of camera pose and scene geometry represented by decomposed low-rank tensor, using only 2D images as supervision. First, we conduct a pilot study based on a 1D signal and relate our findings to 3D scenarios, where the naive joint pose optimization on voxel-based NeRFs can easily lead to sub-optimal solutions. Moreover, based on the analysis of the frequency spectrum, we propose to apply convolutional Gaussian filters on 2D and 3D radiance fields for a coarse-to-fine training schedule that enables joint camera pose optimization. Leveraging the decomposition property in decomposed low-rank tensor, our method achieves an equivalent effect to brute-force 3D convolution with only incurring little computational overhead. To further improve the robustness and stability of joint optimization, we also propose techniques of smoothed 2D supervision, randomly scaled kernel parameters, and edge-guided loss mask. Extensive quantitative and qualitative evaluations demonstrate that our proposed framework achieves superior performance in novel view synthesis as well as rapid convergence for optimization. The source code is available at https://github.com/Nemo1999/Joint-TensoRF",
    "checked": false,
    "id": "874841f6f3f52c04c11ae27181b9b4e05273d8a5",
    "semantic_title": "improving robustness for joint optimization of camera poses and decomposed low-rank tensorial radiance fields",
    "citation_count": 1,
    "authors": [
      "Bo-Yu Chen",
      "Wei-Chen Chiu",
      "Yu-Lun Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27860": {
    "title": "Sketch and Refine: Towards Fast and Accurate Lane Detection",
    "volume": "main",
    "abstract": "Lane detection is to determine the precise location and shape of lanes on the road. Despite efforts made by current methods, it remains a challenging task due to the complexity of real-world scenarios. Existing approaches, whether proposal-based or keypoint-based, suffer from depicting lanes effectively and efficiently. Proposal-based methods detect lanes by distinguishing and regressing a collection of proposals in a streamlined top-down way, yet lack sufficient flexibility in lane representation. Keypoint-based methods, on the other hand, construct lanes flexibly from local descriptors, which typically entail complicated post-processing. In this paper, we present a \"Sketch-and-Refine\" paradigm that utilizes the merits of both keypoint-based and proposal-based methods. The motivation is that local directions of lanes are semantically simple and clear. At the \"Sketch\" stage, local directions of keypoints can be easily estimated by fast convolutional layers. Then we can build a set of lane proposals accordingly with moderate accuracy. At the \"Refine\" stage, we further optimize these proposals via a novel Lane Segment Association Module (LSAM), which allows adaptive lane segment adjustment. Last but not least, we propose multi-level feature integration to enrich lane feature representations more efficiently. Based on the proposed \"Sketch-and-Refine\" paradigm, we propose a fast yet effective lane detector dubbed \"SRLane\". Experiments show that our SRLane can run at a fast speed (i.e., 278 FPS) while yielding an F1 score of 78.9%. The source code is available at: https://github.com/passerer/SRLane",
    "checked": true,
    "id": "e5c54730fb852352565590b8ac1a27b37402d2d7",
    "semantic_title": "sketch and refine: towards fast and accurate lane detection",
    "citation_count": 0,
    "authors": [
      "Chao Chen",
      "Jie Liu",
      "Chang Zhou",
      "Jie Tang",
      "Gangshan Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27861": {
    "title": "Iterative Token Evaluation and Refinement for Real-World Super-resolution",
    "volume": "main",
    "abstract": "Real-world image super-resolution (RWSR) is a long-standing problem as low-quality (LQ) images often have complex and unidentified degradations. Existing methods such as Generative Adversarial Networks (GANs) or continuous diffusion models present their own issues including GANs being difficult to train while continuous diffusion models requiring numerous inference steps. In this paper, we propose an Iterative Token Evaluation and Refinement (ITER) framework for RWSR, which utilizes a discrete diffusion model operating in the discrete token representation space, i.e., indexes of features extracted from a VQGAN codebook pre-trained with high-quality (HQ) images. We show that ITER is easier to train than GANs and more efficient than continuous diffusion models. Specifically, we divide RWSR into two sub-tasks, i.e., distortion removal and texture generation. Distortion removal involves simple HQ token prediction with LQ images, while texture generation uses a discrete diffusion model to iteratively refine the distortion removal output with a token refinement network. In particular, we propose to include a token evaluation network in the discrete diffusion process. It learns to evaluate which tokens are good restorations and helps to improve the iterative refinement results. Moreover, the evaluation network can first check status of the distortion removal output and then adaptively select total refinement steps needed, thereby maintaining a good balance between distortion removal and texture generation. Extensive experimental results show that ITER is easy to train and performs well within just 8 iterative steps",
    "checked": true,
    "id": "1282229a4dcbced5b14376e141d1895168b2534d",
    "semantic_title": "iterative token evaluation and refinement for real-world super-resolution",
    "citation_count": 2,
    "authors": [
      "Chaofeng Chen",
      "Shangchen Zhou",
      "Liang Liao",
      "Haoning Wu",
      "Wenxiu Sun",
      "Qiong Yan",
      "Weisi Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27862": {
    "title": "FeatWalk: Enhancing Few-Shot Classification through Local View Leveraging",
    "volume": "main",
    "abstract": "Few-shot learning is a challenging task due to the limited availability of training samples. Recent few-shot learning studies with meta-learning and simple transfer learning methods have achieved promising performance. However, the feature extractor pre-trained with the upstream dataset may neglect the extraction of certain features which could be crucial for downstream tasks. In this study, inspired by the process of human learning in few-shot tasks, where humans not only observe the whole image (`global view') but also attend to various local image regions (`local view') for comprehensive understanding of detailed features, we propose a simple yet effective few-shot learning method called FeatWalk which can utilize the complementary nature of global and local views, therefore providing an intuitive and effective solution to the problem of insufficient local information extraction from the pre-trained feature extractor. Our method can be easily and flexibly combined with various existing methods, further enhancing few-shot learning performance. Extensive experiments on multiple benchmark datasets consistently demonstrate the effectiveness and versatility of our method.The source code is available at https://github.com/exceefind/FeatWalk",
    "checked": true,
    "id": "f229b04d7583421ce58cf6f232c370cb203f8bcc",
    "semantic_title": "featwalk: enhancing few-shot classification through local view leveraging",
    "citation_count": 0,
    "authors": [
      "Dalong Chen",
      "Jianjia Zhang",
      "Wei-Shi Zheng",
      "Ruixuan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27863": {
    "title": "Real3D: The Curious Case of Neural Scene Degeneration",
    "volume": "main",
    "abstract": "Despite significant progress in utilizing pre-trained text-to-image diffusion models to guide the creation of 3D scenes, these methods often struggle to generate scenes that are sufficiently realistic, leading to \"neural scene degeneration\". In this work, we propose a new 3D scene generation model called Real3D. Specifically, Real3D designs a pipeline from a NeRF-like implicit renderer to a tetrahedrons-based explicit renderer, greatly improving the neural network's ability to generate various neural scenes. Moreover, Real3D introduces an additional discriminator to prevent neural scenes from falling into undesirable local optima, thus avoiding the degeneration phenomenon. Our experimental results demonstrate that Real3D outperforms all existing state-of-the-art text-to-3D generation methods, providing valuable insights to facilitate the development of learning-based 3D scene generation approaches",
    "checked": true,
    "id": "c4d1c5f5374d2e4d3cc7f924de59a2688622b701",
    "semantic_title": "real3d: the curious case of neural scene degeneration",
    "citation_count": 0,
    "authors": [
      "Dengsheng Chen",
      "Jie Hu",
      "Xiaoming Wei",
      "Enhua Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27864": {
    "title": "DDAE: Towards Deep Dynamic Vision BERT Pretraining",
    "volume": "main",
    "abstract": "Recently, masked image modeling (MIM) has demonstrated promising prospects in self-supervised representation learning. However, existing MIM frameworks recover all masked patches equivalently, ignoring that the reconstruction difficulty of different patches can vary sharply due to their diverse distance from visible patches. In this paper, we propose a novel deep dynamic supervision to enable MIM methods to dynamically reconstruct patches with different degrees of difficulty at different pretraining phases and depths of the model. Our deep dynamic supervision helps to provide more locality inductive bias for ViTs especially in deep layers, which inherently makes up for the absence of local prior for self-attention mechanism. Built upon the deep dynamic supervision, we propose Deep Dynamic AutoEncoder (DDAE), a simple yet effective MIM framework that utilizes dynamic mechanisms for pixel regression and feature self-distillation simultaneously. Extensive experiments across a variety of vision tasks including ImageNet classification, semantic segmentation on ADE20K and object detection on COCO demonstrate the effectiveness of our approach",
    "checked": true,
    "id": "74a3874254997657e0697f4abee0d69ece688e42",
    "semantic_title": "ddae: towards deep dynamic vision bert pretraining",
    "citation_count": 1,
    "authors": [
      "Honghao Chen",
      "Xiangwen Kong",
      "Xiangyu Zhang",
      "Xin Zhao",
      "Kaiqi Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27865": {
    "title": "Rethinking Multi-Scale Representations in Deep Deraining Transformer",
    "volume": "main",
    "abstract": "Existing Transformer-based image deraining methods depend mostly on fixed single-input single-output U-Net architecture. In fact, this not only neglects the potentially explicit information from multiple image scales, but also lacks the capability of exploring the complementary implicit information across different scales. In this work, we rethink the multi-scale representations and design an effective multi-input multi-output framework that constructs intra- and inter-scale hierarchical modulation to better facilitate rain removal and help image restoration. We observe that rain levels reduce dramatically in coarser image scales, thus proposing to restore rain-free results from the coarsest scale to the finest scale in image pyramid inputs, which also alleviates the difficulty of model learning. Specifically, we integrate a sparsity-compensated Transformer block and a frequency-enhanced convolutional block into a coupled representation module, in order to jointly learn the intra-scale content-aware features. To facilitate representations learned at different scales to communicate with each other, we leverage a gated fusion module to adaptively aggregate the inter-scale spatial-aware features, which are rich in correlated information of rain appearances, leading to high-quality results. Extensive experiments demonstrate that our model achieves consistent gains on five benchmarks",
    "checked": true,
    "id": "1bc2390c2e32c434043936734c2fb4af5ad800c0",
    "semantic_title": "rethinking multi-scale representations in deep deraining transformer",
    "citation_count": 1,
    "authors": [
      "Hongming Chen",
      "Xiang Chen",
      "Jiyang Lu",
      "Yufeng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27866": {
    "title": "Unsupervised Group Re-identification via Adaptive Clustering-Driven Progressive Learning",
    "volume": "main",
    "abstract": "Group re-identification (G-ReID) aims to correctly associate groups with the same members captured by different cameras. However, supervised approaches for this task often suffer from the high cost of cross-camera sample labeling. Unsupervised methods based on clustering can avoid sample labeling, but the problem of member variations often makes clustering unstable, leading to incorrect pseudo-labels. To address these challenges, we propose an adaptive clustering-driven progressive learning approach (ACPL), which consists of a group adaptive clustering (GAC) module and a global dynamic prototype update (GDPU) module. Specifically, GAC designs the quasi-distance between groups, thus fully capitalizing on both individual-level and holistic information within groups. In the case of great uncertainty in intra-group members, GAC effectively minimizes the impact of non-discriminative features and reduces the noise in the model's pseudo-labels. Additionally, our GDPU devises a dynamic weight to update the prototypes and effectively mine the hard samples with complex member variations, which improves the model's robustness. Extensive experiments conducted on four popular G-ReID datasets demonstrate that our method not only achieves state-of-the-art performance on unsupervised G-ReID but also performs comparably to several fully supervised approaches",
    "checked": true,
    "id": "168bd2caa336413680abf84864a6390fabc32208",
    "semantic_title": "unsupervised group re-identification via adaptive clustering-driven progressive learning",
    "citation_count": 0,
    "authors": [
      "Hongxu Chen",
      "Quan Zhang",
      "Jian-Huang Lai",
      "Xiaohua Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27867": {
    "title": "Guiding a Harsh-Environments Robust Detector via RAW Data Characteristic Mining",
    "volume": "main",
    "abstract": "Consumer-grade cameras capture the RAW physical description of a scene and then process the image signals to obtain high-quality RGB images that are faithful to human visual perception. Conventionally, dense prediction scenes require high-precision recognition of objects in RGB images. However, predicting RGB data to exhibit the expected adaptability and robustness in harsh environments can be challenging. By capitalizing on the broader color gamut and higher bit depth offered by RAW data, in this paper, we demonstrate that RAW data can significantly improve the accuracy and robustness of object detectors in harsh environments. Firstly, we propose a general Pipeline for RAW Detection (PRD), along with a preprocessing strategy tailored to RAW data. Secondly, we design the RAW Corruption Benchmark (RCB) to address the dearth of benchmarks that reflect realistic scenarios in harsh environments. Thirdly, we demonstrate the significant improvement of RAW images in object detection for low-light and corrupt scenes. Specifically, our experiments indicate that PRD (using FCOS) outperforms RGB detection by 13.9mAP on LOD-Snow without generating restored images. Finally, we introduce a new nonlinear method called Functional Regularization (FR), which can effectively mine the unique characteristics of RAW data. The code is available at https://github.com/DreamerCCC/RawMining",
    "checked": true,
    "id": "316f9c8df62d228117e6067b3a3fee391631004a",
    "semantic_title": "guiding a harsh-environments robust detector via raw data characteristic mining",
    "citation_count": 0,
    "authors": [
      "Hongyang Chen",
      "Hung-Shuo Tai",
      "Kaisheng Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27868": {
    "title": "CutFreq: Cut-and-Swap Frequency Components for Low-Level Vision Augmentation",
    "volume": "main",
    "abstract": "Low-level vision plays a crucial role in a wide range of imaging quality and image recognition applications. However, the limited size, quality, and diversity of datasets often pose significant challenges for low-level tasks. Data augmentation is the most effective and practical way of sample expansion, but the commonly used augmentation methods in high-level tasks have limited improvement in the low-level due to the boundary effects or the non-realistic context information. In this paper, we propose the Cut-and-Swap Frequency Components (CutFreq) method for low-level vision, which aims to preserve high-level representations with directionality and improve image synthesis quality. Observing the significant frequency domain differences between reconstructed images and real ones, in CutFreq, we propose to transform the input and real images separately in the frequency domain, then define two stages for the model training process, and finally swap the specified frequency bands respectively and inversely transform to generate augmented samples. The experimental results show the superior performance of CutFreq on five low-level vision tasks. Moreover, we demonstrate the effectiveness of CutFreq in the low-data regime. Code is available at https://github.com/DreamerCCC/CutFreq",
    "checked": true,
    "id": "b80eeb2ed8c107490bb3a2bbf13a1fc717423f7d",
    "semantic_title": "cutfreq: cut-and-swap frequency components for low-level vision augmentation",
    "citation_count": 0,
    "authors": [
      "Hongyang Chen",
      "Kaisheng Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27869": {
    "title": "Null Space Matters: Range-Null Decomposition for Consistent Multi-Contrast MRI Reconstruction",
    "volume": "main",
    "abstract": "Consistency and interpretability have long been the critical issues in MRI reconstruction. While interpretability has been dramatically improved with the employment of deep unfolding networks (DUNs), current methods still suffer from inconsistencies and generate inferior anatomical structure. Especially in multi-contrast scenes, different imaging protocols often exacerbate the concerned issue. In this paper, we propose a range-null decomposition-assisted DUN architecture to ensure consistency while still providing desirable interpretability. Given the input decomposed, we argue that the inconsistency could be analytically relieved by feeding solely the null-space component into proximal mapping, while leaving the range-space counterpart fixed. More importantly, a correlation decoupling scheme is further proposed to narrow the information gap for multi-contrast fusion, which dynamically borrows isotropic features from the opponent while maintaining the modality-specific ones. Specifically, the two features are attached to different frequencies and learned individually by the newly designed isotropy encoder and anisotropy encoder. The former strives for the contrast-shared information, while the latter serves to capture the contrast-specific features. The quantitative and qualitative results show that our proposal outperforms most cutting-edge methods by a large margin. Codes will be released on https://github.com/chenjiachengzzz/RNU",
    "checked": true,
    "id": "14f7cbde73144336bbeb8b0b04247d30d66f1454",
    "semantic_title": "null space matters: range-null decomposition for consistent multi-contrast mri reconstruction",
    "citation_count": 0,
    "authors": [
      "Jiacheng Chen",
      "Jiawei Jiang",
      "Fei Wu",
      "Jianwei Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27870": {
    "title": "PNeSM: Arbitrary 3D Scene Stylization via Prompt-Based Neural Style Mapping",
    "volume": "main",
    "abstract": "3D scene stylization refers to transform the appearance of a 3D scene to match a given style image, ensuring that images rendered from different viewpoints exhibit the same style as the given style image, while maintaining the 3D consistency of the stylized scene. Several existing methods have obtained impressive results in stylizing 3D scenes. However, the mod- els proposed by these methods need to be re-trained when applied to a new scene. In other words, their models are cou- pled with a specific scene and cannot adapt to arbitrary other scenes. To address this issue, we propose a novel 3D scene stylization framework to transfer an arbitrary style to an ar- bitrary scene, without any style-related or scene-related re- training. Concretely, we first map the appearance of the 3D scene into a 2D style pattern space, which realizes complete disentanglement of the geometry and appearance of the 3D scene and makes our model be generalized to arbitrary 3D scenes. Then we stylize the appearance of the 3D scene in the 2D style pattern space via a prompt-based 2D stylization al- gorithm. Experimental results demonstrate that our proposed framework is superior to SOTA methods in both visual qual- ity and generalization",
    "checked": true,
    "id": "6ce6cf6ad2f1d09652b4b5829436199a4c06cc1b",
    "semantic_title": "pnesm: arbitrary 3d scene stylization via prompt-based neural style mapping",
    "citation_count": 0,
    "authors": [
      "Jiafu Chen",
      "Wei Xing",
      "Jiakai Sun",
      "Tianyi Chu",
      "Yiling Huang",
      "Boyan Ji",
      "Lei Zhao",
      "Huaizhong Lin",
      "Haibo Chen",
      "Zhizhong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27871": {
    "title": "TagFog: Textual Anchor Guidance and Fake Outlier Generation for Visual Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "Out-of-distribution (OOD) detection is crucial in many real-world applications. However, intelligent models are often trained solely on in-distribution (ID) data, leading to overconfidence when misclassifying OOD data as ID classes. In this study, we propose a new learning framework which leverage simple Jigsaw-based fake OOD data and rich semantic embeddings (`anchors') from the ChatGPT description of ID knowledge to help guide the training of the image encoder. The learning framework can be flexibly combined with existing post-hoc approaches to OOD detection, and extensive empirical evaluations on multiple OOD detection benchmarks demonstrate that rich textual representation of ID knowledge and fake OOD knowledge can well help train a visual encoder for OOD detection. With the learning framework, new state-of-the-art performance was achieved on all the benchmarks. The code is available at https://github.com/Cverchen/TagFog",
    "checked": true,
    "id": "835d157e2c23d3577f23778ce051ab8d706babf6",
    "semantic_title": "tagfog: textual anchor guidance and fake outlier generation for visual out-of-distribution detection",
    "citation_count": 0,
    "authors": [
      "Jiankang Chen",
      "Tong Zhang",
      "Wei-Shi Zheng",
      "Ruixuan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27872": {
    "title": "EVE: Efficient Vision-Language Pre-training with Masked Prediction and Modality-Aware MoE",
    "volume": "main",
    "abstract": "Building scalable vision-language models to learn from diverse, multimodal data remains an open challenge. In this paper, we introduce an Efficient Vision-languagE foundation model, namely EVE, which is one unified multimodal Transformer pre-trained solely by one unified pre-training task. Specifically, EVE encodes both vision and language within a shared Transformer network integrated with modality-aware sparse Mixture-of-Experts (MoE) modules, which capture modality-specific information by selectively switching to different experts. To unify pre-training tasks of vision and language, EVE performs masked signal modeling on image-text pairs to reconstruct masked signals, i.e., image pixels and text tokens, given visible signals. This simple yet effective pre-training objective accelerates training by 4x compared to the model pre-trained with Image-Text Contrastive and Image-Text Matching losses. Owing to the combination of the unified architecture and pre-training task, EVE is easy to scale up, enabling better downstream performance with fewer resources and faster training speed. Despite its simplicity, EVE achieves state-of-the-art performance on various vision-language downstream tasks, including visual question answering, visual reasoning, and image-text retrieval",
    "checked": true,
    "id": "0ff86630bf775f0510ef20b76352a0757a4ed70b",
    "semantic_title": "eve: efficient vision-language pre-training with masked prediction and modality-aware moe",
    "citation_count": 1,
    "authors": [
      "Junyi Chen",
      "Longteng Guo",
      "Jia Sun",
      "Shuai Shao",
      "Zehuan Yuan",
      "Liang Lin",
      "Dongyu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27873": {
    "title": "CaMIL: Causal Multiple Instance Learning for Whole Slide Image Classification",
    "volume": "main",
    "abstract": "Whole slide image (WSI) classification is a crucial component in automated pathology analysis. Due to the inherent challenges of high-resolution WSIs and the absence of patch-level labels, most of the proposed methods follow the multiple instance learning (MIL) formulation. While MIL has been equipped with excellent instance feature extractors and aggregators, it is prone to learn spurious associations that undermine the performance of the model. For example, relying solely on color features may lead to erroneous diagnoses due to spurious associations between the disease and the color of patches. To address this issue, we develop a causal MIL framework for WSI classification, effectively distinguishing between causal and spurious associations. Specifically, we use the expectation of the intervention P(Y | do(X)) for bag prediction rather than the traditional likelihood P(Y | X). By applying the front-door adjustment, the spurious association is effectively blocked, where the intervened mediator is aggregated from patch-level features. We evaluate our proposed method on two publicly available WSI datasets, Camelyon16 and TCGA-NSCLC. Our causal MIL framework shows outstanding performance and is plug-and-play, seamlessly integrating with various feature extractors and aggregators",
    "checked": true,
    "id": "bd185f06cc119ed7b1d2dc8e9cc16f2cba067901",
    "semantic_title": "camil: causal multiple instance learning for whole slide image classification",
    "citation_count": 2,
    "authors": [
      "Kaitao Chen",
      "Shiliang Sun",
      "Jing Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27874": {
    "title": "Multi-Prototype Space Learning for Commonsense-Based Scene Graph Generation",
    "volume": "main",
    "abstract": "In the domain of scene graph generation, modeling commonsense as a single-prototype representation has been typically employed to facilitate the recognition of infrequent predicates. However, a fundamental challenge lies in the large intra-class variations of the visual appearance of predicates, resulting in subclasses within a predicate class. Such a challenge typically leads to the problem of misclassifying diverse predicates due to the rough predicate space clustering. In this paper, inspired by cognitive science, we maintain multi-prototype representations for each predicate class, which can accurately find the multiple class centers of the predicate space. Technically, we propose a novel multi-prototype learning framework consisting of three main steps: prototype-predicate matching, prototype updating, and prototype space optimization. We first design a triple-level optimal transport to match each predicate feature within the same class to a specific prototype. In addition, the prototypes are updated using momentum updating to find the class centers according to the matching results. Finally, we enhance the inter-class separability of the prototype space through iterations of the inter-class separability loss and intra-class compactness loss. Extensive evaluations demonstrate that our approach significantly outperforms state-of-the-art methods on the Visual Genome dataset",
    "checked": true,
    "id": "b2cfd63fc1a6a4992a81840208e6d1d462b36045",
    "semantic_title": "multi-prototype space learning for commonsense-based scene graph generation",
    "citation_count": 1,
    "authors": [
      "Lianggangxu Chen",
      "Youqi Song",
      "Yiqing  Cai",
      "Jiale Lu",
      "Yang Li",
      "Yuan Xie",
      "Changbo Wang",
      "Gaoqi He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27875": {
    "title": "Kumaraswamy Wavelet for Heterophilic Scene Graph Generation",
    "volume": "main",
    "abstract": "Graph neural networks (GNNs) has demonstrated its capabilities in the field of scene graph generation (SGG) by updating node representations from neighboring nodes. Actually it can be viewed as a form of low-pass filter in the spatial domain, which smooths node feature representation and retains commonalities among nodes. However, spatial GNNs does not work well in the case of heterophilic SGG in which fine-grained predicates are always connected to a large number of coarse-grained predicates. Blind smoothing undermines the discriminative information of the fine-grained predicates, resulting in failure to predict them accurately. To address the heterophily, our key idea is to design tailored filters by wavelet transform from the spectral domain. First, we prove rigorously that when the heterophily on the scene graph increases, the spectral energy gradually shifts towards the high-frequency part. Inspired by this observation, we subsequently propose the Kumaraswamy Wavelet Graph Neural Network (KWGNN). KWGNN leverages complementary multi-group Kumaraswamy wavelets to cover all frequency bands. Finally, KWGNN adaptively generates band-pass filters and then integrates the filtering results to better accommodate varying levels of smoothness on the graph. Comprehensive experiments on the Visual Genome and Open Images datasets show that our method achieves state-of-the-art performance",
    "checked": true,
    "id": "c34d39dce5b8611900f747cc27990ea8ac36ef4c",
    "semantic_title": "kumaraswamy wavelet for heterophilic scene graph generation",
    "citation_count": 0,
    "authors": [
      "Lianggangxu Chen",
      "Youqi Song",
      "Shaohui Lin",
      "Changbo Wang",
      "Gaoqi He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27876": {
    "title": "ViT-Calibrator: Decision Stream Calibration for Vision Transformer",
    "volume": "main",
    "abstract": "A surge of interest has emerged in utilizing Transformers in diverse vision tasks owing to its formidable performance. However, existing approaches primarily focus on optimizing internal model architecture designs that often entail significant trial and error with high burdens. In this work, we propose a new paradigm dubbed Decision Stream Calibration that boosts the performance of general Vision Transformers. To achieve this, we shed light on the information propagation mechanism in the learning procedure by exploring the correlation between different tokens and the relevance coefficient of multiple dimensions. Upon further analysis, it was discovered that 1) the final decision is associated with tokens of foreground targets, while token features of foreground target will be transmitted into the next layer as much as possible, and the useless token features of background area will be eliminated gradually in the forward propagation. 2) Each category is solely associated with specific sparse dimensions in the tokens. Based on the discoveries mentioned above, we designed a two-stage calibration scheme, namely ViT-Calibrator, including token propagation calibration stage and dimension propagation calibration stage. Extensive experiments on commonly used datasets show that the proposed approach can achieve promising results",
    "checked": true,
    "id": "2e46788980581212aba95915a287aa38acd635f3",
    "semantic_title": "vit-calibrator: decision stream calibration for vision transformer",
    "citation_count": 0,
    "authors": [
      "Lin Chen",
      "Zhijie Jia",
      "Lechao Cheng",
      "Yang Gao",
      "Jie Lei",
      "Yijun Bei",
      "Zunlei Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27877": {
    "title": "NeRF-VPT: Learning Novel View Representations with Neural Radiance Fields via View Prompt Tuning",
    "volume": "main",
    "abstract": "Neural Radiance Fields (NeRF) have garnered remarkable success in novel view synthesis. Nonetheless, the task of generating high-quality images for novel views persists as a critical challenge. While the existing efforts have exhibited commendable progress, capturing intricate details, enhancing textures, and achieving superior Peak Signal-to-Noise Ratio (PSNR) metrics warrant further focused attention and advancement. In this work, we propose NeRF-VPT, an innovative method for novel view synthesis to address these challenges. Our proposed NeRF-VPT employs a cascading view prompt tuning paradigm, wherein RGB information gained from preceding rendering outcomes serves as instructive visual prompts for subsequent rendering stages, with the aspiration that the prior knowledge embedded in the prompts can facilitate the gradual enhancement of rendered image quality. NeRF-VPT only requires sampling RGB data from previous stage renderings as priors at each training stage, without relying on extra guidance or complex techniques. Thus, our NeRF-VPT is plug-and-play and can be readily integrated into existing methods. By conducting comparative analyses of our NeRF-VPT against several NeRF-based approaches on demanding real-scene benchmarks, such as Realistic Synthetic 360, Real Forward-Facing, Replica dataset, and a user-captured dataset, we substantiate that our NeRF-VPT significantly elevates baseline performance and proficiently generates more high-quality novel view images than all the compared state-of-the-art methods. Furthermore, the cascading learning of NeRF-VPT introduces adaptability to scenarios with sparse inputs, resulting in a significant enhancement of accuracy for sparse-view novel view synthesis. The source code and dataset are available at https://github.com/Freedomcls/NeRF-VPT",
    "checked": true,
    "id": "9aa058392c30f58f06ad889335d341c0baa5b095",
    "semantic_title": "nerf-vpt: learning novel view representations with neural radiance fields via view prompt tuning",
    "citation_count": 0,
    "authors": [
      "Linsheng Chen",
      "Guangrun Wang",
      "Liuchun Yuan",
      "Keze Wang",
      "Ken Deng",
      "Philip H.S. Torr"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27878": {
    "title": "WebVLN: Vision-and-Language Navigation on Websites",
    "volume": "main",
    "abstract": "Vision-and-Language Navigation (VLN) task aims to enable AI agents to accurately understand and follow natural language instructions to navigate through real-world environments, ultimately reaching specific target locations. We recognise a promising opportunity to extend VLN to a comparable navigation task that holds substantial significance in our daily lives, albeit within the virtual realm: navigating websites on the Internet. This paper proposes a new task named Vision-and-Language Navigation on Websites (WebVLN), where we use question-based instructions to train an agent, emulating how users naturally browse websites. Unlike the existing VLN task that only pays attention to vision and instruction (language), the WebVLN agent further considers underlying web-specific content like HTML, which could not be seen on the rendered web pages yet contain rich visual and textual information. Toward this goal, we contribute a dataset, WebVLN-v1, and introduce a novel approach called Website-aware VLN Network (WebVLN-Net), which is built upon the foundation of state-of-the-art VLN techniques. Experimental results show that WebVLN-Net outperforms current VLN and web-related navigation methods. We believe that the introduction of the newWebVLN task and its dataset will establish a new dimension within the VLN domain and contribute to the broader vision-and-language research community. Code is available at: https://github.com/WebVLN/WebVLN",
    "checked": true,
    "id": "21d7ef3fd958a96efae2a086513e31e9e911853c",
    "semantic_title": "webvln: vision-and-language navigation on websites",
    "citation_count": 1,
    "authors": [
      "Qi Chen",
      "Dileepa Pitawela",
      "Chongyang Zhao",
      "Gengze Zhou",
      "Hsiang-Ting Chen",
      "Qi Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27879": {
    "title": "Learning Multimodal Volumetric Features for Large-Scale Neuron Tracing",
    "volume": "main",
    "abstract": "The current neuron reconstruction pipeline for electron microscopy (EM) data usually includes automatic image segmentation followed by extensive human expert proofreading. In this work, we aim to reduce human workload by predicting connectivity between over-segmented neuron pieces, taking both microscopy image and 3D morphology features into account, similar to human proofreading workflow. To this end, we first construct a dataset, named FlyTracing, that contains millions of pairwise connections of segments expanding the whole fly brain, which is three orders of magnitude larger than existing datasets for neuron segment connection. To learn sophisticated biological imaging features from the connectivity annotations, we propose a novel connectivity-aware contrastive learning method to generate dense volumetric EM image embedding. The learned embeddings can be easily incorporated with any point or voxel-based morphological representations for automatic neuron tracing. Extensive comparisons of different combination schemes of image and morphological representation in identifying split errors across the whole fly brain demonstrate the superiority of the proposed approach, especially for the locations that contain severe imaging artifacts, such as section missing and misalignment. The dataset and code are available at https://github.com/Levishery/Flywire-Neuron-Tracing",
    "checked": true,
    "id": "57e936bc0d2758234bb80b7696b574ff57a928b4",
    "semantic_title": "learning multimodal volumetric features for large-scale neuron tracing",
    "citation_count": 0,
    "authors": [
      "Qihua Chen",
      "Xuejin Chen",
      "Chenxuan Wang",
      "Yixiong Liu",
      "Zhiwei Xiong",
      "Feng Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27880": {
    "title": "M-BEV: Masked BEV Perception for Robust Autonomous Driving",
    "volume": "main",
    "abstract": "3D perception is a critical problem in autonomous driving. Recently, the Bird's-Eye-View (BEV) approach has attracted extensive attention, due to low-cost deployment and desirable vision detection capacity. However, the existing models ignore a realistic scenario during the driving procedure, i.e., one or more view cameras may be failed, which largely deteriorates their performance. To tackle this problem, we propose a generic Masked BEV (M-BEV) perception framework, which can effectively improve robustness to this challenging scenario, by random masking and reconstructing camera views in the end-to-end training. More specifically, we develop a novel Masked View Reconstruction (MVR) module in our M-BEV. It mimics various missing cases by randomly masking features of different camera views, then leverages the original features of these views as self-supervision and reconstructs the masked ones with the distinct spatio-temporal context across camera views. Via such a plug-and-play MVR, our M-BEV is capable of learning the missing views from the resting ones, and thus well generalized for robust view recovery and accurate perception in the testing. We perform extensive experiments on the popular NuScenes benchmark, where our framework can significantly boost 3D perception performance of the state-of-the-art models on various missing view cases, e.g., for the absence of back view, our M-BEV promotes the PETRv2 model with 10.3% mAP gain",
    "checked": true,
    "id": "54d9039e6a5ccc46292ad0ecfba1a5f08ba6fa5e",
    "semantic_title": "m-bev: masked bev perception for robust autonomous driving",
    "citation_count": 4,
    "authors": [
      "Siran Chen",
      "Yue Ma",
      "Yu Qiao",
      "Yali Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27881": {
    "title": "VPDETR: End-to-End Vanishing Point DEtection TRansformers",
    "volume": "main",
    "abstract": "In the field of vanishing point detection, previous works commonly relied on extracting and clustering straight lines or classifying candidate points as vanishing points. This paper proposes a novel end-to-end framework, called VPDETR (Vanishing Point DEtection TRansformer), that views vanishing point detection as a set prediction problem, applicable to both Manhattan and non-Manhattan world datasets. By using the positional embedding of anchor points as queries in Transformer decoders and dynamically updating them layer by layer, our method is able to directly input images and output their vanishing points without the need for explicit straight line extraction and candidate points sampling. Additionally, we introduce an orthogonal loss and a cross-prediction loss to improve accuracy on the Manhattan world datasets. Experimental results demonstrate that VPDETR achieves competitive performance compared to state-of-the-art methods, without requiring post-processing",
    "checked": true,
    "id": "8a11e0d0d1acdffc37d8eb1b33ca2b64bc9e851f",
    "semantic_title": "vpdetr: end-to-end vanishing point detection transformers",
    "citation_count": 0,
    "authors": [
      "Taiyan Chen",
      "Xianghua Ying",
      "Jinfa Yang",
      "Ruibin Wang",
      "Ruohao Guo",
      "Bowei Xing",
      "Ji Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27882": {
    "title": "TCI-Former: Thermal Conduction-Inspired Transformer for Infrared Small Target Detection",
    "volume": "main",
    "abstract": "Infrared small target detection (ISTD) is critical to national security and has been extensively applied in military areas. ISTD aims to segment small target pixels from background. Most ISTD networks focus on designing feature extraction blocks or feature fusion modules, but rarely describe the ISTD process from the feature map evolution perspective. In the ISTD process, the network attention gradually shifts towards target areas. We abstract this process as the directional movement of feature map pixels to target areas through convolution, pooling and interactions with surrounding pixels, which can be analogous to the movement of thermal particles constrained by surrounding variables and particles. In light of this analogy, we propose Thermal Conduction-Inspired Transformer (TCI-Former) based on the theoretical principles of thermal conduction. According to thermal conduction differential equation in heat dynamics, we derive the pixel movement differential equation (PMDE) in the image domain and further develop two modules: Thermal Conduction-Inspired Attention (TCIA) and Thermal Conduction Boundary Module (TCBM). TCIA incorporates finite difference method with PMDE to reach a numerical approximation so that target body features can be extracted. To further remove errors in boundary areas, TCBM is designed and supervised by boundary masks to refine target body features with fine boundary details. Experiments on IRSTD-1k and NUAA-SIRST demonstrate the superiority of our method",
    "checked": true,
    "id": "d242afe48d20c9890e9e9d25bc4d66228f64cf97",
    "semantic_title": "tci-former: thermal conduction-inspired transformer for infrared small target detection",
    "citation_count": 2,
    "authors": [
      "Tianxiang Chen",
      "Zhentao Tan",
      "Qi Chu",
      "Yue Wu",
      "Bin Liu",
      "Nenghai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27883": {
    "title": "Intrinsic Phase-Preserving Networks for Depth Super Resolution",
    "volume": "main",
    "abstract": "Depth map super-resolution (DSR) plays an indispensable role in 3D vision. We discover an non-trivial spectral phenomenon: the components of high-resolution (HR) and low-resolution (LR) depth maps manifest the same intrinsic phase, and the spectral phase of RGB is a superset of them, which suggests that a phase-aware filter can assist in the precise use of RGB cues. Motivated by this, we propose an intrinsic phase-preserving DSR paradigm, named IPPNet, to fully exploit inter-modality collaboration in a mutually guided way. In a nutshell, a novel Phase-Preserving Filtering Module (PPFM) is developed to generate dynamic phase-aware filters according to the LR depth flow to filter out erroneous noisy components contained in RGB and then conduct depth enhancement via the modulation of the phase-preserved RGB signal. By stacking multiple PPFM blocks, the proposed IPPNet is capable of reaching a highly competitive restoration performance. Extensive experiments on various benchmark datasets, e.g., NYU v2, RGB-D-D, reach SOTA performance and also well demonstrate the validity of the proposed phase-preserving scheme. Code: https://github.com/neuralchen/IPPNet/",
    "checked": true,
    "id": "79d3b4119f68b26a216bb9d5e1a0b05ec0e499ef",
    "semantic_title": "intrinsic phase-preserving networks for depth super resolution",
    "citation_count": 0,
    "authors": [
      "Xuanhong Chen",
      "Hang Wang",
      "Jialiang Chen",
      "Kairui Feng",
      "Jinfan Liu",
      "Xiaohang Wang",
      "Weimin Zhang",
      "Bingbing Ni"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27884": {
    "title": "Box2Poly: Memory-Efficient Polygon Prediction of Arbitrarily Shaped and Rotated Text",
    "volume": "main",
    "abstract": "Recently, Transformer-based text detection techniques have sought to predict polygons by encoding the coordinates of individual boundary vertices using distinct query features. However, this approach incurs a significant memory overhead and struggles to effectively capture the intricate relationships between vertices belonging to the same instance. Consequently, irregular text layouts often lead to the prediction of outlined vertices, diminishing the quality of results. To address these challenges, we present an innovative approach rooted in Sparse R-CNN: a cascade decoding pipeline for polygon prediction. Our method ensures precision by iteratively refining polygon predictions, considering both the scale and location of preceding results. Leveraging this stabilized regression pipeline, even employing just a single feature vector to guide polygon instance regression yields promising detection results. Simultaneously, the leverage of instance-level feature proposal substantially enhances memory efficiency ( > 50% less vs. the SOTA method DPText-DETR) and reduces inference speed (> 40% less vs. DPText-DETR) with comparable performance on benchmarks. The code is available at https://github.com/Albertchen98/Box2Poly.git",
    "checked": true,
    "id": "b213fd13ea9188837f95e6cef6583dd7ebe43439",
    "semantic_title": "box2poly: memory-efficient polygon prediction of arbitrarily shaped and rotated text",
    "citation_count": 0,
    "authors": [
      "Xuyang Chen",
      "Dong Wang",
      "Konrad Schindler",
      "Mingwei Sun",
      "Yongliang Wang",
      "Nicolo Savioli",
      "Liqiu Meng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27885": {
    "title": "FashionERN: Enhance-and-Refine Network for Composed Fashion Image Retrieval",
    "volume": "main",
    "abstract": "The goal of composed fashion image retrieval is to locate a target image based on a reference image and modified text. Recent methods utilize symmetric encoders (e.g., CLIP) pre-trained on large-scale non-fashion datasets. However, the input for this task exhibits an asymmetric nature, where the reference image contains rich content while the modified text is often brief. Therefore, methods employing symmetric encoders encounter a severe phenomenon: retrieval results dominated by reference images, leading to the oversight of modified text. We propose a Fashion Enhance-and-Refine Network (FashionERN) centered around two aspects: enhancing the text encoder and refining visual semantics. We introduce a Triple-branch Modifier Enhancement model, which injects relevant information from the reference image and aligns the modified text modality with the target image modality. Furthermore, we propose a Dual-guided Vision Refinement model that retains critical visual information through text-guided refinement and self-guided refinement processes. The combination of these two models significantly mitigates the reference dominance phenomenon, ensuring accurate fulfillment of modifier requirements. Comprehensive experiments demonstrate our approach's state-of-the-art performance on four commonly used datasets",
    "checked": true,
    "id": "fd5fdfb299b4f6f21f4a660ef100bc96ead9df12",
    "semantic_title": "fashionern: enhance-and-refine network for composed fashion image retrieval",
    "citation_count": 0,
    "authors": [
      "Yanzhe Chen",
      "Huasong Zhong",
      "Xiangteng He",
      "Yuxin Peng",
      "Jiahuan Zhou",
      "Lele Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27886": {
    "title": "IT3D: Improved Text-to-3D Generation with Explicit View Synthesis",
    "volume": "main",
    "abstract": "Recent strides in Text-to-3D techniques have been propelled by distilling knowledge from powerful large text-to-image diffusion models (LDMs). Nonetheless, existing Text-to-3D approaches often grapple with challenges such as over-saturation, inadequate detailing, and unrealistic outputs. This study presents a novel strategy that leverages explicitly synthesized multi-view images to address these issues. Our approach involves the utilization of image-to-image pipelines, empowered by LDMs, to generate posed high-quality images based on the renderings of coarse 3D models. Although the generated images mostly alleviate the aforementioned issues, challenges such as view inconsistency and significant content variance persist due to the inherent generative nature of large diffusion models, posing extensive difficulties in leveraging these images effectively. To overcome this hurdle, we advocate integrating a discriminator alongside a novel Diffusion-GAN dual training strategy to guide the training of 3D models. For the incorporated discriminator, the synthesized multi-view images are considered real data, while the renderings of the optimized 3D models function as fake data. We conduct a comprehensive set of experiments that demonstrate the effectiveness of our method over baseline approaches",
    "checked": true,
    "id": "2b94785cbfd865a01cc68d7d4c7500b710e5e2fb",
    "semantic_title": "it3d: improved text-to-3d generation with explicit view synthesis",
    "citation_count": 40,
    "authors": [
      "Yiwen Chen",
      "Chi Zhang",
      "Xiaofeng Yang",
      "Zhongang Cai",
      "Gang Yu",
      "Lei Yang",
      "Guosheng Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27887": {
    "title": "Beyond the Label Itself: Latent Labels Enhance Semi-supervised Point Cloud Panoptic Segmentation",
    "volume": "main",
    "abstract": "As the exorbitant expense of labeling autopilot datasets and the growing trend of utilizing unlabeled data, semi-supervised segmentation on point clouds becomes increasingly imperative. Intuitively, finding out more ``unspoken words'' (i.e., latent instance information) beyond the label itself should be helpful to improve performance. In this paper, we discover two types of latent labels behind the displayed label embedded in LiDAR and image data. First, in the LiDAR Branch, we propose a novel augmentation, Cylinder-Mix, which is able to augment more yet reliable samples for training. Second, in the Image Branch, we propose the Instance Position-scale Learning (IPSL) Module to learn and fuse the information of instance position and scale, which is from a 2D pre-trained detector and a type of latent label obtained from 3D to 2D projection. Finally, the two latent labels are embedded into the multi-modal panoptic segmentation network. The ablation of the IPSL module demonstrates its robust adaptability, and the experiments evaluated on SemanticKITTI and nuScenes demonstrate that our model outperforms the state-of-the-art method, LaserMix",
    "checked": true,
    "id": "20d2a235544c712c9529e080973d940329be8042",
    "semantic_title": "beyond the label itself: latent labels enhance semi-supervised point cloud panoptic segmentation",
    "citation_count": 0,
    "authors": [
      "Yujun Chen",
      "Xin Tan",
      "Zhizhong Zhang",
      "Yanyun Qu",
      "Yuan Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27888": {
    "title": "Visual Chain-of-Thought Prompting for Knowledge-Based Visual Reasoning",
    "volume": "main",
    "abstract": "Knowledge-based visual reasoning remains a daunting task since it not only requires machines to interpret the concepts and relationships from visual scenes but also associate them with external world knowledge to conduct a chain of reasoning on open-world questions. Previous works, however, treat visual perception and language-based reasoning as two independent modules, failing to attend to both modules throughout all stages of reasoning. To this end, we propose Visual Chain-of-thought Prompting (VCTP) for knowledge-based reasoning, which involves the interaction between visual content and natural language in an iterative step-by-step reasoning manner. VCTP contains three stages, see, think, and confirm. The see stage scans the image and grounds the visual concept candidates with a visual perception model. The think stage adopts a pre-trained large language model (LLM) to attend to key visual concepts from natural language questions adaptively. It then transforms key visual context into text context for prompting with a visual captioning model, and adopts the LLM to generate the answer. The confirm stage further uses the LLM to generate the supporting rationale to the answer, which is then passed through a cross-modality classifier to verify that it's consistent with the visual context. We iterate through the think-confirm stages to ensure the verified rationale is consistent with the answer. We conduct experiments on a range of knowledge-based visual reasoning datasets. We found our VCTP enjoys several benefits, 1). it achieves better performance than the previous few-shot learning baselines; 2). it enjoys the total transparency and trustworthiness of the whole reasoning process by providing rationales for each reasoning step; 3). it is computation-efficient compared with other fine-tuning baselines. Our code is available at https://github.com/UMass-Foundation-Model/VisualCoT.git",
    "checked": true,
    "id": "edf3ad2b10d8084c5185072b07f0318f8ed110c9",
    "semantic_title": "visual chain-of-thought prompting for knowledge-based visual reasoning",
    "citation_count": 1,
    "authors": [
      "Zhenfang Chen",
      "Qinhong Zhou",
      "Yikang Shen",
      "Yining Hong",
      "Zhiqing Sun",
      "Dan Gutfreund",
      "Chuang Gan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27889": {
    "title": "Blind Face Restoration under Extreme Conditions: Leveraging 3D-2D Prior Fusion for Superior Structural and Texture Recovery",
    "volume": "main",
    "abstract": "Blind face restoration under extreme conditions involves reconstructing high-quality face images from severely degraded inputs. These input images are often in poor quality and have extreme facial poses, leading to errors in facial structure and unnatural artifacts within the restored images. In this paper, we show that utilizing 3D priors effectively compensates for structure knowledge deficiencies in 2D priors while preserving the texture details. Based on this, we introduce FREx (Face Restoration under Extreme conditions) that combines structure-accurate 3D priors and texture-rich 2D priors in pretrained generative networks for blind face restoration under extreme conditions. To fuse the different information in 3D and 2D priors, we introduce an adaptive weight module that adjusts the importance of features based on the input image's condition. With this approach, our model can restore structure-accurate and natural-looking faces even when the images have lost a lot of information due to degradation and extreme pose. Extensive experimental results on synthetic and real-world datasets validate the effectiveness of our methods",
    "checked": true,
    "id": "2d1159cb9821994a485c5e028adb42a8d03662b4",
    "semantic_title": "blind face restoration under extreme conditions: leveraging 3d-2d prior fusion for superior structural and texture recovery",
    "citation_count": 0,
    "authors": [
      "Zhengrui Chen",
      "Liying Lu",
      "Ziyang Yuan",
      "Yiming Zhu",
      "Yu Li",
      "Chun Yuan",
      "Weihong Deng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27890": {
    "title": "CamoDiffusion: Camouflaged Object Detection via Conditional Diffusion Models",
    "volume": "main",
    "abstract": "Camouflaged Object Detection (COD) is a challenging task in computer vision due to the high similarity between camouflaged objects and their surroundings. Existing COD methods struggle with nuanced object boundaries and overconfident incorrect predictions. In response, we propose a new paradigm that treats COD as a conditional mask-generation task leveraging diffusion models. Our method, dubbed CamoDiffusion, employs the denoising process to progressively refine predictions while incorporating image conditions. Due to the stochastic sampling process of diffusion, our model is capable of sampling multiple possible predictions, avoiding the problem of overconfident point estimation. Moreover, we develop specialized network architecture, training, and sampling strategies, to enhance the model's expressive power, refinement capabilities and suppress overconfident mis-segmentations, thus aptly tailoring the diffusion model to the demands of COD. Extensive experiments on three COD datasets attest to the superior performance of our model compared to existing state-of-the-art methods, particularly on the most challenging COD10K dataset, where our approach achieves 0.019 in terms of MAE. Codes and models are available at https://github.com/Rapisurazurite/CamoDiffusion",
    "checked": true,
    "id": "ba4185ed30b781d8429193e53401b9eda5c5284a",
    "semantic_title": "camodiffusion: camouflaged object detection via conditional diffusion models",
    "citation_count": 4,
    "authors": [
      "Zhongxi Chen",
      "Ke Sun",
      "Xianming Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27891": {
    "title": "DreamIdentity: Enhanced Editability for Efficient Face-Identity Preserved Image Generation",
    "volume": "main",
    "abstract": "While large-scale pre-trained text-to-image models can synthesize diverse and high-quality human-centric images, an intractable problem is how to preserve the face identity and follow the text prompts simultaneously for conditioned input face images and texts. Despite existing encoder-based methods achieving high efficiency and decent face similarity, the generated image often fails to follow the textual prompts. To ease this editability issue, we present DreamIdentity, to learn edit-friendly and accurate face-identity representations in the word embedding space. Specifically, we propose self-augmented editability learning to enhance the editability for projected embedding, which is achieved by constructing paired generated celebrity's face and edited celebrity images for training, aiming at transferring mature editability of off-the-shelf text-to-image models in celebrity to unseen identities. Furthermore, we design a novel dedicated face-identity encoder to learn an accurate representation of human faces, which applies multi-scale ID-aware features followed by a multi-embedding projector to generate the pseudo words in the text embedding space directly. Extensive experiments show that our method can generate more text-coherent and ID-preserved images with negligible time overhead compared to the standard text-to-image generation process",
    "checked": true,
    "id": "657099b643567828b2fa6b867d723b4b53d666f5",
    "semantic_title": "dreamidentity: enhanced editability for efficient face-identity preserved image generation",
    "citation_count": 2,
    "authors": [
      "Zhuowei Chen",
      "Shancheng Fang",
      "Wei Liu",
      "Qian He",
      "Mengqi Huang",
      "Zhendong Mao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27892": {
    "title": "Deep Linear Array Pushbroom Image Restoration: A Degradation Pipeline and Jitter-Aware Restoration Network",
    "volume": "main",
    "abstract": "Linear Array Pushbroom (LAP) imaging technology is widely used in the realm of remote sensing. However, images acquired through LAP always suffer from distortion and blur because of camera jitter. Traditional methods for restoring LAP images, such as algorithms estimating the point spread function (PSF), exhibit limited performance. To tackle this issue, we propose a Jitter-Aware Restoration Network (JARNet), to remove the distortion and blur in two stages. In the first stage, we formulate an Optical Flow Correction (OFC) block to refine the optical flow of the degraded LAP images, resulting in pre-corrected images where most of the distortions are alleviated. In the second stage, for further enhancement of the pre-corrected images, we integrate two jitter-aware techniques within the Spatial and Frequency Residual (SFRes) block: 1) introducing Coordinate Attention (CoA) to the SFRes block in order to capture the jitter state in orthogonal direction; 2) manipulating image features in both spatial and frequency domains to leverage local and global priors. Additionally, we develop a data synthesis pipeline, which applies Continue Dynamic Shooting Model (CDSM) to simulate realistic degradation in LAP images. Both the proposed JARNet and LAP image synthesis pipeline establish a foundation for addressing this intricate challenge. Extensive experiments demonstrate that the proposed two-stage method outperforms state-of-the-art image restoration models. Code is available at https://github.com/JHW2000/JARNet",
    "checked": true,
    "id": "eeb4f4fdeb2a69c93e5b2f2b041a261e8e8bd080",
    "semantic_title": "deep linear array pushbroom image restoration: a degradation pipeline and jitter-aware restoration network",
    "citation_count": 1,
    "authors": [
      "Zida Chen",
      "Ziran Zhang",
      "Haoying Li",
      "Menghao Li",
      "Yueting Chen",
      "Qi Li",
      "Huajun Feng",
      "Zhihai Xu",
      "Shiqi Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27893": {
    "title": "Context-Aware Iteration Policy Network for Efficient Optical Flow Estimation",
    "volume": "main",
    "abstract": "Existing recurrent optical flow estimation networks are computationally expensive since they use a fixed large number of iterations to update the flow field for each sample. An efficient network should skip iterations when the flow improvement is limited. In this paper, we develop a Context-Aware Iteration Policy Network for efficient optical flow estimation, which determines the optimal number of iterations per sample. The policy network achieves this by learning contextual information to realize whether flow improvement is bottlenecked or minimal. On the one hand, we use iteration embedding and historical hidden cell, which include previous iterations information, to convey how flow has changed from previous iterations. On the other hand, we use the incremental loss to make the policy network implicitly perceive the magnitude of optical flow improvement in the subsequent iteration. Furthermore, the computational complexity in our dynamic network is controllable, allowing us to satisfy various resource preferences with a single trained model. Our policy network can be easily integrated into state-of-the-art optical flow networks. Extensive experiments show that our method maintains performance while reducing FLOPs by about 40%/20% for the Sintel/KITTI datasets",
    "checked": true,
    "id": "1096340c3a5fb667a8fb59749a841ac5bc86b42b",
    "semantic_title": "context-aware iteration policy network for efficient optical flow estimation",
    "citation_count": 0,
    "authors": [
      "Ri Cheng",
      "Ruian He",
      "Xuhao Jiang",
      "Shili Zhou",
      "Weimin Tan",
      "Bo Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27894": {
    "title": "SparseGNV: Generating Novel Views of Indoor Scenes with Sparse RGB-D Images",
    "volume": "main",
    "abstract": "We study to generate novel views of indoor scenes given sparse input views. The challenge is to achieve both photorealism and view consistency. We present SparseGNV: a learning framework that incorporates 3D structures and image generative models to generate novel views with three modules. The first module builds a neural point cloud as underlying geometry, providing scene context and guidance for the target novel view. The second module utilizes a transformer-based network to map the scene context and the guidance into a shared latent space and autoregressively decodes the target view in the form of discrete image tokens. The third module reconstructs the tokens back to the image of the target view. SparseGNV is trained across a large-scale indoor scene dataset to learn generalizable priors. Once trained, it can efficiently generate novel views of an unseen indoor scene in a feed-forward manner. We evaluate SparseGNV on real-world indoor scenes and demonstrate that it outperforms state-of-the-art methods based on either neural radiance fields or conditional image generation",
    "checked": true,
    "id": "681424f0f6e04d70d2faface501e9e181691e681",
    "semantic_title": "sparsegnv: generating novel views of indoor scenes with sparse rgb-d images",
    "citation_count": 0,
    "authors": [
      "Weihao Cheng",
      "Yan-Pei Cao",
      "Ying Shan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27895": {
    "title": "Colorizing Monochromatic Radiance Fields",
    "volume": "main",
    "abstract": "Though Neural Radiance Fields (NeRF) can produce colorful 3D representations of the world by using a set of 2D images, such ability becomes non-existent when only monochromatic images are provided. Since color is necessary in representing the world, reproducing color from monochromatic radiance fields becomes crucial. To achieve this goal, instead of manipulating the monochromatic radiance fields directly, we consider it as a representation-prediction task in the Lab color space. By first constructing the luminance and density representation using monochromatic images, our prediction stage can recreate color representation on the basis of an image colorization module. We then reproduce a colorful implicit model through the representation of luminance, density, and color. Extensive experiments have been conducted to validate the effectiveness of our approaches. Our project page: https://liquidammonia.github.io/color-nerf",
    "checked": true,
    "id": "7d8c8e1c0db73e92e9eb9c6ffdf93acb4fa45156",
    "semantic_title": "colorizing monochromatic radiance fields",
    "citation_count": 2,
    "authors": [
      "Yean Cheng",
      "Renjie Wan",
      "Shuchen Weng",
      "Chengxuan Zhu",
      "Yakun Chang",
      "Boxin Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27896": {
    "title": "Parallel Vertex Diffusion for Unified Visual Grounding",
    "volume": "main",
    "abstract": "Unified visual grounding (UVG) capitalizes on a wealth of task-related knowledge across various grounding tasks via one-shot training, which curtails retraining costs and task-specific architecture design efforts. Vertex generation-based UVG methods achieve this versatility by unified modeling object box and contour prediction and provide a text-powered interface to vast related multi-modal tasks, e.g., visual question answering and captioning. However, these methods typically generate vertexes sequentially through autoregression, which is prone to be trapped in error accumulation and heavy computation, especially for high-dimension sequence generation in complex scenarios. In this paper, we develop Parallel Vertex Diffusion (PVD) based on the parallelizability of diffusion models to accurately and efficiently generate vertexes in a parallel and scalable manner. Since the coordinates fluctuate greatly, it typically encounters slow convergence when training diffusion models without geometry constraints. Therefore, we consummate our PVD by two critical components, i.e., center anchor mechanism and angle summation loss, which serve to normalize coordinates and adopt a differentiable geometry descriptor from the point-in-polygon problem of computational geometry to constrain the overall difference of prediction and label vertexes. These innovative designs empower our PVD to demonstrate its superiority with state-of-the-art performance across various grounding tasks",
    "checked": true,
    "id": "d38edd256b44131d752bca76907aeb1d28bf9111",
    "semantic_title": "parallel vertex diffusion for unified visual grounding",
    "citation_count": 13,
    "authors": [
      "Zesen Cheng",
      "Kehan Li",
      "Peng Jin",
      "Siheng Li",
      "Xiangyang Ji",
      "Li Yuan",
      "Chang Liu",
      "Jie Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27897": {
    "title": "iDet3D: Towards Efficient Interactive Object Detection for LiDAR Point Clouds",
    "volume": "main",
    "abstract": "Accurately annotating multiple 3D objects in LiDAR scenes is laborious and challenging. While a few previous studies have attempted to leverage semi-automatic methods for cost-effective bounding box annotation, such methods have limitations in efficiently handling numerous multi-class objects. To effectively accelerate 3D annotation pipelines, we propose iDet3D, an efficient interactive 3D object detector. Supporting a user-friendly 2D interface, which can ease the cognitive burden of exploring 3D space to provide click interactions, iDet3D enables users to annotate the entire objects in each scene with minimal interactions. Taking the sparse nature of 3D point clouds into account, we design a negative click simulation (NCS) to improve accuracy by reducing false-positive predictions. In addition, iDet3D incorporates two click propagation techniques to take full advantage of user interactions: (1) dense click guidance (DCG) for keeping user-provided information throughout the network and (2) spatial click propagation (SCP) for detecting other instances of the same class based on the user-specified objects. Through our extensive experiments, we present that our method can construct precise annotations in a few clicks, which shows the practicality as an efficient annotation tool for 3D object detection",
    "checked": true,
    "id": "d0e6b8a7f419588f9c16faba245999ea3daeb8bf",
    "semantic_title": "idet3d: towards efficient interactive object detection for lidar point clouds",
    "citation_count": 1,
    "authors": [
      "Dongmin Choi",
      "Wonwoo Cho",
      "Kangyeol Kim",
      "Jaegul Choo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27898": {
    "title": "Fusion-Vital: Video-RF Fusion Transformer for Advanced Remote Physiological Measurement",
    "volume": "main",
    "abstract": "Remote physiology, which involves monitoring vital signs without the need for physical contact, has great potential for various applications. Current remote physiology methods rely only on a single camera or radio frequency (RF) sensor to capture the microscopic signatures from vital movements. However, our study shows that fusing deep RGB and RF features from both sensor streams can further improve performance. Because these multimodal features are defined in distinct dimensions and have varying contextual importance, the main challenge in the fusion process lies in the effective alignment of them and adaptive integration of features under dynamic scenarios. To address this challenge, we propose a novel vital sensing model, named Fusion-Vital, that combines the RGB and RF modalities through the new introduction of pairwise input formats and transformer-based fusion strategies. We also perform comprehensive experiments based on a newly collected and released remote vital dataset comprising synchronized video-RF sensors, showing the superiority of the fusion approach over the previous single-sensor baselines in various aspects",
    "checked": true,
    "id": "ec9b8d518e52fe728cc4898a31d0bf85fb6a4325",
    "semantic_title": "fusion-vital: video-rf fusion transformer for advanced remote physiological measurement",
    "citation_count": 2,
    "authors": [
      "Jae-Ho Choi",
      "Ki-Bong Kang",
      "Kyung-Tae Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27899": {
    "title": "MeDM: Mediating Image Diffusion Models for Video-to-Video Translation with Temporal Correspondence Guidance",
    "volume": "main",
    "abstract": "This study introduces an efficient and effective method, MeDM, that utilizes pre-trained image Diffusion Models for video-to-video translation with consistent temporal flow. The proposed framework can render videos from scene position information, such as a normal G-buffer, or perform text-guided editing on videos captured in real-world scenarios. We employ explicit optical flows to construct a practical coding that enforces physical constraints on generated frames and mediates independent frame-wise scores. By leveraging this coding, maintaining temporal consistency in the generated videos can be framed as an optimization problem with a closed-form solution. To ensure compatibility with Stable Diffusion, we also suggest a workaround for modifying observation-space scores in latent Diffusion Models. Notably, MeDM does not require fine-tuning or test-time optimization of the Diffusion Models. Through extensive qualitative, quantitative, and subjective experiments on various benchmarks, the study demonstrates the effectiveness and superiority of the proposed approach. Our project page can be found at https://medm2023.github.io",
    "checked": true,
    "id": "2ef3c9b0830f0a599d900d267c840667295a0811",
    "semantic_title": "medm: mediating image diffusion models for video-to-video translation with temporal correspondence guidance",
    "citation_count": 5,
    "authors": [
      "Ernie Chu",
      "Tzuhsuan Huang",
      "Shuo-Yen Lin",
      "Jun-Cheng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27900": {
    "title": "Attack Deterministic Conditional Image Generative Models for Diverse and Controllable Generation",
    "volume": "main",
    "abstract": "Existing generative adversarial network (GAN) based conditional image generative models typically produce fixed output for the same conditional input, which is unreasonable for highly subjective tasks, such as large-mask image inpainting or style transfer. On the other hand, GAN-based diverse image generative methods require retraining/fine-tuning the network or designing complex noise injection functions, which is computationally expensive, task-specific, or struggle to generate high-quality results. Given that many deterministic conditional image generative models have been able to produce high-quality yet fixed results, we raise an intriguing question: is it possible for pre-trained deterministic conditional image generative models to generate diverse results without changing network structures or parameters? To answer this question, we re-examine the conditional image generation tasks from the perspective of adversarial attack and propose a simple and efficient plug-in projected gradient descent (PGD) like method for diverse and controllable image generation. The key idea is attacking the pre-trained deterministic generative models by adding a micro perturbation to the input condition. In this way, diverse results can be generated without any adjustment of network structures or fine-tuning of the pre-trained models. In addition, we can also control the diverse results to be generated by specifying the attack direction according to a reference text or image. Our work opens the door to applying adversarial attack to low-level vision tasks, and experiments on various conditional image generation tasks demonstrate the effectiveness and superiority of the proposed method",
    "checked": true,
    "id": "db8d6d9d742dca2056d26cc89d9fb3f07cf95257",
    "semantic_title": "attack deterministic conditional image generative models for diverse and controllable generation",
    "citation_count": 0,
    "authors": [
      "Tianyi Chu",
      "Wei Xing",
      "Jiafu Chen",
      "Zhizhong Wang",
      "Jiakai Sun",
      "Lei Zhao",
      "Haibo Chen",
      "Huaizhong Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27901": {
    "title": "NILUT: Conditional Neural Implicit 3D Lookup Tables for Image Enhancement",
    "volume": "main",
    "abstract": "3D lookup tables (3D LUTs) are a key component for image enhancement. Modern image signal processors (ISPs) have dedicated support for these as part of the camera rendering pipeline. Cameras typically provide multiple options for picture styles, where each style is usually obtained by applying a unique handcrafted 3D LUT. Current approaches for learning and applying 3D LUTs are notably fast, yet not so memory-efficient, as storing multiple 3D LUTs is required. For this reason and other implementation limitations, their use on mobile devices is less popular. In this work, we propose a Neural Implicit LUT (NILUT), an implicitly defined continuous 3D color transformation parameterized by a neural network. We show that NILUTs are capable of accurately emulating real 3D LUTs. Moreover, a NILUT can be extended to incorporate multiple styles into a single network with the ability to blend styles implicitly. Our novel approach is memory-efficient, controllable and can complement previous methods, including learned ISPs. Code at https://github.com/mv-lab/nilut",
    "checked": true,
    "id": "fd74c54504dcd17fcd0f1bc6c28e0ed7ee44d270",
    "semantic_title": "nilut: conditional neural implicit 3d lookup tables for image enhancement",
    "citation_count": 3,
    "authors": [
      "Marcos V. Conde",
      "Javier Vazquez-Corral",
      "Michael S. Brown",
      "Radu Timofte"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27902": {
    "title": "Decoupled Optimisation for Long-Tailed Visual Recognition",
    "volume": "main",
    "abstract": "When training on a long-tailed dataset, conventional learning algorithms tend to exhibit a bias towards classes with a larger sample size. Our investigation has revealed that this biased learning tendency originates from the model parameters, which are trained to disproportionately contribute to the classes characterised by their sample size (e.g., many, medium, and few classes). To balance the overall parameter contribution across all classes, we investigate the importance of each model parameter to the learning of different class groups, and propose a multistage parameter Decouple and Optimisation (DO) framework that decouples parameters into different groups with each group learning a specific portion of classes. To optimise the parameter learning, we apply different training objectives with a collaborative optimisation step to learn complementary information about each class group. Extensive experiments on long-tailed datasets, including CIFAR100, Places-LT, ImageNet-LT, and iNaturaList 2018, show that our framework achieves competitive performance compared to the state-of-the-art",
    "checked": true,
    "id": "9578e815851bad56c71bc45c256c45307e0895e8",
    "semantic_title": "decoupled optimisation for long-tailed visual recognition",
    "citation_count": 1,
    "authors": [
      "Cong Cong",
      "Shiyu Xuan",
      "Sidong Liu",
      "Shiliang Zhang",
      "Maurice Pagnucco",
      "Yang Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27903": {
    "title": "Underwater Organism Color Fine-Tuning via Decomposition and Guidance",
    "volume": "main",
    "abstract": "Due to the wavelength dependent light attenuation and scattering, the color of the underwater organism usually appears distorted. The existing underwater image enhancement methods mainly focus on designing networks capable of generating enhanced underwater organisms with fixed color. Due to the complexity of the underwater environment, ground truth labels are difficult to obtain, which results in the non-existence of perfect enhancement effects. Different from the existing methods, this paper proposes an algorithm with color enhancement and color fine-tuning (CECF) capabilities. The color enhancement behavior of CECF is the same as that of existing methods, aiming to restore the color of the distorted underwater organism. Beyond this general purpose, the color fine-tuning behavior of CECF can adjust the color of organisms in a controlled manner, which can generate enhanced organisms with diverse colors. To achieve this purpose, four processes are used in CECF. A supervised enhancement process learns the mapping from a distorted image to an enhanced image by the decomposition of color code. A self reconstruction process and a cross-reconstruction process are used for content-invariant learning. A color fine-tuning process is designed based on the guidance for obtaining various enhanced results with different colors. Experimental results have proven the enhancement ability and color fine-tuning ability of the proposed CECF. The source code is provided in https://github.com/Xiaofeng-life/CECF",
    "checked": true,
    "id": "5bc88f8f3b0b01861e2c257c175d2d78771f9c69",
    "semantic_title": "underwater organism color fine-tuning via decomposition and guidance",
    "citation_count": 1,
    "authors": [
      "Xiaofeng Cong",
      "Jie Gui",
      "Junming Hou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27904": {
    "title": "Color Event Enhanced Single-Exposure HDR Imaging",
    "volume": "main",
    "abstract": "Single-exposure high dynamic range (HDR) imaging aims to reconstruct the wide-range intensities of a scene by using its single low dynamic range (LDR) image, thus providing significant efficiency. Existing methods pay high attention to restoring the luminance by inversing the tone-mapping process, while the color in the over-/under-exposed area cannot be well restored due to the information loss of the single LDR image. To address this issue, we introduce color events into the imaging pipeline, which record asynchronous pixel-wise color changes in a high dynamic range, enabling edge-like scene perception under challenging lighting conditions. Specifically, we propose a joint framework that incorporates color events and a single LDR image to restore both content and color of an HDR image, where an exposureaware transformer (EaT) module is designed to propagate the informative hints, provided by the normal-exposed LDR regions and the event streams, to the missing areas. In this module, an exposure-aware mask is estimated to suppress distractive information and strengthen the restoration of the over-/under-exposed regions. To our knowledge, we are the first to use color events to enhance single-exposure HDR imaging. We also contribute corresponding datasets, consisting of synthesized datasets and a real-world dataset collected by a DAVIS346-color camera. The datasets can be found at https://www.kaggle.com/datasets/mengyaocui/ce-hdr. Extensive experiments demonstrate the effectiveness of the proposed method",
    "checked": true,
    "id": "acbc0fd34ff5049f5e1b91d521d515451852929d",
    "semantic_title": "color event enhanced single-exposure hdr imaging",
    "citation_count": 0,
    "authors": [
      "Mengyao Cui",
      "Zhigang Wang",
      "Dong Wang",
      "Bin Zhao",
      "Xuelong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27905": {
    "title": "PHFormer: Multi-Fragment Assembly Using Proxy-Level Hybrid Transformer",
    "volume": "main",
    "abstract": "Fragment assembly involves restoring broken objects to their original geometries, and has many applications, such as archaeological restoration. Existing learning based frameworks have shown potential for solving part assembly problems with semantic decomposition, but cannot handle such geometrical decomposition problems. In this work, we propose a novel assembly framework, proxy level hybrid Transformer, with the core idea of using a hybrid graph to model and reason complex structural relationships between patches of fragments, dubbed as proxies. To this end, we propose a hybrid attention module, composed of intra and inter attention layers, enabling capturing of crucial contextual information within fragments and relative structural knowledge across fragments. Furthermore, we propose an adjacency aware hierarchical pose estimator, exploiting a decompose and integrate strategy. It progressively predicts adjacent probability and relative poses between fragments, and then implicitly infers their absolute poses by dynamic information integration. Extensive experimental results demonstrate that our method effectively reduces assembly errors while maintaining fast inference speed. The code is available at https://github.com/521piglet/PHFormer",
    "checked": true,
    "id": "adbfbef540dea9e93eec5f01898766f2931e4e64",
    "semantic_title": "phformer: multi-fragment assembly using proxy-level hybrid transformer",
    "citation_count": 0,
    "authors": [
      "Wenting Cui",
      "Runzhao Yao",
      "Shaoyi Du"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27906": {
    "title": "Trash to Treasure: Low-Light Object Detection via Decomposition-and-Aggregation",
    "volume": "main",
    "abstract": "Object detection in low-light scenarios has attracted much attention in the past few years. A mainstream and representative scheme introduces enhancers as the pre-processing for regular detectors. However, because of the disparity in task objectives between the enhancer and detector, this paradigm cannot shine at its best ability. In this work, we try to arouse the potential of enhancer + detector. Different from existing works, we extend the illumination-based enhancers (our newly designed or existing) as a scene decomposition module, whose removed illumination is exploited as the auxiliary in the detector for extracting detection-friendly features. A semantic aggregation module is further established for integrating multi-scale scene-related semantic information in the context space. Actually, our built scheme successfully transforms the \"trash\" (i.e., the ignored illumination in the detector) into the \"treasure\" for the detector. Plenty of experiments are conducted to reveal our superiority against other state-of-the-art methods. The code will be public if it is accepted",
    "checked": true,
    "id": "0eb0f6f72f36b55594a6ffdb4ae64018e3d22983",
    "semantic_title": "trash to treasure: low-light object detection via decomposition-and-aggregation",
    "citation_count": 1,
    "authors": [
      "Xiaohan Cui",
      "Long Ma",
      "Tengyu Ma",
      "Jinyuan Liu",
      "Xin Fan",
      "Risheng Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27907": {
    "title": "Omni-Kernel Network for Image Restoration",
    "volume": "main",
    "abstract": "Image restoration aims to reconstruct a high-quality image from a degraded low-quality observation. Recently, Transformer models have achieved promising performance on image restoration tasks due to their powerful ability to model long-range dependencies. However, the quadratically growing complexity with respect to the input size makes them inapplicable to practical applications. In this paper, we develop an efficient convolutional network for image restoration by enhancing multi-scale representation learning. To this end, we propose an omni-kernel module that consists of three branches, i.e., global, large, and local branches, to learn global-to-local feature representations efficiently. Specifically, the global branch achieves a global perceptive field via the dual-domain channel attention and frequency-gated mechanism. Furthermore, to provide multi-grained receptive fields, the large branch is formulated via different shapes of depth-wise convolutions with unusually large kernel sizes. Moreover, we complement local information using a point-wise depth-wise convolution. Finally, the proposed network, dubbed OKNet, is established by inserting the omni-kernel module into the bottleneck position for efficiency. Extensive experiments demonstrate that our network achieves state-of-the-art performance on 11 benchmark datasets for three representative image restoration tasks, including image dehazing, image desnowing, and image defocus deblurring. The code is available at https://github.com/c-yn/OKNet",
    "checked": true,
    "id": "d5a17832f115c16d4097ea39f204917734f9fba0",
    "semantic_title": "omni-kernel network for image restoration",
    "citation_count": 5,
    "authors": [
      "Yuning Cui",
      "Wenqi Ren",
      "Alois Knoll"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27908": {
    "title": "Aleth-NeRF: Illumination Adaptive NeRF with Concealing Field Assumption",
    "volume": "main",
    "abstract": "The standard Neural Radiance Fields (NeRF) paradigm employs a viewer-centered methodology, entangling the aspects of illumination and material reflectance into emission solely from 3D points. This simplified rendering approach presents challenges in accurately modeling images captured under adverse lighting conditions, such as low light or over-exposure. Motivated by the ancient Greek emission theory that posits visual perception as a result of rays emanating from the eyes, we slightly refine the conventional NeRF framework to train NeRF under challenging light conditions and generate normal-light condition novel views unsupervisedly. We introduce the concept of a ``Concealing Field,\" which assigns transmittance values to the surrounding air to account for illumination effects. In dark scenarios, we assume that object emissions maintain a standard lighting level but are attenuated as they traverse the air during the rendering process. Concealing Field thus compel NeRF to learn reasonable density and colour estimations for objects even in dimly lit situations. Similarly, the Concealing Field can mitigate over-exposed emissions during rendering stage. Furthermore, we present a comprehensive multi-view dataset captured under challenging illumination conditions for evaluation. Our code and proposed dataset are available at https://github.com/cuiziteng/Aleth-NeRF",
    "checked": true,
    "id": "c799930bc727d1e891a578dd7001a3d7e1380957",
    "semantic_title": "aleth-nerf: illumination adaptive nerf with concealing field assumption",
    "citation_count": 2,
    "authors": [
      "Ziteng Cui",
      "Lin Gu",
      "Xiao Sun",
      "Xianzheng Ma",
      "Yu Qiao",
      "Tatsuya Harada"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27909": {
    "title": "Federated Modality-Specific Encoders and Multimodal Anchors for Personalized Brain Tumor Segmentation",
    "volume": "main",
    "abstract": "Most existing federated learning (FL) methods for medical image analysis only considered intramodal heterogeneity, limiting their applicability to multimodal imaging applications. In practice, it is not uncommon that some FL participants only possess a subset of the complete imaging modalities, posing inter-modal heterogeneity as a challenge to effectively training a global model on all participants' data. In addition, each participant would expect to obtain a personalized model tailored for its local data characteristics from the FL in such a scenario. In this work, we propose a new FL framework with federated modality-specific encoders and multimodal anchors (FedMEMA) to simultaneously address the two concurrent issues. Above all, FedMEMA employs an exclusive encoder for each modality to account for the inter-modal heterogeneity in the first place. In the meantime, while the encoders are shared by the participants, the decoders are personalized to meet individual needs. Specifically, a server with full-modal data employs a fusion decoder to aggregate and fuse representations from all modality-specific encoders, thus bridging the modalities to optimize the encoders via backpropagation reversely. Meanwhile, multiple anchors are extracted from the fused multimodal representations and distributed to the clients in addition to the encoder parameters. On the other end, the clients with incomplete modalities calibrate their missing-modal representations toward the global full-modal anchors via scaled dot-product cross-attention, making up the information loss due to absent modalities while adapting the representations of present ones. FedMEMA is validated on the BraTS 2020 benchmark for multimodal brain tumor segmentation. Results show that it outperforms various up-to-date methods for multimodal and personalized FL and that its novel designs are effective. Our code is available",
    "checked": true,
    "id": "d1e98ba0e7d6730ddf4be207ed95c0890d4e4045",
    "semantic_title": "federated modality-specific encoders and multimodal anchors for personalized brain tumor segmentation",
    "citation_count": 0,
    "authors": [
      "Qian Dai",
      "Dong Wei",
      "Hong Liu",
      "Jinghan Sun",
      "Liansheng Wang",
      "Yefeng Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27910": {
    "title": "Generating and Reweighting Dense Contrastive Patterns for Unsupervised Anomaly Detection",
    "volume": "main",
    "abstract": "Recent unsupervised anomaly detection methods often rely on feature extractors pretrained with auxiliary datasets or on well-crafted anomaly-simulated samples. However, this might limit their adaptability to an increasing set of anomaly detection tasks due to the priors in the selection of auxiliary datasets or the strategy of anomaly simulation. To tackle this challenge, we first introduce a prior-less anomaly generation paradigm and subsequently develop an innovative unsupervised anomaly detection framework named GRAD, grounded in this paradigm. GRAD comprises three essential components: (1) a diffusion model (PatchDiff) to generate contrastive patterns by preserving the local structures while disregarding the global structures present in normal images, (2) a self-supervised reweighting mechanism to handle the challenge of long-tailed and unlabeled contrastive patterns generated by PatchDiff, and (3) a lightweight patch-level detector to efficiently distinguish the normal patterns and reweighted contrastive patterns. The generation results of PatchDiff effectively expose various types of anomaly patterns, e.g. structural and logical anomaly patterns. In addition, extensive experiments on both MVTec AD and MVTec LOCO datasets also support the aforementioned observation and demonstrate that GRAD achieves competitive anomaly detection accuracy and superior inference speed",
    "checked": true,
    "id": "814e8989af511bdfea1e34afee27aaabb649fef7",
    "semantic_title": "generating and reweighting dense contrastive patterns for unsupervised anomaly detection",
    "citation_count": 1,
    "authors": [
      "Songmin Dai",
      "Yifan Wu",
      "Xiaoqiang Li",
      "Xiangyang Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27911": {
    "title": "Noisy Correspondence Learning with Self-Reinforcing Errors Mitigation",
    "volume": "main",
    "abstract": "Cross-modal retrieval relies on well-matched large-scale datasets that are laborious in practice. Recently, to alleviate expensive data collection, co-occurring pairs from the Internet are automatically harvested for training. However, it inevitably includes mismatched pairs, i.e., noisy correspondences, undermining supervision reliability and degrading performance. Current methods leverage deep neural networks' memorization effect to address noisy correspondences, which overconfidently focus on similarity-guided training with hard negatives and suffer from self-reinforcing errors. In light of above, we introduce a novel noisy correspondence learning framework, namely Self-Reinforcing Errors Mitigation (SREM). Specifically, by viewing sample matching as classification tasks within the batch, we generate classification logits for the given sample. Instead of a single similarity score, we refine sample filtration through energy uncertainty and estimate model's sensitivity of selected clean samples using swapped classification entropy, in view of the overall prediction distribution. Additionally, we propose cross-modal biased complementary learning to leverage negative matches overlooked in hard-negative training, further improving model optimization stability and curbing self-reinforcing errors. Extensive experiments on challenging benchmarks affirm the efficacy and efficiency of SREM",
    "checked": true,
    "id": "1c18b9be598b5c95f9b3d7e56e9c8ffa363e6828",
    "semantic_title": "noisy correspondence learning with self-reinforcing errors mitigation",
    "citation_count": 0,
    "authors": [
      "Zhuohang Dang",
      "Minnan Luo",
      "Chengyou Jia",
      "Guang Dai",
      "Xiaojun Chang",
      "Jingdong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27912": {
    "title": "LDMVFI: Video Frame Interpolation with Latent Diffusion Models",
    "volume": "main",
    "abstract": "Existing works on video frame interpolation (VFI) mostly employ deep neural networks that are trained by minimizing the L1, L2, or deep feature space distance (e.g. VGG loss) between their outputs and ground-truth frames. However, recent works have shown that these metrics are poor indicators of perceptual VFI quality. Towards developing perceptually-oriented VFI methods, in this work we propose latent diffusion model-based VFI, LDMVFI. This approaches the VFI problem from a generative perspective by formulating it as a conditional generation problem. As the first effort to address VFI using latent diffusion models, we rigorously benchmark our method on common test sets used in the existing VFI literature. Our quantitative experiments and user study indicate that LDMVFI is able to interpolate video content with favorable perceptual quality compared to the state of the art, even in the high-resolution regime. Our code is available at https://github.com/danier97/LDMVFI",
    "checked": true,
    "id": "3bc8bbf3f3909d83b96759af4831cf175a1a0e6e",
    "semantic_title": "ldmvfi: video frame interpolation with latent diffusion models",
    "citation_count": 18,
    "authors": [
      "Duolikun Danier",
      "Fan Zhang",
      "David Bull"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27913": {
    "title": "No More Shortcuts: Realizing the Potential of Temporal Self-Supervision",
    "volume": "main",
    "abstract": "Self-supervised approaches for video have shown impressive results in video understanding tasks. However, unlike early works that leverage temporal self-supervision, current state-of-the-art methods primarily rely on tasks from the image domain (e.g., contrastive learning) that do not explicitly promote the learning of temporal features. We identify two factors that limit existing temporal self-supervision: 1) tasks are too simple, resulting in saturated training performance, and 2) we uncover shortcuts based on local appearance statistics that hinder the learning of high-level features. To address these issues, we propose 1) a more challenging reformulation of temporal self-supervision as frame-level (rather than clip-level) recognition tasks and 2) an effective augmentation strategy to mitigate shortcuts. Our model extends a representation of single video frames, pre-trained through contrastive learning, with a transformer that we train through temporal self-supervision. We demonstrate experimentally that our more challenging frame-level task formulations and the removal of shortcuts drastically improve the quality of features learned through temporal self-supervision. Our extensive experiments show state-of-the-art performance across 10 video understanding datasets, illustrating the generalization ability and robustness of our learned video representations. Project Page: https://daveishan.github.io/nms-webpage",
    "checked": true,
    "id": "4294b80325c89b291b29418f60163cd736da7de6",
    "semantic_title": "no more shortcuts: realizing the potential of temporal self-supervision",
    "citation_count": 2,
    "authors": [
      "Ishan Rajendrakumar Dave",
      "Simon Jenni",
      "Mubarak Shah"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27914": {
    "title": "A Dynamic GCN with Cross-Representation Distillation for Event-Based Learning",
    "volume": "main",
    "abstract": "Recent advances in event-based research prioritize sparsity and temporal precision. Approaches learning sparse point-based representations through graph CNNs (GCN) become more popular. Yet, these graph techniques hold lower performance than their frame-based counterpart due to two issues: (i) Biased graph structures that don't properly incorporate varied attributes (such as semantics, and spatial and temporal signals) for each vertex, resulting in inaccurate graph representations. (ii) A shortage of robust pretrained models. Here we solve the first problem by proposing a new event-based GCN (EDGCN), with a dynamic aggregation module to integrate all attributes of vertices adaptively. To address the second problem, we introduce a novel learning framework called cross-representation distillation (CRD), which leverages the dense representation of events as a cross-representation auxiliary to provide additional supervision and prior knowledge for the event graph. This frame-to-graph distillation allows us to benefit from the large-scale priors provided by CNNs while still retaining the advantages of graph-based models. Extensive experiments show our model and learning framework are effective and generalize well across multiple vision tasks",
    "checked": true,
    "id": "f3427a07ffb1e38d86d2d284be7786d7f0cfd3b7",
    "semantic_title": "a dynamic gcn with cross-representation distillation for event-based learning",
    "citation_count": 1,
    "authors": [
      "Yongjian Deng",
      "Hao Chen",
      "Youfu Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27915": {
    "title": "ResMatch: Residual Attention Learning for Feature Matching",
    "volume": "main",
    "abstract": "Attention-based graph neural networks have made great progress in feature matching. However, the literature lacks a comprehensive understanding of how the attention mechanism operates for feature matching. In this paper, we rethink cross- and self-attention from the viewpoint of traditional feature matching and filtering. To facilitate the learning of matching and filtering, we incorporate the similarity of descriptors into cross-attention and relative positions into self-attention. In this way, the attention can concentrate on learning residual matching and filtering functions with reference to the basic functions of measuring visual and spatial correlation. Moreover, we leverage descriptor similarity and relative positions to extract inter- and intra-neighbors. Then sparse attention for each point can be performed only within its neighborhoods to acquire higher computation efficiency. Extensive experiments, including feature matching, pose estimation and visual localization, confirm the superiority of the proposed method. Our codes are available at https://github.com/ACuOoOoO/ResMatch",
    "checked": true,
    "id": "96e0a6f9d2c2c0124f390c73263511c580cf812a",
    "semantic_title": "resmatch: residual attention learning for feature matching",
    "citation_count": 0,
    "authors": [
      "Yuxin Deng",
      "Kaining Zhang",
      "Shihua Zhang",
      "Yansheng Li",
      "Jiayi Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27916": {
    "title": "SDGMNet: Statistic-Based Dynamic Gradient Modulation for Local Descriptor Learning",
    "volume": "main",
    "abstract": "Rescaling the backpropagated gradient of contrastive loss has made significant progress in descriptor learning. However, current gradient modulation strategies have no regard for the varying distribution of global gradients, so they would suffer from changes in training phases or datasets. In this paper, we propose a dynamic gradient modulation, named SDGMNet, for contrastive local descriptor learning. The core of our method is formulating modulation functions with dynamically estimated statistical characteristics. Firstly, we introduce angle for distance measure after deep analysis on backpropagation of pair-wise loss. On this basis, auto-focus modulation is employed to moderate the impact of statistically uncommon individual pairs in stochastic gradient descent optimization; probabilistic margin cuts off the gradients of proportional triplets that have achieved enough optimization; power adjustment balances the total weights of negative pairs and positive pairs. Extensive experiments demonstrate that our novel descriptor surpasses previous state-of-the-art methods in several tasks including patch verification, retrieval, pose estimation, and 3D reconstruction",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Deng",
      "Jiayi Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27917": {
    "title": "Stereo Vision Conversion from Planar Videos Based on Temporal Multiplane Images",
    "volume": "main",
    "abstract": "With the rapid development of 3D movie and light-field displays, there is a growing demand for stereo videos. However, generating high-quality stereo videos from planar videos remains a challenging task. Traditional depth-image-based rendering techniques struggle to effectively handle the problem of occlusion exposure, which occurs when the occluded contents become visible in other views. Recently, the single-view multiplane images (MPI) representation has shown promising performance for planar video stereoscopy. However, the MPI still lacks real details that are occluded in the current frame, resulting in blurry artifacts in occlusion exposure regions. In fact, planar videos can leverage complementary information from adjacent frames to predict a more complete scene representation for the current frame. Therefore, this paper extends the MPI from still frames to the temporal domain, introducing the temporal MPI (TMPI). By extracting complementary information from adjacent frames based on optical flow guidance, obscured regions in the current frame can be effectively repaired. Additionally, a new module called masked optical flow warping (MOFW) is introduced to improve the propagation of pixels along optical flow trajectories. Experimental results demonstrate that the proposed method can generate high-quality stereoscopic or light-field videos from a single view and reproduce better occluded details than other state-of-the-art (SOTA) methods. https://github.com/Dio3ding/TMPI",
    "checked": true,
    "id": "e923586185f3554bca7543c1db293c2df93c71ba",
    "semantic_title": "stereo vision conversion from planar videos based on temporal multiplane images",
    "citation_count": 0,
    "authors": [
      "Shanding Diao",
      "Yuan Chen",
      "Yang Zhao",
      "Wei Jia",
      "Zhao Zhang",
      "Ronggang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27918": {
    "title": "Weak Distribution Detectors Lead to Stronger Generalizability of Vision-Language Prompt Tuning",
    "volume": "main",
    "abstract": "We propose a generalized method for boosting the generalization ability of pre-trained vision-language models (VLMs) while fine-tuning on downstream few-shot tasks. The idea is realized by exploiting out-of-distribution (OOD) detection to predict whether a sample belongs to a base distribution or a novel distribution and then using the score generated by a dedicated competition based scoring function to fuse the zero-shot and few-shot classifier. The fused classifier is dynamic, which will bias towards the zero-shot classifier if a sample is more likely from the distribution pre-trained on, leading to improved base-to-novel generalization ability. Our method is performed only in test stage, which is applicable to boost existing methods without time-consuming re-training. Extensive experiments show that even weak distribution detectors can still improve VLMs' generalization ability. Specifically, with the help of OOD detectors, the harmonic mean of CoOp and ProGrad increase by 2.6 and 1.5 percentage points over 11 recognition datasets in the base-to-novel setting",
    "checked": true,
    "id": "d6edcea64948ca6f61a42797957c86a0c2a41fef",
    "semantic_title": "weak distribution detectors lead to stronger generalizability of vision-language prompt tuning",
    "citation_count": 1,
    "authors": [
      "Kun Ding",
      "Haojian Zhang",
      "Qiang Yu",
      "Ying Wang",
      "Shiming Xiang",
      "Chunhong Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27919": {
    "title": "Expressive Forecasting of 3D Whole-Body Human Motions",
    "volume": "main",
    "abstract": "Human motion forecasting, with the goal of estimating future human behavior over a period of time, is a fundamental task in many real-world applications. However, existing works typically concentrate on foretelling the major joints of the human body without considering the delicate movements of the human hands. In practical applications, hand gesture plays an important role in human communication with the real world, and expresses the primary intention of human beings. In this work, we are the first to formulate whole-body human pose forecasting task, which jointly predicts future both body and gesture activities. Correspondingly, we propose a novel Encoding-Alignment-Interaction (EAI) framework that aims to predict both coarse (body joints) and fine-grained (gestures) activities collaboratively, enabling expressive and cross-facilitated forecasting of 3D whole-body human motions. Specifically, our model involves two key constituents: cross-context alignment (XCA) and cross-context interaction (XCI). Considering the heterogeneous information within the whole-body, XCA aims to align the latent features of various human components, while XCI focuses on effectively capturing the context interaction among the human components. We conduct extensive experiments on a newly-introduced large-scale benchmark and achieve state-of-the-art performance. The code is public for research purposes at https://github.com/Dingpx/EAI",
    "checked": true,
    "id": "661e99f046cd40e4506d4ebe48befaecd9c220ec",
    "semantic_title": "expressive forecasting of 3d whole-body human motions",
    "citation_count": 1,
    "authors": [
      "Pengxiang Ding",
      "Qiongjie Cui",
      "Haofan Wang",
      "Min Zhang",
      "Mengyuan Liu",
      "Donglin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27920": {
    "title": "Transferable Adversarial Attacks for Object Detection Using Object-Aware Significant Feature Distortion",
    "volume": "main",
    "abstract": "Transferable black-box adversarial attacks against classifiers by disturbing the intermediate-layer features have been extensively studied in recent years. However, these methods have not yet achieved satisfactory performances when directly applied to object detectors. This is largely because the features of detectors are fundamentally different from that of the classifiers. In this study, we propose a simple but effective method to improve the transferability of adversarial examples for object detectors by leveraging the properties of spatial consistency and limited equivariance of object detectors' features. Specifically, we combine a novel loss function and deliberately designed data augmentation to distort the backbone features of object detectors by suppressing significant features corresponding to objects and amplifying the surrounding vicinal features corresponding to object boundaries. As such the target object and background area on the generated adversarial samples are more likely to be confused by other detectors. Extensive experimental results show that our proposed method achieves state-of-the-art black-box transferability for untargeted attacks on various models, including one/two-stage, CNN/Transformer-based, and anchor-free/anchor-based detectors",
    "checked": true,
    "id": "992922464cae18df7a6c22e53f2ccf27b9b7bc45",
    "semantic_title": "transferable adversarial attacks for object detection using object-aware significant feature distortion",
    "citation_count": 0,
    "authors": [
      "Xinlong Ding",
      "Jiansheng Chen",
      "Hongwei Yu",
      "Yu Shang",
      "Yining Qin",
      "Huimin Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27921": {
    "title": "Hyp-OW: Exploiting Hierarchical Structure Learning with Hyperbolic Distance Enhances Open World Object Detection",
    "volume": "main",
    "abstract": "Open World Object Detection (OWOD) is a challenging and realistic task that extends beyond the scope of standard Object Detection task. It involves detecting both known and unknown objects while integrating learned knowledge for future tasks. However, the level of \"unknownness\" varies significantly depending on the context. For example, a tree is typically considered part of the background in a self-driving scene, but it may be significant in a household context. We argue that this contextual information should already be embedded within the known classes. In other words, there should be a semantic or latent structure relationship between the known and unknown items to be discovered. Motivated by this observation, we propose Hyp-OW, a method that learns and models hierarchical representation of known items through a SuperClass Regularizer. Leveraging this representation allows us to effectively detect unknown objects using a similarity distance-based relabeling module. Extensive experiments on benchmark datasets demonstrate the effectiveness of Hyp-OW, achieving improvement in both known and unknown detection (up to 6 percent). These findings are particularly pronounced in our newly designed benchmark, where a strong hierarchical structure exists between known and unknown objects",
    "checked": true,
    "id": "41467217a3d273fa73ca713f14ba3f025ae3642a",
    "semantic_title": "hyp-ow: exploiting hierarchical structure learning with hyperbolic distance enhances open world object detection",
    "citation_count": 4,
    "authors": [
      "Thang Doan",
      "Xin Li",
      "Sima Behpour",
      "Wenbin He",
      "Liang Gou",
      "Liu Ren"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27922": {
    "title": "Exploiting Polarized Material Cues for Robust Car Detection",
    "volume": "main",
    "abstract": "Car detection is an important task that serves as a crucial prerequisite for many automated driving functions. The large variations in lighting/weather conditions and vehicle densities of the scenes pose significant challenges to existing car detection algorithms to meet the highly accurate perception demand for safety, due to the unstable/limited color information, which impedes the extraction of meaningful/discriminative features of cars. In this work, we present a novel learning-based car detection method that leverages trichromatic linear polarization as an additional cue to disambiguate such challenging cases. A key observation is that polarization, characteristic of the light wave, can robustly describe intrinsic physical properties of the scene objects in various imaging conditions and is strongly linked to the nature of materials for cars (e.g., metal and glass) and their surrounding environment (e.g., soil and trees), thereby providing reliable and discriminative features for robust car detection in challenging scenes. To exploit polarization cues, we first construct a pixel-aligned RGB-Polarization car detection dataset, which we subsequently employ to train a novel multimodal fusion network. Our car detection network dynamically integrates RGB and polarization features in a request-and-complement manner and can explore the intrinsic material properties of cars across all learning samples. We extensively validate our method and demonstrate that it outperforms state-of-the-art detection methods. Experimental results show that polarization is a powerful cue for car detection. Our code is available at https://github.com/wind1117/AAAI24-PCDNet",
    "checked": true,
    "id": "6f89f5cb2cbafcaf123d672335d1d21c1a62849a",
    "semantic_title": "exploiting polarized material cues for robust car detection",
    "citation_count": 0,
    "authors": [
      "Wen Dong",
      "Haiyang Mei",
      "Ziqi Wei",
      "Ao Jin",
      "Sen Qiu",
      "Qiang Zhang",
      "Xin Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27923": {
    "title": "Learning Multi-Modal Cross-Scale Deformable Transformer Network for Unregistered Hyperspectral Image Super-resolution",
    "volume": "main",
    "abstract": "Hyperspectral image super-resolution (HSI-SR) is a technology to improve the spatial resolution of HSI. Existing fusion-based SR methods have shown great performance, but still have some problems as follows: 1) existing methods assume that the auxiliary image providing spatial information is strictly registered with the HSI, but images are difficult to be registered finely due to the shooting platforms, shooting viewpoints and the influence of atmospheric turbulence; 2) most of the methods are based on convolutional neural networks (CNNs), which is effective for local features but cannot utilize the global features. To this end, we propose a multi-modal cross-scale deformable transformer network (M2DTN) to achieve unregistered HSI-SR. Specifically, we formulate a spectrum-preserving based spatial-guided registration-SR unified model (SSRU) from the view of the realistic degradation scenarios. According to SSRU, we propose multi-modal registration deformable module (MMRD) to align features between different modalities by deformation field. In order to efficiently utilize the unique information between different modals, we design multi-scale feature transformer (MSFT) to emphasize the spatial-spectral features at different scales. In addition, we propose the cross-scale feature aggregation module (CSFA) to accurately reconstruct the HSI by aggregating feature information at different scales. Experiments show that M2DTN outperforms the-state-of-the-art HSI-SR methods. Code is obtainable at https://github.com/Jiahuiqu/M2DTN",
    "checked": true,
    "id": "d634ca4341ba3f6e454945c7fd0973b53174cf83",
    "semantic_title": "learning multi-modal cross-scale deformable transformer network for unregistered hyperspectral image super-resolution",
    "citation_count": 0,
    "authors": [
      "Wenqian Dong",
      "Yang Xu",
      "Jiahui Qu",
      "Shaoxiong Hou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27924": {
    "title": "Joint Demosaicing and Denoising for Spike Camera",
    "volume": "main",
    "abstract": "As a neuromorphic camera with high temporal resolution, spike camera can capture dynamic scenes with high-speed motion. Recently, spike camera with a color filter array (CFA) has been developed for color imaging. There are some methods for spike camera demosaicing to reconstruct color images from Bayer-pattern spike streams. However, the demosaicing results are bothered by severe noise in spike streams, to which previous works pay less attention. In this paper, we propose an iterative joint demosaicing and denoising network (SJDD-Net) for spike cameras based on the observation model. Firstly, we design a color spike representation (CSR) to learn latent representation from Bayer-pattern spike streams. In CSR, we propose an offset-sharing deformable convolution module to align temporal features of color channels. Then we develop a spike noise estimator (SNE) to obtain features of the noise distribution. Finally, a color correlation prior (CCP) module is proposed to utilize the color correlation for better details. For training and evaluation, we designed a spike camera simulator to generate Bayer-pattern spike streams with synthesized noise. Besides, we captured some Bayer-pattern spike streams, building the first real-world captured dataset to our knowledge. Experimental results show that our method can restore clean images from Bayer-pattern spike streams. The source codes and dataset are available at https://github.com/csycdong/SJDD-Net",
    "checked": true,
    "id": "8ef9169f4362b6b5686756d707d735c0d8644e4f",
    "semantic_title": "joint demosaicing and denoising for spike camera",
    "citation_count": 1,
    "authors": [
      "Yanchen Dong",
      "Ruiqin Xiong",
      "Jing Zhao",
      "Jian Zhang",
      "Xiaopeng Fan",
      "Shuyuan Zhu",
      "Tiejun Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27925": {
    "title": "ChromaFusionNet (CFNet): Natural Fusion of Fine-Grained Color Editing",
    "volume": "main",
    "abstract": "Digital image enhancement aims to deliver visually striking, pleasing images that align with human perception. While global techniques can elevate the image's overall aesthetics, fine-grained color enhancement can further boost visual appeal and expressiveness. However, colorists frequently face challenges in achieving accurate, localized color adjustments. Direct composition of these local edits can result in spatial color inconsistencies. Existing methods, including color style transfer and image harmonization, exhibit inconsistencies, especially at boundary regions. Addressing this, we present ChromaFusionNet (CFNet), a novel approach that views the color fusion problem through the lens of image color inpainting. Built on the Vision Transformer architecture, CFNet captures global context and delivers high-fidelity outputs, seamlessly blending colors while preserving boundary integrity. Empirical studies on ImageNet and COCO datasets demonstrate CFNet's superiority over existing methods in maintaining color harmony and color fidelity. Robustness evaluations and user studies have further validated the effectiveness of CFNet. In conclusion, CFNet introduces an innovative approach to seamless, fine-grained color fusion, paving the way for advancements in the domain of fine-grained color editing. Code and pretrained models are available at our project page: https://yidong.pro/projects/cfnet",
    "checked": true,
    "id": "a5d4f8c467381d4aafe703f6f1dde1dd0f21119a",
    "semantic_title": "chromafusionnet (cfnet): natural fusion of fine-grained color editing",
    "citation_count": 0,
    "authors": [
      "Yi Dong",
      "Yuxi Wang",
      "Ruoxi Fan",
      "Wenqi Ouyang",
      "Zhiqi Shen",
      "Peiran Ren",
      "Xuansong Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27926": {
    "title": "HybridGait: A Benchmark for Spatial-Temporal Cloth-Changing Gait Recognition with Hybrid Explorations",
    "volume": "main",
    "abstract": "Existing gait recognition benchmarks mostly include minor clothing variations in the laboratory environments, but lack persistent changes in appearance over time and space. In this paper, we propose the first in-the-wild benchmark CCGait for cloth-changing gait recognition, which incorporates diverse clothing changes, indoor and outdoor scenes, and multi-modal statistics over 92 days. To further address the coupling effect of clothing and viewpoint variations, we propose a hybrid approach HybridGait that exploits both temporal dynamics and the projected 2D information of 3D human meshes. Specifically, we introduce a Canonical Alignment Spatial-Temporal Transformer (CA-STT) module to encode human joint position-aware features, and fully exploit 3D dense priors via a Silhouette-guided Deformation with 3D-2D Appearance Projection (SilD) strategy. Our contributions are twofold: we provide a challenging benchmark CCGait that captures realistic appearance changes over expanded time and space, and we propose a hybrid framework HybridGait that outperforms prior works on CCGait and Gait3D benchmarks. Our project page is available at https://github.com/HCVLab/HybridGait",
    "checked": true,
    "id": "e43e1d43f99b503ddb3450db87ee604cd893b1c1",
    "semantic_title": "hybridgait: a benchmark for spatial-temporal cloth-changing gait recognition with hybrid explorations",
    "citation_count": 2,
    "authors": [
      "Yilan Dong",
      "Chunlin Yu",
      "Ruiyang Ha",
      "Ye Shi",
      "Yuexin Ma",
      "Lan Xu",
      "Yanwei Fu",
      "Jingya Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27927": {
    "title": "PPEA-Depth: Progressive Parameter-Efficient Adaptation for Self-Supervised Monocular Depth Estimation",
    "volume": "main",
    "abstract": "Self-supervised monocular depth estimation is of significant importance with applications spanning across autonomous driving and robotics. However, the reliance on self-supervision introduces a strong static-scene assumption, thereby posing challenges in achieving optimal performance in dynamic scenes, which are prevalent in most real-world situations. To address these issues, we propose PPEA-Depth, a Progressive Parameter-Efficient Adaptation approach to transfer a pre-trained image model for self-supervised depth estimation. The training comprises two sequential stages: an initial phase trained on a dataset primarily composed of static scenes, succeeded by an expansion to more intricate datasets involving dynamic scenes. To facilitate this process, we design compact encoder and decoder adapters to enable parameter-efficient tuning, allowing the network to adapt effectively. They not only uphold generalized patterns from pre-trained image models but also retain knowledge gained from the preceding phase into the subsequent one. Extensive experiments demonstrate that PPEA-Depth achieves state-of-the-art performance on KITTI, CityScapes and DDAD datasets",
    "checked": true,
    "id": "413ae5b85284c9c0ef7fd8c7e3eb95408b49257c",
    "semantic_title": "ppea-depth: progressive parameter-efficient adaptation for self-supervised monocular depth estimation",
    "citation_count": 1,
    "authors": [
      "Yue-Jiang Dong",
      "Yuan-Chen Guo",
      "Ying-Tian Liu",
      "Fang-Lue Zhang",
      "Song-Hai  Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27928": {
    "title": "CycleVTON: A Cycle Mapping Framework for Parser-Free Virtual Try-On",
    "volume": "main",
    "abstract": "Image-based virtual try-on aims to transfer a target clothing onto a specific person. A significant challenge is arbitrarily matched clothing and person lack corresponding ground truth to supervised learning. A recent pioneering work leveraged an improved cycleGAN to enable one network to generate the desired image for another network during training. However, there is no difference in the result distribution before and after the clothing changes. Therefore, using two different networks is unnecessary and may even increase the difficulty of convergence. Furthermore, the introduced human parsing used to provide body structure information in the input also have a negative impact on the try-on result. How to employ a single network for supervised learning while eliminating human parsing? To tackle these issues, we present a Cycle mapping Virtual Try-On Network (CycleVTON), which can produce photo-realistic try-on results by using a cycle mapping framework without the parser. In particular, we introduce a flow constraint loss to achieve supervised learning of arbitrarily matched clothing and person as inputs to the deformer, thus naturally mimicking the interaction between clothing and the human body. Additionally, we design a skin generation strategy that can adapt to the shape of the target clothing by dynamically adjusting the skin region, i.e., by first removing and then filling skin areas. Extensive experiments conducted on challenging benchmarks demonstrate that our proposed method exhibits superior performance compared to state-of-the-art methods",
    "checked": true,
    "id": "edba8d4c8ba6235fff028110fd46e491c65f2943",
    "semantic_title": "cyclevton: a cycle mapping framework for parser-free virtual try-on",
    "citation_count": 0,
    "authors": [
      "Chenghu Du",
      "Junyin Wang",
      "Yi Rong",
      "Shuqing Liu",
      "Kai Liu",
      "Shengwu Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27929": {
    "title": "Arbitrary-Scale Point Cloud Upsampling by Voxel-Based Network with Latent Geometric-Consistent Learning",
    "volume": "main",
    "abstract": "Recently, arbitrary-scale point cloud upsampling mechanism became increasingly popular due to its efficiency and convenience for practical applications. To achieve this, most previous approaches formulate it as a problem of surface approximation and employ point-based networks to learn surface representations. However, learning surfaces from sparse point clouds is more challenging, and thus they often suffer from the low-fidelity geometry approximation. To address it, we propose an arbitrary-scale Point cloud Upsampling framework using Voxel-based Network (PU-VoxelNet). Thanks to the completeness and regularity inherited from the voxel representation, voxel-based networks are capable of providing predefined grid space to approximate 3D surface, and an arbitrary number of points can be reconstructed according to the predicted density distribution within each grid cell. However, we investigate the inaccurate grid sampling caused by imprecise density predictions. To address this issue, a density-guided grid resampling method is developed to generate high-fidelity points while effectively avoiding sampling outliers. Further, to improve the fine-grained details, we present an auxiliary training supervision to enforce the latent geometric consistency among local surface patches. Extensive experiments indicate the proposed approach outperforms the state-of-the-art approaches not only in terms of fixed upsampling rates but also for arbitrary-scale upsampling. The code is available at https://github.com/hikvision-research/3DVision",
    "checked": true,
    "id": "1309ec6ba3243296cd0e1d2a268c02c9a04a30a7",
    "semantic_title": "arbitrary-scale point cloud upsampling by voxel-based network with latent geometric-consistent learning",
    "citation_count": 0,
    "authors": [
      "Hang Du",
      "Xuejun Yan",
      "Jingjing Wang",
      "Di Xie",
      "Shiliang Pu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27930": {
    "title": "CDPNet: Cross-Modal Dual Phases Network for Point Cloud Completion",
    "volume": "main",
    "abstract": "Point cloud completion aims at completing shapes from their partial. Most existing methods utilized shape's priors information for point cloud completion, such as inputting the partial and getting the complete one through an encoder-decoder deep learning structure. However, it is very often to easily cause the loss of information in the generation process because of the invisibility of missing areas. Unlike most existing methods directly inferring the missing points using shape priors, we address it as a cross-modality task. We propose a new Cross-modal Dual Phases Network (CDPNet) for shape completion. Our key idea is that the global information of the shape is obtained from the extra single-view image, and the partial point clouds provide the geometric information. After that, the multi-modal features jointly guide the specific structural information. To learn the geometric details of the shape, we chose to use patches to preserve the local geometric feature. In this way, we can generate shapes with enough geometric details. Experimental results show that our method achieves state-of-the-art performance on point cloud completion",
    "checked": true,
    "id": "65e662b0fd2c35aad7f4945e02b0260f2e3fea0e",
    "semantic_title": "cdpnet: cross-modal dual phases network for point cloud completion",
    "citation_count": 2,
    "authors": [
      "Zhenjiang Du",
      "Jiale Dou",
      "Zhitao Liu ",
      "Jiwei Wei",
      "Guan Wang",
      "Ning Xie",
      "Yang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27931": {
    "title": "Tuning-Free Inversion-Enhanced Control for Consistent Image Editing",
    "volume": "main",
    "abstract": "Consistent editing of real images is a challenging task, as it requires performing non-rigid edits (e.g., changing postures) to the main objects in the input image without changing their identity or attributes. To guarantee consistent attributes, some existing methods fine-tune the entire model or the textual embedding for structural consistency, but they are time-consuming and fail to perform non-rigid edits. Other works are tuning-free, but their performances are weakened by the quality of Denoising Diffusion Implicit Model (DDIM) reconstruction, which often fails in real-world scenarios. In this paper, we present a novel approach called Tuning-free Inversion-enhanced Control (TIC), which directly correlates features from the inversion process with those from the sampling process to mitigate the inconsistency in DDIM reconstruction. Specifically, our method effectively obtains inversion features from the key and value features in the self-attention layers, and enhances the sampling process by these inversion features, thus achieving accurate reconstruction and content-consistent editing. To extend the applicability of our method to general editing scenarios, we also propose a mask-guided attention concatenation strategy that combines contents from both the inversion and the naive DDIM editing processes. Experiments show that the proposed method outperforms previous works in reconstruction and consistent editing, and produces impressive results in various settings",
    "checked": true,
    "id": "ed526b03334bfaa372f153e69f652eb736186895",
    "semantic_title": "tuning-free inversion-enhanced control for consistent image editing",
    "citation_count": 3,
    "authors": [
      "Xiaoyue Duan",
      "Shuhao Cui",
      "Guoliang Kang",
      "Baochang Zhang",
      "Zhengcong Fei",
      "Mingyuan Fan",
      "Junshi Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27932": {
    "title": "WeditGAN: Few-Shot Image Generation via Latent Space Relocation",
    "volume": "main",
    "abstract": "In few-shot image generation, directly training GAN models on just a handful of images faces the risk of overfitting. A popular solution is to transfer the models pretrained on large source domains to small target ones. In this work, we introduce WeditGAN, which realizes model transfer by editing the intermediate latent codes w in StyleGANs with learned constant offsets (delta w), discovering and constructing target latent spaces via simply relocating the distribution of source latent spaces. The established one-to-one mapping between latent spaces can naturally prevents mode collapse and overfitting. Besides, we also propose variants of WeditGAN to further enhance the relocation process by regularizing the direction or finetuning the intensity of delta w. Experiments on a collection of widely used source/target datasets manifest the capability of WeditGAN in generating realistic and diverse images, which is simple yet highly effective in the research area of few-shot image generation. Codes are available at https://github.com/Ldhlwh/WeditGAN",
    "checked": true,
    "id": "12d37b36d7504a7275800f86eeea0f2eab6aa1ca",
    "semantic_title": "weditgan: few-shot image generation via latent space relocation",
    "citation_count": 5,
    "authors": [
      "Yuxuan Duan",
      "Li Niu",
      "Yan Hong",
      "Liqing Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27933": {
    "title": "SkeletonGait: Gait Recognition Using Skeleton Maps",
    "volume": "main",
    "abstract": "The choice of the representations is essential for deep gait recognition methods. The binary silhouettes and skeletal coordinates are two dominant representations in recent literature, achieving remarkable advances in many scenarios. However, inherent challenges remain, in which silhouettes are not always guaranteed in unconstrained scenes, and structural cues have not been fully utilized from skeletons. In this paper, we introduce a novel skeletal gait representation named skeleton map, together with SkeletonGait, a skeleton-based method to exploit structural information from human skeleton maps. Specifically, the skeleton map represents the coordinates of human joints as a heatmap with Gaussian approximation, exhibiting a silhouette-like image devoid of exact body structure. Beyond achieving state-of-the-art performances over five popular gait datasets, more importantly, SkeletonGait uncovers novel insights about how important structural features are in describing gait and when they play a role. Furthermore, we propose a multi-branch architecture, named SkeletonGait++, to make use of complementary features from both skeletons and silhouettes. Experiments indicate that SkeletonGait++ outperforms existing state-of-the-art methods by a significant margin in various scenarios. For instance, it achieves an impressive rank-1 accuracy of over 85% on the challenging GREW dataset. The source code is available at https://github.com/ShiqiYu/OpenGait",
    "checked": true,
    "id": "b460fe50ab5f44f6c5dfca5c1a27415bce06b61d",
    "semantic_title": "skeletongait: gait recognition using skeleton maps",
    "citation_count": 2,
    "authors": [
      "Chao Fan",
      "Jingzhe Ma",
      "Dongyang Jin",
      "Chuanfu Shen",
      "Shiqi Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27934": {
    "title": "TDeLTA: A Light-Weight and Robust Table Detection Method Based on Learning Text Arrangement",
    "volume": "main",
    "abstract": "The diversity of tables makes table detection a great challenge, leading to existing models becoming more tedious and complex. Despite achieving high performance, they often overfit to the table style in training set, and suffer from significant performance degradation when encountering out-of-distribution tables in other domains. To tackle this problem, we start from the essence of the table, which is a set of text arranged in rows and columns. Based on this, we propose a novel, light-weighted and robust Table Detection method based on Learning Text Arrangement, namely TDeLTA. TDeLTA takes the text blocks as input, and then models the arrangement of them with a sequential encoder and an attention module. To locate the tables precisely, we design a text-classification task, classifying the text blocks into 4 categories according to their semantic roles in the tables. Experiments are conducted on both the text blocks parsed from PDF and extracted by open-source OCR tools, respectively. Compared to several state-of-the-art methods, TDeLTA achieves competitive results with only 3.1M model parameters on the large-scale public datasets. Moreover, when faced with the cross-domain data under the 0-shot setting, TDeLTA outperforms baselines by a large margin of nearly 7%, which shows the strong robustness and transferability of the proposed model",
    "checked": true,
    "id": "3a8c4f5b09788d537b0b7bb09037c5fa055317d2",
    "semantic_title": "tdelta: a light-weight and robust table detection method based on learning text arrangement",
    "citation_count": 0,
    "authors": [
      "Yang Fan",
      "Xiangping Wu",
      "Qingcai Chen",
      "Heng Li",
      "Yan Huang",
      "Zhixiang Cai",
      "Qitian Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27935": {
    "title": "Collaborative Tooth Motion Diffusion Model in Digital Orthodontics",
    "volume": "main",
    "abstract": "Tooth motion generation is an essential task in digital orthodontic treatment for precise and quick dental healthcare, which aims to generate the whole intermediate tooth motion process given the initial pathological and target ideal tooth alignments. Most prior works for multi-agent motion planning problems usually result in complex solutions. Moreover, the occlusal relationship between upper and lower teeth is often overlooked. In this paper, we propose a collaborative tooth motion diffusion model. The critical insight is to remodel the problem as a diffusion process. In this sense, we model the whole tooth motion distribution with a diffusion model and transform the planning problem into a sampling process from this distribution. We design a tooth latent representation to provide accurate conditional guides consisting of two key components: the tooth frame represents the position and posture, and the tooth latent shape code represents the geometric morphology. Subsequently, we present a collaborative diffusion model to learn the multi-tooth motion distribution based on inter-tooth and occlusal constraints, which are implemented by graph structure and new loss functions, respectively. Extensive qualitative and quantitative experiments demonstrate the superiority of our framework in the application of orthodontics compared with state-of-the-art methods",
    "checked": true,
    "id": "b425c1277355136c14af0954de5aeb5fbe0fc5dd",
    "semantic_title": "collaborative tooth motion diffusion model in digital orthodontics",
    "citation_count": 0,
    "authors": [
      "Yeying Fan",
      "Guangshun Wei",
      "Chen Wang",
      "Shaojie Zhuang",
      "Wenping Wang",
      "Yuanfeng Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27936": {
    "title": "Everything2Motion: Synchronizing Diverse Inputs via a Unified Framework for Human Motion Synthesis",
    "volume": "main",
    "abstract": "In the dynamic field of film and game development, the emergence of human motion synthesis methods has revolutionized avatar animation. Traditional methodologies, typically reliant on single modality inputs like text or audio, employ modality-specific model frameworks, posing challenges for unified model deployment and application. To address this, we propose Everything2Motion, a unified model framework. Everything2Motion consists of three key modules. The Input-Output Modality Modulation module tailors structures for specific multimodal inputs, eliminating the need for modality-specific frameworks. The Query-aware Autoencoder, based on the transformer encoder-decoder architecture, enables efficient latent motion generation. Lastly, the Prior Motion Distillation Decoder, a pretrained module, enhances the final skeleton sequence's naturalness and fluidity. Comprehensive experiments on several public datasets demonstrate the effectiveness of Everything2Motion, highlighting its potential for practical applications and setting a new benchmark in human motion synthesis",
    "checked": true,
    "id": "4680c093e354690536e841d302073c400a97184f",
    "semantic_title": "everything2motion: synchronizing diverse inputs via a unified framework for human motion synthesis",
    "citation_count": 0,
    "authors": [
      "Zhaoxin Fan",
      "Longbin Ji",
      "Pengxin Xu",
      "Fan Shen",
      "Kai Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27937": {
    "title": "Variance-Insensitive and Target-Preserving Mask Refinement for Interactive Image Segmentation",
    "volume": "main",
    "abstract": "Point-based interactive image segmentation can ease the burden of mask annotation in applications such as semantic segmentation and image editing. However, fully extracting the target mask with limited user inputs remains challenging. We introduce a novel method, Variance-Insensitive and Target-Preserving Mask Refinement to enhance segmentation quality with fewer user inputs. Regarding the last segmentation result as the initial mask, an iterative refinement process is commonly employed to continually enhance the initial mask. Nevertheless, conventional techniques suffer from sensitivity to the variance in the initial mask. To circumvent this problem, our proposed method incorporates a mask matching algorithm for ensuring consistent inferences from different types of initial masks. We also introduce a target-aware zooming algorithm to preserve object information during downsampling, balancing efficiency and accuracy. Experiments on GrabCut, Berkeley, SBD, and DAVIS datasets demonstrate our method's state-of-the-art performance in interactive image segmentation",
    "checked": true,
    "id": "3cb7f5d89f32ec0e9aaba2c986c8aa4cfda40f1a",
    "semantic_title": "variance-insensitive and target-preserving mask refinement for interactive image segmentation",
    "citation_count": 1,
    "authors": [
      "Chaowei Fang",
      "Ziyin Zhou",
      "Junye Chen",
      "Hanjing Su",
      "Qingyao Wu",
      "Guanbin Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27938": {
    "title": "Evaluate Geometry of Radiance Fields with Low-Frequency Color Prior",
    "volume": "main",
    "abstract": "A radiance field is an effective representation of 3D scenes, which has been widely adopted in novel-view synthesis and 3D reconstruction. It is still an open and challenging problem to evaluate the geometry, i.e., the density field, as the ground-truth is almost impossible to obtain. One alternative indirect solution is to transform the density field into a point-cloud and compute its Chamfer Distance with the scanned ground-truth. However, many widely-used datasets have no point-cloud ground-truth since the scanning process along with the equipment is expensive and complicated. To this end, we propose a novel metric, named Inverse Mean Residual Color (IMRC), which can evaluate the geometry only with the observation images. Our key insight is that the better the geometry, the lower-frequency the computed color field. From this insight, given a reconstructed density field and observation images, we design a closed-form method to approximate the color field with low-frequency spherical harmonics, and compute the inverse mean residual color. Then the higher the IMRC, the better the geometry. Qualitative and quantitative experimental results verify the effectiveness of our proposed IMRC metric. We also benchmark several state-of-the-art methods using IMRC to promote future related research. Our code is available at https://github.com/qihangGH/IMRC",
    "checked": true,
    "id": "564a21fc1c77dc8b5b401ce182ba1699ed8d9179",
    "semantic_title": "evaluate geometry of radiance fields with low-frequency color prior",
    "citation_count": 2,
    "authors": [
      "Qihang Fang",
      "Yafei Song",
      "Keqiang Li",
      "Li Shen",
      "Huaiyu Wu",
      "Gang Xiong",
      "Liefeng Bo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27939": {
    "title": "Simple Image-Level Classification Improves Open-Vocabulary Object Detection",
    "volume": "main",
    "abstract": "Open-Vocabulary Object Detection (OVOD) aims to detect novel objects beyond a given set of base categories on which the detection model is trained. Recent OVOD methods focus on adapting the image-level pre-trained vision-language models (VLMs), such as CLIP, to a region-level object detection task via, eg., region-level knowledge distillation, regional prompt learning, or region-text pre-training, to expand the detection vocabulary. These methods have demonstrated remarkable performance in recognizing regional visual concepts, but they are weak in exploiting the VLMs' powerful global scene understanding ability learned from the billion-scale image-level text descriptions. This limits their capability in detecting hard objects of small, blurred, or occluded appearance from novel/base categories, whose detection heavily relies on contextual information. To address this, we propose a novel approach, namely Simple Image-level Classification for Context-Aware Detection Scoring (SIC-CADS), to leverage the superior global knowledge yielded from CLIP for complementing the current OVOD models from a global perspective. The core of SIC-CADS is a multi-modal multi-label recognition (MLR) module that learns the object co-occurrence-based contextual information from CLIP to recognize all possible object categories in the scene. These image-level MLR scores can then be utilized to refine the instance-level detection scores of the current OVOD models in detecting those hard objects. This is verified by extensive empirical results on two popular benchmarks, OV-LVIS and OV-COCO, which show that SIC-CADS achieves significant and consistent improvement when combined with different types of OVOD models. Further, SIC-CADS also improves the cross-dataset generalization ability on Objects365 and OpenImages. Code is available at https://github.com/mala-lab/SIC-CADS",
    "checked": true,
    "id": "ad08b280acbdadfe7ea695479d6b75809aa1971f",
    "semantic_title": "simple image-level classification improves open-vocabulary object detection",
    "citation_count": 4,
    "authors": [
      "Ruohuan Fang",
      "Guansong Pang",
      "Xiao Bai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27940": {
    "title": "Self-Supervised Bird's Eye View Motion Prediction with Cross-Modality Signals",
    "volume": "main",
    "abstract": "Learning the dense bird's eye view (BEV) motion flow in a self-supervised manner is an emerging research for robotics and autonomous driving. Current self-supervised methods mainly rely on point correspondences between point clouds, which may introduce the problems of fake flow and inconsistency, hindering the model's ability to learn accurate and realistic motion. In this paper, we introduce a novel cross-modality self-supervised training framework that effectively addresses these issues by leveraging multi-modality data to obtain supervision signals. We design three innovative supervision signals to preserve the inherent properties of scene motion, including the masked Chamfer distance loss, the piecewise rigidity loss, and the temporal consistency loss. Through extensive experiments, we demonstrate that our proposed self-supervised framework outperforms all previous self-supervision methods for the motion prediction task",
    "checked": true,
    "id": "216507b805664f1678be185830c9add9d824ac04",
    "semantic_title": "self-supervised bird's eye view motion prediction with cross-modality signals",
    "citation_count": 1,
    "authors": [
      "Shaoheng Fang",
      "Zuhong Liu",
      "Mingyu Wang",
      "Chenxin Xu",
      "Yiqi Zhong",
      "Siheng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27941": {
    "title": "Fewer Steps, Better Performance: Efficient Cross-Modal Clip Trimming for Video Moment Retrieval Using Language",
    "volume": "main",
    "abstract": "Given an untrimmed video and a sentence query, video moment retrieval using language (VMR) aims to locate a target query-relevant moment. Since the untrimmed video is overlong, almost all existing VMR methods first sparsely down-sample each untrimmed video into multiple fixed-length video clips and then conduct multi-modal interactions with the query feature and expensive clip features for reasoning, which is infeasible for long real-world videos that span hours. Since the video is downsampled into fixed-length clips, some query-related frames may be filtered out, which will blur the specific boundary of the target moment, take the adjacent irrelevant frames as new boundaries, easily leading to cross-modal misalignment and introducing both boundary-bias and reasoning-bias. To this end, in this paper, we propose an efficient approach, SpotVMR, to trim the query-relevant clip. Besides, our proposed SpotVMR can serve as plug-and-play module, which achieves efficiency for state-of-the-art VMR methods while maintaining good retrieval performance. Especially, we first design a novel clip search model that learns to identify promising video regions to search conditioned on the language query. Then, we introduce a set of low-cost semantic indexing features to capture the context of objects and interactions that suggest where to search the query-relevant moment. Also, the distillation loss is utilized to address the optimization issues arising from end-to-end joint training of the clip selector and VMR model. Extensive experiments on three challenging datasets demonstrate its effectiveness",
    "checked": true,
    "id": "268533ed51433203062c44347a5d09502a8ac4bd",
    "semantic_title": "fewer steps, better performance: efficient cross-modal clip trimming for video moment retrieval using language",
    "citation_count": 1,
    "authors": [
      "Xiang Fang",
      "Daizong Liu",
      "Wanlong Fang",
      "Pan Zhou",
      "Zichuan Xu",
      "Wenzheng Xu",
      "Junyang Chen",
      "Renfu Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27942": {
    "title": "An Embedding-Unleashing Video Polyp Segmentation Framework via Region Linking and Scale Alignment",
    "volume": "main",
    "abstract": "Automatic polyp segmentation from colonoscopy videos is a critical task for the development of computer-aided screening and diagnosis systems. However, accurate and real-time video polyp segmentation (VPS) is a very challenging task due to low contrast between background and polyps and frame-to-frame dramatic variations in colonoscopy videos. We propose a novel embedding-unleashing framework consisting of a proposal-generative network (PGN) and an appearance-embedding network (AEN) to comprehensively address these challenges. Our framework, for the first time, models VPS as an appearance-level semantic embedding process to facilitate generate more global information to counteract background disturbances and dramatic variations. Specifically, PGN is a video segmentation network to obtain segmentation mask proposals, while AEN is a network we specially designed to produce appearance-level embedding semantics for PGN, thereby unleashing the capability of PGN in VPS. Our AEN consists of a cross-scale region linking (CRL) module and a cross-wise scale alignment (CSA) module. The former screens reliable background information against background disturbances by constructing linking of region semantics, while the latter performs the scale alignment to resist dramatic variations by modeling the center-perceived motion dependence with a cross-wise manner. We further introduce a parameter-free semantic interaction to embed the semantics of AEN into PGN to obtain the segmentation results. Extensive experiments on CVC-612 and SUN-SEG demonstrate that our approach achieves better performance than other state-of-the-art methods. Codes are available at https://github.com/zhixue-fang/EUVPS",
    "checked": true,
    "id": "a7384462247ae51af2d4911b2958585d6891022e",
    "semantic_title": "an embedding-unleashing video polyp segmentation framework via region linking and scale alignment",
    "citation_count": 1,
    "authors": [
      "Zhixue Fang",
      "Xinrong Guo",
      "Jingyin Lin",
      "Huisi Wu",
      "Jing Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27943": {
    "title": "Debiased Novel Category Discovering and Localization",
    "volume": "main",
    "abstract": "In recent years, object detection in deep learning has experienced rapid development. However, most existing object detection models perform well only on closed-set datasets, ignoring a large number of potential objects whose categories are not defined in the training set. These objects are often identified as background or incorrectly classified as pre-defined categories by the detectors. In this paper, we focus on the challenging problem of Novel Class Discovery and Localization (NCDL), aiming to train detectors that can detect the categories present in the training data, while also actively discover, localize, and cluster new categories. We analyze existing NCDL methods and identify the core issue: object detectors tend to be biased towards seen objects, and this leads to the neglect of unseen targets. To address this issue, we first propose an Debiased Region Mining (DRM) approach that combines class-agnostic Region Proposal Network (RPN) and class-aware RPN in a complementary manner. Additionally, we suggest to improve the representation network through semi-supervised contrastive learning by leveraging unlabeled data. Finally, we adopt a simple and efficient mini-batch K-means clustering method for novel class discovery. We conduct extensive experiments on the NCDL benchmark, and the results demonstrate that the proposed DRM approach significantly outperforms previous methods, establishing a new state-of-the-art",
    "checked": true,
    "id": "54d3cf13a1dab8e8386fce96b89287edc574bbe2",
    "semantic_title": "debiased novel category discovering and localization",
    "citation_count": 1,
    "authors": [
      "Juexiao Feng",
      "Yuhong Yang",
      "Yanchun Xie",
      "Yaqian Li",
      "Yandong Guo",
      "Yuchen Guo",
      "Yuwei He",
      "Liuyu Xiang",
      "Guiguang Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27944": {
    "title": "Interpretable3D: An Ad-Hoc Interpretable Classifier for 3D Point Clouds",
    "volume": "main",
    "abstract": "3D decision-critical tasks urgently require research on explanations to ensure system reliability and transparency. Extensive explanatory research has been conducted on 2D images, but there is a lack in the 3D field. Furthermore, the existing explanations for 3D models are post-hoc and can be misleading, as they separate explanations from the original model. To address these issues, we propose an ad-hoc interpretable classifier for 3D point clouds (i.e., Interpretable3D). As an intuitive case-based classifier, Interpretable3D can provide reliable ad-hoc explanations without any embarrassing nuances. It allows users to understand how queries are embedded within past observations in prototype sets. Interpretable3D has two iterative training steps: 1) updating one prototype with the mean of the embeddings within the same sub-class in Prototype Estimation, and 2) penalizing or rewarding the estimated prototypes in Prototype Optimization. The mean of embeddings has a clear statistical meaning, i.e., class sub-centers. Moreover, we update prototypes with their most similar observations in the last few epochs. Finally, Interpretable3D classifies new samples according to prototypes. We evaluate the performance of Interpretable3D on four popular point cloud models: DGCNN, PointNet2, PointMLP, and PointNeXt. Our Interpretable3D demonstrates comparable or superior performance compared to softmax-based black-box models in the tasks of 3D shape classification and part segmentation. Our code is released at: github.com/FengZicai/Interpretable3D",
    "checked": true,
    "id": "074a9cdd78cd9bac459ee4b3a9c4939db2857a09",
    "semantic_title": "interpretable3d: an ad-hoc interpretable classifier for 3d point clouds",
    "citation_count": 4,
    "authors": [
      "Tuo Feng",
      "Ruijie Quan",
      "Xiaohan Wang",
      "Wenguan Wang",
      "Yi Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27945": {
    "title": "Mimic: Speaking Style Disentanglement for Speech-Driven 3D Facial Animation",
    "volume": "main",
    "abstract": "Speech-driven 3D facial animation aims to synthesize vivid facial animations that accurately synchronize with speech and match the unique speaking style. However, existing works primarily focus on achieving precise lip synchronization while neglecting to model the subject-specific speaking style, often resulting in unrealistic facial animations. To the best of our knowledge, this work makes the first attempt to explore the coupled information between the speaking style and the semantic content in facial motions. Specifically, we introduce an innovative speaking style disentanglement method, which enables arbitrary-subject speaking style encoding and leads to a more realistic synthesis of speech-driven facial animations. Subsequently, we propose a novel framework called Mimic to learn disentangled representations of the speaking style and content from facial motions by building two latent spaces for style and content, respectively. Moreover, to facilitate disentangled representation learning, we introduce four well-designed constraints: an auxiliary style classifier, an auxiliary inverse classifier, a content contrastive loss, and a pair of latent cycle losses, which can effectively contribute to the construction of the identity-related style space and semantic-related content space. Extensive qualitative and quantitative experiments conducted on three publicly available datasets demonstrate that our approach outperforms state-of-the-art methods and is capable of capturing diverse speaking styles for speech-driven 3D facial animation. The source code and supplementary video are publicly available at: https://zeqing-wang.github.io/Mimic/",
    "checked": true,
    "id": "8956944d389a03650e3181ce607b5ba9ab209e89",
    "semantic_title": "mimic: speaking style disentanglement for speech-driven 3d facial animation",
    "citation_count": 2,
    "authors": [
      "Hui Fu",
      "Zeqing Wang",
      "Ke Gong",
      "Keze Wang",
      "Tianshui Chen",
      "Haojie Li",
      "Haifeng Zeng",
      "Wenxiong Kang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27946": {
    "title": "Fine-Grained Multi-View Hand Reconstruction Using Inverse Rendering",
    "volume": "main",
    "abstract": "Reconstructing high-fidelity hand models with intricate textures plays a crucial role in enhancing human-object interaction and advancing real-world applications. Despite the state-of-the-art methods excelling in texture generation and image rendering, they often face challenges in accurately capturing geometric details. Learning-based approaches usually offer better robustness and faster inference, which tend to produce smoother results and require substantial amounts of training data. To address these issues, we present a novel fine-grained multi-view hand mesh reconstruction method that leverages inverse rendering to restore hand poses and intricate details. Firstly, our approach predicts a parametric hand mesh model through Graph Convolutional Networks (GCN) based method from multi-view images. We further introduce a novel Hand Albedo and Mesh (HAM) optimization module to refine both the hand mesh and textures, which is capable of preserving the mesh topology. In addition, we suggest an effective mesh-based neural rendering scheme to simultaneously generate photo-realistic image and optimize mesh geometry by fusing the pre-trained rendering network with vertex features. We conduct the comprehensive experiments on InterHand2.6M, DeepHandMesh and dataset collected by ourself, whose promising results show that our proposed approach outperforms the state-of-the-art methods on both reconstruction accuracy and rendering quality. Code and dataset are publicly available at https://github.com/agnJason/FMHR",
    "checked": true,
    "id": "ffa25e8ac2981cccf8396c417c1d83cf8252baeb",
    "semantic_title": "fine-grained multi-view hand reconstruction using inverse rendering",
    "citation_count": 1,
    "authors": [
      "Qijun Gan",
      "Wentong Li",
      "Jinwei Ren",
      "Jianke Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27947": {
    "title": "Attacking Transformers with Feature Diversity Adversarial Perturbation",
    "volume": "main",
    "abstract": "Understanding the mechanisms behind Vision Transformer (ViT), particularly its vulnerability to adversarial perturbations, is crucial for addressing challenges in its real-world applications. Existing ViT adversarial attackers rely on labels to calculate the gradient for perturbation, and exhibit low transferability to other structures and tasks. In this paper, we present a label-free white-box attack approach for ViT-based models that exhibits strong transferability to various black-box models, including most ViT variants, CNNs, and MLPs, even for models developed for other modalities. Our inspiration comes from the feature collapse phenomenon in ViTs, where the critical attention mechanism overly depends on the low-frequency component of features, causing the features in middle-to-end layers to become increasingly similar and eventually collapse. We propose the feature diversity attacker to naturally accelerate this process and achieve remarkable performance and transferability",
    "checked": true,
    "id": "b7459d137cf43bfb06e9a74667a21ba285b94ce6",
    "semantic_title": "attacking transformers with feature diversity adversarial perturbation",
    "citation_count": 0,
    "authors": [
      "Chenxing Gao",
      "Hang Zhou",
      "Junqing Yu",
      "YuTeng Ye",
      "Jiale Cai",
      "Junle Wang",
      "Wei Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27948": {
    "title": "Leveraging Imagery Data with Spatial Point Prior for Weakly Semi-supervised 3D Object Detection",
    "volume": "main",
    "abstract": "Training high-accuracy 3D detectors necessitates massive labeled 3D annotations with 7 degree-of-freedom, which is laborious and time-consuming. Therefore, the form of point annotations is proposed to offer significant prospects for practical applications in 3D detection, which is not only more accessible and less expensive but also provides strong spatial information for object localization. In this paper, we empirically discover that it is non-trivial to merely adapt Point-DETR to its 3D form, encountering two main bottlenecks: 1) it fails to encode strong 3D prior into the model, and 2) it generates low-quality pseudo labels in distant regions due to the extreme sparsity of LiDAR points. To overcome these challenges, we introduce Point-DETR3D, a teacher-student framework for weakly semi-supervised 3D detection, designed to fully capitalize on point-wise supervision within a constrained instance-wise annotation budget. Different from Point-DETR which encodes 3D positional information solely through a point encoder, we propose an explicit positional query initialization strategy to enhance the positional prior. Considering the low quality of pseudo labels at distant regions produced by the teacher model, we enhance the detector's perception by incorporating dense imagery data through a novel Cross-Modal Deformable RoI Fusion (D-RoI). Moreover, an innovative point-guided self-supervised learning technique is proposed to allow for fully exploiting point priors, even in student models. Extensive experiments on representative nuScenes dataset demonstrate our Point-DETR3D obtains significant improvements compared to previous works. Notably, with only 5% of labeled data, Point-DETR3D achieves over 90% performance of its fully supervised counterpart",
    "checked": true,
    "id": "6f6721f408dee5f75939b0b9747c4d0def4d3223",
    "semantic_title": "leveraging imagery data with spatial point prior for weakly semi-supervised 3d object detection",
    "citation_count": 0,
    "authors": [
      "Hongzhi Gao",
      "Zheng Chen",
      "Zehui Chen",
      "Lin Chen",
      "Jiaming Liu",
      "Shanghang Zhang",
      "Feng Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27949": {
    "title": "Dual-Prior Augmented Decoding Network for Long Tail Distribution in HOI Detection",
    "volume": "main",
    "abstract": "Human object interaction detection aims at localizing human-object pairs and recognizing their interactions. Trapped by the long-tailed distribution of the data, existing HOI detection methods often have difficulty recognizing the tail categories. Many approaches try to improve the recognition of HOI tasks by utilizing external knowledge (e.g. pre-trained visual-language models). However, these approaches mainly utilize external knowledge at the HOI combination level and achieve limited improvement in the tail categories. In this paper, we propose a dual-prior augmented decoding network by decomposing the HOI task into two sub-tasks: human-object pair detection and interaction recognition. For each subtask, we leverage external knowledge to enhance the model's ability at a finer granularity. Specifically, we acquire the prior candidates from an external classifier and embed them to assist the subsequent decoding process. Thus, the long-tail problem is mitigated from a coarse-to-fine level with the corresponding external knowledge. Our approach outperforms existing state-of-the-art models in various settings and significantly boosts the performance on the tail HOI categories. The source code is available at https://github.com/PRIS-CV/DP-ADN",
    "checked": true,
    "id": "cbc05849bd04058e4aee09738dd73d9ad6621964",
    "semantic_title": "dual-prior augmented decoding network for long tail distribution in hoi detection",
    "citation_count": 0,
    "authors": [
      "Jiayi Gao",
      "Kongming Liang",
      "Tao Wei",
      "Wei Chen",
      "Zhanyu Ma",
      "Jun Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27950": {
    "title": "LAMM: Label Alignment for Multi-Modal Prompt Learning",
    "volume": "main",
    "abstract": "With the success of pre-trained visual-language (VL) models such as CLIP in visual representation tasks, transferring pre-trained models to downstream tasks has become a crucial paradigm. Recently, the prompt tuning paradigm, which draws inspiration from natural language processing (NLP), has made significant progress in VL field. However, preceding methods mainly focus on constructing prompt templates for text and visual inputs, neglecting the gap in class label representations between the VL models and downstream tasks. To address this challenge, we introduce an innovative label alignment method named \\textbf{LAMM}, which can dynamically adjust the category embeddings of downstream datasets through end-to-end training. Moreover, to achieve a more appropriate label distribution, we propose a hierarchical loss, encompassing the alignment of the parameter space, feature space, and logits space. We conduct experiments on 11 downstream vision datasets and demonstrate that our method significantly improves the performance of existing multi-modal prompt learning models in few-shot scenarios, exhibiting an average accuracy improvement of 2.31(\\%) compared to the state-of-the-art methods on 16 shots. Moreover, our methodology exhibits the preeminence in continual learning compared to other prompt tuning methods. Importantly, our method is synergistic with existing prompt tuning methods and can boost the performance on top of them. Our code and dataset will be publicly available at https://github.com/gaojingsheng/LAMM",
    "checked": true,
    "id": "166802fb539fafbf4be0d6956defd26d70ab2cfe",
    "semantic_title": "lamm: label alignment for multi-modal prompt learning",
    "citation_count": 2,
    "authors": [
      "Jingsheng Gao",
      "Jiacheng Ruan",
      "Suncheng Xiang",
      "Zefang Yu",
      "Ke Ji",
      "Mingye Xie",
      "Ting Liu",
      "Yuzhuo Fu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27951": {
    "title": "Frequency-Controlled Diffusion Model for Versatile Text-Guided Image-to-Image Translation",
    "volume": "main",
    "abstract": "Recently, text-to-image diffusion models have emerged as a powerful tool for image-to-image translation (I2I), allowing flexible image translation via user-provided text prompts. This paper proposes frequency-controlled diffusion model (FCDiffusion), an end-to-end diffusion-based framework contributing a novel solution to text-guided I2I from a frequency-domain perspective. At the heart of our framework is a feature-space frequency-domain filtering module based on Discrete Cosine Transform, which extracts image features carrying different DCT spectral bands to control the text-to-image generation process of the Latent Diffusion Model, realizing versatile I2I applications including style-guided content creation, image semantic manipulation, image scene translation, and image style translation. Different from related methods, FCDiffusion establishes a unified text-driven I2I framework suiting diverse I2I application scenarios simply by switching among different frequency control branches. The effectiveness and superiority of our method for text-guided I2I are demonstrated with extensive experiments both qualitatively and quantitatively. Our project is publicly available at: https://xianggao1102.github.io/FCDiffusion/",
    "checked": true,
    "id": "889ccbd40ee023aab59f9f376fbec79e2823d93d",
    "semantic_title": "frequency-controlled diffusion model for versatile text-guided image-to-image translation",
    "citation_count": 0,
    "authors": [
      "Xiang Gao",
      "Zhengbo Xu",
      "Junhan Zhao",
      "Jiaying Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27952": {
    "title": "A General Implicit Framework for Fast NeRF Composition and Rendering",
    "volume": "main",
    "abstract": "A variety of Neural Radiance Fields (NeRF) methods have recently achieved remarkable success in high render speed. However, current accelerating methods are specialized and incompatible with various implicit methods, preventing real-time composition over various types of NeRF works. Because NeRF relies on sampling along rays, it is possible to provide general guidance for acceleration. To that end, we propose a general implicit pipeline for composing NeRF objects quickly. Our method enables the casting of dynamic shadows within or between objects using analytical light sources while allowing multiple NeRF objects to be seamlessly placed and rendered together with any arbitrary rigid transformations. Mainly, our work introduces a new surface representation known as Neural Depth Fields (NeDF) that quickly determines the spatial relationship between objects by allowing direct intersection computation between rays and implicit surfaces. It leverages an intersection neural network to query NeRF for acceleration instead of depending on an explicit spatial structure.Our proposed method is the first to enable both the progressive and interactive composition of NeRF objects. Additionally, it also serves as a previewing plugin for a range of existing NeRF works",
    "checked": true,
    "id": "d0ab642f46a81b88bf7bad8af3c089e2a21b5241",
    "semantic_title": "a general implicit framework for fast nerf composition and rendering",
    "citation_count": 0,
    "authors": [
      "Xinyu Gao",
      "Ziyi Yang",
      "Yunlu Zhao",
      "Yuxiang Sun",
      "Xiaogang Jin",
      "Changqing Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27953": {
    "title": "Multi-Scene Generalized Trajectory Global Graph Solver with Composite Nodes for Multiple Object Tracking",
    "volume": "main",
    "abstract": "The global multi-object tracking (MOT) system can consider interaction, occlusion, and other ``visual blur'' scenarios to ensure effective object tracking in long videos. Among them, graph-based tracking-by-detection paradigms achieve surprising performance. However, their fully-connected nature poses storage space requirements that challenge algorithm handling long videos. Currently, commonly used methods are still generated trajectories by building one-forward associations across frames. Such matches produced under the guidance of first-order similarity information may not be optimal from a longer-time perspective. Moreover, they often lack an end-to-end scheme for correcting mismatches. This paper proposes the Composite Node Message Passing Network (CoNo-Link), a multi-scene generalized framework for modeling ultra-long frames information for association. CoNo-Link's solution is a low-storage overhead method for building constrained connected graphs. In addition to the previous method of treating objects as nodes, the network innovatively treats object trajectories as nodes for information interaction, improving the graph neural network's feature representation capability. Specifically, we formulate the graph-building problem as a top-k selection task for some reliable objects or trajectories. Our model can learn better predictions on longer-time scales by adding composite nodes. As a result, our method outperforms the state-of-the-art in several commonly used datasets",
    "checked": true,
    "id": "033c3db5906468afe360bd3897bfd72a989e5c34",
    "semantic_title": "multi-scene generalized trajectory global graph solver with composite nodes for multiple object tracking",
    "citation_count": 0,
    "authors": [
      "Yan Gao",
      "Haojun Xu",
      "Jie Li",
      "Nannan Wang",
      "Xinbo Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27954": {
    "title": "A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives",
    "volume": "main",
    "abstract": "Backdoor attacks pose serious security threats to deep neural networks (DNNs). Backdoored models make arbitrarily (targeted) incorrect predictions on inputs containing well-designed triggers, while behaving normally on clean inputs. Prior researches have explored the invisibility of backdoor triggers to enhance attack stealthiness. However, most of them only focus on the invisibility in the spatial domain, neglecting the generation of invisible triggers in the frequency domain. This limitation renders the generated poisoned images easily detectable by recent defense methods. To address this issue, we propose a DUal stealthy BAckdoor attack method named DUBA, which simultaneously considers the invisibility of triggers in both the spatial and frequency domains, to achieve desirable attack performance, while ensuring strong stealthiness. Specifically, we first use Wavelet Transform to embed the high-frequency information of the trigger image into the clean image to ensure attack effectiveness. Then, to attain strong stealthiness, we incorporate Fourier Transform and Cosine Transform to mix the poisoned image and clean image in the frequency domain. Moreover, DUBA adopts a novel attack strategy, training the model with weak triggers and attacking with strong triggers to further enhance attack performance and stealthiness. DUBA is evaluated extensively on four datasets against popular image classifiers, showing significant superiority over state-of-the-art backdoor attacks in attack success rate and stealthiness",
    "checked": true,
    "id": "0982a5b5e88e8ee4eee3758fbaf7f8a99a4ee4fe",
    "semantic_title": "a dual stealthy backdoor: from both spatial and frequency perspectives",
    "citation_count": 1,
    "authors": [
      "Yudong Gao",
      "Honglong Chen",
      "Peng Sun",
      "Junjian Li",
      "Anqing Zhang",
      "Zhibo Wang",
      "Weifeng Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27955": {
    "title": "SoftCLIP: Softer Cross-Modal Alignment Makes CLIP Stronger",
    "volume": "main",
    "abstract": "During the preceding biennium, vision-language pre-training has achieved noteworthy success on several downstream tasks. Nevertheless, acquiring high-quality image-text pairs, where the pairs are entirely exclusive of each other, remains a challenging task, and noise exists in the commonly used datasets. To address this issue, we propose SoftCLIP, a novel approach that relaxes the strict one-to-one constraint and achieves a soft cross-modal alignment by introducing a softened target, which is generated from the fine-grained intra-modal self-similarity. The intra-modal guidance is indicative to enable two pairs have some local similarities and model many-to-many relationships between the two modalities. Besides, since the positive still dominates in the softened target distribution, we disentangle the negatives in the distribution to further boost the relation alignment with the negatives in the cross-modal learning. Extensive experiments demonstrate the effectiveness of SoftCLIP. In particular, on ImageNet zero-shot classification task, using CC3M/CC12M as pre-training dataset, SoftCLIP brings a top-1 accuracy improvement of 6.8%/7.2% over the CLIP baseline",
    "checked": true,
    "id": "9df8e151aadbc3c4df81524f7bb6dee3256ea8dc",
    "semantic_title": "softclip: softer cross-modal alignment makes clip stronger",
    "citation_count": 19,
    "authors": [
      "Yuting Gao",
      "Jinfeng Liu",
      "Zihan Xu",
      "Tong Wu",
      "Enwei Zhang",
      "Ke Li",
      "Jie Yang",
      "Wei  Liu",
      "Xing Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27956": {
    "title": "Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions",
    "volume": "main",
    "abstract": "Non-native speakers with limited vocabulary often struggle to name specific objects despite being able to visualize them, e.g., people outside Australia searching for ‘numbats.' Further, users may want to search for such elusive objects with difficult-to-sketch interactions, e.g., \"numbat digging in the ground.\" In such common but complex situations, users desire a search interface that accepts composite multimodal queries comprising hand-drawn sketches of \"difficult-to-name but easy-to-draw\" objects and text describing \"difficult-to-sketch but easy-to-verbalize\" object's attributes or interaction with the scene. This novel problem statement distinctly differs from the previously well-researched TBIR (text-based image retrieval) and SBIR (sketch-based image retrieval) problems. To study this under-explored task, we curate a dataset, CSTBIR (Composite Sketch+Text Based Image Retrieval), consisting of ~2M queries and 108K natural scene images. Further, as a solution to this problem, we propose a pretrained multimodal transformer-based baseline, STNet (Sketch+Text Network), that uses a hand-drawn sketch to localize relevant objects in the natural scene image, and encodes the text and image to perform image retrieval. In addition to contrastive learning, we propose multiple training objectives that improve the performance of our model. Extensive experiments show that our proposed method outperforms several state-of-the-art retrieval methods for text-only, sketch-only, and composite query modalities. We make the dataset and code available at: https://vl2g.github.io/projects/cstbir",
    "checked": true,
    "id": "b2ebbd6ccec4e5de1791f0e1c3cd13332a2e668a",
    "semantic_title": "composite sketch+text queries for retrieving objects with elusive names and complex interactions",
    "citation_count": 0,
    "authors": [
      "Prajwal Gatti",
      "Kshitij Parikh",
      "Dhriti Prasanna Paul",
      "Manish Gupta",
      "Anand Mishra"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27957": {
    "title": "Neuromorphic Event Signal-Driven Network for Video De-raining",
    "volume": "main",
    "abstract": "Convolutional neural networks-based video de-raining methods commonly rely on dense intensity frames captured by CMOS sensors. However, the limited temporal resolution of these sensors hinders the capture of dynamic rainfall information, limiting further improvement in de-raining performance. This study aims to overcome this issue by incorporating the neuromorphic event signal into the video de-raining to enhance the dynamic information perception. Specifically, we first utilize the dynamic information from the event signal as prior knowledge, and integrate it into existing de-raining objectives to better constrain the solution space. We then design an optimization algorithm to solve the objective, and construct a de-raining network with CNNs as the backbone architecture using a modular strategy to mimic the optimization process. To further explore the temporal correlation of the event signal, we incorporate a spiking self-attention module into our network. By leveraging the low latency and high temporal resolution of the event signal, along with the spatial and temporal representation capabilities of convolutional and spiking neural networks, our model captures more accurate dynamic information and significantly improves de-raining performance. For example, our network achieves a 1.24dB improvement on the SynHeavy25 dataset compared to the previous state-of-the-art method, while utilizing only 39% of the parameters",
    "checked": true,
    "id": "81413d393a3d5dc2f1300b90b9b365b8710cb69d",
    "semantic_title": "neuromorphic event signal-driven network for video de-raining",
    "citation_count": 0,
    "authors": [
      "Chengjie Ge",
      "Xueyang Fu",
      "Peng He",
      "Kunyu Wang",
      "Chengzhi Cao",
      "Zheng-Jun Zha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27958": {
    "title": "Beyond Prototypes: Semantic Anchor Regularization for Better Representation Learning",
    "volume": "main",
    "abstract": "One of the ultimate goals of representation learning is to achieve compactness within a class and well-separability between classes. Many outstanding metric-based and prototype-based methods following the Expectation-Maximization paradigm, have been proposed for this objective. However, they inevitably introduce biases into the learning process, particularly with long-tail distributed training data. In this paper, we reveal that the class prototype is not necessarily to be derived from training features and propose a novel perspective to use pre-defined class anchors serving as feature centroid to unidirectionally guide feature learning. However, the pre-defined anchors may have a large semantic distance from the pixel features, which prevents them from being directly applied. To address this issue and generate feature centroid independent from feature learning, a simple yet effective Semantic Anchor Regularization (SAR) is proposed. SAR ensures the inter-class separability of semantic anchors in the semantic space by employing a classifier-aware auxiliary cross-entropy loss during training via disentanglement learning. By pulling the learned features to these semantic anchors, several advantages can be attained: 1) the intra-class compactness and naturally inter-class separability, 2) induced bias or errors from feature learning can be avoided, and 3) robustness to the long-tailed problem. The proposed SAR can be used in a plug-and-play manner in the existing models. Extensive experiments demonstrate that the SAR performs better than previous sophisticated prototype-based methods. The implementation is available at https://github.com/geyanqi/SAR",
    "checked": true,
    "id": "b30db6576795858f9618dd343677615f9e223d42",
    "semantic_title": "beyond prototypes: semantic anchor regularization for better representation learning",
    "citation_count": 3,
    "authors": [
      "Yanqi Ge",
      "Qiang Nie",
      "Ye Huang",
      "Yong Liu",
      "Chengjie Wang",
      "Feng Zheng",
      "Wen Li",
      "Lixin Duan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27959": {
    "title": "Learning Multi-Scale Video-Text Correspondence for Weakly Supervised Temporal Article Gronding",
    "volume": "main",
    "abstract": "Weakly Supervised temporal Article Grounding (WSAG) is a challenging and practical task in video understanding. Specifically, given a video and a relevant article, whose sentences are at different semantic scales, WSAG aims to localize corresponding video segments for all \"groundable\" sentences. Compared to other grounding tasks, e.g., localizing one target segment with respect to a given sentence query, WSAG confronts an essential obstacle rooted in the intricate multi-scale information inherent within both textual and visual modalities. Existing methods overlook the modeling and alignment of such structured information present in multi-scale video segments and hierarchical textual content. To this end, we propose a Multi-Scale Video-Text Correspondence Learning (MVTCL) framework, which enhances the grounding performance in complex scenes by modeling multi-scale semantic correspondence both within and between modalities. Specifically, MVTCL initially aggregates video content spanning distinct temporal scales and leverages hierarchical textual relationships in both temporal and semantic dimensions via a semantic calibration module. Then multi-scale contrastive learning module is introduced to generate more discriminative representations by selecting typical contexts and performing inter-video contrastive learning. Through the multi-scale semantic calibration architecture and supervision design, our method achieves new state-of-the-art performance on existing WSAG benchmarks",
    "checked": true,
    "id": "7d7c9e92ae6c234a5802e560c61bb461e26d0b99",
    "semantic_title": "learning multi-scale video-text correspondence for weakly supervised temporal article gronding",
    "citation_count": 0,
    "authors": [
      "Wenjia Geng",
      "Yong Liu",
      "Lei Chen",
      "Sujia Wang",
      "Jie Zhou",
      "Yansong Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27960": {
    "title": "PoseGen: Learning to Generate 3D Human Pose Dataset with NeRF",
    "volume": "main",
    "abstract": "This paper proposes an end-to-end framework for generating 3D human pose datasets using Neural Radiance Fields (NeRF). Public datasets generally have limited diversity in terms of human poses and camera viewpoints, largely due to the resource-intensive nature of collecting 3D human pose data. As a result, pose estimators trained on public datasets significantly underperform when applied to unseen out-of-distribution samples. Previous works proposed augmenting public datasets by generating 2D-3D pose pairs or rendering a large amount of random data. Such approaches either overlook image rendering or result in suboptimal datasets for pre-trained models. Here we propose PoseGen, which learns to generate a dataset (human 3D poses and images) with a feedback loss from a given pre-trained pose estimator. In contrast to prior art, our generated data is optimized to improve the robustness of the pre-trained model. The objective of PoseGen is to learn a distribution of data that maximizes the prediction error of a given pre-trained model. As the learned data distribution contains OOD samples of the pre-trained model, sampling data from such a distribution for further fine-tuning a pre-trained model improves the generalizability of the model. This is the first work that proposes NeRFs for 3D human data generation. NeRFs are data-driven and do not require 3D scans of humans. Therefore, using NeRF for data generation is a new direction for convenient user-specific data generation. Our extensive experiments show that the proposed PoseGen improves two baseline models (SPIN and HybrIK) on four datasets with an average 6% relative improvement",
    "checked": true,
    "id": "76c3a0c313615d8f157af42fe7ca2488a9fed85b",
    "semantic_title": "posegen: learning to generate 3d human pose dataset with nerf",
    "citation_count": 0,
    "authors": [
      "Mohsen Gholami",
      "Rabab Ward",
      "Z. Jane Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27961": {
    "title": "SDAC: A Multimodal Synthetic Dataset for Anomaly and Corner Case Detection in Autonomous Driving",
    "volume": "main",
    "abstract": "Nowadays, closed-set perception methods for autonomous driving perform well on datasets containing normal scenes. However, they still struggle to handle anomalies in the real world, such as unknown objects that have never been seen while training. The lack of public datasets to evaluate the model performance on anomaly and corner cases has hindered the development of reliable autonomous driving systems. Therefore, we propose a multimodal Synthetic Dataset for Anomaly and Corner case detection, called SDAC, which encompasses anomalies captured from multi-view cameras and the LiDAR sensor, providing a rich set of annotations for multiple mainstream perception tasks. SDAC is the first public dataset for autonomous driving that categorizes anomalies into object, scene, and scenario levels, allowing the evaluation under different anomalous conditions. Experiments show that closed-set models suffer significant performance drops on anomaly subsets in SDAC. Existing anomaly detection methods fail to achieve satisfactory performance, suggesting that anomaly detection remains a challenging problem. We anticipate that our SDAC dataset could foster the development of safe and reliable systems for autonomous driving",
    "checked": true,
    "id": "66adf0186306940efa4896b3f35fdeab205667e5",
    "semantic_title": "sdac: a multimodal synthetic dataset for anomaly and corner case detection in autonomous driving",
    "citation_count": 2,
    "authors": [
      "Lei Gong",
      "Yu Zhang",
      "Yingqing Xia",
      "Yanyong Zhang",
      "Jianmin Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27962": {
    "title": "ContactGen: Contact-Guided Interactive 3D Human Generation for Partners",
    "volume": "main",
    "abstract": "Among various interactions between humans, such as eye contact and gestures, physical interactions by contact can act as an essential moment in understanding human behaviors. Inspired by this fact, given a 3D partner human with the desired interaction label, we introduce a new task of 3D human generation in terms of physical contact. Unlike previous works of interacting with static objects or scenes, a given partner human can have diverse poses and different contact regions according to the type of interaction. To handle this challenge, we propose a novel method of generating interactive 3D humans for a given partner human based on a guided diffusion framework (ContactGen in short). Specifically, we newly present a contact prediction module that adaptively estimates potential contact regions between two input humans according to the interaction label. Using the estimated potential contact regions as complementary guidances, we dynamically enforce ContactGen to generate interactive 3D humans for a given partner human within a guided diffusion model. We demonstrate ContactGen on the CHI3D dataset, where our method generates physically plausible and diverse poses compared to comparison methods",
    "checked": true,
    "id": "8e3069a48c28f30a4dfd15c0f4798d425703e4e9",
    "semantic_title": "contactgen: contact-guided interactive 3d human generation for partners",
    "citation_count": 1,
    "authors": [
      "Dongjun Gu",
      "Jaehyeok Shim",
      "Jaehoon Jang",
      "Changwoo Kang",
      "Kyungdon Joo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27963": {
    "title": "AnomalyGPT: Detecting Industrial Anomalies Using Large Vision-Language Models",
    "volume": "main",
    "abstract": "Large Vision-Language Models (LVLMs) such as MiniGPT-4 and LLaVA have demonstrated the capability of understanding images and achieved remarkable performance in various visual tasks. Despite their strong abilities in recognizing common objects due to extensive training datasets, they lack specific domain knowledge and have a weaker understanding of localized details within objects, which hinders their effectiveness in the Industrial Anomaly Detection (IAD) task. On the other hand, most existing IAD methods only provide anomaly scores and necessitate the manual setting of thresholds to distinguish between normal and abnormal samples, which restricts their practical implementation. In this paper, we explore the utilization of LVLM to address the IAD problem and propose AnomalyGPT, a novel IAD approach based on LVLM. We generate training data by simulating anomalous images and producing corresponding textual descriptions for each image. We also employ an image decoder to provide fine-grained semantic and design a prompt learner to fine-tune the LVLM using prompt embeddings. Our AnomalyGPT eliminates the need for manual threshold adjustments, thus directly assesses the presence and locations of anomalies. Additionally, AnomalyGPT supports multi-turn dialogues and exhibits impressive few-shot in-context learning capabilities. With only one normal shot, AnomalyGPT achieves the state-of-the-art performance with an accuracy of 86.1%, an image-level AUC of 94.1%, and a pixel-level AUC of 95.3% on the MVTec-AD dataset",
    "checked": true,
    "id": "f2ec0182c6646d3128afa5100f37d9de7b533463",
    "semantic_title": "anomalygpt: detecting industrial anomalies using large vision-language models",
    "citation_count": 24,
    "authors": [
      "Zhaopeng Gu",
      "Bingke Zhu",
      "Guibo Zhu",
      "Yingying Chen",
      "Ming Tang",
      "Jinqiao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27964": {
    "title": "SeqRank: Sequential Ranking of Salient Objects",
    "volume": "main",
    "abstract": "Salient Object Ranking (SOR) is the process of predicting the order of an observer's attention to objects when viewing a complex scene. Existing SOR methods primarily focus on ranking various scene objects simultaneously by exploring their spatial and semantic properties. However, their solutions of simultaneously ranking all salient objects do not align with human viewing behavior, and may result in incorrect attention shift predictions. We observe that humans view a scene through a sequential and continuous process involving a cycle of foveating to objects of interest with our foveal vision while using peripheral vision to prepare for the next fixation location. For instance, when we see a flying kite, our foveal vision captures the kite itself, while our peripheral vision can help us locate the person controlling it such that we can smoothly divert our attention to it next. By repeatedly carrying out this cycle, we can gain a thorough understanding of the entire scene. Based on this observation, we propose to model the dynamic interplay between foveal and peripheral vision to predict human attention shifts sequentially. To this end, we propose a novel SOR model, SeqRank, which reproduces foveal vision to extract high-acuity visual features for accurate salient instance segmentation while also modeling peripheral vision to select the object that is likely to grab the viewer's attention next. By incorporating both types of vision, our model can mimic human viewing behavior better and provide a more faithful ranking among various scene objects. Most notably, our model improves the SA-SOR/MAE scores by +6.1%/-13.0% on IRSR, compared with the state-of-the-art. Extensive experiments show the superior performance of our model on the SOR benchmarks. Code is available at https://github.com/guanhuankang/SeqRank",
    "checked": true,
    "id": "a9cd7d9e17b14697733e55959c7e56b28a67b831",
    "semantic_title": "seqrank: sequential ranking of salient objects",
    "citation_count": 0,
    "authors": [
      "Huankang Guan",
      "Rynson W.H. Lau"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27965": {
    "title": "Knowledge-Aware Neuron Interpretation for Scene Classification",
    "volume": "main",
    "abstract": "Although neural models have achieved remarkable performance, they still encounter doubts due to the intransparency. To this end, model prediction explanation is attracting more and more attentions. However, current methods rarely incorporate external knowledge and still suffer from three limitations: (1) Neglecting concept completeness. Merely selecting concepts may not sufficient for prediction. (2) Lacking concept fusion. Failure to merge semantically-equivalent concepts. (3) Difficult in manipulating model behavior. Lack of verification for explanation on original model. To address these issues, we propose a novel knowledge-aware neuron interpretation framework to explain model predictions for image scene classification. Specifically, for concept completeness, we present core concepts of a scene based on knowledge graph, ConceptNet, to gauge the completeness of concepts. Our method, incorporating complete concepts, effectively provides better prediction explanations compared to baselines. Furthermore, for concept fusion, we introduce a knowledge graph-based method known as Concept Filtering, which produces over 23% point gain on neuron behaviors for neuron interpretation. At last, we propose Model Manipulation, which aims to study whether the core concepts based on ConceptNet could be employed to manipulate model behavior. The results show that core concepts can effectively improve the performance of original model by over 26%",
    "checked": true,
    "id": "e67bc90687a8cb1140af4c1666c797ef3b6f5a20",
    "semantic_title": "knowledge-aware neuron interpretation for scene classification",
    "citation_count": 0,
    "authors": [
      "Yong Guan",
      "Freddy Lécué",
      "Jiaoyan Chen",
      "Ru Li",
      "Jeff Z. Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27966": {
    "title": "Self-Supervised Representation Learning with Meta Comprehensive Regularization",
    "volume": "main",
    "abstract": "Self-Supervised Learning (SSL) methods harness the concept of semantic invariance by utilizing data augmentation strategies to produce similar representations for different deformations of the same input. Essentially, the model captures the shared information among multiple augmented views of samples, while disregarding the non-shared information that may be beneficial for downstream tasks. To address this issue, we introduce a module called CompMod with Meta Comprehensive Regularization (MCR), embedded into existing self-supervised frameworks, to make the learned representations more comprehensive. Specifically, we update our proposed model through a bi-level optimization mechanism, enabling it to capture comprehensive features. Additionally, guided by the constrained extraction of features using maximum entropy coding, the self-supervised learning model learns more comprehensive features on top of learning consistent features. In addition, we provide theoretical support for our proposed method from information theory and causal counterfactual perspective. Experimental results show that our method achieves significant improvement in classification, object detection and semantic segmentation tasks on multiple benchmark datasets",
    "checked": true,
    "id": "64826ea91cb06cb27f03c3b6eb334e0a2b5efd3b",
    "semantic_title": "self-supervised representation learning with meta comprehensive regularization",
    "citation_count": 2,
    "authors": [
      "Huijie Guo",
      "Ying Ba",
      "Jie Hu",
      "Lingyu Si",
      "Wenwen Qiang",
      "Lei Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27967": {
    "title": "Graph Context Transformation Learning for Progressive Correspondence Pruning",
    "volume": "main",
    "abstract": "Most of existing correspondence pruning methods only concentrate on gathering the context information as much as possible while neglecting effective ways to utilize such information. In order to tackle this dilemma, in this paper we propose Graph Context Transformation Network (GCT-Net) enhancing context information to conduct consensus guidance for progressive correspondence pruning. Specifically, we design the Graph Context Enhance Transformer which first generates the graph network and then transforms it into multi-branch graph contexts. Moreover, it employs self-attention and cross-attention to magnify characteristics of each graph context for emphasizing the unique as well as shared essential information. To further apply the recalibrated graph contexts to the global domain, we propose the Graph Context Guidance Transformer. This module adopts a confident-based sampling strategy to temporarily screen high-confidence vertices for guiding accurate classification by searching global consensus between screened vertices and remaining ones. The extensive experimental results on outlier removal and relative pose estimation clearly demonstrate the superior performance of GCT-Net compared to state-of-the-art methods across outdoor and indoor datasets",
    "checked": true,
    "id": "4f7d087ec9c1cb13cdc060635219909ad0595e71",
    "semantic_title": "graph context transformation learning for progressive correspondence pruning",
    "citation_count": 1,
    "authors": [
      "Junwen Guo",
      "Guobao Xiao",
      "Shiping Wang",
      "Jun Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27968": {
    "title": "Depth-Guided Robust and Fast Point Cloud Fusion NeRF for Sparse Input Views",
    "volume": "main",
    "abstract": "Novel-view synthesis with sparse input views is important for real-world applications like AR/VR and autonomous driving. Recent methods have integrated depth information into NeRFs for sparse input synthesis, leveraging depth prior for geometric and spatial understanding. However, most existing works tend to overlook inaccuracies within depth maps and have low time efficiency. To address these issues, we propose a depth-guided robust and fast point cloud fusion NeRF for sparse inputs. We perceive radiance fields as an explicit voxel grid of features. A point cloud is constructed for each input view, characterized within the voxel grid using matrices and vectors. We accumulate the point cloud of each input view to construct the fused point cloud of the entire scene. Each voxel determines its density and appearance by referring to the point cloud of the entire scene. Through point cloud fusion and voxel grid fine-tuning, inaccuracies in depth values are refined or substituted by those from other views. Moreover, our method can achieve faster reconstruction and greater compactness through effective vector-matrix decomposition. Experimental results underline the superior performance and time efficiency of our approach compared to state-of-the-art baselines",
    "checked": true,
    "id": "736352670e479f57ad1b352dbd4901093e1be6f3",
    "semantic_title": "depth-guided robust and fast point cloud fusion nerf for sparse input views",
    "citation_count": 1,
    "authors": [
      "Shuai Guo",
      "Qiuwen Wang",
      "Yijie Gao",
      "Rong Xie",
      "Li Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27969": {
    "title": "Improving Panoptic Narrative Grounding by Harnessing Semantic Relationships and Visual Confirmation",
    "volume": "main",
    "abstract": "Recent advancements in single-stage Panoptic Narrative Grounding (PNG) have demonstrated significant potential. These methods predict pixel-level masks by directly matching pixels and phrases. However, they often neglect the modeling of semantic and visual relationships between phrase-level instances, limiting their ability for complex multi-modal reasoning in PNG. To tackle this issue, we propose XPNG, a \"differentiation-refinement-localization\" reasoning paradigm for accurately locating instances or regions. In XPNG, we introduce a Semantic Context Convolution (SCC) module to leverage semantic priors for generating distinctive features. This well-crafted module employs a combination of dynamic channel-wise convolution and pixel-wise convolution to embed semantic information and establish inter-object relationships guided by semantics. Subsequently, we propose a Visual Context Verification (VCV) module to provide visual cues, eliminating potential space biases introduced by semantics and further refining the visual features generated by the previous module. Extensive experiments on PNG benchmark datasets reveal that our approach achieves state-of-the-art performance, significantly outperforming existing methods by a considerable margin and yielding a 3.9-point improvement in overall metrics. Our codes and results are available at our project webpage: https://github.com/TianyuGoGO/XPNG",
    "checked": true,
    "id": "aa50b841a5553a3ab81a816653b299f948538118",
    "semantic_title": "improving panoptic narrative grounding by harnessing semantic relationships and visual confirmation",
    "citation_count": 2,
    "authors": [
      "Tianyu Guo",
      "Haowei Wang",
      "Yiwei Ma",
      "Jiayi Ji",
      "Xiaoshuai Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27970": {
    "title": "Learning to Manipulate Artistic Images",
    "volume": "main",
    "abstract": "Recent advancement in computer vision has significantly lowered the barriers to artistic creation. Exemplar-based image translation methods have attracted much attention due to flexibility and controllability. However, these methods hold assumptions regarding semantics or require semantic information as the input, while accurate semantics is not easy to obtain in artistic images. Besides, these methods suffer from cross-domain artifacts due to training data prior and generate imprecise structure due to feature compression in the spatial domain. In this paper, we propose an arbitrary Style Image Manipulation Network (SIM-Net), which leverages semantic-free information as guidance and a region transportation strategy in a self-supervised manner for image generation. Our method balances computational efficiency and high resolution to a certain extent. Moreover, our method facilitates zero-shot style image manipulation. Both qualitative and quantitative experiments demonstrate the superiority of our method over state-of-the-art methods.Code is available at https://github.com/SnailForce/SIM-Net",
    "checked": true,
    "id": "18ea6cb23b926073408827fc895c3d4971ecd1a5",
    "semantic_title": "learning to manipulate artistic images",
    "citation_count": 0,
    "authors": [
      "Wei Guo",
      "Yuqi Zhang",
      "De Ma",
      "Qian Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27971": {
    "title": "PICNN: A Pathway towards Interpretable Convolutional Neural Networks",
    "volume": "main",
    "abstract": "Convolutional Neural Networks (CNNs) have exhibited great performance in discriminative feature learning for complex visual tasks. Besides discrimination power, interpretability is another important yet under-explored property for CNNs. One difficulty in the CNN interpretability is that filters and image classes are entangled. In this paper, we introduce a novel pathway to alleviate the entanglement between filters and image classes. The proposed pathway groups the filters in a late conv-layer of CNN into class-specific clusters. Clusters and classes are in a one-to-one relationship. Specifically, we use the Bernoulli sampling to generate the filter-cluster assignment matrix from a learnable filter-class correspondence matrix. To enable end-to-end optimization, we develop a novel reparameterization trick for handling the non-differentiable Bernoulli sampling. We evaluate the effectiveness of our method on ten widely used network architectures (including nine CNNs and a ViT) and five benchmark datasets. Experimental results have demonstrated that our method PICNN (the combination of standard CNNs with our proposed pathway) exhibits greater interpretability than standard CNNs while achieving higher or comparable discrimination power",
    "checked": true,
    "id": "5f924cc5c719b87d41733a692cc15ffeaccbf7f5",
    "semantic_title": "picnn: a pathway towards interpretable convolutional neural networks",
    "citation_count": 0,
    "authors": [
      "Wengang Guo",
      "Jiayi Yang",
      "Huilin Yin",
      "Qijun Chen",
      "Wei Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27972": {
    "title": "GSN: Generalisable Segmentation in Neural Radiance Field",
    "volume": "main",
    "abstract": "Traditional Radiance Field (RF) representations capture details of a specific scene and must be trained afresh on each scene. Semantic feature fields have been added to RFs to facilitate several segmentation tasks. Generalised RF representations learn the principles of view interpolation. A generalised RF can render new views of an unknown and untrained scene, given a few views. We present a way to distil feature fields into the generalised GNT representation. Our GSN representation generates new views of unseen scenes on the fly along with consistent, per-pixel semantic features. This enables multi-view segmentation of arbitrary new scenes. We show different semantic features being distilled into generalised RFs. Our multi-view segmentation results are on par with methods that use traditional RFs. GSN closes the gap between standard and generalisable RF methods significantly. Project Page: https://vinayak-vg.github.io/GSN/",
    "checked": true,
    "id": "ffa2b13214b2e5a2caaa1cdbfd70f941777677f9",
    "semantic_title": "gsn: generalisable segmentation in neural radiance field",
    "citation_count": 1,
    "authors": [
      "Vinayak Gupta",
      "Rahul Goel",
      "Sirikonda Dhawal",
      "P. J.  Narayanan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27973": {
    "title": "AMD: Autoregressive Motion Diffusion",
    "volume": "main",
    "abstract": "Human motion generation aims to produce plausible human motion sequences according to various conditional inputs, such as text or audio. Despite the feasibility of existing methods in generating motion based on short prompts and simple motion patterns, they encounter difficulties when dealing with long prompts or complex motions. The challenges are two-fold: 1) the scarcity of human motion-captured data for long prompts and complex motions. 2) the high diversity of human motions in the temporal domain and the substantial divergence of distributions from conditional modalities, leading to a many-to-many mapping problem when generating motion with complex and long texts. In this work, we address these gaps by 1) elaborating the first dataset pairing long textual descriptions and 3D complex motions (HumanLong3D), and 2) proposing an autoregressive motion diffusion model (AMD). Specifically, AMD integrates the text prompt at the current timestep with the text prompt and action sequences at the previous timestep as conditional information to predict the current action sequences in an iterative manner. Furthermore, we present its generalization for X-to-Motion with \"No Modality Left Behind\", enabling for the first time the generation of high-definition and high-fidelity human motions based on user-defined modality input",
    "checked": true,
    "id": "50656eea23a65a716315ba88a0f741966d798d5e",
    "semantic_title": "amd: autoregressive motion diffusion",
    "citation_count": 8,
    "authors": [
      "Bo Han",
      "Hao Peng",
      "Minjing Dong",
      "Yi Ren",
      "Yixuan Shen",
      "Chang Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27974": {
    "title": "HuTuMotion: Human-Tuned Navigation of Latent Motion Diffusion Models with Minimal Feedback",
    "volume": "main",
    "abstract": "We introduce HuTuMotion, an innovative approach for generating natural human motions that navigates latent motion diffusion models by leveraging few-shot human feedback. Unlike existing approaches that sample latent variables from a standard normal prior distribution, our method adapts the prior distribution to better suit the characteristics of the data, as indicated by human feedback, thus enhancing the quality of motion generation. Furthermore, our findings reveal that utilizing few-shot feedback can yield performance levels on par with those attained through extensive human feedback. This discovery emphasizes the potential and efficiency of incorporating few-shot human-guided optimization within latent diffusion models for personalized and style-aware human motion generation applications. The experimental results show the significantly superior performance of our method over existing state-of-the-art approaches",
    "checked": true,
    "id": "44d319e3ecd0a5949a4b7c9c5de794f28f5aa7e4",
    "semantic_title": "hutumotion: human-tuned navigation of latent motion diffusion models with minimal feedback",
    "citation_count": 1,
    "authors": [
      "Gaoge Han",
      "Shaoli Huang",
      "Mingming Gong",
      "Jinglei Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27975": {
    "title": "MA-Net: Rethinking Neural Unit in the Light of Astrocytes",
    "volume": "main",
    "abstract": "The artificial neuron (N-N) model-based networks have accomplished extraordinary success for various vision tasks. However, as a simplification of the mammal neuron model, their structure is locked during training, resulting in overfitting and over-parameters. The astrocyte, newly explored by biologists, can adaptively modulate neuronal communication by inserting itself between neurons. The communication, between the astrocyte and neuron, is bidirectionally and shows the potential to alleviate issues raised by unidirectional communication in the N-N model. In this paper, we first elaborate on the artificial Multi-Astrocyte-Neuron (MA-N) model, which enriches the functionality of the artificial neuron model. Our MA-N model is formulated at both astrocyte- and neuron-level that mimics the bidirectional communication with temporal and joint mechanisms. Then, we construct the MA-Net network with the MA-N model, whose neural connections can be continuously and adaptively modulated during training. Experiments show that our MA-Net advances new state-of-the-art on multiple tasks while significantly reducing its parameters by connection optimization",
    "checked": true,
    "id": "f5af906b66fadd38d0ebd2c46321d2fbebbef776",
    "semantic_title": "ma-net: rethinking neural unit in the light of astrocytes",
    "citation_count": 0,
    "authors": [
      "Mengqiao Han",
      "Liyuan Pan",
      "Xiabi Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27976": {
    "title": "Dual-Perspective Knowledge Enrichment for Semi-supervised 3D Object Detection",
    "volume": "main",
    "abstract": "Semi-supervised 3D object detection is a promising yet under-explored direction to reduce data annotation costs, especially for cluttered indoor scenes. A few prior works, such as SESS and 3DIoUMatch, attempt to solve this task by utilizing a teacher model to generate pseudo-labels for unlabeled samples. However, the availability of unlabeled samples in the 3D domain is relatively limited compared to its 2D counterpart due to the greater effort required to collect 3D data. Moreover, the loose consistency regularization in SESS and restricted pseudo-label selection strategy in 3DIoUMatch lead to either low-quality supervision or a limited amount of pseudo labels. To address these issues, we present a novel Dual-Perspective Knowledge Enrichment approach named DPKE for semi-supervised 3D object detection. Our DPKE enriches the knowledge of limited training data, particularly unlabeled data, from two perspectives: data-perspective and feature-perspective. Specifically, from the data-perspective, we propose a class-probabilistic data augmentation method that augments the input data with additional instances based on the varying distribution of class probabilities. Our DPKE achieves feature-perspective knowledge enrichment by designing a geometry-aware feature matching method that regularizes feature-level similarity between object proposals from the student and teacher models. Extensive experiments on the two benchmark datasets demonstrate that our DPKE achieves superior performance over existing state-of-the-art approaches under various label ratio conditions. The source code and models will be made available to the public",
    "checked": true,
    "id": "443797f8dff272e35838567a366ee33859d601a3",
    "semantic_title": "dual-perspective knowledge enrichment for semi-supervised 3d object detection",
    "citation_count": 0,
    "authors": [
      "Yucheng Han",
      "Na Zhao",
      "Weiling Chen",
      "Keng Teck Ma",
      "Hanwang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27977": {
    "title": "Exploiting the Social-Like Prior in Transformer for Visual Reasoning",
    "volume": "main",
    "abstract": "Benefiting from instrumental global dependency modeling of self-attention (SA), transformer-based approaches have become the pivotal choices for numerous downstream visual reasoning tasks, such as visual question answering (VQA) and referring expression comprehension (REC). However, some studies have recently suggested that SA tends to suffer from rank collapse thereby inevitably leads to representation degradation as the transformer layer goes deeper. Inspired by social network theory, we attempt to make an analogy between social behavior and regional information interaction in SA, and harness two crucial notions of structural hole and degree centrality in social network to explore the possible optimization towards SA learning, which naturally deduces two plug-and-play social-like modules. Based on structural hole, the former module allows to make information interaction in SA more structured, which effectively avoids redundant information aggregation and global feature homogenization for better rank remedy, followed by latter module to comprehensively characterize and refine the representation discrimination via considering degree centrality of regions and transitivity of relations. Without bells and whistles, our model outperforms a bunch of baselines by a noticeable margin when considering our social-like prior on five benchmarks in VQA and REC tasks, and a series of explanatory results are showcased to sufficiently reveal the social-like behaviors in SA",
    "checked": true,
    "id": "0eeedd5c5ad085b51dfaffa7386ba7cb539bbf4e",
    "semantic_title": "exploiting the social-like prior in transformer for visual reasoning",
    "citation_count": 0,
    "authors": [
      "Yudong Han",
      "Yupeng Hu",
      "Xuemeng Song",
      "Haoyu Tang",
      "Mingzhu Xu",
      "Liqiang Nie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27978": {
    "title": "Improving Audio-Visual Segmentation with Bidirectional Generation",
    "volume": "main",
    "abstract": "The aim of audio-visual segmentation (AVS) is to precisely differentiate audible objects within videos down to the pixel level. Traditional approaches often tackle this challenge by combining information from various modalities, where the contribution of each modality is implicitly or explicitly modeled. Nevertheless, the interconnections between different modalities tend to be overlooked in audio-visual modeling. In this paper, inspired by the human ability to mentally simulate the sound of an object and its visual appearance, we introduce a bidirectional generation framework. This framework establishes robust correlations between an object's visual characteristics and its associated sound, thereby enhancing the performance of AVS. To achieve this, we employ a visual-to-audio projection component that reconstructs audio features from object segmentation masks and minimizes reconstruction errors. Moreover, recognizing that many sounds are linked to object movements, we introduce an implicit volumetric motion estimation module to handle temporal dynamics that may be challenging to capture using conventional optical flow methods. To showcase the effectiveness of our approach, we conduct comprehensive experiments and analyses on the widely recognized AVSBench benchmark. As a result, we establish a new state-of-the-art performance level in the AVS benchmark, particularly excelling in the challenging MS3 subset which involves segmenting multiple sound sources. Code is released in: https://github.com/OpenNLPLab/AVS-bidirectional",
    "checked": true,
    "id": "d782a43e36f2cd3c7f633c12251928219454ed95",
    "semantic_title": "improving audio-visual segmentation with bidirectional generation",
    "citation_count": 14,
    "authors": [
      "Dawei Hao",
      "Yuxin Mao",
      "Bowen He",
      "Xiaodong Han",
      "Yuchao Dai",
      "Yiran Zhong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27979": {
    "title": "Hand-Centric Motion Refinement for 3D Hand-Object Interaction via Hierarchical Spatial-Temporal Modeling",
    "volume": "main",
    "abstract": "Hands are the main medium when people interact with the world. Generating proper 3D motion for hand-object interaction is vital for applications such as virtual reality and robotics. Although grasp tracking or object manipulation synthesis can produce coarse hand motion, this kind of motion is inevitably noisy and full of jitter. To address this problem, we propose a data-driven method for coarse motion refinement. First, we design a hand-centric representation to describe the dynamic spatial-temporal relation between hands and objects. Compared to the object-centric representation, our hand-centric representation is straightforward and does not require an ambiguous projection process that converts object-based prediction into hand motion. Second, to capture the dynamic clues of hand-object interaction, we propose a new architecture that models the spatial and temporal structure in a hierarchical manner. Extensive experiments demonstrate that our method outperforms previous methods by a noticeable margin",
    "checked": true,
    "id": "c856badce6a0ade6e6e30abb5cda09b1cde8f607",
    "semantic_title": "hand-centric motion refinement for 3d hand-object interaction via hierarchical spatial-temporal modeling",
    "citation_count": 2,
    "authors": [
      "Yuze Hao",
      "Jianrong Zhang",
      "Tao Zhuo",
      "Fuan Wen",
      "Hehe Fan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27980": {
    "title": "Progressive Feature Self-Reinforcement for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "Compared to conventional semantic segmentation with pixel-level supervision, weakly supervised semantic segmentation (WSSS) with image-level labels poses the challenge that it commonly focuses on the most discriminative regions, resulting in a disparity between weakly and fully supervision scenarios. A typical manifestation is the diminished precision on object boundaries, leading to deteriorated accuracy of WSSS. To alleviate this issue, we propose to adaptively partition the image content into certain regions (e.g., confident foreground and background) and uncertain regions (e.g., object boundaries and misclassified categories) for separate processing. For uncertain cues, we propose an adaptive masking strategy and seek to recover the local information with self-distilled knowledge. We further assume that confident regions should be robust enough to preserve the global semantics, and introduce a complementary self-distillation method that constrains semantic consistency between confident regions and an augmented view with the same class labels. Extensive experiments conducted on PASCAL VOC 2012 and MS COCO 2014 demonstrate that our proposed single-stage approach for WSSS not only outperforms state-of-the-art counterparts but also surpasses multi-stage methods that trade complexity for accuracy",
    "checked": true,
    "id": "c74bea3c612db7dfe422426b407c07eec44d2054",
    "semantic_title": "progressive feature self-reinforcement for weakly supervised semantic segmentation",
    "citation_count": 1,
    "authors": [
      "Jingxuan He",
      "Lechao Cheng",
      "Chaowei Fang",
      "Zunlei Feng",
      "Tingting Mu",
      "Mingli Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27981": {
    "title": "Prompting Multi-Modal Image Segmentation with Semantic Grouping",
    "volume": "main",
    "abstract": "Multi-modal image segmentation is one of the core issues in computer vision. The main challenge lies in integrating common information between modalities while retaining specific patterns for each modality. Existing methods typically perform full fine-tuning on RGB-based pre-trained parameters to inherit the powerful representation of the foundation model. Although effective, such paradigm is not optimal due to weak transferability and scarce downstream data. Inspired by the recent success of prompt learning in language models, we propose the Grouping Prompt Tuning Framework (GoPT), which introduces explicit semantic grouping to learn modal-related prompts, adapting the frozen pre-trained foundation model to various downstream multi-modal segmentation tasks. Specifically, a class-aware uni-modal prompter is designed to balance intra- and inter-modal semantic propagation by grouping modality-specific class tokens, thereby improving the adaptability of spatial information. Furthermore, an alignment-induced cross-modal prompter is introduced to aggregate class-aware representations and share prompt parameters among different modalities to assist in modeling common statistics. Extensive experiments show the superiority of our GoPT, which achieves SOTA performance on various downstream multi-modal image segmentation tasks by training only < 1% model parameters",
    "checked": true,
    "id": "e92fc5e127f2dfe3832d5d66d7130b6c0a25391d",
    "semantic_title": "prompting multi-modal image segmentation with semantic grouping",
    "citation_count": 3,
    "authors": [
      "Qibin He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27982": {
    "title": "Low-Latency Space-Time Supersampling for Real-Time Rendering",
    "volume": "main",
    "abstract": "With the rise of real-time rendering and the evolution of display devices, there is a growing demand for post-processing methods that offer high-resolution content in a high frame rate. Existing techniques often suffer from quality and latency issues due to the disjointed treatment of frame supersampling and extrapolation. In this paper, we recognize the shared context and mechanisms between frame supersampling and extrapolation, and present a novel framework, Space-time Supersampling (STSS). By integrating them into a unified framework, STSS can improve the overall quality with lower latency. To implement an efficient architecture, we treat the aliasing and warping holes unified as reshading regions and put forth two key components to compensate the regions, namely Random Reshading Masking (RRM) and Efficient Reshading Module (ERM). Extensive experiments demonstrate that our approach achieves superior visual fidelity compared to state-of-the-art (SOTA) methods. Notably, the performance is achieved within only 4ms, saving up to 75\\% of time against the conventional two-stage pipeline that necessitates 17ms",
    "checked": true,
    "id": "2be825c40596e749062e43bc6a2adf1b42af4da2",
    "semantic_title": "low-latency space-time supersampling for real-time rendering",
    "citation_count": 0,
    "authors": [
      "Ruian He",
      "Shili Zhou",
      "Yuqi Sun",
      "Ri Cheng",
      "Weimin Tan",
      "Bo Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27983": {
    "title": "Collaborative Weakly Supervised Video Correlation Learning for Procedure-Aware Instructional Video Analysis",
    "volume": "main",
    "abstract": "Video Correlation Learning (VCL), which aims to analyze the relationships between videos, has been widely studied and applied in various general video tasks. However, applying VCL to instructional videos is still quite challenging due to their intrinsic procedural temporal structure. Specifically, procedural knowledge is critical for accurate correlation analyses on instructional videos. Nevertheless, current procedure-learning methods heavily rely on step-level annotations, which are costly and not scalable. To address this problem, we introduce a weakly supervised framework called Collaborative Procedure Alignment (CPA) for procedure-aware correlation learning on instructional videos. Our framework comprises two core modules: collaborative step mining and frame-to-step alignment. The collaborative step mining module enables simultaneous and consistent step segmentation for paired videos, leveraging the semantic and temporal similarity between frames. Based on the identified steps, the frame-to-step alignment module performs alignment between the frames and steps across videos. The alignment result serves as a measurement of the correlation distance between two videos. We instantiate our framework in two distinct instructional video tasks: sequence verification and action quality assessment. Extensive experiments validate the effectiveness of our approach in providing accurate and interpretable correlation analyses for instructional videos",
    "checked": true,
    "id": "d773f7c84bd82f2c95ce41510760f6e234f8482f",
    "semantic_title": "collaborative weakly supervised video correlation learning for procedure-aware instructional video analysis",
    "citation_count": 2,
    "authors": [
      "Tianyao He",
      "Huabin Liu",
      "Yuxi  Li",
      "Xiao Ma",
      "Cheng Zhong",
      "Yang Zhang",
      "Weiyao Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27984": {
    "title": "Frequency-Adaptive Pan-Sharpening with Mixture of Experts",
    "volume": "main",
    "abstract": "Pan-sharpening involves reconstructing missing high-frequency information in multi-spectral images with low spatial resolution, using a higher-resolution panchromatic image as guidance. Although the inborn connection with frequency domain, existing pan-sharpening research has not almost investigated the potential solution upon frequency domain. To this end, we propose a novel Frequency Adaptive Mixture of Experts (FAME) learning framework for pan-sharpening, which consists of three key components: the Adaptive Frequency Separation Prediction Module, the Sub-Frequency Learning Expert Module, and the Expert Mixture Module. In detail, the first leverages the discrete cosine transform to perform frequency separation by predicting the frequency mask. On the basis of generated mask, the second with low-frequency MOE and high-frequency MOE takes account for enabling the effective low-frequency and high-frequency information reconstruction. Followed by, the final fusion module dynamically weights high frequency and low-frequency MOE knowledge to adapt to remote sensing images with significant content variations. Quantitative and qualitative experiments over multiple datasets demonstrate that our method performs the best against other state-of-the-art ones and comprises a strong generalization ability for real-world scenes. Code will be made publicly at https://github.com/alexhe101/FAME-Net",
    "checked": true,
    "id": "fb9853ebc5cf769621e0c7e7df1bf45407702290",
    "semantic_title": "frequency-adaptive pan-sharpening with mixture of experts",
    "citation_count": 2,
    "authors": [
      "Xuanhua He",
      "Keyu Yan",
      "Rui Li",
      "Chengjun Xie",
      "Jie Zhang",
      "Man Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27985": {
    "title": "Enhancing RAW-to-sRGB with Decoupled Style Structure in Fourier Domain",
    "volume": "main",
    "abstract": "RAW to sRGB mapping, which aims to convert RAW images from smartphones into RGB form equivalent to that of Digital Single-Lens Reflex (DSLR) cameras, has become an important area of research. However, current methods often ignore the difference between cell phone RAW images and DSLR camera RGB images, a difference that goes beyond the color matrix and extends to spatial structure due to resolution variations. Recent methods directly rebuild color mapping and spatial structure via shared deep representation, limiting optimal performance. Inspired by Image Signal Processing (ISP) pipeline, which distinguishes image restoration and enhancement, we present a novel Neural ISP framework, named FourierISP. This approach breaks the image down into style and structure within the frequency domain, allowing for independent optimization. FourierISP is comprised of three subnetworks: Phase Enhance Subnet for structural refinement, Amplitude Refine Subnet for color learning, and Color Adaptation Subnet for blending them in a smooth manner. This approach sharpens both color and structure, and extensive evaluations across varied datasets confirm that our approach realizes state-of-the-art results. Code will be available at https://github.com/alexhe101/FourierISP",
    "checked": true,
    "id": "837f645c97bc0431820d9e547d6ccba37065f9c2",
    "semantic_title": "enhancing raw-to-srgb with decoupled style structure in fourier domain",
    "citation_count": 1,
    "authors": [
      "Xuanhua He",
      "Tao Hu",
      "Guoli Wang",
      "Zejin Wang",
      "Run Wang",
      "Qian Zhang",
      "Keyu Yan",
      "Ziyi Chen",
      "Rui Li",
      "Chengjun Xie",
      "Jie Zhang",
      "Man Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27986": {
    "title": "A User-Friendly Framework for Generating Model-Preferred Prompts in Text-to-Image Synthesis",
    "volume": "main",
    "abstract": "Well-designed prompts have demonstrated the potential to guide text-to-image models in generating amazing images. Although existing prompt engineering methods can provide high-level guidance, it is challenging for novice users to achieve the desired results by manually entering prompts due to a discrepancy between novice-user-input prompts and the model-preferred prompts. To bridge the distribution gap between user input behavior and model training datasets, we first construct a novel Coarse-Fine Granularity Prompts dataset (CFP) and propose a novel User-Friendly Fine-Grained Text Generation framework (UF-FGTG) for automated prompt optimization. For CFP, we construct a novel dataset for text-to-image tasks that combines coarse and fine-grained prompts to facilitate the development of automated prompt generation methods. For UF-FGTG, we propose a novel framework that automatically translates user-input prompts into model-preferred prompts. Specifically, we propose a prompt refiner that continually rewrites prompts to empower users to select results that align with their unique needs. Meanwhile, we integrate image-related loss functions from the text-to-image model into the training process of text generation to generate model-preferred prompts. Additionally, we propose an adaptive feature extraction module to ensure diversity in the generated results. Experiments demonstrate that our approach is capable of generating more visually appealing and diverse images than previous state-of-the-art methods, achieving an average improvement of 5% across six quality and aesthetic metrics. Data and code are available at https://github.com/Naylenv/UF-FGTG",
    "checked": true,
    "id": "57866c5ba4eb25130faeaea82b39b70cab23ef98",
    "semantic_title": "a user-friendly framework for generating model-preferred prompts in text-to-image synthesis",
    "citation_count": 0,
    "authors": [
      "Nailei Hei",
      "Qianyu Guo",
      "Zihao Wang",
      "Yan Wang",
      "Haofen Wang",
      "Wenqiang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27987": {
    "title": "Optimize & Reduce: A Top-Down Approach for Image Vectorization",
    "volume": "main",
    "abstract": "Vector image representation is a popular choice when editability and flexibility in resolution are desired. However, most images are only available in raster form, making raster-to-vector image conversion (vectorization) an important task. Classical methods for vectorization are either domain-specific or yield an abundance of shapes which limits editability and interpretability. Learning-based methods, that use differentiable rendering, have revolutionized vectorization, at the cost of poor generalization to out-of-training distribution domains, and optimization-based counterparts are either slow or produce non-editable and redundant shapes. In this work, we propose Optimize & Reduce (O&R), a top-down approach to vectorization that is both fast and domain-agnostic. O&R aims to attain a compact representation of input images by iteratively optimizing Bezier curve parameters and significantly reducing the number of shapes, using a devised importance measure. We contribute a benchmark of five datasets comprising images from a broad spectrum of image complexities - from emojis to natural-like images. Through extensive experiments on hundreds of images, we demonstrate that our method is domain agnostic and outperforms existing works in both reconstruction and perceptual quality for a fixed number of shapes. Moreover, we show that our algorithm is x10 faster than the state-of-the-art optimization-based method. Our code is publicly available: https://github.com/ajevnisek/optimize-and-reduce",
    "checked": true,
    "id": "aa8cf0a97505629249eb68ef482aa51c755ebd52",
    "semantic_title": "optimize & reduce: a top-down approach for image vectorization",
    "citation_count": 1,
    "authors": [
      "Or Hirschorn",
      "Amir Jevnisek",
      "Shai Avidan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27988": {
    "title": "MotionMix: Weakly-Supervised Diffusion for Controllable Motion Generation",
    "volume": "main",
    "abstract": "Controllable generation of 3D human motions becomes an important topic as the world embraces digital transformation. Existing works, though making promising progress with the advent of diffusion models, heavily rely on meticulously captured and annotated (e.g., text) high-quality motion corpus, a resource-intensive endeavor in the real world. This motivates our proposed MotionMix, a simple yet effective weakly-supervised diffusion model that leverages both noisy and unannotated motion sequences. Specifically, we separate the denoising objectives of a diffusion model into two stages: obtaining conditional rough motion approximations in the initial T-T* steps by learning the noisy annotated motions, followed by the unconditional refinement of these preliminary motions during the last T* steps using unannotated motions. Notably, though learning from two sources of imperfect data, our model does not compromise motion generation quality compared to fully supervised approaches that access gold data. Extensive experiments on several benchmarks demonstrate that our MotionMix, as a versatile framework, consistently achieves state-of-the-art performances on text-to-motion, action-to-motion, and music-to-dance tasks",
    "checked": true,
    "id": "6fee3e7fd37d56b83c85b46d079211ab271a3a5d",
    "semantic_title": "motionmix: weakly-supervised diffusion for controllable motion generation",
    "citation_count": 3,
    "authors": [
      "Nhat M. Hoang",
      "Kehong Gong",
      "Chuan Guo",
      "Michael Bi Mi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27989": {
    "title": "Commonsense for Zero-Shot Natural Language Video Localization",
    "volume": "main",
    "abstract": "Zero-shot Natural Language-Video Localization (NLVL) methods have exhibited promising results in training NLVL models exclusively with raw video data by dynamically generating video segments and pseudo-query annotations. However, existing pseudo-queries often lack grounding in the source video, resulting in unstructured and disjointed content. In this paper, we investigate the effectiveness of commonsense reasoning in zero-shot NLVL. Specifically, we present CORONET, a zero-shot NLVL framework that leverages commonsense to bridge the gap between videos and generated pseudo-queries via a commonsense enhancement module. CORONET employs Graph Convolution Networks (GCN) to encode commonsense information extracted from a knowledge graph, conditioned on the video, and cross-attention mechanisms to enhance the encoded video and pseudo-query representations prior to localization. Through empirical evaluations on two benchmark datasets, we demonstrate that CORONET surpasses both zero-shot and weakly supervised baselines, achieving improvements up to 32.13% across various recall thresholds and up to 6.33% in mIoU. These results underscore the significance of leveraging commonsense reasoning for zero-shot NLVL",
    "checked": true,
    "id": "066ad67338f45d77f4cafbe56fd8969575a19690",
    "semantic_title": "commonsense for zero-shot natural language video localization",
    "citation_count": 1,
    "authors": [
      "Meghana Holla",
      "Ismini Lourentzou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27990": {
    "title": "Learning Subject-Aware Cropping by Outpainting Professional Photos",
    "volume": "main",
    "abstract": "How to frame (or crop) a photo often depends on the image subject and its context; e.g., a human portrait. Recent works have defined the subject-aware image cropping task as a nuanced and practical version of image cropping. We propose a weakly-supervised approach (GenCrop) to learn what makes a high-quality, subject-aware crop from professional stock images. Unlike supervised prior work, GenCrop requires no new manual annotations beyond the existing stock image collection. The key challenge in learning from this data, however, is that the images are already cropped and we do not know what regions were removed. Our insight is to combine a library of stock images with a modern, pre-trained text-to-image diffusion model. The stock image collection provides diversity, and its images serve as pseudo-labels for a good crop. The text-image diffusion model is used to out-paint (i.e., outward inpainting) realistic uncropped images. Using this procedure, we are able to automatically generate a large dataset of cropped-uncropped training pairs to train a cropping model. Despite being weakly-supervised, GenCrop is competitive with state-of-the-art supervised methods and significantly better than comparable weakly-supervised baselines on quantitative and qualitative evaluation metrics",
    "checked": true,
    "id": "9b7e1b05537d96e7dd1a03e526ba0abbd93aadee",
    "semantic_title": "learning subject-aware cropping by outpainting professional photos",
    "citation_count": 0,
    "authors": [
      "James Hong",
      "Lu Yuan",
      "Michaël Gharbi",
      "Matthew Fisher",
      "Kayvon  Fatahalian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27991": {
    "title": "High-Fidelity Diffusion-Based Image Editing",
    "volume": "main",
    "abstract": "Diffusion models have attained remarkable success in the domains of image generation and editing. It is widely recognized that employing larger inversion and denoising steps in diffusion model leads to improved image reconstruction quality. However, the editing performance of diffusion models tends to be no more satisfactory even with increasing denoising steps. The deficiency in editing could be attributed to the conditional Markovian property of the editing process, where errors accumulate throughout denoising steps. To tackle this challenge, we first propose an innovative framework where a rectifier module is incorporated to modulate diffusion model weights with residual features from the original images, thereby providing compensatory information to bridge the fidelity gap. Furthermore, we introduce a novel learning paradigm aimed at minimizing error propagation during the editing process, which trains the editing procedure in a manner similar to denoising score-matching. Extensive experiments demonstrate that our proposed framework and training strategy achieve high-fidelity reconstruction and editing results across various levels of denoising steps, meanwhile exhibits exceptional performance in terms of both quantitative metric and qualitative assessments. Lastly, we explore our model's generalization though several applications like image-to-image translation and out-of-domain image editing",
    "checked": true,
    "id": "9036af5a0174dc8825aac8f7663dab635674a685",
    "semantic_title": "high-fidelity diffusion-based image editing",
    "citation_count": 1,
    "authors": [
      "Chen Hou",
      "Guoqiang  Wei",
      "Zhibo Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27992": {
    "title": "Domain-Hallucinated Updating for Multi-Domain Face Anti-spoofing",
    "volume": "main",
    "abstract": "Multi-Domain Face Anti-Spoofing (MD-FAS) is a practical setting that aims to update models on new domains using only novel data while ensuring that the knowledge acquired from previous domains is not forgotten. Prior methods utilize the responses from models to represent the previous domain knowledge or map the different domains into separated feature spaces to prevent forgetting. However, due to domain gaps, the responses of new data are not as accurate as those of previous data. Also, without the supervision of previous data, separated feature spaces might be destroyed by new domains while updating, leading to catastrophic forgetting. Inspired by the challenges posed by the lack of previous data, we solve this issue from a new standpoint that generates hallucinated previous data for updating FAS model. To this end, we propose a novel Domain-Hallucinated Updating (DHU) framework to facilitate the hallucination of data. Specifically, Domain Information Explorer learns representative domain information of the previous domains. Then, Domain Information Hallucination module transfers the new domain data to pseudo-previous domain ones. Moreover, Hallucinated Features Joint Learning module is proposed to asymmetrically align the new and pseudo-previous data for real samples via dual levels to learn more generalized features, promoting the results on all domains. Our experimental results and visualizations demonstrate that the proposed method outperforms state-of-the-art competitors in terms of effectiveness",
    "checked": true,
    "id": "5d4fa551f46a7fe692f0f94f3940b46bad5b2b76",
    "semantic_title": "domain-hallucinated updating for multi-domain face anti-spoofing",
    "citation_count": 1,
    "authors": [
      "Chengyang Hu",
      "Ke-Yue Zhang",
      "Taiping Yao",
      "Shice Liu",
      "Shouhong Ding",
      "Xin Tan",
      "Lizhuang Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27993": {
    "title": "QI-IRA: Quantum-Inspired Interactive Ranking Aggregation for Person Re-identification",
    "volume": "main",
    "abstract": "Ranking aggregation (RA), the process of aggregating multiple rankings derived from multiple search strategies, has been proved effective in person re-identification (re-ID) because of a single re-ID method can not always achieve consistent superiority for different scenarios. Existing RA research mainly focus on unsupervised and fully-supervised methods. The former lack external supervision to optimize performance, while the latter are costly because of expensive labeling effort required for training. To address the above challenges, this paper proposes a quantum-inspired interactive ranking aggregation (QI-IRA) method, which (1) utilizes quantum theory to interpret and model the generation and aggregation of multiple basic rankings, (2) approximates or even exceeds the performance of fully-supervised RA methods with much less labeling cost, even as low as only two feedbacks per query on Market1501, MARS and DukeMTMC-VideoReID datasets. Comparative experiments conducted on six public re-ID datasets validate the superiority of the proposed QI-IRA method over existing unsupervised, interactive, and fully-supervised RA approaches",
    "checked": true,
    "id": "a470d11119fec8477a83cab5ef993d091c0bc106",
    "semantic_title": "qi-ira: quantum-inspired interactive ranking aggregation for person re-identification",
    "citation_count": 0,
    "authors": [
      "Chunyu Hu",
      "Hong Zhang",
      "Chao Liang",
      "Hao Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27994": {
    "title": "SpaceGTN: A Time-Agnostic Graph Transformer Network for Handwritten Diagram Recognition and Segmentation",
    "volume": "main",
    "abstract": "Online handwriting recognition is pivotal in domains like note-taking, education, healthcare, and office tasks. Existing diagram recognition algorithms mainly rely on the temporal information of strokes, resulting in a decline in recognition performance when dealing with notes that have been modified or have no temporal information. The current datasets are drawn based on templates and cannot reflect the real free-drawing situation. To address these challenges, we present SpaceGTN, a time-agnostic Graph Transformer Network, leveraging spatial integration and removing the need for temporal data. Extensive experiments on multiple datasets have demonstrated that our method consistently outperforms existing methods and achieves state-of-the-art performance. We also propose a pipeline that seamlessly connects offline and online handwritten diagrams. By integrating a stroke restoration technique with SpaceGTN, it enables intelligent editing of previously uneditable offline diagrams at the stroke level. In addition, we have also launched the first online handwritten diagram dataset, OHSD, which is collected using a free-drawing method and comes with modification annotations",
    "checked": true,
    "id": "d4010fabbecd78c1fcb15d33702d52b5c77258ff",
    "semantic_title": "spacegtn: a time-agnostic graph transformer network for handwritten diagram recognition and segmentation",
    "citation_count": 0,
    "authors": [
      "Haoxiang Hu",
      "Cangjun Gao",
      "Yaokun Li",
      "Xiaoming Deng",
      "YuKun Lai",
      "Cuixia Ma",
      "Yong-Jin Liu",
      "Hongan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27995": {
    "title": "Learning Explicit Contact for Implicit Reconstruction of Hand-Held Objects from Monocular Images",
    "volume": "main",
    "abstract": "Reconstructing hand-held objects from monocular RGB images is an appealing yet challenging task. In this task, contacts between hands and objects provide important cues for recovering the 3D geometry of the hand-held objects. Though recent works have employed implicit functions to achieve impressive progress, they ignore formulating contacts in their frameworks, which results in producing less realistic object meshes. In this work, we explore how to model contacts in an explicit way to benefit the implicit reconstruction of hand-held objects. Our method consists of two components: explicit contact prediction and implicit shape reconstruction. In the first part, we propose a new subtask of directly estimating 3D hand-object contacts from a single image. The part-level and vertex-level graph-based transformers are cascaded and jointly learned in a coarse-to-fine manner for more accurate contact probabilities. In the second part, we introduce a novel method to diffuse estimated contact states from the hand mesh surface to nearby 3D space and leverage diffused contact probabilities to construct the implicit neural representation for the manipulated object. Benefiting from estimating the interaction patterns between the hand and the object, our method can reconstruct more realistic object meshes, especially for object parts that are in contact with hands. Extensive experiments on challenging benchmarks show that the proposed method outperforms the current state of the arts by a great margin. Our code is publicly available at https://junxinghu.github.io/projects/hoi.html",
    "checked": true,
    "id": "b8767383f31ad1ffaff8f0154e923d8de02de0af",
    "semantic_title": "learning explicit contact for implicit reconstruction of hand-held objects from monocular images",
    "citation_count": 1,
    "authors": [
      "Junxing Hu",
      "Hongwen Zhang",
      "Zerui Chen",
      "Mengcheng Li",
      "Yunlong Wang",
      "Yebin Liu",
      "Zhenan Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27996": {
    "title": "DALDet: Depth-Aware Learning Based Object Detection for Autonomous Driving",
    "volume": "main",
    "abstract": "3D object detection achieves good detection performance in autonomous driving. However, it requires substantial computational resources, which prevents its practical application. 2D object detection has less computational burden but lacks spatial and geometric information embedded in depth. Therefore, we present DALDet, an efficient depth-aware learning based 2D detector, achieving high-performance object detection for autonomous driving. We design an efficient one-stage detection framework and seamlessly integrate depth cues into convolutional neural network by introducing depth-aware convolution and depth-aware average pooling, which effectively improve the detector's ability to perceive 3D space. Moreover, we propose a depth-guided loss function for training DALDet, which effectively improves the localization ability of the detector. Due to the use of depth map, DALDet can also output the distance of the object, which is of great importance for driving applications such as obstacle avoidance. Extensive experiments demonstrate the superiority and efficiency of DALDet. In particular, our DALDet ranks 1st on both KITTI Car and Cyclist 2D detection test leaderboards among all 2D detectors with high efficiency as well as yielding competitive performance among many leading 3D detectors. Code will be available at https://github.com/hukefy/DALDet",
    "checked": true,
    "id": "4a134742984a958526b193d23a30a86f66004b48",
    "semantic_title": "daldet: depth-aware learning based object detection for autonomous driving",
    "citation_count": 0,
    "authors": [
      "Ke Hu",
      "Tongbo Cao",
      "Yuan Li",
      "Song Chen",
      "Yi Kang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27997": {
    "title": "COMMA: Co-articulated Multi-Modal Learning",
    "volume": "main",
    "abstract": "Pretrained large-scale vision-language models such as CLIP have demonstrated excellent generalizability over a series of downstream tasks. However, they are sensitive to the variation of input text prompts and need a selection of prompt templates to achieve satisfactory performance. Recently, various methods have been proposed to dynamically learn the prompts as the textual inputs to avoid the requirements of laboring hand-crafted prompt engineering in the fine-tuning process. We notice that these methods are suboptimal in two aspects. First, the prompts of the vision and language branches in these methods are usually separated or uni-directionally correlated. Thus, the prompts of both branches are not fully correlated and may not provide enough guidance to align the representations of both branches. Second, it's observed that most previous methods usually achieve better performance on seen classes but cause performance degeneration on unseen classes compared to CLIP. This is because the essential generic knowledge learned in the pretraining stage is partly forgotten in the fine-tuning process. In this paper, we propose Co-Articulated Multi-Modal Learning (COMMA) to handle the above limitations. Especially, our method considers prompts from both branches to generate the prompts to enhance the representation alignment of both branches. Besides, to alleviate forgetting about the essential knowledge, we minimize the feature discrepancy between the learned prompts and the embeddings of hand-crafted prompts in the pre-trained CLIP in the late transformer layers. We evaluate our method across three representative tasks of generalization to novel classes, new target datasets and unseen domain shifts. Experimental results demonstrate the superiority of our method by exhibiting a favorable performance boost upon all tasks with high efficiency. Code is available at https://github.com/hulianyuyy/COMMA",
    "checked": true,
    "id": "b9eb60c1a1cd28def5c1a67ca56982a24c1f26ef",
    "semantic_title": "comma: co-articulated multi-modal learning",
    "citation_count": 0,
    "authors": [
      "Lianyu Hu",
      "Liqing Gao",
      "Zekang Liu",
      "Chi-Man Pun",
      "Wei Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27998": {
    "title": "Latent Space Editing in Transformer-Based Flow Matching",
    "volume": "main",
    "abstract": "This paper strives for image editing via generative models. Flow Matching is an emerging generative modeling technique that offers the advantage of simple and efficient training. Simultaneously, a new transformer-based U-ViT has recently been proposed to replace the commonly used UNet for better scalability and performance in generative modeling. Hence, Flow Matching with a transformer backbone offers the potential for scalable and high-quality generative modeling, but their latent structure and editing ability are as of yet unknown. Hence, we adopt this setting and explore how to edit images through latent space manipulation. We introduce an editing space, which we call u-space, that can be manipulated in a controllable, accumulative, and composable manner. Additionally, we propose a tailored sampling solution to enable sampling with the more efficient adaptive step-size ODE solvers. Lastly, we put forth a straightforward yet powerful method for achieving fine-grained and nuanced editing using text prompts. Our framework is simple and efficient, all while being highly effective at editing images while preserving the essence of the original content. Our code will be publicly available at https://taohu.me/lfm/",
    "checked": true,
    "id": "ca743e75ce090bbf686307e41bd8747661768fbe",
    "semantic_title": "latent space editing in transformer-based flow matching",
    "citation_count": 12,
    "authors": [
      "Vincent Tao Hu",
      "Wei Zhang",
      "Meng Tang",
      "Pascal Mettes",
      "Deli Zhao",
      "Cees  Snoek"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27999": {
    "title": "BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions",
    "volume": "main",
    "abstract": "Vision Language Models (VLMs), which extend Large Language Models (LLM) by incorporating visual understanding capability, have demonstrated significant advancements in addressing open-ended visual question-answering (VQA) tasks. However, these models cannot accurately interpret images infused with text, a common occurrence in real-world scenarios. Standard procedures for extracting information from images often involve learning a fixed set of query embeddings. These embeddings are designed to encapsulate image contexts and are later used as soft prompt inputs in LLMs. Yet, this process is limited to the token count, potentially curtailing the recognition of scenes with text-rich context. To improve upon them, the present study introduces BLIVA: an augmented version of InstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings from InstructBLIP and also directly projects encoded patch embeddings into the LLM, a technique inspired by LLaVA. This approach assists the model to capture intricate details potentially missed during the query decoding process. Empirical evidence demonstrates that our model, BLIVA, significantly enhances performance in processing text-rich VQA benchmarks (up to 17.76% in OCR-VQA benchmark) and in undertaking general (not particularly text-rich) VQA benchmarks (up to 7.9% in Visual Spatial Reasoning benchmark), and achieved 17.72% overall improvement in a comprehensive multimodal LLM benchmark (MME), comparing to our baseline InstructBLIP. BLIVA demonstrates significant capability in decoding real-world images, irrespective of text presence. To demonstrate the broad industry applications enabled by BLIVA, we evaluate the model using a new dataset comprising YouTube thumbnails paired with question-answer sets across 11 diverse categories. For researchers interested in further exploration, our code and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA",
    "checked": true,
    "id": "30cc95639cffca4ffa8c0eafbc502636c0c88fa5",
    "semantic_title": "bliva: a simple multimodal llm for better handling of text-rich visual questions",
    "citation_count": 55,
    "authors": [
      "Wenbo Hu",
      "Yifan Xu",
      "Yi Li",
      "Weiyue Li",
      "Zeyuan Chen",
      "Zhuowen Tu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28000": {
    "title": "A Dynamic Learning Method towards Realistic Compositional Zero-Shot Learning",
    "volume": "main",
    "abstract": "To tackle the challenge of recognizing images of unseen attribute-object compositions, Compositional Zero-Shot Learning (CZSL) methods have been previously addressed. However, test images in realistic scenarios may also incorporate other forms of unknown factors, such as novel semantic concepts or novel image styles. As previous CZSL works have overlooked this critical issue, in this research, we first propose the Realistic Compositional Zero-Shot Learning (RCZSL) task which considers the various types of unknown factors in an unified experimental setting. To achieve this, we firstly conduct re-labelling on MIT-States and use the pre-trained generative models to obtain images of various domains. Then the entire dataset is split into a training set and a test set, with the latter containing images of unseen concepts, unseen compositions, unseen domains as well as their combinations. Following this, we show that the visual-semantic relationship changes on unseen images, leading us to construct two dynamic modulators to adapt the visual features and composition prototypes in accordance with the input image. We believe that such a dynamic learning method could effectively alleviate the domain shift problem caused by various types of unknown factors. We conduct extensive experiments on benchmark datasets for both the conventional CZSL setting and the proposed RCZSL setting. The effectiveness of our method has been proven by empirical results, which significantly outperformed both our baseline method and state-of-the-art approaches",
    "checked": true,
    "id": "3996ffd3a289ed1fd42990bbf3b696f2493f5819",
    "semantic_title": "a dynamic learning method towards realistic compositional zero-shot learning",
    "citation_count": 0,
    "authors": [
      "Xiaoming Hu",
      "Zilei Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28001": {
    "title": "LF-ViT: Reducing Spatial Redundancy in Vision Transformer for Efficient Image Recognition",
    "volume": "main",
    "abstract": "The Vision Transformer (ViT) excels in accuracy when handling high-resolution images, yet it confronts the challenge of significant spatial redundancy, leading to increased computational and memory requirements. To address this, we present the Localization and Focus Vision Transformer (LF-ViT). This model operates by strategically curtailing computational demands without impinging on performance. In the Localization phase, a reduced-resolution image is processed; if a definitive prediction remains elusive, our pioneering Neighborhood Global Class Attention (NGCA) mechanism is triggered, effectively identifying and spotlighting class-discriminative regions based on initial findings. Subsequently, in the Focus phase, this designated region is used from the original image to enhance recognition. Uniquely, LF-ViT employs consistent parameters across both phases, ensuring seamless end-to-end optimization. Our empirical tests affirm LF-ViT's prowess: it remarkably decreases Deit-S's FLOPs by 63% and concurrently amplifies throughput twofold. Code of this project is at https://github.com/edgeai1/LF-ViT.git",
    "checked": true,
    "id": "b1f0ac0b5e4044251dcdcce78e0046feb43cc7c7",
    "semantic_title": "lf-vit: reducing spatial redundancy in vision transformer for efficient image recognition",
    "citation_count": 0,
    "authors": [
      "Youbing Hu",
      "Yun Cheng",
      "Anqi Lu",
      "Zhiqiang Cao",
      "Dawei Wei",
      "Jie Liu",
      "Zhijun Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28002": {
    "title": "O^2-Recon: Completing 3D Reconstruction of Occluded Objects in the Scene with a Pre-trained 2D Diffusion Model",
    "volume": "main",
    "abstract": "Occlusion is a common issue in 3D reconstruction from RGB-D videos, often blocking the complete reconstruction of objects and presenting an ongoing problem. In this paper, we propose a novel framework, empowered by a 2D diffusion-based in-painting model, to reconstruct complete surfaces for the hidden parts of objects. Specifically, we utilize a pre-trained diffusion model to fill in the hidden areas of 2D images. Then we use these in-painted images to optimize a neural implicit surface representation for each instance for 3D reconstruction. Since creating the in-painting masks needed for this process is tricky, we adopt a human-in-the-loop strategy that involves very little human engagement to generate high-quality masks. Moreover, some parts of objects can be totally hidden because the videos are usually shot from limited perspectives. To ensure recovering these invisible areas, we develop a cascaded network architecture for predicting signed distance field, making use of different frequency bands of positional encoding and maintaining overall smoothness. Besides the commonly used rendering loss, Eikonal loss, and silhouette loss, we adopt a CLIP-based semantic consistency loss to guide the surface from unseen camera angles. Experiments on ScanNet scenes show that our proposed framework achieves state-of-the-art accuracy and completeness in object-level reconstruction from scene-level RGB-D videos. Code: https://github.com/THU-LYJ-Lab/O2-Recon",
    "checked": true,
    "id": "2f39b7f099283a09cc348a1d5fe7b581bad81e7f",
    "semantic_title": "o^2-recon: completing 3d reconstruction of occluded objects in the scene with a pre-trained 2d diffusion model",
    "citation_count": 0,
    "authors": [
      "Yubin Hu",
      "Sheng Ye",
      "Wang Zhao",
      "Matthieu Lin",
      "Yuze He",
      "Yu-Hui Wen",
      "Ying He",
      "Yong-Jin Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28003": {
    "title": "Arbitrary-Scale Video Super-resolution Guided by Dynamic Context",
    "volume": "main",
    "abstract": "We propose a Dynamic Context-Guided Upsampling (DCGU) module for video super-resolution (VSR) that leverages temporal context guidance to achieve efficient and effective arbitrary-scale VSR. While most VSR research focuses on backbone design, the importance of the upsampling part is often overlooked. Existing methods rely on pixelshuffle-based upsampling, which has limited capabilities in handling arbitrary upsampling scales. Recent attempts to replace pixelshuffle-based modules with implicit neural function-based and filter-based approaches suffer from slow inference speeds and limited representation capacity, respectively. To overcome these limitations, our DCGU module predicts non-local sampling locations and content-dependent filter weights, enabling efficient and effective arbitrary-scale VSR. Our proposed multi-granularity location search module efficiently identifies non-local sampling locations across the entire low-resolution grid, and the temporal bilateral filter modulation module integrates content information with the filter weight to enhance textual details. Extensive experiments demonstrate the superiority of our method in terms of performance and speed on arbitrary-scale VSR",
    "checked": true,
    "id": "0ffa19408dc66bb924f802a4f37b01398773bb76",
    "semantic_title": "arbitrary-scale video super-resolution guided by dynamic context",
    "citation_count": 0,
    "authors": [
      "Cong Huang",
      "Jiahao Li",
      "Lei Chu",
      "Dong Liu",
      "Yan Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28004": {
    "title": "Dynamic Weighted Combiner for Mixed-Modal Image Retrieval",
    "volume": "main",
    "abstract": "Mixed-Modal Image Retrieval (MMIR) as a flexible search paradigm has attracted wide attention. However, previous approaches always achieve limited performance, due to two critical factors are seriously overlooked. 1) The contribution of image and text modalities is different, but incorrectly treated equally. 2) There exist inherent labeling noises in describing users' intentions with text in web datasets from diverse real-world scenarios, giving rise to overfitting. We propose a Dynamic Weighted Combiner (DWC) to tackle the above challenges, which includes three merits. First, we propose an Editable Modality De-equalizer (EMD) by taking into account the contribution disparity between modalities, containing two modality feature editors and an adaptive weighted combiner. Second, to alleviate labeling noises and data bias, we propose a dynamic soft-similarity label generator (SSG) to implicitly improve noisy supervision. Finally, to bridge modality gaps and facilitate similarity learning, we propose a CLIP-based mutual enhancement module alternately trained by a mixed-modality contrastive loss. Extensive experiments verify that our proposed model significantly outperforms state-of-the-art methods on real-world datasets. The source code is available at https://github.com/fuxianghuang1/DWC",
    "checked": true,
    "id": "8c1660c2c914f19fc7b3038469434b64bf3b1982",
    "semantic_title": "dynamic weighted combiner for mixed-modal image retrieval",
    "citation_count": 1,
    "authors": [
      "Fuxiang Huang",
      "Lei Zhang",
      "Xiaowei Fu",
      "Suqi Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28005": {
    "title": "NeuSurf: On-Surface Priors for Neural Surface Reconstruction from Sparse Input Views",
    "volume": "main",
    "abstract": "Recently, neural implicit functions have demonstrated remarkable results in the field of multi-view reconstruction. However, most existing methods are tailored for dense views and exhibit unsatisfactory performance when dealing with sparse views. Several latest methods have been proposed for generalizing implicit reconstruction to address the sparse view reconstruction task, but they still suffer from high training costs and are merely valid under carefully selected perspectives. In this paper, we propose a novel sparse view reconstruction framework that leverages on-surface priors to achieve highly faithful surface reconstruction. Specifically, we design several constraints on global geometry alignment and local geometry refinement for jointly optimizing coarse shapes and fine details. To achieve this, we train a neural network to learn a global implicit field from the on-surface points obtained from SfM and then leverage it as a coarse geometric constraint. To exploit local geometric consistency, we project on-surface points onto seen and unseen views, treating the consistent loss of projected features as a fine geometric constraint. The experimental results with DTU and BlendedMVS datasets in two prevalent sparse settings demonstrate significant improvements over the state-of-the-art methods",
    "checked": true,
    "id": "8e5e0fdd376295306223b2c6267975d3d881143f",
    "semantic_title": "neusurf: on-surface priors for neural surface reconstruction from sparse input views",
    "citation_count": 3,
    "authors": [
      "Han Huang",
      "Yulun Wu",
      "Junsheng Zhou",
      "Ge Gao",
      "Ming Gu",
      "Yu-Shen Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28006": {
    "title": "Seeing Dark Videos via Self-Learned Bottleneck Neural Representation",
    "volume": "main",
    "abstract": "Enhancing low-light videos in a supervised style presents a set of challenges, including limited data diversity, misalignment, and the domain gap introduced through the dataset construction pipeline. Our paper tackles these challenges by constructing a self-learned enhancement approach that gets rid of the reliance on any external training data. The challenge of self-supervised learning lies in fitting high-quality signal representations solely from input signals. Our work designs a bottleneck neural representation mechanism that extracts those signals. More in detail, we encode the frame-wise representation with a compact deep embedding and utilize a neural network to parameterize the video-level manifold consistently. Then, an entropy constraint is applied to the enhanced results based on the adjacent spatial-temporal context to filter out the degraded visual signals, e.g. noise and frame inconsistency. Last, a novel Chromatic Retinex decomposition is proposed to effectively align the reflectance distribution temporally. It benefits the entropy control on different components of each frame and facilitates noise-to-noise training, successfully suppressing the temporal flicker. Extensive experiments demonstrate the robustness and superior effectiveness of our proposed method. Our project is publicly available at: https://huangerbai.github.io/SLBNR/",
    "checked": true,
    "id": "05b780ed15aafbfef5d26125da4867b7ad2cba58",
    "semantic_title": "seeing dark videos via self-learned bottleneck neural representation",
    "citation_count": 0,
    "authors": [
      "Haofeng Huang",
      "Wenhan Yang",
      "Lingyu Duan",
      "Jiaying Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28007": {
    "title": "Combinatorial CNN-Transformer Learning with Manifold Constraints for Semi-supervised Medical Image Segmentation",
    "volume": "main",
    "abstract": "Semi-supervised learning (SSL), as one of the dominant methods, aims at leveraging the unlabeled data to deal with the annotation dilemma of supervised learning, which has attracted much attentions in the medical image segmentation. Most of the existing approaches leverage a unitary network by convolutional neural networks (CNNs) with compulsory consistency of the predictions through small perturbations applied to inputs or models. The penalties of such a learning paradigm are that (1) CNN-based models place severe limitations on global learning; (2) rich and diverse class-level distributions are inhibited. In this paper, we present a novel CNN-Transformer learning framework in the manifold space for semi-supervised medical image segmentation. First, at intra-student level, we propose a novel class-wise consistency loss to facilitate the learning of both discriminative and compact target feature representations. Then, at inter-student level, we align the CNN and Transformer features using a prototype-based optimal transport method. Extensive experiments show that our method outperforms previous state-of-the-art methods on three public medical image segmentation benchmarks",
    "checked": true,
    "id": "f86b36c5b9a2338c6fcef47c74b0b186a35eb61b",
    "semantic_title": "combinatorial cnn-transformer learning with manifold constraints for semi-supervised medical image segmentation",
    "citation_count": 0,
    "authors": [
      "Huimin Huang",
      "Yawen Huang",
      "Shiao Xie",
      "Lanfen Lin",
      "Ruofeng Tong",
      "Yen-Wei Chen",
      "Yuexiang Li",
      "Yefeng Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28008": {
    "title": "Sparse Bayesian Deep Learning for Cross Domain Medical Image Reconstruction",
    "volume": "main",
    "abstract": "Cross domain medical image reconstruction aims to address the issue that deep learning models trained solely on one source dataset might not generalize effectively to unseen target datasets from different hospitals. Some recent methods achieve satisfactory reconstruction performance, but often at the expense of extensive parameters and time consumption. To strike a balance between cross domain image reconstruction quality and model computational efficiency, we propose a lightweight sparse Bayesian deep learning method. Notably, we apply a fixed-form variational Bayes (FFVB) approach to quantify pixel-wise uncertainty priors derived from degradation distribution of the source domain. Furthermore, by integrating the uncertainty prior into the posterior sampled through stochastic gradient Langevin dynamics (SGLD), we develop a training strategy that dynamically generates and optimizes the prior distribution on the network weights for each unseen domain. This strategy enhances generalizability and ensures robust reconstruction performance. When evaluated on medical image reconstruction tasks, our proposed approach demonstrates impressive performance across various previously unseen domains",
    "checked": true,
    "id": "b82cc411c64afff5f223826c336ebad5ff16ef32",
    "semantic_title": "sparse bayesian deep learning for cross domain medical image reconstruction",
    "citation_count": 1,
    "authors": [
      "Jiaxin Huang",
      "Qi Wu",
      "Yazhou Ren",
      "Fan Yang",
      "Aodi Yang",
      "Qianqian Yang",
      "Xiaorong Pu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28009": {
    "title": "UniCell: Universal Cell Nucleus Classification via Prompt Learning",
    "volume": "main",
    "abstract": "The recognition of multi-class cell nuclei can significantly facilitate the process of histopathological diagnosis. Numerous pathological datasets are currently available, but their annotations are inconsistent. Most existing methods require individual training on each dataset to deduce the relevant labels and lack the use of common knowledge across datasets, consequently restricting the quality of recognition. In this paper, we propose a universal cell nucleus classification framework (UniCell), which employs a novel prompt learning mechanism to uniformly predict the corresponding categories of pathological images from different dataset domains. In particular, our framework adopts an end-to-end architecture for nuclei detection and classification, and utilizes flexible prediction heads for adapting various datasets. Moreover, we develop a Dynamic Prompt Module (DPM) that exploits the properties of multiple datasets to enhance features. The DPM first integrates the embeddings of datasets and semantic categories, and then employs the integrated prompts to refine image representations, efficiently harvesting the shared knowledge among the related cell types and data sources. Experimental results demonstrate that the proposed method effectively achieves the state-of-the-art results on four nucleus detection and classification benchmarks. Code and models are available at https://github.com/lhaof/UniCell",
    "checked": true,
    "id": "02e7dac3c02e84229689fbe3f63e4dd4cf4df384",
    "semantic_title": "unicell: universal cell nucleus classification via prompt learning",
    "citation_count": 0,
    "authors": [
      "Junjia Huang",
      "Haofeng Li",
      "Xiang Wan",
      "Guanbin Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28010": {
    "title": "SC-NeuS: Consistent Neural Surface Reconstruction from Sparse and Noisy Views",
    "volume": "main",
    "abstract": "The recent neural surface reconstruction approaches using volume rendering have made much progress by achieving impressive surface reconstruction quality, but are still limited to dense and highly accurate posed views. To overcome such drawbacks, this paper pays special attention on the consistent surface reconstruction from sparse views with noisy camera poses. Unlike previous approaches, the key difference of this paper is to exploit the multi-view constraints directly from the explicit geometry of the neural surface, which can be used as effective regularization to jointly learn the neural surface and refine the camera poses. To build effective multi-view constraints, we introduce a fast differentiable on-surface intersection to generate on-surface points, and propose view-consistent losses on such differentiable points to regularize the neural surface learning. Based on this point, we propose a joint learning strategy, named SC-NeuS, to perform geometry-consistent surface reconstruction in an end-to-end manner. With extensive evaluation on public datasets, our SC-NeuS can achieve consistently better surface reconstruction results with fine-grained details than previous approaches, especially from sparse and noisy camera views. The source code is available at https://github.com/zouzx/sc-neus.git",
    "checked": true,
    "id": "43b0c25e8a9970ac8b90ddf6edcf1391c7df1073",
    "semantic_title": "sc-neus: consistent neural surface reconstruction from sparse and noisy views",
    "citation_count": 3,
    "authors": [
      "Shi-Sheng Huang",
      "Zixin Zou",
      "Yichi Zhang",
      "Yan-Pei Cao",
      "Ying Shan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28011": {
    "title": "MFTN: Multi-Level Feature Transfer Network Based on MRI-Transformer for MR Image Super-resolution",
    "volume": "main",
    "abstract": "Due to the unique environment and inherent properties of magnetic resonance imaging (MRI) instruments, MR images typically have lower resolution. Therefore, improving the resolution of MR images is beneficial for assisting doctors in diagnosing the condition. Currently, the existing MR image super-resolution (SR) methods still have the problem of insufficient detail reconstruction. To overcome this issue, this paper proposes a multi-level feature transfer network (MFTN) based on MRI-Transformer to realize SR of low-resolution MRI data. MFTN consists of a multi-scale feature reconstruction network (MFRN) and a multi-level feature extraction branch (MFEB). MFRN is constructed as a pyramid structure to gradually reconstruct image features at different scales by integrating the features obtained from MFEB, and MFEB is constructed to provide detail information at different scales for low resolution MR image SR reconstruction by constructing multiple MRI-Transformer modules. Each MRI-Transformer module is designed to learn the transfer features from the reference image by establishing feature correlations between the reference image and low-resolution MR image. In addition, a contrast learning constraint item is added to the loss function to enhance the texture details of the SR image. A large number of experiments show that our network can effectively reconstruct high-quality MR Images and achieves better performance compared to some state-of-the-art methods. The source code of this work will be released on GitHub",
    "checked": true,
    "id": "b7972f13bd51dc482060cb47f21058d14bef2201",
    "semantic_title": "mftn: multi-level feature transfer network based on mri-transformer for mr image super-resolution",
    "citation_count": 0,
    "authors": [
      "Shuying Huang",
      "Ge Chen",
      "Yong Yang",
      "Xiaozheng Wang",
      "Chenbin Liang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28012": {
    "title": "SDGAN: Disentangling Semantic Manipulation for Facial Attribute Editing",
    "volume": "main",
    "abstract": "Facial attribute editing has garnered significant attention, yet prevailing methods struggle with achieving precise attribute manipulation while preserving irrelevant details and controlling attribute styles. This challenge primarily arises from the strong correlations between different attributes and the interplay between attributes and identity. In this paper, we propose Semantic Disentangled GAN (SDGAN), a novel method addressing this challenge. SDGAN introduces two key concepts: a semantic disentanglement generator that assigns facial representations to distinct attribute-specific editing modules, enabling the decoupling of the facial attribute editing process, and a semantic mask alignment strategy that confines attribute editing to appropriate regions, thereby avoiding undesired modifications. Leveraging these concepts, SDGAN demonstrates accurate attribute editing and achieves high-quality attribute style manipulation through both latent-guided and reference-guided manners. We extensively evaluate our method on the CelebA-HQ database, providing both qualitative and quantitative analyses. Our results establish that SDGAN significantly outperforms state-of-the-art techniques, showcasing the effectiveness of our approach. To foster reproducibility and further research, we will provide the code for our method",
    "checked": true,
    "id": "8cd737b653c99523b6a524ef2c1bcf4de6b3b085",
    "semantic_title": "sdgan: disentangling semantic manipulation for facial attribute editing",
    "citation_count": 1,
    "authors": [
      "Wenmin Huang",
      "Weiqi Luo",
      "Jiwu Huang",
      "Xiaochun Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28013": {
    "title": "Frozen CLIP Transformer Is an Efficient Point Cloud Encoder",
    "volume": "main",
    "abstract": "The pretrain-finetune paradigm has achieved great success in NLP and 2D image fields because of the high-quality representation ability and transferability of their pretrained models. However, pretraining such a strong model is difficult in the 3D point cloud field due to the limited amount of point cloud sequences. This paper introduces Efficient Point Cloud Learning (EPCL), an effective and efficient point cloud learner for directly training high-quality point cloud models with a frozen CLIP transformer. Our EPCL connects the 2D and 3D modalities by semantically aligning the image features and point cloud features without paired 2D-3D data. Specifically, the input point cloud is divided into a series of local patches, which are converted to token embeddings by the designed point cloud tokenizer. These token embeddings are concatenated with a task token and fed into the frozen CLIP transformer to learn point cloud representation. The intuition is that the proposed point cloud tokenizer projects the input point cloud into a unified token space that is similar to the 2D images. Comprehensive experiments on 3D detection, semantic segmentation, classification and few-shot learning demonstrate that the CLIP transformer can serve as an efficient point cloud encoder and our method achieves promising performance on both indoor and outdoor benchmarks. In particular, performance gains brought by our EPCL are 19.7 AP50 on ScanNet V2 detection, 4.4 mIoU on S3DIS segmentation and 1.2 mIoU on SemanticKITTI segmentation compared to contemporary pretrained models. Code is available at \\url{https://github.com/XiaoshuiHuang/EPCL}",
    "checked": true,
    "id": "fdb1cbb3ea42a47c8b6eecc94817f5276a4d0ea8",
    "semantic_title": "frozen clip transformer is an efficient point cloud encoder",
    "citation_count": 6,
    "authors": [
      "Xiaoshui Huang",
      "Zhou Huang",
      "Sheng Li",
      "Wentao Qu",
      "Tong He",
      "Yuenan Hou",
      "Yifan Zuo",
      "Wanli Ouyang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28014": {
    "title": "G2L-CariGAN: Caricature Generation from Global Structure to Local Features",
    "volume": "main",
    "abstract": "Existing GAN-based approaches to caricature generation mainly focus on exaggerating a character's global facial structure. This often leads to the failure in highlighting significant facial features such as big eyes and hook nose. To address this limitation, we propose a new approach termed as G2L-CariGAN, which uses feature maps of spatial dimensions instead of latent codes for geometric exaggeration. G2L-CariGAN first exaggerates the global facial structure of the character on a low-dimensional feature map and then exaggerates its local facial features on a high-dimensional feature map. Moreover, we develop a caricature identity loss function based on feature maps, which well retains the character's identity after exaggeration. Our experiments have demonstrated that G2L-CariGAN outperforms the state-of-arts in terms of the quality of exaggerating a character and retaining its identity",
    "checked": true,
    "id": "cd2c4f46aa02c7e2fbaa05931329b0bc24cc7f26",
    "semantic_title": "g2l-carigan: caricature generation from global structure to local features",
    "citation_count": 0,
    "authors": [
      "Xin Huang",
      "Yunfeng Bai",
      "Dong Liang",
      "Feng Tian",
      "Jinyuan Jia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28015": {
    "title": "3D Visibility-Aware Generalizable Neural Radiance Fields for Interacting Hands",
    "volume": "main",
    "abstract": "Neural radiance fields (NeRFs) are promising 3D representations for scenes, objects, and humans. However, most existing methods require multi-view inputs and per-scene training, which limits their real-life applications. Moreover, current methods focus on single-subject cases, leaving scenes of interacting hands that involve severe inter-hand occlusions and challenging view variations remain unsolved. To tackle these issues, this paper proposes a generalizable visibility-aware NeRF (VA-NeRF) framework for interacting hands. Specifically, given an image of interacting hands as input, our VA-NeRF first obtains a mesh-based representation of hands and extracts their corresponding geometric and textural features. Subsequently, a feature fusion module that exploits the visibility of query points and mesh vertices is introduced to adaptively merge features of both hands, enabling the recovery of features in unseen areas. Additionally, our VA-NeRF is optimized together with a novel discriminator within an adversarial learning paradigm. In contrast to conventional discriminators that predict a single real/fake label for the synthesized image, the proposed discriminator generates a pixel-wise visibility map, providing fine-grained supervision for unseen areas and encouraging the VA-NeRF to improve the visual quality of synthesized images. Experiments on the Interhand2.6M dataset demonstrate that our proposed VA-NeRF outperforms conventional NeRFs significantly. Project Page: https://github.com/XuanHuang0/VANeRF",
    "checked": true,
    "id": "d95a5ad6c6ef4fe08f61430f268ab21cfaf79c04",
    "semantic_title": "3d visibility-aware generalizable neural radiance fields for interacting hands",
    "citation_count": 0,
    "authors": [
      "Xuan Huang",
      "Hanhui Li",
      "Zejun Yang",
      "Zhisheng Wang",
      "Xiaodan Liang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28016": {
    "title": "Sunshine to Rainstorm: Cross-Weather Knowledge Distillation for Robust 3D Object Detection",
    "volume": "main",
    "abstract": "LiDAR-based 3D object detection models inevitably struggle under rainy conditions due to the degraded and noisy scanning signals. Previous research has attempted to address this by simulating the noise from rain to improve the robustness of detection models. However, significant disparities exist between simulated and actual rain-impacted data points. In this work, we propose a novel rain simulation method, termed DRET, that unifies Dynamics and Rainy Environment Theory to provide a cost-effective means of expanding the available realistic rain data for 3D detection training. Furthermore, we present a Sunny-to-Rainy Knowledge Distillation (SRKD) approach to enhance 3D detection under rainy conditions. Extensive experiments on the Waymo-Open-Dataset show that, when combined with the state-of-the-art DSVT model and other classical 3D detectors, our proposed framework demonstrates significant detection accuracy improvements, without losing efficiency. Remarkably, our framework also improves detection capabilities under sunny conditions, therefore offering a robust solution for 3D detection regardless of whether the weather is rainy or sunny",
    "checked": true,
    "id": "d4c33a2a141fe770b48471fa6b7ebfa58fa52523",
    "semantic_title": "sunshine to rainstorm: cross-weather knowledge distillation for robust 3d object detection",
    "citation_count": 1,
    "authors": [
      "Xun Huang",
      "Hai Wu",
      "Xin Li",
      "Xiaoliang Fan",
      "Chenglu Wen",
      "Cheng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28017": {
    "title": "Structure-CLIP: Towards Scene Graph Knowledge to Enhance Multi-Modal Structured Representations",
    "volume": "main",
    "abstract": "Large-scale vision-language pre-training has achieved significant performance in multi-modal understanding and generation tasks. However, existing methods often perform poorly on image-text matching tasks that require structured representations, i.e., representations of objects, attributes, and relations. The models cannot make a distinction between \"An astronaut rides a horse\" and \"A horse rides an astronaut\". This is because they fail to fully leverage structured knowledge when learning multi-modal representations. In this paper, we present an end-to-end framework Structure-CLIP, which integrates Scene Graph Knowledge (SGK) to enhance multi-modal structured representations. Firstly, we use scene graphs to guide the construction of semantic negative examples, which results in an increased emphasis on learning structured representations. Moreover, a Knowledge-Enhance Encoder (KEE) is proposed to leverage SGK as input to further enhance structured representations. To verify the effectiveness of the proposed framework, we pre-train our model with the aforementioned approaches and conduct experiments on downstream tasks. Experimental results demonstrate that Structure-CLIP achieves state-of-the-art (SOTA) performance on VG-Attribution and VG-Relation datasets, with 12.5% and 4.1% ahead of the multi-modal SOTA model respectively. Meanwhile, the results on MSCOCO indicate that Structure-CLIP significantly enhances the structured representations while maintaining the ability of general representations. Our code is available at https://github.com/zjukg/Structure-CLIP",
    "checked": true,
    "id": "0b5b753aa23be12f24b4592429514df6e53289bc",
    "semantic_title": "structure-clip: towards scene graph knowledge to enhance multi-modal structured representations",
    "citation_count": 4,
    "authors": [
      "Yufeng Huang",
      "Jiji Tang",
      "Zhuo Chen",
      "Rongsheng Zhang",
      "Xinfeng Zhang",
      "Weijie Chen",
      "Zeng Zhao",
      "Zhou Zhao",
      "Tangjie Lv",
      "Zhipeng Hu",
      "Wen Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28018": {
    "title": "Voxel or Pillar: Exploring Efficient Point Cloud Representation for 3D Object Detection",
    "volume": "main",
    "abstract": "Efficient representation of point clouds is fundamental for LiDAR-based 3D object detection. While recent grid-based detectors often encode point clouds into either voxels or pillars, the distinctions between these approaches remain underexplored. In this paper, we quantify the differences between the current encoding paradigms and highlight the limited vertical learning within. To tackle these limitations, we propose a hybrid detection framework named Voxel-Pillar Fusion (VPF), which synergistically combines the unique strengths of both voxels and pillars. To be concrete, we first develop a sparse voxel-pillar encoder that encodes point clouds into voxel and pillar features through 3D and 2D sparse convolutions respectively, and then introduce the Sparse Fusion Layer (SFL), facilitating bidirectional interaction between sparse voxel and pillar features. Our computationally efficient, fully sparse method can be seamlessly integrated into both dense and sparse detectors. Leveraging this powerful yet straightforward representation, VPF delivers competitive performance, achieving real-time inference speeds on the nuScenes and Waymo Open Dataset",
    "checked": true,
    "id": "d29194b63599d0c13c0690268e29123a20e634ef",
    "semantic_title": "voxel or pillar: exploring efficient point cloud representation for 3d object detection",
    "citation_count": 1,
    "authors": [
      "Yuhao Huang",
      "Sanping Zhou",
      "Junjie Zhang",
      "Jinpeng Dong",
      "Nanning Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28019": {
    "title": "COMBAT: Alternated Training for Effective Clean-Label Backdoor Attacks",
    "volume": "main",
    "abstract": "Backdoor attacks pose a critical concern to the practice of using third-party data for AI development. The data can be poisoned to make a trained model misbehave when a predefined trigger pattern appears, granting the attackers illegal benefits. While most proposed backdoor attacks are dirty-label, clean-label attacks are more desirable by keeping data labels unchanged to dodge human inspection. However, designing a working clean-label attack is a challenging task, and existing clean-label attacks show underwhelming performance. In this paper, we propose a novel mechanism to develop clean-label attacks with outstanding attack performance. The key component is a trigger pattern generator, which is trained together with a surrogate model in an alternating manner. Our proposed mechanism is flexible and customizable, allowing different backdoor trigger types and behaviors for either single or multiple target labels. Our backdoor attacks can reach near-perfect attack success rates and bypass all state-of-the-art backdoor defenses, as illustrated via comprehensive experiments on standard benchmark datasets. Our code is available at https://github.com/VinAIResearch/COMBAT",
    "checked": true,
    "id": "3fcc029ed4469bb30296228f07237b65a8b4e0c0",
    "semantic_title": "combat: alternated training for effective clean-label backdoor attacks",
    "citation_count": 2,
    "authors": [
      "Tran Huynh",
      "Dang Nguyen",
      "Tung Pham",
      "Anh Tran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28020": {
    "title": "MagiCapture: High-Resolution Multi-Concept Portrait Customization",
    "volume": "main",
    "abstract": "Large-scale text-to-image models including Stable Diffusion are capable of generating high-fidelity photorealistic portrait images. There is an active research area dedicated to personalizing these models, aiming to synthesize specific subjects or styles using provided sets of reference images. However, despite the plausible results from these personalization methods, they tend to produce images that often fall short of realism and are not yet on a commercially viable level. This is particularly noticeable in portrait image generation, where any unnatural artifact in human faces is easily discernible due to our inherent human bias. To address this, we introduce MagiCapture, a personalization method for integrating subject and style concepts to generate high-resolution portrait images using just a few subject and style references. For instance, given a handful of random selfies, our fine-tuned model can generate high-quality portrait images in specific styles, such as passport or profile photos. The main challenge with this task is the absence of ground truth for the composed concepts, leading to a reduction in the quality of the final output and an identity shift of the source subject. To address these issues, we present a novel Attention Refocusing loss coupled with auxiliary priors, both of which facilitate robust learning within this weakly supervised learning setting. Our pipeline also includes additional post-processing steps to ensure the creation of highly realistic outputs. MagiCapture outperforms other baselines in both quantitative and qualitative evaluations and can also be generalized to other non-human objects",
    "checked": true,
    "id": "f0410acf0c7c1e391023db24b3162ba11fc38d58",
    "semantic_title": "magicapture: high-resolution multi-concept portrait customization",
    "citation_count": 9,
    "authors": [
      "Junha Hyung",
      "Jaeyo Shin",
      "Jaegul Choo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28021": {
    "title": "Rethinking Peculiar Images by Diffusion Models: Revealing Local Minima's Role",
    "volume": "main",
    "abstract": "Recent significant advancements in diffusion models have revolutionized image generation, enabling the synthesis of highly realistic images with text-based guidance. These breakthroughs have paved the way for constructing datasets via generative artificial intelligence (AI), offering immense potential for various applications. However, two critical challenges hinder the widespread adoption of synthesized data: computational cost and the generation of peculiar images. While computational costs have improved through various approaches, the issue of peculiar image generation remains relatively unexplored. Existing solutions rely on heuristics, extra training, or AI-based post-processing to mitigate this problem. In this paper, we present a novel approach to address both issues simultaneously. We establish that both gradient descent and diffusion sampling are specific cases of the generalized expectation maximization algorithm. We hypothesize and empirically demonstrate that peculiar image generation is akin to the local minima problem in optimization. Inspired by optimization techniques, we apply naive momentum and positive-negative momentum to diffusion sampling. Last, we propose new metrics to evaluate the peculiarity. Experimental results show momentum effectively prevents peculiar image generation without extra computation",
    "checked": true,
    "id": "a8cd87b8f225325525f5a4ff9ef82259dfc4908d",
    "semantic_title": "rethinking peculiar images by diffusion models: revealing local minima's role",
    "citation_count": 0,
    "authors": [
      "Jinhyeok Jang",
      "Chan-Hyun Youn",
      "Minsu Jeon",
      "Changha Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28022": {
    "title": "ProxyDet: Synthesizing Proxy Novel Classes via Classwise Mixup for Open-Vocabulary Object Detection",
    "volume": "main",
    "abstract": "Open-vocabulary object detection (OVOD) aims to recognize novel objects whose categories are not included in the training set. In order to classify these unseen classes during training, many OVOD frameworks leverage the zero-shot capability of largely pretrained vision and language models, such as CLIP. To further improve generalization on the unseen novel classes, several approaches proposed to additionally train with pseudo region labeling on the external data sources that contain a substantial number of novel category labels beyond the existing training data. Albeit its simplicity, these pseudo-labeling methods still exhibit limited improvement with regard to the truly unseen novel classes that were not pseudo-labeled. In this paper, we present a novel, yet simple technique that helps generalization on the overall distribution of novel classes. Inspired by our observation that numerous novel classes reside within the convex hull constructed by the base (seen) classes in the CLIP embedding space, we propose to synthesize proxy-novel classes approximating novel classes via linear mixup between a pair of base classes. By training our detector with these synthetic proxy-novel classes, we effectively explore the embedding space of novel classes. The experimental results on various OVOD benchmarks such as LVIS and COCO demonstrate superior performance on novel classes compared to the other state-of-the-art methods. Code is available at https://github.com/clovaai/ProxyDet",
    "checked": true,
    "id": "f1a81194349bfe012b1c01a1fd0b2bcd66889b62",
    "semantic_title": "proxydet: synthesizing proxy novel classes via classwise mixup for open-vocabulary object detection",
    "citation_count": 3,
    "authors": [
      "Joonhyun Jeong",
      "Geondo Park",
      "Jayeon Yoo",
      "Hyungsik Jung",
      "Heesu Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28023": {
    "title": "A Diffusion Model with State Estimation for Degradation-Blind Inverse Imaging",
    "volume": "main",
    "abstract": "Solving the task of inverse imaging problems can restore unknown clean images from input measurements that have incomplete information. Utilizing powerful generative models, such as denoising diffusion models, could better tackle the ill-posed issues of inverse problems with the distribution prior of the unknown clean images. We propose a learnable state-estimator-based diffusion model to incorporate the measurements into the reconstruction process. Our method makes efficient use of the pre-trained diffusion models with computational feasibility compared to the conditional diffusion models, which need to be trained from scratch. In addition, our pipeline does not require explicit knowledge of the image degradation operator or make the assumption of its form, unlike many other works that use the pre-trained diffusion models at the test time. The experiments on three typical inverse imaging problems (both linear and non-linear), inpainting, deblurring, and JPEG compression restoration, have comparable results with the state-of-the-art methods",
    "checked": true,
    "id": "a8873bc9e9323d80f37c9d06d64492fbe9cbbb2d",
    "semantic_title": "a diffusion model with state estimation for degradation-blind inverse imaging",
    "citation_count": 0,
    "authors": [
      "Liya Ji",
      "Zhefan Rao",
      "Sinno Jialin Pan",
      "Chenyang Lei",
      "Qifeng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28024": {
    "title": "SSMG: Spatial-Semantic Map Guided Diffusion Model for Free-Form Layout-to-Image Generation",
    "volume": "main",
    "abstract": "Despite significant progress in Text-to-Image (T2I) generative models, even lengthy and complex text descriptions still struggle to convey detailed controls. In contrast, Layout-to-Image (L2I) generation, aiming to generate realistic and complex scene images from user-specified layouts, has risen to prominence. However, existing methods transform layout information into tokens or RGB images for conditional control in the generative process, leading to insufficient spatial and semantic controllability of individual instances. To address these limitations, we propose a novel Spatial-Semantic Map Guided (SSMG) diffusion model that adopts the feature map, derived from the layout, as guidance. Owing to rich spatial and semantic information encapsulated in well-designed feature maps, SSMG achieves superior generation quality with sufficient spatial and semantic controllability compared to previous works. Additionally, we propose the Relation-Sensitive Attention (RSA) and Location-Sensitive Attention (LSA) mechanisms. The former aims to model the relationships among multiple objects within scenes while the latter is designed to heighten the model's sensitivity to the spatial information embedded in the guidance. Extensive experiments demonstrate that SSMG achieves highly promising results, setting a new state-of-the-art across a range of metrics encompassing fidelity, diversity, and controllability",
    "checked": true,
    "id": "f1442ebd0c1619d190f893d79c9d064149c0c06a",
    "semantic_title": "ssmg: spatial-semantic map guided diffusion model for free-form layout-to-image generation",
    "citation_count": 6,
    "authors": [
      "Chengyou Jia",
      "Minnan Luo",
      "Zhuohang Dang",
      "Guang Dai",
      "Xiaojun Chang",
      "Mengmeng Wang",
      "Jingdong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28025": {
    "title": "TiMix: Text-Aware Image Mixing for Effective Vision-Language Pre-training",
    "volume": "main",
    "abstract": "Self-supervised Multi-modal Contrastive Learning (SMCL) remarkably advances modern Vision-Language Pre-training (VLP) models by aligning visual and linguistic modalities. Due to noises in web-harvested text-image pairs, however, scaling up training data volume in SMCL presents considerable obstacles in terms of computational cost and data inefficiency. To improve data efficiency in VLP, we propose Text-aware Image Mixing (TiMix), which integrates mix-based data augmentation techniques into SMCL, yielding significant performance improvements without significantly increasing computational overhead. We provide a theoretical analysis of TiMix from a mutual information (MI) perspective, showing that mixed data samples for cross-modal contrastive learning implicitly serve as a regularizer for the contrastive loss. The experimental results demonstrate that TiMix exhibits a comparable performance on downstream tasks, even with a reduced amount of training data and shorter training time, when benchmarked against existing methods. This work empirically and theoretically demonstrates the potential of data mixing for data-efficient and computationally viable VLP, benefiting broader VLP model adoption in practical scenarios. Our code is available on https://github.com/chaoyajiang/TiMiX/tree/main",
    "checked": true,
    "id": "c335be43056c9f7e239c80e8e78721eb562405f7",
    "semantic_title": "timix: text-aware image mixing for effective vision-language pre-training",
    "citation_count": 2,
    "authors": [
      "Chaoya Jiang",
      "Wei Ye",
      "Haiyang Xu",
      "Qinghao Ye",
      "Ming Yan",
      "Ji Zhang",
      "Shikun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28026": {
    "title": "Revealing the Proximate Long-Tail Distribution in Compositional Zero-Shot Learning",
    "volume": "main",
    "abstract": "Compositional Zero-Shot Learning (CZSL) aims to transfer knowledge from seen state-object pairs to novel unseen pairs. In this process, visual bias caused by the diverse interrelationship of state-object combinations blurs their visual features, hindering the learning of distinguishable class prototypes. Prevailing methods concentrate on disentangling states and objects directly from visual features, disregarding potential enhancements that could arise from a data viewpoint. Experimentally, we unveil the results caused by the above problem closely approximate the long-tailed distribution. As a solution, we transform CZSL into a proximate class imbalance problem. We mathematically deduce the role of class prior within the long-tailed distribution in CZSL. Building upon this insight, we incorporate visual bias caused by compositions into the classifier's training and inference by estimating it as a proximate class prior. This enhancement encourages the classifier to acquire more discernible class prototypes for each composition, thereby achieving more balanced predictions. Experimental results demonstrate that our approach elevates the model's performance to the state-of-the-art level, without introducing additional parameters",
    "checked": true,
    "id": "cd5f19ec0506eff3fd5dae32b236ae6595d4d3a5",
    "semantic_title": "revealing the proximate long-tail distribution in compositional zero-shot learning",
    "citation_count": 0,
    "authors": [
      "Chenyi Jiang",
      "Haofeng Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28027": {
    "title": "MWSIS: Multimodal Weakly Supervised Instance Segmentation with 2D Box Annotations for Autonomous Driving",
    "volume": "main",
    "abstract": "Instance segmentation is a fundamental research in computer vision, especially in autonomous driving. However, manual mask annotation for instance segmentation is quite time-consuming and costly. To address this problem, some prior works attempt to apply weakly supervised manner by exploring 2D or 3D boxes. However, no one has ever successfully segmented 2D and 3D instances simultaneously by only using 2D box annotations, which could further reduce the annotation cost by an order of magnitude. Thus, we propose a novel framework called Multimodal Weakly Supervised Instance Segmentation (MWSIS), which incorporates various fine-grained label correction modules for both 2D and 3D modalities, along with a new multimodal cross-supervision approach. In the 2D pseudo label generation branch, the Instance-based Pseudo Mask Generation (IPG) module utilizes predictions for self-supervised correction. Similarly, in the 3D pseudo label generation branch, the Spatial-based Pseudo Label Generation (SPG) module generates pseudo labels by incorporating the spatial prior information of the point cloud. To further refine the generated pseudo labels, the Point-based Voting Label Correction (PVC) module utilizes historical predictions for correction. Additionally, a Ring Segment-based Label Correction (RSC) module is proposed to refine the predictions by leveraging the depth prior information from the point cloud. Finally, the Consistency Sparse Cross-modal Supervision (CSCS) module reduces the inconsistency of multimodal predictions by response distillation. Particularly, transferring the 3D backbone to downstream tasks not only improves the performance of the 3D detectors, but also outperforms fully supervised instance segmentation with only 5% fully supervised annotations. On the Waymo dataset, the proposed framework demonstrates significant improvements over the baseline, especially achieving 2.59% mAP and 12.75% mAP increases for 2D and 3D instance segmentation tasks, respectively. The code is available at https://github.com/jiangxb98/mwsis-plugin",
    "checked": true,
    "id": "569e269e2e27919ab08c58c39fd4e2c3772ba171",
    "semantic_title": "mwsis: multimodal weakly supervised instance segmentation with 2d box annotations for autonomous driving",
    "citation_count": 0,
    "authors": [
      "Guangfeng Jiang",
      "Jun Liu",
      "Yuzhi Wu",
      "Wenlong Liao",
      "Tao He",
      "Pai Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28028": {
    "title": "Transferable Video Moment Localization by Moment-Guided Query Prompting",
    "volume": "main",
    "abstract": "Video moment localization stands as a crucial task within the realm of computer vision, entailing the identification of temporal moments in untrimmed videos that bear semantic relevance to the supplied natural language queries. This work delves into a relatively unexplored facet of the task: the transferability of video moment localization models. This concern is addressed by evaluating moment localization models within a cross-domain transfer setting. In this setup, we curate multiple datasets distinguished by substantial domain gaps. The model undergoes training on one of these datasets, while validation and testing are executed using the remaining datasets. To confront the challenges inherent in this scenario, we draw inspiration from the recently introduced large-scale pre-trained vision-language models. Our focus is on exploring how the strategic utilization of these resources can bolster the capabilities of a model designed for video moment localization. Nevertheless, the distribution of language queries in video moment localization usually diverges from the text used by pre-trained models, exhibiting distinctions in aspects such as length, content, expression, and more. To mitigate the gap, this work proposes a Moment-Guided Query Prompting (MGQP) method for video moment localization. Our key idea is to generate multiple distinct and complementary prompt primitives through stratification of the original queries. Our approach is comprised of a prompt primitive constructor, a multimodal prompt refiner, and a holistic prompt incorporator. We carry out extensive experiments on Charades-STA, TACoS, DiDeMo, and YouCookII datasets, and investigate the efficacy of the proposed method using various pre-trained models, such as CLIP, ActionCLIP, CLIP4Clip, and VideoCLIP. The experimental results demonstrate the effectiveness of our proposed method",
    "checked": true,
    "id": "d2074234484f4d257d1ae9bdbe923c60d8b6c500",
    "semantic_title": "transferable video moment localization by moment-guided query prompting",
    "citation_count": 0,
    "authors": [
      "Hao Jiang",
      "Yang Yizhang",
      "Yadong Mu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28029": {
    "title": "In-Hand 3D Object Reconstruction from a Monocular RGB Video",
    "volume": "main",
    "abstract": "Our work aims to reconstruct a 3D object that is held and rotated by a hand in front of a static RGB camera. Previous methods that use implicit neural representations to recover the geometry of a generic hand-held object from multi-view images achieved compelling results in the visible part of the object. However, these methods falter in accurately capturing the shape within the hand-object contact region due to occlusion. In this paper, we propose a novel method that deals with surface reconstruction under occlusion by incorporating priors of 2D occlusion elucidation and physical contact constraints. For the former, we introduce an object amodal completion network to infer the 2D complete mask of objects under occlusion. To ensure the accuracy and view consistency of the predicted 2D amodal masks, we devise a joint optimization method for both amodal mask refinement and 3D reconstruction. For the latter, we impose penetration and attraction constraints on the local geometry in contact regions. We evaluate our approach on HO3D and HOD datasets and demonstrate that it outperforms the state-of-the-art methods in terms of reconstruction surface quality, with an improvement of 52% on HO3D and 20% on HOD. Project webpage: https://east-j.github.io/ihor",
    "checked": true,
    "id": "5e048334ee6e2d0977bec32f697abf80aed58ac0",
    "semantic_title": "in-hand 3d object reconstruction from a monocular rgb video",
    "citation_count": 1,
    "authors": [
      "Shijian Jiang",
      "Qi Ye",
      "Rengan Xie",
      "Yuchi Huo",
      "Xiang Li",
      "Yang Zhou",
      "Jiming Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28030": {
    "title": "AACP: Aesthetics Assessment of Children's Paintings Based on Self-Supervised Learning",
    "volume": "main",
    "abstract": "The Aesthetics Assessment of Children's Paintings (AACP) is an important branch of the image aesthetics assessment (IAA), playing a significant role in children's education. This task presents unique challenges, such as limited available data and the requirement for evaluation metrics from multiple perspectives. However, previous approaches have relied on training large datasets and subsequently providing an aesthetics score to the image, which is not applicable to AACP. To solve this problem, we construct an aesthetics assessment dataset of children's paintings and a model based on self-supervised learning. 1) We build a novel dataset composed of two parts: the first part contains more than 20k unlabeled images of children's paintings; the second part contains 1.2k images of children's paintings, and each image contains eight attributes labeled by multiple design experts. 2) We design a pipeline that includes a feature extraction module, perception modules and a disentangled evaluation module. 3) We conduct both qualitative and quantitative experiments to compare our model's performance with five other methods using the AACP dataset. Our experiments reveal that our method can accurately capture aesthetic features and achieve state-of-the-art performance",
    "checked": true,
    "id": "816342f5da41cd1b94b7b973cbc8cfc95ec0f3e6",
    "semantic_title": "aacp: aesthetics assessment of children's paintings based on self-supervised learning",
    "citation_count": 0,
    "authors": [
      "Shiqi Jiang",
      "Ning Li",
      "Chen Shi",
      "Liping Guo",
      "Changbo Wang",
      "Chenhui Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28031": {
    "title": "Exploring Self- and Cross-Triplet Correlations for Human-Object Interaction Detection",
    "volume": "main",
    "abstract": "Human-Object Interaction (HOI) detection plays a vital role in scene understanding, which aims to predict the HOI triplet in the form of . Existing methods mainly extract multi-modal features (e.g., appearance, object semantics, human pose) and then fuse them together to directly predict HOI triplets. However, most of these methods focus on seeking for self-triplet aggregation, but ignore the potential cross-triplet dependencies, resulting in ambiguity of action prediction. In this work, we propose to explore Self- and Cross-Triplet Correlations (SCTC) for HOI detection. Specifically, we regard each triplet proposal as a graph where Human, Object represent nodes and Action indicates edge, to aggregate self-triplet correlation. Also, we try to explore cross-triplet dependencies by jointly considering instance-level, semantic-level, and layout-level relations. Besides, we leverage the CLIP model to assist our SCTC obtain interaction-aware feature by knowledge distillation, which provides useful action clues for HOI detection. Extensive experiments on HICO-DET and V-COCO datasets verify the effectiveness of our proposed SCTC",
    "checked": true,
    "id": "b1a8b29ef7e5202a7998e529abfaa919f12b63d2",
    "semantic_title": "exploring self- and cross-triplet correlations for human-object interaction detection",
    "citation_count": 0,
    "authors": [
      "Weibo Jiang",
      "Weihong Ren",
      "Jiandong Tian",
      "Liangqiong Qu",
      "Zhiyong Wang",
      "Honghai Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28032": {
    "title": "Comprehensive Visual Grounding for Video Description",
    "volume": "main",
    "abstract": "The grounding accuracy of existing video captioners is still behind the expectation. The majority of existing methods perform grounded video captioning on sparse entity annotations, whereas the captioning accuracy often suffers from degenerated object appearances on the annotated area such as motion blur and video defocus. Moreover, these methods seldom consider the complex interactions among entities. In this paper, we propose a comprehensive visual grounding network to improve video captioning, by explicitly linking the entities and actions to the visual clues across the video frames. Specifically, the network consists of spatial-temporal entity grounding and action grounding. The proposed entity grounding encourages the attention mechanism to focus on informative spatial areas across video frames, albeit the entity is annotated in only one frame of a video. The action grounding dynamically associates the verbs to related subjects and the corresponding context, which keeps fine-grained spatial and temporal details for action prediction. Both entity grounding and action grounding are formulated as a unified task guided by a soft grounding supervision, which brings architecture simplification and improves training efficiency as well. We conduct extensive experiments on two challenging datasets, and demonstrate significant performance improvements of +2.3 CIDEr on ActivityNet-Entities and +2.2 CIDEr on MSR-VTT compared to state-of-the-arts",
    "checked": true,
    "id": "880279bee3b62c9c515e0d18b0147d1b0eed5d7f",
    "semantic_title": "comprehensive visual grounding for video description",
    "citation_count": 0,
    "authors": [
      "Wenhui Jiang",
      "Yibo Cheng",
      "Linxin Liu",
      "Yuming Fang",
      "Yuxin Peng",
      "Yang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28033": {
    "title": "Far3D: Expanding the Horizon for Surround-View 3D Object Detection",
    "volume": "main",
    "abstract": "Recently 3D object detection from surround-view images has made notable advancements with its low deployment cost. However, most works have primarily focused on close perception range while leaving long-range detection less explored. Expanding existing methods directly to cover long distances poses challenges such as heavy computation costs and unstable convergence. To address these limitations, this paper proposes a novel sparse query-based framework, dubbed Far3D. By utilizing high-quality 2D object priors, we generate 3D adaptive queries that complement the 3D global queries. To efficiently capture discriminative features across different views and scales for long-range objects, we introduce a perspective-aware aggregation module. Additionally, we propose a range-modulated 3D denoising approach to address query error propagation and mitigate convergence issues in long-range tasks. Significantly, Far3D demonstrates SoTA performance on the challenging Argoverse 2 dataset, covering a wide range of 150 meters, surpassing several LiDAR-based approaches. The code is available at https://github.com/megvii-research/Far3D",
    "checked": true,
    "id": "93c4cac28873829a8de48942c286044bf89cc037",
    "semantic_title": "far3d: expanding the horizon for surround-view 3d object detection",
    "citation_count": 17,
    "authors": [
      "Xiaohui Jiang",
      "Shuailin Li",
      "Yingfei Liu",
      "Shihao Wang",
      "Fan Jia",
      "Tiancai Wang",
      "Lijin Han",
      "Xiangyu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28034": {
    "title": "Delving into Multimodal Prompting for Fine-Grained Visual Classification",
    "volume": "main",
    "abstract": "Fine-grained visual classification (FGVC) involves categorizing fine subdivisions within a broader category, which poses challenges due to subtle inter-class discrepancies and large intra-class variations. However, prevailing approaches primarily focus on uni-modal visual concepts. Recent advancements in pre-trained vision-language models have demonstrated remarkable performance in various high-level vision tasks, yet the applicability of such models to FGVC tasks remains uncertain. In this paper, we aim to fully exploit the capabilities of cross-modal description to tackle FGVC tasks and propose a novel multimodal prompting solution, denoted as MP-FGVC, based on the contrastive language-image pertaining (CLIP) model. Our MP-FGVC comprises a multimodal prompts scheme and a multimodal adaptation scheme. The former includes Subcategory-specific Vision Prompt (SsVP) and Discrepancy-aware Text Prompt (DaTP), which explicitly highlights the subcategory-specific discrepancies from the perspectives of both vision and language. The latter aligns the vision and text prompting elements in a common semantic space, facilitating cross-modal collaborative reasoning through a Vision-Language Fusion Module (VLFM) for further improvement on FGVC. Moreover, we tailor a two-stage optimization strategy for MP-FGVC to fully leverage the pre-trained CLIP model and expedite efficient adaptation for FGVC. Extensive experiments conducted on four FGVC datasets demonstrate the effectiveness of our MP-FGVC",
    "checked": true,
    "id": "11e3efa08b5db1a8958dfe8119593a4d3f18796a",
    "semantic_title": "delving into multimodal prompting for fine-grained visual classification",
    "citation_count": 3,
    "authors": [
      "Xin Jiang",
      "Hao Tang",
      "Junyao Gao",
      "Xiaoyu Du",
      "Shengfeng He",
      "Zechao Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28035": {
    "title": "MCA: Moment Channel Attention Networks",
    "volume": "main",
    "abstract": "Channel attention mechanisms endeavor to recalibrate channel weights to enhance representation abilities of networks. However, mainstream methods often rely solely on global average pooling as the feature squeezer, which significantly limits the overall potential of models. In this paper, we investigate the statistical moments of feature maps within a neural network. Our findings highlight the critical role of high-order moments in enhancing model capacity. Consequently, we introduce a flexible and comprehensive mechanism termed Extensive Moment Aggregation (EMA) to capture the global spatial context. Building upon this mechanism, we propose the Moment Channel Attention (MCA) framework, which efficiently incorporates multiple levels of moment-based information while minimizing additional computation costs through our Cross Moment Convolution (CMC) module. The CMC module via channel-wise convolution layer to capture multiple order moment information as well as cross channel features. The MCA block is designed to be lightweight and easily integrated into a variety of neural network architectures. Experimental results on classical image classification, object detection, and instance segmentation tasks demonstrate that our proposed method achieves state-of-the-art results, outperforming existing channel attention methods",
    "checked": true,
    "id": "e0f4ef66e1c53b8034d34840d1375cbef7e8dfd7",
    "semantic_title": "mca: moment channel attention networks",
    "citation_count": 0,
    "authors": [
      "Yangbo Jiang",
      "Zhiwei Jiang",
      "Le Han",
      "Zenan Huang",
      "Nenggan Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28036": {
    "title": "Towards Robust Image Stitching: An Adaptive Resistance Learning against Compatible Attacks",
    "volume": "main",
    "abstract": "Image stitching seamlessly integrates images captured from varying perspectives into a single wide field-of-view image. Such integration not only broadens the captured scene but also augments holistic perception in computer vision applications. Given a pair of captured images, subtle perturbations and distortions which go unnoticed by the human visual system tend to attack the correspondence matching, impairing the performance of image stitching algorithms. In light of this challenge, this paper presents the first attempt to improve the robustness of image stitching against adversarial attacks. Specifically, we introduce a stitching-oriented attack (SoA), tailored to amplify the alignment loss within overlapping regions, thereby targeting the feature matching procedure. To establish an attack resistant model, we delve into the robustness of stitching architecture and develop an adaptive adversarial training (AAT) to balance attack resistance with stitching precision. In this way, we relieve the gap between the routine adversarial training and benign models, ensuring resilience without quality compromise. Comprehensive evaluation across real-world and synthetic datasets validate the deterioration of SoA on stitching performance. Furthermore, AAT emerges as a more robust solution against adversarial perturbations, delivering superior stitching results. Code is available at: https://github.com/Jzy2017/TRIS",
    "checked": true,
    "id": "3ac562d89872a03e0f4ede662731132e891be26e",
    "semantic_title": "towards robust image stitching: an adaptive resistance learning against compatible attacks",
    "citation_count": 0,
    "authors": [
      "Zhiying Jiang",
      "Xingyuan Li",
      "Jinyuan Liu",
      "Xin Fan",
      "Risheng Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28037": {
    "title": "Instance-Aware Multi-Camera 3D Object Detection with Structural Priors Mining and Self-Boosting Learning",
    "volume": "main",
    "abstract": "Camera-based bird-eye-view (BEV) perception paradigm has made significant progress in the autonomous driving field. Under such a paradigm, accurate BEV representation construction relies on reliable depth estimation for multi-camera images. However, existing approaches exhaustively predict depths for every pixel without prioritizing objects, which are precisely the entities requiring detection in the 3D space. To this end, we propose IA-BEV, which integrates image-plane instance awareness into the depth estimation process within a BEV-based detector. First, a category-specific structural priors mining approach is proposed for enhancing the efficacy of monocular depth generation. Besides, a self-boosting learning strategy is further proposed to encourage the model to place more emphasis on challenging objects in computation-expensive temporal stereo matching. Together they provide advanced depth estimation results for high-quality BEV features construction, benefiting the ultimate 3D detection. The proposed method achieves state-of-the-art performances on the challenging nuScenes benchmark, and extensive experimental results demonstrate the effectiveness of our designs",
    "checked": true,
    "id": "5343856c6bd7b13c282918b933ac69b8a0b41fe8",
    "semantic_title": "instance-aware multi-camera 3d object detection with structural priors mining and self-boosting learning",
    "citation_count": 2,
    "authors": [
      "Yang Jiao",
      "Zequn Jie",
      "Shaoxiang Chen",
      "Lechao Cheng",
      "Jingjing Chen",
      "Lin Ma",
      "Yu-Gang Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28038": {
    "title": "PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation",
    "volume": "main",
    "abstract": "Automatic medical report generation (MRG) is of great research value as it has the potential to relieve radiologists from the heavy burden of report writing. Despite recent advancements, accurate MRG remains challenging due to the need for precise clinical understanding and disease identification. Moreover, the imbalanced distribution of diseases makes the challenge even more pronounced, as rare diseases are underrepresented in training data, making their diagnosis unreliable. To address these challenges, we propose diagnosis-driven prompts for medical report generation (PromptMRG), a novel framework that aims to improve the diagnostic accuracy of MRG with the guidance of diagnosis-aware prompts. Specifically, PromptMRG is based on encoder-decoder architecture with an extra disease classification branch. When generating reports, the diagnostic results from the classification branch are converted into token prompts to explicitly guide the generation process. To further improve the diagnostic accuracy, we design cross-modal feature enhancement, which retrieves similar reports from the database to assist the diagnosis of a query image by leveraging the knowledge from a pre-trained CLIP. Moreover, the disease imbalanced issue is addressed by applying an adaptive logit-adjusted loss to the classification branch based on the individual learning status of each disease, which overcomes the barrier of text decoder's inability to manipulate disease distributions. Experiments on two MRG benchmarks show the effectiveness of the proposed method, where it obtains state-of-the-art clinical efficacy performance on both datasets",
    "checked": true,
    "id": "9dbc47793bc136e4728e3c4717db6694700ef344",
    "semantic_title": "promptmrg: diagnosis-driven prompts for medical report generation",
    "citation_count": 14,
    "authors": [
      "Haibo Jin",
      "Haoxuan Che",
      "Yi Lin",
      "Hao Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28039": {
    "title": "PCE-Palm: Palm Crease Energy Based Two-Stage Realistic Pseudo-Palmprint Generation",
    "volume": "main",
    "abstract": "The lack of large-scale data seriously hinders the development of palmprint recognition. Recent approaches address this issue by generating large-scale realistic pseudo palmprints from Bézier curves. However, the significant difference between Bézier curves and real palmprints limits their effectiveness. In this paper, we divide the Bézier-Real difference into creases and texture differences, thus reducing the generation difficulty. We introduce a new palm crease energy (PCE) domain as a bridge from Bézier curves to real palmprints and propose a two-stage generation model. The first stage generates PCE images (realistic creases) from Bézier curves, and the second stage outputs realistic palmprints (realistic texture) with PCE images as input. In addition, we also design a lightweight plug-and-play line feature enhancement block to facilitate domain transfer and improve recognition performance. Extensive experimental results demonstrate that the proposed method surpasses state-of-the-art methods. Under extremely few data settings like 40 IDs (only 2.5% of the total training set), our model achieves a 29% improvement over RPG-Palm and outperforms ArcFace with 100% training set by more than 6% in terms of TAR@FAR=1e-6",
    "checked": true,
    "id": "d64aa6d7564a1e982cdd5db89469e0d3dd04023a",
    "semantic_title": "pce-palm: palm crease energy based two-stage realistic pseudo-palmprint generation",
    "citation_count": 1,
    "authors": [
      "Jianlong Jin",
      "Lei Shen",
      "Ruixin Zhang",
      "Chenglong Zhao",
      "Ge Jin",
      "Jingyun Zhang",
      "Shouhong Ding",
      "Yang Zhao",
      "Wei Jia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28040": {
    "title": "SwiftPillars: High-Efficiency Pillar Encoder for Lidar-Based 3D Detection",
    "volume": "main",
    "abstract": "Lidar-based 3D Detection is one of the significant components of Autonomous Driving. However, current methods over-focus on improving the performance of 3D Lidar perception, which causes the architecture of networks becoming complicated and hard to deploy. Thus, the methods are difficult to apply in Autonomous Driving for real-time processing. In this paper, we propose a high-efficiency network, SwiftPillars, which includes Swift Pillar Encoder (SPE) and Multi-scale Aggregation Decoder (MAD). The SPE is constructed by a concise Dual-attention Module with lightweight operators. The Dual-attention Module utilizes feature pooling, matrix multiplication, etc. to speed up point-wise and channel-wise attention extraction and fusion. The MAD interconnects multiple scale features extracted by SPE with minimal computational cost to leverage performance. In our experiments, our proposal accomplishes 61.3% NDS and 53.2% mAP in nuScenes dataset. In addition, we evaluate inference time on several platforms (P4, T4, A2, MLU370, RTX3080), where SwiftPillars achieves up to 13.3ms (75FPS) on NVIDIA Tesla T4. Compared with PointPillars, SwiftPillars is on average 26.58% faster in inference speed with equivalent GPUs and a higher mAP of approximately 3.2% in the nuScenes dataset",
    "checked": true,
    "id": "fe64b08c16231505abdb1b5cf25ffcffbcf9ccff",
    "semantic_title": "swiftpillars: high-efficiency pillar encoder for lidar-based 3d detection",
    "citation_count": 0,
    "authors": [
      "Xin Jin",
      "Kai Liu",
      "Cong Ma",
      "Ruining Yang",
      "Fei Hui",
      "Wei Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28041": {
    "title": "DeS3: Adaptive Attention-Driven Self and Soft Shadow Removal Using ViT Similarity",
    "volume": "main",
    "abstract": "Removing soft and self shadows that lack clear boundaries from a single image is still challenging. Self shadows are shadows that are cast on the object itself. Most existing methods rely on binary shadow masks, without considering the ambiguous boundaries of soft and self shadows. In this paper, we present DeS3, a method that removes hard, soft and self shadows based on adaptive attention and ViT similarity. Our novel ViT similarity loss utilizes features extracted from a pre-trained Vision Transformer. This loss helps guide the reverse sampling towards recovering scene structures. Our adaptive attention is able to differentiate shadow regions from the underlying objects, as well as shadow regions from the object casting the shadow. This capability enables DeS3 to better recover the structures of objects even when they are partially occluded by shadows. Different from existing methods that rely on constraints during the training phase, we incorporate the ViT similarity during the sampling stage. Our method outperforms state-of-the-art methods on the SRD, AISTD, LRSS, USR and UIUC datasets, removing hard, soft, and self shadows robustly. Specifically, our method outperforms the SOTA method by 16% of the RMSE of the whole image on the LRSS dataset",
    "checked": true,
    "id": "de8cfa46816293b2c50b8260366cbb82807caf7e",
    "semantic_title": "des3: adaptive attention-driven self and soft shadow removal using vit similarity",
    "citation_count": 4,
    "authors": [
      "Yeying Jin",
      "Wei Ye",
      "Wenhan Yang",
      "Yuan Yuan",
      "Robby T. Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28042": {
    "title": "AMD: Anatomical Motion Diffusion with Interpretable Motion Decomposition and Fusion",
    "volume": "main",
    "abstract": "Generating realistic human motion sequences from text descriptions is a challenging task that requires capturing the rich expressiveness of both natural language and human motion. Recent advances in diffusion models have enabled significant progress in human motion synthesis. However, existing methods struggle to handle text inputs that describe complex or long motions. In this paper, we propose the Adaptable Motion Diffusion (AMD) model, which leverages a Large Language Model (LLM) to parse the input text into a sequence of concise and interpretable anatomical scripts that correspond to the target motion. This process exploits the LLM's ability to provide anatomical guidance for complex motion synthesis. We then devise a two-branch fusion scheme that balances the influence of the input text and the anatomical scripts on the inverse diffusion process, which adaptively ensures the semantic fidelity and diversity of the synthesized motion. Our method can effectively handle texts with complex or long motion descriptions, where existing methods often fail. Experiments on datasets with relatively more complex motions, such as CLCD1 and CLCD2, demonstrate that our AMD significantly outperforms existing state-of-the-art models",
    "checked": true,
    "id": "5cba010c96c3b050a5e58641b9455aa6a745256b",
    "semantic_title": "amd: anatomical motion diffusion with interpretable motion decomposition and fusion",
    "citation_count": 3,
    "authors": [
      "Beibei Jing",
      "Youjia Zhang",
      "Zikai Song",
      "Junqing Yu",
      "Wei Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28043": {
    "title": "Retrieval-Augmented Primitive Representations for Compositional Zero-Shot Learning",
    "volume": "main",
    "abstract": "Compositional zero-shot learning (CZSL) aims to recognize unseen attribute-object compositions by learning from seen compositions. Composing the learned knowledge of seen primitives, i.e., attributes or objects, into novel compositions is critical for CZSL. In this work, we propose to explicitly retrieve knowledge of seen primitives for compositional zero-shot learning. We present a retrieval-augmented method, which augments standard multi-path classification methods with two retrieval modules. Specifically, we construct two databases storing the attribute and object representations of training images, respectively. For an input training/testing image, we use two retrieval modules to retrieve representations of training images with the same attribute and object, respectively. The primitive representations of the input image are augmented by using the retrieved representations, for composition recognition. By referencing semantically similar images, the proposed method is capable of recalling knowledge of seen primitives for compositional generalization. Experiments on three widely-used datasets show the effectiveness of the proposed method",
    "checked": true,
    "id": "b2cb7d8df63d395593fccd6799db3efab7efbeea",
    "semantic_title": "retrieval-augmented primitive representations for compositional zero-shot learning",
    "citation_count": 1,
    "authors": [
      "Chenchen Jing",
      "Yukun Li",
      "Hao Chen",
      "Chunhua Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28044": {
    "title": "CrossBind: Collaborative Cross-Modal Identification of Protein Nucleic-Acid-Binding Residues",
    "volume": "main",
    "abstract": "Accurate identification of protein nucleic acid binding residues poses a significant challenge with important implications for various biological processes and drug design. Many typical computational methods for protein analysis rely on a single model that could ignore either the semantic context of the protein or the global 3D geometric information. Consequently, these approaches may result in incomplete or inaccurate protein analysis. To address the above issue, in this paper, we present CrossBind, a novel collaborative cross modal approach for identifying binding residues by exploiting both protein geometric structure and its sequence prior knowledge extracted from a large scale protein language model. Specifically, our multi modal approach leverages a contrastive learning technique and atom wise attention to capture the positional relationships between atoms and residues, thereby incorporating fine grained local geometric knowledge, for better binding residue prediction. Extensive experimental results demonstrate that our approach outperforms the next best state of the art methods, GraphSite and GraphBind, on DNA and RNA datasets by 10.8/17.3% in terms of the harmonic mean of precision and recall (F1 Score) and 11.9/24.8% in Matthews correlation coefficient (MCC), respectively. We release the code at https://github.com/BEAM-Labs/CrossBind",
    "checked": true,
    "id": "8ec37c9732ffb324c162cec6e0cb14d324a31381",
    "semantic_title": "crossbind: collaborative cross-modal identification of protein nucleic-acid-binding residues",
    "citation_count": 0,
    "authors": [
      "Linglin Jing",
      "Sheng Xu",
      "Yifan Wang",
      "Yuzhe Zhou",
      "Tao Shen",
      "Zhigang Ji",
      "Hui Fang",
      "Zhen Li",
      "Siqi Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28045": {
    "title": "X4D-SceneFormer: Enhanced Scene Understanding on 4D Point Cloud Videos through Cross-Modal Knowledge Transfer",
    "volume": "main",
    "abstract": "The field of 4D point cloud understanding is rapidly developing with the goal of analyzing dynamic 3D point cloud sequences. However, it remains a challenging task due to the sparsity and lack of texture in point clouds. Moreover, the irregularity of point cloud poses a difficulty in aligning temporal information within video sequences. To address these issues, we propose a novel cross-modal knowledge transfer framework, called X4D-SceneFormer. This framework enhances 4D-Scene understanding by transferring texture priors from RGB sequences using a Transformer architecture with temporal relationship mining. Specifically, the framework is designed with a dual-branch architecture, consisting of an 4D point cloud transformer and a Gradient-aware Image Transformer (GIT). The GIT combines visual texture and temporal correlation features to offer rich semantics and dynamics for better point cloud representation. During training, we employ multiple knowledge transfer techniques, including temporal consistency losses and masked self-attention, to strengthen the knowledge transfer between modalities. This leads to enhanced performance during inference using single-modal 4D point cloud inputs. Extensive experiments demonstrate the superior performance of our framework on various 4D point cloud video understanding tasks, including action recognition, action segmentation and semantic segmentation. The results achieve 1st places, i.e., 85.3% (+7.9%) accuracy and 47.3% (+5.0%) mIoU for 4D action segmentation and semantic segmentation, on the HOI4D challenge, outperforming previous state-of-the-art by a large margin. We release the code at https://github.com/jinglinglingling/X4D",
    "checked": true,
    "id": "dfd491548ac65ba20f25033849b64adf32f17bca",
    "semantic_title": "x4d-sceneformer: enhanced scene understanding on 4d point cloud videos through cross-modal knowledge transfer",
    "citation_count": 1,
    "authors": [
      "Linglin Jing",
      "Ying Xue",
      "Xu Yan",
      "Chaoda Zheng",
      "Dong Wang",
      "Ruimao Zhang",
      "Zhigang Wang",
      "Hui Fang",
      "Bin Zhao",
      "Zhen Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28046": {
    "title": "VVS: Video-to-Video Retrieval with Irrelevant Frame Suppression",
    "volume": "main",
    "abstract": "In content-based video retrieval (CBVR), dealing with large-scale collections, efficiency is as important as accuracy; thus, several video-level feature-based studies have actively been conducted. Nevertheless, owing to the severe difficulty of embedding a lengthy and untrimmed video into a single feature, these studies have been insufficient for accurate retrieval compared to frame-level feature-based studies. In this paper, we show that appropriate suppression of irrelevant frames can provide insight into the current obstacles of the video-level approaches. Furthermore, we propose a Video-to-Video Suppression network (VVS) as a solution. VVS is an end-to-end framework that consists of an easy distractor elimination stage to identify which frames to remove and a suppression weight generation stage to determine the extent to suppress the remaining frames. This structure is intended to effectively describe an untrimmed video with varying content and meaningless information. Its efficacy is proved via extensive experiments, and we show that our approach is not only state-of-the-art in video-level approaches but also has a fast inference time despite possessing retrieval capabilities close to those of frame-level approaches. Code is available at https://github.com/sejong-rcv/VVS",
    "checked": true,
    "id": "1b642a398e7925cd169bbeaf0d50d28c26bf2a5c",
    "semantic_title": "vvs: video-to-video retrieval with irrelevant frame suppression",
    "citation_count": 2,
    "authors": [
      "Won Jo",
      "Geuntaek Lim",
      "Gwangjin Lee",
      "Hyunwoo Kim",
      "Byungsoo Ko",
      "Yukyung Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28047": {
    "title": "Rethinking Robustness of Model Attributions",
    "volume": "main",
    "abstract": "For machine learning models to be reliable and trustworthy, their decisions must be interpretable. As these models find increasing use in safety-critical applications, it is important that not just the model predictions but also their explanations (as feature attributions) be robust to small human-imperceptible input perturbations. Recent works have shown that many attribution methods are fragile and have proposed improvements in either these methods or the model training. We observe two main causes for fragile attributions: first, the existing metrics of robustness (e.g., top-k intersection) overpenalize even reasonable local shifts in attribution, thereby making random perturbations to appear as a strong attack, and second, the attribution can be concentrated in a small region even when there are multiple important parts in an image. To rectify this, we propose simple ways to strengthen existing metrics and attribution methods that incorporate locality of pixels in robustness metrics and diversity of pixel locations in attributions. Towards the role of model training in attributional robustness, we empirically observe that adversarially trained models have more robust attributions on smaller datasets, however, this advantage disappears in larger datasets. Code is made available at https://github.com/ksandeshk/LENS",
    "checked": true,
    "id": "ba30fb2e9fa8134abe9bf331a39338e542edfbe9",
    "semantic_title": "rethinking robustness of model attributions",
    "citation_count": 0,
    "authors": [
      "Sandesh Kamath",
      "Sankalp Mittal",
      "Amit Deshpande",
      "Vineeth N Balasubramanian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28048": {
    "title": "Cross-Constrained Progressive Inference for 3D Hand Pose Estimation with Dynamic Observer-Decision-Adjuster Networks",
    "volume": "main",
    "abstract": "Generalization is very important for pose estimation, especially for 3D pose estimation where small changes in the 2D images could trigger structural changes in the 3D space. To achieve generalization, the system needs to have the capability of detecting estimation errors by double-checking the projection coherence between the 3D and 2D spaces and adapting its network inference process based on this feedback. Current pose estimation is one-time feed-forward and lacks the capability to gather feedback and adapt the inference outcome. To address this problem, we propose to explore the concept of progressive inference where the network learns an observer to continuously detect the prediction error based on constraints matching, as well as an adjuster to refine its inference outcome based on these constraints errors. Within the context of 3D hand pose estimation, we find that this observer-adjuster design is relatively unstable since the observer is operating in the 2D image domain while the adjuster is operating in the 3D domain. To address this issue, we propose to construct two sets of observers-adjusters with complementary constraints from different perspectives. They operate in a dynamic sequential manner controlled by a decision network to progressively improve the 3D pose estimation. We refer to this method as Cross-Constrained Progressive Inference (CCPI). Our extensive experimental results on FreiHAND and HO-3D benchmark datasets demonstrate that the proposed CCPI method is able to significantly improve the generalization capability and performance of 3D hand pose estimation",
    "checked": true,
    "id": "28082160e77c2abdfec696b32369589e9433bf8e",
    "semantic_title": "cross-constrained progressive inference for 3d hand pose estimation with dynamic observer-decision-adjuster networks",
    "citation_count": 0,
    "authors": [
      "Zhehan Kan",
      "Xueting Hu",
      "Zihan Liao",
      "Ke Yu",
      "Zhihai He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28049": {
    "title": "Catch-Up Mix: Catch-Up Class for Struggling Filters in CNN",
    "volume": "main",
    "abstract": "Deep learning has made significant advances in computer vision, particularly in image classification tasks. Despite their high accuracy on training data, deep learning models often face challenges related to complexity and overfitting. One notable concern is that the model often relies heavily on a limited subset of filters for making predictions. This dependency can result in compromised generalization and an increased vulnerability to minor variations. While regularization techniques like weight decay, dropout, and data augmentation are commonly used to address this issue, they may not directly tackle the reliance on specific filters. Our observations reveal that the heavy reliance problem gets severe when slow-learning filters are deprived of learning opportunities due to fast-learning filters. Drawing inspiration from image augmentation research that combats over-reliance on specific image regions by removing and replacing parts of images, Our idea is to mitigate the problem of over-reliance on strong filters by substituting highly activated features. To this end, we present a novel method called Catch-up Mix, which provides learning opportunities to a wide range of filters during training, focusing on filters that may lag behind. By mixing activation maps with relatively lower norms, Catch-up Mix promotes the development of more diverse representations and reduces reliance on a small subset of filters. Experimental results demonstrate the superiority of our method in various vision classification datasets, providing enhanced robustness",
    "checked": true,
    "id": "8923db58bc7d920fb9a2245897ad7f7ac24e7239",
    "semantic_title": "catch-up mix: catch-up class for struggling filters in cnn",
    "citation_count": 1,
    "authors": [
      "Minsoo Kang",
      "Minkoo Kang",
      "Suhyun Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28050": {
    "title": "VLCounter: Text-Aware Visual Representation for Zero-Shot Object Counting",
    "volume": "main",
    "abstract": "Zero-Shot Object Counting~(ZSOC) aims to count referred instances of arbitrary classes in a query image without human-annotated exemplars. To deal with ZSOC, preceding studies proposed a two-stage pipeline: discovering exemplars and counting. However, there remains a challenge of vulnerability to error propagation of the sequentially designed two-stage process. In this work, we propose an one-stage baseline, Visual-Language Baseline (VLBase), exploring the implicit association of the semantic-patch embeddings of CLIP. Subsequently, we extend the VLBase to Visual-language Counter (VLCounter) by incorporating three modules devised to tailor VLBase for object counting. First, we introduce Semantic-conditioned Prompt Tuning (SPT) within the image encoder to acquire target-highlighted representations. Second, Learnable Affine Transformation (LAT) is employed to translate the semantic-patch similarity map to be appropriate for the counting task. Lastly, we transfer the layer-wisely encoded features to the decoder through Segment-aware Skip Connection (SaSC) to keep the generalization capability for unseen classes. Through extensive experiments on FSC147, CARPK, and PUCPR+, we demonstrate the benefits of our end-to-end framework, VLCounter. Code is available at https://github.com/seunggu0305/VLCounter",
    "checked": true,
    "id": "ebd49ede490d2cbd431bbf83790ee70b20c418fd",
    "semantic_title": "vlcounter: text-aware visual representation for zero-shot object counting",
    "citation_count": 3,
    "authors": [
      "Seunggu Kang",
      "WonJun Moon",
      "Euiyeon Kim",
      "Jae-Pil Heo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28051": {
    "title": "StegFormer: Rebuilding the Glory of Autoencoder-Based Steganography",
    "volume": "main",
    "abstract": "Image hiding aims to conceal one or more secret images within a cover image of the same resolution. Due to strict capacity requirements, image hiding is commonly called large-capacity steganography. In this paper, we propose StegFormer, a novel autoencoder-based image-hiding model. StegFormer can conceal one or multiple secret images within a cover image of the same resolution while preserving the high visual quality of the stego image. In addition, to mitigate the limitations of current steganographic models in real-world scenarios, we propose a normalizing training strategy and a restrict loss to improve the reliability of the steganographic models under realistic conditions. Furthermore, we propose an efficient steganographic capacity expansion method to increase the capacity of steganography and enhance the efficiency of secret communication. Through this approach, we can increase the relative payload of StegFormer to 96 bits per pixel without any training strategy modifications. Experiments demonstrate that our StegFormer outperforms existing state-of-the-art (SOTA) models. In the case of single-image steganography, there is an improvement of more than 3 dB and 5 dB in PSNR for secret/recovery image pairs and cover/stego image pairs",
    "checked": true,
    "id": "9f1193ce9320b3ffe1dd262b9426495b45f6d8ed",
    "semantic_title": "stegformer: rebuilding the glory of autoencoder-based steganography",
    "citation_count": 0,
    "authors": [
      "Xiao  Ke",
      "Huanqi Wu",
      "Wenzhong Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28052": {
    "title": "Expediting Contrastive Language-Image Pretraining via Self-Distilled Encoders",
    "volume": "main",
    "abstract": "Recent advances in vision language pretraining (VLP) have been largely attributed to the large-scale data collected from the web. However, uncurated dataset contains weakly correlated image-text pairs, causing data inefficiency. To address the issue, knowledge distillation have been explored at the expense of extra image and text momentum encoders to generate teaching signals for misaligned image-text pairs. In this paper, our goal is to resolve the misalignment problem with an efficient distillation framework. To this end, we propose ECLIPSE: Expediting Contrastive Language-Image Pretraining with Self-distilled Encoders. ECLIPSE features a distinctive distillation architecture wherein a shared text encoder is utilized between an online image encoder and a momentum image encoder. This strategic design choice enables the distillation to operate within a unified projected space of text embedding, resulting in better performance. Based on the unified text embedding space, ECLIPSE compensates for the additional computational cost of the momentum image encoder by expediting the online image encoder. Through our extensive experiments, we validate that there is a sweet spot between expedition and distillation where the partial view from the expedited online image encoder interacts complementarily with the momentum teacher. As a result, ECLIPSE outperforms its counterparts while achieving substantial acceleration in inference speed",
    "checked": true,
    "id": "8a0bc3ea8dbf6016e8967cab80b3fce191d019f8",
    "semantic_title": "expediting contrastive language-image pretraining via self-distilled encoders",
    "citation_count": 0,
    "authors": [
      "Bumsoo Kim",
      "Jinhyung Kim",
      "Yeonsik Jo",
      "Seung Hwan Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28053": {
    "title": "Weakly Supervised Semantic Segmentation for Driving Scenes",
    "volume": "main",
    "abstract": "State-of-the-art techniques in weakly-supervised semantic segmentation (WSSS) using image-level labels exhibit severe performance degradation on driving scene datasets such as Cityscapes. To address this challenge, we develop a new WSSS framework tailored to driving scene datasets. Based on extensive analysis of dataset characteristics, we employ Contrastive Language-Image Pre-training (CLIP) as our baseline to obtain pseudo-masks. However, CLIP introduces two key challenges: (1) pseudo-masks from CLIP lack in representing small object classes, and (2) these masks contain notable noise. We propose solutions for each issue as follows. (1) We devise Global-Local View Training that seamlessly incorporates small-scale patches during model training, thereby enhancing the model's capability to handle small-sized yet critical objects in driving scenes (e.g., traffic light). (2) We introduce Consistency-Aware Region Balancing (CARB), a novel technique that discerns reliable and noisy regions through evaluating the consistency between CLIP masks and segmentation predictions. It prioritizes reliable pixels over noisy pixels via adaptive loss weighting. Notably, the proposed method achieves 51.8\\% mIoU on the Cityscapes test dataset, showcasing its potential as a strong WSSS baseline on driving scene datasets. Experimental results on CamVid and WildDash2 demonstrate the effectiveness of our method across diverse datasets, even with small-scale datasets or visually challenging conditions. The code is available at https://github.com/k0u-id/CARB",
    "checked": true,
    "id": "a0d46c8ceefdc2ce23438b7b5d8ece8899adafca",
    "semantic_title": "weakly supervised semantic segmentation for driving scenes",
    "citation_count": 1,
    "authors": [
      "Dongseob Kim",
      "Seungho Lee",
      "Junsuk Choe",
      "Hyunjung Shim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28054": {
    "title": "FPRF: Feed-Forward Photorealistic Style Transfer of Large-Scale 3D Neural Radiance Fields",
    "volume": "main",
    "abstract": "We present FPRF, a feed-forward photorealistic style transfer method for large-scale 3D neural radiance fields. FPRF stylizes large-scale 3D scenes with arbitrary, multiple style reference images without additional optimization while preserving multi-view appearance consistency. Prior arts required tedious per-style/-scene optimization and were limited to small-scale 3D scenes. FPRF efficiently stylizes large-scale 3D scenes by introducing a style-decomposed 3D neural radiance field, which inherits AdaIN's feed-forward stylization machinery, supporting arbitrary style reference images. Furthermore, FPRF supports multi-reference stylization with the semantic correspondence matching and local AdaIN, which adds diverse user control for 3D scene styles. FPRF also preserves multi-view consistency by applying semantic matching and style transfer processes directly onto queried features in 3D space. In experiments, we demonstrate that FPRF achieves favorable photorealistic quality 3D scene stylization for large-scale scenes with diverse reference images",
    "checked": true,
    "id": "a53e6d23d131f7f7e4747626ba23482652409f88",
    "semantic_title": "fprf: feed-forward photorealistic style transfer of large-scale 3d neural radiance fields",
    "citation_count": 1,
    "authors": [
      "GeonU Kim",
      "Kim Youwang",
      "Tae-Hyun Oh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28055": {
    "title": "Let There Be Sound: Reconstructing High Quality Speech from Silent Videos",
    "volume": "main",
    "abstract": "The goal of this work is to reconstruct high quality speech from lip motions alone, a task also known as lip-to-speech. A key challenge of lip-to-speech systems is the one-to-many mapping caused by (1) the existence of homophenes and (2) multiple speech variations, resulting in a mispronounced and over-smoothed speech. In this paper, we propose a novel lip-to-speech system that significantly improves the generation quality by alleviating the one-to-many mapping problem from multiple perspectives. Specifically, we incorporate (1) self-supervised speech representations to disambiguate homophenes, and (2) acoustic variance information to model diverse speech styles. Additionally, to better solve the aforementioned problem, we employ a flow based post-net which captures and refines the details of the generated speech. We perform extensive experiments on two datasets, and demonstrate that our method achieves the generation quality close to that of real human utterance, outperforming existing methods in terms of speech naturalness and intelligibility by a large margin. Synthesised samples are available at our demo page: https://mm.kaist.ac.kr/projects/LTBS",
    "checked": true,
    "id": "330ab71d1b9bcdf37c5688bff6af51278c56d246",
    "semantic_title": "let there be sound: reconstructing high quality speech from silent videos",
    "citation_count": 0,
    "authors": [
      "Ji-Hoon Kim",
      "Jaehun Kim",
      "Joon Son Chung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28056": {
    "title": "Expand-and-Quantize: Unsupervised Semantic Segmentation Using High-Dimensional Space and Product Quantization",
    "volume": "main",
    "abstract": "Unsupervised semantic segmentation (USS) aims to discover and recognize meaningful categories without any labels. For a successful USS, two key abilities are required: 1) information compression and 2) clustering capability. Previous methods have relied on feature dimension reduction for information compression, however, this approach may hinder the process of clustering. In this paper, we propose a novel USS framework called Expand-and-Quantize Unsupervised Semantic Segmentation (EQUSS), which combines the benefits of high-dimensional spaces for better clustering and product quantization for effective information compression. Our extensive experiments demonstrate that EQUSS achieves state-of-the-art results on three standard benchmarks. In addition, we analyze the entropy of USS features, which is the first step towards understanding USS from the perspective of information theory",
    "checked": true,
    "id": "467227272889a8307c83a1b2ffd1daad6d8d8bfa",
    "semantic_title": "expand-and-quantize: unsupervised semantic segmentation using high-dimensional space and product quantization",
    "citation_count": 0,
    "authors": [
      "Jiyoung Kim",
      "Kyuhong Shim",
      "Insu Lee",
      "Byonghyo Shim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28057": {
    "title": "Sync-NeRF: Generalizing Dynamic NeRFs to Unsynchronized Videos",
    "volume": "main",
    "abstract": "Recent advancements in 4D scene reconstruction using neural radiance fields (NeRF) have demonstrated the ability to represent dynamic scenes from multi-view videos. However, they fail to reconstruct the dynamic scenes and struggle to fit even the training views in unsynchronized settings. It happens because they employ a single latent embedding for a frame while the multi-view images at the same frame were actually captured at different moments. To address this limitation, we introduce time offsets for individual unsynchronized videos and jointly optimize the offsets with NeRF. By design, our method is applicable for various baselines and improves them with large margins. Furthermore, finding the offsets always works as synchronizing the videos without manual effort. Experiments are conducted on the common Plenoptic Video Dataset and a newly built Unsynchronized Dynamic Blender Dataset to verify the performance of our method. Project page: https://seoha-kim.github.io/sync-nerf",
    "checked": true,
    "id": "f4f11c99d253519379796927faef6adcd8acbfe4",
    "semantic_title": "sync-nerf: generalizing dynamic nerfs to unsynchronized videos",
    "citation_count": 2,
    "authors": [
      "Seoha Kim",
      "Jeongmin Bae",
      "Youngsik Yun",
      "Hahyun Lee",
      "Gun Bang",
      "Youngjung Uh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28058": {
    "title": "Improving Open Set Recognition via Visual Prompts Distilled from Common-Sense Knowledge",
    "volume": "main",
    "abstract": "Open Set Recognition (OSR) poses significant challenges in distinguishing known from unknown classes. In OSR, the overconfidence problem has become a persistent obstacle, where visual recognition models often misclassify unknown objects as known objects with high confidence. This issue stems from the fact that visual recognition models often lack the integration of common-sense knowledge, a feature that is naturally present in language-based models but lacking in visual recognition systems. In this paper, we propose a novel approach to enhance OSR performance by distilling common-sense knowledge into visual prompts. Utilizing text prompts that embody common-sense knowledge about known classes, the proposed visual prompt is learned by extracting semantic common-sense features and aligning them with image features from visual recognition models. The unique aspect of this work is the training of individual visual prompts for each class to encapsulate this common-sense knowledge. Our methodology is model-agnostic, capable of enhancing OSR across various visual recognition models, and computationally light as it focuses solely on training the visual prompts. This research introduces a method for addressing OSR, aiming at a more systematic integration of visual recognition systems with common-sense knowledge. The obtained results indicate an enhancement in recognition accuracy, suggesting the applicability of this approach in practical settings",
    "checked": true,
    "id": "880f8154979949194fa3d1a98065832944aeeb80",
    "semantic_title": "improving open set recognition via visual prompts distilled from common-sense knowledge",
    "citation_count": 2,
    "authors": [
      "Seongyeop Kim",
      "Hyung-Il Kim",
      "Yong Man Ro"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28059": {
    "title": "Gaussian Mixture Proposals with Pull-Push Learning Scheme to Capture Diverse Events for Weakly Supervised Temporal Video Grounding",
    "volume": "main",
    "abstract": "In the weakly supervised temporal video grounding study, previous methods use predetermined single Gaussian proposals which lack the ability to express diverse events described by the sentence query. To enhance the expression ability of a proposal, we propose a Gaussian mixture proposal (GMP) that can depict arbitrary shapes by learning importance, centroid, and range of every Gaussian in the mixture. In learning GMP, each Gaussian is not trained in a feature space but is implemented over a temporal location. Thus the conventional feature-based learning for Gaussian mixture model is not valid for our case. In our special setting, to learn moderately coupled Gaussian mixture capturing diverse events, we newly propose a pull-push learning scheme using pulling and pushing losses, each of which plays an opposite role to the other. The effects of components in our scheme are verified in-depth with extensive ablation studies and the overall scheme achieves state-of-the-art performance. Our code is available at https://github.com/sunoh-kim/pps",
    "checked": true,
    "id": "4ae34510bc501ce418743fda52b0d61f480e8f7a",
    "semantic_title": "gaussian mixture proposals with pull-push learning scheme to capture diverse events for weakly supervised temporal video grounding",
    "citation_count": 0,
    "authors": [
      "Sunoh Kim",
      "Jungchan Cho",
      "Joonsang Yu",
      "YoungJoon Yoo",
      "Jin Young Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28060": {
    "title": "PARSAC: Accelerating Robust Multi-Model Fitting with Parallel Sample Consensus",
    "volume": "main",
    "abstract": "We present a real-time method for robust estimation of multiple instances of geometric models from noisy data. Geometric models such as vanishing points, planar homographies or fundamental matrices are essential for 3D scene analysis. Previous approaches discover distinct model instances in an iterative manner, thus limiting their potential for speedup via parallel computation. In contrast, our method detects all model instances independently and in parallel. A neural network segments the input data into clusters representing potential model instances by predicting multiple sets of sample and inlier weights. Using the predicted weights, we determine the model parameters for each potential instance separately in a RANSAC-like fashion. We train the neural network via task-specific loss functions, i.e. we do not require a ground-truth segmentation of the input data. As suitable training data for homography and fundamental matrix fitting is scarce, we additionally present two new synthetic datasets. We demonstrate state-of-the-art performance on these as well as multiple established datasets, with inference times as small as five milliseconds per image",
    "checked": true,
    "id": "f8c34f3fb9719ce3e9a71490884a02aa9f5da828",
    "semantic_title": "parsac: accelerating robust multi-model fitting with parallel sample consensus",
    "citation_count": 4,
    "authors": [
      "Florian Kluger",
      "Bodo Rosenhahn"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28061": {
    "title": "Distribution Matching for Multi-Task Learning of Classification Tasks: A Large-Scale Study on Faces & Beyond",
    "volume": "main",
    "abstract": "Multi-Task Learning (MTL) is a framework, where multiple related tasks are learned jointly and benefit from a shared representation space, or parameter transfer. To provide sufficient learning support, modern MTL uses annotated data with full, or sufficiently large overlap across tasks, i.e., each input sample is annotated for all, or most of the tasks. However, collecting such annotations is prohibitive in many real applications, and cannot benefit from datasets available for individual tasks. In this work, we challenge this setup and show that MTL can be successful with classification tasks with little, or non-overlapping annotations, or when there is big discrepancy in the size of labeled data per task. We explore task-relatedness for co-annotation and co-training, and propose a novel approach, where knowledge exchange is enabled between the tasks via distribution matching. To demonstrate the general applicability of our method, we conducted diverse case studies in the domains of affective computing, face recognition, species recognition, and shopping item classification using nine datasets. Our large-scale study of affective tasks for basic expression recognition and facial action unit detection illustrates that our approach is network agnostic and brings large performance improvements compared to the state-of-the-art in both tasks and across all studied databases. In all case studies, we show that co-training via task-relatedness is advantageous and prevents negative transfer (which occurs when MT model's performance is worse than that of at least one single-task model)",
    "checked": true,
    "id": "16d26f3adaf77d477b60b96081c488ae26abb730",
    "semantic_title": "distribution matching for multi-task learning of classification tasks: a large-scale study on faces & beyond",
    "citation_count": 11,
    "authors": [
      "Dimitrios Kollias",
      "Viktoriia Sharmanska",
      "Stefanos Zafeiriou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28062": {
    "title": "Block Image Compressive Sensing with Local and Global Information Interaction",
    "volume": "main",
    "abstract": "Block image compressive sensing methods, which divide a single image into small blocks for efficient sampling and reconstruction, have achieved significant success. However, these methods process each block locally and thus disregard the global communication among different blocks in the reconstruction step. Existing methods have attempted to address this issue with local filters or by directly reconstructing the entire image, but they have only achieved insufficient communication among adjacent pixels or bypassed the problem. To directly confront the communication problem among blocks and effectively resolve it, we propose a novel approach called Block Reconstruction with Blocks' Communication Network (BRBCN). BRBCN focuses on both local and global information, while further taking their interactions into account. Specifically, BRBCN comprises dual CNN and Transformer architectures, in which CNN is used to reconstruct each block for powerful local processing and Transformer is used to calculate the global communication among all the blocks. Moreover, we propose a global-to-local module (G2L) and a local-to-global module (L2G) to effectively integrate the representations of CNN and Transformer, with which our BRBCN network realizes the bidirectional interaction between local and global information. Extensive experiments show our BRBCN method outperforms existing state-of-the-art methods by a large margin. The code is available at https://github.com/kongxiuxiu/BRBCN",
    "checked": true,
    "id": "aa1ac8cf02a273798f6307e79140dcebd2a22539",
    "semantic_title": "block image compressive sensing with local and global information interaction",
    "citation_count": 0,
    "authors": [
      "Xiaoyu Kong",
      "Yongyong Chen",
      "Feng Zheng",
      "Zhenyu He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28063": {
    "title": "QDETRv: Query-Guided DETR for One-Shot Object Localization in Videos",
    "volume": "main",
    "abstract": "In this work, we study one-shot video object localization problem that aims to localize instances of unseen objects in the target video using a single query image of the object. Toward addressing this challenging problem, we extend a popular and successful object detection method, namely DETR (Detection Transformer), and introduce a novel approach –query-guided detection transformer for videos (QDETRv). A distinctive feature of QDETRv is its capacity to exploit information from the query image and spatio-temporal context of the target video, which significantly aids in precisely pinpointing the desired object in the video. We incorporate cross-attention mechanisms that capture temporal relationships across adjacent frames to handle the dynamic context in videos effectively. Further, to ensure strong initialization for QDETRv, we also introduce a novel unsupervised pretraining technique tailored to videos. This involves training our model on synthetic object trajectories with an analogous objective as the query-guided localization task. During this pretraining phase, we incorporate recurrent object queries and loss functions that encourage accurate patch feature reconstruction. These additions enable better temporal understanding and robust representation learning. Our experiments show that the proposed model significantly outperforms the competitive baselines on two public benchmarks, VidOR and ImageNet-VidVRD, extended for one-shot open-set localization tasks",
    "checked": true,
    "id": "d072dfeb79b5667d4ddfd5171733d7e309e890c5",
    "semantic_title": "qdetrv: query-guided detr for one-shot object localization in videos",
    "citation_count": 0,
    "authors": [
      "Yogesh Kumar",
      "Saswat Mallick",
      "Anand Mishra",
      "Sowmya Rasipuram",
      "Anutosh Maitra",
      "Roshni Ramnani"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28064": {
    "title": "LaViP: Language-Grounded Visual Prompting",
    "volume": "main",
    "abstract": "We introduce a language-grounded visual prompting method to adapt the visual encoder of vision-language models for downstream tasks. By capitalizing on language integration, we devise a parameter-efficient strategy to adjust the input of the visual encoder, eliminating the need to modify or add to the model's parameters. Due to this design choice, our algorithm can operate even in black-box scenarios, showcasing adaptability in situations where access to the model's parameters is constrained. We will empirically demonstrate that, compared to prior art, grounding visual prompts with language enhances both the accuracy and speed of adaptation. Moreover, our algorithm excels in base-to-novel class generalization, overcoming limitations of visual prompting and exhibiting the capacity to generalize beyond seen classes. We thoroughly assess and evaluate our method across a variety of image recognition datasets, such as EuroSAT, UCF101, DTD, and CLEVR, spanning different learning situations, including few-shot adaptation, base-to-novel class generalization, and transfer learning",
    "checked": true,
    "id": "d808742a12873e428f94a35ee0cc4920e21f848f",
    "semantic_title": "lavip: language-grounded visual prompting",
    "citation_count": 0,
    "authors": [
      "Nilakshan Kunananthaseelan",
      "Jing Zhang",
      "Mehrtash Harandi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28065": {
    "title": "Towards More Faithful Natural Language Explanation Using Multi-Level Contrastive Learning in VQA",
    "volume": "main",
    "abstract": "Natural language explanation in visual question answer (VQA-NLE) aims to explain the decision-making process of models by generating natural language sentences to increase users' trust in the black-box systems. Existing post-hoc methods have achieved significant progress in obtaining a plausible explanation. However, such post-hoc explanations are not always aligned with human logical inference, suffering from the issues on: 1) Deductive unsatisfiability, the generated explanations do not logically lead to the answer; 2) Factual inconsistency, the model falsifies its counterfactual explanation for answers without considering the facts in images; and 3) Semantic perturbation insensitivity, the model can not recognize the semantic changes caused by small perturbations. These problems reduce the faithfulness of explanations generated by models. To address the above issues, we propose a novel self-supervised Multi-level Contrastive Learning based natural language Explanation model (MCLE) for VQA with semantic-level, image-level, and instance-level factual and counterfactual samples. MCLE extracts discriminative features and aligns the feature spaces from explanations with visual question and answer to generate more consistent explanations. We conduct extensive experiments, ablation analysis, and case study to demonstrate the effectiveness of our method on two VQA-NLE benchmarks",
    "checked": true,
    "id": "d9f38c99fdf74ab2d3918ca10bdbcd2cb9fbbfd2",
    "semantic_title": "towards more faithful natural language explanation using multi-level contrastive learning in vqa",
    "citation_count": 2,
    "authors": [
      "Chengen Lai",
      "Shengli  Song",
      "Shiqi Meng",
      "Jingyang Li",
      "Sitong Yan",
      "Guangneng Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28066": {
    "title": "MatchDet: A Collaborative Framework for Image Matching and Object Detection",
    "volume": "main",
    "abstract": "Image matching and object detection are two fundamental and challenging tasks, while many related applications consider them two individual tasks (i.e. task-individual). In this paper, a collaborative framework called MatchDet (i.e. task-collaborative) is proposed for image matching and object detection to obtain mutual improvements. To achieve the collaborative learning of the two tasks, we propose three novel modules, including a Weighted Spatial Attention Module (WSAM) for Detector, and Weighted Attention Module (WAM) and Box Filter for Matcher. Specifically, the WSAM highlights the foreground regions of target image to benefit the subsequent detector, the WAM enhances the connection between the foreground regions of pair images to ensure high-quality matches, and Box Filter mitigates the impact of false matches. We evaluate the approaches on a new benchmark with two datasets called Warp-COCO and miniScanNet. Experimental results show our approaches are effective and achieve competitive improvements",
    "checked": true,
    "id": "c965465163735fe082c9d8b5740ac3291c06a587",
    "semantic_title": "matchdet: a collaborative framework for image matching and object detection",
    "citation_count": 0,
    "authors": [
      "Jinxiang Lai",
      "Wenlong Wu",
      "Bin-Bin Gao",
      "Jun Liu",
      "Jiawei Zhan",
      "Congchong Nie",
      "Yi Zeng",
      "Chengjie Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28067": {
    "title": "ViTree: Single-Path Neural Tree for Step-Wise Interpretable Fine-Grained Visual Categorization",
    "volume": "main",
    "abstract": "As computer vision continues to advance and finds widespread applications across various domains, the need for interpretability in deep learning models becomes paramount. Existing methods often resort to post-hoc techniques or prototypes to explain the decision-making process, which can be indirect and lack intrinsic illustration. In this research, we introduce ViTree, a novel approach for fine-grained visual categorization that combines the popular vision transformer as a feature extraction backbone with neural decision trees. By traversing the tree paths, ViTree effectively selects patches from transformer-processed features to highlight informative local regions, thereby refining representations in a step-wise manner. Unlike previous tree-based models that rely on soft distributions or ensembles of paths, ViTree selects a single tree path, offering a clearer and simpler decision-making process. This patch and path selectivity enhances model interpretability of ViTree, enabling better insights into the model's inner workings. Remarkably, extensive experimentation validates that this streamlined approach surpasses various strong competitors and achieves state-of-the-art performance while maintaining exceptional interpretability which is proved by multi-perspective methods. Code can be found at https://github.com/SJTU-DeepVisionLab/ViTree",
    "checked": true,
    "id": "776cf9685aef060c7a36fdd13e35f3610dcbd5f4",
    "semantic_title": "vitree: single-path neural tree for step-wise interpretable fine-grained visual categorization",
    "citation_count": 0,
    "authors": [
      "Danning Lao",
      "Qi Liu",
      "Jiazi Bu",
      "Junchi Yan",
      "Wei Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28068": {
    "title": "MaskDiff: Modeling Mask Distribution with Diffusion Probabilistic Model for Few-Shot Instance Segmentation",
    "volume": "main",
    "abstract": "Few-shot instance segmentation extends the few-shot learning paradigm to the instance segmentation task, which tries to segment instance objects from a query image with a few annotated examples of novel categories. Conventional approaches have attempted to address the task via prototype learning, known as point estimation. However, this mechanism depends on prototypes (e.g. mean of K-shot) for prediction, leading to performance instability. To overcome the disadvantage of the point estimation mechanism, we propose a novel approach, dubbed MaskDiff, which models the underlying conditional distribution of a binary mask, which is conditioned on an object region and K-shot information. Inspired by augmentation approaches that perturb data with Gaussian noise for populating low data density regions, we model the mask distribution with a diffusion probabilistic model. We also propose to utilize classifier-free guided mask sampling to integrate category information into the binary mask generation process. Without bells and whistles, our proposed method consistently outperforms state-of-the-art methods on both base and novel classes of the COCO dataset while simultaneously being more stable than existing methods. The source code is available at: https://github.com/minhquanlecs/MaskDiff",
    "checked": true,
    "id": "a86846ad0893595896c36f465cf4f7ce07945247",
    "semantic_title": "maskdiff: modeling mask distribution with diffusion probabilistic model for few-shot instance segmentation",
    "citation_count": 6,
    "authors": [
      "Minh-Quan Le",
      "Tam V. Nguyen",
      "Trung-Nghia Le",
      "Thanh-Toan Do",
      "Minh N. Do",
      "Minh-Triet Tran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28069": {
    "title": "FRED: Towards a Full Rotation-Equivariance in Aerial Image Object Detection",
    "volume": "main",
    "abstract": "Rotation-equivariance is an essential yet challenging property in oriented object detection. While general object detectors naturally leverage robustness to spatial shifts due to the translation-equivariance of the conventional CNNs, achieving rotation-equivariance remains an elusive goal. Current detectors deploy various alignment techniques to derive rotation-invariant features, but still rely on high capacity models and heavy data augmentation with all possible rotations. In this paper, we introduce a Fully Rotation-Equivariant Oriented Object Detector (FRED), whose entire process from the image to the bounding box prediction is strictly equivariant. Specifically, we decouple the invariant task (object classification) and the equivariant task (object localization) to achieve end-to-end equivariance. We represent the bounding box as a set of rotation-equivariant vectors to implement rotation-equivariant localization. Moreover, we utilized these rotation-equivariant vectors as offsets in the deformable convolution, thereby enhancing the existing advantages of spatial adaptation. Leveraging full rotation-equivariance, our FRED demonstrates higher robustness to image-level rotation compared to existing methods. Furthermore, we show that FRED is one step closer to non-axis aligned learning through our experiments. Compared to state-of-the-art methods, our proposed method delivers comparable performance on DOTA-v1.0 and outperforms by 1.5 mAP on DOTA-v1.5, all while significantly reducing the model parameters to 16%",
    "checked": true,
    "id": "84a04ed8f34145915d416ff61861615d088035da",
    "semantic_title": "fred: towards a full rotation-equivariance in aerial image object detection",
    "citation_count": 1,
    "authors": [
      "Chanho Lee",
      "Jinsu Son",
      "Hyounguk Shon",
      "Yunho Jeon",
      "Junmo Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28070": {
    "title": "Domain Generalization with Vital Phase Augmentation",
    "volume": "main",
    "abstract": "Deep neural networks have shown remarkable performance in image classification. However, their performance significantly deteriorates with corrupted input data. Domain generalization methods have been proposed to train robust models against out-of-distribution data. Data augmentation in the frequency domain is one of such approaches that enable a model to learn phase features to establish domain-invariant representations. This approach changes the amplitudes of the input data while preserving the phases. However, using fixed phases leads to susceptibility to phase fluctuations because amplitudes and phase fluctuations commonly occur in out-of-distribution. In this study, to address this problem, we introduce an approach using finite variation of the phases of input data rather than maintaining fixed phases. Based on the assumption that the degree of domain-invariant features varies for each phase, we propose a method to distinguish phases based on this degree. In addition, we propose a method called vital phase augmentation (VIPAug) that applies the variation to the phases differently according to the degree of domain-invariant features of given phases. The model depends more on the vital phases that contain more domain-invariant features for attaining robustness to amplitude and phase fluctuations. We present experimental evaluations of our proposed approach, which exhibited improved performance for both clean and corrupted data. VIPAug achieved SOTA performance on the benchmark CIFAR-10 and CIFAR-100 datasets, as well as near-SOTA performance on the ImageNet-100 and ImageNet datasets. Our code is available at https://github.com/excitedkid/vipaug",
    "checked": true,
    "id": "f75bd014fbe0894f2e5c024f6e67f7956a574517",
    "semantic_title": "domain generalization with vital phase augmentation",
    "citation_count": 0,
    "authors": [
      "Ingyun Lee",
      "Wooju Lee",
      "Hyun Myung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28071": {
    "title": "Modeling Stereo-Confidence out of the End-to-End Stereo-Matching Network via Disparity Plane Sweep",
    "volume": "main",
    "abstract": "We propose a novel stereo-confidence that can be measured externally to various stereo-matching networks, offering an alternative input modality choice of the cost volume for learning-based approaches, especially in safety-critical systems. Grounded in the foundational concepts of disparity definition and the disparity plane sweep, the proposed stereo-confidence method is built upon the idea that any shift in a stereo-image pair should be updated in a corresponding amount shift in the disparity map. Based on this idea, the proposed stereo-confidence method can be summarized in three folds. 1) Using the disparity plane sweep, multiple disparity maps can be obtained and treated as a 3-D volume (predicted disparity volume), like the cost volume is constructed. 2) One of these disparity maps serves as an anchor, allowing us to define a desirable (or ideal) disparity profile at every spatial point. 3) By comparing the desirable and predicted disparity profiles, we can quantify the level of matching ambiguity between left and right images for confidence measurement. Extensive experimental results using various stereo-matching networks and datasets demonstrate that the proposed stereo-confidence method not only shows competitive performance on its own but also consistent performance improvements when it is used as an input modality for learning-based stereo-confidence methods",
    "checked": true,
    "id": "6bbb7d349aaa1e18f646853793c073f71cd3e69f",
    "semantic_title": "modeling stereo-confidence out of the end-to-end stereo-matching network via disparity plane sweep",
    "citation_count": 0,
    "authors": [
      "Jae Young Lee",
      "Woonghyun Ka",
      "Jaehyun Choi",
      "Junmo Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28072": {
    "title": "MFOS: Model-Free & One-Shot Object Pose Estimation",
    "volume": "main",
    "abstract": "Existing learning-based methods for object pose estimation in RGB images are mostly model-specific or category based. They lack the capability to generalize to new object categories at test time, hence severely hindering their practicability and scalability. Notably, recent attempts have been made to solve this issue, but they still require accurate 3D data of the object surface at both train and test time. In this paper, we introduce a novel approach that can estimate in a single forward pass the pose of objects never seen during training, given minimum input. In contrast to existing state-of-the-art approaches, which rely on task-specific modules, our proposed model is entirely based on a transformer architecture, which can benefit from recently proposed 3D-geometry general pretraining. We conduct extensive experiments and report state-of-the-art one-shot performance on the challenging LINEMOD benchmark. Finally, extensive ablations allow us to determine good practices with this relatively new type of architecture in the field",
    "checked": true,
    "id": "9147b582eb4a155a4de9b85baeafa7d07fa4f939",
    "semantic_title": "mfos: model-free & one-shot object pose estimation",
    "citation_count": 2,
    "authors": [
      "JongMin Lee",
      "Yohann Cabon",
      "Romain Brégier",
      "Sungjoo Yoo",
      "Jerome Revaud"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28073": {
    "title": "Noise-Free Optimization in Early Training Steps for Image Super-resolution",
    "volume": "main",
    "abstract": "Recent deep-learning-based single image super-resolution (SISR) methods have shown impressive performance whereas typical methods train their networks by minimizing the pixel-wise distance with respect to a given high-resolution (HR) image. However, despite the basic training scheme being the predominant choice, its use in the context of ill-posed inverse problems has not been thoroughly investigated. In this work, we aim to provide a better comprehension of the underlying constituent by decomposing target HR images into two subcomponents: (1) the optimal centroid which is the expectation over multiple potential HR images, and (2) the inherent noise defined as the residual between the HR image and the centroid. Our findings show that the current training scheme cannot capture the ill-posed nature of SISR and becomes vulnerable to the inherent noise term, especially during early training steps. To tackle this issue, we propose a novel optimization method that can effectively remove the inherent noise term in the early steps of vanilla training by estimating the optimal centroid and directly optimizing toward the estimation. Experimental results show that the proposed method can effectively enhance the stability of vanilla training, leading to overall performance gain. Codes are available at github.com/2minkyulee/ECO",
    "checked": true,
    "id": "ad1edc074309f785580d1ccc5edbec6645543813",
    "semantic_title": "noise-free optimization in early training steps for image super-resolution",
    "citation_count": 1,
    "authors": [
      "MinKyu Lee",
      "Jae-Pil Heo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28074": {
    "title": "Spectrum Translation for Refinement of Image Generation (STIG) Based on Contrastive Learning and Spectral Filter Profile",
    "volume": "main",
    "abstract": "Currently, image generation and synthesis have remarkably progressed with generative models. Despite photo-realistic results, intrinsic discrepancies are still observed in the frequency domain. The spectral discrepancy appeared not only in generative adversarial networks but in diffusion models. In this study, we propose a framework to effectively mitigate the disparity in frequency domain of the generated images to improve generative performance of both GAN and diffusion models. This is realized by spectrum translation for the refinement of image generation (STIG) based on contrastive learning. We adopt theoretical logic of frequency components in various generative networks. The key idea, here, is to refine the spectrum of the generated image via the concept of image-to-image translation and contrastive learning in terms of digital signal processing. We evaluate our framework across eight fake image datasets and various cutting-edge models to demonstrate the effectiveness of STIG. Our framework outperforms other cutting-edges showing significant decreases in FID and log frequency distance of spectrum. We further emphasize that STIG improves image quality by decreasing the spectral anomaly. Additionally, validation results present that the frequency-based deepfake detector confuses more in the case where fake spectrums are manipulated by STIG",
    "checked": true,
    "id": "8286b1a4eb8c70e24b121ed758e7306c2aa44288",
    "semantic_title": "spectrum translation for refinement of image generation (stig) based on contrastive learning and spectral filter profile",
    "citation_count": 2,
    "authors": [
      "Seokjun Lee",
      "Seung-Won Jung",
      "Hyunseok Seo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28075": {
    "title": "Few-Shot Neural Radiance Fields under Unconstrained Illumination",
    "volume": "main",
    "abstract": "In this paper, we introduce a new challenge for synthesizing novel view images in practical environments with limited input multi-view images and varying lighting conditions. Neural radiance fields (NeRF), one of the pioneering works for this task, demand an extensive set of multi-view images taken under constrained illumination, which is often unattainable in real-world settings. While some previous works have managed to synthesize novel views given images with different illumination, their performance still relies on a substantial number of input multi-view images. To address this problem, we suggest ExtremeNeRF, which utilizes multi-view albedo consistency, supported by geometric alignment. Specifically, we extract intrinsic image components that should be illumination-invariant across different views, enabling direct appearance comparison between the input and novel view under unconstrained illumination. We offer thorough experimental results for task evaluation, employing the newly created NeRF Extreme benchmark—the first in-the-wild benchmark for novel view synthesis under multiple viewing directions and varying illuminations",
    "checked": true,
    "id": "b50031ffe7c060fdd9c7fefe313d47b00c73097f",
    "semantic_title": "few-shot neural radiance fields under unconstrained illumination",
    "citation_count": 3,
    "authors": [
      "SeokYeong Lee",
      "JunYong Choi",
      "Seungryong Kim",
      "Ig-Jae Kim",
      "Junghyun Cho"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28076": {
    "title": "Object-Aware Domain Generalization for Object Detection",
    "volume": "main",
    "abstract": "Single-domain generalization (S-DG) aims to generalize a model to unseen environments with a single-source domain. However, most S-DG approaches have been conducted in the field of classification. When these approaches are applied to object detection, the semantic features of some objects can be damaged, which can lead to imprecise object localization and misclassification. To address these problems, we propose an object-aware domain generalization (OA-DG) method for single-domain generalization in object detection. Our method consists of data augmentation and training strategy, which are called OA-Mix and OA-Loss, respectively. OA-Mix generates multi-domain data with multi-level transformation and object-aware mixing strategy. OA-Loss enables models to learn domain-invariant representations for objects and backgrounds from the original and OA-Mixed images. Our proposed method outperforms state-of-the-art works on standard benchmarks. Our code is available at https://github.com/WoojuLee24/OA-DG",
    "checked": true,
    "id": "bf423c74fa7565aa4659263265b76e0657e4e750",
    "semantic_title": "object-aware domain generalization for object detection",
    "citation_count": 1,
    "authors": [
      "Wooju Lee",
      "Dasol Hong",
      "Hyungtae Lim",
      "Hyun Myung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28077": {
    "title": "Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention",
    "volume": "main",
    "abstract": "Vision Transformer(ViT) is one of the most widely used models in the computer vision field with its great performance on various tasks. In order to fully utilize the ViT-based architecture in various applications, proper visualization methods with a decent localization performance are necessary, but these methods employed in CNN-based models are still not available in ViT due to its unique structure. In this work, we propose an attention-guided visualization method applied to ViT that provides a high-level semantic explanation for its decision. Our method selectively aggregates the gradients directly propagated from the classification output to each self-attention, collecting the contribution of image features extracted from each location of the input image. These gradients are additionally guided by the normalized self-attention scores, which are the pairwise patch correlation scores. They are used to supplement the gradients on the patch-level context information efficiently detected by the self-attention mechanism. This approach of our method provides elaborate high-level semantic explanations with great localization performance only with the class labels. As a result, our method outperforms the previous leading explainability methods of ViT in the weakly-supervised localization task and presents great capability in capturing the full instances of the target class object. Meanwhile, our method provides a visualization that faithfully explains the model, which is demonstrated in the perturbation comparison test",
    "checked": true,
    "id": "ffc855594cad345ea5a1cce2ee27095bec767bc8",
    "semantic_title": "attention guided cam: visual explanations of vision transformer guided by self-attention",
    "citation_count": 0,
    "authors": [
      "Saebom Leem",
      "Hyunseok Seo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28078": {
    "title": "Contrastive Tuning: A Little Help to Make Masked Autoencoders Forget",
    "volume": "main",
    "abstract": "Masked Image Modeling (MIM) methods, like Masked Autoencoders (MAE), efficiently learn a rich representation of the input. However, for adapting to downstream tasks, they require a sufficient amount of labeled data since their rich features code not only objects but also less relevant image background. In contrast, Instance Discrimination (ID) methods focus on objects. In this work, we study how to combine the efficiency and scalability of MIM with the ability of ID to perform downstream classification in the absence of large amounts of labeled data. To this end, we introduce Masked Autoencoder Contrastive Tuning (MAE-CT), a sequential approach that utilizes the implicit clustering of the Nearest Neighbor Contrastive Learning (NNCLR) objective to induce abstraction in the topmost layers of a pre-trained MAE. MAE-CT tunes the rich features such that they form semantic clusters of objects without using any labels. Notably, MAE-CT does not rely on hand-crafted augmentations and frequently achieves its best performances while using only minimal augmentations (crop & flip). Further, MAE-CT is compute efficient as it requires at most 10% overhead compared to MAE re-training. Applied to large and huge Vision Transformer (ViT) models, MAE-CT excels over previous self-supervised methods trained on ImageNet in linear probing, k-NN and low-shot classification accuracy as well as in unsupervised clustering accuracy. With ViT-H/16 MAE-CT achieves a new state-of-the-art in linear probing of 82.2%. Project page: github.com/ml-jku/MAE-CT",
    "checked": true,
    "id": "5e97c57cf3ff5034bc8bf6473c0cd0369fa64816",
    "semantic_title": "contrastive tuning: a little help to make masked autoencoders forget",
    "citation_count": 7,
    "authors": [
      "Johannes Lehner",
      "Benedikt Alkin",
      "Andreas Fürst",
      "Elisabeth Rumetshofer",
      "Lukas Miklautz",
      "Sepp Hochreiter"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28079": {
    "title": "Few-Shot Learning from Augmented Label-Uncertain Queries in Bongard-HOI",
    "volume": "main",
    "abstract": "Detecting human-object interactions (HOI) in a few-shot setting remains a challenge. Existing meta-learning methods struggle to extract representative features for classification due to the limited data, while existing few-shot HOI models rely on HOI text labels for classification. Moreover, some query images may display visual similarity to those outside their class, such as similar backgrounds between different HOI classes. This makes learning more challenging, especially with limited samples. Bongard-HOI epitomizes this HOI few-shot problem, making it the benchmark we focus on in this paper. In our proposed method, we introduce novel label-uncertain query augmentation techniques to enhance the diversity of the query inputs, aiming to distinguish the positive HOI class from the negative ones. As these augmented inputs may or may not have the same class label as the original inputs, their class label is unknown. Those belonging to a different class become hard samples due to their visual similarity to the original ones. Additionally, we introduce a novel pseudo-label generation technique that enables a mean teacher model to learn from the augmented label-uncertain inputs. We propose to augment the negative support set for the student model to enrich the semantic information, fostering diversity that challenges and enhances the student's learning. Experimental results demonstrate that our method sets a new state-of-the-art (SOTA) performance by achieving 68.74% accuracy on the Bongard-HOI benchmark, a significant improvement over the existing SOTA of 66.59%. In our evaluation on HICO-FS, a more general few-shot recognition dataset, our method achieves 73.27% accuracy, outperforming the previous SOTA of 71.20% in the 5- way 5-shot task",
    "checked": true,
    "id": "e66d66b0d3d6c05e63dabb578c9fb991c671992f",
    "semantic_title": "few-shot learning from augmented label-uncertain queries in bongard-hoi",
    "citation_count": 0,
    "authors": [
      "Qinqian Lei",
      "Bo Wang",
      "Robby T. Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28080": {
    "title": "Removing Interference and Recovering Content Imaginatively for Visible Watermark Removal",
    "volume": "main",
    "abstract": "Visible watermarks, while instrumental in protecting image copyrights, frequently distort the underlying content, complicating tasks like scene interpretation and image editing. Visible watermark removal aims to eliminate the interference of watermarks and restore the background content. However, existing methods often implement watermark component removal and background restoration tasks within a singular branch, leading to residual watermarks in the predictions and ignoring cases where watermarks heavily obscure the background. To address these limitations, this study introduces the Removing Interference and Recovering Content Imaginatively (RIRCI) framework. RIRCI embodies a two-stage approach: the initial phase centers on discerning and segregating the watermark component, while the subsequent phase focuses on background content restoration. To achieve meticulous background restoration, our proposed model employs a dual-path network capable of fully exploring the intrinsic background information beneath semi-transparent watermarks and peripheral contextual information from unaffected regions. Moreover, a Global and Local Context Interaction module is built upon multi-layer perceptrons and bidirectional feature transformation for comprehensive representation modeling in the background restoration phase. The efficacy of our approach is empirically validated across two large-scale datasets, and our findings reveal a marked enhancement over existing watermark removal techniques",
    "checked": true,
    "id": "3bbf488b113db65996e65dda9d29ca686daf637d",
    "semantic_title": "removing interference and recovering content imaginatively for visible watermark removal",
    "citation_count": 0,
    "authors": [
      "Yicheng Leng",
      "Chaowei Fang",
      "Gen Li",
      "Yixiang Fang",
      "Guanbin Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28081": {
    "title": "Data Roaming and Quality Assessment for Composed Image Retrieval",
    "volume": "main",
    "abstract": "The task of Composed Image Retrieval (CoIR) involves queries that combine image and text modalities, allowing users to express their intent more effectively. However, current CoIR datasets are orders of magnitude smaller compared to other vision and language (V&L) datasets. Additionally, some of these datasets have noticeable issues, such as queries containing redundant modalities. To address these shortcomings, we introduce the Large Scale Composed Image Retrieval (LaSCo) dataset, a new CoIR dataset which is ten times larger than existing ones. Pre-training on our LaSCo, shows a noteworthy improvement in performance, even in zero-shot. Furthermore, we propose a new approach for analyzing CoIR datasets and methods, which detects modality redundancy or necessity, in queries. We also introduce a new CoIR baseline, the Cross-Attention driven Shift Encoder (CASE). This baseline allows for early fusion of modalities using a cross-attention module and employs an additional auxiliary task during training. Our experiments demonstrate that this new baseline outperforms the current state-of-the-art methods on established benchmarks like FashionIQ and CIRR",
    "checked": true,
    "id": "1c205939f60ab42079f63738fa755f2eda026a03",
    "semantic_title": "data roaming and quality assessment for composed image retrieval",
    "citation_count": 9,
    "authors": [
      "Matan Levy",
      "Rami Ben-Ari",
      "Nir Darshan",
      "Dani Lischinski"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28082": {
    "title": "Point Transformer with Federated Learning for Predicting Breast Cancer HER2 Status from Hematoxylin and Eosin-Stained Whole Slide Images",
    "volume": "main",
    "abstract": "Directly predicting human epidermal growth factor receptor 2 (HER2) status from widely available hematoxylin and eosin (HE)-stained whole slide images (WSIs) can reduce technical costs and expedite treatment selection. Accurately predicting HER2 requires large collections of multi-site WSIs. Federated learning enables collaborative training of these WSIs without gigabyte-size WSIs transportation and data privacy concerns. However, federated learning encounters challenges in addressing label imbalance in multi-site WSIs from the real world. Moreover, existing WSI classification methods cannot simultaneously exploit local context information and long-range dependencies in the site-end feature representation of federated learning. To address these issues, we present a point transformer with federated learning for multi-site HER2 status prediction from HE-stained WSIs. Our approach incorporates two novel designs. We propose a dynamic label distribution strategy and an auxiliary classifier, which helps to establish a well-initialized model and mitigate label distribution variations across sites. Additionally, we propose a farthest cosine sampling based on cosine distance. It can sample the most distinctive features and capture the long-range dependencies. Extensive experiments and analysis show that our method achieves state-of-the-art performance at four sites with a total of 2687 WSIs. Furthermore, we demonstrate that our model can generalize to two unseen sites with 229 WSIs. Code is available at: https://github.com/boyden/PointTransformerFL",
    "checked": true,
    "id": "faf54324a75571bd8cd50e826b2d5480c608d583",
    "semantic_title": "point transformer with federated learning for predicting breast cancer her2 status from hematoxylin and eosin-stained whole slide images",
    "citation_count": 1,
    "authors": [
      "Bao Li",
      "Zhenyu Liu",
      "Lizhi Shao",
      "Bensheng Qiu",
      "Hong Bu",
      "Jie Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28083": {
    "title": "Unsupervised Cross-Domain Image Retrieval via Prototypical Optimal Transport",
    "volume": "main",
    "abstract": "Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images sharing the same category across diverse domains without relying on labeled data. Prior approaches have typically decomposed the UCIR problem into two distinct tasks: intra-domain representation learning and cross-domain feature alignment. However, these segregated strategies overlook the potential synergies between these tasks. This paper introduces ProtoOT, a novel Optimal Transport formulation explicitly tailored for UCIR, which integrates intra-domain feature representation learning and cross-domain alignment into a unified framework. ProtoOT leverages the strengths of the K-means clustering method to effectively manage distribution imbalances inherent in UCIR. By utilizing K-means for generating initial prototypes and approximating class marginal distributions, we modify the constraints in Optimal Transport accordingly, significantly enhancing its performance in UCIR scenarios. Furthermore, we incorporate contrastive learning into the ProtoOT framework to further improve representation learning. This encourages local semantic consistency among features with similar semantics, while also explicitly enforcing separation between features and unmatched prototypes, thereby enhancing global discriminativeness. ProtoOT surpasses existing state-of-the-art methods by a notable margin across benchmark datasets. Notably, on DomainNet, ProtoOT achieves an average P@200 enhancement of 24.44%, and on Office-Home, it demonstrates a P@15 improvement of 12.12%. Code is available at https://github.com/HCVLAB/ProtoOT",
    "checked": true,
    "id": "f9da402462d6845fca253e7d0f2c563cd8b0e483",
    "semantic_title": "unsupervised cross-domain image retrieval via prototypical optimal transport",
    "citation_count": 1,
    "authors": [
      "Bin Li",
      "Ye Shi",
      "Qian Yu",
      "Jingya Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28084": {
    "title": "Semantic-Guided Generative Image Augmentation Method with Diffusion Models for Image Classification",
    "volume": "main",
    "abstract": "Existing image augmentation methods consist of two categories: perturbation-based methods and generative methods. Perturbation-based methods apply pre-defined perturbations to augment an original image, but only locally vary the image, thus lacking image diversity. In contrast, generative methods bring more image diversity in the augmented images but may not preserve semantic consistency, thus may incorrectly change the essential semantics of the original image. To balance image diversity and semantic consistency in augmented images, we propose SGID, a Semantic-guided Generative Image augmentation method with Diffusion models for image classification. Specifically, SGID employs diffusion models to generate augmented images with good image diversity. More importantly, SGID takes image labels and captions as guidance to maintain semantic consistency between the augmented and original images. Experimental results show that SGID outperforms the best augmentation baseline by 1.72% on ResNet-50 (from scratch), 0.33% on ViT (ImageNet-21k), and 0.14% on CLIP-ViT (LAION-2B). Moreover, SGID can be combined with other image augmentation baselines and further improves the overall performance. We demonstrate the semantic consistency and image diversity of SGID through quantitative human and automated evaluations, as well as qualitative case studies",
    "checked": true,
    "id": "1e2c20d1c77aa2413cfaf362a77ec627462033f6",
    "semantic_title": "semantic-guided generative image augmentation method with diffusion models for image classification",
    "citation_count": 1,
    "authors": [
      "Bohan Li",
      "Xiao Xu",
      "Xinghao Wang",
      "Yutai Hou",
      "Yunlong Feng",
      "Feng Wang",
      "Xuanliang Zhang",
      "Qingfu Zhu",
      "Wanxiang Che"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28085": {
    "title": "One at a Time: Progressive Multi-Step Volumetric Probability Learning for Reliable 3D Scene Perception",
    "volume": "main",
    "abstract": "Numerous studies have investigated the pivotal role of reliable 3D volume representation in scene perception tasks, such as multi-view stereo (MVS) and semantic scene completion (SSC). They typically construct 3D probability volumes directly with geometric correspondence, attempting to fully address the scene perception tasks in a single forward pass. However, such a single-step solution makes it hard to learn accurate and convincing volumetric probability, especially in challenging regions like unexpected occlusions and complicated light reflections. Therefore, this paper proposes to decompose the complicated 3D volume representation learning into a sequence of generative steps to facilitate fine and reliable scene perception. Considering the recent advances achieved by strong generative diffusion models, we introduce a multi-step learning framework, dubbed as VPD, dedicated to progressively refining the Volumetric Probability in a Diffusion process. Specifically, we first build a coarse probability volume from input images with the off-the-shelf scene perception baselines, which is then conditioned as the basic geometry prior before being fed into a 3D diffusion UNet, to progressively achieve accurate probability distribution modeling. To handle the corner cases in challenging areas, a Confidence-Aware Contextual Collaboration (CACC) module is developed to correct the uncertain regions for reliable volumetric learning based on multi-scale contextual contents. Moreover, an Online Filtering (OF) strategy is designed to maintain representation consistency for stable diffusion sampling. Extensive experiments are conducted on scene perception tasks including multi-view stereo (MVS) and semantic scene completion (SSC), to validate the efficacy of our method in learning reliable volumetric representations. Notably, for the SSC task, our work stands out as the first to surpass LiDAR-based methods on the SemanticKITTI dataset",
    "checked": true,
    "id": "76cac517fdfb1b721265b38a7d90549258fe2339",
    "semantic_title": "one at a time: progressive multi-step volumetric probability learning for reliable 3d scene perception",
    "citation_count": 1,
    "authors": [
      "Bohan Li",
      "Yasheng Sun",
      "Jingxin Dong",
      "Zheng Zhu",
      "Jinming Liu",
      "Xin Jin",
      "Wenjun Zeng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28086": {
    "title": "AE-NeRF: Audio Enhanced Neural Radiance Field for Few Shot Talking Head Synthesis",
    "volume": "main",
    "abstract": "Audio-driven talking head synthesis is a promising topic with wide applications in digital human, film making and virtual reality. Recent NeRF-based approaches have shown superiority in quality and fidelity compared to previous studies. However, when it comes to few-shot talking head generation, a practical scenario where only few seconds of talking video is available for one identity, two limitations emerge: 1) they either have no base model, which serves as a facial prior for fast convergence, or ignore the importance of audio when building the prior; 2) most of them overlook the degree of correlation between different face regions and audio, e.g., mouth is audio related, while ear is audio independent. In this paper, we present Audio Enhanced Neural Radiance Field (AE-NeRF) to tackle the above issues, which can generate realistic portraits of a new speaker with few-shot dataset. Specifically, we introduce an Audio Aware Aggregation module into the feature fusion stage of the reference scheme, where the weight is determined by the similarity of audio between reference and target image. Then, an Audio-Aligned Face Generation strategy is proposed to model the audio related and audio independent regions respectively, with a dual-NeRF framework. Extensive experiments have shown AE-NeRF surpasses the state-of-the-art on image fidelity, audio-lip synchronization, and generalization ability, even in limited training set or training iterations",
    "checked": true,
    "id": "29f10d0e14e00e4749bb6003917035a66d44c746",
    "semantic_title": "ae-nerf: audio enhanced neural radiance field for few shot talking head synthesis",
    "citation_count": 2,
    "authors": [
      "Dongze Li",
      "Kang Zhao",
      "Wei Wang",
      "Bo Peng",
      "Yingya Zhang",
      "Jing Dong",
      "Tieniu Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28087": {
    "title": "Monocular 3D Hand Mesh Recovery via Dual Noise Estimation",
    "volume": "main",
    "abstract": "Current parametric models have made notable progress in 3D hand pose and shape estimation. However, due to the fixed hand topology and complex hand poses, current models are hard to generate meshes that are aligned with the image well. To tackle this issue, we introduce a dual noise estimation method in this paper. Given a single-view image as input, we first adopt a baseline parametric regressor to obtain the coarse hand meshes. We assume the mesh vertices and their image-plane projections are noisy, and can be associated in a unified probabilistic model. We then learn the distributions of noise to refine mesh vertices and their projections. The refined vertices are further utilized to refine camera parameters in a closed-form manner. Consequently, our method obtains well-aligned and high-quality 3D hand meshes. Extensive experiments on the large-scale Interhand2.6M dataset demonstrate that the proposed method not only improves the performance of its baseline by more than 10% but also achieves state-of-the-art performance. Project page: https://github.com/hanhuili/DNE4Hand",
    "checked": true,
    "id": "83f618c9633a1fefcf0e6fdea3f1a01e8ace02c2",
    "semantic_title": "monocular 3d hand mesh recovery via dual noise estimation",
    "citation_count": 0,
    "authors": [
      "Hanhui Li",
      "Xiaojian Lin",
      "Xuan Huang",
      "Zejun Yang",
      "Zhisheng Wang",
      "Xiaodan Liang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28088": {
    "title": "Point2Real: Bridging the Gap between Point Cloud and Realistic Image for Open-World 3D Recognition",
    "volume": "main",
    "abstract": "Recognition in open-world scenarios is an important and challenging field, where Vision-Language Pre-training paradigms have greatly impacted the 2D domain. This inspires a growing interest in introducing 2D pre-trained models, such as CLIP, into the 3D domain to enhance the ability of point cloud understanding. Considering the difference between discrete 3D point clouds and real-world 2D images, reducing the domain gap is crucial. Some recent works project point clouds onto a 2D plane to enable 3D zero-shot capabilities without training. However, this simplistic approach leads to an unclear or even distorted geometric structure, limiting the potential of 2D pre-trained models in 3D. To address the domain gap, we propose Point2Real, a training-free framework based on the realistic rendering technique to automate the transformation of the 3D point cloud domain into the Vision-Language domain. Specifically, Point2Real leverages a shape recovery module that devises an iterative ball-pivoting algorithm to convert point clouds into meshes, narrowing the gap in shape at first. To simulate photo-realistic images, a set of refined textures as candidates is applied for rendering, where the CLIP confidence is utilized to select the suitable one. Moreover, to tackle the viewpoint challenge, a heuristic multi-view adapter is implemented for feature aggregation, which exploits the depth surface as an effective indicator of view-specific discriminability for recognition. We conduct experiments on ModelNet10, ModelNet40, and ScanObjectNN datasets, and the results demonstrate that Point2Real outperforms other approaches in zero-shot and few-shot tasks by a large margin",
    "checked": true,
    "id": "f26f2c4d136cc802a6a156610deededd07f638ce",
    "semantic_title": "point2real: bridging the gap between point cloud and realistic image for open-world 3d recognition",
    "citation_count": 0,
    "authors": [
      "Hanxuan Li",
      "Bin Fu",
      "Ruiping Wang",
      "Xilin Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28089": {
    "title": "Gradual Residuals Alignment: A Dual-Stream Framework for GAN Inversion and Image Attribute Editing",
    "volume": "main",
    "abstract": "GAN-based image attribute editing firstly leverages GAN Inversion to project real images into the latent space of GAN and then manipulates corresponding latent codes. Recent inversion methods mainly utilize additional high-bit features to improve image details preservation, as low-bit codes cannot faithfully reconstruct source images, leading to the loss of details. However, during editing, existing works fail to accurately complement the lost details and suffer from poor editability. The main reason is they inject all the lost details indiscriminately at one time, which inherently induces the position and quantity of details to overfit source images, resulting in inconsistent content and artifacts in edited images. This work argues that details should be gradually injected into both the reconstruction and editing process in a multi-stage coarse-to-fine manner for better detail preservation and high editability. Therefore, a novel dual-stream framework is proposed to accurately complement details at each stage. The Reconstruction Stream is employed to embed coarse-to-fine lost details into residual features and then adaptively add them to the GAN generator. In the Editing Stream, residual features are accurately aligned by our Selective Attention mechanism and then injected into the editing process in a multi-stage manner. Extensive experiments have shown the superiority of our framework in both reconstruction accuracy and editing quality compared with existing methods",
    "checked": true,
    "id": "e950bff27ab92c14b4b12d6d99a765498e70b0ac",
    "semantic_title": "gradual residuals alignment: a dual-stream framework for gan inversion and image attribute editing",
    "citation_count": 1,
    "authors": [
      "Hao Li",
      "Mengqi Huang",
      "Lei Zhang",
      "Bo Hu",
      "Yi Liu",
      "Zhendong Mao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28090": {
    "title": "Towards Automated Chinese Ancient Character Restoration: A Diffusion-Based Method with a New Dataset",
    "volume": "main",
    "abstract": "Automated Chinese ancient character restoration (ACACR) remains a challenging task due to its historical significance and aesthetic complexity. Existing methods are constrained by non-professional masks and even overfitting when training on small-scale datasets, which hinder their interdisciplinary application to traditional fields. In this paper, we are proud to introduce the Chinese Ancient Rubbing and Manuscript Character Dataset (ARMCD), which consists of 15,553 real-world ancient single-character images with 42 rubbings and manuscripts, covering the works of over 200 calligraphy artists spanning from 200 to 1,800 AD. We are also dedicated to providing professional synthetic masks by extracting localized erosion from real eroded images. Moreover, we propose DiffACR (Diffusion model for automated Chinese Ancient Character Restoration), a diffusion-based method for the ACACR task. Specifically, we regard the synthesis of eroded images as a special form of cold diffusion on uneroded ones and extract the prior mask directly from the eroded images. Our experiments demonstrate that our method comprehensively outperforms most existing methods on the proposed ARMCD. Dataset and code are available at https://github.com/lhl322001/DiffACR",
    "checked": true,
    "id": "1397ed489c67b496008ad0587669ce9dede3d285",
    "semantic_title": "towards automated chinese ancient character restoration: a diffusion-based method with a new dataset",
    "citation_count": 0,
    "authors": [
      "Haolong Li",
      "Chenghao Du",
      "Ziheng Jiang",
      "Yifan Zhang",
      "Jiawei Ma",
      "Chen Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28091": {
    "title": "Learning Deformable Hypothesis Sampling for Accurate PatchMatch Multi-View Stereo",
    "volume": "main",
    "abstract": "This paper introduces a learnable Deformable Hypothesis Sampler (DeformSampler) to address the challenging issue of noisy depth estimation in faithful PatchMatch multi-view stereo (MVS). We observe that the heuristic depth hypothesis sampling modes employed by PatchMatch MVS solvers are insensitive to (i) the piece-wise smooth distribution of depths across the object surface and (ii) the implicit multi-modal distribution of depth prediction probabilities along the ray direction on the surface points. Accordingly, we develop DeformSampler to learn distribution-sensitive sample spaces to (i) propagate depths consistent with the scene's geometry across the object surface and (ii) fit a Laplace Mixture model that approaches the point-wise probabilities distribution of the actual depths along the ray direction. We integrate DeformSampler into a learnable PatchMatch MVS system to enhance depth estimation in challenging areas, such as piece-wise discontinuous surface boundaries and weakly-textured regions. Experimental results on DTU and Tanks & Temples datasets demonstrate its superior performance and generalization capabilities compared to state-of-the-art competitors. Code is available at https://github.com/Geo-Tell/DS-PMNet",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongjie Li",
      "Yao Guo",
      "Xianwei Zheng",
      "Hanjiang Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28092": {
    "title": "Catalyst for Clustering-Based Unsupervised Object Re-identification: Feature Calibration",
    "volume": "main",
    "abstract": "Clustering-based methods are emerging as a ubiquitous technology in unsupervised object Re-Identification (ReID), which alternate between pseudo-label generation and representation learning. Recent advances in this field mainly fall into two groups: pseudo-label correction and robust representation learning. Differently, in this work, we improve unsupervised object ReID from feature calibration, a completely different but complementary insight from the current approaches. Specifically, we propose to insert a conceptually simple yet empirically powerful Feature Calibration Module (FCM) before pseudo-label generation. In practice, FCM calibrates the features using a nonparametric graph attention network, enforcing similar instances to move together in the feature space while allowing dissimilar instances to separate. As a result, we can generate more reliable pseudo-labels using the calibrated features and further improve subsequent representation learning. FCM is simple, effective, parameter-free, training-free, plug-and-play, and can be considered as a catalyst, increasing the 'chemical reaction' between pseudo-label generation and representation learning. Moreover, it maintains the efficiency of testing time with negligible impact on training time. In this paper, we insert FCM into a simple baseline. Experiments across different scenarios and benchmarks show that FCM consistently improves the baseline (e.g., 8.2% mAP gain on MSMT17), and achieves the new state-of-the-art results. Code is available at: https://github.com/lhf12278/FCM-ReID",
    "checked": true,
    "id": "5b6d65bf0757486adfb6b57e3e73a096115ffa6b",
    "semantic_title": "catalyst for clustering-based unsupervised object re-identification: feature calibration",
    "citation_count": 1,
    "authors": [
      "Huafeng Li",
      "Qingsong Hu",
      "Zhanxuan Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28093": {
    "title": "EAN: An Efficient Attention Module Guided by Normalization for Deep Neural Networks",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) have achieved remarkable success in various fields, and two powerful techniques, feature normalization and attention mechanisms, have been widely used to enhance model performance. However, they are usually considered as two separate approaches or combined in a simplistic manner. In this paper, we investigate the intrinsic relationship between feature normalization and attention mechanisms and propose an Efficient Attention module guided by Normalization, dubbed EAN. Instead of using costly fully-connected layers for attention learning, EAN leverages the strengths of feature normalization and incorporates an Attention Generation (AG) unit to re-calibrate features. The proposed AG unit exploits the normalization component as a measure of the importance of distinct features and generates an attention mask using GroupNorm, L2 Norm, and Adaptation operations. By employing a grouping, AG unit and aggregation strategy, EAN is established, offering a unified module that harnesses the advantages of both normalization and attention, while maintaining minimal computational overhead. Furthermore, EAN serves as a plug-and-play module that can be seamlessly integrated with classic backbone architectures. Extensive quantitative evaluations on various visual tasks demonstrate that EAN achieves highly competitive performance compared to the current state-of-the-art attention methods while sustaining lower model complexity",
    "checked": true,
    "id": "5a0b5d323adea5053380b7583dc12aa27a720813",
    "semantic_title": "ean: an efficient attention module guided by normalization for deep neural networks",
    "citation_count": 0,
    "authors": [
      "Jiafeng Li",
      "Zelin Li",
      "Ying Wen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28094": {
    "title": "Label-Efficient Few-Shot Semantic Segmentation with Unsupervised Meta-Training",
    "volume": "main",
    "abstract": "The goal of this paper is to alleviate the training cost for few-shot semantic segmentation (FSS) models. Despite that FSS in nature improves model generalization to new concepts using only a handful of test exemplars, it relies on strong supervision from a considerable amount of labeled training data for base classes. However, collecting pixel-level annotations is notoriously expensive and time-consuming, and small-scale training datasets convey low information density that limits test-time generalization. To resolve the issue, we take a pioneering step towards label-efficient training of FSS models from fully unlabeled training data, or additionally a few labeled samples to enhance the performance. This motivates an approach based on a novel unsupervised meta-training paradigm. In particular, the approach first distills pre-trained unsupervised pixel embedding into compact semantic clusters from which a massive number of pseudo meta-tasks is constructed. To mitigate the noise in the pseudo meta-tasks, we further advocate a robust Transformer-based FSS model with a novel prototype-based cross-attention design. Extensive experiments have been conducted on two standard benchmarks, i.e., PASCAL-5i and COCO-20i, and the results show that our method produces impressive performance without any annotations, and is comparable to fully supervised competitors even using only 20% of the annotations. Our code is available at: https://github.com/SSSKYue/UMTFSS",
    "checked": true,
    "id": "4dd949b1703c07a1e1909715f9d85d1c71bf04e8",
    "semantic_title": "label-efficient few-shot semantic segmentation with unsupervised meta-training",
    "citation_count": 0,
    "authors": [
      "Jianwu Li",
      "Kaiyue Shi",
      "Guo-Sen Xie",
      "Xiaofeng Liu",
      "Jian Zhang",
      "Tianfei Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28095": {
    "title": "FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy Labels",
    "volume": "main",
    "abstract": "Federated Learning with Noisy Labels (F-LNL) aims at seeking an optimal server model via collaborative distributed learning by aggregating multiple client models trained with local noisy or clean samples. On the basis of a federated learning framework, recent advances primarily adopt label noise filtering to separate clean samples from noisy ones on each client, thereby mitigating the negative impact of label noise. However, these prior methods do not learn noise filters by exploiting knowledge across all clients, leading to sub-optimal and inferior noise filtering performance and thus damaging training stability. In this paper, we present FedDiv to tackle the challenges of F-LNL. Specifically, we propose a global noise filter called Federated Noise Filter for effectively identifying samples with noisy labels on every client, thereby raising stability during local training sessions. Without sacrificing data privacy, this is achieved by modeling the global distribution of label noise across all clients. Then, in an effort to make the global model achieve higher performance, we introduce a Predictive Consistency based Sampler to identify more credible local data for local model training, thus preventing noise memorization and further boosting the training stability. Extensive experiments on CIFAR-10, CIFAR-100, and Clothing1M demonstrate that FedDiv achieves superior performance over state-of-the-art F-LNL methods under different label noise settings for both IID and non-IID data partitions. Source code is publicly available at https://github.com/lijichang/FLNL-FedDiv",
    "checked": true,
    "id": "064dcb85d67231075a768cbfed65264402c72b91",
    "semantic_title": "feddiv: collaborative noise filtering for federated learning with noisy labels",
    "citation_count": 4,
    "authors": [
      "Jichang Li",
      "Guanbin Li",
      "Hui Cheng",
      "Zicheng Liao",
      "Yizhou Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28096": {
    "title": "Fully Data-Driven Pseudo Label Estimation for Pointly-Supervised Panoptic Segmentation",
    "volume": "main",
    "abstract": "The core of pointly-supervised panoptic segmentation is estimating accurate dense pseudo labels from sparse point labels to train the panoptic head. Previous works generate pseudo labels mainly based on hand-crafted rules, such as connecting multiple points into polygon masks, or assigning the label information of labeled pixels to unlabeled pixels based on the artificially defined traversing distance. The accuracy of pseudo labels is limited by the quality of the hand-crafted rules (polygon masks are rough at object contour regions, and the traversing distance error will result in wrong pseudo labels). To overcome the limitation of hand-crafted rules, we estimate pseudo labels with a fully data-driven pseudo label branch, which is optimized by point labels end-to-end and predicts more accurate pseudo labels than previous methods. We also train an auxiliary semantic branch with point labels, it assists the training of the pseudo label branch by transferring semantic segmentation knowledge through shared parameters. Experiments on Pascal VOC and MS COCO demonstrate that our approach is effective and shows state-of-the-art performance compared with related works. Codes are available at https://github.com/BraveGroup/FDD",
    "checked": true,
    "id": "da3d0e947f958111a73b7c031635adf4239cfddd",
    "semantic_title": "fully data-driven pseudo label estimation for pointly-supervised panoptic segmentation",
    "citation_count": 0,
    "authors": [
      "Jing Li",
      "Junsong Fan",
      "Yuran Yang",
      "Shuqi Mei",
      "Jun Xiao",
      "Zhaoxiang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28097": {
    "title": "FAVOR: Full-Body AR-Driven Virtual Object Rearrangement Guided by Instruction Text",
    "volume": "main",
    "abstract": "Rearrangement operations form the crux of interactions between humans and their environment. The ability to generate natural, fluid sequences of this operation is of essential value in AR/VR and CG. Bridging a gap in the field, our study introduces FAVOR: a novel dataset for Full-body AR-driven Virtual Object Rearrangement that uniquely employs motion capture systems and AR eyeglasses. Comprising 3k diverse motion rearrangement sequences and 7.17 million interaction data frames, this dataset breaks new ground in research data. We also present a pipeline FAVORITE for producing digital human rearrangement motion sequences guided by instructions. Experimental results, both qualitative and quantitative, suggest that this dataset and pipeline deliver high-quality motion sequences. Our dataset, code, and appendix are available at https://kailinli.github.io/FAVOR",
    "checked": true,
    "id": "dbc48d6b266151e6f89382536079ef0e624445f7",
    "semantic_title": "favor: full-body ar-driven virtual object rearrangement guided by instruction text",
    "citation_count": 2,
    "authors": [
      "Kailin Li",
      "Lixin Yang",
      "Zenan Lin",
      "Jian Xu",
      "Xinyu Zhan",
      "Yifei Zhao",
      "Pengxiang Zhu",
      "Wenxiong Kang",
      "Kejian Wu",
      "Cewu Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28098": {
    "title": "Panoptic Scene Graph Generation with Semantics-Prototype Learning",
    "volume": "main",
    "abstract": "Panoptic Scene Graph Generation (PSG) parses objects and predicts their relationships (predicate) to connect human language and visual scenes. However, different language preferences of annotators and semantic overlaps between predicates lead to biased predicate annotations in the dataset, i.e. different predicates for the same object pairs. Biased predicate annotations make PSG models struggle in constructing a clear decision plane among predicates, which greatly hinders the real application of PSG models. To address the intrinsic bias above, we propose a novel framework named ADTrans to adaptively transfer biased predicate annotations to informative and unified ones. To promise consistency and accuracy during the transfer process, we propose to observe the invariance degree of representations in each predicate class, and learn unbiased prototypes of predicates with different intensities. Meanwhile, we continuously measure the distribution changes between each presentation and its prototype, and constantly screen potentially biased data. Finally, with the unbiased predicate-prototype representation embedding space, biased annotations are easily identified. Experiments show that ADTrans significantly improves the performance of benchmark models, achieving a new state-of-the-art performance, and shows great generalization and effectiveness on multiple datasets. Our code is released at https://github.com/lili0415/PSG-biased-annotation",
    "checked": true,
    "id": "ad15b5abc44d4e2520bb16c0cf06c31ed461b599",
    "semantic_title": "panoptic scene graph generation with semantics-prototype learning",
    "citation_count": 19,
    "authors": [
      "Li Li",
      "Wei Ji",
      "Yiming Wu",
      "Mengze Li",
      "You Qin",
      "Lina Wei",
      "Roger Zimmermann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28099": {
    "title": "SpectralNeRF: Physically Based Spectral Rendering with Neural Radiance Field",
    "volume": "main",
    "abstract": "In this paper, we propose SpectralNeRF, an end-to-end Neural Radiance Field (NeRF)-based architecture for high-quality physically based rendering from a novel spectral perspective. We modify the classical spectral rendering into two main steps, 1) the generation of a series of spectrum maps spanning different wavelengths, 2) the combination of these spectrum maps for the RGB output. Our SpectralNeRF follows these two steps through the proposed multi-layer perceptron (MLP)-based architecture (SpectralMLP) and Spectrum Attention UNet (SAUNet). Given the ray origin and the ray direction, the SpectralMLP constructs the spectral radiance field to obtain spectrum maps of novel views, which are then sent to the SAUNet to produce RGB images of white-light illumination. Applying NeRF to build up the spectral rendering is a more physically-based way from the perspective of ray-tracing. Further, the spectral radiance fields decompose difficult scenes and improve the performance of NeRF-based methods. Comprehensive experimental results demonstrate the proposed SpectralNeRF is superior to recent NeRF-based methods when synthesizing new views on synthetic and real datasets. The codes and datasets are available at https://github.com/liru0126/SpectralNeRF",
    "checked": true,
    "id": "b368b958476a002dc7d1205e97d131cec15cbb56",
    "semantic_title": "spectralnerf: physically based spectral rendering with neural radiance field",
    "citation_count": 1,
    "authors": [
      "Ru Li",
      "Jia Liu",
      "Guanghui Liu",
      "Shengping Zhang",
      "Bing Zeng",
      "Shuaicheng Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28100": {
    "title": "GridFormer: Point-Grid Transformer for Surface Reconstruction",
    "volume": "main",
    "abstract": "Implicit neural networks have emerged as a crucial technology in 3D surface reconstruction. To reconstruct continuous surfaces from discrete point clouds, encoding the input points into regular grid features (plane or volume) has been commonly employed in existing approaches. However, these methods typically use the grid as an index for uniformly scattering point features. Compared with the irregular point features, the regular grid features may sacrifice some reconstruction details but improve efficiency. To take full advantage of these two types of features, we introduce a novel and high-efficiency attention mechanism between the grid and point features named Point-Grid Transformer (GridFormer). This mechanism treats the grid as a transfer point connecting the space and point cloud. Our method maximizes the spatial expressiveness of grid features and maintains computational efficiency. Furthermore, optimizing predictions over the entire space could potentially result in blurred boundaries. To address this issue, we further propose a boundary optimization strategy incorporating margin binary cross-entropy loss and boundary sampling. This approach enables us to achieve a more precise representation of the object structure. Our experiments validate that our method is effective and outperforms the state-of-the-art approaches under widely used benchmarks by producing more precise geometry reconstructions. The code is available at https://github.com/list17/GridFormer",
    "checked": true,
    "id": "527753455847ee9ac6bc2a9b98d4e5406b8a5157",
    "semantic_title": "gridformer: point-grid transformer for surface reconstruction",
    "citation_count": 1,
    "authors": [
      "Shengtao Li",
      "Ge Gao",
      "Yudong Liu",
      "Yu-Shen Liu",
      "Ming Gu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28101": {
    "title": "Adaptive Uncertainty-Based Learning for Text-Based Person Retrieval",
    "volume": "main",
    "abstract": "Text-based person retrieval aims at retrieving a specific pedestrian image from a gallery based on textual descriptions. The primary challenge is how to overcome the inherent heterogeneous modality gap in the situation of significant intra-class variation and minimal inter-class variation. Existing approaches commonly employ vision-language pre-training or attention mechanisms to learn appropriate cross-modal alignments from noise inputs. Despite commendable progress, current methods inevitably suffer from two defects: 1) Matching ambiguity, which mainly derives from unreliable matching pairs; 2) One-sided cross-modal alignments, stemming from the absence of exploring one-to-many correspondence, i.e., coarse-grained semantic alignment. These critical issues significantly deteriorate retrieval performance. To this end, we propose a novel framework termed Adaptive Uncertainty-based Learning (AUL) for text-based person retrieval from the uncertainty perspective. Specifically, our AUL framework consists of three key components: 1) Uncertainty-aware Matching Filtration that leverages Subjective Logic to effectively mitigate the disturbance of unreliable matching pairs and select high-confidence cross-modal matches for training; 2) Uncertainty-based Alignment Refinement, which not only simulates coarse-grained alignments by constructing uncertainty representations but also performs progressive learning to incorporate coarse- and fine-grained alignments properly; 3) Cross-modal Masked Modeling that aims at exploring more comprehensive relations between vision and language. Extensive experiments demonstrate that our AUL method consistently achieves state-of-the-art performance on three benchmark datasets in supervised, weakly supervised, and domain generalization settings. Our code is available at https://github.com/CFM-MSG/Code-AUL",
    "checked": true,
    "id": "7b2dff4bec69aa6511590608ce8bfb200ba70215",
    "semantic_title": "adaptive uncertainty-based learning for text-based person retrieval",
    "citation_count": 1,
    "authors": [
      "Shenshen Li",
      "Chen He",
      "Xing Xu",
      "Fumin Shen",
      "Yang Yang",
      "Heng Tao Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28102": {
    "title": "Learning Continuous Implicit Field with Local Distance Indicator for Arbitrary-Scale Point Cloud Upsampling",
    "volume": "main",
    "abstract": "Point cloud upsampling aims to generate dense and uniformly distributed point sets from a sparse point cloud, which plays a critical role in 3D computer vision. Previous methods typically split a sparse point cloud into several local patches, upsample patch points, and merge all upsampled patches. However, these methods often produce holes, outliers or non-uniformity due to the splitting and merging process which does not maintain consistency among local patches.To address these issues, we propose a novel approach that learns an unsigned distance field guided by local priors for point cloud upsampling. Specifically, we train a local distance indicator (LDI) that predicts the unsigned distance from a query point to a local implicit surface. Utilizing the learned LDI, we learn an unsigned distance field to represent the sparse point cloud with patch consistency. At inference time, we randomly sample queries around the sparse point cloud, and project these query points onto the zero-level set of the learned implicit field to generate a dense point cloud. We justify that the implicit field is naturally continuous, which inherently enables the application of arbitrary-scale upsampling without necessarily retraining for various scales. We conduct comprehensive experiments on both synthetic data and real scans, and report state-of-the-art results under widely used benchmarks. Project page: https://lisj575.github.io/APU-LDI",
    "checked": true,
    "id": "d45bcd82fd2859475f06115da115a2b62acd6900",
    "semantic_title": "learning continuous implicit field with local distance indicator for arbitrary-scale point cloud upsampling",
    "citation_count": 2,
    "authors": [
      "Shujuan Li",
      "Junsheng Zhou",
      "Baorui Ma",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28103": {
    "title": "Long-Tailed Learning as Multi-Objective Optimization",
    "volume": "main",
    "abstract": "Real-world data is extremely imbalanced and presents a long-tailed distribution, resulting in models biased towards classes with sufficient samples and performing poorly on rare classes. Recent methods propose to rebalance classes but they undertake the seesaw dilemma (what is increasing performance on tail classes may decrease that of head classes, and vice versa). In this paper, we argue that the seesaw dilemma is derived from the gradient imbalance of different classes, in which gradients of inappropriate classes are set to important for updating, thus prone to overcompensation or undercompensation on tail classes. To achieve ideal compensation, we formulate long-tailed recognition as a multi-objective optimization problem, which fairly respects the contributions of head and tail classes simultaneously. For efficiency, we propose a Gradient-Balancing Grouping (GBG) strategy to gather the classes with similar gradient directions, thus approximately making every update under a Pareto descent direction. Our GBG method drives classes with similar gradient directions to form a more representative gradient and provides ideal compensation to the tail classes. Moreover, we conduct extensive experiments on commonly used benchmarks in long-tailed learning and demonstrate the superiority of our method over existing SOTA methods. Our code is released at https://github.com/WickyLee1998/GBG_v1",
    "checked": true,
    "id": "7056b7b7be998425fdac5fde072d6f9b7f027138",
    "semantic_title": "long-tailed learning as multi-objective optimization",
    "citation_count": 1,
    "authors": [
      "Weiqi Li",
      "Fan Lyu",
      "Fanhua Shang",
      "Liang Wan",
      "Wei Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28104": {
    "title": "Temporal-Distributed Backdoor Attack against Video Based Action Recognition",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) have achieved tremendous success in various applications including video action recognition, yet remain vulnerable to backdoor attacks (Trojans). The backdoor-compromised model will mis-classify to the target class chosen by the attacker when a test instance (from a non-target class) is embedded with a specific trigger, while maintaining high accuracy on attack-free instances. Although there are extensive studies on backdoor attacks against image data, the susceptibility of video-based systems under backdoor attacks remains largely unexplored. Current studies are direct extensions of approaches proposed for image data, e.g., the triggers are independently embedded within the frames, which tend to be detectable by existing defenses. In this paper, we introduce a simple yet effective backdoor attack against video data. Our proposed attack, adding perturbations in a transformed domain, plants an imperceptible, temporally distributed trigger across the video frames, and is shown to be resilient to existing defensive strategies. The effectiveness of the proposed attack is demonstrated by extensive experiments with various well-known models on two video recognition benchmarks, UCF101 and HMDB51, and a sign language recognition benchmark, Greek Sign Language (GSL) dataset. We delve into the impact of several influential factors on our proposed attack and identify an intriguing effect termed \"collateral damage\" through extensive studies",
    "checked": true,
    "id": "a717ebfe821d1f8defd22abc73ce992334c56b0b",
    "semantic_title": "temporal-distributed backdoor attack against video based action recognition",
    "citation_count": 4,
    "authors": [
      "Xi Li",
      "Songhe Wang",
      "Ruiquan Huang",
      "Mahanth Gowda",
      "George Kesidis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28105": {
    "title": "DI-V2X: Learning Domain-Invariant Representation for Vehicle-Infrastructure Collaborative 3D Object Detection",
    "volume": "main",
    "abstract": "Vehicle-to-Everything (V2X) collaborative perception has recently gained significant attention due to its capability to enhance scene understanding by integrating information from various agents, e.g., vehicles, and infrastructure. However, current works often treat the information from each agent equally, ignoring the inherent domain gap caused by the utilization of different LiDAR sensors of each agent, thus leading to suboptimal performance. In this paper, we propose DI-V2X, that aims to learn Domain-Invariant representations through a new distillation framework to mitigate the domain discrepancy in the context of V2X 3D object detection. DI-V2X comprises three essential components: a domain-mixing instance augmentation (DMA) module, a progressive domain-invariant distillation (PDD) module, and a domain-adaptive fusion (DAF) module. Specifically, DMA builds a domain-mixing 3D instance bank for the teacher and student models during training, resulting in aligned data representation. Next, PDD encourages the student models from different domains to gradually learn a domain-invariant feature representation towards the teacher, where the overlapping regions between agents are employed as guidance to facilitate the distillation process. Furthermore, DAF closes the domain gap between the students by incorporating calibration-aware domain-adaptive attention. Extensive experiments on the challenging DAIR-V2X and V2XSet benchmark datasets demonstrate DI-V2X achieves remarkable performance, outperforming all the previous V2X models. Code is available at https://github.com/Serenos/DI-V2X",
    "checked": true,
    "id": "7205815c010275d481a52004434821143d8b8c0b",
    "semantic_title": "di-v2x: learning domain-invariant representation for vehicle-infrastructure collaborative 3d object detection",
    "citation_count": 6,
    "authors": [
      "Xiang Li",
      "Junbo Yin",
      "Wei Li",
      "Chengzhong Xu",
      "Ruigang Yang",
      "Jianbing Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28106": {
    "title": "Multi-Modality Affinity Inference for Weakly Supervised 3D Semantic Segmentation",
    "volume": "main",
    "abstract": "3D point cloud semantic segmentation has a wide range of applications. Recently, weakly supervised point cloud segmentation methods have been proposed, aiming to alleviate the expensive and laborious manual annotation process by leveraging scene-level labels. However, these methods have not effectively exploited the rich geometric information (such as shape and scale) and appearance information (such as color and texture) present in RGB-D scans. Furthermore, current approaches fail to fully leverage the point affinity that can be inferred from the feature extraction network, which is crucial for learning from weak scene-level labels. Additionally, previous work overlooks the detrimental effects of the long-tailed distribution of point cloud data in weakly supervised 3D semantic segmentation. To this end, this paper proposes a simple yet effective scene-level weakly supervised point cloud segmentation method with a newly introduced multi-modality point affinity inference module. The point affinity proposed in this paper is characterized by features from multiple modalities (e.g., point cloud and RGB), and is further refined by normalizing the classifier weights to alleviate the detrimental effects of long-tailed distribution without the need of the prior of category distribution. Extensive experiments on the ScanNet and S3DIS benchmarks verify the effectiveness of our proposed method, which outperforms the state-of-the-art by ~4% to ~ 6% mIoU. Codes are released at https://github.com/Sunny599/AAAI24-3DWSSG-MMA",
    "checked": true,
    "id": "7712928cc56933648473c3c6349209996fdfba07",
    "semantic_title": "multi-modality affinity inference for weakly supervised 3d semantic segmentation",
    "citation_count": 1,
    "authors": [
      "Xiawei Li",
      "Qingyuan Xu",
      "Jing Zhang",
      "Tianyi Zhang",
      "Qian Yu",
      "Lu Sheng",
      "Dong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28107": {
    "title": "IINet: Implicit Intra-inter Information Fusion for Real-Time Stereo Matching",
    "volume": "main",
    "abstract": "Recently, there has been a growing interest in 3D CNN-based stereo matching methods due to their remarkable accuracy. However, the high complexity of 3D convolution makes it challenging to strike a balance between accuracy and speed. Notably, explicit 3D volumes contain considerable redundancy. In this study, we delve into more compact 2D implicit network to eliminate redundancy and boost real-time performance. However, simply replacing explicit 3D networks with 2D implicit networks causes issues that can lead to performance degradation, including the loss of structural information, the quality decline of inter-image information, as well as the inaccurate regression caused by low-level features. To address these issues, we first integrate intra-image information to fuse with inter-image information, facilitating propagation guided by structural cues. Subsequently, we introduce the Fast Multi-scale Score Volume (FMSV) and Confidence Based Filtering (CBF) to efficiently acquire accurate multi-scale, noise-free inter-image information. Furthermore, combined with the Residual Context-aware Upsampler (RCU), our Intra-Inter Fusing network is meticulously designed to enhance information transmission on both feature-level and disparity-level, thereby enabling accurate and robust regression. Experimental results affirm the superiority of our network in terms of both speed and accuracy compared to all other fast methods",
    "checked": true,
    "id": "f9fef9ef3d2b6a4e9a6a01aabdf35d65c19af2b2",
    "semantic_title": "iinet: implicit intra-inter information fusion for real-time stereo matching",
    "citation_count": 3,
    "authors": [
      "Ximeng Li",
      "Chen Zhang",
      "Wanjuan Su",
      "Wenbing Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28108": {
    "title": "Causal Representation Learning via Counterfactual Intervention",
    "volume": "main",
    "abstract": "Existing causal representation learning methods are based on the causal graph they build. However, due to the omission of bias within the causal graph, they essentially encourage models to learn biased causal effects in latent space. In this paper, we propose a novel causally disentangling framework that aims to learn unbiased causal effects. We first introduce inductive and dataset biases into traditional causal graph for the physical concepts of interest. Then, we eliminate the negative effects from these two biases by counterfactual intervention with reweighted loss function for learning unbiased causal effects. Finally, we employ the causal effects into the VAE to endow the latent representations with causality. In particular, we highlight that removing biases in this paper is regarded as a part of learning process for unbiased causal effects, which is crucial for causal disentanglement performance improvement. Through extensive experiments on real-world and synthetic datasets, we show that our method outperforms different baselines and obtains the state-of-the-art results for achieving causal representation learning",
    "checked": true,
    "id": "9a7768fd651aad877f3ffb16d0f3da1aa48abb54",
    "semantic_title": "causal representation learning via counterfactual intervention",
    "citation_count": 1,
    "authors": [
      "Xiutian Li",
      "Siqi Sun",
      "Rui Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28109": {
    "title": "Bi-ViT: Pushing the Limit of Vision Transformer Quantization",
    "volume": "main",
    "abstract": "Vision transformers (ViTs) quantization offers a promising prospect to facilitate deploying large pre-trained networks on resource-limited devices. Fully-binarized ViTs (Bi-ViT) that pushes the quantization of ViTs to its limit remain largely unexplored and a very challenging task yet, due to their unacceptable performance. Through extensive empirical analyses, we identify the severe drop in ViT binarization is caused by attention distortion in self-attention, which technically stems from the gradient vanishing and ranking disorder. To address these issues, we first introduce a learnable scaling factor to reactivate the vanished gradients and illustrate its effectiveness through theoretical and experimental analyses. We then propose a ranking-aware distillation method to rectify the disordered ranking in a teacher-student framework. Bi-ViT achieves significant improvements over popular DeiT and Swin backbones in terms of Top-1 accuracy and FLOPs. For example, with DeiT-Tiny and Swin-Tiny, our method significantly outperforms baselines by 22.1% and 21.4% respectively, while 61.5x and 56.1x theoretical acceleration in terms of FLOPs compared with real-valued counterparts on ImageNet. Our codes and models are attached on https://github.com/YanjingLi0202/Bi-ViT/",
    "checked": true,
    "id": "b48a85980deb5f1baa64d862b9f0e4e62124e4de",
    "semantic_title": "bi-vit: pushing the limit of vision transformer quantization",
    "citation_count": 1,
    "authors": [
      "Yanjing Li",
      "Sheng Xu",
      "Mingbao Lin",
      "Xianbin Cao",
      "Chuanjian Liu",
      "Xiao Sun",
      "Baochang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28110": {
    "title": "Harnessing Edge Information for Improved Robustness in Vision Transformers",
    "volume": "main",
    "abstract": "Deep Neural Networks (DNNs) have demonstrated remarkable accuracy in vision classification tasks. However, they exhibit vulnerability to additional noises known as adversarial attacks. Previous studies hypothesize that this vulnerability might stem from the fact that high-accuracy DNNs heavily rely on irrelevant and non-robust features, such as textures and the background. In this work, we reveal that edge information extracted from images can provide relevant and robust features related to shapes and the foreground. These features assist pretrained DNNs in achieving improved adversarial robustness without compromising their accuracy on clean images. A lightweight and plug-and-play EdgeNet is proposed, which can be seamlessly integrated into existing pretrained DNNs, including Vision Transformers, a recent family of state-of-the-art models for vision classification. Our EdgeNet can process edges derived from either clean nature images or noisy adversarial images, yielding robust features which can be injected into the intermediate layers of the frozen backbone DNNs. The cost of obtaining such edges using conventional edge detection algorithms (e.g., Canny edge detector) is marginal, and the cost of training the EdgeNet is equivalent to that of fine-tuning the backbone network with techniques such as Adapter",
    "checked": true,
    "id": "f57183918c68c1571bcf172a7085b206302065a4",
    "semantic_title": "harnessing edge information for improved robustness in vision transformers",
    "citation_count": 0,
    "authors": [
      "Yanxi Li",
      "Chengbin  Du",
      "Chang Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28111": {
    "title": "Multi-Region Text-Driven Manipulation of Diffusion Imagery",
    "volume": "main",
    "abstract": "Text-guided image manipulation has attracted significant attention recently. Prevailing techniques concentrate on image attribute editing for individual objects, however, encountering challenges when it comes to multi-object editing. The main reason is the lack of consistency constraints on the spatial layout. This work presents a multi-region guided image manipulation framework, enabling manipulation through region-level textual prompts. With MultiDiffusion as a baseline, we are dedicated to the automatic generation of a rational multi-object spatial distribution, where disparate regions are fused as a unified entity. To mitigate interference from regional fusion, we employ an off-the-shelf model (CLIP) to impose region-aware spatial guidance on multi-object manipulation. Moreover, when applied to the StableDiffusion, the presence of quality-related yet object-agnostic lengthy words hampers the manipulation. To ensure focus on meaningful object-specific words for efficient guidance and generation, we introduce a keyword selection method. Furthermore, we demonstrate a downstream application of our method for multi-region inversion, which is tailored for manipulating multiple objects in real images. Our approach, compatible with variants of Stable Diffusion models, is readily applicable for manipulating diverse objects in extensive images with high-quality generation, showing superb image control capabilities. Code is available at https://github.com/liyiming09/multi-region-guided-diffusion",
    "checked": true,
    "id": "64b8f1b57fd0f79dbabb814f541f7b0ede2103eb",
    "semantic_title": "multi-region text-driven manipulation of diffusion imagery",
    "citation_count": 0,
    "authors": [
      "Yiming Li",
      "Peng  Zhou",
      "Jun Sun",
      "Yi Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28112": {
    "title": "Direct May Not Be the Best: An Incremental Evolution View of Pose Generation",
    "volume": "main",
    "abstract": "Pose diversity is an inherent representative characteristic of 2D images. Due to the 3D to 2D projection mechanism, there is evident content discrepancy among distinct pose images. This is the main obstacle bothering pose transformation related researches. To deal with this challenge, we propose a fine-grained incremental evolution centered pose generation framework, rather than traditional direct one-to-one in a rush. Since proposed approach actually bypasses the theoretical difficulty of directly modeling dramatic non-linear variation, the incurred content distortion and blurring could be effectively constrained, at the same time the various individual pose details, especially clothes texture, could be precisely maintained. In order to systematically guide the evolution course, both global and incremental evolution constraints are elaborately designed and merged into the overall framework. And a novel triple-path knowledge fusion structure is worked out to take full advantage of all available valuable knowledge to conduct high-quality pose synthesis. In addition, our framework could generate a series of valuable by-products, namely the various intermediate poses. Extensive experiments have been conducted to verify the effectiveness of the proposed approach. Code is available at https://github.com/Xiaofei-CN/Incremental-Evolution-Pose-Generation",
    "checked": true,
    "id": "560153fbadf7dd147fee5688cbd13f445118fc15",
    "semantic_title": "direct may not be the best: an incremental evolution view of pose generation",
    "citation_count": 0,
    "authors": [
      "Yuelong Li",
      "Tengfei Xiao",
      "Lei Geng",
      "Jianming Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28113": {
    "title": "FocalDreamer: Text-Driven 3D Editing via Focal-Fusion Assembly",
    "volume": "main",
    "abstract": "While text-3D editing has made significant strides in leveraging score distillation sampling, emerging approaches still fall short in delivering separable, precise and consistent outcomes that are vital to content creation. In response, we introduce FocalDreamer, a framework that merges base shape with editable parts according to text prompts for fine-grained editing within desired regions. Specifically, equipped with geometry union and dual-path rendering, FocalDreamer assembles independent 3D parts into a complete object, tailored for convenient instance reuse and part-wise control. We propose geometric focal loss and style consistency regularization, which encourage focal fusion and congruent overall appearance. Furthermore, FocalDreamer generates high-fidelity geometry and PBR textures which are compatible with widely-used graphics engines. Extensive experiments have highlighted the superior editing capabilities of FocalDreamer in both quantitative and qualitative evaluations",
    "checked": true,
    "id": "b89cdd726f41fcbbaa076f6a3a2bc420ab6643bf",
    "semantic_title": "focaldreamer: text-driven 3d editing via focal-fusion assembly",
    "citation_count": 35,
    "authors": [
      "Yuhan Li",
      "Yishun Dou",
      "Yue Shi",
      "Yu Lei",
      "Xuanhong Chen",
      "Yi Zhang",
      "Peng  Zhou",
      "Bingbing Ni"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28114": {
    "title": "SAVSR: Arbitrary-Scale Video Super-Resolution via a Learned Scale-Adaptive Network",
    "volume": "main",
    "abstract": "Deep learning-based video super-resolution (VSR) networks have gained significant performance improvements in recent years. However, existing VSR networks can only support a fixed integer scale super-resolution task, and when we want to perform VSR at multiple scales, we need to train several models. This implementation certainly increases the consumption of computational and storage resources, which limits the application scenarios of VSR techniques. In this paper, we propose a novel Scale-adaptive Arbitrary-scale Video Super-Resolution network (SAVSR), which is the first work focusing on spatial VSR at arbitrary scales including both non-integer and asymmetric scales. We also present an omni-dimensional scale-attention convolution, which dynamically adapts according to the scale of the input to extract inter-frame features with stronger representational power. Moreover, the proposed spatio-temporal adaptive arbitrary-scale upsampling performs VSR tasks using both temporal features and scale information. And we design an iterative bi-directional architecture for implicit feature alignment. Experiments at various scales on the benchmark datasets show that the proposed SAVSR outperforms state-of-the-art (SOTA) methods at non-integer and asymmetric scales. The source code is available at https://github.com/Weepingchestnut/SAVSR",
    "checked": true,
    "id": "e9dbfe1b8ff3c62ba98c12f13d2d03f07c805a24",
    "semantic_title": "savsr: arbitrary-scale video super-resolution via a learned scale-adaptive network",
    "citation_count": 1,
    "authors": [
      "Zekun Li",
      "Hongying Liu",
      "Fanhua Shang",
      "Yuanyuan Liu",
      "Liang Wan",
      "Wei Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28115": {
    "title": "Sampling-Resilient Multi-Object Tracking",
    "volume": "main",
    "abstract": "Multi-Object Tracking (MOT) is a cornerstone operator for video surveillance applications. To enable real-time processing of large-scale live video streams, we study an interesting scenario called down-sampled MOT, which performs object tracking only on a small subset of video frames. The problem is challenging for state-of-the-art MOT methods, which exhibit significant performance degradation under high frame reduction ratios. In this paper, we devise a sampling-resilient tracker with a novel sparse-observation Kalman filter (SOKF). It integrates an LSTM network to capture non-linear and dynamic motion patterns caused by sparse observations. Since the LSTM-based state transition is not compatible with the original noise estimation mechanism, we propose new estimation strategies based on Bayesian neural networks and derive the optimal Kalman gain for SOKF. To associate the detected bounding boxes robustly, we also propose a comprehensive similarity metric that systematically integrates multiple spatial matching signals. Experiments on three benchmark datasets show that our proposed tracker achieves the best trade-off between efficiency and accuracy. With the same tracking accuracy, we reduce the total processing time of ByteTrack by 2× in MOT17 and 3× in DanceTrack",
    "checked": true,
    "id": "ea3fe33fc17255d73d5964b0c6845558e723ae14",
    "semantic_title": "sampling-resilient multi-object tracking",
    "citation_count": 0,
    "authors": [
      "Zepeng Li",
      "Dongxiang  Zhang",
      "Sai Wu",
      "Mingli Song",
      "Gang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28116": {
    "title": "Object-Aware Adaptive-Positivity Learning for Audio-Visual Question Answering",
    "volume": "main",
    "abstract": "This paper focuses on the Audio-Visual Question Answering (AVQA) task that aims to answer questions derived from untrimmed audible videos. To generate accurate answers, an AVQA model is expected to find the most informative audio-visual clues relevant to the given questions. In this paper, we propose to explicitly consider fine-grained visual objects in video frames (object-level clues) and explore the multi-modal relations (\\textit{i.e.}, the object, audio, and question) in terms of feature interaction and model optimization. For the former, we present an end-to-end object-oriented network that adopts a question-conditioned clue discovery module to concentrate audio/visual modalities on respective keywords of the question and designs a modality-conditioned clue collection module to highlight closely associated audio segments or visual objects. For model optimization, we propose an object-aware adaptive-positivity learning strategy that selects the highly semantic-matched multi-modal pair as \\textit{positivity}. Specifically, we design two object-aware contrastive loss functions to identify the highly relevant question-object pairs and audio-object pairs, respectively. These selected pairs are constrained to have larger similarity values than the mismatched pairs. The positivity-selecting process is adaptive as the positivity pairs selected in each video frame may be different. These two object-aware objectives help the model understand \\textit{which objects are exactly relevant to the question} and \\textit{which are making sounds}. Extensive experiments on the MUSIC-AVQA dataset demonstrate the proposed method is effective in finding favorable audio-visual clues and also achieves new state-of-the-art question-answering performance. The code is available at https://github.com/zhangbin-ai/APL",
    "checked": true,
    "id": "06f25d3b3112b7cfa5c9395e184644fdbb896d76",
    "semantic_title": "object-aware adaptive-positivity learning for audio-visual question answering",
    "citation_count": 2,
    "authors": [
      "Zhangbin Li",
      "Dan Guo",
      "Jinxing Zhou",
      "Jing Zhang",
      "Meng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28117": {
    "title": "Hypercorrelation Evolution for Video Class-Incremental Learning",
    "volume": "main",
    "abstract": "Video class-incremental learning aims to recognize new actions while restricting the catastrophic forgetting of old ones, whose representative samples can only be saved in limited memory. Semantically variable subactions are susceptible to class confusion due to data imbalance. While existing methods address the problem by estimating and distilling the spatio-temporal knowledge, we further explores that the refinement of hierarchical correlations is crucial for the alignment of spatio-temporal features. To enhance the adaptability on evolved actions, we proposes a hierarchical aggregation strategy, in which hierarchical matching matrices are combined and jointly optimized to selectively store and retrieve relevant features from previous tasks. Meanwhile, a correlation refinement mechanism is presented to reinforce the bias on informative exemplars according to online hypercorrelation distribution. Experimental results demonstrate the effectiveness of the proposed method on three standard video class-incremental learning benchmarks, outperforming state-of-the-art methods. Code is available at: https://github.com/Lsen991031/HCE",
    "checked": true,
    "id": "a9ccbdce0f213d6b88862af1aed16f0ec018a158",
    "semantic_title": "hypercorrelation evolution for video class-incremental learning",
    "citation_count": 0,
    "authors": [
      "Sen Liang",
      "Kai Zhu",
      "Wei Zhai",
      "Zhiheng Liu",
      "Yang Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28118": {
    "title": "CoSTA: End-to-End Comprehensive Space-Time Entanglement for Spatio-Temporal Video Grounding",
    "volume": "main",
    "abstract": "This paper studies the spatio-temporal video grounding task, which aims to localize a spatio-temporal tube in an untrimmed video based on the given text description of an event. Existing one-stage approaches suffer from insufficient space-time interaction in two aspects: i) less precise prediction of event temporal boundaries, and ii) inconsistency in object prediction for the same event across adjacent frames. To address these issues, we propose a framework of Comprehensive Space-Time entAnglement (CoSTA) to densely entangle space-time multi-modal features for spatio-temporal localization. Specifically, we propose a space-time collaborative encoder to extract comprehensive video features and leverage Transformer to perform spatio-temporal multi-modal understanding. Our entangled decoder couples temporal boundary prediction and spatial localization via an entangled query, boasting an enhanced ability to capture object-event relationships. We conduct extensive experiments on the challenging benchmarks of HC-STVG and VidSTG, where CoSTA outperforms existing state-of-the-art methods, demonstrating its effectiveness for this task",
    "checked": true,
    "id": "6c854ba13bc8a68252e1dbbdf91fe581fcfa1da0",
    "semantic_title": "costa: end-to-end comprehensive space-time entanglement for spatio-temporal video grounding",
    "citation_count": 0,
    "authors": [
      "Yaoyuan Liang",
      "Xiao Liang",
      "Yansong Tang",
      "Zhao Yang",
      "Ziran Li",
      "Jingang Wang",
      "Wenbo Ding",
      "Shao-Lun Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28119": {
    "title": "Any-Stereo: Arbitrary Scale Disparity Estimation for Iterative Stereo Matching",
    "volume": "main",
    "abstract": "Due to unaffordable computational costs, the regularized disparity in iterative stereo matching is typically maintained at a lower resolution than the input. To regress the full resolution disparity, most stereo methods resort to convolutions to decode a fixed-scale output. However, they are inadequate for recovering vital high-frequency information lost during downsampling, limiting their performance on full-resolution prediction. In this paper, we introduce AnyStereo, an accurate and efficient disparity upsampling module with implicit neural representation for the iterative stereo pipeline. By modeling the disparity as a continuous representation over 2D spatial coordinates, subtle details can emerge from the latent space at arbitrary resolution. To further complement the missing information and details in the latent code, we propose two strategies: intra-scale similarity unfolding and cross-scale feature alignment. The former unfolds the neighbor relationships, while the latter introduces the context in high-resolution feature maps. The proposed AnyStereo can seamlessly replace the upsampling module in most iterative stereo models, improving their ability to capture fine details and generate arbitrary-scale disparities even with fewer parameters. With our method, the iterative stereo pipeline establishes a new state-of-the-art performance. The code is available at https://github.com/Zhaohuai-L/Any-Stereo",
    "checked": true,
    "id": "98d1f09c6ad0fadff7df5085365d25c6b01775b9",
    "semantic_title": "any-stereo: arbitrary scale disparity estimation for iterative stereo matching",
    "citation_count": 2,
    "authors": [
      "Zhaohuai Liang",
      "Changhe Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28120": {
    "title": "Impartial Adversarial Distillation: Addressing Biased Data-Free Knowledge Distillation via Adaptive Constrained Optimization",
    "volume": "main",
    "abstract": "Data-Free Knowledge Distillation (DFKD) enables knowledge transfer from a pretrained teacher to a light-weighted student without original training data. Existing works are limited by a strong assumption that samples used to pretrain the teacher model are balanced, which is, however, unrealistic for many real-world tasks. In this work, we investigated a pragmatic yet under-explored problem: how to perform DFKD from a teacher model pretrained from imbalanced data. We observe a seemingly counter-intuitive phenomenon, i.e., adversarial DFKD algorithms favour minority classes, while causing a disastrous impact on majority classes. We theoretically prove that a biased teacher could cause severe disparity on different groups of synthetic data in adversarial distillation, which further exacerbates the mode collapse of a generator and consequently degenerates the overall accuracy of a distilled student model. To tackle this problem, we propose a class-adaptive regularization method, aiming to encourage impartial representation learning of a generator among different classes under a constrained learning formulation. We devise a primal-dual algorithm to solve the target optimization problem. Through extensive experiments, we show that our method mitigates the biased learning of majority classes in DFKD and improves the overall performance compared with baselines. Code will be available at https://github.com/ldpbuaa/ipad",
    "checked": true,
    "id": "429e080c5209da6fcb0de0008b00fa8ce43d2306",
    "semantic_title": "impartial adversarial distillation: addressing biased data-free knowledge distillation via adaptive constrained optimization",
    "citation_count": 0,
    "authors": [
      "Dongping Liao",
      "Xitong Gao",
      "Chengzhong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28121": {
    "title": "VLM2Scene: Self-Supervised Image-Text-LiDAR Learning with Foundation Models for Autonomous Driving Scene Understanding",
    "volume": "main",
    "abstract": "Vision and language foundation models (VLMs) have showcased impressive capabilities in 2D scene understanding. However, their latent potential in elevating the understanding of 3D autonomous driving scenes remains untapped. In this paper, we propose VLM2Scene, which exploits the potential of VLMs to enhance 3D self-supervised representation learning through our proposed image-text-LiDAR contrastive learning strategy. Specifically, in the realm of autonomous driving scenes, the inherent sparsity of LiDAR point clouds poses a notable challenge for point-level contrastive learning methods. This method often grapples with limitations tied to a restricted receptive field and the presence of noisy points. To tackle this challenge, our approach emphasizes region-level learning, leveraging regional masks without semantics derived from the vision foundation model. This approach capitalizes on valuable contextual information to enhance the learning of point cloud representations. First, we introduce Region Caption Prompts to generate fine-grained language descriptions for the corresponding regions, utilizing the language foundation model. These region prompts then facilitate the establishment of positive and negative text-point pairs within the contrastive loss framework. Second, we propose a Region Semantic Concordance Regularization, which involves a semantic-filtered region learning and a region semantic assignment strategy. The former aims to filter the false negative samples based on the semantic distance, and the latter mitigates potential inaccuracies in pixel semantics, thereby enhancing overall semantic consistency. Extensive experiments on representative autonomous driving datasets demonstrate that our self-supervised method significantly outperforms other counterparts. Codes are available at https://github.com/gbliao/VLM2Scene",
    "checked": true,
    "id": "96148eb50d850813da8ae97158e0897b2fd81317",
    "semantic_title": "vlm2scene: self-supervised image-text-lidar learning with foundation models for autonomous driving scene understanding",
    "citation_count": 4,
    "authors": [
      "Guibiao Liao",
      "Jiankun Li",
      "Xiaoqing Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28122": {
    "title": "Text-to-Image Generation for Abstract Concepts",
    "volume": "main",
    "abstract": "Recent years have witnessed the substantial progress of large-scale models across various domains, such as natural language processing and computer vision, facilitating the expression of concrete concepts. Unlike concrete concepts that are usually directly associated with physical objects, expressing abstract concepts through natural language requires considerable effort since they are characterized by intricate semantics and connotations. An alternative approach is to leverage images to convey rich visual information as a supplement. Nevertheless, existing Text-to-Image (T2I) models are primarily trained on concrete physical objects and often struggle to visualize abstract concepts. Inspired by the three-layer artwork theory that identifies critical factors, intent, object and form during artistic creation, we propose a framework of Text-to-Image generation for Abstract Concepts (TIAC). The abstract concept is clarified into a clear intent with a detailed definition to avoid ambiguity. LLMs then transform it into semantic-related physical objects, and the concept-dependent form is retrieved from an LLM-extracted form pattern set. Information from these three aspects will be integrated to generate prompts for T2I models via LLM. Evaluation results from human assessments and our newly designed metric concept score demonstrate the effectiveness of our framework in creating images that can sufficiently express abstract concepts",
    "checked": true,
    "id": "0d38f1edac66b4645cf5fa05abaf9d92cba5d5d3",
    "semantic_title": "text-to-image generation for abstract concepts",
    "citation_count": 4,
    "authors": [
      "Jiayi Liao",
      "Xu Chen",
      "Qiang Fu",
      "Lun Du",
      "Xiangnan He",
      "Xiang Wang",
      "Shi Han",
      "Dongmei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28123": {
    "title": "VSFormer: Visual-Spatial Fusion Transformer for Correspondence Pruning",
    "volume": "main",
    "abstract": "Correspondence pruning aims to find correct matches (inliers) from an initial set of putative correspondences, which is a fundamental task for many applications. The process of finding is challenging, given the varying inlier ratios between scenes/image pairs due to significant visual differences. However, the performance of the existing methods is usually limited by the problem of lacking visual cues (e.g., texture, illumination, structure) of scenes. In this paper, we propose a Visual-Spatial Fusion Transformer (VSFormer) to identify inliers and recover camera poses accurately. Firstly, we obtain highly abstract visual cues of a scene with the cross attention between local features of two-view images. Then, we model these visual cues and correspondences by a joint visual-spatial fusion module, simultaneously embedding visual cues into correspondences for pruning. Additionally, to mine the consistency of correspondences, we also design a novel module that combines the KNN-based graph and the transformer, effectively capturing both local and global contexts. Extensive experiments have demonstrated that the proposed VSFormer outperforms state-of-the-art methods on outdoor and indoor benchmarks. Our code is provided at the following repository: https://github.com/sugar-fly/VSFormer",
    "checked": true,
    "id": "d8ecf82bd3bfc17ba2e7875672377a51b01e36c6",
    "semantic_title": "vsformer: visual-spatial fusion transformer for correspondence pruning",
    "citation_count": 1,
    "authors": [
      "Tangfei Liao",
      "Xiaoqin Zhang",
      "Li Zhao",
      "Tao Wang",
      "Guobao Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28124": {
    "title": "NightRain: Nighttime Video Deraining via Adaptive-Rain-Removal and Adaptive-Correction",
    "volume": "main",
    "abstract": "Existing deep-learning-based methods for nighttime video deraining rely on synthetic data due to the absence of real-world paired data. However, the intricacies of the real world, particularly with the presence of light effects and low-light regions affected by noise, create significant domain gaps, hampering synthetic-trained models in removing rain streaks properly and leading to over-saturation and color shifts. Motivated by this, we introduce NightRain, a novel nighttime video deraining method with adaptive-rain-removal and adaptive-correction. Our adaptive-rain-removal uses unlabeled rain videos to enable our model to derain real-world rain videos, particularly in regions affected by complex light effects. The idea is to allow our model to obtain rain-free regions based on the confidence scores. Once rain-free regions and the corresponding regions from our input are obtained, we can have region-based paired real data. These paired data are used to train our model using a teacher-student framework, allowing the model to iteratively learn from less challenging regions to more challenging regions. Our adaptive-correction aims to rectify errors in our model's predictions, such as over-saturation and color shifts. The idea is to learn from clear night input training videos based on the differences or distance between those input videos and their corresponding predictions. Our model learns from these differences, compelling our model to correct the errors. From extensive experiments, our method demonstrates state-of-the-art performance. It achieves a PSNR of 26.73dB, surpassing existing nighttime video deraining methods by a substantial margin of 13.7%",
    "checked": true,
    "id": "bed73f894a89efd988b2f84a483d246c80d21031",
    "semantic_title": "nightrain: nighttime video deraining via adaptive-rain-removal and adaptive-correction",
    "citation_count": 2,
    "authors": [
      "Beibei Lin",
      "Yeying Jin",
      "Wending Yan",
      "Wei Ye",
      "Yuan Yuan",
      "Shunli Zhang",
      "Robby T. Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28125": {
    "title": "Unsupervised Pan-Sharpening via Mutually Guided Detail Restoration",
    "volume": "main",
    "abstract": "Pan-sharpening is a task that aims to super-resolve the low-resolution multispectral (LRMS) image with the guidance of a corresponding high-resolution panchromatic (PAN) image. The key challenge in pan-sharpening is to accurately modeling the relationship between the MS and PAN images. While supervised deep learning methods are commonly employed to address this task, the unavailability of ground-truth severely limits their effectiveness. In this paper, we propose a mutually guided detail restoration method for unsupervised pan-sharpening. Specifically, we treat pan-sharpening as a blind image deblurring task, in which the blur kernel can be estimated by a CNN. Constrained by the blur kernel, the pan-sharpened image retains spectral information consistent with the LRMS image. Once the pan-sharpened image is obtained, the PAN image is blurred using a pre-defined blur operator. The pan-sharpened image, in turn, is used to guide the detail restoration of the blurred PAN image. By leveraging the mutual guidance between MS and PAN images, the pan-sharpening network can implicitly learn the spatial relationship between the two modalities. Extensive experiments show that the proposed method significantly outperforms existing unsupervised pan-sharpening methods",
    "checked": true,
    "id": "342b3c768e052a5f296b993970114d334425d1c6",
    "semantic_title": "unsupervised pan-sharpening via mutually guided detail restoration",
    "citation_count": 0,
    "authors": [
      "Huangxing Lin",
      "Yuhang Dong",
      "Xinghao Ding",
      "Tianpeng Liu",
      "Yongxiang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28126": {
    "title": "Gramformer: Learning Crowd Counting via Graph-Modulated Transformer",
    "volume": "main",
    "abstract": "Transformer has been popular in recent crowd counting work since it breaks the limited receptive field of traditional CNNs. However, since crowd images always contain a large number of similar patches, the self-attention mechanism in Transformer tends to find a homogenized solution where the attention maps of almost all patches are identical. In this paper, we address this problem by proposing Gramformer: a graph-modulated transformer to enhance the network by adjusting the attention and input node features respectively on the basis of two different types of graphs. Firstly, an attention graph is proposed to diverse attention maps to attend to complementary information. The graph is building upon the dissimilarities between patches, modulating the attention in an anti-similarity fashion. Secondly, a feature-based centrality encoding is proposed to discover the centrality positions or importance of nodes. We encode them with a proposed centrality indices scheme to modulate the node features and similarity relationships. Extensive experiments on four challenging crowd counting datasets have validated the competitiveness of the proposed method. Code is available at https://github.com/LoraLinH/Gramformer",
    "checked": true,
    "id": "42d4057b9f03b538349c7c66a02fdc6c84c066f1",
    "semantic_title": "gramformer: learning crowd counting via graph-modulated transformer",
    "citation_count": 2,
    "authors": [
      "Hui Lin",
      "Zhiheng Ma",
      "Xiaopeng Hong",
      "Qinnan Shangguan",
      "Deyu Meng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28127": {
    "title": "Weakly Supervised Open-Vocabulary Object Detection",
    "volume": "main",
    "abstract": "Despite weakly supervised object detection (WSOD) being a promising step toward evading strong instance-level annotations, its capability is confined to closed-set categories within a single training dataset. In this paper, we propose a novel weakly supervised open-vocabulary object detection framework, namely WSOVOD, to extend traditional WSOD to detect novel concepts and utilize diverse datasets with only image-level annotations. To achieve this, we explore three vital strategies, including dataset-level feature adaptation, image-level salient object localization, and region-level vision-language alignment. First, we perform data-aware feature extraction to produce an input-conditional coefficient, which is leveraged into dataset attribute prototypes to identify dataset bias and help achieve cross-dataset generalization. Second, a customized location-oriented weakly supervised region proposal network is proposed to utilize high-level semantic layouts from the category-agnostic segment anything model to distinguish object boundaries. Lastly, we introduce a proposal-concept synchronized multiple-instance network, i.e., object mining and refinement with visual-semantic alignment, to discover objects matched to the text embeddings of concepts. Extensive experiments on Pascal VOC and MS COCO demonstrate that the proposed WSOVOD achieves new state-of-the-art compared with previous WSOD methods in both close-set object localization and detection tasks. Meanwhile, WSOVOD enables cross-dataset and open-vocabulary learning to achieve on-par or even better performance than well-established fully-supervised open-vocabulary object detection (FSOVOD)",
    "checked": true,
    "id": "3beff9defd7666a197ab78bb0ab337e7dcf24598",
    "semantic_title": "weakly supervised open-vocabulary object detection",
    "citation_count": 2,
    "authors": [
      "Jianghang Lin",
      "Yunhang Shen",
      "Bingquan Wang",
      "Shaohui Lin",
      "Ke Li",
      "Liujuan Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28128": {
    "title": "Spot the Error: Non-autoregressive Graphic Layout Generation with Wireframe Locator",
    "volume": "main",
    "abstract": "Layout generation is a critical step in graphic design to achieve meaningful compositions of elements. Most previous works view it as a sequence generation problem by concatenating element attribute tokens (i.e., category, size, position). So far the autoregressive approach (AR) has achieved promising results, but is still limited in global context modeling and suffers from error propagation since it can only attend to the previously generated tokens. Recent non-autoregressive attempts (NAR) have shown competitive results, which provides a wider context range and the flexibility to refine with iterative decoding. However, current works only use simple heuristics to recognize erroneous tokens for refinement which is inaccurate. This paper first conducts an in-depth analysis to better understand the difference between the AR and NAR framework. Furthermore, based on our observation that pixel space is more sensitive in capturing spatial patterns of graphic layouts (e.g., overlap, alignment), we propose a learning-based locator to detect erroneous tokens which takes the wireframe image rendered from the generated layout sequence as input. We show that it serves as a complementary modality to the element sequence in object space and contributes greatly to the overall performance. Experiments on two public datasets show that our approach outperforms both AR and NAR baselines. Extensive studies further prove the effectiveness of different modules with interesting findings. Our code will be available at https://github.com/ffffatgoose/SpotError",
    "checked": true,
    "id": "e4c7f5f83b417335b2eb7b44d87037fe24b8f538",
    "semantic_title": "spot the error: non-autoregressive graphic layout generation with wireframe locator",
    "citation_count": 1,
    "authors": [
      "Jieru Lin",
      "Danqing Huang",
      "Tiejun Zhao",
      "Dechen Zhan",
      "Chin-Yew Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28129": {
    "title": "M2SD:Multiple Mixing Self-Distillation for Few-Shot Class-Incremental Learning",
    "volume": "main",
    "abstract": "Few-shot Class-incremental learning (FSCIL) is a challenging task in machine learning that aims to recognize new classes from a limited number of instances while preserving the ability to classify previously learned classes without retraining the entire model. This presents challenges in updating the model with new classes using limited training data, particularly in balancing acquiring new knowledge while retaining the old. We propose a novel method named Multiple Mxing Self-Distillation (M2SD) during the training phase to address these issues. Specifically, we propose a dual-branch structure that facilitates the expansion of the entire feature space to accommodate new classes. Furthermore, we introduce a feature enhancement component that can pass additional enhanced information back to the base network by self-distillation, resulting in improved classification performance upon adding new classes. After training, we discard both structures, leaving only the primary network to classify new class instances. Extensive experiments demonstrate that our approach achieves superior performance over previous state-of-the-art methods",
    "checked": false,
    "id": "73f7b7e32da246f9a232a9cf313ea7932b1d8c25",
    "semantic_title": "m2sd: multiple mixing self-distillation for few-shot class-incremental learning",
    "citation_count": 0,
    "authors": [
      "Jinhao Lin",
      "Ziheng Wu",
      "Weifeng Lin",
      "Jun Huang",
      "RongHua Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28130": {
    "title": "EDA: Evolving and Distinct Anchors for Multimodal Motion Prediction",
    "volume": "main",
    "abstract": "Motion prediction is a crucial task in autonomous driving, and one of its major challenges lands in the multimodality of future behaviors. Many successful works have utilized mixture models which require identification of positive mixture components, and correspondingly fall into two main lines: prediction-based and anchor-based matching. The prediction clustering phenomenon in prediction-based matching makes it difficult to pick representative trajectories for downstream tasks, while the anchor-based matching suffers from a limited regression capability. In this paper, we introduce a novel paradigm, named Evolving and Distinct Anchors (EDA), to define the positive and negative components for multimodal motion prediction based on mixture models. We enable anchors to evolve and redistribute themselves under specific scenes for an enlarged regression capacity. Furthermore, we select distinct anchors before matching them with the ground truth, which results in impressive scoring performance. Our approach enhances all metrics compared to the baseline MTR, particularly with a notable relative reduction of 13.5% in Miss Rate, resulting in state-of-the-art performance on the Waymo Open Motion Dataset. Appendix and code are available at https://github.com/Longzhong-Lin/EDA",
    "checked": true,
    "id": "7aada1cf092ea79ed373f6bd81ff76b3d0a23a16",
    "semantic_title": "eda: evolving and distinct anchors for multimodal motion prediction",
    "citation_count": 2,
    "authors": [
      "Longzhong Lin",
      "Xuewu Lin",
      "Tianwei Lin",
      "Lichao Huang",
      "Rong Xiong",
      "Yue Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28131": {
    "title": "PTUS: Photo-Realistic Talking Upper-Body Synthesis via 3D-Aware Motion Decomposition Warping",
    "volume": "main",
    "abstract": "Talking upper-body synthesis is a promising task due to its versatile potential for video creation and consists of animating the body and face from a source image with the motion from a given driving video. However, prior synthesis approaches fall short in addressing this task and have been either limited to animating heads of a target person only, or have animated the upper body but neglected the synthesis of precise facial details. To tackle this task, we propose a Photo-realistic Talking Upper-body Synthesis method via 3D-aware motion decomposition warping, named PTUS, to both precisely synthesize the upper body as well as recover the details of the face such as blinking and lip synchronization. In particular, the motion decomposition mechanism consists of a face-body motion decomposition, which decouples the 3D motion estimation of the face and body, and a local-global motion decomposition, which decomposes the 3D face motion into global and local motions resulting in the transfer of facial expression. The 3D-aware warping module transfers the large-scale and subtle 3D motions to the extracted 3D depth-aware features in a coarse-tofine manner. Moreover, we present a new dataset, Talking-UB, which includes upper-body images with high-resolution faces, addressing the limitations of prior datasets that either consist of only facial images or upper-body images with blurry faces. Experimental results demonstrate that our proposed method can synthesize high-quality videos that preserve facial details, and achieves superior results compared to state-of-the-art cross-person motion transfer approaches. Code and collected dataset are released in https://github.com/cooluoluo/PTUS",
    "checked": true,
    "id": "eae107ee26815b25ab9f82ff58a280f8e14bf983",
    "semantic_title": "ptus: photo-realistic talking upper-body synthesis via 3d-aware motion decomposition warping",
    "citation_count": 0,
    "authors": [
      "Luoyang Lin",
      "Zutao Jiang",
      "Xiaodan Liang",
      "Liqian Ma",
      "Michael C. Kampffmeyer",
      "Xiaochun Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28132": {
    "title": "Exploring Temporal Feature Correlation for Efficient and Stable Video Semantic Segmentation",
    "volume": "main",
    "abstract": "This paper tackles the problem of efficient and stable video semantic segmentation. While stability has been under-explored, prevalent work in efficient video semantic segmentation uses the keyframe paradigm. They efficiently process videos by only recomputing the low-level features and reusing high-level features computed at selected keyframes. In addition, the reused features stabilize the predictions across frames, thereby improving video consistency. However, dynamic scenes in the video can easily lead to misalignments between reused and recomputed features, which hampers performance. Moreover, relying on feature reuse to improve prediction consistency is brittle; an erroneous alignment of the features can easily lead to unstable predictions. Therefore, the keyframe paradigm exhibits a dilemma between stability and performance. We address this efficiency and stability challenge using a novel yet simple Temporal Feature Correlation (TFC) module. It uses the cosine similarity between two frames' low-level features to inform the semantic label's consistency across frames. Specifically, we selectively reuse label-consistent features across frames through linear interpolation and update others through sparse multi-scale deformable attention. As a result, we no longer directly reuse features to improve stability and thus effectively solve feature misalignment. This work provides a significant step towards efficient and stable video semantic segmentation. On the VSPW dataset, our method significantly improves the prediction consistency of image-based methods while being as fast and accurate",
    "checked": true,
    "id": "4933214f5c731c554699e7fa44c4e3bb560ac4c6",
    "semantic_title": "exploring temporal feature correlation for efficient and stable video semantic segmentation",
    "citation_count": 0,
    "authors": [
      "Matthieu Lin",
      "Jenny Sheng",
      "Yubin Hu",
      "Yangguang Li",
      "Lu Qi",
      "Andrew Zhao",
      "Gao Huang",
      "Yong-Jin Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28133": {
    "title": "Boosting Adversarial Transferability across Model Genus by Deformation-Constrained Warping",
    "volume": "main",
    "abstract": "Adversarial examples generated by a surrogate model typically exhibit limited transferability to unknown target systems. To address this problem, many transferability enhancement approaches (e.g., input transformation and model augmentation) have been proposed. However, they show poor performances in attacking systems having different model genera from the surrogate model. In this paper, we propose a novel and generic attacking strategy, called Deformation-Constrained Warping Attack (DeCoWA), that can be effectively applied to cross model genus attack. Specifically, DeCoWA firstly augments input examples via an elastic deformation, namely Deformation-Constrained Warping (DeCoW), to obtain rich local details of the augmented input. To avoid severe distortion of global semantics led by random deformation, DeCoW further constrains the strength and direction of the warping transformation by a novel adaptive control strategy. Extensive experiments demonstrate that the transferable examples crafted by our DeCoWA on CNN surrogates can significantly hinder the performance of Transformers (and vice versa) on various tasks, including image classification, video action recognition, and audio recognition. Code is made available at https://github.com/LinQinLiang/DeCoWA",
    "checked": true,
    "id": "c8aa4f78499b4def6738d7687d660f0de742815d",
    "semantic_title": "boosting adversarial transferability across model genus by deformation-constrained warping",
    "citation_count": 0,
    "authors": [
      "Qinliang Lin",
      "Cheng Luo",
      "Zenghao Niu",
      "Xilin He",
      "Weicheng Xie",
      "Yuanbo Hou",
      "Linlin Shen",
      "Siyang Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28134": {
    "title": "A Fixed-Point Approach to Unified Prompt-Based Counting",
    "volume": "main",
    "abstract": "Existing class-agnostic counting models typically rely on a single type of prompt, e.g., box annotations. This paper aims to establish a comprehensive prompt-based counting framework capable of generating density maps for concerned objects indicated by various prompt types, such as box, point, and text. To achieve this goal, we begin by converting prompts from different modalities into prompt masks without requiring training. These masks are then integrated into a class-agnostic counting methodology for predicting density maps. Furthermore, we introduce a fixed-point inference along with an associated loss function to improve counting accuracy, all without introducing new parameters. The effectiveness of this method is substantiated both theoretically and experimentally. Additionally, a contrastive training scheme is implemented to mitigate dataset bias inherent in current class-agnostic counting datasets, a strategy whose effectiveness is confirmed by our ablation study. Our model excels in prominent class-agnostic datasets and exhibits superior performance in cross-dataset adaptation tasks",
    "checked": true,
    "id": "7708a8618ce479c0d7b1592bd9ba1ad9ced3b3d0",
    "semantic_title": "a fixed-point approach to unified prompt-based counting",
    "citation_count": 1,
    "authors": [
      "Wei Lin",
      "Antoni B. Chan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28135": {
    "title": "Boosting Multiple Instance Learning Models for Whole Slide Image Classification: A Model-Agnostic Framework Based on Counterfactual Inference",
    "volume": "main",
    "abstract": "Multiple instance learning is an effective paradigm for whole slide image (WSI) classification, where labels are only provided at the bag level. However, instance-level prediction is also crucial as it offers insights into fine-grained regions of interest. Existing multiple instance learning methods either solely focus on training a bag classifier or have the insufficient capability of exploring instance prediction. In this work, we propose a novel model-agnostic framework to boost existing multiple instance learning models, to improve the WSI classification performance in both bag and instance levels. Specifically, we propose a counterfactual inference-based sub-bag assessment method and a hierarchical instance searching strategy to help to search reliable instances and obtain their accurate pseudo labels. Furthermore, an instance classifier is well-trained to produce accurate predictions. The instance embedding it generates is treated as a prompt to refine the instance feature for bag prediction. This framework is model-agnostic, capable of adapting to existing multiple instance learning models, including those without specific mechanisms like attention. Extensive experiments on three datasets demonstrate the competitive performance of our method. Code will be available at https://github.com/centurion-crawler/CIMIL",
    "checked": true,
    "id": "e64a031f900a1fb9cfc2c9604c72c3f7bbfe44f6",
    "semantic_title": "boosting multiple instance learning models for whole slide image classification: a model-agnostic framework based on counterfactual inference",
    "citation_count": 0,
    "authors": [
      "Weiping Lin",
      "Zhenfeng Zhuang",
      "Lequan Yu",
      "Liansheng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28136": {
    "title": "Relightable and Animatable Neural Avatars from Videos",
    "volume": "main",
    "abstract": "Lightweight creation of 3D digital avatars is a highly desirable but challenging task. With only sparse videos of a person under unknown illumination, we propose a method to create relightable and animatable neural avatars, which can be used to synthesize photorealistic images of humans under novel viewpoints, body poses, and lighting. The key challenge here is to disentangle the geometry, material of the clothed body, and lighting, which becomes more difficult due to the complex geometry and shadow changes caused by body motions. To solve this ill-posed problem, we propose novel techniques to better model the geometry and shadow changes. For geometry change modeling, we propose an invertible deformation field, which helps to solve the inverse skinning problem and leads to better geometry quality. To model the spatial and temporal varying shading cues, we propose a pose-aware part-wise light visibility network to estimate light occlusion. Extensive experiments on synthetic and real datasets show that our approach reconstructs high-quality geometry and generates realistic shadows under different body poses. Code and data are available at https://wenbin-lin.github.io/RelightableAvatar-page",
    "checked": true,
    "id": "af945274d2c61debdac3eaa2d4f1c7fa405a1a60",
    "semantic_title": "relightable and animatable neural avatars from videos",
    "citation_count": 4,
    "authors": [
      "Wenbin Lin",
      "Chengwei Zheng",
      "Jun-Hai Yong",
      "Feng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28137": {
    "title": "TD²-Net: Toward Denoising and Debiasing for Video Scene Graph Generation",
    "volume": "main",
    "abstract": "Dynamic scene graph generation (SGG) focuses on detecting objects in a video and determining their pairwise relationships. Existing dynamic SGG methods usually suffer from several issues, including 1) Contextual noise, as some frames might contain occluded and blurred objects. 2) Label bias, primarily due to the high imbalance between a few positive relationship samples and numerous negative ones. Additionally, the distribution of relationships exhibits a long-tailed pattern. To address the above problems, in this paper, we introduce a network named TD2-Net that aims at denoising and debiasing for dynamic SGG. Specifically, we first propose a denoising spatio-temporal transformer module that enhances object representation with robust contextual information. This is achieved by designing a differentiable Top-K object selector that utilizes the gumbel-softmax sampling strategy to select the relevant neighborhood for each object. Second, we introduce an asymmetrical reweighting loss to relieve the issue of label bias. This loss function integrates asymmetry focusing factors and the volume of samples to adjust the weights assigned to individual samples. Systematic experimental results demonstrate the superiority of our proposed TD2-Net over existing state-of-the-art approaches on Action Genome databases. In more detail, TD2-Net outperforms the second-best competitors by 12.7% on mean-Recall@10 for predicate classification",
    "checked": true,
    "id": "a8d009ad768cc0e34624374fd277fecda013860b",
    "semantic_title": "td²-net: toward denoising and debiasing for video scene graph generation",
    "citation_count": 0,
    "authors": [
      "Xin Lin",
      "Chong Shi",
      "Yibing Zhan",
      "Zuopeng Yang",
      "Yaqi Wu",
      "Dacheng Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28138": {
    "title": "Ced-NeRF: A Compact and Efficient Method for Dynamic Neural Radiance Fields",
    "volume": "main",
    "abstract": "Rendering photorealistic dynamic scenes has been a focus of recent research, with applications in virtual and augmented reality. While the Neural Radiance Field (NeRF) has shown remarkable rendering quality for static scenes, achieving real-time rendering of dynamic scenes remains challenging due to expansive computation for the time dimension. The incorporation of explicit-based methods, specifically voxel grids, has been proposed to accelerate the training and rendering of neural radiance fields with hybrid representation. However, employing a hybrid representation for dynamic scenes results in overfitting due to fast convergence, which can result in artifacts (e.g., floaters, noisy geometric) on novel views. To address this, we propose a compact and efficient method for dynamic neural radiance fields, namely Ced-NeRF which only require a small number of additional parameters to construct a hybrid representation of dynamic NeRF. Evaluation of dynamic scene datasets shows that our Ced-NeRF achieves fast rendering speeds while maintaining high-quality rendering results. Our method outperforms the current state-of-the-art methods in terms of quality, training and rendering speed",
    "checked": true,
    "id": "9b7d52f65fcc5184929a8e20c141752c5a094299",
    "semantic_title": "ced-nerf: a compact and efficient method for dynamic neural radiance fields",
    "citation_count": 0,
    "authors": [
      "Youtian Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28139": {
    "title": "TagCLIP: A Local-to-Global Framework to Enhance Open-Vocabulary Multi-Label Classification of CLIP without Training",
    "volume": "main",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) has demonstrated impressive capabilities in open-vocabulary classification. The class token in the image encoder is trained to capture the global features to distinguish different text descriptions supervised by contrastive loss, making it highly effective for single-label classification. However, it shows poor performance on multi-label datasets because the global feature tends to be dominated by the most prominent class and the contrastive nature of softmax operation aggravates it. In this study, we observe that the multi-label classification results heavily rely on discriminative local features but are overlooked by CLIP. As a result, we dissect the preservation of patch-wise spatial information in CLIP and proposed a local-to-global framework to obtain image tags. It comprises three steps: (1) patch-level classification to obtain coarse scores; (2) dual-masking attention refinement (DMAR) module to refine the coarse scores; (3) class-wise reidentification (CWR) module to remedy predictions from a global perspective. This framework is solely based on frozen CLIP and significantly enhances its multi-label classification performance on various benchmarks without dataset-specific training. Besides, to comprehensively assess the quality and practicality of generated tags, we extend their application to the downstream task, i.e., weakly supervised semantic segmentation (WSSS) with generated tags as image-level pseudo labels. Experiments demonstrate that this classify-then-segment paradigm dramatically outperforms other annotation-free segmentation methods and validates the effectiveness of generated tags. Our code is available at https://github.com/linyq2117/TagCLIP",
    "checked": true,
    "id": "a08bbdbf885c7a6fb5499dccae24982770abd909",
    "semantic_title": "tagclip: a local-to-global framework to enhance open-vocabulary multi-label classification of clip without training",
    "citation_count": 2,
    "authors": [
      "Yuqi Lin",
      "Minghao Chen",
      "Kaipeng Zhang",
      "Hengjia Li",
      "Mingming Li",
      "Zheng Yang",
      "Dongqin Lv",
      "Binbin Lin",
      "Haifeng Liu",
      "Deng Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28140": {
    "title": "Independency Adversarial Learning for Cross-Modal Sound Separation",
    "volume": "main",
    "abstract": "The sound mixture separation is still challenging due to heavy sound overlapping and disturbance from noise. Unsupervised separation would significantly increase the difficulty. As sound overlapping always hinders accurate sound separation, we propose an Independency Adversarial Learning based Cross-Modal Sound Separation (IAL-CMS) approach, where IAL employs adversarial learning to minimize the correlation of separated sound elements, exploring high sound independence; CMS performs cross-modal sound separation, incorporating audio-visual consistent feature learning and interactive cross-attention learning to emphasize the semantic consistency among cross-modal features. Both audio-visual consistency and audio consistency are kept to guarantee accurate separation. The consistency and sound independence ensure the decomposition of overlapping mixtures into unrelated and distinguishable sound elements. The proposed approach is evaluated on MUSIC, VGGSound, and AudioSet. Extensive experiments certify that our approach outperforms existing approaches in supervised and unsupervised scenarios",
    "checked": true,
    "id": "a2db1363fee616485ba3ac17710fe62463bee073",
    "semantic_title": "independency adversarial learning for cross-modal sound separation",
    "citation_count": 0,
    "authors": [
      "Zhenkai Lin",
      "Yanli Ji",
      "Yang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28141": {
    "title": "BEV-MAE: Bird's Eye View Masked Autoencoders for Point Cloud Pre-training in Autonomous Driving Scenarios",
    "volume": "main",
    "abstract": "Existing LiDAR-based 3D object detection methods for autonomous driving scenarios mainly adopt the training-from-scratch paradigm. Unfortunately, this paradigm heavily relies on large-scale labeled data, whose collection can be expensive and time-consuming. Self-supervised pre-training is an effective and desirable way to alleviate this dependence on extensive annotated data. In this work, we present BEV-MAE, an efficient masked autoencoder pre-training framework for LiDAR-based 3D object detection in autonomous driving. Specifically, we propose a bird's eye view (BEV) guided masking strategy to guide the 3D encoder learning feature representation in a BEV perspective and avoid complex decoder design during pre-training. Furthermore, we introduce a learnable point token to maintain a consistent receptive field size of the 3D encoder with fine-tuning for masked point cloud inputs. Based on the property of outdoor point clouds in autonomous driving scenarios, i.e., the point clouds of distant objects are more sparse, we propose point density prediction to enable the 3D encoder to learn location information, which is essential for object detection. Experimental results show that BEV-MAE surpasses prior state-of-the-art self-supervised methods and achieves a favorably pre-training efficiency. Furthermore, based on TransFusion-L, BEV-MAE achieves new state-of-the-art LiDAR-based 3D object detection results, with 73.6 NDS and 69.6 mAP on the nuScenes benchmark. The source code will be released at https://github.com/VDIGPKU/BEV-MAE",
    "checked": true,
    "id": "b58f0b97f13ce8b327285c77828858457e86862a",
    "semantic_title": "bev-mae: bird's eye view masked autoencoders for point cloud pre-training in autonomous driving scenarios",
    "citation_count": 7,
    "authors": [
      "Zhiwei Lin",
      "Yongtao Wang",
      "Shengxiang Qi",
      "Nan Dong",
      "Ming-Hsuan Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28142": {
    "title": "Focus Stacking with High Fidelity and Superior Visual Effects",
    "volume": "main",
    "abstract": "Focus stacking is a technique in computational photography, and it synthesizes a single all-in-focus image from different focal plane images. It is difficult for previous works to produce a high-quality all-in-focus image that meets two goals: high-fidelity to its source images and good visual effects without defects or abnormalities. This paper proposes a novel method based on optical imaging process analysis and modeling. Based on a foreground segmentation - diffusion elimination architecture, the foreground segmentation makes most of the areas in full-focus images heritage information from the source images to achieve high fidelity; diffusion elimination models the physical imaging process and is specially used to solve the transition region (TR) problem that is a long-term neglected issue and degrades visual effects of synthesized images. Based on extensive experiments on simulated dataset, existing realistic dataset and our proposed BetaFusion dataset, the results show that our proposed method can generate high-quality all-in-focus images by achieving two goals simultaneously, especially can successfully solve the TR problem and eliminate the visual effect degradation of synthesized images caused by the TR problem",
    "checked": true,
    "id": "100a0c96cbe9898a6369552297f9f69d150d043c",
    "semantic_title": "focus stacking with high fidelity and superior visual effects",
    "citation_count": 0,
    "authors": [
      "Bo Liu",
      "Bin Hu",
      "Xiuli Bi",
      "Weisheng Li",
      "Bin Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28143": {
    "title": "DeepBranchTracer: A Generally-Applicable Approach to Curvilinear Structure Reconstruction Using Multi-Feature Learning",
    "volume": "main",
    "abstract": "Curvilinear structures, which include line-like continuous objects, are fundamental geometrical elements in image-based applications. Reconstructing these structures from images constitutes a pivotal research area in computer vision. However, the complex topology and ambiguous image evidence render this process a challenging task. In this paper, we introduce DeepBranchTracer, a novel method that learns both external image features and internal geometric characteristics to reconstruct curvilinear structures. Firstly, we formulate the curvilinear structures extraction as a geometric attribute estimation problem. Then, a curvilinear structure feature learning network is designed to extract essential branch attributes, including the image features of centerline and boundary, and the geometric features of direction and radius. Finally, utilizing a multi-feature fusion tracing strategy, our model iteratively traces the entire branch by integrating the extracted image and geometric features. We extensively evaluated our model on both 2D and 3D datasets, demonstrating its superior performance over existing segmentation and reconstruction methods in terms of accuracy and continuity",
    "checked": true,
    "id": "e6e59bcf20541a6a7e26dd2108f120803c0f6736",
    "semantic_title": "deepbranchtracer: a generally-applicable approach to curvilinear structure reconstruction using multi-feature learning",
    "citation_count": 0,
    "authors": [
      "Chao Liu",
      "Ting Zhao",
      "Nenggan Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28144": {
    "title": "Decoupling Degradations with Recurrent Network for Video Restoration in Under-Display Camera",
    "volume": "main",
    "abstract": "Under-display camera (UDC) systems are the foundation of full-screen display devices in which the lens mounts under the display. The pixel array of light-emitting diodes used for display diffracts and attenuates incident light, causing various degradations as the light intensity changes. Unlike general video restoration which recovers video by treating different degradation factors equally, video restoration for UDC systems is more challenging that concerns removing diverse degradation over time while preserving temporal consistency. In this paper, we introduce a novel video restoration network, called D2RNet, specifically designed for UDC systems. It employs a set of Decoupling Attention Modules (DAM) that effectively separate the various video degradation factors. More specifically, a soft mask generation function is proposed to formulate each frame into flare and haze based on the diffraction arising from incident light of different intensities, followed by the proposed flare and haze removal components that leverage long- and short-term feature learning to handle the respective degradations. Such a design offers an targeted and effective solution to eliminating various types of degradation in UDC systems. We further extend our design into multi-scale to overcome the scale-changing of degradation that often occur in long-range videos. To demonstrate the superiority of D2RNet, we propose a large-scale UDC video benchmark by gathering HDR videos and generating realistically degraded videos using the point spread function measured by a commercial UDC system. Extensive quantitative and qualitative evaluations demonstrate the superiority of D2RNet compared to other state-of-the-art video restoration and UDC image restoration methods",
    "checked": true,
    "id": "5939c181212d8ebeee3e81b3b77660aed6b682f4",
    "semantic_title": "decoupling degradations with recurrent network for video restoration in under-display camera",
    "citation_count": 1,
    "authors": [
      "Chengxu Liu",
      "Xuan Wang",
      "Yuanting Fan",
      "Shuai Li",
      "Xueming Qian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28145": {
    "title": "Unsupervised Domain Adaptative Temporal Sentence Localization with Mutual Information Maximization",
    "volume": "main",
    "abstract": "Temporal sentence localization (TSL) aims to localize a target segment in a video according to a given sentence query. Though respectable works have made decent achievements in this task, they severely rely on abundant yet expensive manual annotations for training. Moreover, these trained data-dependent models usually can not generalize well to unseen scenarios because of the inherent domain shift. To facilitate this issue, in this paper, we target another more practical but challenging setting: unsupervised domain adaptative temporal sentence localization (UDA-TSL), which explores whether the localization knowledge can be transferred from a fully-annotated data domain (source domain) to a new unannotated data domain (target domain). Particularly, we propose an effective and novel baseline for UDA-TSL to bridge the multi-modal gap across different domains and learn the potential correspondence between the video-query pairs in target domain. We first develop separate modality-specific domain adaptation modules to smoothly balance the minimization of the domain shifts in cross-dataset video and query domains. Then, to fully exploit the semantic correspondence of both modalities in target domain for unsupervised localization, we devise a mutual information learning module to adaptively align the video-query pairs which are more likely to be relevant in target domain, leading to more truly aligned target pairs and ensuring the discriminability of target features. In this way, our model can learn domain-invariant and semantic-aligned cross-modal representations. Three sets of migration experiments show that our model achieves competitive performance compared to existing methods",
    "checked": true,
    "id": "745e525afca4ba6fe5d7e07473288c36400da5bd",
    "semantic_title": "unsupervised domain adaptative temporal sentence localization with mutual information maximization",
    "citation_count": 0,
    "authors": [
      "Daizong Liu",
      "Xiang Fang",
      "Xiaoye Qu",
      "Jianfeng Dong",
      "He Yan",
      "Yang Yang",
      "Pan Zhou",
      "Yu Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28146": {
    "title": "Explicitly Perceiving and Preserving the Local Geometric Structures for 3D Point Cloud Attack",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daizong Liu",
      "Wei Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28147": {
    "title": "Adv-Diffusion: Imperceptible Adversarial Face Identity Attack via Latent Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Decheng Liu",
      "Xijun Wang",
      "Chunlei Peng",
      "Nannan Wang",
      "Ruimin Hu",
      "Xinbo Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28148": {
    "title": "Multi-View Dynamic Reflection Prior for Video Glass Surface Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fang Liu",
      "Yuhao Liu",
      "Jiaying Lin",
      "Ke Xu",
      "Rynson W.H. Lau"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28149": {
    "title": "Grab What You Need: Rethinking Complex Table Structure Recognition with Flexible Components Deliberation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Liu",
      "Xin Li",
      "Mingming Gong",
      "Bing Liu",
      "Yunfei Wu",
      "Deqiang Jiang",
      "Yinsong Liu",
      "Xing Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28150": {
    "title": "DiDA: Disambiguated Domain Alignment for Cross-Domain Retrieval with Partial Labels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Liu",
      "Ying Ma",
      "Ming Yan",
      "Yingke Chen",
      "Dezhong Peng",
      "Xu Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28151": {
    "title": "Test-Time Personalization with Meta Prompt for Gaze Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huan Liu",
      "Julia Qi",
      "Zhenhao Li",
      "Mohammad Hassanpour",
      "Yang Wang",
      "Konstantinos N. Plataniotis",
      "Yuanhao Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28152": {
    "title": "M3SOT: Multi-Frame, Multi-Field, Multi-Space 3D Single Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaming Liu",
      "Yue Wu",
      "Maoguo Gong",
      "Qiguang Miao",
      "Wenping Ma",
      "Cai Xu",
      "Can Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28153": {
    "title": "Unsupervised Continual Anomaly Detection with Contrastively-Learned Prompt",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Liu",
      "Kai Wu",
      "Qiang Nie",
      "Ying Chen",
      "Bin-Bin Gao",
      "Yong Liu",
      "Jinbao Wang",
      "Chengjie Wang",
      "Feng Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28154": {
    "title": "Region-Aware Exposure Consistency Network for Mixed Exposure Correction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin Liu",
      "Huiyuan Fu",
      "Chuanming Wang",
      "Huadong Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28155": {
    "title": "R3CD: Scene Graph to Image Generation with Relation-Aware Compositional Contrastive Control Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinxiu Liu",
      "Qi Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28156": {
    "title": "DifAttack: Query-Efficient Black-Box Adversarial Attack via Disentangled Feature Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Liu",
      "Jiantao Zhou",
      "Jiandian Zeng",
      "Jinyu Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28157": {
    "title": "Frequency Shuffling and Enhancement for Open Set Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lijun Liu",
      "Rui Wang",
      "Yuan Wang",
      "Lihua Jing",
      "Chuan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28158": {
    "title": "KPA-Tracker: Towards Robust and Real-Time Category-Level Articulated Object 6D Pose Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liu Liu",
      "Anran Huang",
      "Qi Wu",
      "Dan Guo",
      "Xun Yang",
      "Meng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28159": {
    "title": "UVAGaze: Unsupervised 1-to-2 Views Adaptation for Gaze Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruicong Liu",
      "Feng Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28160": {
    "title": "Compact HD Map Construction via Douglas-Peucker Point Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruixin Liu",
      "Zejian Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28161": {
    "title": "Primitive-Based 3D Human-Object Interaction Modelling and Programming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siqi Liu",
      "Yong-Lu Li",
      "Zhou Fang",
      "Xinpeng Liu",
      "Yang You",
      "Cewu Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28162": {
    "title": "Fast Inter-frame Motion Prediction for Compressed Dynamic Point Cloud Attribute Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wang Liu",
      "Wei Gao",
      "Xingming Mu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28163": {
    "title": "RWMS: Reliable Weighted Multi-Phase for Semi-supervised Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wensi Liu",
      "Xiao-Yu Tang",
      "Chong Yang",
      "Chunjie Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28164": {
    "title": "Learning Real-World Image De-weathering with Imperfect Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohui Liu",
      "Zhilu Zhang",
      "Xiaohe Wu",
      "Chaoyu Feng",
      "Xiaotao Wang",
      "Lei Lei",
      "Wangmeng Zuo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28165": {
    "title": "Differentiable Auxiliary Learning for Sketch Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyu Liu",
      "Xu Cheng",
      "Haoyu Chen",
      "Hao Yu",
      "Guoying Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28166": {
    "title": "Keypoint Fusion for RGB-D Based 3D Hand Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyu Liu",
      "Pengfei Ren",
      "Yuanyuan Gao",
      "Jingyu Wang",
      "Haifeng Sun",
      "Qi Qi",
      "Zirui Zhuang",
      "Jianxin Liao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28167": {
    "title": "CAVEN: An Embodied Conversational Agent for Efficient Audio-Visual Navigation in Noisy Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiulong Liu",
      "Sudipta Paul",
      "Moitreya Chatterjee",
      "Anoop Cherian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28168": {
    "title": "DeepCalliFont: Few-Shot Chinese Calligraphy Font Synthesis by Integrating Dual-Modality Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yitian Liu",
      "Zhouhui Lian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28169": {
    "title": "Stable Unlearnable Example: Enhancing the Robustness of Unlearnable Examples via Stable Error-Minimizing Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixin Liu",
      "Kaidi Xu",
      "Xun Chen",
      "Lichao Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28170": {
    "title": "Scaling and Masking: A New Paradigm of Data Sampling for Image and Video Quality Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongxu Liu",
      "Yinghui Quan",
      "Guoyao Xiao",
      "Aobo Li",
      "Jinjian Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28171": {
    "title": "Implicit Modeling of Non-rigid Objects with Cross-Category Signals",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchun Liu",
      "Benjamin Planche",
      "Meng Zheng",
      "Zhongpai Gao",
      "Pierre Sibut-Bourde",
      "Fan Yang",
      "Terrence Chen",
      "Ziyan Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28172": {
    "title": "Recasting Regional Lighting for Shadow Removal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Liu",
      "Zhanghan Ke",
      "Ke Xu",
      "Fang Liu",
      "Zhenwei Wang",
      "Rynson W.H. Lau"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28173": {
    "title": "Rolling-Unet: Revitalizing MLP's Ability to Efficiently Extract Long-Distance Dependencies for Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutong Liu",
      "Haijiang Zhu",
      "Mengting Liu",
      "Huaiyuan Yu",
      "Zihan Chen",
      "Jie Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28174": {
    "title": "Advancing Video Synchronization with Fractional Frame Analysis: Introducing a Novel Dataset and Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Liu",
      "Haizhou Ai",
      "Junliang Xing",
      "Xuri Li",
      "Xiaoyi Wang",
      "Pin Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28175": {
    "title": "FedCD: Federated Semi-Supervised Learning with Class Awareness Balance via Dual Teachers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhi Liu",
      "Huisi Wu",
      "Jing Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28176": {
    "title": "BLADE: Box-Level Supervised Amodal Segmentation through Directed Expansion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaochen Liu",
      "Zhixuan Li",
      "Tingting Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28177": {
    "title": "Towards Balanced Alignment: Modal-Enhanced Semantic Modeling for Video Moment Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihang Liu",
      "Jun Li",
      "Hongtao Xie",
      "Pandeng Li",
      "Jiannan Ge",
      "Sun-Ao Liu",
      "Guoqing Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28178": {
    "title": "Improving Cross-Modal Alignment with Synthetic Pairs for Text-Only Image Captioning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyue Liu",
      "Jinyuan Liu",
      "Fanrong Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28179": {
    "title": "Cell Graph Transformer for Nuclei Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Lou",
      "Guanbin Li",
      "Xiang Wan",
      "Haofeng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28180": {
    "title": "Detect Any Keypoints: An Efficient Light-Weight Few-Shot Keypoint Detector",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changsheng Lu",
      "Piotr Koniusz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28181": {
    "title": "TCNet: Continuous Sign Language Recognition from Trajectories and Correlated Regions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hui Lu",
      "Albert Ali Salah",
      "Ronald Poppe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28182": {
    "title": "MLNet: Mutual Learning Network with Neighborhood Invariance for Universal Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanzuo Lu",
      "Meng Shen",
      "Andy J Ma",
      "Xiaohua Xie",
      "Jian-Huang Lai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28183": {
    "title": "Set Prediction Guided by Semantic Concepts for Diverse Video Captioning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Lu",
      "Ziqi Zhang",
      "Chunfeng Yuan",
      "Peng Li",
      "Yan Wang",
      "Bing Li",
      "Weiming Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28184": {
    "title": "Entropy Induced Pruning Framework for Convolutional Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiheng Lu",
      "Ziyu Guan",
      "Yaming Yang",
      "Wei Zhao",
      "Maoguo Gong",
      "Cai Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28185": {
    "title": "Pano-NeRF: Synthesizing High Dynamic Range Novel Views with Geometry from Sparse Low Dynamic Range Panoramic Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhan Lu",
      "Qian Zheng",
      "Boxin Shi",
      "Xudong Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28186": {
    "title": "ScanERU: Interactive 3D Visual Grounding Based on Embodied Reference Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyang Lu",
      "Yunqiang Pei",
      "Guoqing Wang",
      "Peiwei Li",
      "Yang Yang",
      "Yinjie  Lei",
      "Heng Tao Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28187": {
    "title": "MGNet: Learning Correspondences via Multiple Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dai Luanyuan",
      "Xiaoyu Du",
      "Hanwang Zhang",
      "Jinhui Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28188": {
    "title": "SCP: Spherical-Coordinate-Based Learned Point Cloud Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ao Luo",
      "Linxin Song",
      "Keisuke Nonaka",
      "Kyohei Unno",
      "Heming Sun",
      "Masayuki Goto",
      "Jiro Katto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28189": {
    "title": "DLCA-Recon: Dynamic Loose Clothing Avatar Reconstruction from Monocular Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chunjie Luo",
      "Fei Luo",
      "Yusen Wang",
      "Enxu Zhao",
      "Chunxia Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28190": {
    "title": "Dual-Window Multiscale Transformer for Hyperspectral Snapshot Compressive Imaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fulin Luo",
      "Xi Chen",
      "Xiuwen Gong",
      "Weiwen Wu",
      "Tan Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28191": {
    "title": "Electron Microscopy Images as Set of Fragments for Mitochondrial Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naisong Luo",
      "Rui Sun",
      "Yuwen Pan",
      "Tianzhu Zhang",
      "Feng Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28192": {
    "title": "DiffusionTrack: Diffusion Model for Multi-Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Run Luo",
      "Zikai Song",
      "Lintao Ma",
      "Jinlin Wei",
      "Wei Yang",
      "Min Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28193": {
    "title": "Devignet: High-Resolution Vignetting Removal via a Dual Aggregated Fusion Transformer with Adaptive Channel Expansion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shenghong Luo",
      "Xuhang Chen",
      "Weiwen Chen",
      "Zinuo Li",
      "Shuqiang Wang",
      "Chi-Man Pun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28194": {
    "title": "AdaFormer: Efficient Transformer with Adaptive Token Sparsification for Image Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaotong Luo",
      "Zekun Ai",
      "Qiuyuan Liang",
      "Ding Liu",
      "Yuan Xie",
      "Yanyun Qu",
      "Yun Fu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28195": {
    "title": "SkipDiff: Adaptive Skip Diffusion Model for High-Fidelity Perceptual Image Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaotong Luo",
      "Yuan Xie",
      "Yanyun Qu",
      "Yun Fu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28196": {
    "title": "Modeling Continuous Motion for 3D Point Cloud Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhipeng Luo",
      "Gongjie Zhang",
      "Changqing Zhou",
      "Zhonghua Wu",
      "Qingyi Tao",
      "Lewei Lu",
      "Shijian Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28197": {
    "title": "SGFormer: Semantic Graph Transformer for Point Cloud-Based 3D Scene Graph Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changsheng Lv",
      "Mengshi Qi",
      "Xia Li",
      "Zhengyuan Yang",
      "Huadong Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28198": {
    "title": "Privileged Prior Information Distillation for Image Matting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Lyu",
      "Jiake Xie",
      "Bo Xu",
      "Cheng Lu",
      "Han Huang",
      "Xin Huang",
      "Ming Wu",
      "Chuang Zhang",
      "Yong Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28199": {
    "title": "FedST: Federated Style Transfer Learning for Non-IID Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyuan Ma",
      "Xiang Yin",
      "Jing Tan",
      "Yongfeng Chen",
      "Haiyou Huang",
      "Hao Wang",
      "Weihua Xue",
      "Xiaojuan Ban"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28200": {
    "title": "SlowTrack: Increasing the Latency of Camera-Based Perception in Autonomous Driving Using Adversarial Examples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Ma",
      "Ningfei Wang",
      "Qi Alfred Chen",
      "Chao Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28201": {
    "title": "Uncertainty-Aware GAN for Single Image Super Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxi Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28202": {
    "title": "Stitching Segments and Sentences towards Generalization in Video-Text Pre-training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Ma",
      "Xiaojie Jin",
      "Heng Wang",
      "Jingjia Huang",
      "Linchao Zhu",
      "Yi Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28203": {
    "title": "Image Captioning with Multi-Context Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feipeng Ma",
      "Yizhou Zhou",
      "Fengyun Rao",
      "Yueyi Zhang",
      "Xiaoyan Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28204": {
    "title": "Directed Diffusion: Direct Control of Object Placement through Attention Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wan-Duo Kurt Ma",
      "Avisek Lahiri",
      "J. P. Lewis",
      "Thomas Leung",
      "W. Bastiaan Kleijn"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28205": {
    "title": "Unifying Visual and Vision-Language Tracking via Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinchao Ma",
      "Yuyang Tang",
      "Wenfei Yang",
      "Tianzhu Zhang",
      "Jinpeng Zhang",
      "Mengxue Kang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28206": {
    "title": "Follow Your Pose: Pose-Guided Text-to-Video Generation Using Pose-Free Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Ma",
      "Yingqing He",
      "Xiaodong Cun",
      "Xintao Wang",
      "Siran Chen",
      "Xiu Li",
      "Qifeng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28207": {
    "title": "Let All Be Whitened: Multi-Teacher Distillation for Efficient Visual Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Ma",
      "Jianfeng Dong",
      "Shouling Ji",
      "Zhenguang Liu",
      "Xuhong Zhang",
      "Zonghui Wang",
      "Sifeng He",
      "Feng Qian",
      "Xiaobo Zhang",
      "Lei Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28208": {
    "title": "Cross-Layer and Cross-Sample Feature Optimization Network for Few-Shot Fine-Grained Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen-Xiang Ma",
      "Zhen-Duo Chen",
      "Li-Jun Zhao",
      "Zi-Chao Zhang",
      "Xin  Luo",
      "Xin-Shun Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28209": {
    "title": "LMD: Faster Image Reconstruction with Latent Masking Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Ma",
      "Zhihuan Yu",
      "Jianjun Li",
      "Bowen Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28210": {
    "title": "AdapEdit: Spatio-Temporal Guided Adaptive Editing Algorithm for Text-Based Continuity-Sensitive Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Ma",
      "Guoli Jia",
      "Bowen Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28211": {
    "title": "Pay Attention to Target: Relation-Aware Temporal Consistency for Domain Adaptive Video Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huayu Mai",
      "Rui Sun",
      "Yuan Wang",
      "Tianzhu Zhang",
      "Feng Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28212": {
    "title": "Improving Automatic VQA Evaluation Using Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oscar Mañas",
      "Benno Krojer",
      "Aishwarya Agrawal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28213": {
    "title": "Inconsistency-Based Data-Centric Active Open-Set Annotation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiyu Mao",
      "Ouyang Xu",
      "Yunhui Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28214": {
    "title": "Progressive High-Frequency Reconstruction for Pan-Sharpening with Implicit Neural Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ge Meng",
      "Jingjia Huang",
      "Yingying Wang",
      "Zhenqi Fu",
      "Xinghao Ding",
      "Yue Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28215": {
    "title": "NaMa: Neighbor-Aware Multi-Modal Adaptive Learning for Prostate Tumor Segmentation on Anisotropic MR Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runqi Meng",
      "Xiao Zhang",
      "Shijie Huang",
      "Yuning Gu",
      "Guiqin Liu",
      "Guangyu Wu",
      "Nizhuan Wang",
      "Kaicong Sun",
      "Dinggang Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28216": {
    "title": "ConVQG: Contrastive Visual Question Generation with Multimodal Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Mi",
      "Syrielle Montariol",
      "Javiera Castillo Navarro",
      "Xianjie Dai",
      "Antoine Bosselut",
      "Devis Tuia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28217": {
    "title": "Out-of-Distribution Detection in Long-Tailed Recognition with Calibrated Outlier Class Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjun Miao",
      "Guansong Pang",
      "Xiao Bai",
      "Tianqi Li",
      "Jin Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28218": {
    "title": "BCLNet: Bilateral Consensus Learning for Two-View Correspondence Pruning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyang Miao",
      "Guobao Xiao",
      "Shiping Wang",
      "Jun Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28219": {
    "title": "Understanding the Role of the Projector in Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roy Miles",
      "Krystian Mikolajczyk"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28220": {
    "title": "Robust Blind Text Image Deblurring via Maximum Consensus Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijian Min",
      "Gundu Mohamed Hassan",
      "Geun-Sik Jo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28221": {
    "title": "Knowledge Guided Semi-supervised Learning for Quality Assessment of User Generated Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shankhanil Mitra",
      "Rajiv Soundararajan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28222": {
    "title": "Bridging the Gap between 2D and 3D Visual Question Answering: A Fusion Approach for 3D VQA",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wentao Mo",
      "Yang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28223": {
    "title": "Augmented Commonsense Knowledge for Remote Object Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bahram Mohammadi",
      "Yicong Hong",
      "Yuankai Qi",
      "Qi Wu",
      "Shirui Pan",
      "Javen Qinfeng Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28224": {
    "title": "Recurrent Partial Kernel Network for Efficient Optical Flow Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Henrique Morimitsu",
      "Xiaobin Zhu",
      "Xiangyang Ji",
      "Xu-Cheng Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28225": {
    "title": "TETRIS: Towards Exploring the Robustness of Interactive Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrey Moskalenko",
      "Vlad Shakhuro",
      "Anna Vorontsova",
      "Anton Konushin",
      "Anton Antonov",
      "Alexander Krapukhin",
      "Denis Shepelev",
      "Konstantin Soshin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28226": {
    "title": "T2I-Adapter: Learning Adapters to Dig Out More Controllable Ability for Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chong Mou",
      "Xintao Wang",
      "Liangbin Xie",
      "Yanze Wu",
      "Jian Zhang",
      "Zhongang Qi",
      "Ying Shan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28227": {
    "title": "Semi-supervised Open-World Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sahal Shaji Mullappilly",
      "Abhishek Singh Gehlot",
      "Rao Muhammad Anwer ",
      "Fahad Shahbaz Khan",
      "Hisham Cholakkal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28228": {
    "title": "Adversarial Attacks on the Interpretation of Neuron Activation Maximization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Geraldin Nanfack",
      "Alexander Fulleringer",
      "Jonathan Marty",
      "Michael Eickenberg",
      "Eugene Belilovsky"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28229": {
    "title": "ColNeRF: Collaboration for Generalizable Sparse Input Neural Radiance Field",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangkai Ni",
      "Peiqi Yang",
      "Wenhan Yang",
      "Hanli Wang",
      "Lin Ma",
      "Sam Kwong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28230": {
    "title": "Wavelet-Driven Spatiotemporal Predictive Learning: Bridging Frequency and Time Variations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuesong Nie",
      "Yunfeng Yan",
      "Siyuan Li",
      "Cheng Tan",
      "Xi Chen",
      "Haoyuan Jin",
      "Zhihang Zhu",
      "Stan Z. Li",
      "Donglian Qi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28231": {
    "title": "Painterly Image Harmonization by Learning from Painterly Objects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Niu",
      "Junyan Cao",
      "Yan Hong",
      "Liqing Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28232": {
    "title": "Progressive Painterly Image Harmonization from Low-Level Styles to High-Level Styles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Niu",
      "Yan Hong",
      "Junyan Cao",
      "Liqing Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28233": {
    "title": "Domain Generalizable Person Search Using Unreal Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minyoung Oh",
      "Duhyun Kim",
      "Jae-Young Sim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28234": {
    "title": "OctOcc: High-Resolution 3D Occupancy Prediction with Octree",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenzhe Ouyang",
      "Xiaolin Song",
      "Bailan Feng",
      "Zenglin Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28235": {
    "title": "NeSyFOLD: A Framework for Interpretable Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Parth Padalkar",
      "Huaduo Wang",
      "Gopal Gupta"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28236": {
    "title": "Semi-Supervised Blind Image Quality Assessment through Knowledge Distillation and Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wensheng Pan",
      "Timin Gao",
      "Yan Zhang",
      "Xiawu Zheng",
      "Yunhang Shen",
      "Ke Li",
      "Runze Hu",
      "Yutao Liu",
      "Pingyang Dai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28237": {
    "title": "Less Is More: Label Recommendation for Weakly Supervised Point Cloud Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyi Pan",
      "Nan Zhang",
      "Wei Gao",
      "Shan Liu",
      "Ge Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28238": {
    "title": "patchDPCC: A Patchwise Deep Compression Framework for Dynamic Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zirui Pan",
      "Mengbai Xiao",
      "Xu Han",
      "Dongxiao Yu",
      "Guanghui Zhang",
      "Yao Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28239": {
    "title": "LISR: Learning Linear 3D Implicit Surface Representation Using Compactly Supported Radial Basis Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atharva Pandey",
      "Vishal Yadav",
      "Rajendra Nagar",
      "Santanu Chaudhury"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28240": {
    "title": "RadarMOSEVE: A Spatial-Temporal Transformer Network for Radar-Only Moving Object Segmentation and Ego-Velocity Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changsong Pang",
      "Xieyuanli Chen",
      "Yimin Liu",
      "Huimin Lu",
      "Yuwei Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28241": {
    "title": "NeBLa: Neural Beer-Lambert for 3D Reconstruction of Oral Structures from Panoramic Radiographs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sihwa Park",
      "Seongjun Kim",
      "Doeyoung Kwon",
      "Yohan Jang",
      "In-Seok Song",
      "Seung Jun Baek"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28242": {
    "title": "Task-Disruptive Background Suppression for Few-Shot Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suho Park",
      "SuBeen Lee",
      "Sangeek Hyun",
      "Hyun Seok Seong",
      "Jae-Pil Heo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28243": {
    "title": "SA²VP: Spatially Aligned-and-Adapted Visual Prompt",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjie Pei",
      "Tongqi Xia",
      "Fanglin Chen",
      "Jinsong Li",
      "Jiandong Tian",
      "Guangming Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28244": {
    "title": "ConditionVideo: Training-Free Condition-Guided Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Peng",
      "Xinyuan Chen",
      "Yaohui Wang",
      "Chaochao Lu",
      "Yu Qiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28245": {
    "title": "ViTEraser: Harnessing the Power of Vision Transformers for Scene Text Removal with SegMIM Pretraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dezhi Peng",
      "Chongyu Liu",
      "Yuliang Liu",
      "Lianwen Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28246": {
    "title": "FRIH: Fine-Grained Region-Aware Image Harmonization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinlong Peng",
      "Zekun Luo",
      "Liang Liu",
      "Boshen Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28247": {
    "title": "Navigating Open Set Scenarios for Skeleton-Based Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kunyu Peng",
      "Cheng Yin",
      "Junwei Zheng",
      "Ruiping Liu",
      "David Schneider",
      "Jiaming Zhang",
      "Kailun Yang",
      "M. Saquib Sarfraz",
      "Rainer Stiefelhagen",
      "Alina Roitberg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28248": {
    "title": "LaneGraph2Seq: Lane Topology Extraction with Language Model via Vertex-Edge Encoding and Connectivity Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renyuan Peng",
      "Xinyue Cai",
      "Hang Xu",
      "Jiachen Lu",
      "Feng Wen",
      "Wei Zhang",
      "Li Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28249": {
    "title": "Data Adaptive Traceback for Vision-Language Foundation Models in Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenshuo Peng",
      "Kaipeng Zhang",
      "Yue Yang",
      "Hao Zhang",
      "Yu Qiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28250": {
    "title": "SAM-PARSER: Fine-Tuning SAM Efficiently by Parameter Space Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zelin Peng",
      "Zhengqin Xu",
      "Zhilin Zeng",
      "Xiaokang Yang",
      "Wei Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28251": {
    "title": "Relational Distant Supervision for Image Captioning without Image-Text Pairs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yayun Qi",
      "Wentian Zhao",
      "Xinxiao Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28252": {
    "title": "Bias-Conflict Sample Synthesis and Adversarial Removal Debias Strategy for Temporal Sentence Grounding in Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaobo Qi",
      "Yibo Yuan",
      "Xiaowen Ruan",
      "Shuhui Wang",
      "Weigang Zhang",
      "Qingming Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28253": {
    "title": "NuScenes-QA: A Multi-Modal Visual Question Answering Benchmark for Autonomous Driving Scenario",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianwen Qian",
      "Jingjing Chen",
      "Linhai Zhuo",
      "Yang Jiao",
      "Yu-Gang Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28254": {
    "title": "X-RefSeg3D: Enhancing Referring 3D Instance Segmentation via Structured Cross-Modal Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhipeng Qian",
      "Yiwei Ma",
      "Jiayi Ji",
      "Xiaoshuai Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28255": {
    "title": "BARET: Balanced Attention Based Real Image Editing Driven by Target-Text Inversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuming Qiao",
      "Fanyi Wang",
      "Jingwen Su",
      "Yanhao Zhang",
      "Yunjie Yu",
      "Siyu Wu",
      "Guo-Jun Qi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28256": {
    "title": "High-Fidelity 3D Head Avatars Reconstruction through Spatially-Varying Expression Conditioned Neural Radiance Field",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghan Qin",
      "Yifan Liu",
      "Yuelang Xu",
      "Xiaochen Zhao",
      "Yebin Liu",
      "Haoqian Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28257": {
    "title": "Text2City: One-Stage Text-Driven Urban Layout Regeneration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiming Qin",
      "Nanxuan Zhao",
      "Bin Sheng",
      "Rynson W.H. Lau"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28258": {
    "title": "Empowering CAM-Based Methods with Capability to Generate Fine-Grained and High-Faithfulness Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changqing Qiu",
      "Fusheng Jin",
      "Yining Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28259": {
    "title": "High-Order Structure Based Middle-Feature Learning for Visible-Infrared Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liuxiang Qiu",
      "Si Chen",
      "Yan Yan",
      "Jing-Hao Xue",
      "Da-Han Wang",
      "Shunzhi Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28260": {
    "title": "Mining Fine-Grained Image-Text Alignment for Zero-Shot Captioning via Text-Only Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longtian Qiu",
      "Shan Ning",
      "Xuming He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28261": {
    "title": "HiHPQ: Hierarchical Hyperbolic Product Quantization for Unsupervised Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zexuan Qiu",
      "Jiahong Liu",
      "Yankai Chen",
      "Irwin King"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28262": {
    "title": "S2CycleDiff: Spatial-Spectral-Bilateral Cycle-Diffusion Framework for Hyperspectral Image Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahui Qu",
      "Jie He",
      "Wenqian Dong",
      "Jingyu Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28263": {
    "title": "E2HQV: High-Quality Video Generation from Event Camera via Theory-Inspired Model-Aided Deep Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiang Qu",
      "Yiran Shen",
      "Xiaoming Chen",
      "Yuk Ying Chung",
      "Tongliang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28264": {
    "title": "BLiRF: Bandlimited Radiance Fields for Dynamic Scene Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sameera Ramasinghe",
      "Violetta Shevchenko",
      "Gil Avraham",
      "Anton van den Hengel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28265": {
    "title": "Cross-Sentence Gloss Consistency for Continuous Sign Language Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Rao",
      "Ke Sun",
      "Xiaohan Wang",
      "Qi Wang",
      "Bang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28266": {
    "title": "Forecasting Bimanual Object Manipulation Sequences from Unimanual Observations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haziq Razali",
      "Yiannis Demiris"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28267": {
    "title": "Multi-Step Denoising Scheduled Sampling: Towards Alleviating Exposure Bias for Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyao Ren",
      "Yibing Zhan",
      "Liang Ding",
      "Gaoang Wang",
      "Chaoyue Wang",
      "Zhongyi Fan",
      "Dacheng Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28268": {
    "title": "CRA-PCN: Point Cloud Completion with Intra- and Inter-level Cross-Resolution Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Rong",
      "Haoran Zhou",
      "Lixin Yuan",
      "Cheng Mei",
      "Jiahao Wang",
      "Tong Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28269": {
    "title": "Entropic Open-Set Active Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bardia Safaei",
      "Vibashan VS",
      "Celso M. de Melo",
      "Vishal M. Patel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28270": {
    "title": "Generating Images of Rare Concepts Using Pre-trained Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dvir Samuel",
      "Rami Ben-Ari",
      "Simon Raviv",
      "Nir Darshan",
      "Gal Chechik"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28271": {
    "title": "RG-GAN: Dynamic Regenerative Pruning for Data-Efficient Generative Adversarial Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Divya Saxena",
      "Jiannong Cao",
      "Jiahao Xu",
      "Tarun Kulshrestha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28272": {
    "title": "SeTformer Is What You Need for Vision and Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pourya Shamsolmoali",
      "Masoumeh Zareapoor",
      "Eric Granger",
      "Michael Felsberg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28273": {
    "title": "Multi-Domain Multi-Scale Diffusion Model for Low-Light Image Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Shang",
      "Mingwen  Shao",
      "Chao Wang",
      "Yuanshuo Cheng",
      "Shuigen Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28274": {
    "title": "Polyper: Boundary Sensitive Polyp Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Shao",
      "Yang Zhang",
      "Qibin Hou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28275": {
    "title": "Collaborative Consortium of Foundation Models for Open-World Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Shao",
      "Yu Bai",
      "Yan Wang",
      "Baodi Liu",
      "Bin Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28276": {
    "title": "FaceCoresetNet: Differentiable Coresets for Face Set Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gil Shapira",
      "Yosi Keller"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28277": {
    "title": "Decouple Content and Motion for Conditional Image-to-Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cuifeng Shen",
      "Yulu Gan",
      "Chen Chen",
      "Xiongwei Zhu",
      "Lele Cheng",
      "Tingting Gao",
      "Jinzhi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28278": {
    "title": "GroundVLP: Harnessing Zero-Shot Visual Grounding from Vision-Language Pre-training and Open-Vocabulary Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haozhan Shen",
      "Tiancheng Zhao",
      "Mingwei Zhu",
      "Jianwei Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28279": {
    "title": "Automatic Radiology Reports Generation via Memory Alignment Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongyu Shen",
      "Mingtao Pei",
      "Juncai Liu",
      "Zhaoxing Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28280": {
    "title": "CGMGM: A Cross-Gaussian Mixture Generative Model for Few-Shot Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junao Shen",
      "Kun Kuang",
      "Jiaheng Wang",
      "Xinyu Wang",
      "Tian Feng",
      "Wei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28281": {
    "title": "Learn How to See: Collaborative Embodied Learning for Object Detection and Camera Adjusting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingdong Shen",
      "Chunlei Huo",
      "Nuo Xu",
      "Chaowei Han",
      "Zichen Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28282": {
    "title": "Distributed Manifold Hashing for Image Set Classification and Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaobo Shen",
      "Peizhuo Song",
      "Yun-Hao Yuan",
      "Yuhui Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28283": {
    "title": "Controllable 3D Face Generation with Conditional Style Code Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaolong Shen",
      "Jianxin Ma",
      "Chang Zhou",
      "Zongxin Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28284": {
    "title": "Adaptive Integration of Partial Label Learning and Negative Learning for Enhanced Noisy Label Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengmeng Sheng",
      "Zeren Sun",
      "Zhenhuang Cai",
      "Tao Chen",
      "Yichao Zhou",
      "Yazhou Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28285": {
    "title": "Transformer-Based No-Reference Image Quality Assessment via Supervised Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinsong Shi",
      "Pan Gao",
      "Jie Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28286": {
    "title": "Explicit Visual Prompts for Visual Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liangtao Shi",
      "Bineng Zhong",
      "Qihua Liang",
      "Ning Li",
      "Shengping Zhang",
      "Xianxian Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28287": {
    "title": "Evidential Uncertainty-Guided Mitochondria Segmentation for 3D EM Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruohua Shi",
      "Lingyu Duan",
      "Tiejun Huang",
      "Tingting Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28288": {
    "title": "Towards Squeezing-Averse Virtual Try-On via Sequential Deformation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sang-Heon Shim",
      "Jiwoo Chung",
      "Jae-Pil Heo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28289": {
    "title": "DPA-P2PNet: Deformable Proposal-Aware P2PNet for Accurate Point-Based Cell Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongyi Shui",
      "Sunyi Zheng",
      "Chenglu Zhu",
      "Shichuan Zhang",
      "Xiaoxuan Yu",
      "Honglin Li",
      "Jingxiong Li",
      "Pingyi Chen",
      "Lin Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28290": {
    "title": "DVANet: Disentangling View and Action Features for Multi-View Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nyle Siddiqui",
      "Praveen Tirupattur",
      "Mubarak Shah"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28291": {
    "title": "Learning to Approximate Adaptive Kernel Convolution on Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeyoon Sim",
      "Sooyeon Jeon",
      "InJun Choi",
      "Guorong Wu",
      "Won Hwa Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28292": {
    "title": "Semi-supervised Active Learning for Video Action Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayush Singh",
      "Aayush J Rana",
      "Akash Kumar",
      "Shruti Vyas",
      "Yogesh Singh Rawat"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28293": {
    "title": "DeblurSR: Event-Based Motion Deblurring under the Spiking Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Song",
      "Chandrajit Bajaj",
      "Qixing Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28294": {
    "title": "Multi-Cross Sampling and Frequency-Division Reconstruction for Image Compressed Sensing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heping Song",
      "Jingyao Gong",
      "Hongying Meng",
      "Yuping Lai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28295": {
    "title": "Generalizable Fourier Augmentation for Unsupervised Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huihui Song",
      "Tiankang Su",
      "Yuhui Zheng",
      "Kaihua Zhang",
      "Bo Liu",
      "Dong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28296": {
    "title": "Semantic-Aware Autoregressive Image Modeling for Visual Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiyou Song",
      "Shan Zhang",
      "Tong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28297": {
    "title": "Self-Prompt Mechanism for Few-Shot Image Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingchen Song",
      "Huiqiang Wang",
      "Guoqiang Zhong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28298": {
    "title": "Diverse Person: Customize Your Own Dataset for Text-Based Person Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zifan Song",
      "Guosheng Hu",
      "Cairong Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28299": {
    "title": "V2Meow: Meowing to the Visual Beat via Video-to-Music Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Su",
      "Judith Yue Li",
      "Qingqing Huang",
      "Dima Kuzmin",
      "Joonseok Lee",
      "Chris Donahue",
      "Fei Sha",
      "Aren Jansen",
      "Yu Wang",
      "Mauro Verzetti",
      "Timo Denk"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28300": {
    "title": "F³-Pruning: A Training-Free and Generalized Pruning Strategy towards Faster and Finer Text-to-Video Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sitong Su",
      "Jianzhi Liu",
      "Lianli Gao",
      "Jingkuan Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28301": {
    "title": "A Unified Environmental Network for Pedestrian Trajectory Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchao Su",
      "Yuanman Li",
      "Wei Wang",
      "Jiantao Zhou",
      "Xia Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28302": {
    "title": "LRANet: Towards Accurate and Efficient Scene Text Detection with Low-Rank Approximation Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchen Su",
      "Zhineng Chen",
      "Zhiwen Shao",
      "Yuning Du",
      "Zhilong Ji",
      "Jinfeng Bai",
      "Yong Zhou",
      "Yu-Gang Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28303": {
    "title": "Spatial-Semantic Collaborative Cropping for User Generated Content",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yukun Su",
      "Yiwen Cao",
      "Jingliang Deng",
      "Fengyun Rao",
      "Qingyao Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28304": {
    "title": "TR-DETR: Task-Reciprocal Transformer for Joint Moment Retrieval and Highlight Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Sun",
      "Mingyao Zhou",
      "Wenjing Chen",
      "Wei Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28305": {
    "title": "UniAP: Towards Universal Animal Perception in Vision via Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meiqi Sun",
      "Zhonghan Zhao",
      "Wenhao Chai",
      "Hanjun Luo",
      "Shidong Cao",
      "Yanting Zhang",
      "Jenq-Neng Hwang",
      "Gaoang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28306": {
    "title": "CFR-ICL: Cascade-Forward Refinement with Iterative Click Loss for Interactive Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shoukun Sun",
      "Min Xian",
      "Fei Xu",
      "Luca Capriotti",
      "Tiankai Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28307": {
    "title": "RL-SeqISP: Reinforcement Learning-Based Sequential Optimization for Image Signal Processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Sun",
      "Zhikun Zhao",
      "Lili Wei",
      "Congyan Lang",
      "Mingxuan Cai",
      "Longfei Han",
      "Juan Wang",
      "Bing Li",
      "Yuxuan Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28308": {
    "title": "PathAsst: A Generative Foundation AI Assistant towards Artificial General Intelligence of Pathology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Sun",
      "Chenglu Zhu",
      "Sunyi Zheng",
      "Kai Zhang",
      "Lin Sun",
      "Zhongyi Shui",
      "Yunlong Zhang",
      "Honglin Li",
      "Lin Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28309": {
    "title": "FG-EmoTalk: Talking Head Video Generation with Fine-Grained Controllable Facial Expressions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoxu Sun",
      "Yuze Xuan",
      "Fang Liu",
      "Yang Xiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28310": {
    "title": "Frequency-Aware Deepfake Detection: Improving Generalizability through Frequency Space Domain Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuangchuang Tan",
      "Yao Zhao",
      "Shikui Wei",
      "Guanghua Gu",
      "Ping Liu",
      "Yunchao Wei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28311": {
    "title": "Compound Text-Guided Prompt Tuning via Image-Adaptive Cues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Tan",
      "Jun Li",
      "Yizhuang Zhou",
      "Jun Wan",
      "Zhen Lei",
      "Xiangyu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28312": {
    "title": "Occluded Person Re-identification via Saliency-Guided Patch Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Tan",
      "Jiaer Xia",
      "Wenfeng Liu",
      "Pingyang Dai",
      "Yongjian Wu",
      "Liujuan Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28313": {
    "title": "Style2Talker: High-Resolution Talking Head Generation with Emotion Style and Art Style",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Tan",
      "Bin Ji",
      "Ye Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28314": {
    "title": "Say Anything with Any Style",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Tan",
      "Bin Ji",
      "Yu Ding",
      "Ye Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28315": {
    "title": "Semantic-Aware Data Augmentation for Text-to-Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaorui Tan",
      "Xi Yang",
      "Kaizhu Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28316": {
    "title": "Data-Free Generalized Zero-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Tang",
      "Jing Zhang",
      "Long Yan",
      "Qian Yu",
      "Lu Sheng",
      "Dong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28317": {
    "title": "Offline and Online Optical Flow Enhancement for Deep Video Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuanbo Tang",
      "Xihua Sheng",
      "Zhuoyuan Li",
      "Haotian Zhang",
      "Li Li",
      "Dong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28318": {
    "title": "Manifold Constraints for Imperceptible Adversarial Attacks on Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keke Tang",
      "Xu He",
      "Weilong Peng",
      "Jianpeng Wu",
      "Yawen Shi",
      "Daizong Liu",
      "Pan Zhou",
      "Wenping Wang",
      "Zhihong Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28319": {
    "title": "Once and for All: Universal Transferable Adversarial Perturbation against Deep Hashing-Based Facial Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Long Tang",
      "Dengpan Ye",
      "Yunna Lv",
      "Chuanxi Chen",
      "Yunming Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28320": {
    "title": "Prior and Prediction Inverse Kernel Transformer for Single Image Defocus Deblurring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Tang",
      "Zhiqiang Xu",
      "Chunlai Zhou",
      "Pengfei Wei",
      "Peng Han",
      "Xin Cao",
      "Tobias Lasser"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28321": {
    "title": "Semantic Lens: Instance-Centric Semantic Alignment for Video Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Tang",
      "Yao Zhao",
      "Meiqin Liu",
      "Jian Jin",
      "Chao Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28322": {
    "title": "Boosting Residual Networks with Group Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengji Tang",
      "Peng Ye",
      "Baopu Li",
      "Weihao Lin",
      "Tao Chen",
      "Tong He",
      "Chong Yu",
      "Wanli Ouyang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28323": {
    "title": "Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwen Tang",
      "Ray Zhang",
      "Zoey Guo",
      "Xianzheng Ma",
      "Bin Zhao",
      "Zhigang Wang",
      "Dong Wang",
      "Xuelong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28324": {
    "title": "Context-I2W: Mapping Images to Context-Dependent Words for Accurate Zero-Shot Composed Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanmin Tang",
      "Jing Yu",
      "Keke Gai",
      "Jiamin Zhuang",
      "Gang Xiong",
      "Yue Hu",
      "Qi Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28325": {
    "title": "Generative-Based Fusion Mechanism for Multi-Modal Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangyong Tang",
      "Tianyang Xu",
      "Xiaojun Wu",
      "Xue-Feng Zhu",
      "Josef Kittler"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28326": {
    "title": "Shadow Generation with Decomposed Mask Prediction and Attentive Shadow Filling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinhao Tao",
      "Junyan Cao",
      "Yan Hong",
      "Li Niu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28327": {
    "title": "Towards Efficient and Effective Text-to-Video Retrieval with Coarse-to-Fine Visual Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaibin Tian",
      "Yanhua Cheng",
      "Yi Liu",
      "Xinglin Hou",
      "Quan Chen",
      "Han Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28328": {
    "title": "Open-Vocabulary Video Relation Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wentao Tian",
      "Zheng Wang",
      "Yuqian Fu",
      "Jingjing Chen",
      "Lechao Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28329": {
    "title": "Divide and Conquer: Hybrid Pre-training for Person Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanling Tian",
      "Di Chen",
      "Yunan Liu",
      "Jian Yang",
      "Shanshan Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28330": {
    "title": "Taxonomy Driven Fast Adversarial Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Tong",
      "Chengze Jiang",
      "Jie Gui",
      "Yuan Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28331": {
    "title": "End-to-End Real-Time Vanishing Point Detection with Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Tong",
      "Shi Peng",
      "Yufei Guo",
      "Xuhui Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28332": {
    "title": "Discrete Cycle-Consistency Based Unsupervised Deep Graph Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddharth Tourani",
      "Muhammad Haris Khan",
      "Carsten Rother",
      "Bogdan Savchynskyy"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28333": {
    "title": "A Unified Masked Autoencoder with Patchified Skeletons for Motion Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Esteve Valls Mascaró",
      "Hyemin Ahn",
      "Dongheui Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28334": {
    "title": "CoVR: Learning Composed Video Retrieval from Web Video Captions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucas Ventura",
      "Antoine Yang",
      "Cordelia Schmid",
      "Gül Varol"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28335": {
    "title": "Supervision Interpolation via LossMix: Generalizing Mixup for Object Detection and Beyond",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thanh Vu",
      "Baochen Sun",
      "Bodi Yuan",
      "Alex Ngai",
      "Yueqi Li",
      "Jan-Michael  Frahm"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28336": {
    "title": "Integrated Decision Gradients: Compute Your Attributions Where the Model Makes Its Decision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chase Walker",
      "Sumit Jha",
      "Kenny Chen",
      "Rickard Ewetz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28337": {
    "title": "HISR: Hybrid Implicit Surface Representation for Photorealistic 3D Human Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Angtian Wang",
      "Yuanlu Xu",
      "Nikolaos Sarafianos",
      "Robert Maier",
      "Edmond Boyer",
      "Alan Yuille",
      "Tony Tung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28338": {
    "title": "VIGC: Visual Instruction Generation and Correction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Wang",
      "Fan Wu",
      "Xiao Han",
      "Jiahui Peng",
      "Huaping Zhong",
      "Pan Zhang",
      "Xiaoyi Dong",
      "Weijia Li",
      "Wei Li",
      "Jiaqi Wang",
      "Conghui He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28339": {
    "title": "Low-Light Face Super-resolution via Illumination, Structure, and Texture Associated Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyang Wang",
      "Junjun Jiang",
      "Kui Jiang",
      "Xianming Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28340": {
    "title": "SelfPromer: Self-Prompt Dehazing Transformers with Depth-Consistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cong Wang",
      "Jinshan Pan",
      "Wanyu Lin",
      "Jiangxin Dong",
      "Wei Wang",
      "Xiao-Ming Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28341": {
    "title": "Correlation Matching Transformation Transformers for UHD Image Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cong Wang",
      "Jinshan Pan",
      "Wei Wang",
      "Gang Fu",
      "Siyuan Liang",
      "Mengzhu Wang",
      "Xiao-Ming Wu",
      "Jun Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28342": {
    "title": "EulerMormer: Robust Eulerian Motion Magnification via Dynamic Filtering within Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Wang",
      "Dan Guo",
      "Kun Li",
      "Meng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28343": {
    "title": "Learning to Learn Better Visual Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengxiang Wang",
      "Wanrong Huang",
      "Shaowu Yang",
      "Qi Fan",
      "Long Lan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28344": {
    "title": "MuST: Robust Image Watermarking for Multi-Source Tracing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanjie Wang",
      "Zehua Ma",
      "Chang Liu",
      "Xi Yang",
      "Han Fang",
      "Weiming Zhang",
      "Nenghai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28345": {
    "title": "LION: Implicit Vision Prompt Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haixin Wang",
      "Jianlong Chang",
      "Yihang Zhai",
      "Xiao Luo",
      "Jinan Sun",
      "Zhouchen Lin",
      "Qi Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28346": {
    "title": "B-spine: Learning B-spline Curve Representation for Robust and Interpretable Spinal Curvature Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Wang",
      "Qiang Song",
      "Ruofeng Yin",
      "Rui Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28347": {
    "title": "ViLT-CLIP: Video and Language Tuning CLIP with Multimodal Prompt Learning and Scenario-Guided Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Wang",
      "Fang Liu",
      "Licheng   Jiao",
      "Jiahao Wang",
      "Zehua Hao",
      "Shuo Li",
      "Lingling Li",
      "Puhua Chen",
      "Xu Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28348": {
    "title": "Triple Feature Disentanglement for One-Stage Adaptive Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoan Wang",
      "Shilong Jia",
      "Tieyong Zeng",
      "Guixu Zhang",
      "Zhi Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28349": {
    "title": "Neural Physical Simulation with Multi-Resolution Hash Grid Encoding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoxiang Wang",
      "Tao Yu",
      "Tianwei Yang",
      "Hui Qiao",
      "Qionghai Dai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28350": {
    "title": "Deep Unfolded Network with Intrinsic Supervision for Pan-Sharpening",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hebaixu Wang",
      "Meiqi Gong",
      "Xiaoguang Mei",
      "Hao Zhang",
      "Jiayi Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28351": {
    "title": "Continuous Piecewise-Affine Based Motion Model for Image Animation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hexiang Wang",
      "Fengqi Liu",
      "Qianyu Zhou",
      "Ran Yi",
      "Xin Tan",
      "Lizhuang Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28352": {
    "title": "Temporal Adaptive RGBT Tracking with Modality Prompt",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongyu Wang",
      "Xiaotao Liu",
      "Yifan Li",
      "Meng Sun",
      "Dian Yuan",
      "Jing Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28353": {
    "title": "SAUI: Scale-Aware Unseen Imagineer for Zero-Shot Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Wang",
      "Caixia Yan",
      "Weizhan Zhang",
      "Huan Liu",
      "Hao Sun",
      "Qinghua Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28354": {
    "title": "Omnidirectional Image Super-resolution via Bi-projection Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangang Wang ",
      "Yuning Cui",
      "Yawen Li",
      "Wenqi Ren",
      "Xiaochun Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28355": {
    "title": "Adaptive FSS: A Novel Few-Shot Segmentation Framework via Prototype Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Wang",
      "Jiangyun Li",
      "Chen Chen",
      "Yisi Zhang",
      "Haoran Shen",
      "Tianxiang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28356": {
    "title": "PointAttN: You Only Need Attention for Point Cloud Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Wang",
      "Ying Cui",
      "Dongyan Guo",
      "Junxia Li",
      "Qingshan Liu",
      "Chunhua Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28357": {
    "title": "EarthVQA: Towards Queryable Earth via Relational Reasoning-Based Remote Sensing Visual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjue Wang",
      "Zhuo Zheng",
      "Zihang Chen",
      "Ailong Ma",
      "Yanfei Zhong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28358": {
    "title": "Semi-supervised Class-Agnostic Motion Prediction with Pseudo Label Regeneration and BEVMix",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kewei Wang",
      "Yizheng Wu",
      "Zhiyu Pan",
      "Xingyi Li",
      "Ke Xian",
      "Zhe Wang",
      "Zhiguo Cao",
      "Guosheng Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28359": {
    "title": "Multi-Domain Incremental Learning for Face Presentation Attack Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keyao Wang",
      "Guosheng Zhang",
      "Haixiao Yue",
      "Ajian Liu",
      "Gang Zhang",
      "Haocheng Feng",
      "Junyu Han",
      "Errui Ding",
      "Jingdong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28360": {
    "title": "AltNeRF: Learning Robust Neural Radiance Field via Alternating Depth-Pose Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Wang",
      "Zhiqiang Yan",
      "Huang Tian",
      "Zhenyu Zhang",
      "Xiang Li",
      "Jun Li",
      "Jian Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28361": {
    "title": "A Multimodal, Multi-Task Adapting Framework for Video Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengmeng Wang",
      "Jiazheng Xing",
      "Boyuan Jiang",
      "Jun Chen",
      "Jianbiao Mei",
      "Xingxing Zuo",
      "Guang Dai",
      "Jingdong Wang",
      "Yong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28362": {
    "title": "msLPCC: A Multimodal-Driven Scalable Framework for Deep LiDAR Point Cloud Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miaohui Wang",
      "Runnan Huang",
      "Hengjin Dong",
      "Di Lin",
      "Yun Song",
      "Wuyuan Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28363": {
    "title": "Cycle-Consistency Learning for Captioning and Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ning Wang",
      "Jiajun Deng",
      "Mingbo Jia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28364": {
    "title": "Compositional Text-to-Image Synthesis with Attention Map Control of Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruichen Wang",
      "Zekang Chen",
      "Chen Chen",
      "Jian Ma",
      "Haonan Lu",
      "Xiaodong Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28365": {
    "title": "AGS: Affordable and Generalizable Substitute Training for Transferable Adversarial Attack",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruikui Wang",
      "Yuanfang Guo",
      "Yunhong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28366": {
    "title": "DocNLC: A Document Image Enhancement Framework with Normalized and Latent Contrastive Representation for Multiple Degradations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruilu Wang",
      "Yang Xue",
      "Lianwen Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28367": {
    "title": "Towards Evidential and Class Separable Open Set Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruofan Wang",
      "Rui-Wei Zhao",
      "Xiaobo Zhang",
      "Rui Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28368": {
    "title": "Suppressing Uncertainty in Gaze Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shijing Wang",
      "Yaping Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28369": {
    "title": "What Effects the Generalization in Visual Reinforcement Learning: Policy Consistency with Truncated Return Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Wang",
      "Zhihao Wu",
      "Xiaobo Hu",
      "Jinwen Wang",
      "Youfang Lin",
      "Kai Lv"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28370": {
    "title": "DeepAccident: A Motion and Accident Prediction Benchmark for V2X Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianqi Wang",
      "Sukmin Kim",
      "Ji Wenxuan",
      "Enze Xie",
      "Chongjian Ge",
      "Junsong Chen",
      "Zhenguo Li",
      "Ping Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28371": {
    "title": "Semantic-Guided Novel Category Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weishuai Wang",
      "Ting Lei",
      "Qingchao Chen",
      "Yang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28372": {
    "title": "HARDVS: Revisiting Human Activity Recognition with Dynamic Vision Sensors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Wang",
      "Zongzhen Wu",
      "Bo Jiang",
      "Zhimin Bao",
      "Lin Zhu",
      "Guoqi Li",
      "Yaowei Wang",
      "Yonghong Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28373": {
    "title": "Structural Information Guided Multimodal Pre-training for Vehicle-Centric Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Wang",
      "Wentao Wu",
      "Chenglong Li",
      "Zhicheng Zhao",
      "Zhe Chen",
      "Yukai Shi",
      "Jin Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28374": {
    "title": "ICAR: Image-Based Complementary Auto Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xijun Wang",
      "Anqi Liang",
      "Junbang Liang",
      "Ming Lin",
      "Yu Lou",
      "Shan Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28375": {
    "title": "GCNext: Towards the Unity of Graph Convolutions for Human Motion Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinshun Wang",
      "Qiongjie Cui",
      "Chen Chen",
      "Mengyuan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28376": {
    "title": "CL2CM: Improving Cross-Lingual Cross-Modal Retrieval via Cross-Lingual Knowledge Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yabing Wang",
      "Fan Wang",
      "Jianfeng Dong",
      "Hao Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28377": {
    "title": "OSFFNet: Omni-Stage Feature Fusion Network for Lightweight Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Wang",
      "Tao Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28378": {
    "title": "Prompting Segmentation with Sound Is Generalizable Audio-Visual Source Localizer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaoting Wang",
      "Weisong Liu",
      "Guangyao Li",
      "Jian Ding",
      "Di Hu",
      "Xi Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28379": {
    "title": "Mask-Homo: Pseudo Plane Mask-Guided Unsupervised Multi-Homography Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yasi Wang",
      "Hong Liu",
      "Chao Zhang",
      "Lu Xu",
      "Qiang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28380": {
    "title": "PointPatchMix: Point Cloud Mixing with Patch Scoring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Wang",
      "Jiaze Wang",
      "Jinpeng Li",
      "Zixu Zhao",
      "Guangyong Chen",
      "Anfeng Liu",
      "Pheng Ann Heng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28381": {
    "title": "Data Distribution Distilled Generative Model for Generalized Zero-Shot Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijie Wang",
      "Mingjian Hong",
      "Luwen Huangfu",
      "Sheng Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28382": {
    "title": "SiMA-Hand: Boosting 3D Hand-Mesh Reconstruction by Single-to-Multi-View Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinqiao Wang",
      "Hao Xu",
      "Pheng Ann Heng",
      "Chi-Wing Fu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28383": {
    "title": "SQLdepth: Generalizable Self-Supervised Fine-Structured Monocular Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youhong Wang",
      "Yunji Liang",
      "Hao Xu",
      "Shaohui Jiao",
      "Hongkai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28384": {
    "title": "H2GFormer: Horizontal-to-Global Voxel Transformer for 3D Semantic Scene Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Wang",
      "Chao Tong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28385": {
    "title": "Exploring Diverse Representations for Open Set Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Wang",
      "Junxian Mu",
      "Pengfei Zhu",
      "Qinghua Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28386": {
    "title": "SMILEtrack: SiMIlarity LEarning for Occlusion-Aware Multiple Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-Hsiang Wang",
      "Jun-Wei Hsieh",
      "Ping-Yang Chen",
      "Ming-Ching Chang",
      "Hung-Hin So",
      "Xin Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28387": {
    "title": "Learning Hierarchical Prompt with Structured Linguistic Knowledge for Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yubin Wang",
      "Xinyang Jiang",
      "De Cheng",
      "Dongsheng Li",
      "Cairong Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28388": {
    "title": "TOP-ReID: Multi-Spectral Object Re-identification with Token Permutation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Wang",
      "Xuehu Liu",
      "Pingping Zhang",
      "Hu Lu",
      "Zhengzheng Tu",
      "Huchuan Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28389": {
    "title": "GMMFormer: Gaussian-Mixture-Model Based Transformer for Efficient Partially Relevant Video Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuting Wang",
      "Jinpeng Wang",
      "Bin Chen",
      "Ziyun Zeng",
      "Shu-Tao Xia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28390": {
    "title": "Out of Thin Air: Exploring Data-Free Adversarial Robustness Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzheng Wang",
      "Zhaoyu Chen",
      "Dingkang Yang",
      "Pinxue Guo",
      "Kaixun Jiang",
      "Wenqiang Zhang",
      "Lizhe Qi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28391": {
    "title": "QAGait: Revisit Gait Recognition from a Quality Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zengbin Wang",
      "Saihui Hou",
      "Man Zhang",
      "Xu Liu",
      "Chunshui Cao",
      "Yongzhen Huang",
      "Peipei Li",
      "Shibiao Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28392": {
    "title": "Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder Super-resolution Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyang Wang",
      "Dongyang Li",
      "Mingyang Zhang",
      "Hao Luo",
      "Maoguo Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28393": {
    "title": "SkyScript: A Large and Semantically Diverse Vision-Language Dataset for Remote Sensing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhecheng Wang",
      "Rajanie Prabha",
      "Tianyuan Huang",
      "Jiajun Wu",
      "Ram Rajagopal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28394": {
    "title": "DTMFormer: Dynamic Token Merging for Boosting Transformer-Based Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhehao Wang",
      "Xian Lin",
      "Nannan Wu",
      "Li Yu",
      "Kwang-Ting Cheng",
      "Zengqiang Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28395": {
    "title": "SGNet: Structure Guided Network via Gradient-Frequency Awareness for Depth Map Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengxue Wang",
      "Zhiqiang Yan",
      "Jian Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28396": {
    "title": "Vision Transformer Off-the-Shelf: A Surprising Baseline for Few-Shot Class-Agnostic Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhicheng Wang",
      "Liwen Xiao",
      "Zhiguo Cao",
      "Hao Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28397": {
    "title": "Existence Is Chaos: Enhancing 3D Human Motion Prediction with Uncertainty Consideration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihao Wang",
      "Yulin Zhou",
      "Ningyu Zhang",
      "Xiaosong Yang",
      "Jun Xiao",
      "Zhao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28398": {
    "title": "Heterogeneous Test-Time Training for Multi-Modal Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zi Wang",
      "Huaibo Huang",
      "Aihua Zheng",
      "Ran He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28399": {
    "title": "Fine-Grained Prototypes Distillation for Few-Shot Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zichen Wang",
      "Bo Yang",
      "Haonan Yue",
      "Zhenghao Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28400": {
    "title": "Semantic Complete Scene Forecasting from a 4D Dynamic Point Cloud Sequence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zifan Wang",
      "Zhuorui Ye",
      "Haoran Wu",
      "Junyu Chen",
      "Li Yi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28401": {
    "title": "Enhanced Fine-Grained Motion Diffusion for Text-Driven Human Motion Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Wei",
      "Xiaoning Sun",
      "Huaijiang Sun",
      "Shengxiang Hu",
      "Bin Li",
      "Weiqing Li",
      "Jianfeng Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28402": {
    "title": "Image as a Language: Revisiting Scene Text Recognition via Balanced, Unified and Synchronized Vision-Language Reasoning Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiajun Wei",
      "Hongjian Zhan",
      "Yue Lu",
      "Xiao Tu",
      "Bing Yin",
      "Cong Liu",
      "Umapada Pal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28403": {
    "title": "WeakPCSOD: Overcoming the Bias of Box Annotations for Weakly Supervised Point Cloud Salient Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Wei",
      "S. Kevin Zhou",
      "Shuguang Cui",
      "Zhen Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28404": {
    "title": "RetouchFormer: Semi-supervised High-Quality Face Retouching Transformer with Prior-Based Selective Self-Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xue Wen",
      "Lianxin Xie",
      "Le Jiang",
      "Tianyi Chen",
      "Si Wu",
      "Cheng Liu",
      "Hau-San Wong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28405": {
    "title": "Mean Teacher DETR with Masked Feature Alignment: A Robust Domain Adaptive Detection Transformer Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weixi Weng",
      "Chun Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28406": {
    "title": "Keep the Faith: Faithful Explanations in Convolutional Neural Networks for Case-Based Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tom Nuno Wolf",
      "Fabian Bongratz",
      "Anne-Marie Rickmann",
      "Sebastian Pölsterl",
      "Christian Wachinger"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28407": {
    "title": "Factorized Diffusion Autoencoder for Unsupervised Disentangled Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ancong Wu",
      "Wei-Shi Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28408": {
    "title": "3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changli Wu",
      "Yiwei Ma",
      "Qi Chen",
      "Haowei Wang",
      "Gen Luo",
      "Jiayi Ji",
      "Xiaoshuai Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28409": {
    "title": "SCD-Net: Spatiotemporal Clues Disentanglement Network for Self-Supervised Skeleton-Based Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cong Wu",
      "Xiao-Jun Wu",
      "Josef Kittler",
      "Tianyang Xu",
      "Sara Ahmed",
      "Muhammad Awais",
      "Zhenhua Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28410": {
    "title": "G-NAS: Generalizable Neural Architecture Search for Single Domain Generalization Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Wu",
      "Jinling Gao",
      "Lanqing Hong",
      "Xinbing Wang",
      "Chenghu Zhou",
      "Nanyang Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28411": {
    "title": "Multiscale Low-Frequency Memory Network for Improved Feature Extraction in Convolutional Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fuzhi Wu",
      "Jiasong Wu",
      "Youyong Kong",
      "Chunfeng Yang",
      "Guanyu Yang",
      "Huazhong Shu",
      "Guy Carrault",
      "Lotfi Senhadji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28412": {
    "title": "Learning from History: Task-agnostic Model Contrastive Learning for Image Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gang Wu",
      "Junjun Jiang",
      "Kui Jiang",
      "Xianming Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28413": {
    "title": "Hybrid-Supervised Dual-Search: Leveraging Automatic Learning for Loss-Free Multi-Exposure Image Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanyao Wu",
      "Hongming Fu",
      "Jinyuan Liu",
      "Long Ma",
      "Xin Fan",
      "Risheng Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28414": {
    "title": "When to Grow? A Fitting Risk-Aware Policy for Layer Growing in Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haihang Wu",
      "Wei Wang",
      "Tamasha Malepathirana",
      "Damith Senanayake",
      "Denny Oetomo",
      "Saman Halgamuge"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28415": {
    "title": "p-Laplacian Adaptation for Generative Pre-trained Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyuan Wu",
      "Xinyun Zhang",
      "Peng Xu",
      "Peiyu Liao",
      "Xufeng Yao",
      "Bei Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28416": {
    "title": "Task-Adaptive Prompted Transformer for Cross-Domain Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiamin Wu",
      "Xin Liu",
      "Xiaotian Yin",
      "Tianzhu Zhang",
      "Yongdong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28417": {
    "title": "SyFormer: Structure-Guided Synergism Transformer for Large-Portion Image Inpainting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Wu",
      "Yuchao Feng",
      "Honghui Xu",
      "Chuanmeng Zhu",
      "Jianwei Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28418": {
    "title": "MedSegDiff-V2: Diffusion-Based Medical Image Segmentation with Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junde Wu",
      "Wei Ji",
      "Huazhu Fu",
      "Min Xu",
      "Yueming Jin",
      "Yanwu Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28419": {
    "title": "Selective and Orthogonal Feature Activation for Pedestrian Attribute Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyi Wu",
      "Yan Huang",
      "Min Gao",
      "Yuzhen Niu",
      "Mingjing Yang",
      "Zhipeng Gao",
      "Jianqiang Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28420": {
    "title": "Swift-Mapping: Online Neural Implicit Dense Mapping in Urban Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Wu",
      "Kaizhao Zhang",
      "Mingzhe Gao",
      "Jieru Zhao",
      "Zhongxue Gan",
      "Wenchao Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28421": {
    "title": "CPN: Complementary Proposal Network for Unconstrained Text Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longhuang Wu",
      "Shangxuan Tian",
      "Youxin Wang",
      "Pengfei Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28422": {
    "title": "Toward Open-Set Human Object Interaction Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingrui Wu",
      "Yuqi Liu",
      "Jiayi Ji",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28423": {
    "title": "VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Wu",
      "Xuerong Zhou",
      "Guansong Pang",
      "Lingru Zhou",
      "Qingsen Yan",
      "Peng Wang",
      "Yanning Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28424": {
    "title": "Temporal Correlation Vision Transformer for Video Person Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengfei Wu",
      "Le Wang",
      "Sanping Zhou",
      "Gang Hua",
      "Changyin Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28425": {
    "title": "Point-to-Spike Residual Learning for Energy-Efficient 3D Point Cloud Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiaoyun Wu",
      "Quanxiao Zhang",
      "Chunyu Tan",
      "Yun Zhou",
      "Changyin Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28426": {
    "title": "Segment beyond View: Handling Partially Missing Modality for Audio-Visual Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renjie Wu",
      "Hu Wang",
      "Feras Dayoub",
      "Hsiang-Ting Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28427": {
    "title": "Towards Transferable Adversarial Attacks with Centralized Perturbation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangbo Wu",
      "Yu-an Tan",
      "Yajie Wang",
      "Ruinan Ma",
      "Wencong Ma",
      "Yuanzhang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28428": {
    "title": "CLIM: Contrastive Language-Image Mosaic for Region Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Size Wu",
      "Wenwei Zhang",
      "Lumin Xu",
      "Sheng Jin",
      "Wentao Liu",
      "Chen Change Loy"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28429": {
    "title": "SphereDiffusion: Spherical Geometry-Aware Distortion Resilient Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Wu",
      "Xuewei Li",
      "Zhongang Qi",
      "Di Hu",
      "Xintao Wang",
      "Ying Shan",
      "Xi Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28430": {
    "title": "LRS: Enhancing Adversarial Transferability through Lipschitz Regularized Surrogate",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Wu",
      "Tie Luo",
      "Donald C. Wunsch II"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28431": {
    "title": "CR-SAM: Curvature Regularized Sharpness-Aware Minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Wu",
      "Tie Luo",
      "Donald C. Wunsch II"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28432": {
    "title": "Semi-supervised 3D Object Detection with PatchTeacher and PillarMix",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaopei Wu",
      "Liang Peng",
      "Liang Xie",
      "Yuenan Hou",
      "Binbin Lin",
      "Xiaoshui Huang",
      "Haifeng Liu",
      "Deng Cai",
      "Wanli Ouyang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28433": {
    "title": "Text-Based Occluded Person Re-identification via Multi-Granularity Contrastive Consistency Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyi Wu",
      "Wentao Ma",
      "Dan Guo",
      "Tongqing Zhou",
      "Shan Zhao",
      "Zhiping Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28434": {
    "title": "CMG-Net: Robust Normal Estimation for Point Clouds via Chamfer Normal Distance and Multi-Scale Geometry",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingrui Wu",
      "Mingyang Zhao",
      "Keqiang Li",
      "Weize Quan",
      "Tianqi Yu",
      "Jianfeng Yang",
      "Xiaohong Jia",
      "Dong-Ming Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28435": {
    "title": "WaveFormer: Wavelet Transformer for Noise-Robust Video Inpainting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiliang Wu",
      "Changchang Sun",
      "Hanyu Xuan",
      "Gaowen Liu",
      "Yan Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28436": {
    "title": "FD3D: Exploiting Foreground Depth Map for Feature-Supervised Monocular 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zizhang Wu",
      "Yuanzhu Gan",
      "Yunzhe Wu",
      "Ruihao Wang",
      "Xiaoquan Wang",
      "Jian Pu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28437": {
    "title": "Attention Disturbance and Dual-Path Constraint Network for Occluded Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaer Xia",
      "Lei Tan",
      "Pingyang Dai",
      "Mingbo Zhao",
      "Yongjian Wu",
      "Liujuan Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28438": {
    "title": "Locality Preserving Refinement for Shape Matching with Functional Maps",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Xia",
      "Yifan Lu",
      "Yuan Gao",
      "Jiayi Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28439": {
    "title": "SocialCVAE: Predicting Pedestrian Trajectory via Interaction Conditioned Latents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Xiang",
      "Haoteng YIN",
      "He Wang",
      "Xiaogang Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28440": {
    "title": "Dynamic Semantic-Based Spatial Graph Convolution Network for Skeleton-Based Human Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianyang Xie",
      "Yanda Meng",
      "Yitian Zhao",
      "Anh Nguyen",
      "Xiaoyun Yang",
      "Yalin Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28441": {
    "title": "G2P-DDM: Generating Sign Pose Sequence from Gloss Sequence with Discrete Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pan Xie",
      "Qipeng Zhang",
      "Peng Taiying",
      "Hao Tang",
      "Yao Du",
      "Zexian Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28442": {
    "title": "Towards Understanding Future: Consistency Guided Probabilistic Modeling for Action Anticipation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhao Xie",
      "Yadong Shi",
      "Kewei Wu",
      "Yaru Cheng",
      "Dan Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28443": {
    "title": "Towards Detailed Text-to-Motion Synthesis via Basic-to-Advanced Hierarchical Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Xie",
      "Yang Wu",
      "Xuehao Gao",
      "Zhongqian Sun",
      "Wei Yang",
      "Xiaodan Liang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28444": {
    "title": "Learning by Erasing: Conditional Entropy Based Transferable Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meng Xing",
      "Zhiyong Feng",
      "Yong Su",
      "Changjae Oh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28445": {
    "title": "Unsupervised Action Segmentation via Fast Learning of Semantically Consistent Actoms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Xing",
      "Weibing Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28446": {
    "title": "SPEAL: Skeletal Prior Embedded Attention Learning for Cross-Source Point Cloud Registration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kezheng Xiong",
      "Maoji Zheng",
      "Qingshan Xu",
      "Chenglu Wen",
      "Siqi Shen",
      "Cheng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28447": {
    "title": "Patched Line Segment Learning for Vector Road Mapping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiakun Xu",
      "Bowen Xu",
      "Gui-Song Xia",
      "Liang Dong",
      "Nan Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28448": {
    "title": "MuLTI: Efficient Video-and-Language Understanding with Text-Guided MultiWay-Sampler and Multiple Choice Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Xu",
      "Bo Liu",
      "Yunkuo Chen",
      "Mengli Cheng",
      "Xing Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28449": {
    "title": "Regulating Intermediate 3D Features for Vision-Centric Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junkai Xu",
      "Liang Peng",
      "Haoran Cheng",
      "Linxuan Xia",
      "Qi Zhou",
      "Dan Deng",
      "Wei Qian",
      "Wenxiao Wang",
      "Deng Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28450": {
    "title": "ZOOM: Learning Video Mirror Detection with Extremely-Weak Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Xu",
      "Tsun Wai Siu",
      "Rynson W.H. Lau"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28451": {
    "title": "Weakly Supervised Multimodal Affordance Grounding for Egocentric Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingjing Xu",
      "Yang Gao",
      "Wenfeng Song",
      "Aimin Hao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28452": {
    "title": "Gaze from Origin: Learning for Generalized Gaze Estimation by Embedding the Gaze Frontalization Process",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingjie Xu",
      "Feng Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28453": {
    "title": "HACDR-Net: Heterogeneous-Aware Convolutional Network for Diabetic Retinopathy Multi-Lesion Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "QiHao Xu",
      "Xiaoling Luo",
      "Chao Huang",
      "Chengliang Liu",
      "Jie Wen",
      "Jialei Wang",
      "Yong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28454": {
    "title": "Learning Invariant Inter-pixel Correlations for Superpixel Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sen Xu",
      "Shikui Wei",
      "Tao Ruan",
      "Lixin Liao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28455": {
    "title": "Direction-Aware Video Demoiréing with Temporal-Guided Bilateral Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuning Xu",
      "Binbin Song",
      "Xiangyu Chen",
      "Jiantao Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28456": {
    "title": "Spectral Prompt Tuning: Unveiling Unseen Classes for Zero-Shot Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Xu",
      "Rongtao Xu",
      "Changwei Wang",
      "Shibiao Xu",
      "Li Guo",
      "Man Zhang",
      "Xiaopeng Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28457": {
    "title": "SCTNet: Single-Branch CNN with Transformer Semantic Information for Real-Time Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengze Xu",
      "Dongyue Wu",
      "Changqian Yu",
      "Xiangxiang Chu",
      "Nong Sang",
      "Changxin Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28458": {
    "title": "Chain of Generation: Multi-Modal Gesture Synthesis via Cascaded Conditional Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zunnan Xu",
      "Yachao Zhang",
      "Sicheng Yang",
      "Ronghui Li",
      "Xiu Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28459": {
    "title": "Decoupled Contrastive Learning for Long-Tailed Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyu Xuan",
      "Shiliang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28460": {
    "title": "Revisiting Gradient Pruning: A Dual Realization for Defending against Gradient Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lulu Xue",
      "Shengshan Hu",
      "Ruizhi Zhao",
      "Leo Yu Zhang",
      "Shengqing Hu",
      "Lichao Sun",
      "Dezhong Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28461": {
    "title": "A Convolutional Neural Network Interpretable Framework for Human Ventral Visual Pathway Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mufan Xue",
      "Xinyu Wu",
      "Jinlong Li",
      "Xuesong Li",
      "Guoyuan Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28462": {
    "title": "Self-Supervised 3D Human Mesh Recovery from a Single Image with Uncertainty-Aware Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guoli Yan",
      "Zichun Zhong",
      "Jing Hua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28463": {
    "title": "HORIZON: High-Resolution Semantically Controlled Panorama Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Yan",
      "Lei Ji",
      "Chenfei Wu",
      "Jian Liang",
      "Ming Zhou",
      "Nan Duan",
      "Shuai Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28464": {
    "title": "CF-NeRF: Camera Parameter Free Neural Radiance Fields with Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingsong Yan",
      "Qiang Wang",
      "Kaiyong Zhao",
      "Jie Chen",
      "Bo Li",
      "Xiaowen Chu",
      "Fei Deng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28465": {
    "title": "Referred by Multi-Modality: A Unified Temporal Transformer for Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shilin Yan",
      "Renrui Zhang",
      "Ziyu Guo",
      "Wenchao Chen",
      "Wei Zhang",
      "Hongyang Li",
      "Yu Qiao",
      "Hao Dong",
      "Zhongjiang He",
      "Peng Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28466": {
    "title": "Embracing Language Inclusivity and Diversity in CLIP through Continual Language Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bang Yang",
      "Yong Dai",
      "Xuxin Cheng",
      "Yaowei Li",
      "Asif Raza",
      "Yuexian Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28467": {
    "title": "Geometry-Guided Domain Generalization for Monocular 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Yang",
      "Hui Chen",
      "Yuwei He",
      "Sicheng Zhao",
      "Chenghao Zhang",
      "Kai Ni",
      "Guiguang Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28468": {
    "title": "Diversity-Authenticity Co-constrained Stylization for Federated Domain Generalization in Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengxiang Yang",
      "Zhun Zhong",
      "Zhiming Luo",
      "Yifan He",
      "Shaozi Li",
      "Nicu Sebe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28469": {
    "title": "Semantic-Aware Transformation-Invariant RoI Align",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guo-Ye Yang",
      "George Kiyohiro Nakayama",
      "Zi-Kai Xiao",
      "Tai-Jiang Mu",
      "Xiaolei Huang",
      "Shi-Min Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28470": {
    "title": "FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hunmin Yang",
      "Jongoh Jeong",
      "Kuk-Jin Yoon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28471": {
    "title": "Hybrid-SORT: Weak Cues Matter for Online Multi-Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingzhan Yang",
      "Guangxin Han",
      "Bin Yan",
      "Wenhua Zhang",
      "Jinqing Qi",
      "Huchuan Lu",
      "Dong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28472": {
    "title": "Multi-Modal Prompting for Open-Vocabulary Video Visual Relationship Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Yang",
      "Yongqi Wang",
      "Xiaofeng Ji",
      "Xinxiao Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28473": {
    "title": "Learning Dense Correspondence for NeRF-Based Face Reenactment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songlin Yang",
      "Wei Wang",
      "Yushi Lan",
      "Xiangyu Fan",
      "Bo Peng",
      "Lei Yang",
      "Jing Dong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28474": {
    "title": "Motion Deblurring via Spatial-Temporal Collaboration of Frames and Events",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen Yang",
      "Jinjian Wu",
      "Jupo Ma",
      "Leida Li",
      "Guangming Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28475": {
    "title": "DGL: Dynamic Global-Local Prompt Tuning for Text-Video Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangpeng Yang",
      "Linchao Zhu",
      "Xiaohan Wang",
      "Yi Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28476": {
    "title": "Diverse and Stable 2D Diffusion Guided Text to 3D Generation with Noise Recalibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofeng Yang",
      "Fayao Liu",
      "Yi Xu",
      "Hanjing Su",
      "Qingyao Wu",
      "Guosheng Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28477": {
    "title": "Semantic Segmentation in Multiple Adverse Weather Conditions with Domain Knowledge Retention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Yang",
      "Wending Yan",
      "Yuan Yuan",
      "Michael Bi Mi",
      "Robby T. Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28478": {
    "title": "Hyperspectral Image Reconstruction via Combinatorial Embedding of Cross-Channel Spatio-Spectral Clues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingxing Yang",
      "Jie Chen",
      "Zaifeng Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28479": {
    "title": "Decomposing Semantic Shifts for Composed Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyu Yang",
      "Daqing Liu",
      "Heng Zhang",
      "Yong Luo",
      "Chaoyue Wang",
      "Jing Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28480": {
    "title": "Gaze Target Detection by Merging Human Attention and Activity Cues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaokun Yang",
      "Yihan Yin",
      "Feng Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28481": {
    "title": "PM-INR: Prior-Rich Multi-Modal Implicit Large-Scale Scene Neural Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiying Yang",
      "Fukun Yin",
      "Wen Liu",
      "Jiayuan Fan",
      "Xin Chen",
      "Gang Yu",
      "Tao Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28482": {
    "title": "FontDiffuser: One-Shot Font Generation via Denoising Diffusion with Multi-Scale Content Aggregation and Style Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenhua Yang",
      "Dezhi Peng",
      "Yuxin Kong",
      "Yuyi Zhang",
      "Cong Yao",
      "Lianwen Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28483": {
    "title": "Full-Body Motion Reconstruction with Sparse Sensing from Graph Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feiyu Yao",
      "Zongkai Wu",
      "Li Yi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28484": {
    "title": "FoSp: Focus and Separation Network for Early Smoke Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lujian Yao",
      "Haitao Zhao",
      "Jingchao Peng",
      "Zhongze Wang",
      "Kaijie Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28485": {
    "title": "How to Evaluate the Generalization of Detection? A Benchmark for Comprehensive Open-Vocabulary Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyang Yao",
      "Peng Liu",
      "Tiancheng Zhao",
      "Qianqian Zhang",
      "Jiajia Liao",
      "Chunxin Fang",
      "Kyusong Lee",
      "Qing Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28486": {
    "title": "Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guy Yariv",
      "Itai Gat",
      "Sagie Benaim",
      "Lior Wolf",
      "Idan Schwartz",
      "Yossi Adi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28487": {
    "title": "AltDiffusion: A Multilingual Text-to-Image Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fulong Ye",
      "Guang Liu",
      "Xinya Wu",
      "Ledell Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28488": {
    "title": "Mutual-Modality Adversarial Attack with Semantic Perturbation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingwen Ye",
      "Ruonan Yu",
      "Songhua Liu",
      "Xinchao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28489": {
    "title": "STDiff: Spatio-Temporal Diffusion for Continuous Stochastic Video Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Ye",
      "Guillaume-Alexandre Bilodeau"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28490": {
    "title": "DiffusionEdge: Diffusion Probabilistic Model for Crisp Edge Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunfan Ye",
      "Kai Xu",
      "Yuhang Huang",
      "Renjiao Yi",
      "Zhiping Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28491": {
    "title": "Dynamic Feature Pruning and Consolidation for Occluded Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "YuTeng Ye",
      "Hang Zhou",
      "Jiale Cai",
      "Chenxing Gao",
      "Youjia Zhang",
      "Junle Wang",
      "Qiang Hu",
      "Junqing Yu",
      "Wei Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28492": {
    "title": "Progressive Text-to-Image Diffusion with Soft Latent Direction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "YuTeng Ye",
      "Jiale Cai",
      "Hang Zhou",
      "Guanwen Li",
      "Youjia Zhang",
      "Zikai Song",
      "Chenxing Gao",
      "Junqing Yu",
      "Wei Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28493": {
    "title": "UCMCTrack: Multi-Object Tracking with Uniform Camera Motion Compensation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kefu Yi",
      "Kai Luo",
      "Xiaolei Luo",
      "Jiangui Huang",
      "Hao Wu",
      "Rongdong Hu",
      "Wei Hao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28494": {
    "title": "DiffRAW: Leveraging Diffusion Model to Generate DSLR-Comparable Perceptual Quality sRGB from Smartphone RAW Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingxin Yi",
      "Kai Zhang",
      "Pei Liu",
      "Tanli Zuo",
      "Jingduo Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28495": {
    "title": "Efficient Look-Up Table from Expanded Convolutional Network for Accelerating Image Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Yin",
      "Jie Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28496": {
    "title": "CLIP-Gaze: Towards General Gaze Estimation via Visual-Linguistic Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengwei Yin",
      "Guanzhong Zeng",
      "Jingjing Wang",
      "Di Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28497": {
    "title": "Point Deformable Network with Enhanced Normal Embedding for Point Cloud Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyilang Yin",
      "Xi Yang",
      "Liangchen Liu",
      "Nannan Wang",
      "Xinbo Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28498": {
    "title": "Revisiting Open-Set Panoptic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Yin",
      "Hao Chen",
      "Wengang Zhou",
      "Jiajun Deng",
      "Haiming Xu",
      "Houqiang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28499": {
    "title": "VQAttack: Transferable Adversarial Attacks on Visual Question Answering via Pre-trained Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyi Yin",
      "Muchao Ye",
      "Tianrong Zhang",
      "Jiaqi Wang",
      "Han Liu",
      "Jinghui Chen",
      "Ting Wang",
      "Fenglong Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28500": {
    "title": "TF-CLIP: Learning Text-Free CLIP for Video-Based Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyang Yu",
      "Xuehu Liu",
      "Yingquan Wang",
      "Pingping Zhang",
      "Huchuan Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28501": {
    "title": "MM-Point: Multi-View Information-Enhanced Multi-Modal Self-Supervised 3D Point Cloud Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai-Tao Yu",
      "Mofei Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28502": {
    "title": "Spatial Transform Decoupling for Oriented Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongtian Yu",
      "Yunjie Tian",
      "Qixiang Ye",
      "Yunfan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28503": {
    "title": "Step Vulnerability Guided Mean Fluctuation Adversarial Attack against Conditional Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongwei Yu",
      "Jiansheng Chen",
      "Xinlong Ding",
      "Yudong Zhang",
      "Ting Tang",
      "Huimin Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28504": {
    "title": "PaintHuman: Towards High-Fidelity Text-to-3D Human Texturing via Denoised Score Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianhui Yu",
      "Hao Zhu",
      "Liming Jiang",
      "Chen Change Loy",
      "Weidong Cai",
      "Wayne Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28505": {
    "title": "CatFormer: Category-Level 6D Object Pose Estimation with Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sheng Yu",
      "Di-Hua Zhai",
      "Yuanqing Xia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28506": {
    "title": "DME: Unveiling the Bias for Better Generalized Monocular Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songsong Yu",
      "Yifan Wang",
      "Yunzhi Zhuge",
      "Lijun Wang",
      "Huchuan Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28507": {
    "title": "DOCTR: Disentangled Object-Centric Transformer for Point Scene Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoxuan Yu",
      "Hao Wang",
      "Weiming Li",
      "Qiang Wang",
      "Soonyong Cho",
      "Younghun Sung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28508": {
    "title": "Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuanlong Yu",
      "Gianni Franchi",
      "Jindong Gu",
      "Emanuel Aldea"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28509": {
    "title": "Attacks on Continual Semantic Segmentation by Perturbing Incremental Samples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhidong Yu",
      "Wei Yang",
      "Xike Xie",
      "Zhenbo Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28510": {
    "title": "Data-Free Hard-Label Robustness Stealing Attack",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaojian Yuan",
      "Kejiang Chen",
      "Wen Huang",
      "Jie Zhang",
      "Weiming Zhang",
      "Nenghai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28511": {
    "title": "Efficient Conditional Diffusion Model with Probability Flow Sampling for Image Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutao Yuan",
      "Chun Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28512": {
    "title": "SD-MVS: Segmentation-Driven Deformation Multi-View Stereo with Spherical Refinement and EM Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenlong Yuan",
      "Jiakai Cao",
      "Zhaoxin Li",
      "Hao Jiang",
      "Zhaoqi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28513": {
    "title": "KeDuSR: Real-World Dual-Lens Super-Resolution via Kernel-Free Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huanjing Yue",
      "Zifan Cui",
      "Kun Li",
      "Jingyu Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28514": {
    "title": "SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxi Yue",
      "Jing Zhang",
      "Kun Hu",
      "Yong Xia",
      "Jiebo Luo",
      "Zhiyong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28515": {
    "title": "Unveiling Details in the Dark: Simultaneous Brightening and Zooming for Low-Light Image Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyu Yue",
      "Jiaxin Gao",
      "Zhixun Su"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28516": {
    "title": "Weakly-Supervised Temporal Action Localization by Inferring Salient Snippet-Feature",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wulian Yun",
      "Mengshi Qi",
      "Chuanming Wang",
      "Huadong Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28517": {
    "title": "Behavioral Recognition of Skeletal Data Based on Targeted Dual Fusion Strategy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Yun",
      "Chenglong Xu",
      "Kevin Riou",
      "Kaiwen Dong",
      "Yanjing Sun",
      "Song Li",
      "Kevin Subrin",
      "Patrick Le Callet"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28518": {
    "title": "Zero-Shot Aerial Object Detection with Visual Description Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengqing Zang",
      "Chenyu Lin",
      "Chenwei Tang",
      "Tao Wang",
      "Jiancheng Lv"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28519": {
    "title": "Controllable Mind Visual Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bohan Zeng",
      "Shanglin Li",
      "Xuhui Liu",
      "Sicheng Gao",
      "Xiaolong Jiang",
      "Xu Tang",
      "Yao Hu",
      "Jianzhuang Liu",
      "Baochang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28520": {
    "title": "MGQFormer: Mask-Guided Query-Based Transformer for Image Manipulation Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kunlun Zeng",
      "Ri Cheng",
      "Weimin Tan",
      "Bo Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28521": {
    "title": "Weakly-Supervised Mirror Detection via Scribble Annotations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingfeng Zha",
      "Yunqiang Pei",
      "Guoqing Wang",
      "Tianyu Li",
      "Yang Yang",
      "Wenbin Qian",
      "Heng Tao Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28522": {
    "title": "Towards Compact 3D Representations via Point Feature Enhancement Masked Autoencoders",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaohua Zha",
      "Huizhen Ji",
      "Jinmin Li",
      "Rongsheng Li",
      "Tao Dai",
      "Bin Chen",
      "Zhi Wang",
      "Shu-Tao Xia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28523": {
    "title": "Fine-Grained Knowledge Selection and Restoration for Non-exemplar Class Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiang-Tian Zhai",
      "Xialei Liu",
      "Lu Yu",
      "Ming-Ming Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28524": {
    "title": "Multi-Prompts Learning with Cross-Modal Alignment for Attribute-Based Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yajing Zhai",
      "Yawen Zeng",
      "Zhiyong  Huang",
      "Zheng Qin",
      "Xin Jin",
      "Da Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28525": {
    "title": "Mono3DVG: 3D Visual Grounding in Monocular Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Zhan",
      "Yuan Yuan",
      "Zhitong Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28526": {
    "title": "Amodal Scene Analysis via Holistic Occlusion Relation Inference and Generative Mask Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Zhang",
      "Qing Liu",
      "Jianming Zhang",
      "Yilin Wang",
      "Liyang Liu",
      "Zhe Lin",
      "Yifan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28527": {
    "title": "High-Quality Real-Time Rendering Using Subpixel Sampling Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyu Zhang",
      "Hongliang Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28528": {
    "title": "Weakly Supervised Few-Shot Object Detection with DETR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenbo Zhang",
      "Yinglu Zhang",
      "Lu Zhang",
      "Jiajia Zhao",
      "Jihong Guan",
      "Shuigeng Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28529": {
    "title": "S2WAT: Image Style Transfer via Hierarchical Vision Transformer Using Strips Window Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chiyu Zhang",
      "Xiaogang Xu",
      "Lei Wang",
      "Zaiyan Dai",
      "Jun Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28530": {
    "title": "Synergistic Multiscale Detail Refinement via Intrinsic Supervision for Underwater Image Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dehuan Zhang",
      "Jingchun Zhou",
      "Chunle Guo",
      "Weishi Zhang",
      "Chongyi Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28531": {
    "title": "W2P: Switching from Weak Supervision to Partial Supervision for Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangyuan Zhang",
      "Tianxiang Pan",
      "Jun-Hai Yong",
      "Bin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28532": {
    "title": "HyperEditor: Achieving Both Authenticity and Cross-Domain Capability in Image Editing via Hypernetworks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Zhang",
      "Chunwei Wu",
      "Guitao Cao",
      "Hailing Wang",
      "Wenming Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28533": {
    "title": "RadOcc: Learning Cross-Modality Occupancy Knowledge through Rendering Assisted Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiming Zhang",
      "Xu Yan",
      "Dongfeng Bai",
      "Jiantao Gao",
      "Pan Wang",
      "Bingbing Liu",
      "Shuguang Cui",
      "Zhen Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28534": {
    "title": "GSDD: Generative Space Dataset Distillation for Image Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiyu Zhang",
      "Shaolin Su",
      "Yu Zhu",
      "Jinqiu Sun",
      "Yanning Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28535": {
    "title": "CSL: Class-Agnostic Structure-Constrained Learning for Segmentation Including the Unseen",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Zhang",
      "Fang Li",
      "Lu Qi",
      "Ming-Hsuan Yang",
      "Narendra Ahuja"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28536": {
    "title": "A Robust Mutual-Reinforcing Framework for 3D Multi-Modal Medical Image Fusion Based on Visual-Semantic Consistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Zhang",
      "Xuhui Zuo",
      "Huabing Zhou",
      "Tao Lu",
      "Jiayi Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28537": {
    "title": "Learning Task-Aware Language-Image Representation for Class-Incremental Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongquan Zhang",
      "Bin-Bin Gao",
      "Yi Zeng",
      "Xudong Tian",
      "Xin Tan",
      "Zhizhong Zhang",
      "Yanyun Qu",
      "Jun Liu",
      "Yuan Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28538": {
    "title": "Identification of Necessary Semantic Undertakers in the Causal View for Image-Text Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huatian Zhang",
      "Lei Zhang",
      "Kun Zhang",
      "Zhendong Mao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28539": {
    "title": "HR-Pro: Point-Supervised Temporal Action Localization via Hierarchical Reliability Propagation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huaxin Zhang",
      "Xiang Wang",
      "Xiaohao Xu",
      "Zhiwu Qing",
      "Changxin Gao",
      "Nong Sang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28540": {
    "title": "AvatarVerse: High-Quality & Stable 3D Avatar Creation from Text and Pose",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huichao Zhang",
      "Bowen Chen",
      "Hao Yang",
      "Liao Qu",
      "Xu Wang",
      "Li Chen",
      "Chao Long",
      "Feida Zhu",
      "Daniel Du",
      "Min  Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28541": {
    "title": "Improving the Adversarial Transferability of Vision Transformers with Virtual Dense Connection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianping Zhang",
      "Yizhan Huang",
      "Zhuoer Xu",
      "Weibin Wu",
      "Michael R. Lyu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28542": {
    "title": "Curvature-Invariant Adversarial Attacks for 3D Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianping Zhang",
      "Wenwei Gu",
      "Yizhan Huang",
      "Zhihan Jiang",
      "Weibin Wu",
      "Michael R. Lyu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28543": {
    "title": "Cross-Modal Feature Distribution Calibration for Few-Shot Visual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Zhang",
      "Xiaoqiang Liu",
      "Mingzhe Chen",
      "Zhe Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28544": {
    "title": "Robust 3D Tracking with Quality-Aware Shape Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingwen Zhang",
      "Zikun Zhou",
      "Guangming Lu",
      "Jiandong Tian",
      "Wenjie Pei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28545": {
    "title": "Neighborhood-Enhanced 3D Human Pose Estimation with Monocular LiDAR in Long-Range Outdoor Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyi Zhang",
      "Qihong Mao",
      "Guosheng Hu",
      "Siqi Shen",
      "Cheng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28546": {
    "title": "NeRF-LiDAR: Generating Realistic LiDAR Point Clouds with Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junge Zhang",
      "Feihu Zhang",
      "Shaochen Kuang",
      "Li Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28547": {
    "title": "Point Cloud Part Editing: Segmentation, Generation, Assembly, and Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiyi Zhang",
      "Yang Chen",
      "Ximing Yang",
      "Weizhong Zhang",
      "Cheng Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28548": {
    "title": "CatmullRom Splines-Based Regression for Image Forgery Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Zhang",
      "Mingliang Xu",
      "Dong Li",
      "Jianming Du",
      "Rujing Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28549": {
    "title": "Deep Semantic Graph Transformer for Multi-View 3D Human Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lijun Zhang",
      "Kangkang Zhou",
      "Feng Lu",
      "Xiang-Dong Zhou",
      "Yu Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28550": {
    "title": "Brush Your Text: Synthesize Any Scene Text on Images via Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingjun Zhang",
      "Xinyuan Chen",
      "Yaohui Wang",
      "Yue Lu",
      "Yu Qiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28551": {
    "title": "IRPruneDet: Efficient Infrared Small Target Detection via Wavelet Structure-Regularized Soft Channel Pruning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingjin Zhang",
      "Handi Yang",
      "Jie Guo",
      "Yunsong Li",
      "Xinbo Gao",
      "Jing Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28552": {
    "title": "M2Doc: A Multi-Modal Fusion Approach for Document Layout Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ning Zhang",
      "Hiuyi Cheng",
      "Jiayu Chen",
      "Zongyuan Jiang",
      "Jun Huang",
      "Yang Xue",
      "Lianwen Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28553": {
    "title": "Multi-View People Detection in Large Scenes via Supervised View-Wise Contribution Weighting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Zhang",
      "Yunfei Gong",
      "Daijie Chen",
      "Antoni B. Chan",
      "Hui Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28554": {
    "title": "Aligning Geometric Spatial Layout in Cross-View Geo-Localization via Feature Recombination",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingwang Zhang",
      "Yingying Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28555": {
    "title": "MobileInst: Video Instance Segmentation on the Mobile",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renhong Zhang",
      "Tianheng Cheng",
      "Shusheng Yang",
      "Haoyi Jiang",
      "Shuai Zhang",
      "Jiancheng Lyu",
      "Xin Li",
      "Xiaowen Ying",
      "Dashan Gao",
      "Wenyu Liu",
      "Xinggang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28556": {
    "title": "Scalable Geometric Fracture Assembly via Co-creation Space among Assemblers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiyuan Zhang",
      "Jiaxiang Liu",
      "Zexi Li",
      "Hao Dong",
      "Jie Fu",
      "Chao Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28557": {
    "title": "S3A: Towards Realistic Zero-Shot Classification via Self Structural Semantic Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sheng Zhang",
      "Muzammal Naseer",
      "Guangyi Chen",
      "Zhiqiang Shen",
      "Salman Khan",
      "Kun Zhang",
      "Fahad Shahbaz Khan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28558": {
    "title": "A Computation-Aware Shape Loss Function for Point Cloud Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shunran Zhang",
      "Xiubo Zhang",
      "Tsz Nam Chan",
      "Shenghui Zhang",
      "Leong Hou U"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28559": {
    "title": "Vision-Language Pre-training with Object Contrastive Learning for 3D Scene Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taolin Zhang",
      "Sunan He",
      "Tao Dai",
      "Zhi Wang",
      "Bin Chen",
      "Shu-Tao Xia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28560": {
    "title": "Transformer-Based Selective Super-resolution for Efficient Image Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyi Zhang",
      "Kishore Kasichainula",
      "Yaoxin Zhuo",
      "Baoxin Li",
      "Jae-Sun Seo",
      "Yu Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28561": {
    "title": "Exploring Base-Class Suppression with Prior Guidance for Bias-Free One-Shot Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenwen Zhang",
      "Yun Hu",
      "Hangguan Shan",
      "Eryun Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28562": {
    "title": "HEAP: Unsupervised Object Discovery and Localization with Contrastive Grouping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Zhang",
      "Jinheng Xie",
      "Yuan Yuan",
      "Michael Bi Mi",
      "Robby T. Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28563": {
    "title": "Scribble Hides Class: Promoting Scribble-Based Weakly-Supervised Semantic Segmentation with Its Class Label",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinliang Zhang",
      "Lei Zhu",
      "Hangzhou He",
      "Lujia Jin",
      "Yanye Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28564": {
    "title": "Negative Pre-aware for Noisy Cross-Modal Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Zhang",
      "Hao Li",
      "Mang Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28565": {
    "title": "Compositional Inversion for Stable Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xulu Zhang",
      "Xiao-Yong Wei",
      "Jinlin Wu",
      "Tianyi Zhang",
      "Zhaoxiang Zhang",
      "Zhen Lei",
      "Qing Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28566": {
    "title": "Cross-Modal Match for Language Conditioned 3D Object Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yachao Zhang",
      "Runze Hu",
      "Ronghui Li",
      "Yanyun Qu",
      "Yuan Xie",
      "Xiu Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28567": {
    "title": "MotionGPT: Finetuned LLMs Are General-Purpose Motion Generators",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaqi Zhang",
      "Di Huang",
      "Bin Liu",
      "Shixiang Tang",
      "Yan Lu",
      "Lu Chen",
      "Lei Bai",
      "Qi Chu",
      "Nenghai Yu",
      "Wanli Ouyang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28568": {
    "title": "Concept-Guided Prompt Learning for Generalization in Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Zhang",
      "Ce Zhang",
      "Ke Yu",
      "Yushun Tang",
      "Zhihai He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28569": {
    "title": "ISP-Teacher:Image Signal Process with Disentanglement Regularization for Unsupervised Domain Adaptive Dark Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yin Zhang",
      "Yongqiang Zhang",
      "Zian Zhang",
      "Man Zhang",
      "Rui Tian",
      "Mingli Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28570": {
    "title": "ArtBank: Artistic Style Transfer with Pre-trained Diffusion Model and Implicit Style Prompt Bank",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhanjie Zhang",
      "Quanwei Zhang",
      "Wei Xing",
      "Guangyuan Li",
      "Lei Zhao",
      "Jiakai Sun",
      "Zehua Lan",
      "Junsheng Luan",
      "Yiling Huang",
      "Huaizhong Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28571": {
    "title": "A New Benchmark and Model for Challenging Image Manipulation Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenfei Zhang",
      "Mingyang Li",
      "Ming-Ching Chang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28572": {
    "title": "TMFormer: Token Merging Transformer for Brain Tumor Segmentation with Missing Modalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheyu Zhang",
      "Gang Yang",
      "Yueyi Zhang",
      "Huanjing Yue",
      "Aiping Liu",
      "Yunwei Ou",
      "Jian Gong",
      "Xiaoyan Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28573": {
    "title": "FaceRSA: RSA-Aware Facial Identity Cryptography Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongyi Zhang",
      "Tianyi Wei",
      "Wenbo Zhou",
      "Hanqing Zhao",
      "Weiming Zhang",
      "Nenghai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28574": {
    "title": "Spatial-Contextual Discrepancy Information Compensation for GAN Inversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqiang Zhang",
      "Yan Yan",
      "Jing-Hao Xue",
      "Hanzi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28575": {
    "title": "Self-Distillation Regularized Connectionist Temporal Classification Loss for Text Recognition: A Simple Yet Effective Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyin Zhang",
      "Ning Lu",
      "Minghui Liao",
      "Yongshuai Huang",
      "Cheng Li",
      "Min Wang",
      "Wei Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28576": {
    "title": "PNeRFLoc: Visual Localization with Point-Based Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boming Zhao",
      "Luwei Yang",
      "Mao Mao",
      "Hujun Bao",
      "Zhaopeng Cui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28577": {
    "title": "SimDistill: Simulated Multi-Modal Distillation for BEV 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haimei Zhao",
      "Qiming Zhang",
      "Shanshan Zhao",
      "Zhe Chen",
      "Jing Zhang",
      "Dacheng Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28578": {
    "title": "Large Occluded Human Image Completion via Image-Prior Cooperating",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hengrun Zhao",
      "Yu Zeng",
      "Huchuan Lu",
      "Lijun Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28579": {
    "title": "Recognizing Ultra-High-Speed Moving Objects with Bio-Inspired Spike Camera",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junwei Zhao",
      "Shiliang Zhang",
      "Zhaofei Yu",
      "Tiejun Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28580": {
    "title": "Rethinking Two-Stage Referring Expression Comprehension: A Novel Grounding and Segmentation Method Modulated by Point",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peizhi Zhao",
      "Shiyi Zheng",
      "Wenye Zhao",
      "Dongsheng Xu",
      "Pijian Li",
      "Yi Cai",
      "Qingbao Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28581": {
    "title": "Optical Flow for Spike Camera with Hierarchical Spatial-Temporal Spike Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Zhao",
      "Ruiqin Xiong",
      "Jian Zhang",
      "Xinfeng Zhang",
      "Zhaofei Yu",
      "Tiejun Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28582": {
    "title": "Towards Fine-Grained HBOE with Rendered Orientation Set and Laplace Smoothing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruisi Zhao",
      "Mingming Li",
      "Zheng Yang",
      "Binbin Lin",
      "Xiaohui Zhong",
      "Xiaobo Ren",
      "Deng Cai",
      "Boxi Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28583": {
    "title": "No Head Left Behind – Multi-Head Alignment Distillation for Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyang Zhao",
      "Kunwar Yashraj Singh",
      "Srikar Appalaraju",
      "Peng Tang",
      "Vijay Mahadevan",
      "R. Manmatha",
      "Ying Nian Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28584": {
    "title": "SFC: Shared Feature Calibration in Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinqiao Zhao",
      "Feilong Tang",
      "Xiaoyang Wang",
      "Jimin Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28585": {
    "title": "Unifying Multi-Modal Uncertainty Modeling and Semantic Alignment for Text-to-Image Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwei Zhao",
      "Bin Liu",
      "Yan Lu",
      "Qi Chu",
      "Nenghai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28586": {
    "title": "Mining Gaze for Contrastive Learning toward Computer-Assisted Diagnosis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Zhao",
      "Sheng Wang",
      "Qian Wang",
      "Dinggang Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28587": {
    "title": "Quad Bayer Joint Demosaicing and Denoising Based on Dual Encoder Network with Joint Residual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bolun Zheng",
      "Haoran Li",
      "Quan Chen",
      "Tingyu Wang",
      "Xiaofei Zhou",
      "Zhenghui Hu",
      "Chenggang Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28588": {
    "title": "End-to-End RGB-D Image Compression via Exploiting Channel-Modality Redundancy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huiming Zheng",
      "Wei Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28589": {
    "title": "Any-Size-Diffusion: Toward Efficient Text-Driven Synthesis for Any-Size HD Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingping Zheng",
      "Yuanfan Guo",
      "Jiankang Deng",
      "Jianhua Han",
      "Ying Li",
      "Songcen Xu",
      "Hang Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28590": {
    "title": "Spatio-Temporal Fusion for Human Action Recognition via Joint Trajectory Graph",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaolin Zheng",
      "Hongbo Huang",
      "Xiuying Wang",
      "Xiaoxu Yan",
      "Longfei Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28591": {
    "title": "ODTrack: Online Dense Temporal Token Learning for Visual Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaozong Zheng",
      "Bineng Zhong",
      "Qihua Liang",
      "Zhiyi Mo",
      "Shengping Zhang",
      "Xianxian Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28592": {
    "title": "PVALane: Prior-Guided 3D Lane Detection with View-Agnostic Feature Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zewen Zheng",
      "Xuemin Zhang",
      "Yongqiang Mou",
      "Xiang Gao",
      "Chengxin Li",
      "Guoheng Huang",
      "Chi-Man Pun",
      "Xiaochen Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28593": {
    "title": "SpFormer: Spatio-Temporal Modeling for Scanpaths with Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenqi Zhong",
      "Linzhi Yu",
      "Chen Xia",
      "Junwei Han",
      "Dingwen Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28594": {
    "title": "ExpCLIP: Bridging Text and Facial Expressions via Semantic Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yicheng Zhong",
      "Huawei Wei",
      "Peiji Yang",
      "Zhisheng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28595": {
    "title": "Learning Image Demoiréing from Unpaired Real Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunshan Zhong",
      "Yuyao Zhou",
      "Yuxin Zhang",
      "Fei Chao",
      "Rongrong Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28596": {
    "title": "Lifting by Image – Leveraging Image Cues for Accurate 3D Human Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Zhou",
      "Jianqin Yin",
      "Peiyang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28597": {
    "title": "NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gengze Zhou",
      "Yicong Hong",
      "Qi Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28598": {
    "title": "Novel Class Discovery in Chest X-rays via Paired Images and Text",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaying Zhou",
      "Yang Liu",
      "Qingchao Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28599": {
    "title": "AMSP-UOD: When Vortex Convolution and Stochastic Perturbation Meet Underwater Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingchun Zhou",
      "Zongxin He",
      "Kin-Man Lam",
      "Yudong Wang",
      "Weishi Zhang",
      "Chunle Guo",
      "Chongyi Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28600": {
    "title": "SOGDet: Semantic-Occupancy Guided Multi-View 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiu Zhou",
      "Jinming Cao",
      "Hanchao Leng",
      "Yifang Yin",
      "Yu Kun",
      "Roger Zimmermann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28601": {
    "title": "Test-Time Adaptation via Style and Structure Guidance for Histological Image Registration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shenglong Zhou",
      "Zhiwei Xiong",
      "Feng Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28602": {
    "title": "Reducing Spatial Fitting Error in Distillation of Denoising Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengzhe Zhou",
      "Zejian Li",
      "Shengyuan Zhang",
      "Lefan Hou",
      "Changyuan Yang",
      "Guang Yang",
      "Zhiyuan Yang",
      "Lingyun Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28603": {
    "title": "SAMFlow: Eliminating Any Fragmentation in Optical Flow with Segment Anything Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shili Zhou",
      "Ruian He",
      "Weimin Tan",
      "Bo Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28604": {
    "title": "Efficient Lightweight Image Denoising with Triple Attention Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yubo Zhou",
      "Jin Lin",
      "Fangchen Ye",
      "Yanyun Qu",
      "Yuan Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28605": {
    "title": "Intentional Evolutionary Learning for Untrimmed Videos with Long Tail Distribution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxi Zhou",
      "Xiujie Wang",
      "Jianhua Zhang",
      "Jiajia Wang",
      "Jie Yu",
      "Hao Zhou",
      "Yi Gao",
      "Shengyong Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28606": {
    "title": "SasWOT: Real-Time Semantic Segmentation Architecture Search WithOut Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chendi Zhu",
      "Lujun Li",
      "Yuli Wu",
      "Zhengxing Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28607": {
    "title": "Enhance Sketch Recognition's Explainability via Semantic Component-Level Parsing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangming Zhu",
      "Siyuan Wang",
      "Tianci Wu",
      "Liang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28608": {
    "title": "Learning Discriminative Noise Guidance for Image Forgery Detection and Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaying Zhu",
      "Dong Li",
      "Xueyang Fu",
      "Gang Yang",
      "Jie Huang",
      "Aiping Liu",
      "Zheng-Jun Zha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28609": {
    "title": "Video Frame Prediction from a Single Image and Events",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juanjuan Zhu",
      "Zhexiong Wan",
      "Yuchao Dai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28610": {
    "title": "Finding Visual Saliency in Continuous Spike Stream",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lin Zhu",
      "Xianzhang Chen",
      "Xiao Wang",
      "Hua Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28611": {
    "title": "SEER: Backdoor Detection for Vision-Language Models through Searching Target Text and Image Trigger Jointly",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liuwan Zhu",
      "Rui Ning",
      "Jiang Li",
      "Chunsheng Xin",
      "Hongyi Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28612": {
    "title": "Text Image Inpainting via Global Structure-Guided Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shipeng Zhu",
      "Pengfei Fang",
      "Chenjie Zhu",
      "Zuoyan Zhao",
      "Qiang Xu",
      "Hui Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28613": {
    "title": "Rethinking Mesh Watermark: Towards Highly Robust and Adaptable Deep 3D Mesh Watermarking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyu Zhu",
      "Guanhui Ye",
      "Xiapu Luo",
      "Xuetao Wei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28614": {
    "title": "Boosting Few-Shot Learning via Attentive Feature Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyu Zhu",
      "Shuo Wang",
      "Jinda Lu",
      "Yanbin Hao",
      "Haifeng Liu",
      "Xiangnan He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28615": {
    "title": "Memory-Efficient Prompt Tuning for Incremental Histopathology Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Zhu",
      "Kang Li",
      "Lequan Yu",
      "Pheng Ann Heng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28616": {
    "title": "SPGroup3D: Superpoint Grouping Network for Indoor 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun Zhu",
      "Le Hui",
      "Yaqi Shen",
      "Jin Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28617": {
    "title": "SEIT: Structural Enhancement for Unsupervised Image Translation in Frequency Domain",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhifeng Zhu",
      "Yaochen Li",
      "Yifan Li",
      "Jinhuo Yang",
      "Peijun Chen",
      "Yuehu Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28618": {
    "title": "A Pre-convolved Representation for Plug-and-Play Neural Illumination Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyu Zhuang",
      "Qi Zhang",
      "Xuan Wang",
      "Hao Zhu",
      "Ying Feng",
      "Xiaoyu Li",
      "Ying Shan",
      "Xun Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28619": {
    "title": "IPRemover: A Generative Model Inversion Attack against Deep Neural Network Fingerprinting and Watermarking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Zong",
      "Yang-Wai Chow",
      "Willy Susilo",
      "Joonsang  Baek",
      "Jongkil Kim",
      "Seyit Camtepe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28620": {
    "title": "DiffBEV: Conditional Diffusion Model for Bird's Eye View Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayu Zou",
      "Kun Tian",
      "Zheng Zhu",
      "Yun Ye",
      "Xingang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28621": {
    "title": "Cross-Covariate Gait Recognition: A Benchmark",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shinan Zou",
      "Chao Fan",
      "Jianbo Xiong",
      "Chuanfu Shen",
      "Shiqi Yu",
      "Jin Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28622": {
    "title": "Towards Efficient Diffusion-Based Image Editing with Instant Attention Masks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyu Zou",
      "Jiji Tang",
      "Yiyi Zhou",
      "Jing He",
      "Chaoyi Zhao",
      "Rongsheng Zhang",
      "Zhipeng Hu",
      "Xiaoshuai Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28623": {
    "title": "VQCNIR: Clearer Night Image Restoration with Vector-Quantized Codebook",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenbin Zou",
      "Hongxia Gao",
      "Tian Ye",
      "Liang Chen",
      "Weipeng Yang",
      "Shasha Huang",
      "Hongsheng Chen",
      "Sixiang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28624": {
    "title": "Enhancing Neural Radiance Fields with Adaptive Multi-Exposure Fusion: A Bilevel Optimization Approach for Novel View Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Zou",
      "Xingyuan Li",
      "Zhiying Jiang",
      "Jinyuan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28625": {
    "title": "Improved MLP Point Cloud Processing with High-Dimensional Positional Encoding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanmei Zou",
      "Hongshan Yu",
      "Zhengeng Yang",
      "Zechuan Li",
      "Naveed Akhtar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28626": {
    "title": "Sparse3D: Distilling Multiview-Consistent Diffusion for Object Reconstruction from Sparse Views",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixin Zou",
      "Weihao Cheng",
      "Yan-Pei Cao",
      "Shi-Sheng Huang",
      "Ying Shan",
      "Song-Hai  Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28627": {
    "title": "CEDFlow: Latent Contour Enhancement for Dark Optical Flow Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengyuan Zuo",
      "Zhaolin Xiao",
      "Haiyan Jin",
      "Haonan Su"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28628": {
    "title": "Parameterization of (Partial) Maximum Satisfiability above Matching in a Variable-Clause Graph",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vasily Alferov",
      "Ivan Bliznets",
      "Kirill Brilliantov"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28629": {
    "title": "Approximation Scheme for Weighted Metric Clustering via Sherali-Adams",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dmitrii Avdiukhin",
      "Vaggos Chatziafratis",
      "Konstantin Makarychev",
      "Grigory Yaroslavtsev"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28630": {
    "title": "Neural Time-Reversed Generalized Riccati Equation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessandro Betti",
      "Michele Casoni",
      "Marco Gori",
      "Simone Marullo",
      "Stefano Melacci",
      "Matteo Tiezzi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28631": {
    "title": "Runtime vs. Extracted Proof Size: An Exponential Gap for CDCL on QBFs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Olaf Beyersdorff",
      "Benjamin Böhm",
      "Meena Mahajan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28632": {
    "title": "Testing Self-Reducible Samplers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rishiraj Bhattacharyya",
      "Sourav Chakraborty",
      "Yash Pote",
      "Uddalok Sarkar",
      "Sayantan Sen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28633": {
    "title": "Using Symmetries to Lift Satisfiability Checking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pierre Carbonnelle",
      "Gottfried Schenner",
      "Maurice Bruynooghe",
      "Bart Bogaerts",
      "Marc Denecker"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28634": {
    "title": "Robust Beamforming for Downlink Multi-Cell Systems: A Bilevel Optimization Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingdi Chen",
      "Yu Xiong",
      "Kai Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28635": {
    "title": "Hardness of Random Reordered Encodings of Parity for Resolution and CDCL",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leroy Chew",
      "Alexis de Colnet",
      "Friedrich Slivovsky",
      "Stefan Szeider"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28636": {
    "title": "Percentile Risk-Constrained Budget Pacing for Guaranteed Display Advertising in Online Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Dai",
      "Kejie Lyu",
      "Chengcheng Zhang",
      "Guangming Zhao",
      "Zhonglin Zu",
      "Liang Wang",
      "Bo Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28637": {
    "title": "Unifying Decision and Function Queries in Stochastic Boolean Satisfiability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-Wei Fan",
      "Jie-Hong R. Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28638": {
    "title": "Parallel Empirical Evaluations: Resilience despite Concurrency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johannes K. Fichte",
      "Tobias Geibinger",
      "Markus Hecher",
      "Matthias Schlögel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28639": {
    "title": "Locally Rainbow Paths",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Till Fluschnik",
      "Leon Kellerhals",
      "Malte Renken"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28640": {
    "title": "Approximate Integer Solution Counts over Linear Arithmetic Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cunjing Ge"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28641": {
    "title": "Composing Biases by Using CP to Decompose Minimal Functional Dependencies for Acquiring Complex Formulae",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ramiz Gindullin",
      "Nicolas Beldiceanu",
      "Jovial Cheukam-Ngouonou",
      "Rémi Douence",
      "Claude-Guy Quimper"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28642": {
    "title": "End-to-End Verification for Subgraph Solving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stephan Gocht",
      "Ciaran McCreesh",
      "Magnus O. Myreen",
      "Jakob Nordström",
      "Andy Oertel",
      "Yong Kiam Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28643": {
    "title": "SAT-Based Techniques for Lexicographically Smallest Finite Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mikoláš Janota",
      "Choiwah Chow",
      "João Araújo",
      "Michael Codish",
      "Petr Vojtěchovský"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28644": {
    "title": "Theoretical and Empirical Analysis of Cost-Function Merging for Implicit Hitting Set WCSP Solving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Javier Larrosa",
      "Conrado Martínez",
      "Emma Rollon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28645": {
    "title": "Automatic Core-Guided Reformulation via Constraint Explanation and Condition Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Leo",
      "Grame Gange",
      "Maria Garcia de la Banda",
      "Mark Wallace"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28646": {
    "title": "Learning to Pivot as a Smart Expert",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianhao Liu",
      "Shanwen Pu",
      "Dongdong Ge",
      "Yinyu Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28647": {
    "title": "Using Clustering to Strengthen Decision Diagram Bounds for Discrete Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohsen Nafar",
      "Michael Römer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28648": {
    "title": "On Partial Optimal Transport: Revising the Infeasibility of Sinkhorn and Efficient Gradient Methods",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anh Duc Nguyen",
      "Tuan Dung Nguyen",
      "Quang Minh Nguyen",
      "Hoang H. Nguyen",
      "Lam M. Nguyen",
      "Kim-Chuan Toh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28649": {
    "title": "An Eager Satisfiability Modulo Theories Solver for Algebraic Datatypes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amar Shah",
      "Federico Mora",
      "Sanjit A.  Seshia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28650": {
    "title": "An Approximate Skolem Function Counter",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arijit Shaw",
      "Brendan Juba",
      "Kuldeep S. Meel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28651": {
    "title": "Optimizing ADMM and Over-Relaxed ADMM Parameters for Linear Quadratic Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jintao Song",
      "Wenqi Lu",
      "Yunwen Lei",
      "Yuchao Tang",
      "Zhenkuan Pan",
      "Jinming Duan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28652": {
    "title": "Disjoint Partial Enumeration without Blocking Clauses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giuseppe Spallitta",
      "Roberto Sebastiani",
      "Armin Biere"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28653": {
    "title": "SAT-Based Algorithms for Regular Graph Pattern Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miguel Terra-Neves",
      "José Amaral",
      "Alexandre Lemos",
      "Rui Quintino",
      "Pedro Resende",
      "Antonio Alegria"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28654": {
    "title": "CEGAR-Based Approach for Solving Combinatorial Optimization Modulo Quantified Linear Arithmetics Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kerian Thuillier",
      "Anne Siegel",
      "Loïc Paulevé"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28655": {
    "title": "Learning to Learn in Interactive Constraint Acquisition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dimosthenis Tsouros",
      "Senne Berden",
      "Tias Guns"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28656": {
    "title": "GSO-Net: Grid Surface Optimization via Learning Geometric Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoyun Wang",
      "Jingmin Xin",
      "Nanning Zheng",
      "Caigui Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28657": {
    "title": "Encoding Constraints as Binary Constraint Networks Satisfying BTP",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiwei Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28658": {
    "title": "What Are the Rules? Discovering Constraints from Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boris Wiegand",
      "Dietrich  Klakow",
      "Jilles Vreeken"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28659": {
    "title": "SAT-Based Tree Decomposition with Iterative Cascading Policy Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Xia",
      "Stefan Szeider"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28660": {
    "title": "Engineering an Exact Pseudo-Boolean Model Counter",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suwei Yang",
      "Kuldeep S. Meel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28661": {
    "title": "A Reinforcement-Learning-Based Multiple-Column Selection Strategy for Column Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haofeng Yuan",
      "Lichang Fang",
      "Shiji Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28662": {
    "title": "Large-Scale Non-convex Stochastic Constrained Distributionally Robust Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Zhang",
      "Yi Zhou",
      "Ashley Prater-Bennette",
      "Lixin Shen",
      "Shaofeng Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28663": {
    "title": "Multimodal Graph Neural Architecture Search under Distribution Shifts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Cai",
      "Xin Wang",
      "Haoyang Li",
      "Ziwei Zhang",
      "Wenwu Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28664": {
    "title": "Make Lossy Compression Meaningful for Low-Light Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shilv Cai",
      "Liqun Chen",
      "Sheng Zhong",
      "Luxin Yan",
      "Jiahuan Zhou",
      "Xu Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28665": {
    "title": "RR-PU: A Synergistic Two-Stage Positive and Unlabeled Learning Framework for Robust Tax Evasion Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuzhi Cao",
      "Jianfei Ruan",
      "Bo Dong",
      "Bin Shi",
      "Qinghua Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28666": {
    "title": "Hierarchical and Incremental Structural Entropy Minimization for Unsupervised Social Event Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuwei Cao",
      "Hao Peng",
      "Zhengtao Yu",
      "Philip S. Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28667": {
    "title": "Distributional Off-Policy Evaluation for Slate Recommendations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shreyas Chaudhari",
      "David Arbour",
      "Georgios Theocharous",
      "Nikos Vlassis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28668": {
    "title": "Uncertainty-Aware Yield Prediction with Multimodal Molecular Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayuan Chen",
      "Kehan  Guo",
      "Zhen Liu",
      "Olexandr Isayev",
      "Xiangliang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28669": {
    "title": "Sparse Enhanced Network: An Adversarial Generation Method for Robust Augmentation in Sequential Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyang Chen",
      "Guoxuan Zou",
      "Pan Zhou",
      "Wu Yirui",
      "Zhenghan Chen",
      "Houcheng Su",
      "Huan Wang",
      "Zhiguo Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28670": {
    "title": "Signed Graph Neural Ordinary Differential Equation for Modeling Continuous-Time Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lanlan Chen",
      "Kai Wu",
      "Jian Lou",
      "Jing Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28671": {
    "title": "Deep Structural Knowledge Exploitation and Synergy for Estimating Node Importance Value on Heterogeneous Information Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yankai Chen",
      "Yixiang Fang",
      "Qiongyan Wang",
      "Xin Cao",
      "Irwin King"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28672": {
    "title": "KGTS: Contrastive Trajectory Similarity Learning over Prompt Knowledge Graph Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Chen",
      "Dalin Zhang",
      "Shanshan Feng",
      "Kaixuan Chen",
      "Lisi Chen",
      "Peng Han",
      "Shuo Shang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28673": {
    "title": "Learning to Reweight for Generalizable Graph Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengyu Chen",
      "Teng  Xiao",
      "Kun Kuang",
      "Zheqi Lv",
      "Min Zhang",
      "Jinluan Yang",
      "Chengqiang Lu",
      "Hongxia Yang",
      "Fei Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28674": {
    "title": "Effective Comparative Prototype Hashing for Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hui Cui",
      "Lihai Zhao",
      "Fengling Li",
      "Lei Zhu",
      "Xiaohui Han",
      "Jingjing Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28675": {
    "title": "Modeling Knowledge Graphs with Composite Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wanyun Cui",
      "Linqiu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28676": {
    "title": "Discovering Sequential Patterns with Predictable Inter-event Delays",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joscha Cüppers",
      "Paul Krieger",
      "Jilles Vreeken"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28677": {
    "title": "Unveiling Implicit Deceptive Patterns in Multi-Modal Fake News via Neuro-Symbolic Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiqi Dong",
      "Dongxiao He",
      "Xiaobao Wang",
      "Youzhu Jin",
      "Meng Ge",
      "Carl Yang",
      "Di Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28678": {
    "title": "Enhancing Job Recommendation through LLM-Based Generative Adversarial Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingpeng Du",
      "Di Luo",
      "Rui Yan",
      "Xiaopei Wang",
      "Hongzhi Liu",
      "Hengshu Zhu",
      "Yang Song",
      "Jie Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28679": {
    "title": "Structural Entropy Based Graph Structure Learning for Node Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Duan",
      "Xiang Chen",
      "Wenjie Liu",
      "Daliang Liu",
      "Kun Yue",
      "Angsheng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28680": {
    "title": "Progressive Distillation Based on Masked Generation Feature Method for Knowledge Graph Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cunhang Fan",
      "Yujie Chen",
      "Jun Xue",
      "Yonghui Kong",
      "Jianhua Tao",
      "Zhao Lv"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28681": {
    "title": "StockMixer: A Simple Yet Strong MLP-Based Architecture for Stock Price Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyong Fan",
      "Yanyan Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28682": {
    "title": "Dense Projection for Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dazhi Fu",
      "Zhao Zhang",
      "Jicong Fan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28683": {
    "title": "Knowledge-Enhanced Historical Document Segmentation and Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "En-Hao Gao",
      "Yu-Xuan Huang",
      "Wen-Chao Hu",
      "Xin-Hao Zhu",
      "Wang-Zhou Dai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28684": {
    "title": "Zero-1-to-3: Domain-Level Zero-Shot Cognitive Diagnosis via One Batch of Early-Bird Students towards Three Diagnostic Objectives",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weibo Gao",
      "Qi Liu",
      "Hao Wang",
      "Linan Yue",
      "Haoyang Bi",
      "Yin Gu",
      "Fangzhou Yao",
      "Zheng Zhang",
      "Xin Li",
      "Yuanjing He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28685": {
    "title": "Your Career Path Matters in Person-Job Fit",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuocheng Gong",
      "Yang Song",
      "Tao Zhang",
      "Ji-Rong Wen",
      "Dongyan Zhao",
      "Rui Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28686": {
    "title": "Efficient Representation Learning of Satellite Image Time Series and Their Fusion for Spatiotemporal Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Poonam Goyal",
      "Arshveer Kaur",
      "Arvind Ram",
      "Navneet Goyal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28687": {
    "title": "Rethinking Reverse Distillation for Multi-Modal Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihao Gu",
      "Jiangning Zhang",
      "Liang Liu",
      "Xu Chen",
      "Jinlong Peng",
      "Zhenye Gan",
      "Guannan Jiang",
      "Annan Shu",
      "Yabiao Wang",
      "Lizhuang Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28688": {
    "title": "LGMRec: Local and Global Graph Learning for Multimodal Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiqiang Guo",
      "Jianjun Li",
      "Guohui Li",
      "Chaoyang Wang",
      "Si Shi",
      "Bin Ruan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28689": {
    "title": "Intra- and Inter-group Optimal Transport for User-Oriented Fairness in Recommender Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongxuan Han",
      "Chaochao Chen",
      "Xiaolin Zheng",
      "Meng Li",
      "Weiming Liu",
      "Binhui Yao",
      "Yuyuan Li",
      "Jianwei Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28690": {
    "title": "A Diffusion-Based Framework for Multi-Class Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyang He",
      "Jiangning Zhang",
      "Hongxu Chen",
      "Xuhai Chen",
      "Zhishan Li",
      "Xu Chen",
      "Yabiao Wang",
      "Chengjie Wang",
      "Lei Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28691": {
    "title": "ADA-GAD: Anomaly-Denoised Autoencoders for Graph Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junwei He",
      "Qianqian Xu",
      "Yangbangyan Jiang",
      "Zitai Wang",
      "Qingming Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28692": {
    "title": "ViSTec: Video Modeling for Sports Technique Recognition and Tactical Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchen He",
      "Zeqing Yuan",
      "Yihong Wu",
      "Liqi Cheng",
      "Dazhen Deng",
      "Yingcai Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28693": {
    "title": "Label Attentive Distillation for GNN-Based Graph Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaobin Hong",
      "Wenzhong Li",
      "Chaoqun Wang",
      "Mingkai Lin",
      "Sanglu Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28694": {
    "title": "DAG-Aware Variational Autoencoder for Social Propagation Graph Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongpeng Hou",
      "Chao Gao",
      "Xuelong Li",
      "Zhen Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28695": {
    "title": "Social-Aware Group Display Configuration in VR Conference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bay-Yuan Hsu",
      "Chih-Ya Shen",
      "Hao Shan Yuan",
      "Wang-Chien  Lee",
      "De-Nian Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28696": {
    "title": "AnomalyDiffusion: Few-Shot Anomaly Image Generation with Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Teng Hu",
      "Jiangning Zhang",
      "Ran Yi",
      "Yuzhen Du",
      "Xu Chen",
      "Liang Liu",
      "Yabiao Wang",
      "Chengjie Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28697": {
    "title": "Learning Time Slot Preferences via Mobility Tree for Next POI Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianhao Huang",
      "Xuan Pan",
      "Xiangrui Cai",
      "Ying Zhang",
      "Xiaojie Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28698": {
    "title": "ReGCL: Rethinking Message Passing in Graph Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Ji",
      "Zixuan Huang",
      "Qingyun Sun",
      "Hao Peng",
      "Xingcheng Fu",
      "Qian Li",
      "Jianxin Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28699": {
    "title": "D3: A Methodological Exploration of Domain Division, Modeling, and Balance in Multi-Domain Recommendations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengyue Jia",
      "Yichao Wang",
      "Shanru Lin",
      "Xiaopeng Li",
      "Xiangyu Zhao",
      "Huifeng Guo",
      "Ruiming Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28700": {
    "title": "Graph Invariant Learning with Subgraph Co-mixup for Out-of-Distribution Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianrui Jia",
      "Haoyang Li",
      "Cheng Yang",
      "Tao Tao",
      "Chuan Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28701": {
    "title": "Enhancing Multi-Scale Diffusion Prediction via Sequential Hypergraphs and Adversarial Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengfei Jiao",
      "Hongqian Chen",
      "Qing Bao",
      "Wang Zhang",
      "Huaming Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28702": {
    "title": "Multi-Domain Recommendation to Attract Users via Domain Preference Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunjun Ju",
      "SeongKu Kang",
      "Dongha Lee",
      "Junyoung Hwang",
      "Sanghwan Jang",
      "Hwanjo Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28703": {
    "title": "Few Shot Part Segmentation Reveals Compositional Logic for Industrial Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soopil Kim",
      "Sion An",
      "Philip Chikontwe",
      "Myeongkyun Kang",
      "Ehsan Adeli",
      "Kilian M. Pohl",
      "Sang Hyun Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28704": {
    "title": "VITA: ‘Carefully Chosen and Weighted Less' Is Better in Medication Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taeri Kim",
      "Jiho Heo",
      "Hongil Kim",
      "Kijung Shin",
      "Sang-Wook Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28705": {
    "title": "Optimal Quasi-clique: Hardness, Equivalence with Densest-k-Subgraph, and Quasi-partitioned Community Mining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aritra Konar",
      "Nicholas D. Sidiropoulos"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28706": {
    "title": "Learning Persistent Community Structures in Dynamic Networks via Topological Data Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dexu  Kong",
      "Anping Zhang",
      "Yang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28707": {
    "title": "Spatio-Temporal Pivotal Graph Neural Networks for Traffic Flow Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiyang Kong",
      "Ziyu Guo",
      "Yubao Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28708": {
    "title": "Knowledge-Aware Explainable Reciprocal Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai-Huang Lai",
      "Zhe-Rui Yang",
      "Pei-Yuan Lai",
      "Chang-Dong Wang",
      "Mohsen  Guizani ",
      "Min Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28709": {
    "title": "Adaptive Hardness Negative Sampling for Collaborative Filtering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Riwei Lai",
      "Rui Chen",
      "Qilong Han",
      "Chi Zhang",
      "Li Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28710": {
    "title": "MDFL: Multi-Domain Diffusion-Driven Feature Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daixun Li",
      "Weiying Xie",
      "Jiaqing Zhang",
      "Yunsong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28711": {
    "title": "CoreRec: A Counterfactual Correlation Inference for Next Set Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kexin Li",
      "Chengjiang Long",
      "Shengyu Zhang",
      "Xudong Tang",
      "Zhichao Zhai",
      "Kun Kuang",
      "Jun Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28712": {
    "title": "Ada-Retrieval: An Adaptive Multi-Round Retrieval Paradigm for Sequential Recommendations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Li",
      "Jianxun Lian",
      "Xiao Zhou",
      "Xing Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28713": {
    "title": "CONSIDER: Commonalities and Specialties Driven Multilingual Code Retrieval Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Li",
      "Liyang He",
      "Qi Liu",
      "Yuze Zhao",
      "Zheng Zhang",
      "Zhenya Huang",
      "Yu Su",
      "Shijin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28714": {
    "title": "UniGen: A Unified Generative Framework for Retrieval and Question Answering with Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoxi Li",
      "Yujia Zhou",
      "Zhicheng Dou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28715": {
    "title": "MESED: A Multi-Modal Entity Set Expansion Dataset with Fine-Grained Semantic Classes and Hard Negative Entities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangning Li",
      "Tingwei Lu",
      "Hai-Tao Zheng",
      "Yinghui Li",
      "Shulin Huang",
      "Tianyu Yu",
      "Jun Yuan",
      "Rui Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28716": {
    "title": "A Generalized Neural Diffusion Framework on Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yibo Li",
      "Xiao Wang",
      "Hongrui Liu",
      "Chuan Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28717": {
    "title": "Learning to Rank in Generative Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongqi Li",
      "Nan Yang",
      "Liang Wang",
      "Furu Wei",
      "Wenjie Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28718": {
    "title": "Urban Region Embedding via Multi-View Contrastive Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zechen Li",
      "Weiming Huang",
      "Kai Zhao",
      "Min Yang",
      "Yongshun Gong",
      "Meng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28719": {
    "title": "Hawkes-Enhanced Spatial-Temporal Hypergraph Contrastive Learning Based on Criminal Correlations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Liang",
      "Sihang Zhou",
      "Meng Liu",
      "Yue Liu",
      "Wenxuan Tu",
      "Yi Zhang",
      "Liming Fang",
      "Zhe Liu",
      "Xinwang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28720": {
    "title": "A Comprehensive Augmentation Framework for Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiang Lin",
      "Yaping Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28721": {
    "title": "Temporally and Distributionally Robust Optimization for Cold-Start Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Lin",
      "Wenjie Wang",
      "Jujia Zhao",
      "Yongqi Li",
      "Fuli Feng",
      "Tat-Seng Chua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28722": {
    "title": "Towards Continual Knowledge Graph Embedding via Incremental Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiajun Liu",
      "Wenjun Ke",
      "Peng Wang",
      "Ziyu Shang",
      "Jinhua Gao",
      "Guozheng Li",
      "Ke Ji",
      "Yanhe Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28723": {
    "title": "Graph Disentangled Contrastive Learning with Personalized Transfer for Cross-Domain Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Liu",
      "Lele Sun",
      "Weizhi Nie",
      "Peiguang Jing",
      "Yuting Su"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28724": {
    "title": "Multimodal Event Causality Reasoning with Scene Graph Enhanced Interaction Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jintao Liu",
      "Kaiwen Wei",
      "Chenglong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28725": {
    "title": "AT4CTR: Auxiliary Match Tasks for Enhancing Click-Through Rate Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Liu",
      "Xuyang Hou",
      "Defu Lian",
      "Zhe Wang",
      "Haoran Jin",
      "Jia Cheng",
      "Jun Lei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28726": {
    "title": "Online Conversion Rate Prediction via Multi-Interval Screening and Synthesizing under Delayed Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiming Liu",
      "Xiang Ao",
      "Yuyao Guo",
      "Qing He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28727": {
    "title": "KG-TREAT: Pre-training for Treatment Effect Estimation by Synergizing Patient Data with Knowledge Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruoqi Liu",
      "Lingfei Wu",
      "Ping Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28728": {
    "title": "Learning Accurate and Bidirectional Transformation via Dynamic Embedding Transportation for Cross-Domain Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiming Liu",
      "Chaochao Chen",
      "Xinting Liao",
      "Mengling Hu",
      "Yanchao Tan",
      "Fan Wang",
      "Xiaolin Zheng",
      "Yew Soon Ong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28729": {
    "title": "Knowledge Graph Error Detection with Contrastive Confidence Adaption",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyu Liu",
      "Yang Liu",
      "Wei Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28730": {
    "title": "Perturbation-Invariant Adversarial Training for Neural Ranking Models: Improving the Effectiveness-Robustness Trade-Off",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-An Liu",
      "Ruqing Zhang",
      "Mingkun Zhang",
      "Wei Chen",
      "Maarten de Rijke",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28731": {
    "title": "Full Bayesian Significance Testing for Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zehua Liu",
      "Zimeng Li",
      "Jingyuan Wang",
      "Yue He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28732": {
    "title": "KGDM: A Diffusion Model to Capture Multiple Relation Semantics for Knowledge Graph Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Long",
      "Liansheng Zhuang",
      "Aodi Li",
      "Jiuchang Wei",
      "Houqiang Li",
      "Shafei Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28733": {
    "title": "Deep Hierarchical Video Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Lu",
      "Zhihao Duan",
      "Fengqing Zhu",
      "Zhan Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28734": {
    "title": "Spectral-Based Graph Neural Networks for Complementary Item Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haitong Luo",
      "Xuying Meng",
      "Suhang Wang",
      "Hanyun Cao",
      "Weiyao Zhang",
      "Yequan Wang",
      "Yujun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28735": {
    "title": "Enhancing Cognitive Diagnosis Using Un-interacted Exercises: A Collaboration-Aware Mixed Sampling Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiping Ma",
      "Changqian Wang",
      "Hengshu Zhu",
      "Shangshang Yang",
      "Xiaoming Zhang",
      "Xingyi Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28736": {
    "title": "Plug-In Diffusion Model for Sequential Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haokai Ma",
      "Ruobing Xie",
      "Lei Meng",
      "Xin Chen",
      "Xu Zhang",
      "Leyu Lin",
      "Zhanhui Kang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28737": {
    "title": "Tail-STEAK: Improve Friend Recommendation for Tail Users via Self-Training Enhanced Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijun Ma",
      "Chaozhuo Li",
      "Xiao Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28738": {
    "title": "Graph Contrastive Invariant Learning from the Causal Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanhu Mo",
      "Xiao Wang",
      "Shaohua Fan",
      "Chuan Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28739": {
    "title": "HGE: Embedding Temporal Knowledge Graphs in a Product Space of Heterogeneous Geometric Subspaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxin Pan",
      "Mojtaba Nayyeri",
      "Yinan Li",
      "Steffen Staab"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28740": {
    "title": "Cross-Domain Contrastive Learning for Time Series Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Furong Peng",
      "Jiachen Luo",
      "Xuan Lu",
      "Sheng Wang",
      "Feijiang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28741": {
    "title": "Refining Latent Homophilic Structures over Heterophilic Graphs for Robust Graph Convolution Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyang Qiu",
      "Guoshun Nan",
      "Tianyu Xiong",
      "Wendi Deng",
      "Di Wang",
      "Zhiyang Teng",
      "Lijuan Sun",
      "Qimei Cui",
      "Xiaofeng Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28742": {
    "title": "Link Prediction in Multilayer Networks via Cross-Network Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guojing Ren",
      "Xiao Ding",
      "Xiao-Ke Xu",
      "Hai-Feng Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28743": {
    "title": "Towards Diverse Perspective Learning with Selection over Multiple Temporal Poolings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihyeon Seong",
      "Jungmin Kim",
      "Jaesik Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28744": {
    "title": "LAFA: Multimodal Knowledge Graph Completion with Link Aware Fusion and Aggregation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Shang",
      "Yinliang Zhao",
      "Jun Liu",
      "Di Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28745": {
    "title": "Mixed Geometry Message and Trainable Convolutional Attention Network for Knowledge Graph Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Shang",
      "Yinliang Zhao",
      "Jun Liu",
      "Di Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28746": {
    "title": "ResDiff: Combining CNN and Diffusion Model for Image Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuyao Shang",
      "Zhengyang Shan",
      "Guangxing Liu",
      "LunQian Wang",
      "XingHua Wang",
      "Zekai Zhang",
      "Jinglin Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28747": {
    "title": "An Attentive Inductive Bias for Sequential Recommendation beyond the Self-Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yehjin Shin",
      "Jeongwhan Choi",
      "Hyowon Wi",
      "Noseong Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28748": {
    "title": "A Diffusion-Based Pre-training Framework for Crystal Property Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixing Song",
      "Ziqiao Meng",
      "Irwin King"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28749": {
    "title": "STEM: Unleashing the Power of Embeddings for Multi-Task Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liangcai Su",
      "Junwei Pan",
      "Ximei Wang",
      "Xi Xiao",
      "Shijie Quan",
      "Xihua Chen",
      "Jie Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28750": {
    "title": "Anchoring Path for Inductive Relation Prediction in Knowledge Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixiang Su",
      "Di Wang",
      "Chunyan Miao",
      "Lizhen Cui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28751": {
    "title": "MAPTree: Beating \"Optimal\" Decision Trees with Bayesian Decision Trees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Colin Sullivan",
      "Mo Tiwari",
      "Sebastian Thrun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28752": {
    "title": "CREAD: A Classification-Restoration Framework with Error Adaptive Discretization for Watch Time Prediction in Video Recommender Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Sun",
      "Zhaoying Ding",
      "Xiaoshuang Chen",
      "Qi Chen",
      "Yincheng Wang",
      "Kaiqiao Zhan",
      "Ben Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28753": {
    "title": "ModWaveMLP: MLP-Based Mode Decomposition and Wavelet Denoising Model to Defeat Complex Structures in Traffic Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Sun",
      "Pei Liu",
      "Pengfei Li",
      "Zhifang  Liao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28754": {
    "title": "Motif-Aware Riemannian Graph Neural Network with Generative-Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Sun",
      "Zhenhao Huang",
      "Zixi Wang",
      "Feiyang Wang",
      "Hao Peng",
      "Philip S. Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28755": {
    "title": "Fine-Tuning Graph Neural Networks by Preserving Graph Generative Patterns",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Sun",
      "Qi Zhu",
      "Yang Yang",
      "Chunping Wang",
      "Tianyu Fan",
      "Jiajun Zhu",
      "Lei Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28756": {
    "title": "Finding Interpretable Class-Specific Patterns through Efficient Neural Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nils Philipp Walter",
      "Jonas Fischer",
      "Jilles Vreeken"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28757": {
    "title": "End-to-End Learning of LTLf Formulae by Faithful LTLf Encoding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Wan",
      "Pingjia Liang",
      "Jianfeng Du",
      "Weilin Luo",
      "Rongzhen Ye",
      "Bo Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28758": {
    "title": "Contributing Dimension Structure of Deep Feature for Coreset Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhijing Wan",
      "Zhixiang Wang",
      "Yuran Wang",
      "Zheng Wang",
      "Hongyuan Zhu",
      "Shin'ichi Satoh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28759": {
    "title": "Towards Dynamic Spatial-Temporal Graph Learning: A Decoupled Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Binwu Wang",
      "Pengkun Wang",
      "Yudong Zhang",
      "Xu Wang",
      "Zhengyang Zhou",
      "Lei Bai",
      "Yang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28760": {
    "title": "EnMatch: Matchmaking for Better Player Engagement via Neural Combinatorial Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Wang",
      "Haoyu Liu",
      "Zhipeng Hu",
      "Xiaochuan Feng",
      "Minghao Zhao",
      "Shiwei Zhao",
      "Runze Wu",
      "Xudong Shen",
      "Tangjie Lv",
      "Changjie Fan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28761": {
    "title": "Review-Enhanced Hierarchical Contrastive Learning for Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Wang",
      "Yanmin Zhu",
      "Tianzi Zang",
      "Chunyang Wang",
      "Mengyuan Jing"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28762": {
    "title": "Pseudo-Label Calibration Semi-supervised Multi-Modal Entity Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luyao Wang",
      "Pengnian Qi",
      "Xigang Bao",
      "Chunlai Zhou",
      "Biao Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28763": {
    "title": "Preference Aware Dual Contrastive Learning for Item Cold-Start Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenbo Wang",
      "Bingquan Liu",
      "Lili Shan",
      "Chengjie Sun",
      "Ben Chen",
      "Jian Guan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28764": {
    "title": "Deciphering Compatibility Relationships with Textual Descriptions via Extraction and Explanation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Wang",
      "Zexue He",
      "Zhankui He",
      "Hao Xu",
      "Julian McAuley"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28765": {
    "title": "Open-Set Graph Domain Adaptation via Separate Domain Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Wang",
      "Ronghang Zhu",
      "Pengsheng Ji",
      "Sheng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28766": {
    "title": "G^2SAM: Graph-Based Global Semantic Awareness Method for Multimodal Sarcasm Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwei Wei",
      "Shaozu Yuan",
      "Hengyang Zhou",
      "Longbiao Wang",
      "Zhiling Yan",
      "Ruosong Yang",
      "Meng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28767": {
    "title": "Poincaré Differential Privacy for Hierarchy-Aware Graph Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuecen Wei",
      "Haonan Yuan",
      "Xingcheng Fu",
      "Qingyun Sun",
      "Hao Peng",
      "Xianxian Li",
      "Chunming Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28768": {
    "title": "Pairwise-Label-Based Deep Incremental Hashing with Simultaneous Code Expansion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dayan Wu",
      "Qinghang Su",
      "Bo Li",
      "Weiping Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28769": {
    "title": "Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Likang Wu",
      "Zhaopeng Qiu",
      "Zhi Zheng",
      "Hengshu Zhu",
      "Enhong Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28770": {
    "title": "CI-STHPAN: Pre-trained Attention Network for Stock Selection with Channel-Independent Spatio-Temporal Hypergraph",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongjie Xia",
      "Huijie Ao",
      "Long Li",
      "Yu Liu",
      "Sen Liu",
      "Guangnan Ye",
      "Hongfeng Chai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28771": {
    "title": "Feature Distribution Matching by Optimal Transport for Effective and Robust Coreset Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiwei Xiao",
      "Yongyong Chen",
      "Qiben Shan",
      "Yaowei Wang",
      "Jingyong Su"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28772": {
    "title": "NestE: Modeling Nested Relational Structures for Knowledge Graph Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Xiong",
      "Mojtaba Nayyeri",
      "Linhao Luo",
      "Zihao Wang",
      "Shirui Pan",
      "Steffen Staab"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28773": {
    "title": "Revisiting Graph-Based Fraud Detection in Sight of Heterophily and Spectrum",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Xu",
      "Nan Wang",
      "Hao Wu",
      "Xuezhi Wen",
      "Xibin Zhao",
      "Hai Wan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28774": {
    "title": "Empowering Dual-Level Graph Self-Supervised Pretraining with Motif Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengwei Yan",
      "Kaisong Song",
      "Zhuoren Jiang",
      "Yangyang Kang",
      "Tianqianjin Lin",
      "Changlong Sun",
      "Xiaozhong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28775": {
    "title": "Hypergraph Joint Representation Learning for Hypervertices and Hyperedges via Cross Expansion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuguang Yan",
      "Yuanlin Chen",
      "Shibo Wang",
      "Hanrui Wu",
      "Ruichu Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28776": {
    "title": "FairSIN: Achieving Fairness in Graph Neural Networks through Sensitive Information Neutralization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Yang",
      "Jixi Liu",
      "Yunhe Yan",
      "Chuan Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28777": {
    "title": "Fine-Tuning Large Language Model Based Explainable Recommendation with Explainable Quality Reward",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengyuan Yang",
      "Mengying Zhu",
      "Yan Wang",
      "Linxun Chen",
      "Yilei Zhao",
      "Xiuyuan Wang",
      "Bing Han",
      "Xiaolin Zheng",
      "Jianwei Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28778": {
    "title": "Graph Neural Networks with Soft Association between Topology and Attribute",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yachao Yang",
      "Yanfeng Sun",
      "Shaofan Wang",
      "Jipeng Guo",
      "Junbin Gao",
      "Fujiao Ju",
      "Baocai  Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28779": {
    "title": "TriSampler: A Better Negative Sampling Principle for Dense Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Yang",
      "Zhou Shao",
      "Yuxiao Dong",
      "Jie Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28780": {
    "title": "Parallel Ranking of Ads and Creatives in Real-Time Advertising Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiguang Yang",
      "Liufang Sang",
      "Haoran Wang",
      "Wenlong Chen",
      "Lu Wang",
      "Jie He",
      "Changping Peng",
      "Zhangang Lin",
      "Chun Gan",
      "Jingping Shao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28781": {
    "title": "WaveNet: Tackling Non-stationary Graph Signals via Graph Spectral Wavelets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhirui Yang",
      "Yulan Hu",
      "Sheng Ouyang",
      "Jingyu Liu",
      "Shuqiang Wang",
      "Xibo Ma",
      "Wenhan Wang",
      "Hanjing Su",
      "Yong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28782": {
    "title": "RRL: Recommendation Reverse Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyu You",
      "Jianwei Xu",
      "Mi Zhang",
      "Zechen Gao",
      "Min Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28783": {
    "title": "UNEX-RL: Reinforcing Long-Term Rewards in Multi-Stage Recommender Systems with UNidirectional EXecution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gengrui Zhang",
      "Yao Wang",
      "Xiaoshuang Chen",
      "Hongyi Qian",
      "Kaiqiao Zhan",
      "Ben Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28784": {
    "title": "M3D: Dataset Condensation by Minimizing Maximum Mean Discrepancy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hansong Zhang",
      "Shikun Li",
      "Pengju Wang",
      "Dan Zeng",
      "Shiming Ge"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28785": {
    "title": "DiG-In-GNN: Discriminative Feature Guided GNN-Based Fraud Detector against Inconsistencies in Multi-Relation Fraud Graph",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinghui Zhang",
      "Zhengjia Xu",
      "Dingyang Lv",
      "Zhan Shi",
      "Dian Shen",
      "Jiahui Jin",
      "Fang Dong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28786": {
    "title": "Dual-View Whitening on Pre-trained Text Embeddings for Sequential Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingzi Zhang",
      "Xin Zhou",
      "Zhiwei Zeng",
      "Zhiqi Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28787": {
    "title": "CAMEL: Capturing Metaphorical Alignment with Context Disentangling for Multimodal Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linhao Zhang",
      "Li Jin",
      "Guangluan Xu",
      "Xiaoyu Li",
      "Cai Xu",
      "Kaiwen Wei",
      "Nayu Liu",
      "Haonan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28788": {
    "title": "ROG_PL: Robust Open-Set Graph Learning via Region-Based Prototype Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qin Zhang",
      "Xiaowei Li",
      "Jiexin Lu",
      "Liping Qiu",
      "Shirui Pan",
      "Xiaojun Chen",
      "Junyang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28789": {
    "title": "Temporal Graph Contrastive Learning for Sequential Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengzhe Zhang",
      "Liyi Chen",
      "Chao Wang",
      "Shuangli Li",
      "Hui Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28790": {
    "title": "Influential Exemplar Replay for Incremental Learning in Recommender Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinni Zhang",
      "Yankai Chen",
      "Chenhao Ma",
      "Yixiang Fang",
      "Irwin King"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28791": {
    "title": "Another Way to the Top: Exploit Contextual Clustering in Learned Image Coding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichi Zhang",
      "Zhihao Duan",
      "Ming Lu",
      "Dandan Ding",
      "Fengqing Zhu",
      "Zhan Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28792": {
    "title": "Multi-Domain Deep Learning from a Multi-View Perspective for Cross-Border E-commerce Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiqian Zhang",
      "Yinfu Feng",
      "Wen-Ji Zhou",
      "Yunan Ye",
      "Min Tan",
      "Rong Xiao",
      "Haihong Tang",
      "Jiajun Ding",
      "Jun Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28793": {
    "title": "Spatial-Temporal Interplay in Human Mobility: A Hierarchical Reinforcement Learning Approach with Hypergraph Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaofan Zhang",
      "Yanan Xiao",
      "Lu Jiang",
      "Dingqi Yang",
      "Minghao Yin",
      "Pengyang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28794": {
    "title": "FacetCRS: Multi-Faceted Preference Learning for Pricking Filter Bubbles in Conversational Recommender System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongsen Zheng",
      "Ziliang Chen",
      "Jinghui Qin",
      "Liang Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28795": {
    "title": "GMP-AR: Granularity Message Passing and Adaptive Reconciliation for Temporal Hierarchy Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Zhou",
      "Chen Pan",
      "Lintao Ma",
      "Yu Liu",
      "Siqiao Xue",
      "James Zhang",
      "Jun Zhou",
      "Hongyuan Mei",
      "Weitao Lin",
      "Zi Zhuang",
      "Wenxin Ning",
      "Yunhua Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28796": {
    "title": "Explainable Origin-Destination Crowd Flow Interpolation via Variational Multi-Modal Recurrent Graph Auto-Encoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiang Zhou",
      "Xinjiang Lu",
      "Jingjing Gu",
      "Zhe Zheng",
      "Bo Jin",
      "Jingbo Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28797": {
    "title": "An Efficient Subgraph-Inferring Framework for Large-Scale Heterogeneous Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Zhou",
      "Hong Huang",
      "Ruize Shi",
      "Kehan Yin",
      "Hai Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28894": {
    "title": "Optimal Makespan in a Minute Timespan! A Scalable Multi-Robot Goal Assignment Algorithm for Minimizing Mission Time",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aakash  ",
      "Indranil Saha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28895": {
    "title": "On Computing Makespan-Optimal Solutions for Generalized Sliding-Tile Puzzles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcus Gozon",
      "Jingjin Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28896": {
    "title": "Interactive Visual Task Learning for Robots",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiwei Gu",
      "Anant Sah",
      "Nakul Gopalan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28897": {
    "title": "DexFuncGrasp: A Robotic Dexterous Functional Grasp Dataset Constructed from a Cost-Effective Real-Simulation Annotation System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinglue Hang",
      "Xiangbo Lin",
      "Tianqiang Zhu",
      "Xuanheng Li",
      "Rina Wu",
      "Xiaohong Ma",
      "Yi Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28898": {
    "title": "LINGO-Space: Language-Conditioned Incremental Grounding for Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dohyun Kim",
      "Nayoung Oh",
      "Deokmin Hwang",
      "Daehyung Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28899": {
    "title": "CTO-SLAM: Contour Tracking for Object-Level Robust 4D SLAM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohan Li",
      "Dong Liu",
      "Jun Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28900": {
    "title": "BAT: Behavior-Aware Human-Like Trajectory Prediction for Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haicheng Liao",
      "Zhenning Li",
      "Huanming Shen",
      "Wenxuan Zeng",
      "Dongping Liao",
      "Guofa Li",
      "Chengzhong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28901": {
    "title": "Deep Homography Estimation for Visual Place Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Lu",
      "Shuting Dong",
      "Lijun Zhang",
      "Bingxi Liu",
      "Xiangyuan Lan",
      "Dongmei Jiang",
      "Chun Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28902": {
    "title": "Task Planning for Object Rearrangement in Multi-Room Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Karan Mirakhor",
      "Sourav Ghosh",
      "Dipanjan Das",
      "Brojeshwar Bhowmick"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28903": {
    "title": "Hierarchical Planning and Learning for Robots in Stochastic Settings Using Zero-Shot Option Invention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naman Shah",
      "Siddharth Srivastava"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28904": {
    "title": "MorphVAE: Advancing Morphological Design of Voxel-Based Soft Robots with Variational Autoencoders",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junru Song",
      "Yang Yang",
      "Wei Peng",
      "Weien Zhou",
      "Feifei Wang",
      "Wen Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28905": {
    "title": "DistilVPR: Cross-Modal Knowledge Distillation for Visual Place Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sijie Wang",
      "Rui She",
      "Qiyu Kang",
      "Xingchao Jian",
      "Kai Zhao",
      "Yang Song",
      "Wee Peng Tay"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28906": {
    "title": "Angle Robustness Unmanned Aerial Vehicle Navigation in GNSS-Denied Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Wang",
      "Zunlei Feng",
      "Haofei Zhang",
      "Yang Gao",
      "Jie Lei",
      "Li Sun",
      "Mingli Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28907": {
    "title": "Learning from Ambiguous Demonstrations with Self-Explanation Guided Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yantian Zha",
      "Lin Guan",
      "Subbarao Kambhampati"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28908": {
    "title": "Multi-Constellation-Inspired Single-Shot Global LiDAR Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tongzhou Zhang",
      "Gang Wang",
      "Yu Chen",
      "Hai Zhang",
      "Jue Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28909": {
    "title": "DeepPointMap: Advancing LiDAR SLAM with Unified Neural Descriptors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaze Zhang",
      "Ziheng Ding",
      "Qi Jing",
      "Yuejie Zhang",
      "Wenchao Ding",
      "Rui Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28798": {
    "title": "Analytically Tractable Models for Decision Making under Present Bias",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yasunori Akagi",
      "Naoki Marumo",
      "Takeshi Kurashima"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28799": {
    "title": "Optimistic Policy Gradient in Multi-Player Markov Games with a Single Controller: Convergence beyond the Minty Property",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ioannis Anagnostides",
      "Ioannis Panageas",
      "Gabriele Farina",
      "Tuomas Sandholm"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28800": {
    "title": "Improved Metric Distortion via Threshold Approvals",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elliot Anshelevich",
      "Aris Filos-Ratsikas",
      "Christopher Jerrett",
      "Alexandros A. Voudouris"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28801": {
    "title": "Fair Lotteries for Participatory Budgeting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haris Aziz",
      "Xinhang Lu",
      "Mashbat Suzuki",
      "Jeremy Vollen",
      "Toby Walsh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28802": {
    "title": "Envy-Free House Allocation under Uncertain Preferences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haris Aziz",
      "Isaiah Iliffe",
      "Bo Li",
      "Angus Ritossa",
      "Ankang Sun",
      "Mashbat Suzuki"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28803": {
    "title": "Content Filtering with Inattentive Information Consumers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ian Ball",
      "James Bono",
      "Justin Grana",
      "Nicole Immorlica",
      "Brendan Lucier",
      "Aleksandrs Slivkins"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28804": {
    "title": "Nearly Equitable Allocations beyond Additivity and Monotonicity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddharth Barman",
      "Umang Bhaskar",
      "Yeshwant Pandit",
      "Soumyajit Pyne"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28805": {
    "title": "Principal-Agent Reward Shaping in MDPs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omer Ben-Porat",
      "Yishay Mansour",
      "Michal Moshkovitz",
      "Boaz Taitler"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28806": {
    "title": "Enhancing the Efficiency of Altruism and Taxes in Affine Congestion Games through Signalling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vittorio Bilò",
      "Cosimo Vinci"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28807": {
    "title": "Approval-Based Committee Voting in Practice: A Case Study of (over-)Representation in the Polkadot Blockchain",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Niclas Boehmer",
      "Markus Brill",
      "Alfonso Cevallos",
      "Jonas Gehrlein",
      "Luis Sánchez-Fernández",
      "Ulrike Schmidt-Kraepelin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28808": {
    "title": "Completing Priceable Committees: Utilitarian and Representation Guarantees for Proportional Multiwinner Voting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Markus Brill",
      "Jannik Peters"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28809": {
    "title": "Stability in Online Coalition Formation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martin Bullinger",
      "René Romen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28810": {
    "title": "Participation Incentives in Approval-Based Committee Elections",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martin Bullinger",
      "Chris Dong",
      "Patrick Lederer",
      "Clara Mehler"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28811": {
    "title": "Low-Distortion Clustering with Ordinal and Limited Cardinal Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jakob Burkhardt",
      "Ioannis Caragiannis",
      "Karl Fehrs",
      "Matteo Russo",
      "Chris Schwiegelshohn",
      "Sudarshan Shyam"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28812": {
    "title": "Efficient Learning in Polyhedral Games via Best-Response Oracles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Darshan Chakrabarti",
      "Gabriele Farina",
      "Christian Kroer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28813": {
    "title": "Proportional Aggregation of Preferences for Sequential Decision Making",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikhil Chandak",
      "Shashwat Goel",
      "Dominik Peters"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28814": {
    "title": "How to Make Knockout Tournaments More Popular?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juhi Chaudhary",
      "Hendrik Molter",
      "Meirav Zehavi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28815": {
    "title": "1/2-Approximate MMS Allocation for Separable Piecewise Linear Concave Valuations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chandra Chekuri",
      "Pooja Kulkarni ",
      "Rucha Kulkarni",
      "Ruta Mehta"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28816": {
    "title": "Dynamic Budget Throttling in Repeated Second-Price Auctions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaohua Chen",
      "Chang Wang",
      "Qian Wang",
      "Yuqi Pan",
      "Zhuming Shi",
      "Zheng Cai",
      "Yukun Ren",
      "Zhihua Zhu",
      "Xiaotie Deng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28817": {
    "title": "The Complexity of Computing Robust Mediated Equilibria in Ordinal Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Conitzer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28818": {
    "title": "Learning Discrete-Time Major-Minor Mean Field Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Cui",
      "Gökçe Dayanıklı",
      "Mathieu Laurière",
      "Matthieu Geist",
      "Olivier Pietquin",
      "Heinz Koeppl"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28819": {
    "title": "Automated Design of Affine Maximizer Mechanisms in Dynamic Settings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Curry",
      "Vinzenz Thoma",
      "Darshan Chakrabarti",
      "Stephen McAleer",
      "Christian Kroer",
      "Tuomas Sandholm",
      "Niao He",
      "Sven Seuken"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28820": {
    "title": "How to Evaluate Behavioral Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Greg d'Eon",
      "Sophie Greenwood",
      "Kevin Leyton-Brown",
      "James R. Wright"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28821": {
    "title": "Independence of Irrelevant Alternatives under the Lens of Pairwise Distortion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Théo Delemazure",
      "Jérôme Lang",
      "Grzegorz Pierczyński"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28822": {
    "title": "The Complexity of Fair Division of Indivisible Items with Externalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Argyrios Deligkas",
      "Eduard Eiben",
      "Viktoriia Korchemna",
      "Šimon Schierreich"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28823": {
    "title": "Competition among Pairwise Lottery Contests",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaotie Deng",
      "Hangxin Gan",
      "Ningyuan Li",
      "Weian Li",
      "Qi Qi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28824": {
    "title": "Refined Characterizations of Approval-Based Committee Scoring Rules",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chris Dong",
      "Patrick Lederer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28825": {
    "title": "Implications of Distance over Redistricting Maps: Central and Outlier Maps",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seyed A. Esmaeili",
      "Darshan Chakrabarti",
      "Hayley Grape",
      "Brian Brubach"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28826": {
    "title": "On Optimal Tradeoffs between EFX and Nash Welfare",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michal Feldman",
      "Simon Mauras",
      "Tomasz Ponitka"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28827": {
    "title": "Manipulation-Robust Selection of Citizens' Assemblies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bailey Flanigan",
      "Jennifer Liang",
      "Ariel D. Procaccia",
      "Sven Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28828": {
    "title": "Project-Fair and Truthful Mechanisms for Budget Aggregation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rupert Freeman",
      "Ulrike Schmidt-Kraepelin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28829": {
    "title": "Maxileximin Envy Allocations and Connected Goods",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gianluigi Greco",
      "Francesco Scarcello"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28830": {
    "title": "Information Design for Congestion Games with Unknown Demand",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Svenja M. Griesbach",
      "Martin Hoefer",
      "Max Klimm",
      "Tim Koglin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28831": {
    "title": "Zero-Sum Games between Mean-Field Teams: Reachability-Based Analysis under Mean-Field Sharing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Guan",
      "Mohammad Afshari",
      "Panagiotis Tsiotras"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28832": {
    "title": "Worst-Case VCG Redistribution Mechanism Design Based on the Lottery Ticket Hypothesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyu Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28833": {
    "title": "An Exercise in Tournament Design: When Some Matches Must Be Scheduled",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sushmita Gupta",
      "Ramanujan Sridharan",
      "Peter Strulo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28834": {
    "title": "Regret Analysis of Repeated Delegated Choice",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Hajiaghayi",
      "Mohammad Mahdavi",
      "Keivan Rezaei",
      "Suho Shin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28835": {
    "title": "Cost Minimization for Equilibrium Transition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoqiang Huang",
      "Zihe Wang",
      "Zhide Wei",
      "Jie Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28836": {
    "title": "Reachability of Fair Allocations via Sequential Exchanges",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayumi Igarashi",
      "Naoyuki Kamiyama",
      "Warut Suksompong",
      "Sheung Man Yuen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28837": {
    "title": "Repeated Fair Allocation of Indivisible Items",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayumi Igarashi",
      "Martin Lackner",
      "Oliviero Nardi",
      "Arianna Novaro"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28838": {
    "title": "Spatial Voting with Incomplete Voter Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aviram Imber",
      "Jonas Israel",
      "Markus Brill",
      "Hadas Shachnai",
      "Benny Kimelfeld"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28839": {
    "title": "Maximizing Nash Social Welfare under Two-Sided Preferences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pallavi Jain",
      "Rohit Vaish"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28840": {
    "title": "Optimal Mechanism in a Dynamic Stochastic Knapsack Environment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihyeok Jung",
      "Chan-Oi Song",
      "Deok-Joo Lee",
      "Kiho Yoon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28841": {
    "title": "Proportional Representation in Metric Spaces and Low-Distortion Committee Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusuf Kalayci",
      "David Kempe",
      "Vikram Kher"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28842": {
    "title": "Towards Optimal Subsidy Bounds for Envy-Freeable Allocations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yasushi Kawase",
      "Kazuhisa Makino",
      "Hanna Sumita",
      "Akihisa Tamura",
      "Makoto Yokoo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28843": {
    "title": "Strategyproof Mechanisms for Group-Fair Obnoxious Facility Location Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqian Li",
      "Minming Li",
      "Hau Chan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28844": {
    "title": "Opponent-Model Search in Games with Incomplete Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junkang Li",
      "Bruno Zanuttini",
      "Véronique Ventos"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28845": {
    "title": "Double Auction on Diffusion Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miao Li",
      "Yuhan Cao",
      "Dengji Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28846": {
    "title": "Pay to (Not) Play: Monetizing Impatience in Mobile Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taylor Lundy",
      "Narun Raman",
      "Hu Fu",
      "Kevin Leyton-Brown"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28847": {
    "title": "Weighted Envy-Freeness for Submodular Valuations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luisa Montanari",
      "Ulrike Schmidt-Kraepelin",
      "Warut Suksompong",
      "Nicholas Teh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28848": {
    "title": "Computing Nash Equilibria in Potential Games with Private Uncoupled Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikolas Patris",
      "Stelios Stavroulakis",
      "Fivos Kalogiannis",
      "Rose Zhang",
      "Ioannis Panageas"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28849": {
    "title": "Peer Neighborhood Mechanisms: A Framework for Mechanism Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adam Richardson",
      "Boi Faltings"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28850": {
    "title": "Machine Learning-Powered Combinatorial Clock Auction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ermis Nikiforos Soumalias",
      "Jakob Weissteiner",
      "Jakob Heiss",
      "Sven Seuken"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28851": {
    "title": "Almost Envy-Free Allocations of Indivisible Goods or Chores with Entitlements",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Max Springer",
      "MohammadTaghi Hajiaghayi",
      "Hadi Yami"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28852": {
    "title": "The Moderating Effect of Instant Runoff Voting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kiran Tomlinson",
      "Johan Ugander",
      "Jon Kleinberg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28853": {
    "title": "Unravelling Expressive Delegations: Complexity and Normative Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giannis Tyrovolas",
      "Andrei Constantinescu",
      "Edith Elkind"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28854": {
    "title": "Predicting Real-World Penny Auction Durations by Integrating Game Theory and Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujia Wang",
      "Haoran Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28855": {
    "title": "Simultaneous Optimization of Bid Shading and Internal Auction for Demand-Side Platforms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yadong Xu",
      "Bonan Ni",
      "Weiran Shen",
      "Xun Wang",
      "Zichen Wang",
      "Yinsong Xue",
      "Pingzhong Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28856": {
    "title": "Learning Coalition Structures with Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixuan Even Xu",
      "Chun Kai Ling",
      "Fei Fang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28857": {
    "title": "Non-excludable Bilateral Trade between Groups",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixuan Even Xu",
      "Hanrui Zhang",
      "Vincent Conitzer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28858": {
    "title": "Greedy-Based Online Fair Allocation with Adversarial Input: Enabling Best-of-Many-Worlds Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongjun Yang",
      "Luofeng Liao",
      "Christian Kroer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28859": {
    "title": "On the Outcome Equivalence of Extensive-Form and Behavioral Correlated Equilibria",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Brian Hu Zhang",
      "Tuomas Sandholm"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28860": {
    "title": "Eliciting Honest Information from Authors Using Sequential Review",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichi Zhang",
      "Grant Schoenebeck",
      "Weijie Su"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28861": {
    "title": "Fair Allocation of Items in Multiple Regions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Houyu Zhou",
      "Tianze Wei",
      "Biaoshuai Tao",
      "Minming Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28862": {
    "title": "Altruism in Facility Location Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Houyu Zhou",
      "Hau Chan",
      "Minming Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28863": {
    "title": "Explaining Reinforcement Learning Agents through Counterfactual Action Outcomes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yotam Amitai",
      "Yael Septon",
      "Ofra Amir"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28864": {
    "title": "Data-Driven Knowledge-Aware Inference of Private Information in Continuous Double Auctions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lvye Cui",
      "Haoran Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28865": {
    "title": "Procedural Level Generation with Diffusion Models from a Single Example",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiqi Dai",
      "Xuanyu Zhu",
      "Naiqi Li",
      "Tao Dai",
      "Zhi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28866": {
    "title": "When Are Two Lists Better than One?: Benefits and Harms in Joint Decision-Making",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kate Donahue",
      "Sreenivas Gollapudi",
      "Kostas Kollias"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28867": {
    "title": "A Local-Ascending-Global Learning Strategy for Brain-Computer Interface",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongrui Gao",
      "Haokai Zhang",
      "Pengrui Li",
      "Tian Tang",
      "Shihong Liu",
      "Zhihong Zhou",
      "Shaofei Ying",
      "Ye Zhu",
      "Yongqing Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28868": {
    "title": "Working Memory Capacity of ChatGPT: An Empirical Study",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongyu Gong",
      "Xingchen Wan",
      "Dingmin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28869": {
    "title": "Count What You Want: Exemplar Identification and Few-Shot Counting of Human Actions in the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifeng Huang",
      "Duc Duy Nguyen",
      "Lam Nguyen",
      "Cuong Pham",
      "Minh Hoai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28870": {
    "title": "Learning Optimal Advantage from Preferences and Mistaking It for Reward",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "W. Bradley Knox",
      "Stephane Hatgis-Kessell",
      "Sigurdur Orn Adalgeirsson",
      "Serena Booth",
      "Anca Dragan",
      "Peter Stone",
      "Scott Niekum"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28871": {
    "title": "A Unified Self-Distillation Framework for Multimodal Sentiment Analysis with Uncertain Missing Modalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingcheng Li",
      "Dingkang Yang",
      "Yuxuan Lei",
      "Shunli Wang",
      "Shuaibing Wang",
      "Liuzhen Su",
      "Kun Yang",
      "Yuzheng Wang",
      "Mingyang Sun",
      "Lihua Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28872": {
    "title": "Decoding AI's Nudge: A Unified Framework to Predict Human Behavior in AI-Assisted Decision Making",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoyan Li",
      "Zhuoran Lu",
      "Ming Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28873": {
    "title": "GigaHumanDet: Exploring Full-Body Detection on Gigapixel-Level Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenglong Liu",
      "Haoran Wei",
      "Jinze Yang",
      "Jintao Liu",
      "Wenxi Li",
      "Yuchen Guo",
      "Lu Fang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28874": {
    "title": "Hypergraph-Guided Disentangled Spectrum Transformer Networks for Near-Infrared Facial Expression Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingjun Luo",
      "Haowen Wang",
      "Jinpeng Wang",
      "Junjie Zhu",
      "Xibin Zhao",
      "Yue Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28875": {
    "title": "Goal Alignment: Re-analyzing Value Alignment Problems Using Human-Aware AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Malek Mechergui",
      "Sarath Sreedharan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28876": {
    "title": "Efficient Online Crowdsourcing with Complex Annotations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Reshef Meir",
      "Viet-An Nguyen",
      "Xu Chen",
      "Jagdish Ramakrishnan",
      "Udi Weinsberg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28877": {
    "title": "Can You Rely on Synthetic Labellers in Preference-Based Reinforcement Learning? It's Complicated",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katherine Metcalf",
      "Miguel Sarabia",
      "Masha Fedzechkina",
      "Barry-John Theobald"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28878": {
    "title": "When to Show a Suggestion? Integrating Human Feedback in AI-Assisted Programming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hussein Mozannar",
      "Gagan Bansal",
      "Adam Fourney",
      "Eric Horvitz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28879": {
    "title": "Improving Transferability for Cross-Domain Trajectory Prediction via Neural Stochastic Differential Equation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daehee Park",
      "Jaewoo Jeong",
      "Kuk-Jin Yoon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28880": {
    "title": "Exploring Domain Incremental Video Highlights Detection with the LiveFood Benchmark",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sen Pei",
      "Shixiong Xu",
      "Xiaojie Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28881": {
    "title": "Sample-Constrained Black Box Optimization for Audio Personalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rajalaxmi Rajagopalan",
      "Yu-Lin Wei",
      "Romit Roy Choudhury"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28882": {
    "title": "Intelligent Calibration for Bias Reduction in Sentiment Corpora Annotation Process",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Idan Toker",
      "David Sarne",
      "Jonathan Schler"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28883": {
    "title": "TransGOP: Transformer-Based Gaze Object Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Binglu Wang",
      "Chenxi Guo",
      "Yang Jin",
      "Haisheng Xia",
      "Nian Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28884": {
    "title": "Visual Redundancy Removal for Composite Images: A Benchmark Dataset and a Multi-Visual-Effects Driven Incremental Method",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miaohui Wang",
      "Rong Zhang",
      "Lirong Huang",
      "Yanshan Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28885": {
    "title": "TexFit: Text-Driven Fashion Image Editing with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tongxin Wang",
      "Mang Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28886": {
    "title": "Rating-Based Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Devin White",
      "Mingkang Wu",
      "Ellen Novoseller",
      "Vernon J. Lawhern",
      "Nicholas Waytowich",
      "Yongcan Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28887": {
    "title": "MKG-FENN: A Multimodal Knowledge Graph Fused End-to-End Neural Network for Accurate Drug–Drug Interaction Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Di Wu",
      "Wu Sun",
      "Yi He",
      "Zhong Chen",
      "Xin Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28888": {
    "title": "Spatial-Related Sensors Matters: 3D Human Motion Reconstruction Assisted with Textual Semantics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xueyuan Yang",
      "Chao Yao",
      "Xiaojuan Ban"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28889": {
    "title": "Scalable Motion Style Transfer with Constrained Diffusion Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjie Yin",
      "Yi Yu",
      "Hang Yin",
      "Danica Kragic",
      "Mårten Björkman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28890": {
    "title": "‘Why Didn't You Allocate This Task to Them?' Negotiation-Aware Task Allocation and Contrastive Explanation Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zahra Zahedi",
      "Sailik Sengupta",
      "Subbarao Kambhampati"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28891": {
    "title": "Beyond Mimicking Under-Represented Emotions: Deep Data Augmentation with Emotional Subspace Constraints for EEG-Based Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Zhang",
      "Shenghua Zhong",
      "Yan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28892": {
    "title": "MetaRLEC: Meta-Reinforcement Learning for Discovery of Brain Effective Connectivity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zuozhen Zhang",
      "Junzhong Ji",
      "Jinduo Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28893": {
    "title": "DanceMVP: Self-Supervised Learning for Multi-Task Primitive-Based Dance Performance Assessment via Transformer Text Prompting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun Zhong",
      "Yiannis Demiris"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28910": {
    "title": "Complexity of Credulous and Skeptical Acceptance in Epistemic Argumentation Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gianvincenzo Alfano",
      "Sergio Greco",
      "Francesco Parisi",
      "Irina Trubitsyna"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28911": {
    "title": "Approximation Algorithms for Preference Aggregation Using CP-Nets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abu Mohammad Hammad Ali",
      "Boting Yang",
      "Sandra Zilles"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28912": {
    "title": "What Does a Query Answer Tell You? Informativeness of Query Answers for Knowledge Bases",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Andolfi",
      "Gianluca Cima",
      "Marco Console",
      "Maurizio Lenzerini"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28913": {
    "title": "Defeasible Normative Reasoning: A Proof-Theoretic Integration of Logical Argumentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ofer Arieli",
      "Kees van Berkel",
      "Christian Straßer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28914": {
    "title": "Computing the Why-Provenance for Datalog Queries via SAT Solvers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marco Calautti",
      "Ester Livshits",
      "Andreas Pieris",
      "Markus Schneider"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28915": {
    "title": "Generalisation through Negation and Predicate Invention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David M. Cerna",
      "Andrew Cropper"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28916": {
    "title": "Learning Small Decision Trees for Data of Low Rank-Width",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Konrad K. Dabrowski",
      "Eduard Eiben",
      "Sebastian Ordyniak",
      "Giacomo Paesani",
      "Stefan Szeider"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28917": {
    "title": "Stable Model Semantics for Description Logic Terminologies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Federica Di Stefano",
      "Mantas Šimkus"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28918": {
    "title": "Redefining ABA+ Semantics via Abstract Set-to-Set Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yannis Dimopoulos ",
      "Wolfgang Dvorak",
      "Matthias König",
      "Anna Rapberger",
      "Markus Ulbricht",
      "Stefan Woltran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28919": {
    "title": "Towards Epistemic-Doxastic Planning with Observation and Revision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thorsten Engesser",
      "Andreas Herzig",
      "Elise Perrotin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28920": {
    "title": "Dynamic Tangled Derivative Logic of Metric Spaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Fernández-Duque",
      "Yoàv Montacute"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28921": {
    "title": "Submodel Enumeration for CTL Is Hard",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Fröhlich",
      "Arne Meier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28922": {
    "title": "Linear-Time Verification of Data-Aware Processes Modulo Theories via Covers and Automata",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessandro Gianola",
      "Marco Montali",
      "Sarah Winkler"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28923": {
    "title": "On the Structural Hardness of Answer Set Programming: Can Structure Efficiently Confine the Power of Disjunctions?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Markus Hecher",
      "Rafael Kiesel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28924": {
    "title": "Knowledge Enhanced Representation Learning for Drug Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thanh Lam Hoang",
      "Marco Luca Sbodio",
      "Marcos Martinez Galindo",
      "Mykhaylo Zayats",
      "Raul Fernandez-Diaz",
      "Victor Valls",
      "Gabriele Picco",
      "Cesar Berrospi",
      "Vanessa Lopez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28925": {
    "title": "Learning MDL Logic Programs from Noisy Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Céline Hocquette",
      "Andreas Niskanen",
      "Matti Järvisalo",
      "Andrew Cropper"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28926": {
    "title": "A Compiler for Weak Decomposable Negation Normal Form",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Petr Illner",
      "Petr Kučera"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28927": {
    "title": "Exact ASP Counting with Compact Encodings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohimenul Kabir",
      "Supratik Chakraborty",
      "Kuldeep S. Meel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28928": {
    "title": "Minimal Macro-Based Rewritings of Formal Languages: Theory and Applications in Ontology Engineering (and Beyond)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christian Kindermann",
      "Anne-Marie George",
      "Bijan Parsia",
      "Uli Sattler"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28929": {
    "title": "On the Expressivity of Recurrent Neural Cascades",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nadezda Alexandrovna Knorozova",
      "Alessandro Ronca"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28930": {
    "title": "Efficient Axiomatization of OWL 2 EL Ontologies from Data by Means of Formal Concept Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesco Kriegel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28931": {
    "title": "BAIT: Benchmarking (Embedding) Architectures for Interactive Theorem-Proving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sean Lamont",
      "Michael Norrish",
      "Amir Dezfouli",
      "Christian Walder",
      "Paul Montague"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28932": {
    "title": "INFORMEDQX: Informed Conflict Detection for Over-Constrained Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Viet-Man Le",
      "Alexander Felfernig",
      "Thi Ngoc Trang Tran",
      "Mathias Uta"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28933": {
    "title": "Abstraction of Situation Calculus Concurrent Game Structures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yves Lesperance",
      "Giuseppe De Giacomo",
      "Maryam Rostamigiv",
      "Shakil M. Khan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28934": {
    "title": "Relational Programming with Foundational Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyang Li",
      "Jiani Huang",
      "Jason Liu",
      "Felix Zhu",
      "Eric Zhao",
      "William Dodds",
      "Neelay Velingker",
      "Rajeev Alur",
      "Mayur Naik"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28935": {
    "title": "MINES: Message Intercommunication for Inductive Relation Reasoning over Neighbor-Enhanced Subgraphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Liang",
      "Lingyuan Meng",
      "Sihang Zhou",
      "Wenxuan Tu",
      "Siwei Wang",
      "Yue Liu",
      "Meng Liu",
      "Long Zhao",
      "Xiangjun Dong",
      "Xinwang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28936": {
    "title": "Auditable Algorithms for Approximate Model Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kuldeep S. Meel",
      "Supratik Chakraborty",
      "S. Akshay"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28937": {
    "title": "A General Theoretical Framework for Learning Smallest Interpretable Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sebastian Ordyniak",
      "Giacomo Paesani",
      "Mateusz Rychlicki",
      "Stefan Szeider"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28938": {
    "title": "Reinforcement Learning and Data-Generation for Syntax-Guided Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julian Parsert",
      "Elizabeth Polgreen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28939": {
    "title": "Adaptive Reactive Synthesis for LTL and LTLf Modulo Theories",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andoni Rodríguez",
      "César Sánchez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28940": {
    "title": "A Unified View on Forgetting and Strong Equivalence Notions in Answer Set Programming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeynep G. Saribatur",
      "Stefan Woltran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28941": {
    "title": "BeliefFlow: A Framework for Logic-Based Belief Diffusion via Iterated Belief Change",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Schwind",
      "Katsumi Inoue",
      "Sébastien Konieczny",
      "Pierre Marquis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28942": {
    "title": "NegVSR: Augmenting Negatives for Generalized Noise Modeling in Real-world Video Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yexing Song",
      "Meilin Wang",
      "Zhijing Yang",
      "Xiaoyu Xian",
      "Yukai Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28943": {
    "title": "Scalable Enumeration of Trap Spaces in Boolean Networks via Answer Set Programming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giang Trinh",
      "Belaid Benhamou",
      "Samuel Pastva",
      "Sylvain Soliman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28944": {
    "title": "Non-flat ABA Is an Instance of Bipolar Argumentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Markus Ulbricht",
      "Nico Potyka",
      "Anna Rapberger",
      "Francesca Toni"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28945": {
    "title": "Bilateral Gradual Semantics for Weighted Argumentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongshun Wang",
      "Yuping Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28946": {
    "title": "Decomposing Constraint Networks for Calculating c-Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marco Wilhelm",
      "Gabriele Kern-Isberner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28947": {
    "title": "Optimised Storage for Datalog Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyue Zhang",
      "Pan Hu",
      "Yavor Nenov",
      "Ian Horrocks"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28948": {
    "title": "Prot2Text: Multimodal Protein's Function Generation with GNNs and Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hadi Abdine",
      "Michail Chatzianastasis",
      "Costas Bouyioukos",
      "Michalis Vazirgiannis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28949": {
    "title": "Unsupervised Neighborhood Propagation Kernel Layers for Semi-supervised Node Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sonny Achten",
      "Francesco Tonin",
      "Panagiotis Patrinos",
      "Johan A.K. Suykens"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28950": {
    "title": "No Prejudice! Fair Federated Graph Neural Networks for Personalized Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nimesh Agrawal",
      "Anuj Kumar Sirohi",
      "Sandeep Kumar",
      "Jayadeva"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28951": {
    "title": "Pareto Front-Diverse Batch Multi-Objective Bayesian Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alaleh Ahmadianshalchi",
      "Syrine Belakaria",
      "Janardhan Rao Doppa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28952": {
    "title": "SimCS: Simulation for Domain Incremental Online Continual Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Motasem Alfarra",
      "Zhipeng Cai",
      "Adel Bibi",
      "Bernard Ghanem",
      "Matthias Müller"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28953": {
    "title": "Sample Efficient Reinforcement Learning with Partial Dynamics Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meshal Alharbi",
      "Mardavij Roozbehani",
      "Munther Dahleh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28954": {
    "title": "Understanding and Improving Optimization in Predictive Coding Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicholas Alonso",
      "Jeffrey Krichmar",
      "Emre Neftci"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28955": {
    "title": "Limited Memory Online Gradient Descent for Kernelized Pairwise Learning with Dynamic Averaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hilal AlQuabeh",
      "William de Vazelhes",
      "Bin Gu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28956": {
    "title": "Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Altmeyer",
      "Mojtaba Farmanbar",
      "Arie van Deursen",
      "Cynthia C. S. Liem"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28957": {
    "title": "Optimal Transport with Tempered Exponential Measures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ehsan Amid",
      "Frank Nielsen",
      "Richard Nock",
      "Manfred K. Warmuth"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28958": {
    "title": "Elijah: Eliminating Backdoors Injected in Diffusion Models via Distribution Shift",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengwei An",
      "Sheng-Yen Chou",
      "Kaiyuan Zhang",
      "Qiuling Xu",
      "Guanhong Tao",
      "Guangyu Shen",
      "Siyuan Cheng",
      "Shiqing Ma",
      "Pin-Yu Chen",
      "Tsung-Yi Ho",
      "Xiangyu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28959": {
    "title": "Transfer and Alignment Network for Generalized Category Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenbin An",
      "Feng Tian",
      "Wenkai Shi",
      "Yan Chen",
      "Yaqiang Wu",
      "Qianying Wang",
      "Ping Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28960": {
    "title": "Fluctuation-Based Adaptive Structured Pruning for Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongqi An",
      "Xu Zhao",
      "Tao Yu",
      "Ming Tang",
      "Jinqiao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28961": {
    "title": "Active Learning Guided by Efficient Surrogate Learners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunpyo An",
      "Suyeong Park",
      "Kwang In Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28962": {
    "title": "Formal Logic Enabled Personalized Federated Learning through Property Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyan An",
      "Taylor T. Johnson",
      "Meiyi Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28963": {
    "title": "Generating Universal Adversarial Perturbations for Quantum Classifiers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gautham Anil",
      "Vishnu Vinod",
      "Apurva Narayan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28964": {
    "title": "Enhancing Training of Spiking Neural Network with Stochastic Latency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Srinivas Anumasa",
      "Bhaskar Mukhoty",
      "Velibor Bojkovic",
      "Giulia De Masi",
      "Huan Xiong",
      "Bin Gu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28965": {
    "title": "Task-Agnostic Privacy-Preserving Representation Learning for Federated Learning against Attribute Inference Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Caridad Arroyo Arevalo",
      "Sayedeh Leila Noorbakhsh",
      "Yun Dong",
      "Yuan Hong",
      "Binghui Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28966": {
    "title": "Neural Network Approximators for Marginal MAP in Probabilistic Circuits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivvrat Arya",
      "Tahrima Rahman",
      "Vibhav Gogate"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28967": {
    "title": "Generator Assisted Mixture of Experts for Feature Acquisition in Batch",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vedang Asgaonkar",
      "Aditya Jain ",
      "Abir De"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28968": {
    "title": "Taming Binarized Neural Networks and Mixed-Integer Programs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johannes Aspman",
      "Georgios Korpas",
      "Jakub Marecek"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28969": {
    "title": "Contextual Pandora's Box",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexia Atsidakou",
      "Constantine Caramanis",
      "Evangelia Gergatsouli",
      "Orestis Papadigenopoulos",
      "Christos Tzamos"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28970": {
    "title": "Contextual Pre-planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guy Azran",
      "Mohamad H. Danesh",
      "Stefano V. Albrecht",
      "Sarah Keren"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28971": {
    "title": "FairTrade: Achieving Pareto-Optimal Trade-Offs between Balanced Accuracy and Fairness in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maryam Badar",
      "Sandipan Sikdar",
      "Wolfgang Nejdl",
      "Marco Fisichella"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28972": {
    "title": "Robustness-Guided Image Synthesis for Data-Free Quantization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianhong Bai",
      "Yuchen Yang",
      "Huanpeng Chu",
      "Hualiang Wang",
      "Zuozhu Liu",
      "Ruizhe Chen",
      "Xiaoxuan He",
      "Lianrui Mu",
      "Chengfei Cai",
      "Haoji Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28973": {
    "title": "Regret Analysis of Policy Gradient Algorithm for Infinite Horizon Average Reward Markov Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qinbo Bai",
      "Washim Uddin Mondal",
      "Vaneet Aggarwal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28974": {
    "title": "Combating Data Imbalances in Federated Semi-supervised Learning with Dual Regulators",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sikai Bai",
      "Shuaicheng Li",
      "Weiming Zhuang",
      "Jie Zhang",
      "Kunlin Yang",
      "Jun Hou",
      "Shuai Yi",
      "Shuai Zhang",
      "Junyu Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28975": {
    "title": "SpikingBERT: Distilling BERT to Train Spiking Language Models Using Implicit Differentiation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Malyaban  Bal",
      "Abhronil Sengupta"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28976": {
    "title": "Disentangled Partial Label Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei-Xuan Bao",
      "Yong Rui",
      "Min-Ling Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28977": {
    "title": "Efficient Target Propagation by Deriving Analytical Solution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanhao Bao",
      "Tatsukichi Shibuya",
      "Ikuro Sato",
      "Rei Kawakami",
      "Nakamasa Inoue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28978": {
    "title": "Strong Baselines for Parameter-Efficient Few-Shot Fine-Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samyadeep Basu",
      "Shell Hu",
      "Daniela Massiceti",
      "Soheil Feizi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28979": {
    "title": "TREE-G: Decision Trees Contesting Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maya Bechler-Speicher",
      "Amir Globerson",
      "Ran Gilad-Bachrach"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28980": {
    "title": "Scores for Learning Discrete Causal Graphs with Unobserved Confounders",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexis Bellot",
      "Junzhe Zhang",
      "Elias Bareinboim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28981": {
    "title": "Simplicity Bias in Overparameterized Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yakir Berchenko"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28982": {
    "title": "Maximizing the Success Probability of Policy Allocations in Online Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Artem Betlei",
      "Mariia Vladimirova",
      "Mehdi Sebbar",
      "Nicolas Urien",
      "Thibaud Rahier",
      "Benjamin Heymann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28983": {
    "title": "DGCLUSTER: A Neural Framework for Attributed Graph Clustering via Modularity Maximization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aritra Bhowmick",
      "Mert Kosan",
      "Zexi Huang",
      "Ambuj Singh",
      "Sourav Medya"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28984": {
    "title": "MEPSI: An MDL-Based Ensemble Pruning Approach with Structural Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao-Dong Bi",
      "Shao-Qun Zhang",
      "Yuan Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28985": {
    "title": "Constraint Latent Space Matters: An Anti-anomalous Waveform Transformation Solution from Photoplethysmography to Arterial Blood Pressure",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Bian",
      "Xiaoyu Li",
      "Qi Bi",
      "Guangpu Zhu",
      "Jiegeng Lyu",
      "Weile Zhang",
      "Yelei Li",
      "Zijing Zeng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28986": {
    "title": "Axiomatic Aggregations of Abductive Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gagan Biradar",
      "Yacine Izza",
      "Elita Lobo",
      "Vignesh Viswanathan",
      "Yair Zick"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28987": {
    "title": "MIND: Multi-Task Incremental Network Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacopo Bonato",
      "Francesco Pelosin",
      "Luigi Sabetta",
      "Alessandro Nicolosi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28988": {
    "title": "HyperFast: Instant Classification for Tabular Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Bonet",
      "Daniel Mas Montserrat",
      "Xavier Giró-i-Nieto",
      "Alexander G. Ioannidis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28989": {
    "title": "A Theory of Non-acyclic Generative Flow Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leo Brunswic",
      "Yinchuan Li",
      "Yushun Xu",
      "Yijun Feng",
      "Shangling Jui",
      "Lizhuang Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28990": {
    "title": "Where and How to Attack? A Causality-Inspired Recipe for Generating Counterfactual Adversarial Examples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruichu Cai",
      "Yuxuan Zhu",
      "Jie Qiao",
      "Zefeng Liang",
      "Furui Liu",
      "Zhifeng Hao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28991": {
    "title": "MSGNet: Learning Multi-Scale Inter-series Correlations for Multivariate Time Series Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wanlin Cai",
      "Yuxuan Liang",
      "Xianggen Liu",
      "Jianshuai Feng",
      "Yuankai Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28992": {
    "title": "Kernelized Normalizing Constant Estimation: Bridging Bayesian Quadrature and Bayesian Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Cai",
      "Jonathan Scarlett"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28993": {
    "title": "EG-NAS: Neural Architecture Search with Fast Evolutionary Exploration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zicheng Cai",
      "Lei Chen",
      "Peng Liu",
      "Tongtao Ling",
      "Yutao Lai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28994": {
    "title": "Mixup-Induced Domain Extrapolation for Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meng Cao",
      "Songcan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28995": {
    "title": "Continuous-Time Graph Representation with Sequential Survival Process",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abdulkadir Çelikkanat",
      "Nikolaos Nakis",
      "Morten Mørup"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28996": {
    "title": "Learning to Unlearn: Instance-Wise Unlearning for Pre-trained Classifiers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sungmin Cha",
      "Sungjun Cho",
      "Dasol Hwang",
      "Honglak Lee",
      "Taesup Moon",
      "Moontae Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28997": {
    "title": "Variable Importance in High-Dimensional Settings Requires Grouping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmad Chamma",
      "Bertrand Thirion",
      "Denis Engemann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28998": {
    "title": "Privacy Amplification by Iteration for ADMM with (Strongly) Convex Objective Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "T-H. Hubert Chan",
      "Hao Xie",
      "Mengshi Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/28999": {
    "title": "Understanding Distributed Representations of Concepts in Deep Neural Networks without Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wonjoon Chang",
      "Dahee Kwon",
      "Jaesik Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29000": {
    "title": "Incomplete Contrastive Multi-View Clustering with High-Confidence Guiding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guoqing Chao",
      "Yi Jiang",
      "Dianhui Chu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29001": {
    "title": "Offline Model-Based Optimization via Policy-Guided Gradient Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yassine Chemingui",
      "Aryan Deshwal",
      "Trong Nghia Hoang",
      "Janardhan Rao Doppa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29002": {
    "title": "Focus-Then-Decide: Segmentation-Assisted Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Chen",
      "Jiacheng Xu",
      "Weijian Liao",
      "Hao Ding",
      "Zongzhang Zhang",
      "Yang Yu",
      "Rui Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29003": {
    "title": "Data Shunt: Collaboration of Small and Large Models for Lower Costs and Better Performance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Chen",
      "Yueting Zhuang",
      "Shuo Zhang",
      "Jinfeng Liu",
      "Su Dong",
      "Siliang Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29004": {
    "title": "EPSD: Early Pruning with Self-Distillation for Efficient Model Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Chen",
      "Ning Liu",
      "Yichen Zhu",
      "Zhengping Che",
      "Rui Ma",
      "Fachao Zhang",
      "Xiaofeng Mou",
      "Yi Chang",
      "Jian Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29005": {
    "title": "A Generalized Shuffle Framework for Privacy Amplification: Strengthening Privacy Guarantees and Enhancing Utility",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "E Chen",
      "Yang Cao",
      "Yifei Ge"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29006": {
    "title": "Adaptive Discovering and Merging for Incremental Novel Class Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangyao Chen",
      "Peixi Peng",
      "Yangru Huang",
      "Mengyue Geng",
      "Yonghong Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29007": {
    "title": "FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haokun Chen",
      "Yao Zhang",
      "Denis Krompass",
      "Jindong Gu",
      "Volker Tresp"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29008": {
    "title": "Uncertainty Quantification for Data-Driven Change-Point Learning via Cross-Validation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hui Chen",
      "Yinxu Jia",
      "Guanghui Wang",
      "Changliang Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29009": {
    "title": "Bridging the Semantic Latent Space between Brain and Machine: Similarity Is All You Need",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxuan Chen",
      "Yu Qi",
      "Yueming Wang",
      "Gang Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29010": {
    "title": "On Disentanglement of Asymmetrical Knowledge Transfer for Modality-Task Agnostic Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Chen",
      "Aidong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29011": {
    "title": "Accelerate Multi-Agent Reinforcement Learning in Zero-Sum Games with Subgame Curriculum Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayu Chen",
      "Zelai Xu",
      "Yunfei Li",
      "Chao Yu",
      "Jiaming Song",
      "Huazhong Yang",
      "Fei Fang",
      "Yu Wang",
      "Yi Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29012": {
    "title": "Watch Your Head: Assembling Projection Heads to Save the Reliability of Federated Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinqian Chen",
      "Jihua Zhu",
      "Qinghai Zheng",
      "Zhongyu Li",
      "Zhiqiang Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29013": {
    "title": "Discriminative Forests Improve Generative Diversity for Generative Adversarial Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Chen",
      "Jiahao Li",
      "Chen Song",
      "Bin Li",
      "Qingcai Chen",
      "Hongchang Gao",
      "Wendy Hui Wang",
      "Zenglin Xu",
      "Xinghua Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29014": {
    "title": "Efficient Algorithms for Non-gaussian Single Index Models with Generative Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junren Chen",
      "Zhaoqiang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29015": {
    "title": "Audio Scanning Network: Bridging Time and Frequency Domains for Audio Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liangwei Chen",
      "Xiren Zhou",
      "Huanhuan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29016": {
    "title": "Deep Contrastive Graph Learning with Clustering-Oriented Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mulin Chen",
      "Bocheng Wang",
      "Xuelong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29017": {
    "title": "On the Unstable Convergence Regime of Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Chen",
      "Jiaying Peng",
      "Xiaolong Li",
      "Yao Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29018": {
    "title": "PG-LBO: Enhancing High-Dimensional Bayesian Optimization with Pseudo-Label and Gaussian Process Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taicai Chen",
      "Yue Duan",
      "Dong Li",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29019": {
    "title": "DGPO: Discovering Multiple Strategies with Diversity-Guided Policy Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wentse Chen",
      "Shiyu Huang",
      "Yuan Chiang",
      "Tim Pearce",
      "Wei-Wei Tu",
      "Ting Chen",
      "Jun Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29020": {
    "title": "Exploiting Symmetric Temporally Sparse BPTT for Efficient RNN Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Chen",
      "Chang Gao",
      "Zuowen Wang",
      "Longbiao Cheng",
      "Sheng Zhou",
      "Shih-Chii Liu",
      "Tobi Delbruck"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29021": {
    "title": "Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Chen",
      "Xiao Lin",
      "Bo Yan",
      "Libo Zhang",
      "Jiamou Liu",
      "Neset Özkan Tan",
      "Michael Witbrock"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29022": {
    "title": "Exact Policy Recovery in Offline RL with Both Heavy-Tailed Rewards and Data Corruption",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiding Chen",
      "Xuezhou Zhang",
      "Qiaomin Xie",
      "Xiaojin Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29023": {
    "title": "Progressive Poisoned Data Isolation for Training-Time Backdoor Defense",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiming Chen",
      "Haiwei Wu",
      "Jiantao Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29024": {
    "title": "Pushing the Limit of Fine-Tuning for Few-Shot Learning: Where Feature Reusing Meets Cross-Scale Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ying-Yu Chen",
      "Jun-Wei Hsieh",
      "Xin Li",
      "Ming-Ching Chang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29025": {
    "title": "Fed-QSSL: A Framework for Personalized Federated Learning under Bitwidth and Data Heterogeneity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyue Chen",
      "Haris Vikalo",
      "Chianing Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29026": {
    "title": "TopoGCL: Topological Graph Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhou Chen",
      "Jose Frias",
      "Yulia R. Gel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29027": {
    "title": "Continuous Rotation Group Equivariant Network Inspired by Neural Population Coding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiqiang Chen",
      "Yang Chen",
      "Xiaolong Zou",
      "Shan Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29028": {
    "title": "Diagnosing and Rectifying Fake OOD Invariance: A Restructured Causal Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziliang Chen",
      "Yongsen Zheng",
      "Zhao-Rong Lai",
      "Quanlong Guan",
      "Liang Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29029": {
    "title": "Instrumental Variable Estimation for Causal Inference in Longitudinal Data with Time-Dependent Latent Confounders",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debo Cheng",
      "Ziqi Xu",
      "Jiuyong Li",
      "Lin Liu",
      "Jixue Liu",
      "Wentao Gao",
      "Thuc Duy Le"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29030": {
    "title": "Hierarchize Pareto Dominance in Multi-Objective Stochastic Linear Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ji Cheng",
      "Bo Xue",
      "Jiaxiang Yi",
      "Qingfu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29031": {
    "title": "FedGCR: Achieving Performance and Fairness for Federated Learning with Distinct Client Types via Group Customization and Reweighting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shu-Ling Cheng",
      "Chin-Yuan Yeh",
      "Ting-An Chen",
      "Eliana Pastor",
      "Ming-Syan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29032": {
    "title": "Clarifying the Behavior and the Difficulty of Adversarial Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Cheng",
      "Hao Zhang",
      "Yue Xin",
      "Wen Shen",
      "Quanshi Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29033": {
    "title": "Arithmetic Feature Interaction Is Necessary for Deep Tabular Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Cheng",
      "Renjun Hu",
      "Haochao Ying",
      "Xing Shi",
      "Jian Wu",
      "Wei Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29034": {
    "title": "CUTS+: High-Dimensional Causal Discovery from Irregular Time-Series",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxiao Cheng",
      "Lianglong Li",
      "Tingxiong Xiao",
      "Zongren Li",
      "Jinli Suo",
      "Kunlun He",
      "Qionghai Dai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29035": {
    "title": "Generalized Variational Inference via Optimal Transport",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinjin Chi",
      "Zhichao Zhang",
      "Zhiyao Yang",
      "Jihong Ouyang",
      "Hongbin Pei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29036": {
    "title": "Operator-Learning-Inspired Modeling of Neural Ordinary Differential Equations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Woojin Cho",
      "Seunghyeon Cho",
      "Hyundong Jin",
      "Jinsung Jeon",
      "Kookjin Lee",
      "Sanghyun Hong",
      "Dongeun Lee",
      "Jonghyun Choi",
      "Noseong Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29037": {
    "title": "Make Prompts Adaptable: Bayesian Modeling for Vision-Language Prompt Learning with Data-Dependent Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youngjae Cho",
      "HeeSun Bae",
      "Seungjae Shin",
      "Yeo Dong Youn",
      "Weonyoung Joo",
      "Il-Chul Moon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29038": {
    "title": "SNN-PDE: Learning Dynamic PDEs from Data with Simplicial Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jae Choi",
      "Yuzhou Chen",
      "Huikyo Lee",
      "Hyun Kim",
      "Yulia R. Gel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29039": {
    "title": "Unsupervised Object Interaction Learning with Counterfactual Dynamics Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jongwook Choi",
      "Sungtae Lee",
      "Xinyu Wang",
      "Sungryull Sohn",
      "Honglak Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29040": {
    "title": "DUEL: Duplicate Elimination on Active Memory for Self-Supervised Class-Imbalanced Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Won-Seok Choi",
      "Hyundo Lee",
      "Dong-Sig Han",
      "Junseok Park",
      "Heeyeon Koo",
      "Byoung-Tak Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29041": {
    "title": "Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wonjeong Choi",
      "Jungwuk Park",
      "Dong-Jun Han",
      "Younghyun Park",
      "Jaekyun Moon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29042": {
    "title": "A Provably Accurate Randomized Sampling Algorithm for Logistic Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Agniva Chowdhury",
      "Pradeep Ramuhalli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29043": {
    "title": "Graph-Based Prediction and Planning Policy Network (GP3Net) for Scalable Self-Driving in Dynamic Environments Using Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jayabrata Chowdhury",
      "Venkataramanan Shivaraman",
      "Suresh Sundaram",
      "PB Sujit"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29044": {
    "title": "Lyapunov-Stable Deep Equilibrium Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu Chu",
      "Shikui Wei",
      "Ting Liu",
      "Yao Zhao",
      "Yuto Miyatake"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29045": {
    "title": "Make RepVGG Greater Again: A Quantization-Aware Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangxiang Chu",
      "Liang Li",
      "Bo Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29046": {
    "title": "Meta-Reinforcement Learning via Exploratory Task Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhendong Chu",
      "Renqin Cai",
      "Hongning Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29047": {
    "title": "Task-Driven Causal Feature Distillation: Towards Trustworthy Risk Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixuan Chu",
      "Mengxuan Hu",
      "Qing Cui",
      "Longfei Li",
      "Sheng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29048": {
    "title": "Resource Efficient Deep Learning Hardware Watermarks with Signature Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joseph Clements",
      "Yingjie Lao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29049": {
    "title": "RLfOLD: Reinforcement Learning from Online Demonstrations in Urban Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Coelho",
      "Miguel Oliveira",
      "Vitor Santos"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29050": {
    "title": "Big Learning Expectation Maximization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yulai Cong",
      "Sijia Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29051": {
    "title": "Time-Aware Knowledge Representations of Dynamic Objects with Multidimensional Persistence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baris Coskunuzer",
      "Ignacio Segovia-Dominguez",
      "Yuzhou Chen",
      "Yulia R. Gel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29052": {
    "title": "BadRL: Sparse Targeted Backdoor Attack against Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Cui",
      "Yufei Han",
      "Yuzhe Ma",
      "Jianbin Jiao",
      "Junge Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29053": {
    "title": "Deletion-Robust Submodular Maximization with Knapsack Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuang Cui",
      "Kai Han",
      "He Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29054": {
    "title": "Continual Vision-Language Retrieval via Dynamic Knowledge Rectification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Cui",
      "Yuxin Peng",
      "Xun Wang",
      "Manyu Zhu",
      "Jiahuan Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29055": {
    "title": "Inverse Weight-Balancing for Deep Long-Tailed Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenqi Dang",
      "Zhou Yang",
      "Weisheng Dong",
      "Xin Li",
      "Guangming Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29056": {
    "title": "Learn the Force We Can: Enabling Sparse Motion Control in Multi-Object Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aram Davtyan",
      "Paolo Favaro"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29057": {
    "title": "Iterative Regularization with k-support Norm: An Important Complement to Sparse Recovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "William de Vazelhes",
      "Bhaskar Mukhoty",
      "Xiao-Tong Yuan",
      "Bin Gu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29058": {
    "title": "SEA-GWNN: Simple and Effective Adaptive Graph Wavelet Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Swakshar Deb",
      "Sejuti Rahman",
      "Shafin Rahman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29059": {
    "title": "Self-Interpretable Graph Learning with Sufficient and Necessary Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiale Deng",
      "Yanyan Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29060": {
    "title": "Semi-supervised TEE Segmentation via Interacting with SAM Equipped with Noise-Resilient Prompting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sen Deng",
      "Yidan Feng",
      "Haoneng Lin",
      "Yiting Fan",
      "Alex Pui-Wai  Lee",
      "Xiaowei Hu",
      "Jing Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29061": {
    "title": "Peer Learning: Learning Complex Policies in Groups from Scratch via Action Recommendations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cedric Derstroff",
      "Mattia Cerrato",
      "Jannis Brugger",
      "Jan Peters",
      "Stefan Kramer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29062": {
    "title": "Conformal Autoregressive Generation: Beam Search with Coverage Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Deutschmann",
      "Marvin Alberts",
      "María Rodríguez Martínez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29063": {
    "title": "Exploiting Label Skews in Federated Learning with Model Concatenation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiqun Diao",
      "Qinbin Li",
      "Bingsheng He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29064": {
    "title": "Multi-View Randomized Kernel Classification via Nonconvex Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaojian Ding",
      "Fan Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29065": {
    "title": "Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Ding",
      "Yongwei Wang",
      "Zuheng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29066": {
    "title": "Shrinking Your TimeStep: Towards Low-Latency Neuromorphic Object Recognition with Spiking Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongqi Ding",
      "Lin Zuo",
      "Mengmeng Jing",
      "Pei He",
      "Yongjun Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29067": {
    "title": "DGA-GNN: Dynamic Grouping Aggregation GNN for Fraud Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingjiang Duan",
      "Tongya Zheng",
      "Yang Gao",
      "Gang Wang",
      "Zunlei Feng",
      "Xinyu Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29068": {
    "title": "Roll with the Punches: Expansion and Shrinkage of Soft Label Selection for Semi-supervised Fine-Grained Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Duan",
      "Zhen Zhao",
      "Lei Qi",
      "Luping Zhou",
      "Lei Wang",
      "Yinghuan Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29069": {
    "title": "Provably Powerful Graph Neural Networks for Directed Multigraphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Béni Egressy",
      "Luc von Niederhäusern",
      "Jovan Blanuša",
      "Erik Altman",
      "Roger Wattenhofer",
      "Kubilay Atasu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29070": {
    "title": "Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmad-Reza Ehyaei",
      "Kiarash Mohammadi",
      "Amir-Hossein Karimi",
      "Samira Samadi",
      "Golnoosh Farnadi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29071": {
    "title": "Double-Descent Curves in Neural Networks: A New Perspective Using Gaussian Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ouns El Harzli",
      "Bernardo Cuenca Grau",
      "Guillermo Valle-Pérez",
      "Ard A. Louis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29072": {
    "title": "A Score-Based Deterministic Diffusion Algorithm with Smooth Scores for General Distributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Karthik Elamvazhuthi",
      "Xuechen Zhang",
      "Matthew Jacobs",
      "Samet Oymak",
      "Fabio Pasqualetti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29073": {
    "title": "Feature Transportation Improves Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Moshe Eliasof",
      "Eldad Haber",
      "Eran Treister"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29074": {
    "title": "Exact Inference for Continuous-Time Gaussian Process Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katharina Ensinger",
      "Nicholas  Tagliapietra ",
      "Sebastian Ziesche",
      "Sebastian Trimpe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29075": {
    "title": "Learning Hybrid Dynamics Models with Simulator-Informed Latent States",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katharina Ensinger",
      "Sebastian Ziesche",
      "Sebastian Trimpe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29076": {
    "title": "PAC-Bayes Generalisation Bounds for Dynamical Systems including Stable RNNs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Deividas Eringis",
      "John Leth",
      "Zheng-Hua Tan",
      "Rafael Wisniewski",
      "Mihály Petreczky"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29077": {
    "title": "Non-parametric Representation Learning with Kernels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pascal Esser",
      "Maximilian Fleissner",
      "Debarghya Ghoshdastidar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29078": {
    "title": "Neural Gaussian Similarity Modeling for Differential Graph Structure Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaolong Fan",
      "Maoguo Gong",
      "Yue Wu",
      "Zedong Tang",
      "Jieyi Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29079": {
    "title": "Dynamic Sub-graph Distillation for Robust Semi-supervised Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Fan",
      "Yu Wang",
      "Pengfei Zhu",
      "Qinghua Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29080": {
    "title": "Selective Focus: Investigating Semantics Sensitivity in Post-training Quantization for Lane Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunqian Fan",
      "Xiuying Wei",
      "Ruihao Gong",
      "Yuqing Ma",
      "Xiangguo Zhang",
      "Qi Zhang",
      "Xianglong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29081": {
    "title": "Backdoor Adjustment via Group Adaptation for Debiased Coupon Recommendations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junpeng Fang",
      "Gongduo Zhang",
      "Qing Cui",
      "Caizhi Tang",
      "Lihong Gu",
      "Longfei Li",
      "Jinjie Gu",
      "Jun Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29082": {
    "title": "Improving GNN Calibration with Discriminative Ability: Insights and Strategies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujie Fang",
      "Xin Li",
      "Qianyu Chen",
      "Mingzhong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29083": {
    "title": "SUF: Stabilized Unconstrained Fine-Tuning for Offline-to-Online Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaheng Feng",
      "Mingxiao Feng",
      "Haolin Song",
      "Wengang Zhou",
      "Houqiang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29084": {
    "title": "BaCon: Boosting Imbalanced Semi-supervised Learning via Balanced Feature-Level Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qianhan Feng",
      "Lujing Xie",
      "Shijie Fang",
      "Tong Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29085": {
    "title": "Latent Diffusion Transformer for Probabilistic Time Series Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shibo Feng",
      "Chunyan Miao",
      "Zhong Zhang",
      "Peilin Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29086": {
    "title": "Partial Multi-View Clustering via Self-Supervised Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Feng",
      "Guoshuai Sheng",
      "Qianqian Wang",
      "Quanxue Gao",
      "Zhiqiang Tao",
      "Bo Dong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29087": {
    "title": "Harnessing Manycore Processors with Distributed Memory for Accelerated Training of Sparse and Recurrent Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan Finkbeiner",
      "Thomas Gmeinder",
      "Mark Pupilli",
      "Alexander Titterton",
      "Emre Neftci"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29088": {
    "title": "Graph Learning in 4D: A Quaternion-Valued Laplacian to Enhance Spectral GCNs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stefano Fiorini",
      "Stefano Coniglio",
      "Michele Ciavotta",
      "Enza Messina"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29089": {
    "title": "Learning Broadcast Protocols",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dana Fisman",
      "Noa Izsak",
      "Swen Jacobs"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29090": {
    "title": "Beyond Expected Return: Accounting for Policy Reproducibility When Evaluating Reinforcement Learning Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manon Flageat",
      "Bryan Lim",
      "Antoine Cully"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29091": {
    "title": "Symbolic Regression Enhanced Decision Trees for Classification Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kei Sen Fong",
      "Mehul Motani"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29092": {
    "title": "Fast Machine Unlearning without Retraining through Selective Synaptic Dampening",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jack Foster",
      "Stefan Schoepf",
      "Alexandra Brintrup"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29093": {
    "title": "Combinatorial Stochastic-Greedy Bandit",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fares Fourati",
      "Christopher John Quinn",
      "Mohamed-Slim Alouini",
      "Vaneet Aggarwal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29094": {
    "title": "REGLO: Provable Neural Network Repair for Global Robustness Properties",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feisi Fu",
      "Zhilu Wang",
      "Weichao Zhou",
      "Yixuan Wang",
      "Jiameng Fan",
      "Chao Huang",
      "Qi Zhu",
      "Xin Chen",
      "Wenchao Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29095": {
    "title": "QLABGrad: A Hyperparameter-Free and Convergence-Guaranteed Scheme for Deep Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghan Fu",
      "Fang-Xiang Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29096": {
    "title": "DTL: Disentangled Transfer Learning for Visual Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghao Fu",
      "Ke Zhu",
      "Jianxin Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29097": {
    "title": "Noise-Aware Image Captioning with Progressively Exploring Mismatched Words",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongtian Fu",
      "Kefei Song",
      "Luping Zhou",
      "Yang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29098": {
    "title": "Learning Small Decision Trees with Few Outliers: A Parameterized Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harmender Gahlawat",
      "Meirav Zehavi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29099": {
    "title": "Online Sensitivity Optimization in Differentially Private Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Filippo Galli",
      "Catuscia Palamidessi",
      "Tommaso Cucinotta"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29100": {
    "title": "Compressing Image-to-Image Translation GANs Using Local Density Structures on Their Learned Manifold",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alireza Ganjdanesh",
      "Shangqian Gao",
      "Hirad Alipanah",
      "Heng Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29101": {
    "title": "ACT: Empowering Decision Transformer with Dynamic Programming via Advantage Conditioning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen-Xiao Gao",
      "Chenyang Wu",
      "Mingjun Cao",
      "Rui Kong",
      "Zongzhang Zhang",
      "Yang Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29102": {
    "title": "Get a Head Start: On-Demand Pedagogical Policy Selection in Intelligent Tutoring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ge Gao",
      "Xi Yang",
      "Min  Chi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29103": {
    "title": "Rethinking Causal Relationships Learning in Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Gao",
      "Chengyu Yao",
      "Jiangmeng Li",
      "Lingyu Si",
      "Yifan Jin",
      "Fengge Wu",
      "Changwen Zheng",
      "Huaping Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29104": {
    "title": "AVSegFormer: Audio-Visual Segmentation with Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengyi Gao",
      "Zhe Chen",
      "Guo Chen",
      "Wenhai Wang",
      "Tong Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29105": {
    "title": "Eliciting Kemeny Rankings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anne-Marie George",
      "Christos Dimitrakakis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29106": {
    "title": "Interactive Hyperparameter Optimization in Multi-Objective Problems via Preference Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joseph Giovanelli",
      "Alexander Tornede",
      "Tanja Tornede",
      "Marius Lindauer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29107": {
    "title": "Layer Compression of Deep Networks with Straight Flows",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengyue Gong",
      "Xiaocong Du",
      "Bhargav Bhushanam",
      "Lemeng  Wu",
      "Xingchao Liu",
      "Dhruv Choudhary",
      "Arun Kejariwal",
      "Qiang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29108": {
    "title": "Fast and Controllable Post-training Sparsity: Learning Optimal Sparsity Allocation with Global Constraint in Minutes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruihao Gong",
      "Yang Yong",
      "Zining Wang",
      "Jinyang Guo",
      "Xiuying Wei",
      "Yuqing Ma",
      "Xianglong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29109": {
    "title": "DeepSaDe: Learning Neural Networks That Guarantee Domain Constraint Satisfaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kshitij Goyal",
      "Sebastijan Dumancic",
      "Hendrik Blockeel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29110": {
    "title": "Taming the Sigmoid Bottleneck: Provably Argmaxable Sparse Multi-Label Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andreas Grivas",
      "Antonio Vergari",
      "Adam Lopez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29111": {
    "title": "Summarizing Stream Data for Memory-Constrained Online Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianyang Gu",
      "Kai Wang",
      "Wei Jiang",
      "Yang You"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29112": {
    "title": "G-Adapter: Towards Structure-Aware Parameter-Efficient Transfer Learning for Graph Transformer Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anchun Gui",
      "Jinqiang Ye",
      "Han Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29113": {
    "title": "FedCSL: A Scalable and Accurate Approach to Federated Causal Structure Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianjie Guo",
      "Kui Yu",
      "Lin Liu",
      "Jiuyong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29114": {
    "title": "Ternary Spike: Learning Ternary Spikes for Spiking Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Guo",
      "Yuanpei Chen",
      "Xiaode Liu",
      "Weihang Peng",
      "Yuhan Zhang",
      "Xuhui Huang",
      "Zhe Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29115": {
    "title": "From Past to Future: Rethinking Eligibility Traces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dhawal Gupta",
      "Scott M. Jordan",
      "Shreyas Chaudhari",
      "Bo Liu",
      "Philip S. Thomas",
      "Bruno Castro da Silva"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29116": {
    "title": "Domain-Aware Fine-Tuning: Enhancing Neural Network Adaptability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seokhyeon Ha",
      "Sunbeom Jeong",
      "Jungwoo Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29117": {
    "title": "Forced Exploration in Bandit Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Han",
      "Li Zhu",
      "Fei Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29118": {
    "title": "Complexity of Neural Network Training and ETR: Extensions with Effectively Continuous Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Teemu Hankala",
      "Miika Hannula",
      "Juha Kontinen",
      "Jonni Virtema"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29119": {
    "title": "Composite Active Learning: Towards Multi-Domain Active Learning with Theoretical Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guang-Yuan Hao",
      "Hengguan Huang",
      "Haotian Wang",
      "Jie Gao",
      "Hao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29120": {
    "title": "Double-Layer Hybrid-Label Identification Feature Selection for Multi-View Multi-Label Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pingting Hao",
      "Kunpeng Liu",
      "Wanfu Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29121": {
    "title": "Multiagent Gumbel MuZero: Efficient Planning in Combinatorial Action Spaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaotian Hao",
      "Jianye Hao",
      "Chenjun Xiao",
      "Kai Li",
      "Dong Li",
      "Yan Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29122": {
    "title": "Calibrated One Round Federated Learning with Bayesian Inference in the Predictive Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohsin Hasan",
      "Guojun Zhang",
      "Kaiyang Guo",
      "Xi Chen",
      "Pascal Poupart"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29123": {
    "title": "Selective Deep Autoencoder for Unsupervised Feature Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wael Hassanieh",
      "Abdallah Chehade"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29124": {
    "title": "Fairness under Covariate Shift: Improving Fairness-Accuracy Tradeoff with Few Unlabeled Test Samples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shreyas Havaldar",
      "Jatin Chauhan",
      "Karthikeyan Shanmugam",
      "Jay Nandy",
      "Aravindan Raghuveer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29125": {
    "title": "A New Mechanism for Eliminating Implicit Conflict in Graph Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongxiao He",
      "Jitao Zhao",
      "Cuiying Huo",
      "Yongqi Huang",
      "Yuxiao Huang",
      "Zhiyong Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29126": {
    "title": "Improving Distinguishability of Class for Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongxiao He",
      "Shuwei Liu",
      "Meng Ge",
      "Zhizhi Yu",
      "Guangquan Xu",
      "Zhiyong Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29127": {
    "title": "Decoupling Meta-Reinforcement Learning with Gaussian Task Contexts and Skills",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongcai He",
      "Anjie Zhu",
      "Shuang Liang",
      "Feiyu Chen",
      "Jie Shao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29128": {
    "title": "IS-DARTS: Stabilizing DARTS through Precise Measurement on Candidate Importance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongyi He",
      "Longjun Liu",
      "Haonan Zhang",
      "Nanning Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29129": {
    "title": "Not All Tasks Are Equally Difficult: Multi-Task Deep Reinforcement Learning with Dynamic Depth Routing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinmin He",
      "Kai Li",
      "Yifan Zang",
      "Haobo Fu",
      "Qiang Fu",
      "Junliang Xing",
      "Jian Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29130": {
    "title": "Enhancing Semi-supervised Domain Adaptation via Effective Target Labeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiujun He",
      "Bin Liu",
      "Guosheng Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29131": {
    "title": "Generative Calibration of Inaccurate Annotation for Label Distribution Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang He",
      "Yunan Lu",
      "Weiwei Li",
      "Xiuyi Jia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29132": {
    "title": "Exploring Channel-Aware Typical Features for Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rundong He",
      "Yue Yuan",
      "Zhongyi Han",
      "Fan Wang",
      "Wan Su",
      "Yilong Yin",
      "Tongliang Liu",
      "Yongshun Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29133": {
    "title": "Learning Only When It Matters: Cost-Aware Long-Tailed Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-Cheng He",
      "Yao-Xiang Ding",
      "Han-Jia Ye",
      "Zhi-Hua Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29134": {
    "title": "SoundCount: Sound Counting from Raw Audio with Dyadic Decomposition Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhang He",
      "Zhuangzhuang Dai",
      "Niki Trigoni",
      "Long Chen",
      "Andrew Markham"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29135": {
    "title": "Training-Free Quantum Architecture Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhimin He",
      "Maijie Deng",
      "Shenggen Zheng",
      "Lvzhou Li",
      "Haozhen Situ"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29136": {
    "title": "Imitate the Good and Avoid the Bad: An Incremental Approach to Safe Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huy Hoang",
      "Tien Mai",
      "Pradeep Varakantham"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29137": {
    "title": "Few-Shot Learning via Repurposing Ensemble of Black-Box Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minh Hoang",
      "Trong Nghia Hoang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29138": {
    "title": "Transitivity-Preserving Graph Representation Learning for Bridging Local Connectivity and Role-Based Similarity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Van Thuy Hoang",
      "O-Joun Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29139": {
    "title": "Colored Noise in PPO: Improved Exploration and Performance through Correlated Action Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jakob Hollenstein",
      "Georg Martius",
      "Justus Piater"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29140": {
    "title": "Foreseeing Reconstruction Quality of Gradient Inversion: An Optimization Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeong Gwon Hong",
      "Yooshin Cho",
      "Hanbyel Cho",
      "Jaesung Ahn",
      "Junmo Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29141": {
    "title": "Complete Neural Networks for Complete Euclidean Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Snir Hordan",
      "Tal Amir",
      "Steven J. Gortler",
      "Nadav Dym"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29142": {
    "title": "Structured Probabilistic Coding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dou Hu",
      "Lingwei Wei",
      "Yaxin Liu",
      "Wei Zhou",
      "Songlin Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29143": {
    "title": "A Sequentially Fair Mechanism for Multiple Sensitive Attributes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francois Hu",
      "Philipp Ratz",
      "Arthur Charpentier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29144": {
    "title": "Relax Image-Specific Prompt Requirement in SAM: A Single Generic Prompt for Segmenting Camouflaged Objects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Hu",
      "Jiayi Lin",
      "Shaogang Gong",
      "Weitong Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29145": {
    "title": "Sequential Fusion Based Multi-Granularity Consistency for Space-Time Transformer Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Hu",
      "Wenjing Yang",
      "Wanrong Huang",
      "Xianchen Zhou",
      "Mingyu Cao",
      "Jing Ren",
      "Huibin Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29146": {
    "title": "FedMut: Generalized Federated Learning via Stochastic Mutation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Hu",
      "Yue Cao",
      "Anran Li",
      "Zhiming Li",
      "Chengwei Liu",
      "Tianlin Li",
      "Mingsong Chen",
      "Yang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29147": {
    "title": "PrefAce: Face-Centric Pretraining with Self-Structure Aware Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Hu",
      "Zheng Wang",
      "Peng Hu",
      "Xi Peng",
      "Jie Wu",
      "Hongyuan Zhu",
      "Yew Soon Ong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29148": {
    "title": "PA2D-MORL: Pareto Ascent Directional Decomposition Based Multi-Objective Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianmeng Hu",
      "Biao Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29149": {
    "title": "Spotting the Unseen: Reciprocal Consensus Network Guided by Visual Archetypes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenbo Hu",
      "Hongjian Zhan",
      "Xinchen Ma",
      "Yue Lu",
      "Ching Y. Suen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29150": {
    "title": "Terrain Diffusion Network: Climatic-Aware Terrain Generation with Geological Sketch Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zexin Hu",
      "Kun Hu",
      "Clinton Mo",
      "Lei Pan",
      "Zhiyong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29151": {
    "title": "Energy Efficient Streaming Time Series Classification with Attentive Power Iteration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Huang",
      "Tapan Shah",
      "Scott Evans",
      "Shinjae Yoo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29152": {
    "title": "SEC: More Accurate Clustering Algorithm via Structural Entropy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyu Huang",
      "Qilong Feng",
      "Jiahui Wang",
      "Ziyun Huang",
      "Jinhui Xu",
      "Jianxin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29153": {
    "title": "eTag: Class-Incremental Learning via Embedding Distillation and Task-Oriented Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Libo Huang",
      "Yan Zeng",
      "Chuanguang Yang",
      "Zhulin An",
      "Boyu Diao",
      "Yongjun Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29154": {
    "title": "PPO-Clip Attains Global Optimality: Towards Deeper Understandings of Clipping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nai-Chieh Huang",
      "Ping-Chun Hsieh",
      "Kuo-Hao Ho",
      "I-Chen Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29155": {
    "title": "HDMixer: Hierarchical Dependency with Extendable Patch for Multivariate Time Series Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihe Huang",
      "Lei Shen",
      "Ruixin Zhang",
      "Jiahuan Cheng",
      "Shouhong Ding",
      "Zhengyang Zhou",
      "Yang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29156": {
    "title": "Measuring Task Similarity and Its Implication in Fine-Tuning Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renhong Huang",
      "Jiarong Xu",
      "Xin Jiang",
      "Chenglu Pan",
      "Zhiming Yang",
      "Chunping Wang",
      "Yang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29157": {
    "title": "Factorized Explainer for Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rundong Huang",
      "Farhad Shirani",
      "Dongsheng Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29158": {
    "title": "Stochastic Bayesian Optimization with Unknown Continuous Context Distribution via Kernel Density Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaobin Huang",
      "Lei Song",
      "Ke Xue",
      "Chao Qian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29159": {
    "title": "One Step Learning, One Step Review",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaolong Huang",
      "Qiankun Li",
      "Xueran Li",
      "Xuesong Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29160": {
    "title": "Higher-Order Graph Convolutional Network with Flower-Petals Laplacians on Simplicial Complexes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiming Huang",
      "Yujie Zeng",
      "Qiang Wu",
      "Linyuan Lü"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29161": {
    "title": "Protein 3D Graph Structure Learning for Robust Structure-Based Protein Property Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Huang",
      "Siyuan Li",
      "Lirong Wu",
      "Jin Su",
      "Haitao Lin",
      "Odin Zhang",
      "Zihan Liu",
      "Zhangyang Gao",
      "Jiangbin Zheng",
      "Stan Z. Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29162": {
    "title": "Binding-Adaptive Diffusion Models for Structure-Based Drug Design",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhilin Huang",
      "Ling Yang",
      "Zaixi Zhang",
      "Xiangxin Zhou",
      "Yu Bao",
      "Xiawu Zheng",
      "Yuwei Yang",
      "Yu Wang",
      "Wenming Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29163": {
    "title": "Optimal Survival Trees: A Dynamic Programming Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tim Huisman",
      "Jacobus G. M. van der Linden",
      "Emir Demirović"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29164": {
    "title": "ProCC: Progressive Cross-Primitive Compatibility for Open-World Compositional Zero-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fushuo Huo",
      "Wenchao Xu",
      "Song Guo",
      "Jingcai Guo",
      "Haozhao Wang",
      "Ziming Liu",
      "Xiaocheng Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29165": {
    "title": "Non-exemplar Online Class-Incremental Continual Learning via Dual-Prototype Self-Augment and Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fushuo Huo",
      "Wenchao Xu",
      "Jingcai Guo",
      "Haozhao Wang",
      "Yunfeng Fan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29166": {
    "title": "New Classes of the Greedy-Applicable Arm Feature Distributions in the Sparse Linear Bandit Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Koji Ichikawa",
      "Shinji Ito",
      "Daisuke Hatano",
      "Hanna Sumita",
      "Takuro Fukunaga",
      "Naonori Kakimura",
      "Ken-ichi Kawarabayashi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29167": {
    "title": "Fairness without Demographics through Shared Latent Space-Based Debiasing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rashidul Islam",
      "Huiyuan Chen",
      "Yiwei Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29168": {
    "title": "TMPNN: High-Order Polynomial Regression Based on Taylor Map Factorization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrei Ivanov",
      "Stefan Ailuro"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29169": {
    "title": "Personalized Reinforcement Learning with a Budget of Policies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dmitry Ivanov",
      "Omer Ben-Porat"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29170": {
    "title": "Delivering Inflated Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yacine Izza",
      "Alexey Ignatiev",
      "Peter J. Stuckey",
      "Joao Marques-Silva"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29171": {
    "title": "Unified Framework for Diffusion Generative Models in SO(3): Applications in Computer Vision and Astrophysics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yesukhei Jagvaral",
      "Francois Lanusse",
      "Rachel Mandelbaum"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29172": {
    "title": "GO-DICE: Goal-Conditioned Option-Aware Offline Imitation Learning via Stationary Distribution Correction Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhinav Jain",
      "Vaibhav Unhelkar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29173": {
    "title": "Instance-Conditional Timescales of Decay for Non-Stationary Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nishant  Jain",
      "Pradeep Shenoy"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29174": {
    "title": "Universal Weak Coreset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ragesh Jaiswal",
      "Amit Kumar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29175": {
    "title": "Transportable Representations for Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kasra Jalaldoust",
      "Elias Bareinboim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29176": {
    "title": "Meta-Learning-Based Adaptive Stability Certificates for Dynamical Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amit Jena",
      "Dileep Kalathil",
      "Le Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29177": {
    "title": "Rethinking Dimensional Rationale in Graph Contrastive Learning from Causal Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qirui Ji",
      "Jiangmeng Li",
      "Jie Hu",
      "Rui Wang",
      "Changwen Zheng",
      "Fanjiang Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29178": {
    "title": "MusER: Musical Element-Based Regularization for Generating Symbolic Music with Emotion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shulei Ji",
      "Xinyu Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29179": {
    "title": "FedFixer: Mitigating Heterogeneous Label Noise in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyuan Ji",
      "Zhaowei Zhu",
      "Wei Xi",
      "Olga Gadyatskaya",
      "Zilong Song",
      "Yong Cai",
      "Yang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29180": {
    "title": "Stratified GNN Explanations through Sufficient Expansion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuwen Ji",
      "Lei Shi",
      "Zhimeng Liu",
      "Ge Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29181": {
    "title": "FedLPS: Heterogeneous Federated Learning for Multiple Tasks with Local Parameter Sharing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongzhe Jia",
      "Xuyun Zhang",
      "Amin Beheshti",
      "Wanchun Dou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29182": {
    "title": "Long-Tailed Partial Label Learning by Head Classifier and Tail Classifier Cooperation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuheng Jia",
      "Xiaorui Peng",
      "Ran Wang",
      "Min-Ling Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29183": {
    "title": "Which Is More Effective in Label Noise Cleaning, Correction or Filtering?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gaoxia Jiang",
      "Jia Zhang",
      "Xuefei Bai",
      "Wenjian Wang",
      "Deyu Meng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29184": {
    "title": "Navigating Real-World Partial Label Learning: Unveiling Fine-Grained Images with Attributes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Jiang",
      "Zhihao Sun",
      "YingJie Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29185": {
    "title": "DHGCN: Dynamic Hop Graph Convolution Network for Self-Supervised Point Cloud Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jincen Jiang",
      "Lizhi Zhao",
      "Xuequan Lu",
      "Wei Hu",
      "Imran Razzak",
      "Meili Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29186": {
    "title": "FMRNet: Image Deraining via Frequency Mutual Revision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kui Jiang",
      "Junjun Jiang",
      "Xianming Liu",
      "Xin Xu",
      "Xianzheng Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29187": {
    "title": "Racing Control Variable Genetic Programming for Symbolic Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nan Jiang",
      "Yexiang Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29188": {
    "title": "Learning Diverse Risk Preferences in Population-Based Self-Play",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhua Jiang",
      "Qihan Liu",
      "Xiaoteng Ma",
      "Chenghao Li",
      "Yiqin Yang",
      "Jun Yang",
      "Bin Liang",
      "Qianchuan Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29189": {
    "title": "Deep Incomplete Multi-View Learning Network with Insufficient Label Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangqi Jiang",
      "Tingjin Luo",
      "Xinyan Liang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29190": {
    "title": "Provably Convergent Federated Trilevel Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Jiao",
      "Kai Yang",
      "Tiancheng Wu",
      "Chengtao Jian",
      "Jianwei Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29191": {
    "title": "Performative Federated Learning: A Solution to Model-Dependent and Heterogeneous Distribution Shifts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Jin",
      "Tongxin Yin",
      "Zhongzhu Chen",
      "Zeyu Sun",
      "Xueru Zhang",
      "Yang Liu",
      "Mingyan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29192": {
    "title": "Fractional Deep Reinforcement Learning for Age-Minimal Mobile Edge Computing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lyudong Jin",
      "Ming Tang",
      "Meng Zhang",
      "Hao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29193": {
    "title": "Finite-Time Frequentist Regret Bounds of Multi-Agent Thompson Sampling on Sparse Hypergraphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyuan Jin",
      "Hao-Lun Hsu",
      "William Chang",
      "Pan Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29194": {
    "title": "GLDL: Graph Label Distribution Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Jin",
      "Richard Gao",
      "Yi He",
      "Xingquan Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29195": {
    "title": "Sterling: Synergistic Representation Learning on Bipartite Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baoyu Jing",
      "Yuchen Yan",
      "Kaize Ding",
      "Chanyoung Park",
      "Yada Zhu",
      "Huan Liu",
      "Hanghang Tong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29196": {
    "title": "FoX: Formation-Aware Exploration in Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yonghyeon Jo",
      "Sunwoo Lee",
      "Junghyuk Yeom",
      "Seungyul Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29197": {
    "title": "FLAME: A Small Language Model for Spreadsheet Formulas",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harshit Joshi",
      "Abishai Ebenezer",
      "José Cambronero Sanchez",
      "Sumit Gulwani",
      "Aditya Kanade",
      "Vu Le",
      "Ivan Radiček",
      "Gust Verbruggen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29198": {
    "title": "Towards Safe Policy Learning under Partial Identifiability: A Causal Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shalmali Joshi",
      "Junzhe Zhang",
      "Elias Bareinboim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29199": {
    "title": "Patch-Wise Graph Contrastive Learning for Image Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chanyong Jung",
      "Gihyun Kwon",
      "Jong Chul Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29200": {
    "title": "NN-Steiner: A Mixed Neural-Algorithmic Approach for the Rectilinear Steiner Minimum Tree Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrew B. Kahng",
      "Robert R. Nerem",
      "Yusu Wang",
      "Chien-Yi Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29201": {
    "title": "Measuring Self-Supervised Representation Quality for Downstream Classification Using Discriminative Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neha Kalibhat",
      "Kanika Narang",
      "Hamed Firooz",
      "Maziar Sanjabi",
      "Soheil Feizi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29202": {
    "title": "Recall-Oriented Continual Learning with Generative Adversarial Meta-Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haneol Kang",
      "Dong-Wan Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29203": {
    "title": "Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiyu Kang",
      "Kai Zhao",
      "Yang Song",
      "Yihang Xie",
      "Yanan Zhao",
      "Sijie Wang",
      "Rui She",
      "Wee Peng Tay"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29204": {
    "title": "Neural Oscillators for Generalization of Physics-Informed Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taniya Kapoor",
      "Abhishek Chandra",
      "Daniel M. Tartakovsky",
      "Hongrui Wang",
      "Alfredo Nunez",
      "Rolf Dollevoet"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29205": {
    "title": "SHAP@k: Efficient and Probably Approximately Correct (PAC) Identification of Top-K Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanjay Kariyappa",
      "Leonidas Tsepenekas",
      "Freddy Lécué",
      "Daniele Magazzeni"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29206": {
    "title": "Communication-Efficient Collaborative Regret Minimization in Multi-Armed Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikolai Karpov",
      "Qin Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29207": {
    "title": "Adversarially Balanced Representation for Continuous Treatment Effect Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amirreza Kazemi",
      "Martin Ester"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29208": {
    "title": "Shaping Up SHAP: Enhancing Stability through Layer-Wise Neighbor Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gwladys Kelodjou",
      "Laurence Rozé",
      "Véronique Masson",
      "Luis Galárraga",
      "Romaric Gaudel",
      "Maurice Tchuente",
      "Alexandre Termier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29209": {
    "title": "IOFM: Using the Interpolation Technique on the Over-Fitted Models to Identify Clean-Annotated Samples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongha Kim",
      "Yongchan Choi",
      "Kunwoong Kim",
      "Ilsang Ohn",
      "Yongdai Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29210": {
    "title": "When Model Meets New Normals: Test-Time Adaptation for Unsupervised Time-Series Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongmin Kim",
      "Sunghyun  Park",
      "Jaegul Choo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29211": {
    "title": "Adaptive Shortcut Debiasing for Online Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Doyoung Kim",
      "Dongmin Park",
      "Yooju Shin",
      "Jihwan Bang",
      "Hwanjun Song",
      "Jae-Gil Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29212": {
    "title": "MetaMix: Meta-State Precision Searcher for Mixed-Precision Activation Quantization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han-Byul Kim",
      "Joo Hyung Lee",
      "Sungjoo Yoo",
      "Hong-Seok Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29213": {
    "title": "Curved Representation Space of Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juyeop Kim",
      "Junha Park",
      "Songkuk Kim",
      "Jong-Seok Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29214": {
    "title": "Robust Distributed Gradient Aggregation Using Projections onto Gradient Manifolds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kwang In Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29215": {
    "title": "Stitching Sub-trajectories with Conditional Diffusion Model for Goal-Conditioned Offline RL",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sungyoon Kim",
      "Yunseon Choi",
      "Daiki E. Matsunaga",
      "Kee-Eung Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29216": {
    "title": "Cross-Class Feature Augmentation for Class Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taehoon Kim",
      "Jaeyoo Park",
      "Bohyung Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29217": {
    "title": "Robust Policy Learning via Offline Skill Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Woo Kyung Kim",
      "Minjong Yoo",
      "Honguk Woo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29218": {
    "title": "Relaxed Stationary Distribution Correction Estimation for Improved Offline Policy Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Woosung Kim",
      "Donghyeon Ki",
      "Byung-Jun Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29219": {
    "title": "Structure-Aware Multimodal Sequential Learning for Visual Dialog",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Young-Jin Kim",
      "Min-Jun Kim",
      "Kyunghwan An",
      "Jinwoo Ahn",
      "Jaeseok Kim",
      "Yu-Jung Heo",
      "Du-Seong Chang",
      "Eun-Sol Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29220": {
    "title": "A Class of Topological Pseudodistances for Fast Comparison of Persistence Diagrams",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rolando Kindelan Nuñez",
      "Mircea Petrache",
      "Mauricio Cerda",
      "Nancy Hitschfeld"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29221": {
    "title": "SALSA: Semantically-Aware Latent Space Autoencoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kathryn E. Kirchoff",
      "Travis Maxfield",
      "Alexander Tropsha",
      "Shawn M. Gomez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29222": {
    "title": "Principle Component Trees and Their Persistent Homology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ben Kizaric",
      "Daniel Pimentel-Alarcón"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29223": {
    "title": "Pantypes: Diverse Representatives for Self-Explainable Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rune Kjærsgaard",
      "Ahcène Boubekki",
      "Line Clemmensen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29224": {
    "title": "Shuffled Deep Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Masahiro Kohjima"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29225": {
    "title": "Approximating the Shapley Value without Marginal Contributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Kolpaczki",
      "Viktor Bengs",
      "Maximilian Muschalik",
      "Eyke Hüllermeier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29226": {
    "title": "Improved Bandits in Many-to-One Matching Markets with Incentive Compatibility",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fang Kong",
      "Shuai Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29227": {
    "title": "Unknown-Aware Graph Regularization for Robust Semi-supervised Learning from Uncurated Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heejo Kong",
      "Suneung Kim",
      "Ho-Joong Kim",
      "Seong-Whan Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29228": {
    "title": "Ghost Noise for Regularizing Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atli Kosson",
      "Dongyang Fan",
      "Martin Jaggi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29229": {
    "title": "Zero-Shot Task Adaptation with Relevant Feature Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atsutoshi Kumagai",
      "Tomoharu Iwata",
      "Yasuhiro Fujiwara"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29230": {
    "title": "Friendly Attacks to Improve Channel Coding Reliability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anastasiia Kurmukova",
      "Deniz Gunduz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29231": {
    "title": "Evolving Parameterized Prompt Memory for Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Rifki  Kurniawan",
      "Xiang Song",
      "Zhiheng Ma",
      "Yuhang He",
      "Yihong Gong",
      "Yang  Qi",
      "Xing Wei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29232": {
    "title": "AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joonwoo Kwon",
      "Sooyoung  Kim",
      "Yuewei Lin",
      "Shinjae Yoo",
      "Jiook Cha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29233": {
    "title": "HDformer: A Higher-Dimensional Transformer for Detecting Diabetes Utilizing Long-Range Vascular Signals",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ella Lan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29234": {
    "title": "Generative Model Perception Rectification Algorithm for Trade-Off between Diversity and Quality",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guipeng Lan",
      "Shuai Xiao",
      "Jiachen Yang",
      "Jiabao Wen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29235": {
    "title": "CoLAL: Co-learning Active Learning for Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linh Le",
      "Genghong Zhao",
      "Xia Zhang",
      "Guido Zuccon",
      "Gianluca Demartini"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29236": {
    "title": "Doubly Perturbed Task Free Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Byung Hyun Lee",
      "Min-hwan Oh",
      "Se Young Chun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29237": {
    "title": "OWQ: Outlier-Aware Weight Quantization for Efficient Fine-Tuning and Inference of Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changhun Lee",
      "Jungyu Jin",
      "Taesu Kim",
      "Hyungjun Kim",
      "Eunhyeok Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29238": {
    "title": "DiSCO: Diffusion Schrödinger Bridge for Molecular Conformer Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Danyeong Lee",
      "Dohoon Lee",
      "Dongmin Bang",
      "Sun Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29239": {
    "title": "Spear and Shield: Adversarial Attacks and Defense Methods for Model-Based Link Prediction on Continuous-Time Dynamic Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongjin Lee",
      "Juho Lee",
      "Kijung Shin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29240": {
    "title": "The Choice of Noninformative Priors for Thompson Sampling in Multiparameter Bandit Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jongyeong Lee",
      "Chao-Kai Chiang",
      "Masashi Sugiyama"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29241": {
    "title": "Learning Uncertainty-Aware Temporally-Extended Actions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joongkyu Lee",
      "Seung Joon Park",
      "Yunhao Tang",
      "Min-hwan Oh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29242": {
    "title": "Any-Way Meta Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "JunHoo Lee",
      "Yearim Kim",
      "Hyunho Lee",
      "Nojun Kwak"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29243": {
    "title": "Mixed-Effects Contextual Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyungbok Lee",
      "Myunghee Cho Paik",
      "Min-hwan Oh",
      "Gi-Soo Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29244": {
    "title": "Proxyformer: Nyström-Based Linear Transformer with Trainable Proxy Tokens",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sangho Lee",
      "Hayun Lee",
      "Dongkun Shin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29245": {
    "title": "Multi-Architecture Multi-Expert Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunsung Lee",
      "JinYoung Kim",
      "Hyojun Go",
      "Myeongho Jeong",
      "Shinhyeok Oh",
      "Seungtaek Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29246": {
    "title": "PC-Conv: Unifying Homophily and Heterophily with Two-Fold Filtering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingheng Li",
      "Erlin Pan",
      "Zhao Kang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29247": {
    "title": "All Beings Are Equal in Open Set Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaohua Li",
      "Enhao Zhang",
      "Chuanxing Geng",
      "Songcan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29248": {
    "title": "GxVAEs: Two Joint VAEs Generate Hit Molecules from Gene Expression Profiles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Li",
      "Yoshihiro Yamanishi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29249": {
    "title": "Towards Continual Learning Desiderata via HSIC-Bottleneck Orthogonalization and Equiangular Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Depeng Li",
      "Tianqi Wang",
      "Junwei Chen",
      "Qining Ren",
      "Kenji Kawaguchi",
      "Zhigang Zeng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29250": {
    "title": "Regroup Median Loss for Combating Label Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengpeng Li",
      "Kemou Li",
      "Jinyu Tian",
      "Jiantao Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29251": {
    "title": "Parsing All Adverse Scenes: Severity-Aware Semantic Segmentation with Mask-Enhanced Cross-Domain Consistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fuhao Li",
      "Ziyang Gong",
      "Yupeng Deng",
      "Xianzheng Ma",
      "Renrui Zhang",
      "Zhenming Ji",
      "Xiangwei Zhu",
      "Hong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29252": {
    "title": "Learning Spatially Collaged Fourier Bases for Implicit Neural Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jason Chun Lok Li",
      "Chang Liu",
      "Binxiao Huang",
      "Ngai Wong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29253": {
    "title": "High-Dimensional Analysis for Generalized Nonlinear Regression: From Asymptotics to Algorithm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Li",
      "Yong Liu",
      "Weiping Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29254": {
    "title": "FedNS: A Fast Sketching Newton-Type Algorithm for Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Li",
      "Yong Liu",
      "Weiping Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29255": {
    "title": "Hierarchical Topology Isomorphism Expertise Embedded Graph Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangmeng Li",
      "Yifan Jin",
      "Hang Gao",
      "Wenwen Qiang",
      "Changwen Zheng",
      "Fuchun Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29256": {
    "title": "Curriculum-Enhanced Residual Soft An-Isotropic Normalization for Over-Smoothness in Deep GNNs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin Li",
      "Qirong Zhang",
      "Shuling Xu",
      "Xinlong Chen",
      "Longkun Guo",
      "Yang-Geng Fu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29257": {
    "title": "Tensorized Label Learning on Anchor Graph",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Li",
      "Quanxue Gao",
      "Qianqian Wang",
      "Wei Xia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29258": {
    "title": "EMGAN: Early-Mix-GAN on Extracting Server-Side Model in Split Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingtao Li",
      "Xing Chen",
      "Li Yang",
      "Adnan Siraj Rakin",
      "Deliang Fan",
      "Chaitali Chakrabarti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29259": {
    "title": "Contrastive Continual Learning with Importance Sampling and Prototype-Instance Relation Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiyong Li",
      "Dilshod Azizov",
      "Yang LI",
      "Shangsong Liang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29260": {
    "title": "Twice Class Bias Correction for Imbalanced Semi-supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lan Li",
      "Bowen Tao",
      "Lu Han",
      "De-chuan Zhan",
      "Han-jia Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29261": {
    "title": "Dynamic Regret of Adversarial MDPs with Unknown Transition and Linear Function Approximation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Long-Fei Li",
      "Peng Zhao",
      "Zhi-Hua Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29262": {
    "title": "Feature Fusion from Head to Tail for Long-Tailed Visual Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengke Li",
      "Zhikai HU",
      "Yang Lu",
      "Weichao Lan",
      "Yiu-ming Cheung",
      "Hui Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29263": {
    "title": "Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingxin Li",
      "Richong Zhang",
      "Zhijie Nie",
      "Yongyi Mao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29264": {
    "title": "AdapterGNN: Parameter-Efficient Fine-Tuning Improves Generalization in GNNs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengrui Li",
      "Xueting Han",
      "Jing Bai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29265": {
    "title": "Robust Visual Imitation Learning with Inverse Dynamics Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Li",
      "Xun Wang",
      "Rongchang Zuo",
      "Kewu Sun",
      "Lingfei Cui",
      "Jishiyu Ding",
      "Peng Liu",
      "Zhe Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29266": {
    "title": "Cumulative Difference Learning VAE for Time-Series with Temporally Correlated Inflow-Outflow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianchun Li",
      "Chengxiang Wu",
      "Pengyi Shi",
      "Xiaoqian Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29267": {
    "title": "Federated X-armed Bandit",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjie Li",
      "Qifan Song",
      "Jean Honorio",
      "Guang Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29268": {
    "title": "Unsupervised Training Sequence Design: Efficient and Generalizable Agent Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjun Li",
      "Pradeep Varakantham"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29269": {
    "title": "Image Content Generation with Causal Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaochuan Li",
      "Baoyu Fan",
      "Runze Zhang",
      "Liang Jin",
      "Di Wang",
      "Zhenhua Guo",
      "Yaqian Zhao",
      "Rengang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29270": {
    "title": "Deep Active Learning with Noise Stability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingjian Li",
      "Pengkun Yang",
      "Yangcheng Gu",
      "Xueying Zhan",
      "Tianyang Wang",
      "Min Xu",
      "Chengzhong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29271": {
    "title": "Distribution-Conditioned Adversarial Variational Autoencoder for Valid Instrumental Variable Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinshu Li",
      "Lina Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29272": {
    "title": "Agile Multi-Source-Free Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyao Li",
      "Jingjing Li",
      "Fengling Li",
      "Lei Zhu",
      "Ke Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29273": {
    "title": "Towards Effective and General Graph Unlearning via Mutual Evolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xunkai Li",
      "Yulin Zhao",
      "Zhengyu Wu",
      "Wentao Zhang",
      "Rong-Hua Li",
      "Guoren Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29274": {
    "title": "Component Fourier Neural Operator for Singularly Perturbed Differential Equations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ye Li",
      "Ting Du",
      "Yiwen Pang",
      "Zhongyi Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29275": {
    "title": "Learning to Prompt Knowledge Transfer for Open-World Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujie Li",
      "Xin Yang",
      "Hao Wang",
      "Xiangkun Wang",
      "Tianrui Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29276": {
    "title": "SPD-DDPM: Denoising Diffusion Probabilistic Models in the Symmetric Positive Definite Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunchen Li",
      "Zhou Yu",
      "Gaoqi He",
      "Yunhang Shen",
      "Ke Li",
      "Xing Sun",
      "Shaohui Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29277": {
    "title": "Backpropagation Through Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Li",
      "Wenshuai Zhao",
      "Lijun Wu",
      "Joni Pajarinen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29278": {
    "title": "Multi-Granularity Causal Structure Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxuan Liang",
      "Jun Wang",
      "Guoxian Yu",
      "Shuyin Xia",
      "Guoyin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29279": {
    "title": "Inducing Clusters Deep Kernel Gaussian Process for Longitudinal Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Liang",
      "Weijieying Ren",
      "Hanifi Sahar",
      "Vasant Honavar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29280": {
    "title": "Self-Supervised Multi-Modal Knowledge Graph Contrastive Hashing for Cross-Modal Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meiyu Liang",
      "Junping Du",
      "Zhengyang Liang",
      "Yongwang Xing",
      "Wei Huang",
      "Zhe Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29281": {
    "title": "DC-NAS: Divide-and-Conquer Neural Architecture Search for Multi-Modal Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyan Liang",
      "Pinhan Fu",
      "Qian Guo",
      "Keyin Zheng",
      "Yuhua Qian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29282": {
    "title": "Value at Adversarial Risk: A Graph Defense Strategy against Cost-Aware Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junlong Liao",
      "Wenda Fu",
      "Cong Wang",
      "Zhongyu Wei",
      "Jiarong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29283": {
    "title": "Invariant Random Forest: Tree-Based Model Solution for OOD Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufan Liao",
      "Qi Wu",
      "Xing Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29284": {
    "title": "Ahpatron: A New Budgeted Online Kernel Learning Machine with Tighter Mistake Bound",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun Liao",
      "Junfan Li",
      "Shizhong Liao",
      "Qinghua Hu",
      "Jianwu Dang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29285": {
    "title": "Spiking NeRF: Representing the Real-World Geometry by a Discontinuous Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhanfeng Liao",
      "Yan Liu",
      "Qian Zheng",
      "Gang Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29286": {
    "title": "Mitigating Label Noise through Data Ambiguation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julian Lienen",
      "Eyke Hüllermeier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29287": {
    "title": "Episodic Return Decomposition by Difference of Implicitly Assigned Sub-trajectory Reward",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoxin Lin",
      "Hongqiu Wu",
      "Jiaji Zhang",
      "Yihao Sun",
      "Junyin Ye",
      "Yang Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29288": {
    "title": "Jointly Modeling Spatio-Temporal Features of Tactile Signals for Action Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jimmy Lin",
      "Junkai Li",
      "Jiasi Gao",
      "Weizhi Ma",
      "Yang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29289": {
    "title": "ERL-TD: Evolutionary Reinforcement Learning Enhanced with Truncated Variance and Distillation Mutation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiuzhen Lin",
      "Yangfan Chen",
      "Lijia Ma",
      "Wei-Neng Chen",
      "Jianqiang  Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29290": {
    "title": "Hypergraph Neural Architecture Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Lin",
      "Xu Peng",
      "Zhengtao Yu",
      "Taisong Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29291": {
    "title": "Scaling Few-Shot Learning for the Open World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhipeng Lin",
      "Wenjing Yang",
      "Haotian Wang",
      "Haoang Chi",
      "Long Lan",
      "Ji Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29292": {
    "title": "Towards Inductive Robustness: Distilling and Fostering Wave-Induced Resonance in Transductive GCNs against Graph Adversarial Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ao Liu",
      "Wenshan Li",
      "Tao Li",
      "Beibei Li",
      "Hanyuan Huang",
      "Pan Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29293": {
    "title": "Attention-Induced Embedding Imputation for Incomplete Multi-View Partial Multi-Label Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengliang Liu",
      "Jinlong Jia",
      "Jie Wen",
      "Yabo Liu",
      "Xiaoling Luo",
      "Chao Huang",
      "Yong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29294": {
    "title": "Learning Temporal Resolution in Spectrogram for Audio Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haohe Liu",
      "Xubo Liu",
      "Qiuqiang Kong",
      "Wenwu Wang",
      "Mark D. Plumbley"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29295": {
    "title": "Language-Guided Transformer for Federated Multi-Label Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "I-Jieh Liu",
      "Ci-Siang Lin",
      "Fu-En Yang",
      "Yu-Chiang Frank Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29296": {
    "title": "UPDP: A Unified Progressive Depth Pruner for CNN and Vision Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ji Liu",
      "Dehua Tang",
      "Yuanxian Huang",
      "Li Zhang",
      "Xiaocheng Zeng",
      "Dong Li",
      "Mingjie Lu",
      "Jinzhang Peng",
      "Yu Wang",
      "Fan Jiang",
      "Lu Tian",
      "Ashish Sirasao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29297": {
    "title": "FedASMU: Efficient Asynchronous Federated Learning with Dynamic Staleness-Aware Model Update",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ji Liu",
      "Juncheng Jia",
      "Tianshi Che",
      "Chao Huo",
      "Jiaxiang Ren",
      "Yang Zhou",
      "Huaiyu Dai",
      "Dejing Dou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29298": {
    "title": "Towards Making Learnware Specification and Market Evolvable",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian-Dong Liu",
      "Zhi-Hao Tan",
      "Zhi-Hua  Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29299": {
    "title": "TimesURL: Self-Supervised Contrastive Learning for Universal Time Series Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiexi Liu",
      "Songcan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29300": {
    "title": "Faster Stochastic Variance Reduction Methods for Compositional MiniMax Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin Liu",
      "Xiaokang Pan",
      "Junwen Duan",
      "Hong-Dong Li",
      "Youqi Li",
      "Zhe Qu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29301": {
    "title": "Sketched Newton Value Iteration for Large-Scale Markov Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinsong Liu",
      "Chenghan Xie",
      "Qi Deng",
      "Dongdong Ge",
      "Yinyu Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29302": {
    "title": "Beyond OOD State Actions: Supported Cross-Domain Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinxin Liu",
      "Ziqi Zhang",
      "Zhenyu Wei",
      "Zifeng Zhuang",
      "Yachen Kang",
      "Sibo Gai",
      "Donglin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29303": {
    "title": "OVD-Explorer: Optimism Should Not Be the Sole Pursuit of Exploration in Noisy Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyi Liu",
      "Zhi Wang",
      "Yan Zheng",
      "Jianye Hao",
      "Chenjia Bai",
      "Junjie  Ye",
      "Zhen Wang",
      "Haiyin Piao",
      "Yang Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29304": {
    "title": "Rethinking Propagation for Unsupervised Graph Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meihan Liu",
      "Zeyu Fang",
      "Zhen Zhang",
      "Ming Gu",
      "Sheng Zhou",
      "Xin Wang",
      "Jiajun Bu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29305": {
    "title": "ECHO-GL: Earnings Calls-Driven Heterogeneous Graph Learning for Stock Movement Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengpu Liu",
      "Mengying Zhu",
      "Xiuyuan Wang",
      "Guofang Ma",
      "Jianwei Yin",
      "Xiaolin Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29306": {
    "title": "Decentralized Scheduling with QoS Constraints: Achieving O(1) QoS Regret of Multi-Player Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingsong Liu",
      "Zhixuan Fang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29307": {
    "title": "ASWT-SGNN: Adaptive Spectral Wavelet Transform-Based Self-Supervised Graph Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruyue Liu",
      "Rong Yin",
      "Yong Liu",
      "Weiping Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29308": {
    "title": "Density Matters: Improved Core-Set for Active Domain Adaptive Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shizhan Liu",
      "Zhengkai Jiang",
      "Yuxi Li",
      "Jinlong Peng",
      "Yabiao Wang",
      "Weiyao Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29309": {
    "title": "RPSC: Robust Pseudo-Labeling for Semantic Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sihang Liu",
      "Wenming Cao",
      "Ruigang Fu",
      "Kaixiang Yang",
      "Zhiwen Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29310": {
    "title": "Sample-Level Cross-View Similarity Learning for Incomplete Multi-View Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suyuan Liu",
      "Junpu Zhang",
      "Yi Wen",
      "Xihong Yang",
      "Siwei Wang",
      "Yi Zhang",
      "En Zhu",
      "Chang Tang",
      "Long Zhao",
      "Xinwang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29311": {
    "title": "UFDA: Universal Federated Domain Adaptation with Practical Assumptions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinhui Liu",
      "Zhenghao Chen",
      "Luping Zhou",
      "Dong Xu",
      "Wei Xi",
      "Gairui Bai",
      "Yihan Zhao",
      "Jizhong Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29312": {
    "title": "Unify Named Entity Recognition Scenarios via Contrastive Real-Time Updating Prototype",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanhe Liu",
      "Peng Wang",
      "Wenjun Ke",
      "Guozheng Li",
      "Xiye Chen",
      "Jiteng Zhao",
      "Ziyu Shang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29313": {
    "title": "Effect Size Estimation for Duration Recommendation in Online Experiments: Leveraging Hierarchical Models and Objective Utility Approaches",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Liu",
      "Runzhe Wan",
      "James McQueen",
      "Doug Hains",
      "Jinxiang Gu",
      "Rui Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29314": {
    "title": "Causality-Inspired Invariant Representation Learning for Text-Based Person Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Liu",
      "Guihe Qin",
      "Haipeng Chen",
      "Zhiyong Cheng",
      "Xun Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29315": {
    "title": "Detection-Based Intermediate Supervision for Visual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhang Liu",
      "Daowan Peng",
      "Wei Wei",
      "Yuanyuan Fu",
      "Wenfeng Xie",
      "Dangyang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29316": {
    "title": "Text Diffusion with Reinforced Conditioning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Liu",
      "Tianchi Yang",
      "Shaohan Huang",
      "Zihan Zhang",
      "Haizhen Huang",
      "Furu Wei",
      "Weiwei Deng",
      "Feng Sun",
      "Qi Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29317": {
    "title": "Diffusion Language-Shapelets for Semi-supervised Time-Series Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Liu",
      "Wenbin Pei",
      "Disen Lan",
      "Qianli Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29318": {
    "title": "Decentralized Sum-of-Nonconvex Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuanghua Liu",
      "Bryan Kian Hsiang Low"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29319": {
    "title": "Incremental Quasi-Newton Methods with Faster Superlinear Convergence Rates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuanghua Liu",
      "Luo Luo",
      "Bryan Kian Hsiang Low"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29320": {
    "title": "DART: Dual-Modal Adaptive Online Prompting and Knowledge Retention for Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zichen Liu",
      "Hongbo Sun",
      "Yuxin Peng",
      "Jiahuan Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29321": {
    "title": "Backdoor Attacks via Machine Unlearning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Liu",
      "Tianhao Wang",
      "Mengdi Huai",
      "Chenglin Miao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29322": {
    "title": "Cooperative Knowledge Distillation: A Learner Agnostic Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Livanos",
      "Ian Davidson",
      "Stephen Wong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29323": {
    "title": "On the Convergence of an Adaptive Momentum Method for Adversarial Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sheng Long",
      "Wei Tao",
      "Shuohao LI",
      "Jun Lei",
      "Jun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29324": {
    "title": "Layer Collaboration in the Forward-Forward Algorithm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guy Lorberbom",
      "Itai Gat",
      "Yossi Adi",
      "Alexander Schwing",
      "Tamir Hazan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29325": {
    "title": "CGS-Mask: Making Time Series Predictions Intuitive for All",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Lu",
      "Wei Li",
      "Yifei Sun",
      "Cheng Song",
      "Yufei Ren",
      "Albert Y. Zomaya"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29326": {
    "title": "Improving Expressive Power of Spectral Graph Neural Networks with Eigenvalue Correction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kangkang Lu",
      "Yanhua Yu",
      "Hao Fei",
      "Xuan Li",
      "Zixuan Yang",
      "Zirui Guo",
      "Meiyu Liang",
      "Mengran Yin",
      "Tat-Seng Chua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29327": {
    "title": "UniADS: Universal Architecture-Distiller Search for Distillation Gap",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liming Lu",
      "Zhenghan Chen",
      "Xiaoyu Lu",
      "Yihang Rao",
      "Lujun Li",
      "Shuchao Pang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29328": {
    "title": "NodeMixup: Tackling Under-Reaching for Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weigang Lu",
      "Ziyu Guan",
      "Wei Zhao",
      "Yaming Yang",
      "Long Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29329": {
    "title": "Federated Learning with Extremely Noisy Clients via Negative Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Lu",
      "Lin Chen",
      "Yonggang Zhang",
      "Yiliang Zhang",
      "Bo Han",
      "Yiu-ming Cheung",
      "Hanzi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29330": {
    "title": "Decoupled Contrastive Multi-View Clustering with High-Order Random Walks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiding Lu",
      "Yijie Lin",
      "Mouxing Yang",
      "Dezhong Peng",
      "Peng Hu",
      "Xi Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29331": {
    "title": "Are You Concerned about Limited Function Evaluations: Data-Augmented Pareto Set Learning for Expensive Multi-Objective Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongfan Lu",
      "Bingdong Li",
      "Aimin Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29332": {
    "title": "Autoregressive Omni-Aware Outpainting for Open-Vocabulary 360-Degree Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuqiang Lu",
      "Kun Hu",
      "Chaoyue Wang",
      "Lei Bai",
      "Zhiyong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29333": {
    "title": "Leveraging Diffusion Perturbations for Measuring Fairness in Computer Vision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicholas Lui",
      "Bryan Chia",
      "William Berrios",
      "Candace Ross",
      "Douwe Kiela"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29334": {
    "title": "Three Heads Are Better than One: Complementary Experts for Long-Tailed Semi-supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengcheng Ma",
      "Ismail Elezi",
      "Jiankang Deng",
      "Weiming Dong",
      "Changsheng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29335": {
    "title": "Discerning Temporal Difference Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianfei Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29336": {
    "title": "One-Step Forward and Backtrack: Overcoming Zig-Zagging in Loss-Aware Quantization Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lianbo Ma",
      "Yuee Zhou",
      "Jianlun Ma",
      "Guo Yu",
      "Qing Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29337": {
    "title": "U-Mixer: An Unet-Mixer Architecture with Stationarity Correction for Time Series Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Ma",
      "Xuemei Li",
      "Lexin Fang",
      "Tianlong Zhao",
      "Caiming Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29338": {
    "title": "Transformer-Based Video-Structure Multi-Instance Learning for Whole Slide Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingfan Ma",
      "Xiaoyuan Luo",
      "Kexue Fu",
      "Manning Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29339": {
    "title": "PPIDSG: A Privacy-Preserving Image Distribution Sharing Scheme with GAN in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuting Ma",
      "Yuanzhi Yao",
      "Xiaohua Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29340": {
    "title": "Hard Regularization to Prevent Deep Online Clustering Collapse without Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Louis Mahon",
      "Thomas Lukasiewicz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29341": {
    "title": "Simple Weak Coresets for Non-decomposable Classification Measures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jayesh Malaviya",
      "Anirban Dasgupta",
      "Rachit Chhaya"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29342": {
    "title": "One Self-Configurable Model to Solve Many Abstract Visual Reasoning Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mikołaj Małkiński",
      "Jacek Mańdziuk"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29343": {
    "title": "Permutation-Based Hypothesis Testing for Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesca Mandel",
      "Ian Barnett"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29344": {
    "title": "Online Markov Decision Processes Configuration with Continuous Decision Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Davide Maran",
      "Pierriccardo Olivieri",
      "Francesco Emanuele Stradi",
      "Giuseppe Urso",
      "Nicola Gatti",
      "Marcello Restelli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29345": {
    "title": "GradTree: Learning Axis-Aligned Decision Trees with Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sascha Marton",
      "Stefan Lüdtke",
      "Christian Bartelt",
      "Heiner Stuckenschmidt"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29346": {
    "title": "Optimal Attack and Defense for Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeremy McMahan",
      "Young Wu",
      "Xiaojin Zhu",
      "Qiaomin Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29347": {
    "title": "QCS-SGM+: Improved Quantized Compressed Sensing with Score-Based Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangming Meng",
      "Yoshiyuki Kabashima"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29348": {
    "title": "Learning Representations on the Unit Sphere: Investigating Angular Gaussian and Von Mises-Fisher Distributions for Online Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Michel",
      "Giovanni Chierchia",
      "Romain Negrel",
      "Jean-François Bercher"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29349": {
    "title": "HOP to the Next Tasks and Domains for Continual Learning in NLP",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Umberto Michieli",
      "Mete Ozay"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29350": {
    "title": "Leveraging Local Variance for Pseudo-Label Selection in Semi-supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeping Min",
      "Jinfeng Bai",
      "Chengfei Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29351": {
    "title": "Input Margins Can Predict Generalization Too",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Coenraad Mouton",
      "Marthinus Wilhelmus Theunissen",
      "Marelie H Davel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29352": {
    "title": "Beyond TreeSHAP: Efficient Computation of Any-Order Shapley Interactions for Tree Ensembles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximilian Muschalik",
      "Fabian Fumagalli",
      "Barbara Hammer",
      "Eyke Hüllermeier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29353": {
    "title": "Continuous Treatment Effect Estimation Using Gradient Interpolation and Kernel Smoothing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lokesh Nagalapatti",
      "Akshay Iyer",
      "Abir De",
      "Sunita Sarawagi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29354": {
    "title": "Revisiting Disentanglement in Downstream Tasks: A Study on Its Necessity for Abstract Visual Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiqian Nai",
      "Zixin Wen",
      "Ji Li",
      "Yuanzhi Li",
      "Yang Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29355": {
    "title": "Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shintaro Nakamura",
      "Masashi Sugiyama"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29356": {
    "title": "Efficient Learning of PDEs via Taylor Expansion and Sparse Decomposition into Value and Fourier Domains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Nasim",
      "Yexiang Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29357": {
    "title": "Secure Distributed Sparse Gaussian Process Models Using Multi-Key Homomorphic Encryption",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adil Nawaz",
      "Guopeng Chen",
      "Muhammad Umair Raza",
      "Zahid Iqbal",
      "Jianqiang  Li",
      "Victor C.M. Leung",
      "Jie Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29358": {
    "title": "Multiple Hypothesis Dropout: Estimating the Parameters of Multi-Modal Output Distributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David D. Nguyen",
      "David Liebowitz",
      "Salil S. Kanhere",
      "Surya Nepal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29359": {
    "title": "On Inference Stability for Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Viet Nguyen",
      "Giang Vu",
      "Tung Nguyen Thanh",
      "Khoat Than",
      "Toan Tran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29360": {
    "title": "Improve Robustness of Reinforcement Learning against Observation Perturbations via l∞ Lipschitz Policy Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Buqing Nie",
      "Jingtian Ji",
      "Yangqing Fu",
      "Yue Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29361": {
    "title": "Multi-Class Support Vector Machine with Maximizing Minimum Margin",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feiping Nie",
      "Zhezheng Hao",
      "Rong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29362": {
    "title": "Symmetric Q-learning: Reducing Skewness of Bellman Error in Online Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Motoki Omura",
      "Takayuki Osa",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29363": {
    "title": "A Primal-Dual Algorithm for Hybrid Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tom Overman",
      "Garrett Blum",
      "Diego Klabjan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29364": {
    "title": "Multi-Objective Bayesian Optimization with Active Preference Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryota Ozaki",
      "Kazuki Ishikawa",
      "Youhei Kanzaki",
      "Shion Takeno",
      "Ichiro Takeuchi",
      "Masayuki Karasuyama"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29365": {
    "title": "Towards Fair Graph Federated Learning via Incentive Mechanisms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenglu Pan",
      "Jiarong Xu",
      "Yue Yu",
      "Ziqi Yang",
      "Qingbiao Wu",
      "Chunping Wang",
      "Lei Chen",
      "Yang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29366": {
    "title": "A Graph Dynamics Prior for Relational Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liming Pan",
      "Cheng Shi",
      "Ivan Dokmanic"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29367": {
    "title": "Learning Reduced Fluid Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zherong Pan",
      "Xifeng Gao",
      "Kui Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29368": {
    "title": "FedLF: Layer-Wise Fair Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zibin Pan",
      "Chi Li",
      "Fangchen Yu",
      "Shuyi Wang",
      "Haijin Wang",
      "Xiaoying Tang",
      "Junhua Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29369": {
    "title": "Convolutional Channel-Wise Competitive Learning for the Forward-Forward Algorithm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andreas Papachristodoulou",
      "Christos Kyrkou",
      "Stelios Timotheou",
      "Theocharis Theocharides"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29370": {
    "title": "REPrune: Channel Pruning via Kernel Representative Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mincheol Park",
      "Dongjin  Kim",
      "Cheonjun Park",
      "Yuna Park",
      "Gyeong Eun Gong",
      "Won Woo Ro",
      "Suhyun Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29371": {
    "title": "ConceptBed: Evaluating Concept Learning Abilities of Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maitreya Patel",
      "Tejas Gokhale",
      "Chitta Baral",
      "Yezhou Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29372": {
    "title": "CrystalBox: Future-Based Explanations for Input-Driven Deep RL Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sagar Patel",
      "Sangeetha Abdu Jyothi",
      "Nina Narodytska"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29373": {
    "title": "HAGO-Net: Hierarchical Geometric Massage Passing for Molecular Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongbin Pei",
      "Taile Chen",
      "Chen A",
      "Huiqi Deng",
      "Jing Tao",
      "Pinghui Wang",
      "Xiaohong Guan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29374": {
    "title": "CARAT: Contrastive Feature Reconstruction and Aggregation for Multi-Modal Multi-Label Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Peng",
      "Ke Chen",
      "Lidan Shou",
      "Gang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29375": {
    "title": "Variational Hybrid-Attention Framework for Multi-Label Few-Shot Aspect Category Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Peng",
      "Ke Chen",
      "Lidan Shou",
      "Gang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29376": {
    "title": "Hypothesis, Verification, and Induction: Grounding Large Language Models with Self-Driven Skill Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaohui Peng",
      "Xing Hu",
      "Qi Yi",
      "Rui Zhang",
      "Jiaming Guo",
      "Di Huang",
      "Zikang Tian",
      "Ruizhi Chen",
      "Zidong Du",
      "Qi Guo",
      "Yunji Chen",
      "Ling Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29377": {
    "title": "Recurrent Graph Neural Networks and Their Connections to Bisimulation and Logic",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximilian Pflueger",
      "David Tena Cucala",
      "Egor V. Kostylev"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29378": {
    "title": "Learning Performance Maximizing Ensembles with Explainability Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Pisztora",
      "Jia Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29379": {
    "title": "Reconciling Predictive and Statistical Parity: A Causal Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Drago Plecko",
      "Elias Bareinboim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29380": {
    "title": "Adaptive Feature Imputation with Latent Graph for Deep Incomplete Multi-View Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyu Pu",
      "Chenhang Cui",
      "Xinyue Chen",
      "Yazhou Ren",
      "Xiaorong Pu",
      "Zhifeng Hao",
      "Philip S. Yu",
      "Lifang He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29381": {
    "title": "MDGNN: Multi-Relational Dynamic Graph Neural Network for Comprehensive and Dynamic Stock Investment Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Qian",
      "Hongting Zhou",
      "Qian Zhao",
      "Hao Chen",
      "Hongxiang Yao",
      "Jingwei Wang",
      "Ziqi Liu",
      "Fei Yu",
      "Zhiqiang Zhang",
      "Jun Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29382": {
    "title": "Towards Modeling Uncertainties of Self-Explaining Neural Networks via Conformal Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Qian",
      "Chenxu Zhao",
      "Yangyi Li",
      "Fenglong Ma",
      "Chao Zhang",
      "Mengdi Huai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29383": {
    "title": "Upper Bounding Barlow Twins: A Novel Filter for Multi-Relational Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaowei Qian",
      "Bingheng Li",
      "Zhao Kang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29384": {
    "title": "EarnHFT: Efficient Hierarchical Reinforcement Learning for High Frequency Trading",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Molei Qin",
      "Shuo Sun",
      "Wentao Zhang",
      "Haochong Xia ",
      "Xinrun Wang",
      "Bo An"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29385": {
    "title": "Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Qin",
      "Feiyi Chen",
      "Chen Zhi",
      "Xueqiang Yan",
      "Shuiguang Deng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29386": {
    "title": "Tree Search-Based Evolutionary Bandits for Protein Sequence Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Qiu",
      "Hui Yuan",
      "Jinghong Zhang",
      "Wentao Chen",
      "Huazheng Wang",
      "Mengdi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29387": {
    "title": "Multi-Level Cross-Modal Alignment for Image Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liping Qiu",
      "Qin Zhang",
      "Xiaojun Chen",
      "Shaotian Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29388": {
    "title": "Integer Is Enough: When Vertical Federated Learning Meets Rounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengyu Qiu",
      "Yuwen Pu",
      "Yongchao Liu",
      "Wenyan Liu",
      "Yun Yue",
      "Xiaowei Zhu",
      "Lichun Li",
      "Jinbao Li",
      "Shouling Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29389": {
    "title": "Towards Multi-Mode Outlier Robust Tensor Ring Decomposition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuning Qiu",
      "Guoxu Zhou",
      "Andong Wang",
      "Zhenhao Huang",
      "Qibin Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29390": {
    "title": "Learning the Topology and Behavior of Discrete Dynamical Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zirou Qiu",
      "Abhijin Adiga",
      "Madhav V. Marathe",
      "S. S. Ravi",
      "Daniel J. Rosenkrantz",
      "Richard E. Stearns",
      "Anil Vullikanti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29391": {
    "title": "LDS2AE: Local Diffusion Shared-Specific Autoencoder for Multimodal Remote Sensing Image Classification with Arbitrary Missing Modalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahui Qu",
      "Yuanbo Yang",
      "Wenqian Dong",
      "Yufei Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29392": {
    "title": "Dual-Level Curriculum Meta-Learning for Noisy Few-Shot Learning Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofan Que",
      "Qi Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29393": {
    "title": "DSD²: Can We Dodge Sparse Double Descent and Compress the Neural Network Worry-Free?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Victor Quétu",
      "Enzo Tartaglione"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29394": {
    "title": "Fair Participation via Sequential Policies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Reilly Raab",
      "Ross Boczar",
      "Maryam Fazel",
      "Yang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29395": {
    "title": "Understanding the Generalization of Pretrained Diffusion Models on Out-of-Distribution Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Niranjan Ramachandran",
      "Rudrabha Mukhopadhyay",
      "Madhav Agarwal",
      "C.V. Jawahar",
      "Vinay Namboodiri"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29396": {
    "title": "GINN-LP: A Growing Interpretable Neural Network for Discovering Multivariate Laurent Polynomial Equations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nisal Ranasinghe",
      "Damith Senanayake",
      "Sachith Seneviratne",
      "Malin Premaratne",
      "Saman Halgamuge"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29397": {
    "title": "Using Stratified Sampling to Improve LIME Image Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Rashid",
      "Elvio G. Amparore",
      "Enrico Ferrari",
      "Damiano Verda"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29398": {
    "title": "NESTER: An Adaptive Neurosymbolic Method for Causal Effect Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abbavaram Gowtham Reddy",
      "Vineeth N Balasubramanian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29399": {
    "title": "Towards Learning and Explaining Indirect Causal Effects in Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abbavaram Gowtham Reddy",
      "Saketh Bachu",
      "Harsharaj Pathak",
      "Benin Godfrey L",
      "Varshaneya V",
      "Vineeth N Balasubramanian",
      "Satyanarayan Kar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29400": {
    "title": "Towards Improved Proxy-Based Deep Metric Learning via Data-Augmented Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Ren",
      "Chen Chen",
      "Liqiang Wang",
      "Kien Hua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29401": {
    "title": "Statistical Spatially Inhomogeneous Diffusion Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinuo Ren",
      "Yiping Lu",
      "Lexing Ying",
      "Grant M. Rotskoff"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29402": {
    "title": "Protect Your Score: Contact-Tracing with Differential Privacy Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rob Romijnders",
      "Christos Louizos",
      "Yuki M. Asano",
      "Max Welling"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29403": {
    "title": "Limitations of Face Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harrison Rosenberg",
      "Shimaa Ahmed",
      "Guruprasad Ramesh",
      "Kassem Fawaz",
      "Ramya Korlakai Vinayak"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29404": {
    "title": "Scaling Up Semi-supervised Learning with Unconstrained Unlabelled Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuvendu Roy",
      "Ali Etemad"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29405": {
    "title": "SimPSI: A Simple Strategy to Preserve Spectral Information in Time Series Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyun Ryu",
      "Sunjae Yoon",
      "Hee Suk Yoon",
      "Eunseop Yoon",
      "Chang D. Yoo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29406": {
    "title": "Learning the Causal Structure of Networked Dynamical Systems under Latent Nodes and Structured Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Augusto Santos",
      "Diogo Rente",
      "Rui Seabra",
      " José M. F. Moura"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29407": {
    "title": "XKD: Cross-Modal Knowledge Distillation with Domain Alignment for Video Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pritam Sarkar",
      "Ali Etemad"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29408": {
    "title": "Understanding and Leveraging the Learning Phases of Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johannes Schneider",
      "Mohit Prabhushankar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29409": {
    "title": "What Do Hebbian Learners Learn? Reduction Axioms for Iterated Hebbian Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Caleb Schultz Kisby",
      "Saúl A. Blanco",
      "Lawrence S. Moss"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29410": {
    "title": "Leaving the Nest: Going beyond Local Loss Functions for Predict-Then-Optimize",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanket Shah",
      "Bryan Wilder",
      "Andrew Perrault",
      "Milind Tambe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29411": {
    "title": "Phoneme Hallucinator: One-Shot Voice Conversion via Set Expansion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Shan",
      "Yang Li",
      "Amartya Banerjee",
      "Junier B. Oliva"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29412": {
    "title": "No Internal Regret with Non-convex Loss Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dravyansh Sharma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29413": {
    "title": "Symbolic Cognitive Diagnosis via Hybrid Optimization for Intelligent Education Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhao Shen",
      "Hong Qian",
      "Wei Zhang",
      "Aimin Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29414": {
    "title": "BBScore: A Brownian Bridge Based Metric for Assessing Text Coherence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhecheng Sheng",
      "Tianhao Zhang",
      "Chen Jiang",
      "Dongyeop Kang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29415": {
    "title": "Building Variable-Sized Models via Learngene Pool",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyu Shi",
      "Shiyu Xia",
      "Xu Yang",
      "Haokun Chen",
      "Zhiqiang Kou",
      "Xin Geng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29416": {
    "title": "CLIP-Guided Federated Learning on Heterogeneity and Long-Tailed Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangming Shi",
      "Shanshan Zheng",
      "Xiangbo Yin",
      "Yang Lu",
      "Yuan Xie",
      "Yanyun Qu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29417": {
    "title": "Structural Information Enhanced Graph Representation for Link Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Shi",
      "Bin Hu",
      "Deng Zhao",
      "Jianshan He",
      "Zhiqiang Zhang",
      "Jun Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29418": {
    "title": "A Closer Look at Curriculum Adversarial Training: From an Online Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lianghe Shi",
      "Weiwei Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29419": {
    "title": "Double-Bounded Optimal Transport for Advanced Clustering and Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liangliang Shi",
      "Zhaoqi Shen",
      "Junchi Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29420": {
    "title": "Teacher as a Lenient Expert: Teacher-Agnostic Data-Free Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunjune Shin",
      "Dong-Wan Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29421": {
    "title": "SemTra: A Semantic Skill Translator for Cross-Domain Zero-Shot Policy Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sangwoo Shin",
      "Minjong Yoo",
      "Jeongwoo Lee",
      "Honguk Woo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29422": {
    "title": "Region-Disentangled Diffusion Model for High-Fidelity PPG-to-ECG Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debaditya Shome",
      "Pritam Sarkar",
      "Ali Etemad"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29423": {
    "title": "Fusing Conditional Submodular GAN and Programmatic Weak Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kumar Shubham",
      "Pranav Sastry",
      "Prathosh AP"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29424": {
    "title": "Partial Label Learning with a Partner",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chongjie Si",
      "Zekun Jiang",
      "Xuehui Wang",
      "Yan Wang",
      "Xiaokang Yang",
      "Wei Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29425": {
    "title": "Online Submodular Maximization via Online Convex Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tareq Si Salem",
      "Gözde Özcan",
      "Iasonas Nikolaou",
      "Evimaria Terzi",
      "Stratis Ioannidis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29426": {
    "title": "Robustly Train Normalizing Flows via KL Divergence Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Song",
      "Ruben Solozabal",
      "Hao Li",
      "Martin Takáč",
      "Lu Ren",
      "Fakhri Karray"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29427": {
    "title": "Non-exemplar Domain Incremental Object Detection via Learning Domain Bias",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Song",
      "Yuhang He",
      "Songlin Dong",
      "Yihong Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29428": {
    "title": "Reinforcement Learning as a Parsimonious Alternative to Prediction Cascades: A Case Study on Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bharat Srikishan",
      "Anika Tabassum",
      "Srikanth Allu",
      "Ramakrishnan Kannan",
      "Nikhil Muralidhar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29429": {
    "title": "United We Stand: Using Epoch-Wise Agreement of Ensembles to Combat Overfit",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Uri Stern",
      "Daniel Shwartz",
      "Daphna Weinshall"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29430": {
    "title": "Multi-Dimensional Fair Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cong Su",
      "Guoxian Yu",
      "Jun Wang",
      "Hui Li",
      "Qingzhong Li",
      "Han Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29431": {
    "title": "Sharpness-Aware Model-Agnostic Long-Tailed Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Houcheng Su",
      "Weihao Luo",
      "Daixian Liu",
      "Mengzhu Wang",
      "Jing Tang",
      "Junyang Chen",
      "Cong Wang",
      "Zhenghan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29432": {
    "title": "Multiscale Attention Wavelet Neural Operator for Capturing Steep Trajectories in Biochemical Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayang Su",
      "Junbo Ma",
      "Songyang Tong",
      "Enze Xu",
      "Minghan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29433": {
    "title": "GSENet:Global Semantic Enhancement Network for Lane Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhao Su",
      "Zhenghan Chen",
      "Chenghao He",
      "Dongzhi Guan",
      "Changpeng Cai",
      "Tongxi Zhou",
      "Jiashen Wei",
      "Wenhua Tian",
      "Zhihuai Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29434": {
    "title": "Federated Adaptive Prompt Tuning for Multi-Domain Collaborative Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangchao Su",
      "Mingzhao Yang",
      "Bin Li",
      "Xiangyang Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29435": {
    "title": "Towards Real-World Test-Time Adaptation: Tri-net Self-Training with Balanced Normalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongyi Su",
      "Xun Xu",
      "Kui Jia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29436": {
    "title": "Unraveling Batch Normalization for Realistic Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixian Su",
      "Jingwei Guo",
      "Kai Yao",
      "Xi Yang",
      "Qiufeng Wang",
      "Kaizhu Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29437": {
    "title": "CUDC: A Curiosity-Driven Unsupervised Data Collection Method with Adaptive Temporal Distances for Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyu Sun",
      "Hangwei Qian",
      "Chunyan Miao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29438": {
    "title": "T2MAC: Targeted and Trusted Multi-Agent Communication through Selective Engagement and Evidence-Driven Integration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuxiong Sun",
      "Zehua Zang",
      "Jiabao Li",
      "Jiangmeng Li",
      "Xiao Xu",
      "Rui Wang",
      "Changwen Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29439": {
    "title": "On the Role of Server Momentum in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianhui Sun",
      "Xidong Wu",
      "Heng Huang",
      "Aidong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29440": {
    "title": "RedCore: Relative Advantage Aware Cross-Modal Representation Learning for Missing Modalities with Imbalanced Missing Rates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Sun",
      "Xinxin Zhang",
      "Shoukang Han",
      "Yu-Ping Ruan",
      "Taihao Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29441": {
    "title": "Dual Self-Paced Cross-Modal Hashing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Sun",
      "Jian Dai",
      "Zhenwen Ren",
      "Yingke Chen",
      "Dezhong Peng",
      "Peng Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29442": {
    "title": "ACAMDA: Improving Data Efficiency in Reinforcement Learning through Guided Counterfactual Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuewen Sun",
      "Erli Wang",
      "Biwei Huang",
      "Chaochao Lu",
      "Lu Feng",
      "Changyin Sun",
      "Kun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29443": {
    "title": "Learning Not to Regret",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Sychrovský",
      "Michal Šustr",
      "Elnaz Davoodi",
      "Michael Bowling",
      "Marc Lanctot",
      "Martin Schmid"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29444": {
    "title": "Optimal Transport with Cyclic Symmetry",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shoichiro Takeda",
      "Yasunori Akagi",
      "Naoki Marumo",
      "Kenta Niwa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29445": {
    "title": "Cross-Gate MLP with Protein Complex Invariant Embedding Is a One-Shot Antibody Designer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Tan",
      "Zhangyang Gao",
      "Lirong Wu",
      "Jun Xia",
      "Jiangbin Zheng",
      "Xihong Yang",
      "Yue Liu",
      "Bozhen Hu",
      "Stan Z. Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29446": {
    "title": "FedCompetitors: Harmonious Collaboration in Federated Learning with Competing Participants",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanli Tan",
      "Hao Cheng",
      "Xiaohu Wu",
      "Han Yu",
      "Tiantian He",
      "Yew Soon Ong",
      "Chongjun Wang",
      "Xiaofeng Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29447": {
    "title": "Harnessing the Power of Beta Scoring in Deep Active Learning for Multi-Label Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Tan",
      "Ngoc Dang Nguyen",
      "Lan Du",
      "Wray Buntine"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29448": {
    "title": "A Two-Stage Information Extraction Network for Incomplete Multi-View Multi-Label Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Tan",
      "Ce Zhao",
      "Chengliang Liu",
      "Jie Wen",
      "Zhanyan Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29449": {
    "title": "An Effective Augmented Lagrangian Method for Fine-Grained Multi-View Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuze Tan",
      "Hecheng Cai",
      "Shudong Huang",
      "Shuping Wei",
      "Fan Yang",
      "Jiancheng Lv"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29450": {
    "title": "SimCalib: Graph Neural Network Calibration Based on Similarity between Nodes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boshi Tang",
      "Zhiyong Wu",
      "Xixin Wu",
      "Qiaochu Huang",
      "Jun Chen",
      "Shun Lei",
      "Helen Meng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29451": {
    "title": "DP-AdamBC: Your DP-Adam Is Actually DP-SGD (Unless You Apply Bias Correction)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiaoyue Tang",
      "Frederick Shpilevskiy",
      "Mathias Lécuyer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29452": {
    "title": "Non-monotone Sequential Submodular Maximization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaojie Tang",
      "Jing Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29453": {
    "title": "Comprehensive View Embedding Learning for Single-Cell Multimodal Integration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenchao Tang",
      "Jiehui Huang",
      "Guanxing Chen",
      "Calvin Yu-Chian Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29454": {
    "title": "z-SignFedAvg: A Unified Stochastic Sign-Based Compression for Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwei Tang",
      "Yanmeng Wang",
      "Tsung-Hui Chang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29455": {
    "title": "Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lue Tao",
      "Yu-Xuan Huang",
      "Wang-Zhou Dai",
      "Yuan Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29456": {
    "title": "Efficient Nonparametric Tensor Decomposition for Binary and Count Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zerui Tao",
      "Toshihisa Tanaka",
      "Qibin Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29457": {
    "title": "FFT-Based Dynamic Token Mixer for Vision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuki Tatsunami",
      "Masato Taki"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29458": {
    "title": "An Information-Flow Perspective on Algorithmic Fairness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Teuber",
      "Bernhard Beckert"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29459": {
    "title": "Amalgamating Multi-Task Models with Heterogeneous Architectures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jidapa Thadajarassiri",
      "Walter Gerych",
      "Xiangnan Kong",
      "Elke Rundensteiner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29460": {
    "title": "ConSequence: Synthesizing Logically Constrained Sequences for Electronic Health Record Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Brandon Theodorou",
      "Shrusti Jain",
      "Cao Xiao",
      "Jimeng Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29461": {
    "title": "N-gram Unsupervised Compoundation and Feature Injection for Better Symbolic Music Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinhao Tian",
      "Zuchao Li",
      "Jiajia Li",
      "Ping Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29462": {
    "title": "DeRDaVa: Deletion-Robust Data Valuation for Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Tian",
      "Rachael Hwee Ling Sim",
      "Jue  Fan ",
      "Bryan Kian Hsiang Low"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29463": {
    "title": "Weisfeiler and Lehman Go Paths: Learning Topological Features via Path Complexes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quang Truong",
      "Peter Chin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29464": {
    "title": "Attribute-Missing Graph Clustering Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Tu",
      "Renxiang Guan",
      "Sihang Zhou",
      "Chuan Ma",
      "Xin Peng",
      "Zhiping Cai",
      "Zhe Liu",
      "Jieren Cheng",
      "Xinwang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29465": {
    "title": "Parameterized Projected Bellman Operator",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Théo Vincent",
      "Alberto Maria Metelli",
      "Boris Belousov",
      "Jan Peters",
      "Marcello Restelli",
      "Carlo D'Eramo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29466": {
    "title": "Causal Strategic Learning with Competitive Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kiet Q. H. Vo",
      "Muneeb Aadil",
      "Siu Lun Chau",
      "Krikamol Muandet"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29467": {
    "title": "Data Disparity and Temporal Unavailability Aware Asynchronous Federated Learning for Predictive Maintenance on Transportation Fleets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leonie von Wahl",
      "Niklas Heidenreich",
      "Prasenjit Mitra",
      "Michael Nolting",
      "Nicolas Tempelmeier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29468": {
    "title": "Federated Graph Learning under Domain Shift with Generalizable Prototypes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guancheng Wan",
      "Wenke Huang",
      "Mang Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29469": {
    "title": "Unlocking the Power of Open Set: A New Perspective for Open-Set Noisy Label Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhai Wan",
      "Xinrui Wang",
      "Ming-Kun Xie",
      "Shao-Yuan Li",
      "Sheng-Jun Huang",
      "Songcan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29470": {
    "title": "DiffAIL: Diffusion Adversarial Imitation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingzheng Wang",
      "Guoqiang Wu",
      "Teng Pang",
      "Yan Zhang",
      "Yilong Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29471": {
    "title": "DR-Label: Label Deconstruction and Reconstruction of GNN Models for Catalysis Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Wang",
      "Chen Liang",
      "Jiaze Wang",
      "Jiezhong Qiu",
      "Furui Liu",
      "Shaogang Hao",
      "Dong Li",
      "Guangyong Chen",
      "Xiaolong Zou",
      "Pheng Ann Heng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29472": {
    "title": "GAD-PVI: A General Accelerated Dynamic-Weight Particle-Based Variational Inference Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangyikang Wang",
      "Huminhao Zhu",
      "Chao Zhang",
      "Hanbin Zhao",
      "Hui Qian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29473": {
    "title": "Generative Model-Based Feature Knowledge Distillation for Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guiqin Wang",
      "Peng Zhao",
      "Yanjiang Shi",
      "Cong Zhao",
      "Shusen Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29474": {
    "title": "Gradient-Guided Modality Decoupling for Missing-Modality Robustness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Wang",
      "Shengda Luo",
      "Guosheng Hu",
      "Jianguo Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29475": {
    "title": "V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by Connecting Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heng Wang",
      "Jianbo Ma",
      "Santiago Pascual",
      "Richard Cartwright",
      "Weidong Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29476": {
    "title": "Practical Privacy-Preserving MLaaS: When Compressive Sensing Meets Generative Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jia Wang",
      "Wuqiang Su",
      "Zushu Huang",
      "Jie Chen",
      "Chengwen Luo",
      "Jianqiang  Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29477": {
    "title": "Towards Stability and Generalization Bounds in Decentralized Minibatch Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahuan Wang",
      "Hong Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29478": {
    "title": "SURER: Structure-Adaptive Unified Graph Neural Network for Multi-View Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Wang",
      "Songhe Feng",
      "Gengyu Lyu",
      "Jiazheng Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29479": {
    "title": "Rethinking Graph Masked Autoencoders through Alignment and Uniformity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Wang",
      "Xiang Tao",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29480": {
    "title": "GOODAT: Towards Test-Time Graph Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luzhi Wang",
      "Dongxiao He",
      "He Zhang",
      "Yixin Liu",
      "Wenjie Wang",
      "Shirui Pan",
      "Di Jin",
      "Tat-Seng Chua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29481": {
    "title": "TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for Lazy Clients",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengdi Wang",
      "Anna Bodonhelyi",
      "Efe Bozkir",
      "Enkelejda Kasneci"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29482": {
    "title": "MetaCARD: Meta-Reinforcement Learning with Task Uncertainty Feedback via Decoupled Context-Aware Reward and Dynamics Components",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min Wang",
      "Xin Li",
      "Leiji Zhang",
      "Mingzhong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29483": {
    "title": "Considering Nonstationary within Multivariate Time Series with Variational Hierarchical Transformer for Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muyao Wang",
      "Wenchao Chen",
      "Bo Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29484": {
    "title": "Controller-Guided Partial Label Consistency Regularization with Unlabeled Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qian-Wei Wang",
      "Bowen Zhao",
      "Mingyan Zhu",
      "Tianxiang Li",
      "Zimo Liu",
      "Shu-Tao Xia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29485": {
    "title": "A Bregman Proximal Stochastic Gradient Method with Extrapolation for Nonconvex Nonsmooth Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingsong Wang",
      "Zehui Liu",
      "Chunfeng Cui",
      "Deren Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29486": {
    "title": "ND-MRM: Neuronal Diversity Inspired Multisensory Recognition Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qixin Wang",
      "Chaoqiong Fan",
      "Tianyuan Jia",
      "Yuyang Han",
      "Xia Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29487": {
    "title": "AQ-DETR: Low-Bit Quantized Detection Transformer with Auxiliary Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runqi Wang",
      "Huixin Sun",
      "Linlin Yang",
      "Shaohui Lin",
      "Chuanjian Liu",
      "Yan Gao",
      "Yao Hu",
      "Baochang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29488": {
    "title": "Constrained Bayesian Optimization under Partial Observations: Balanced Improvements and Provable Convergence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengbo Wang",
      "Ke Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29489": {
    "title": "Online Restless Multi-Armed Bandits with Long-Term Fairness Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shufan  Wang",
      "Guojun Xiong",
      "Jian Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29490": {
    "title": "Exploring Gradient Explosion in Generative Adversarial Imitation Learning: A Probabilistic Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wanying Wang",
      "Yichen Zhu",
      "Yirui Zhou",
      "Chaomin Shen",
      "Jian Tang",
      "Zhiyuan Xu",
      "Yaxin Peng",
      "Yangchun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29491": {
    "title": "IGAMT: Privacy-Preserving Electronic Health Record Synthesization with Heterogeneity and Irregularity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjie Wang",
      "Pengfei Tang",
      "Jian Lou",
      "Yuanming Shao",
      "Lance Waller",
      "Yi-an Ko",
      "Li Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29492": {
    "title": "Decoupled Training: Return of Frustratingly Easy Multi-Domain Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ximei Wang",
      "Junwei Pan",
      "Xingzhuo Guo",
      "Dapeng Liu",
      "Jie Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29493": {
    "title": "Probability-Polarized Optimal Transport for Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Wang",
      "Chuan-Xian Ren",
      "Yi-Ming Zhai",
      "You-Wei Luo",
      "Hong Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29494": {
    "title": "Limited-Supervised Multi-Label Learning with Dependency Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yejiang Wang",
      "Yuhai Zhao",
      "Zhengkui Wang",
      "Wen Shan",
      "Xingwei Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29495": {
    "title": "Non-stationary Projection-Free Online Learning with Dynamic and Adaptive Regret Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yibo Wang",
      "Wenhao Yang",
      "Wei Jiang",
      "Shiyin Lu",
      "Bing Wang",
      "Haihong Tang",
      "Yuanyu Wan",
      "Lijun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29496": {
    "title": "Wavelet Dynamic Selection Network for Inertial Sensor Signal Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifeng Wang",
      "Yi Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29497": {
    "title": "Lost Domain Generalization Is a Natural Consequence of Lack of Training Domains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yimu Wang",
      "Yihan Wu",
      "Hongyang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29498": {
    "title": "Semi-supervised Learning of Dynamical Systems with Neural Ordinary Differential Equations: A Teacher-Student Model Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Wang",
      "Yuxuan Yin",
      "Karthik Somayaji NS",
      "Ján Drgoňa",
      "Malachi Schram",
      "Mahantesh Halappanavar",
      "Frank Liu",
      "Peng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29499": {
    "title": "Critic-Guided Decision Transformer for Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanfu Wang",
      "Chao Yang",
      "Ying Wen",
      "Yu Liu",
      "Yu Qiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29500": {
    "title": "Fully-Connected Spatial-Temporal Graph for Multivariate Time-Series Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yucheng Wang",
      "Yuecong Xu",
      "Jianfei Yang",
      "Min Wu",
      "Xiaoli Li",
      "Lihua Xie",
      "Zhenghua Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29501": {
    "title": "Graph-Aware Contrasting for Multivariate Time-Series Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yucheng Wang",
      "Yuecong Xu",
      "Jianfei Yang",
      "Min Wu",
      "Xiaoli Li",
      "Lihua Xie",
      "Zhenghua Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29502": {
    "title": "Superposed Atomic Representation for Robust High-Dimensional Data Recovery of Multiple Low-Dimensional Structures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yulong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29503": {
    "title": "Consistency-GAN: Training GANs with Consistency Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunpeng Wang",
      "Meng Pang",
      "Shengbo Chen",
      "Hong Rao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29504": {
    "title": "DRF: Improving Certified Robustness via Distributional Robustness Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zekai Wang",
      "Zhengyu Zhou",
      "Weiwei Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29505": {
    "title": "BVT-IMA: Binary Vision Transformer with Information-Modified Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Wang",
      "Hao Luo",
      "Xuemei Xie",
      "Fan Wang",
      "Guangming Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29506": {
    "title": "Stealthy Adversarial Attacks on Stochastic Multi-Armed Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwei Wang",
      "Huazheng Wang",
      "Hongning Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29507": {
    "title": "Building Minimal and Reusable Causal State Abstractions for Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zizhao Wang",
      "Caroline Wang",
      "Xuesu Xiao",
      "Yuke Zhu",
      "Peter Stone"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29508": {
    "title": "EAT: Towards Long-Tailed Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tong Wei",
      "Bo-Lin Wang",
      "Min-Ling Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29509": {
    "title": "Levenshtein Distance Embedding with Poisson Regression for DNA Storage",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Wei",
      "Alan J.X. Guo",
      "Sihan Sun",
      "Mengyi Wei",
      "Wei Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29510": {
    "title": "Multi-Source Collaborative Gradient Discrepancy Minimization for Federated Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yikang Wei",
      "Yahong Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29511": {
    "title": "Auto-Prox: Training-Free Vision Transformer Architecture Search via Automatic Proxy Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zimian Wei",
      "Peijie Dong",
      "Zheng Hui",
      "Anggeng Li",
      "Lujun Li",
      "Menglong Lu",
      "Hengyue  Pan",
      "Dongsheng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29512": {
    "title": "Hyperbolic Graph Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingfeng Wen",
      "Xuan Tang",
      "Mingjie Ouyang",
      "Xiangxiang Shen",
      "Jian Yang",
      "Daxin Zhu",
      "Mingsong Chen",
      "Xian Wei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29513": {
    "title": "Communication Efficient Distributed Newton Method over Unreliable Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Wen",
      "Chengchang Liu",
      "Yuedong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29514": {
    "title": "Homophily-Related: Adaptive Hybrid Graph Filter for Multi-View Graph Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zichen Wen",
      "Yawen Ling",
      "Yazhou Ren",
      "Tianyi Wu",
      "Jianpeng Chen",
      "Xiaorong Pu",
      "Zhifeng Hao",
      "Lifang He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29515": {
    "title": "Reproduce, Replicate, Reevaluate. The Long but Safe Way to Extend Machine Learning Methods",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luisa Werner",
      "Nabil Layaïda",
      "Pierre Genevès",
      "Jérôme Euzenat",
      "Damien Graux"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29516": {
    "title": "Robust Loss Functions for Training Decision Trees with Noisy Labels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonathan Wilton",
      "Nan Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29517": {
    "title": "Neural Network Approximation for Pessimistic Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Di Wu",
      "Yuling Jiao",
      "Li Shen",
      "Haizhao Yang",
      "Xiliang Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29518": {
    "title": "Solving Spectrum Unmixing as a Multi-Task Bayesian Inverse Problem with Latent Factors for Endmember Variability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Wu",
      "Mingmin Chi",
      "Xuan Zang",
      "Bo Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29519": {
    "title": "Distilling Reliable Knowledge for Instance-Dependent Partial Label Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong-Dong Wu",
      "Deng-Bao Wang",
      "Min-Ling Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29520": {
    "title": "OCEAN-MBRL: Offline Conservative Exploration for Model-Based Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Wu",
      "Rui Zhang",
      "Qi Yi",
      "Yunkai Gao",
      "Jiaming Guo",
      "Shaohui Peng",
      "Siming Lan",
      "Husheng Han",
      "Yansong Pan",
      "Kaizhao Yuan",
      "Pengwei Jin",
      "Ruizhi Chen",
      "Yunji Chen",
      "Ling Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29521": {
    "title": "Earthfarsser: Versatile Spatio-Temporal Dynamical Systems Modeling in One Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Wu",
      "Yuxuan Liang",
      "Wei Xiong",
      "Zhengyang Zhou",
      "Wei Huang",
      "Shilong Wang",
      "Kun Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29522": {
    "title": "SafeAR: Safe Algorithmic Recourse by Risk-Aware Policies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haochen Wu",
      "Shubham Sharma",
      "Sunandita Patra",
      "Sriram Gopalakrishnan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29523": {
    "title": "SwitchTab: Switched Autoencoders Are Effective Tabular Learners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Wu",
      "Suiyao Chen",
      "Qi Zhao",
      "Renat Sergazinov",
      "Chen Li",
      "Shengjie Liu",
      "Chongchao Zhao",
      "Tianpei Xie",
      "Hanqing Guo",
      "Cheng Ji",
      "Daniel Cociorva",
      "Hakan Brunzell"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29524": {
    "title": "PORTAL: Automatic Curricula Generation for Multiagent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jizhou Wu",
      "Jianye Hao",
      "Tianpei Yang",
      "Xiaotian Hao",
      "Yan Zheng",
      "Weixun Wang",
      "Matthew E. Taylor"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29525": {
    "title": "FedA3I: Annotation Quality-Aware Aggregation for Federated Medical Image Segmentation against Heterogeneous Annotation Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nannan Wu",
      "Zhaobin Sun",
      "Zengqiang Yan",
      "Li Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29526": {
    "title": "Low-Rank Kernel Tensor Learning for Incomplete Multi-View Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tingting Wu",
      "Songhe Feng",
      "Jiazheng Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29527": {
    "title": "Test-Time Domain Adaptation by Learning Domain-Aware Batch Normalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanan Wu",
      "Zhixiang Chi",
      "Yang Wang",
      "Konstantinos N. Plataniotis",
      "Songhe Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29528": {
    "title": "H-ensemble: An Information Theoretic Approach to Reliable Few-Shot Multi-Source-Free Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanru Wu",
      "Jianning Wang",
      "Weida Wang",
      "Yang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29529": {
    "title": "Data Poisoning to Fake a Nash Equilibria for Markov Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Young Wu",
      "Jeremy McMahan",
      "Xiaojin Zhu",
      "Qiaomin Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29530": {
    "title": "Self-Training Based Few-Shot Node Classification by Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongqian Wu",
      "Yujie Mo",
      "Peng Zhou",
      "Shangbo Yuan",
      "Xiaofeng Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29531": {
    "title": "Market-GAN: Adding Control to Financial Market Data Generation with Semantic Context",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haochong Xia ",
      "Shuo Sun",
      "Xinrun Wang",
      "Bo An"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29532": {
    "title": "A Separation and Alignment Framework for Black-Box Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingxuan Xia",
      "Junbo Zhao",
      "Gengyu Lyu",
      "Zenan Huang",
      "Tianlei Hu",
      "Gang Chen",
      "Haobo Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29533": {
    "title": "Transformer as Linear Expansion of Learngene",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyu Xia",
      "Miaosen Zhang",
      "Xu Yang",
      "Ruiming Chen",
      "Haokun Chen",
      "Xin Geng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29534": {
    "title": "IVP-VAE: Modeling EHR Time Series with Initial Value Problem Solvers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingge Xiao",
      "Leonie Basso",
      "Wolfgang Nejdl",
      "Niloy Ganguly",
      "Sandipan Sikdar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29535": {
    "title": "SHoP: A Deep Learning Framework for Solving High-Order Partial Differential Equations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tingxiong Xiao",
      "Runzhao Yang",
      "Yuxiao Cheng",
      "Jinli Suo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29536": {
    "title": "Enhancing Evolving Domain Generalization through Dynamic Latent Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Binghui Xie",
      "Yongqiang Chen",
      "Jiaqi Wang",
      "Kaiwen Zhou",
      "Bo Han",
      "Wei Meng",
      "James Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29537": {
    "title": "Trust Region Methods for Nonconvex Stochastic Optimization beyond Lipschitz Smoothness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenghan Xie",
      "Chenxi Li",
      "Chuwen Zhang",
      "Qi Deng",
      "Dongdong Ge",
      "Yinyu Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29538": {
    "title": "AUC Optimization from Multiple Unlabeled Datasets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Xie",
      "Yu Liu",
      "Ming Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29539": {
    "title": "MoDE: A Mixture-of-Experts Model with Mutual Distillation among the Experts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhitian Xie",
      "Yinger Zhang",
      "Chenyi Zhuang",
      "Qitao Shi",
      "Zhining Liu",
      "Jinjie Gu",
      "Guannan Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29540": {
    "title": "MmAP: Multi-Modal Alignment Prompt for Cross-Domain Multi-Task Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Xin",
      "Junlong Du",
      "Qiang Wang",
      "Ke Yan",
      "Shouhong Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29541": {
    "title": "VMT-Adapter: Parameter-Efficient Transfer Learning for Multi-Task Dense Scene Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Xin",
      "Junlong Du",
      "Qiang Wang",
      "Zhiwen Lin",
      "Ke Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29542": {
    "title": "BiPFT: Binary Pre-trained Foundation Transformer with Low-Rank Estimation of Binarization Residual Polynomials",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingrun Xing",
      "Li Du",
      "Xinyuan Wang",
      "Xianlin Zeng",
      "Yequan Wang",
      "Zheng Zhang",
      "Jiajun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29543": {
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guojun Xiong",
      "Gang Yan",
      "Shiqiang Wang",
      "Jian Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29544": {
    "title": "TEILP: Time Prediction over Knowledge Graphs via Logical Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siheng Xiong",
      "Yuan Yang",
      "Ali Payani",
      "James C Kerce",
      "Faramarz Fekri"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29545": {
    "title": "FairWASP: Fast and Optimal Fair Wasserstein Pre-processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zikai Xiong",
      "Niccolò Dalmasso",
      "Alan Mishler",
      "Vamsi K. Potluru",
      "Tucker Balch",
      "Manuela Veloso"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29546": {
    "title": "Reliable Conflictive Multi-View Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cai Xu",
      "Jiajun Si",
      "Ziyu Guan",
      "Wei Zhao",
      "Yue Wu",
      "Xiyue Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29547": {
    "title": "A Label Disambiguation-Based Multimodal Massive Multiple Instance Learning Approach for Immune Repertoire Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Xu",
      "Yu Zhao",
      "Bingzhe Wu",
      "Yueshan Huang",
      "Qin Ren",
      "Yang Xiao",
      "Bing He",
      "Jie Zheng",
      "Jianhua Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29548": {
    "title": "Deep Variational Incomplete Multi-View Clustering: Exploring Shared Clustering Structures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gehui Xu",
      "Jie Wen",
      "Chengliang Liu",
      "Bing Hu",
      "Yicheng Liu",
      "Lunke Fei",
      "Wei Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29549": {
    "title": "Sparse Variational Student-t Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Xu",
      "Delu Zeng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29550": {
    "title": "Relative Policy-Transition Optimization for Fast Policy Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Xu",
      "Cheng Zhou",
      "Yizheng Zhang",
      "Baoxiang Wang",
      "Lei Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29551": {
    "title": "Union Subgraph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxing Xu",
      "Aihu Zhang",
      "Qingtian Bian",
      "Vijay Prakash Dwivedi",
      "Yiping Ke"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29552": {
    "title": "Enhancing Ensemble Clustering with Adaptive High-Order Topological Weights",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxuan Xu",
      "Taiyong Li",
      "Lei Duan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29553": {
    "title": "PTMQ: Post-training Multi-Bit Quantization of Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Xu",
      "Zhongcheng Li",
      "Shanshan Wang",
      "Xingyi Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29554": {
    "title": "LSTKC: Long Short-Term Knowledge Consolidation for Lifelong Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kunlun Xu",
      "Xu Zou",
      "Jiahuan Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29555": {
    "title": "Defying Imbalanced Forgetting in Class Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shixiong Xu",
      "Gaofeng Meng",
      "Xing Nie",
      "Bolin Ni",
      "Bin Fan",
      "Shiming Xiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29556": {
    "title": "E2E-AT: A Unified Framework for Tackling Uncertainty in Task-Aware End-to-End Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wangkun Xu",
      "Jianhong Wang",
      "Fei Teng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29557": {
    "title": "LERE: Learning-Based Low-Rank Matrix Recovery with Rank Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengqin Xu",
      "Yulun Zhang",
      "Chao Ma",
      "Yichao Yan",
      "Zelin Peng",
      "Shoulie Xie",
      "Shiqian Wu",
      "Xiaokang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29558": {
    "title": "Multiobjective Lipschitz Bandits under Lexicographic Ordering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Xue",
      "Ji Cheng",
      "Fei Liu",
      "Yimu Wang",
      "Qingfu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29559": {
    "title": "Residual Hyperbolic Graph Convolution Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangkai Xue",
      "Jindou Dai",
      "Zhipeng Lu",
      "Yuwei Wu",
      "Yunde Jia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29560": {
    "title": "GraFITi: Graphs for Forecasting Irregularly Sampled Time Series",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vijaya Krishna Yalavarthi",
      "Kiran Madhusudhanan",
      "Randolf Scholz",
      "Nourhan Ahmed",
      "Johannes Burchert",
      "Shayan Jawed",
      "Stefan Born",
      "Lars Schmidt-Thieme"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29561": {
    "title": "Live and Learn: Continual Action Clustering with Incremental Views",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqiang Yan",
      "Yingtao Gan",
      "Yiqiao Mao",
      "Yangdong Ye",
      "Hui Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29562": {
    "title": "Federated Partial Label Learning with Local-Adaptive Augmentation and Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Yan",
      "Yuhong Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29563": {
    "title": "An Optimal Transport View for Subspace Clustering and Spectral Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuguang Yan",
      "Zhihao Xu",
      "Canlin Yang",
      "Jie Zhang",
      "Ruichu Cai",
      "Michael Kwok-Po Ng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29564": {
    "title": "Exploiting Geometry for Treatment Effect Estimation via Optimal Transport",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuguang Yan",
      "Zeqin Yang",
      "Weilin Chen",
      "Ruichu Cai",
      "Zhifeng Hao",
      "Michael Kwok-Po Ng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29565": {
    "title": "Wasserstein Differential Privacy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengyi Yang",
      "Jiayin Qi",
      "Aimin Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29566": {
    "title": "Federated Causality Learning with Explainable Adaptive Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dezhi Yang",
      "Xintong He",
      "Jun Wang",
      "Guoxian Yu",
      "Carlotta Domeniconi",
      "Jinglin Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29567": {
    "title": "Multi-Modal Disordered Representation Learning Network for Description-Based Person Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Yang",
      "Wei Li",
      "Menglong Yang",
      "Binbin Liang",
      "Jianwei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29568": {
    "title": "Exploring One-Shot Semi-supervised Federated Learning with Pre-trained Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingzhao Yang",
      "Shangchao Su",
      "Bin Li",
      "Xiangyang Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29569": {
    "title": "Exploring Sparse Visual Prompt for Domain Adaptive Dense Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Senqiao Yang",
      "Jiarui Wu",
      "Jiaming Liu",
      "Xiaoqi Li",
      "Qizhe Zhang",
      "Mingjie Pan",
      "Yulu Gan",
      "Zehui Chen",
      "Shanghang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29570": {
    "title": "A Variational Autoencoder for Neural Temporal Point Processes with Dynamic Latent Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sikun Yang",
      "Hongyuan Zha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29571": {
    "title": "A Transfer Approach Using Graph Neural Networks in Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianpei Yang",
      "Heng You",
      "Jianye Hao",
      "Yan Zheng",
      "Matthew E. Taylor"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29572": {
    "title": "Safe Abductive Learning in the Presence of Inaccurate Rules",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao-Wen Yang",
      "Jie-Jing Shao",
      "Wei-Wei Tu",
      "Yu-Feng Li",
      "Wang-Zhou Dai",
      "Zhi-Hua  Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29573": {
    "title": "Leveraging Normalization Layer in Adapters with Progressive Learning and Adaptive Distillation for Cross-Domain Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "YongJin Yang",
      "Taehyeon Kim",
      "Se-Young Yun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29574": {
    "title": "Adversarial Purification with the Manifold Hypothesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyuan Yang",
      "Zhiwei Xu",
      "Jing Zhang",
      "Richard Hartley",
      "Peter Tu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29575": {
    "title": "Dynamic Knowledge Injection for AIXI Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Yang-Zhao",
      "Kee Siong Ng",
      "Marcus Hutter"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29576": {
    "title": "PerFedRLNAS: One-for-All Personalized Federated Neural Architecture Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dixi Yao",
      "Baochun Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29577": {
    "title": "VQ-FONT: Few-Shot Font Generation with Structure-Aware Enhancement and Quantization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingshuai Yao",
      "Yabo Zhang",
      "Xianhui Lin",
      "Xiaoming Li",
      "Wangmeng Zuo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29578": {
    "title": "DrFuse: Learning Disentangled Representation for Clinical Multi-Modal Fusion with Missing Modality and Modal Inconsistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenfang Yao",
      "Kejing Yin",
      "William K. Cheung",
      "Jia Liu",
      "Jing Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29579": {
    "title": "Progressively Knowledge Distillation via Re-parameterizing Diffusion Reverse Process",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xufeng Yao",
      "Fanbin Lu",
      "Yuechen Zhang",
      "Xinyun Zhang",
      "Wenqian Zhao",
      "Bei Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29580": {
    "title": "Data-Augmented Curriculum Graph Neural Architecture Search under Distribution Shifts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Yao",
      "Xin Wang",
      "Yijian Qin",
      "Ziwei Zhang",
      "Wenwu Zhu",
      "Hong Mei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29581": {
    "title": "Task-Free Dynamic Sparse Vision Transformer for Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Ye",
      "Adrian G. Bors"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29582": {
    "title": "Task-Free Continual Generation and Representation Learning via Dynamic Expansionable Memory Cluster",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Ye",
      "Adrian G. Bors"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29583": {
    "title": "Uncertainty Regularized Evidential Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Ye",
      "Tiejin Chen",
      "Hua Wei",
      "Liang Zhan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29584": {
    "title": "Near-Optimal Resilient Aggregation Rules for Distributed Learning Using 1-Center and 1-Mean Clustering with Outliers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Yi",
      "Ronghui You",
      "Hong  Liu",
      "Changxin Liu",
      "Yuan Wang",
      "Jiancheng Lv"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29585": {
    "title": "Discriminatively Fuzzy Multi-View K-means Clustering with Local Structure Preserving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Yin",
      "Shiliang Sun",
      "Lai Wei",
      "Pei Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29586": {
    "title": "Effective Causal Discovery under Identifiable Heteroscedastic Noise Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naiyu Yin",
      "Tian Gao",
      "Yue Yu",
      "Qiang Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29587": {
    "title": "Dynamic Spiking Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nan Yin",
      "Mengzhu Wang",
      "Zhenghan Chen",
      "Giulia De Masi",
      "Huan Xiong",
      "Bin Gu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29588": {
    "title": "Asymmetric Mutual Alignment for Unsupervised Zero-Shot Sketch-Based Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihui Yin",
      "Jiexi Yan",
      "Chenghao Xu",
      "Cheng Deng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29589": {
    "title": "Risk-Conditioned Reinforcement Learning: A Generalized Approach for Adapting to Varying Risk Measures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gwangpyo Yoo",
      "Jinwoo Park",
      "Honguk Woo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29590": {
    "title": "Online Boosting Adaptive Learning under Concept Drift for Multistream Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "En Yu",
      "Jie Lu",
      "Bin Zhang",
      "Guangquan Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29591": {
    "title": "Chronic Poisoning: Backdoor Attack against Split Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangchao Yu",
      "Bo Zeng",
      "Kai Zhao",
      "Zhi Pang",
      "Lina Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29592": {
    "title": "Cheaper and Faster: Distributed Deep Reinforcement Learning with Serverless Computing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanfei Yu",
      "Jian Li",
      "Yang Hua",
      "Xu Yuan",
      "Hao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29593": {
    "title": "Barely Supervised Learning for Graph-Based Fraud Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Yu",
      "Zhengyang Liu",
      "Xiangfeng Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29594": {
    "title": "A Non-parametric Graph Clustering Framework for Multi-View Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengju Yu",
      "Siwei Wang",
      "Zhibin Dong",
      "Wenxuan Tu",
      "Suyuan Liu",
      "Zhao Lv",
      "Pan Li",
      "Miao Wang",
      "En Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29595": {
    "title": "DVSAI: Diverse View-Shared Anchors Based Incomplete Multi-View Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengju Yu",
      "Siwei Wang",
      "Pei Zhang",
      "Miao Wang",
      "Ziming Wang",
      "Zhe Liu",
      "Liming Fang",
      "En Zhu",
      "Xinwang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29596": {
    "title": "HGPrompt: Bridging Homogeneous and Heterogeneous Graphs for Few-Shot Prompt Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingtong Yu",
      "Yuan Fang",
      "Zemin Liu",
      "Xinming Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29597": {
    "title": "ANEDL: Adaptive Negative Evidential Deep Learning for Open-Set Semi-supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Yu",
      "Danruo Deng",
      "Furui Liu",
      "Qi Dou",
      "Yueming Jin",
      "Guangyong Chen",
      "Pheng Ann Heng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29598": {
    "title": "TIKP: Text-to-Image Knowledge Preservation for Continual Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhidong Yu",
      "Wei Yang",
      "Xike Xie",
      "Zhenbo Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29599": {
    "title": "Accelerating Text-to-Image Editing via Cache-Enabled Sparse Diffusion Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Yu",
      "Haoyang Li",
      "Fangcheng Fu",
      "Xupeng Miao",
      "Bin Cui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29600": {
    "title": "PDE+: Enhancing Generalization via PDE with Adaptive Distributional Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yige Yuan",
      "Bingbing Xu",
      "Bo Lin",
      "Liang Hou",
      "Fei Sun",
      "Huawei Shen",
      "Xueqi Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29601": {
    "title": "Self-Paced Unified Representation Learning for Hierarchical Multi-Label Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixuan Yuan",
      "Hao Liu",
      "Haoyi Zhou",
      "Denghui Zhang",
      "Xiao Zhang",
      "Hao Wang",
      "Hui  Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29602": {
    "title": "A Plug-and-Play Quaternion Message-Passing Module for Molecular Conformation Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Angxiao Yue",
      "Dixin Luo",
      "Hongteng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29603": {
    "title": "Efficient Asynchronous Federated Learning with Prospective Momentum Aggregation and Fine-Grained Correction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Zang",
      "Zhe Xue",
      "Shilong Ou",
      "Lingyang Chu",
      "Junping Du",
      "Yunfei Long"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29604": {
    "title": "Generalizing across Temporal Domains with Koopman Operators",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiuhao Zeng",
      "Wei Wang",
      "Fan Zhou",
      "Gezheng Xu",
      "Ruizhi Pu",
      "Changjian Shui",
      "Christian Gagné",
      "Shichun Yang",
      "Charles X. Ling",
      "Boyu Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29605": {
    "title": "Hierarchical Multi-Marginal Optimal Transport for Network Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhichen Zeng",
      "Boxin Du",
      "Si Zhang",
      "Yinglong Xia",
      "Zhining Liu",
      "Hanghang Tong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29606": {
    "title": "Harnessing the Power of SVD: An SVA Module for Enhanced Signal Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Zhai",
      "Shuyuan Yang",
      "Yitong Li",
      "Zhixi Feng",
      "Zhihao Chang",
      "Quanwei Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29607": {
    "title": "Optimistic Model Rollouts for Pessimistic Offline Policy Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanzhao Zhai",
      "Yiying Li",
      "Zijian Gao",
      "Xudong Gong",
      "Kele Xu",
      "Dawei Feng",
      "Ding Bo",
      "Huaimin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29608": {
    "title": "MetaDiff: Meta-Learning with Conditional Diffusion for Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baoquan Zhang",
      "Chuyao Luo",
      "Demin Yu",
      "Xutao Li",
      "Huiwei Lin",
      "Yunming Ye",
      "Bowen Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29609": {
    "title": "Learning Cluster-Wise Anchors for Multi-View Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Zhang",
      "Xiuyi Jia",
      "Zechao Li",
      "Chunlin Chen",
      "Huaxiong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29610": {
    "title": "Targeted Activation Penalties Help CNNs Ignore Spurious Signals",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dekai Zhang",
      "Matt Williams",
      "Francesca Toni"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29611": {
    "title": "Robust Test-Time Adaptation for Zero-Shot Prompt Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ding-Chu Zhang",
      "Zhi Zhou",
      "Yu-Feng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29612": {
    "title": "FM-OV3D: Foundation Model-Based Cross-Modal Knowledge Blending for Open-Vocabulary 3D Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongmei Zhang",
      "Chang Li",
      "Renrui Zhang",
      "Shenghao Xie",
      "Wei Xue",
      "Xiaodong Xie",
      "Shanghang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29613": {
    "title": "Coupled Confusion Correction: Learning from Crowds with Sparse Annotations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hansong Zhang",
      "Shikun Li",
      "Dan Zeng",
      "Chenggang Yan",
      "Shiming Ge"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29614": {
    "title": "Exponential Hardness of Optimization from the Locality in Quantum Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao-Kai Zhang",
      "Chengkai Zhu",
      "Geng Liu",
      "Xin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29615": {
    "title": "HONGAT: Graph Attention Networks in the Presence of High-Order Neighbors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heng-Kai Zhang",
      "Yi-Ge Zhang",
      "Zhi Zhou",
      "Yu-Feng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29616": {
    "title": "Memory-Efficient Reversible Spiking Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hong Zhang",
      "Yu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29617": {
    "title": "FedTGP: Trainable Global Prototypes with Adaptive-Margin-Enhanced Contrastive Learning for Data and Model Heterogeneity in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianqing Zhang",
      "Yang Liu",
      "Yang Hua",
      "Jian Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29618": {
    "title": "Reinforced Adaptive Knowledge Learning for Multimodal Fake News Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Litian Zhang",
      "Xiaoming Zhang",
      "Ziyi Zhou",
      "Feiran Huang",
      "Chaozhuo Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29619": {
    "title": "Multi-Label Supervised Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pingyue Zhang",
      "Mengyue Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29620": {
    "title": "United We Stand: Accelerating Privacy-Preserving Neural Inference by Conjunctive Optimization with Interleaved Nexus",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiao Zhang",
      "Tao Xiang",
      "Chunsheng Xin",
      "Hongyi Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29621": {
    "title": "A Learnable Discrete-Prior Fusion Autoencoder with Contrastive Learning for Tabular Data Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rongchao Zhang",
      "Yiwei Lou",
      "Dexuan Xu",
      "Yongzhi Cao",
      "Hanpin Wang",
      "Yu Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29622": {
    "title": "Efficient Deweahter Mixture-of-Experts with Uncertainty-Aware Feature-Wise Linear Modulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rongyu Zhang",
      "Yulin Luo",
      "Jiaming Liu",
      "Huanrui Yang",
      "Zhen Dong",
      "Denis Gudovskiy",
      "Tomoyuki Okuno",
      "Yohei Nakata",
      "Kurt Keutzer",
      "Yuan Du",
      "Shanghang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29623": {
    "title": "Analyzing Generalization in Policy Networks: A Case Study with the Double-Integrator System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruining Zhang",
      "Haoran Han",
      "Maolong Lv",
      "Qisong Yang",
      "Jian Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29624": {
    "title": "Reviewing the Forgotten Classes for Domain Adaptation of Black-Box Predictors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaojie Zhang",
      "Chun Shen",
      "Shuai Lü",
      "Zeyu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29625": {
    "title": "TC-LIF: A Two-Compartment Spiking Neuron Model for Long-Term Sequential Modelling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shimin Zhang",
      "Qu Yang",
      "Chenxiang Ma",
      "Jibin Wu",
      "Haizhou Li",
      "Kay Chen Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29626": {
    "title": "Learning with Noisy Labels Using Hyperspherical Margin Weighting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Zhang",
      "Yuwen Li",
      "Zhongyu Wang",
      "Jianqing Li",
      "Chengyu Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29627": {
    "title": "One Step Closer to Unbiased Aleatoric Uncertainty Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wang Zhang",
      "Ziwen Martin Ma",
      "Subhro Das",
      "Tsui-Wei Lily Weng",
      "Alexandre Megretski",
      "Luca Daniel",
      "Lam M. Nguyen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29628": {
    "title": "Gaussian Process Neural Additive Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Zhang",
      "Brian Barr",
      "John Paisley"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29629": {
    "title": "From Toxic to Trustworthy: Using Self-Distillation and Semi-supervised Methods to Refine Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianda Zhang",
      "Baolin Zheng",
      "Jianbao Hu",
      "Chengyang Li",
      "Xiaoying Bai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29630": {
    "title": "Low Category Uncertainty and High Training Potential Instance Learning for Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Zhang",
      "Meng Kang",
      "Shuai Lü"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29631": {
    "title": "Class-Attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuechen Zhang",
      "Mingchen Li",
      "Jiasi Chen",
      "Christos Thrampoulidis",
      "Samet Oymak"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29632": {
    "title": "Learning Multi-Task Sparse Representation Based on Fisher Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yayu Zhang",
      "Yuhua Qian",
      "Guoshuai Ma",
      "Keyin Zheng",
      "Guoqing Liu",
      "Qingfu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29633": {
    "title": "A Perspective of Q-value Estimation on Offline-to-Online Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinmin Zhang",
      "Jie Liu",
      "Chuming Li",
      "Yazhe Niu",
      "Yaodong Yang",
      "Yu Liu",
      "Wanli Ouyang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29634": {
    "title": "Mitigating Label Bias in Machine Learning: Fairness through Confident Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixuan Zhang",
      "Boyu Li",
      "Zenan Ling",
      "Feng Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29635": {
    "title": "Enhancing Representation of Spiking Neural Networks via Similarity-Sensitive Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhan Zhang",
      "Xiaode Liu",
      "Yuanpei Chen",
      "Weihang Peng",
      "Yufei Guo",
      "Xuhui Huang",
      "Zhe Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29636": {
    "title": "Cached Transformers: Improving Transformers with Differentiable Memory Cachde",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyang Zhang",
      "Wenqi Shao",
      "Yixiao Ge",
      "Xiaogang Wang",
      "Jinwei Gu",
      "Ping Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29637": {
    "title": "An Implicit Trust Region Approach to Behavior Regularized Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Zhang",
      "Xiaoyang Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29638": {
    "title": "Towards a Theoretical Understanding of Why Local Search Works for Clustering with Fair-Center Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Zhang",
      "Junfeng Yang",
      "Limei Liu",
      "Xuesong Xu",
      "Guozhen Rong",
      "Qilong Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29639": {
    "title": "Symmetric Self-Paced Learning for Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Di Zhao",
      "Yun Sing Koh",
      "Gillian Dobbie",
      "Hongsheng Hu",
      "Philippe Fournier-Viger"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29640": {
    "title": "Dynamic Reactive Spiking Graph Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Zhao",
      "Xu Yang",
      "Cheng Deng",
      "Junchi Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29641": {
    "title": "Learning Visual Abstract Reasoning through Dual-Stream Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Zhao",
      "Chang Xu",
      "Bailu Si"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29642": {
    "title": "Robust Visual Recognition with Class-Imbalanced Open-World Noisy Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Na Zhao",
      "Gim Hee Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29643": {
    "title": "From GARCH to Neural Network for Volatility Forecast",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengfei Zhao",
      "Haoren Zhu",
      "Wilfred Siu Hung NG",
      "Dik Lun Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29644": {
    "title": "Robust Nonparametric Regression under Poisoning Attack",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Puning Zhao",
      "Zhiguo Wan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29645": {
    "title": "Embedded Feature Selection on Graph-Based Multi-View Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhui Zhao",
      "Guangfei Li",
      "Haizhou Yang",
      "Quanxue Gao",
      "Qianqian Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29646": {
    "title": "Domain Invariant Learning for Gaussian Processes and Bayesian Exploration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xilong Zhao",
      "Siyuan Bian",
      "Yaoyun Zhang",
      "Yuliang Zhang",
      "Qinying Gu",
      "Xinbing Wang",
      "Chenghu Zhou",
      "Nanyang Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29647": {
    "title": "CcDPM: A Continuous Conditional Diffusion Probabilistic Model for Inverse Design",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanxuan Zhao",
      "Peng Zhang",
      "Guopeng Sun",
      "Zhigong Yang",
      "Jianqiang Chen",
      "Yueqing Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29648": {
    "title": "A Twist for Graph Classification: Optimizing Causal Information Flow in Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Zhao",
      "Pengkun Wang",
      "Haibin Wen",
      "Yudong Zhang",
      "Zhengyang Zhou",
      "Yang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29649": {
    "title": "DCLP: Neural Architecture Predictor with Curriculum Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shenghe Zheng",
      "Hongzhi Wang",
      "Tianyu Mu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29650": {
    "title": "Confusing Pair Correction Based on Category Prototype for Domain Adaptation under Noisy Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Churan Zhi",
      "Junbao Zhuo",
      "Shuhui Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29651": {
    "title": "Knowledge-Aware Parameter Coaching for Personalized Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingjian Zhi",
      "Yuanguo Bi",
      "Wenchao Xu",
      "Haozhao Wang",
      "Tianao Xiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29652": {
    "title": "No Prior Mask: Eliminate Redundant Action for Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dianyu Zhong",
      "Yiqin Yang",
      "Qianchuan Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29653": {
    "title": "PreRoutGNN for Timing Prediction with Order Preserving Partition: Global Circuit Pre-training, Local Delay Learning and Attentional Cell Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruizhe Zhong",
      "Junjie Ye",
      "Zhentao Tang",
      "Shixiong Kai",
      "Mingxuan Yuan",
      "Jianye Hao",
      "Junchi Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29654": {
    "title": "Cycle Self-Refinement for Multi-Source Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoyang Zhou",
      "Zengmao Wang",
      "Bo Du",
      "Yong Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29655": {
    "title": "Explaining Generalization Power of a DNN Using Interactive Concepts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huilin Zhou",
      "Hao Zhang",
      "Huiqi Deng",
      "Dongrui Liu",
      "Wen Shen",
      "Shih-Han Chan",
      "Quanshi Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29656": {
    "title": "Token-Level Contrastive Learning with Modality-Aware Prompting for Multimodal Intent Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qianrui Zhou",
      "Hua Xu",
      "Hao Li",
      "Hanlei Zhang",
      "Xiaohan Zhang",
      "Yifan Wang",
      "Kai Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29657": {
    "title": "On the Robustness of Neural-Enhanced Video Streaming against Adversarial Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihua Zhou",
      "Jingcai Guo",
      "Song Guo",
      "Ruibin Li",
      "Jie Zhang",
      "Bingjie Wang",
      "Zhenda Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29658": {
    "title": "Generalizable Task Representation Learning for Offline Meta-Reinforcement Learning with Data Limitations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renzhe Zhou",
      "Chen-Xiao Gao",
      "Zongzhang Zhang",
      "Yang Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29659": {
    "title": "Federated Label-Noise Learning with Local Diversity Product Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaochen Zhou",
      "Xudong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29660": {
    "title": "Abstract and Explore: A Novel Behavioral Metric with Cyclic Dynamics in Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anjie Zhu",
      "Peng-Fei Zhang",
      "Ruihong Qiu",
      "Zetao Zheng",
      "Zi Huang",
      "Jie Shao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29661": {
    "title": "Adaptive Meta-Learning Probabilistic Inference Framework for Long Sequence Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianping Zhu",
      "Xin Guo",
      "Yang Chen",
      "Yao Yang",
      "Wenbo Li",
      "Bo Jin",
      "Fei Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29662": {
    "title": "Towards the Disappearing Truth: Fine-Grained Joint Causal Influences Learning with Hidden Variable-Driven Causal Hypergraphs in Time Series",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Zhu",
      "Chunhui Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29663": {
    "title": "Contrastive Balancing Representation Learning for Heterogeneous Dose-Response Curves Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minqin Zhu",
      "Anpeng Wu",
      "Haoxuan Li",
      "Ruoxuan Xiong",
      "Bo Li",
      "Xiaoqing Yang",
      "Xuan Qin",
      "Peng Zhen",
      "Jiecheng Guo",
      "Fei Wu",
      "Kun Kuang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29664": {
    "title": "Every Node Is Different: Dynamically Fusing Self-Supervised Tasks for Attributed Graph Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengfei Zhu",
      "Qian Wang",
      "Yu Wang",
      "Jialu Li",
      "Qinghua Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29665": {
    "title": "Double Buffers CEM-TD3: More Efficient Evolution and Richer Exploration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sheng Zhu",
      "Chun Shen",
      "Shuai Lü",
      "Junhong Wu",
      "Daolong An"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29666": {
    "title": "Decoding Global Preferences: Temporal and Cooperative Dependency Modeling in Multi-Agent Preference-Based Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianchen Zhu",
      "Yue Qiu",
      "Haoyi Zhou",
      "Jianxin Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29667": {
    "title": "Detection and Defense of Unlearnable Examples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Zhu",
      "Lijia Yu",
      "Xiao-Shan Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29668": {
    "title": "Robust Node Classification on Graph Data with Graph and Label Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yonghua Zhu",
      "Lei Feng",
      "Zhenyun Deng",
      "Yang Chen",
      "Robert Amor",
      "Michael Witbrock"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29669": {
    "title": "MFABA: A More Faithful and Accelerated Boundary-Based Attribution Method for Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyu Zhu",
      "Huaming Chen",
      "Jiayu Zhang",
      "Xinyi Wang",
      "Zhibo Jin",
      "Minhui Xue",
      "Dongxiao Zhu",
      "Kim-Kwang Raymond Choo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29670": {
    "title": "DS-AL: A Dual-Stream Analytic Learning for Exemplar-Free Class-Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huiping Zhuang",
      "Run He",
      "Kai Tong",
      "Ziqian Zeng",
      "Cen Chen",
      "Zhiping Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29671": {
    "title": "Patch-Aware Sample Selection for Efficient Masked Image Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengyang Zhuge",
      "Jiaxing Wang",
      "Yong Li",
      "Yongjun Bao",
      "Peisong  Wang",
      "Jian Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29672": {
    "title": "Dirichlet-Based Prediction Calibration for Learning with Noisy Labels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen-Chen Zong",
      "Ye-Wen Wang",
      "Ming-Kun Xie",
      "Sheng-Jun Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29673": {
    "title": "Coverage-Guaranteed Prediction Sets for Out-of-Distribution Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Zou",
      "Weiwei Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29674": {
    "title": "Generalization Analysis of Machine Learning Algorithms via the Worst-Case Data-Generating Probability Measure",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinying Zou",
      "Samir M. Perlaza",
      "Iñaki Esnaola",
      "Eitan Altman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29675": {
    "title": "Probabilistic Neural Circuits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pedro Zuidberg Dos Martires"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29676": {
    "title": "Improved Anonymous Multi-Agent Path Finding Algorithm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zain Alabedeen Ali",
      "Konstantin Yakovlev"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29677": {
    "title": "Cautiously-Optimistic Knowledge Sharing for Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanwen Ba",
      "Xuan Liu",
      "Xinning Chen",
      "Hao Wang",
      "Yang Xu",
      "Kenli Li",
      "Shigeng Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29678": {
    "title": "Natural Strategic Ability in Stochastic Multi-Agent Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raphaël Berthon",
      "Joost-Pieter Katoen",
      "Munyque Mittelmann",
      "Aniello Murano"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29679": {
    "title": "On Alternating-Time Temporal Logic, Hyperproperties, and Strategy Sharing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raven Beutner",
      "Bernd Finkbeiner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29680": {
    "title": "RGMComm: Return Gap Minimization via Discrete Communications in Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingdi Chen",
      "Tian Lan",
      "Carlee Joe-Wong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29681": {
    "title": "STAS: Spatial-Temporal Return Decomposition for Solving Sparse Rewards Problems in Multi-agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sirui Chen",
      "Zhaowei Zhang",
      "Yaodong Yang",
      "Yali Du"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29682": {
    "title": "Learning Efficient and Robust Multi-Agent Communication via Graph Information Bottleneck",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shifei Ding",
      "Wei Du",
      "Ling Ding",
      "Lili Guo",
      "Jian Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29683": {
    "title": "Expressive Multi-Agent Communication via Identity-Aware Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Du",
      "Shifei Ding",
      "Lili Guo",
      "Jian Zhang",
      "Ling Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29684": {
    "title": "Situation-Dependent Causal Influence-Based Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Du",
      "Yutong Ye",
      "Pengyu Zhang",
      "Yaning Yang",
      "Mingsong Chen",
      "Ting Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29685": {
    "title": "Learning Multi-Object Positional Relationships via Emergent Communication",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yicheng Feng",
      "Boshi An",
      "Zongqing Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29686": {
    "title": "Exact Algorithms and Lowerbounds for Multiagent Path Finding: Power of Treelike Topology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Foivos Fioravantes",
      "Dušan Knop",
      "Jan Matyáš Křištan",
      "Nikolaos Melissinos",
      "Michal Opler"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29687": {
    "title": "The Irrelevance of Influencers: Information Diffusion with Re-Activation and Immunity Lasts Exponentially Long on Social Network Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tobias Friedrich",
      "Andreas Göbel",
      "Nicolas Klodt",
      "Martin S. Krejca",
      "Marcus Pappik"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29688": {
    "title": "Memory Asymmetry Creates Heteroclinic Orbits to Nash Equilibrium in Learning in Zero-Sum Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuma Fujimoto",
      "Kaito Ariu",
      "Kenshi Abe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29689": {
    "title": "Factored Online Planning in Many-Agent POMDPs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maris F. L. Galesloot",
      "Thiago D. Simão",
      "Sebastian Junges",
      "Nils Jansen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29690": {
    "title": "Foundations of Reactive Synthesis for Declarative Process Specifications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Geatti",
      "Marco Montali",
      "Andrey Rivkin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29691": {
    "title": "Learning in Online Principal-Agent Interactions: The Power of Menus",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minbiao Han",
      "Michael Albert",
      "Haifeng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29692": {
    "title": "Stability of Multi-Agent Learning in Competitive Networks: Delaying the Onset of Chaos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aamal Hussain",
      "Francesco Belardinelli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29693": {
    "title": "Settling Decentralized Multi-Agent Coordinated Exploration by Novelty Sharing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haobin Jiang",
      "Ziluo Ding",
      "Zongqing Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29694": {
    "title": "Optimistic Value Instructors for Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Li",
      "Yupeng Zhang",
      "Jianqi Wang",
      "Yujing Hu",
      "Shaokang Dong",
      "Wenbin Li",
      "Tangjie Lv",
      "Changjie Fan",
      "Yang Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29695": {
    "title": "ConcaveQ: Non-monotonic Value Function Factorization via Concave Representations in Deep Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huiqun Li",
      "Hanhan Zhou",
      "Yifei Zou",
      "Dongxiao Yu",
      "Tian Lan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29696": {
    "title": "Transition-Informed Reinforcement Learning for Large-Scale Stackelberg Mean-Field Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengdeng Li",
      "Runsheng Yu",
      "Xinrun Wang",
      "Bo An"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29697": {
    "title": "Decentralized Gradient-Free Methods for Stochastic Non-smooth Non-convex Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenwei Lin",
      "Jingfan Xia",
      "Qi Deng",
      "Luo Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29698": {
    "title": "Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeyang Liu",
      "Lipeng Wan",
      "Xinrui Yang",
      "Zhuoran Chen",
      "Xingyu Chen",
      "Xuguang Lan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29699": {
    "title": "TAPE: Leveraging Agent Topology for Cooperative Multi-Agent Policy Gradient",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingzhou Lou",
      "Junge Zhang",
      "Timothy J. Norman",
      "Kaiqi Huang",
      "Yali Du"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29700": {
    "title": "PMAC: Personalized Multi-Agent Communication",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangrui Meng",
      "Ying Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29701": {
    "title": "Adaptive Anytime Multi-Agent Path Finding Using Bandit-Based Large Neighborhood Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomy Phan",
      "Taoan Huang",
      "Bistra Dilkina",
      "Sven Koenig"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29702": {
    "title": "Minimum Coverage Sets for Training Robust Ad Hoc Teamwork Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Rahman",
      "Jiaxun Cui",
      "Peter Stone"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29703": {
    "title": "Decentralized Monte Carlo Tree Search for Partially Observable Multi-Agent Pathfinding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexey Skrynnik",
      "Anton Andreychuk",
      "Konstantin Yakovlev",
      "Aleksandr Panov"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29704": {
    "title": "Learn to Follow: Decentralized Lifelong Multi-Agent Pathfinding via Planning and Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexey Skrynnik",
      "Anton Andreychuk",
      "Maria Nesterova",
      "Konstantin Yakovlev",
      "Aleksandr Panov"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29705": {
    "title": "What Makes Good Collaborative Views? Contrastive Mutual Information Maximization for Multi-Agent Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wanfang Su",
      "Lixing Chen",
      "Yang Bai",
      "Xi Lin",
      "Gaolei Li",
      "Zhe Qu",
      "Pan Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29706": {
    "title": "Bidirectional Temporal Plan Graph: Enabling Switchable Passing Orders for More Efficient Multi-Agent Path Finding Plan Execution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Su",
      "Rishi Veerapaneni",
      "Jiaoyang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29707": {
    "title": "Large-Scale Multi-Robot Coverage Path Planning via Local Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingtao Tang",
      "Hang Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29708": {
    "title": "Robust Communicative Multi-Agent Reinforcement Learning with Active Defense",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lebin Yu",
      "Yunbo Qiu",
      "Quanming Yao",
      "Yuan Shen",
      "Xudong Zhang",
      "Jian Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29709": {
    "title": "Leveraging Partial Symmetry for Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Yu",
      "Rongye Shi",
      "Pu Feng",
      "Yongkai Tian",
      "Simin Li",
      "Shuhao Liao",
      "Wenjun Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29710": {
    "title": "ProAgent: Building Proactive Cooperative Agents with Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ceyao Zhang",
      "Kaijie Yang",
      "Siyi Hu",
      "Zihao Wang",
      "Guanghe Li",
      "Yihang Sun",
      "Cheng Zhang",
      "Zhaowei Zhang",
      "Anji Liu",
      "Song-Chun Zhu",
      "Xiaojun Chang",
      "Junge Zhang",
      "Feng Yin",
      "Yitao Liang",
      "Yaodong Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29711": {
    "title": "Intrinsic Action Tendency Consistency for Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junkai Zhang",
      "Yifan Zhang",
      "Xi Sheryl Zhang",
      "Yifan Zang",
      "Jian Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29712": {
    "title": "Emergent Communication for Numerical Concepts Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Enshuai Zhou",
      "Yifan Hao",
      "Rui Zhang",
      "Yuxuan Guo",
      "Zidong Du",
      "Xishan Zhang",
      "Xinkai Song",
      "Chao Wang",
      "Xuehai Zhou",
      "Jiaming Guo",
      "Qi Yi",
      "Shaohui Peng",
      "Di Huang",
      "Ruizhi Chen",
      "Qi Guo",
      "Yunji Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29713": {
    "title": "Decomposing Temporal Equilibrium Strategy for Coordinated Distributed Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyang Zhu",
      "Wen Si",
      "Jinyu Zhu",
      "Zhihao Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29714": {
    "title": "Balancing Humans and Machines: A Study on Integration Scale and Its Impact on Collaborative Performance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Zou",
      "Sannyuya Liu",
      "Yawei Luo",
      "Yaqi Liu",
      "Jintian Feng",
      "Mengqi Wei",
      "Jianwen Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29715": {
    "title": "Frame Semantic Role Labeling Using Arbitrary-Order Conditional Random Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoyi Ai",
      "Kewei Tu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29716": {
    "title": "DTF-AT: Decoupled Time-Frequency Audio Transformer for Event Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tony Alex",
      "Sara Ahmed",
      "Armin Mustafa",
      "Muhammad Awais",
      "Philip JB Jackson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29717": {
    "title": "WikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in Wikipedia",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kenichiro Ando",
      "Satoshi Sekine",
      "Mamoru Komachi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29718": {
    "title": "Beyond Grounding: Extracting Fine-Grained Event Hierarchies across Modalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hammad Ayyubi",
      "Christopher Thomas",
      "Lovish Chum",
      "Rahul Lokesh",
      "Long Chen",
      "Yulei Niu",
      "Xudong Lin",
      "Xuande Feng",
      "Jaywon Koo",
      "Sounak Ray",
      "Shih-Fu Chang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29719": {
    "title": "All Should Be Equal in the Eyes of LMs: Counterfactually Aware Fair Text Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pragyan Banerjee",
      "Abhinav Java",
      "Surgan Jandial",
      "Simra Shahid",
      "Shaz Furniturewala",
      "Balaji Krishnamurthy",
      "Sumit Bhatia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29720": {
    "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maciej Besta",
      "Nils Blach",
      "Ales Kubicek",
      "Robert Gerstenberger",
      "Michal Podstawski",
      "Lukas Gianinazzi",
      "Joanna Gajda",
      "Tomasz Lehmann",
      "Hubert Niewiadomski",
      "Piotr Nyczyk",
      "Torsten Hoefler"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29721": {
    "title": "When Do Program-of-Thought Works for Reasoning?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Bi",
      "Ningyu Zhang",
      "Yinuo Jiang",
      "Shumin Deng",
      "Guozhou Zheng",
      "Huajun Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29722": {
    "title": "Beyond Attention: Breaking the Limits of Transformer Context Length with Recurrent Memory",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aydar Bulatov",
      "Yuri Kuratov",
      "Yermek Kapushev",
      "Mikhail Burtsev"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29723": {
    "title": "MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Cai",
      "Linlin Wang",
      "Ye Wang",
      "Gerard de Melo",
      "Ya Zhang",
      "Yanfeng Wang",
      "Liang He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29724": {
    "title": "CAR-Transformer: Cross-Attention Reinforcement Transformer for Cross-Lingual Summarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuang Cai",
      "Yuyu Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29725": {
    "title": "Compositional Generalization for Multi-Label Text Classification: A Data-Augmentation Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyang Chai",
      "Zhuang Li",
      "Jiahui Liu",
      "Lei Chen",
      "Fei Li",
      "Donghong Ji",
      "Chong Teng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29726": {
    "title": "Counterfactual-Enhanced Information Bottleneck for Aspect-Based Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingshan Chang",
      "Min Yang",
      "Qingshan Jiang",
      "Ruifeng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29727": {
    "title": "Visual Instruction Tuning with Polite Flamingo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Delong Chen",
      "Jianfeng Liu",
      "Wenliang Dai",
      "Baoyuan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29728": {
    "title": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Chen",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29729": {
    "title": "CIDR: A Cooperative Integrated Dynamic Refining Method for Minimal Feature Removal Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qian Chen",
      "Taolin Zhang",
      "Dongyang Li",
      "Xiaofeng He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29730": {
    "title": "Is a Large Language Model a Good Annotator for Event Extraction?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruirui Chen",
      "Chengwei Qin",
      "Weifeng Jiang",
      "Dongkyu Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29731": {
    "title": "Modeling Adaptive Inter-Task Feature Interactions via Sentiment-Aware Contrastive Learning for Joint Aspect-Sentiment Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Chen",
      "Yuxuan Liu",
      "Zhao Zhang",
      "Fuzhen Zhuang",
      "Jiang Zhong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29732": {
    "title": "From Coarse to Fine: A Distillation Method for Fine-Grained Emotion-Causal Span Pair Extraction in Conversation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinhao Chen",
      "Chong Yang",
      "Changzhi Sun",
      "Man Lan",
      "Aimin Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29733": {
    "title": "Divergence-Guided Simultaneous Speech Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinjie Chen",
      "Kai Fan",
      "Wei Luo",
      "Linlin Zhang",
      "Libo Zhao",
      "Xinggao Liu",
      "Zhongqiang Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29734": {
    "title": "Benchmarking Large Language Models on Controllable Generation under Diversified Instructions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihan Chen",
      "Benfeng Xu",
      "Quan Wang",
      "Yi Liu",
      "Zhendong Mao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29735": {
    "title": "Journey to the Center of the Knowledge Neurons: Discoveries of Language-Independent Knowledge Neurons and Degenerate Knowledge Neurons",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuheng Chen",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29736": {
    "title": "Talk Funny! A Large-Scale Humor Response Dataset with Chain-of-Humor Interpretation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyan Chen",
      "Yichen Yuan",
      "Panjun Liu",
      "Dayiheng Liu",
      "Qinghao Guan",
      "Mengfei Guo",
      "Haiming Peng",
      "Bang Liu",
      "Zhixu Li",
      "Yanghua Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29737": {
    "title": "Editing Language Model-Based Knowledge Graph Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Cheng",
      "Ningyu Zhang",
      "Bozhong Tian",
      "Xi Chen",
      "Qingbin Liu",
      "Huajun Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29738": {
    "title": "Towards Multi-Intent Spoken Language Understanding via Hierarchical Attention and Optimal Transport",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuxin Cheng",
      "Zhihong Zhu",
      "Hongxiang Li",
      "Yaowei Li",
      "Xianwei Zhuang",
      "Yuexian Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29739": {
    "title": "Cooper: Coordinating Specialized Agents towards a Complex Dialogue Goal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Cheng",
      "Wenge Liu",
      "Jian Wang",
      "Chak Tou Leong",
      "Yi Ouyang",
      "Wenjie Li",
      "Xian Wu",
      "Yefeng Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29740": {
    "title": "DDDM-VC: Decoupled Denoising Diffusion Models with Disentangled Representation and Prior Mixup for Verified Robust Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ha-Yeong Choi",
      "Sang-Hoon Lee",
      "Seong-Whan Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29741": {
    "title": "How to Protect Copyright Data in Optimization of Large Language Models?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Timothy Chu",
      "Zhao Song",
      "Chiwun Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29742": {
    "title": "Unsupervised Layer-Wise Score Aggregation for Textual OOD Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maxime Darrin",
      "Guillaume Staerman",
      "Eduardo Dadalto Camara Gomes",
      "Jackie C. K. Cheung",
      "Pablo Piantanida",
      "Pierre Colombo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29743": {
    "title": "Spanning the Spectrum of Hatred Detection: A Persian Multi-Label Hate Speech Dataset with Annotator Rationales",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zahra  Delbari",
      "Nafise Sadat Moosavi",
      "Mohammad Taher Pilehvar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29744": {
    "title": "Enhancing Bilingual Lexicon Induction via Bi-directional Translation Pair Retrieving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiuyu Ding",
      "Hailong Cao",
      "Tiejun Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29745": {
    "title": "From Retrieval to Generation: A Simple and Unified Generative Model for End-to-End Task-Oriented Dialogue",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeyuan Ding",
      "Zhihao Yang",
      "Ling Luo",
      "Yuanyuan Sun",
      "Hongfei Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29746": {
    "title": "How to Trade Off the Quantity and Capacity of Teacher Ensemble: Learning Categorical Distribution to Stochastically Employ a Teacher for Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixiang Ding",
      "Guoqing Jiang",
      "Shuai Zhang",
      "Lin Guo",
      "Wei Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29747": {
    "title": "UniCATS: A Unified Context-Aware Text-to-Speech Framework with Contextual VQ-Diffusion and Vocoding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenpeng Du",
      "Yiwei Guo",
      "Feiyu Shen",
      "Zhijun Liu",
      "Zheng Liang",
      "Xie Chen",
      "Shuai Wang",
      "Hui Zhang",
      "Kai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29748": {
    "title": "DocMSU: A Comprehensive Benchmark for Document-Level Multimodal Sarcasm Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Du",
      "Guoshun Nan",
      "Sicheng Zhang",
      "Binzhu Xie",
      "Junrui Xu",
      "Hehe Fan",
      "Qimei Cui",
      "Xiaofeng Tao",
      "Xudong Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29749": {
    "title": "AdaCCD: Adaptive Semantic Contrasts Discovery Based Cross Lingual Adaptation for Code Clone Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangkai Du",
      "Tengfei Ma",
      "Lingfei Wu",
      "Xuhong Zhang",
      "Shouling Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29750": {
    "title": "Frugal LMs Trained to Invoke Symbolic Solvers Achieve Parameter-Efficient Arithmetic Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Subhabrata Dutta",
      "Ishan Pandey",
      "Joykirat Singh",
      "Sunny Manchanda",
      "Soumen Chakrabarti",
      "Tanmoy Chakraborty"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29751": {
    "title": "Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Caoyun Fan",
      "Jindou Chen",
      "Yaohui Jin",
      "Hao He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29752": {
    "title": "Enhancing Low-Resource Relation Representations through Multi-View Decoupling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenghao Fan",
      "Wei Wei",
      "Xiaoye Qu",
      "Zhenyi Lu",
      "Wenfeng Xie",
      "Yu Cheng",
      "Dangyang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29753": {
    "title": "Quantum-Inspired Neural Network with Runge-Kutta Method",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zipeng Fan",
      "Jing Zhang",
      "Peng Zhang",
      "Qianxi Lin",
      "Hui Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29754": {
    "title": "Large Language Models Are Neurosymbolic Reasoners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meng Fang",
      "Shilong Deng",
      "Yudi Zhang",
      "Zijing Shi",
      "Ling Chen",
      "Mykola Pechenizkiy",
      "Jun Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29755": {
    "title": "Combining Multiple Supervision for Robust Zero-Shot Dense Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Fang",
      "Qingyao Ai",
      "Jingtao Zhan",
      "Yiqun Liu",
      "Xiaolong Wu",
      "Zhao Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29756": {
    "title": "Watermarking Conditional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark Remedy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Fu",
      "Deyi Xiong",
      "Yue Dong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29757": {
    "title": "BAND: Biomedical Alert News Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Fu",
      "Meiru Zhang",
      "Zaiqiao Meng",
      "Yannan Shen",
      "David Buckeridge",
      "Nigel Collier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29758": {
    "title": "Winnie: Task-Oriented Dialog System with Structure-Aware Contrastive Learning and Enhanced Policy Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaizhi Gao",
      "Tianyu Wang",
      "Zhongjing Ma",
      "Suli Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29759": {
    "title": "Confucius: Iterative Tool Learning from Introspection Feedback by Easy-to-Difficult Curriculum",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shen Gao",
      "Zhengliang Shi",
      "Minghang Zhu",
      "Bowen Fang",
      "Xin Xin",
      "Pengjie Ren",
      "Zhumin Chen",
      "Jun Ma",
      "Zhaochun Ren"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29760": {
    "title": "Customizing Language Model Responses with Contrastive In-Context Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Gao",
      "Kamalika Das"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29761": {
    "title": "DA-Net: A Disentangled and Adaptive Network for Multi-Source Cross-Lingual Transfer Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ling Ge",
      "Chunming Hu",
      "Guanghui Ma",
      "Jihong Liu",
      "Hong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29762": {
    "title": "Discrepancy and Uncertainty Aware Denoising Knowledge Distillation for Zero-Shot Cross-Lingual Named Entity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ling Ge",
      "Chunming Hu",
      "Guanghui Ma",
      "Jihong Liu",
      "Hong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29763": {
    "title": "Who Knows the Answer? Finding the Best Model and Prompt for Each Query Using Confidence-Based Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Walter Gerych",
      "Yara Rizk",
      "Vatche Isahagian",
      "Vinod Muthusamy",
      "Evelyn Duesterwald",
      "Praveen Venkateswaran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29764": {
    "title": "A General Search-Based Framework for Generating Textual Counterfactual Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Gilo",
      "Shaul Markovitch"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29765": {
    "title": "What Makes Quantization for Large Language Model Hard? An Empirical Study from the Lens of Perturbation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuocheng Gong",
      "Jiahao Liu",
      "Jingang Wang",
      "Xunliang Cai",
      "Dongyan Zhao",
      "Rui Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29766": {
    "title": "CoPL: Contextual Prompt Learning for Vision-Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Koustava Goswami",
      "Srikrishna Karanam",
      "Prateksha Udhayanan",
      "K J Joseph",
      "Balaji Vasan Srinivasan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29767": {
    "title": "Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhouhong Gu",
      "Xiaoxuan Zhu",
      "Haoning Ye",
      "Lin Zhang",
      "Jianchen Wang",
      "Yixin Zhu",
      "Sihang Jiang",
      "Zhuozhi Xiong",
      "Zihan Li",
      "Weijie Wu",
      "Qianyu He",
      "Rui Xu",
      "Wenhao Huang",
      "Jingping Liu",
      "Zili Wang",
      "Shusen Wang",
      "Weiguo Zheng",
      "Hongwei Feng",
      "Yanghua Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29768": {
    "title": "DINGO: Towards Diverse and Fine-Grained Instruction-Following Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihui Gu",
      "Xingwu Sun",
      "Fengzong Lian",
      "Zhanhui Kang",
      "Chengzhong Xu",
      "Ju Fan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29769": {
    "title": "MM-TTS: Multi-Modal Prompt Based Style Transfer for Expressive Text-to-Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Guan",
      "Yishuang Li",
      "Tao Li",
      "Hukai Huang",
      "Feng Wang",
      "Jiayan Lin",
      "Lingyan Huang",
      "Lin Li",
      "Qingyang Hong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29770": {
    "title": "Mitigating Large Language Model Hallucinations via Autonomous Knowledge Graph-Based Retrofitting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyan Guan",
      "Yanjiang Liu",
      "Hongyu Lin",
      "Yaojie Lu",
      "Ben He",
      "Xianpei Han",
      "Le Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29771": {
    "title": "Detecting and Preventing Hallucinations in Large Vision Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anisha Gunjal",
      "Jihan Yin",
      "Erhan Bas"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29772": {
    "title": "MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoqiang Guo",
      "Sendong Zhao",
      "Haochun Wang",
      "Yanrui Du",
      "Bing Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29773": {
    "title": "Audio Generation with Multiple Conditional Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhifang Guo",
      "Jianguo Mao",
      "Rui Tao",
      "Long Yan",
      "Kazushige Ouchi",
      "Hong Liu",
      "Xiangdong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29774": {
    "title": "Small Language Model Can Self-Correct",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haixia Han",
      "Jiaqing Liang",
      "Jie Shi",
      "Qianyu He",
      "Yanghua Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29775": {
    "title": "Decoupling Representation and Knowledge for Few-Shot Intent Classification and Slot Filling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Han",
      "Yixiong Zou",
      "Haozhao Wang",
      "Jun Wang",
      "Wei Liu",
      "Yao Wu",
      "Tao Zhang",
      "Ruixuan Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29776": {
    "title": "Multi-Modal Latent Space Learning for Chain-of-Thought Reasoning in Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liqi He",
      "Zuchao Li",
      "Xiantao Cai",
      "Ping Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29777": {
    "title": "Can Large Language Models Understand Real-World Complex Instructions?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qianyu He",
      "Jie Zeng",
      "Wenhao Huang",
      "Lina Chen",
      "Jin Xiao",
      "Qianxi He",
      "Xunzhe Zhou",
      "Jiaqing Liang",
      "Yanghua Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29778": {
    "title": "Improving Factual Error Correction by Learning to Inject Factual Errors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingwei He",
      "Qianru Zhang",
      "A-Long Jin",
      "Jun Ma",
      "Yuan Yuan",
      "Siu Ming Yiu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29779": {
    "title": "Text2Analysis: A Benchmark of Table Question Answering with Advanced Data Analysis and Unclear Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyi He",
      "Mengyu Zhou",
      "Xinrun Xu",
      "Xiaojun Ma",
      "Rui Ding",
      "Lun Du",
      "Yan Gao",
      "Ran Jia",
      "Xu Chen",
      "Shi Han",
      "Zejian Yuan",
      "Dongmei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29780": {
    "title": "ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zachary Horvitz",
      "Ajay Patel",
      "Chris Callison-Burch",
      "Zhou Yu",
      "Kathleen McKeown"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29781": {
    "title": "ShareBERT: Embeddings Are Capable of Learning Hidden Layers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jia Cheng Hu",
      "Roberto Cavicchioli",
      "Giulia Berardinelli",
      "Alessandro Capotondi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29782": {
    "title": "LLM vs Small Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linmei Hu",
      "Hongyu He",
      "Duokang Wang",
      "Ziwang Zhao",
      "Yingxia Shao",
      "Liqiang Nie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29783": {
    "title": "Learning Robust Rationales for Model Explainability: A Guidance-Based Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuaibo Hu",
      "Kui Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29784": {
    "title": "Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinshuo Hu",
      "Dongfang Li",
      "Baotian Hu",
      "Zihao Zheng",
      "Zhenyu Liu",
      "Min Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29785": {
    "title": "Three Heads Are Better than One: Improving Cross-Domain NER with Progressive Decomposed Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuming Hu",
      "Zhaochen Hong",
      "Yong Jiang",
      "Zhichao Lin",
      "Xiaobin Wang",
      "Pengjun Xie",
      "Philip S. Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29786": {
    "title": "Uncovering and Mitigating the Hidden Chasm: A Study on the Text-Text Domain Gap in Euphemism Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxue Hu",
      "Junsong Li",
      "Mingmin Wu",
      "Zhongqiang Huang",
      "Gang Chen",
      "Ying Sha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29787": {
    "title": "PoetryDiffusion: Towards Joint Semantic and Metrical Manipulation in Poetry Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Hu",
      "Chumin Liu",
      "Yue Feng",
      "Anh Tuan Luu",
      "Bryan Hooi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29788": {
    "title": "Towards Equipping Transformer with the Ability of Systematic Compositionality",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Huang",
      "Peixin Qin",
      "Wenqiang Lei",
      "Jiancheng Lv"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29789": {
    "title": "Cross-Modal and Uni-Modal Soft-Label Alignment for Image-Text Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hailang Huang",
      "Zhijie Nie",
      "Ziqiao Wang",
      "Ziyu Shang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29790": {
    "title": "Response Enhanced Semi-supervised Dialogue Query Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianheng Huang",
      "Ante Wang",
      "Linfeng Gao",
      "Linfeng Song",
      "Jinsong Su"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29791": {
    "title": "PMRC: Prompt-Based Machine Reading Comprehension for Few-Shot Named Entity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin Huang",
      "Danfeng Yan",
      "Yuanqiang Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29792": {
    "title": "Revisiting Document-Level Relation Extraction with Context-Guided Link Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Monika Jain",
      "Raghava Mutharaju",
      "Ramakanth Kavuluru",
      "Kuldeep Singh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29793": {
    "title": "Enhancing Zero-Shot Multi-Speaker TTS with Negated Speaker Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yejin Jeon",
      "Yunsu Kim",
      "Gary Geunbae  Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29794": {
    "title": "Chain-of-Thought Improves Text Generation with Citations in Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Ji",
      "Huijun Liu",
      "Mingzhe Du",
      "See-Kiong Ng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29795": {
    "title": "Debiasing Multimodal Sarcasm Detection with Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengzhao Jia",
      "Can Xie",
      "Liqiang Jing"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29796": {
    "title": "ZO-AdaMU Optimizer: Adapting Perturbation by the Momentum and Uncertainty in Zeroth-Order Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuoran Jiang",
      "Qingcai Chen",
      "Youcheng Pan",
      "Yang Xiang",
      "Yukang Lin",
      "Xiangping Wu",
      "Chuanyi Liu",
      "Xiaobao Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29797": {
    "title": "Unsupervised Extractive Summarization with Learnable Length Control Strategies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renlong Jie",
      "Xiaojun Meng",
      "Xin Jiang",
      "Qun Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29798": {
    "title": "BOK-VQA: Bilingual outside Knowledge-Based Visual Question Answering via Graph Representation Pretraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "MinJun Kim",
      "SeungWoo Song",
      "YouHan Lee",
      "Haneol Jang",
      "KyungTae Lim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29799": {
    "title": "Improving Knowledge Extraction from LLMs for Task Learning through Agent Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James R. Kirk",
      "Robert E. Wray",
      "Peter Lindes",
      "John E. Laird"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29800": {
    "title": "On Unsupervised Domain Adaptation: Pseudo Label Guided Mixup for Adversarial Prompt Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fanshuang Kong",
      "Richong Zhang",
      "Ziqiao Wang",
      "Yongyi Mao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29801": {
    "title": "A Hierarchical Network for Multimodal Document-Level Relation Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingxing Kong",
      "Jiuliang Wang",
      "Zheng Ma",
      "Qifeng Zhou",
      "Jianbing Zhang",
      "Liang He",
      "Jiajun Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29802": {
    "title": "Large Language Models Are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taeyoon Kwon",
      "Kai Tzu-iunn Ong",
      "Dongjin Kang",
      "Seungjun Moon",
      "Jeong Ryong Lee",
      "Dosik Hwang",
      "Beomseok Sohn",
      "Yongsik Sim",
      "Dongha Lee",
      "Jinyoung Yeo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29803": {
    "title": "Frequency Spectrum Is More Effective for Multimodal Representation and Fusion: A Multimodal Spectrum Rumor Detector",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "An Lao",
      "Qi Zhang",
      "Chongyang Shi",
      "Longbing Cao",
      "Kun Yi",
      "Liang Hu",
      "Duoqian Miao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29804": {
    "title": "LAMPAT: Low-Rank Adaption for Multilingual Paraphrasing Using Adversarial Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khoi M. Le",
      "Trinh Pham",
      "Tho Quan",
      "Anh Tuan Luu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29805": {
    "title": "Continual Relation Extraction via Sequential Multi-Task Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thanh-Thien Le",
      "Manh Nguyen",
      "Tung Thanh Nguyen",
      "Linh Ngo Van",
      "Thien Huu Nguyen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29806": {
    "title": "Labels Need Prompts Too: Mask Matching for Natural Language Understanding Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Li",
      "Wei Ye",
      "Quansen Wang",
      "Wen Zhao",
      "Shikun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29807": {
    "title": "Harnessing Holistic Discourse Features and Triadic Interaction for Sentiment Quadruple Extraction in Dialogues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bobo Li",
      "Hao Fei",
      "Lizi Liao",
      "Yu Zhao",
      "Fangfang Su",
      "Fei Li",
      "Donghong Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29808": {
    "title": "Task Contamination: Language Models May Not Be Few-Shot Anymore",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changmao Li",
      "Jeffrey Flanigan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29809": {
    "title": "Dialogue for Prompting: A Policy-Gradient-Based Discrete Prompt Generation for Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengzhengxu Li",
      "Xiaoming Liu",
      "Yichen Wang",
      "Duyi Li",
      "Yu Lan",
      "Chao Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29810": {
    "title": "DeepSpeed Data Efficiency: Improving Deep Learning Model Quality and Training Efficiency via Efficient Data Sampling and Routing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Conglong Li",
      "Zhewei Yao",
      "Xiaoxia Wu",
      "Minjia Zhang",
      "Connor Holmes",
      "Cheng Li",
      "Yuxiong He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29811": {
    "title": "Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangjun Li",
      "David C. Hogg",
      "Anthony G. Cohn"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29812": {
    "title": "Exploiting Auxiliary Caption for Video Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongxiang Li",
      "Meng Cao",
      "Xuxin Cheng",
      "Yaowei Li",
      "Zhihong Zhu",
      "Yuexian Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29813": {
    "title": "VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialu Li",
      "Aishwarya Padmakumar",
      "Gaurav Sukhatme",
      "Mohit Bansal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29814": {
    "title": "Enhancing Multi-Label Classification via Dynamic Label-Order Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangnan Li",
      "Yice Zhang",
      "Shiwei Chen",
      "Ruifeng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29815": {
    "title": "Norm Tweaking: High-Performance Low-Bit Quantization of Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Li",
      "Qingyuan Li",
      "Bo Zhang",
      "Xiangxiang Chu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29816": {
    "title": "Object Attribute Matters in Visual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peize Li",
      "Qingyi Si",
      "Peng Fu",
      "Zheng Lin",
      "Yan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29817": {
    "title": "Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing Idiomatic Translation with Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuang Li",
      "Jiangjie Chen",
      "Siyu Yuan",
      "Xinyi Wu",
      "Hao Yang",
      "Shimin Tao",
      "Yanghua Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29818": {
    "title": "PMET: Precise Model Editing in a Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaopeng Li",
      "Shasha Li",
      "Shezheng Song",
      "Jing Yang",
      "Jun Ma",
      "Jie Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29819": {
    "title": "Dialogues Are Not Just Text: Modeling Cognition for Dialogue Coherence Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xue Li",
      "Jia Su",
      "Yang Yang",
      "Zipeng Gao",
      "Xinyu Duan",
      "Yi Guan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29820": {
    "title": "EcomGPT: Instruction-Tuning Large Language Models with Chain-of-Task Tasks for E-commerce",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangning Li",
      "Shirong Ma",
      "Xiaobin Wang",
      "Shen Huang",
      "Chengyue Jiang",
      "Hai-Tao Zheng",
      "Pengjun Xie",
      "Fei Huang",
      "Yong Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29821": {
    "title": "Turning Dust into Gold: Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwei Li",
      "Peiwen Yuan",
      "Shaoxiong Feng",
      "Boyuan Pan",
      "Bin Sun",
      "Xinglin Wang",
      "Heda Wang",
      "Kan Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29822": {
    "title": "LatestEval: Addressing Data Contamination in Language Model Evaluation through Dynamic and Time-Sensitive Test Construction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yucheng Li",
      "Frank Guerin",
      "Chenghua Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29823": {
    "title": "FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Li",
      "Sunqi Fan",
      "Yu Gu",
      "Xiuxing Li",
      "Zhichao Duan",
      "Bowen Dong",
      "Ning Liu",
      "Jianyong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29824": {
    "title": "Machine-Created Universal Language for Cross-Lingual Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaobo Liang",
      "Quanzhi Zhu",
      "Junhe Zhao",
      "Nan Duan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29825": {
    "title": "CFEVER: A Chinese Fact Extraction and VERification Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ying-Jia Lin",
      "Chun-Yi Lin",
      "Chia-Jen Yeh",
      "Yi-Ting Li",
      "Yun-Yu Hu",
      "Chih-Hao Hsu",
      "Mei-Feng Lee",
      "Hung-Yu Kao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29826": {
    "title": "Bootstrapping Large Language Models for Radiology Report Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chang Liu",
      "Yuanhe Tian",
      "Weidong Chen",
      "Yan Song",
      "Yongdong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29827": {
    "title": "Liberating Seen Classes: Boosting Few-Shot and Zero-Shot Text Classification via Anchor Generation and Classification Reframing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Liu",
      "Siyang Zhao",
      "Xiaotong Zhang",
      "Feng Zhang",
      "Wei Wang",
      "Fenglong Ma",
      "Hongyang Chen",
      "Hong Yu",
      "Xianchao Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29828": {
    "title": "Beyond Entities: A Large-Scale Multi-Modal Knowledge Graph with Triplet Fact Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingping Liu",
      "Mingchuan Zhang",
      "Weichen Li",
      "Chao Wang",
      "Shuang Li",
      "Haiyun Jiang",
      "Sihang Jiang",
      "Yanghua Xiao",
      "Yunwen Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29829": {
    "title": "Chinese Spelling Correction as Rephrasing Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linfeng Liu",
      "Hongqiu Wu",
      "Hai Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29830": {
    "title": "TA&AT: Enhancing Task-Oriented Dialog with Turn-Level Auxiliary Tasks and Action-Tree Based Scheduled Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longxiang Liu",
      "Xiuxing Li",
      "Yang Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29831": {
    "title": "Hierarchical Aligned Multimodal Learning for NER on Tweet Posts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peipei Liu",
      "Hong Li",
      "Yimo Ren",
      "Jie Liu",
      "Shuaizong Si",
      "Hongsong Zhu",
      "Limin Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29832": {
    "title": "Adaptive Prompt Routing for Arbitrary Text Style Transfer with Pre-trained Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingyi Liu",
      "Jinghui Qin",
      "Wenxuan Ye",
      "Hao Mou",
      "Yuxuan He",
      "Keze Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29833": {
    "title": "Emotion Rendering for Conversational Speech Synthesis with Heterogeneous Graph-Based Context Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Liu",
      "Yifan Hu",
      "Yi Ren",
      "Xiang Yin",
      "Haizhou Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29834": {
    "title": "Robust Evaluation Measures for Evaluating Social Biases in Masked Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29835": {
    "title": "Improved Graph Contrastive Learning for Short Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yonghao Liu",
      "Lan Huang",
      "Fausto Giunchiglia",
      "Xiaoyue Feng",
      "Renchu Guan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29836": {
    "title": "QuerySum: A Multi-Document Query-Focused Summarization Dataset Augmented with Similar Query Clusters",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yushan Liu",
      "Zili Wang",
      "Ruifeng Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29837": {
    "title": "Generative Multi-Modal Knowledge Retrieval with Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinwei Long",
      "Jiali Zeng",
      "Fandong Meng",
      "Zhiyuan Ma",
      "Kaiyan Zhang",
      "Bowen Zhou",
      "Jie Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29838": {
    "title": "Synergistic Anchored Contrastive Pre-training for Few-Shot Relation Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Da Luo",
      "Yanglei Gan",
      "Rui Hou",
      "Run Lin",
      "Qiao Liu",
      "Yuxiang Cai",
      "Wannian Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29839": {
    "title": "STAR: Boosting Low-Resource Information Extraction by Structure-to-Text Data Generation with Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyu Derek Ma",
      "Xiaoxuan Wang",
      "Po-Nien Kung",
      "P. Jeffrey Brantingham",
      "Nanyun Peng",
      "Wei Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29840": {
    "title": "Mastering Context-to-Label Representation Transformation for Event Causality Identification with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hieu Man",
      "Franck Dernoncourt",
      "Thien Huu Nguyen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29841": {
    "title": "Span Graph Transformer for Document-Level Named Entity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongli Mao",
      "Xian-Ling Mao",
      "Hanlin Tang",
      "Yu-Ming Shang",
      "Heyan Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29842": {
    "title": "Underspecification in Language Modeling Tasks: A Causality-Informed Study of Gendered Pronoun Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emily McMilin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29843": {
    "title": "MCL-NER: Cross-Lingual Named Entity Recognition via Multi-View Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ying Mo",
      "Jian Yang",
      "Jiahao Liu",
      "Qifan Wang",
      "Ruoyu Chen",
      "Jingang Wang",
      "Zhoujun Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29844": {
    "title": "KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debjyoti Mondal",
      "Suraj Modi",
      "Subhadarshi Panda",
      "Rituraj Singh",
      "Godawari Sudhakar Rao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29845": {
    "title": "Accelerating the Global Aggregation of Local Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alon Mor",
      "Yonatan Belinkov",
      "Benny Kimelfeld"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29846": {
    "title": "Self-Supervised Disentangled Representation Learning for Robust Target Speech Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoxi Mu",
      "Xinyu Yang",
      "Sining Sun",
      "Qing Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29847": {
    "title": "READ-PVLA: Recurrent Adapter with Partial Video-Language Alignment for Parameter-Efficient Transfer Learning in Low-Resource Video-Language Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thong Nguyen",
      "Xiaobao Wu",
      "Xinshuai Dong",
      "Khoi M. Le",
      "Zhiyuan Hu",
      "Cong-Duy Nguyen",
      "See-Kiong Ng",
      "Anh Tuan Luu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29848": {
    "title": "Code-Style In-Context Learning for Knowledge-Based Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhijie Nie",
      "Richong Zhang",
      "Zhongyuan Wang",
      "Xudong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29849": {
    "title": "Aspect-Based Sentiment Analysis with Explicit Sentiment Augmentations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihong Ouyang",
      "Zhiyao Yang",
      "Silong Liang",
      "Bing Wang",
      "Yimeng Wang",
      "Ximing Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29850": {
    "title": "Fact-Driven Logical Reasoning for Machine Reading Comprehension",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siru Ouyang",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29851": {
    "title": "Preparing Lessons for Progressive Training on Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Pan",
      "Ye Yuan",
      "Yichun Yin",
      "Jiaxin Shi",
      "Zenglin Xu",
      "Ming Zhang",
      "Lifeng Shang",
      "Xin Jiang",
      "Qun Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29852": {
    "title": "A Novel Energy Based Model Mechanism for Multi-Modal Aspect-Based Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianshuo Peng",
      "Zuchao Li",
      "Ping Wang",
      "Lefei Zhang",
      "Hai Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29853": {
    "title": "A Joint Framework with Heterogeneous-Relation-Aware Graph and Multi-Channel Label Enhancing Strategy for Event Causality Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruili Pu",
      "Yang Li",
      "Jun Zhao",
      "Suge Wang",
      "Deyu Li",
      "Jian Liao",
      "Jianxing Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29854": {
    "title": "MULTISCRIPT: Multimodal Script Learning for Supporting Open Domain Everyday Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyuan Qi",
      "Minqian Liu",
      "Ying Shen",
      "Zhiyang Xu",
      "Lifu Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29855": {
    "title": "Exploring Transformer Extrapolation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Qin",
      "Yiran Zhong",
      "Hui Deng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29856": {
    "title": "Using Artificial Populations to Study Psychological Phenomena in Neural Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jesse Roberts",
      "Kyle Moore",
      "Drew Wilenzick",
      "Douglas Fisher"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29857": {
    "title": "Better than Random: Reliable NLG Human Evaluation with Constrained Active Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Ruan",
      "Xiao Pu",
      "Mingqi Gao",
      "Xiaojun Wan",
      "Yuesheng Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29858": {
    "title": "VELMA: Verbalization Embodiment of LLM Agents for Vision and Language Navigation in Street View",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raphael Schumann",
      "Wanrong Zhu",
      "Weixi Feng",
      "Tsu-Jui Fu",
      "Stefan Riezler",
      "William Yang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29859": {
    "title": "OntoFact: Unveiling Fantastic Fact-Skeleton of LLMs via Ontology-Driven Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyu Shang",
      "Wenjun Ke",
      "Nana Xiu",
      "Peng Wang",
      "Jiajun Liu",
      "Yanhui Li",
      "Zhizhao Luo",
      "Ke Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29860": {
    "title": "Agile-Quant: Activation-Guided Quantization for Faster Inference of LLMs on the Edge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuan Shen",
      "Peiyan Dong",
      "Lei Lu",
      "Zhenglun Kong",
      "Zhengang Li",
      "Ming Lin",
      "Chao Wu",
      "Yanzhi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29861": {
    "title": "CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks for Chinese Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dan Shi",
      "Chaobin You",
      "Jiantao Huang",
      "Taihao Li",
      "Deyi Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29862": {
    "title": "A Unified Knowledge Transfer Network for Generalized Category Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenkai Shi",
      "Wenbin An",
      "Feng Tian",
      "Yan Chen",
      "Yaqiang Wu",
      "Qianying Wang",
      "Ping Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29863": {
    "title": "RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Shu",
      "Liangchen Luo",
      "Jayakumar Hoskere",
      "Yun Zhu",
      "Yinxiao Liu",
      "Simon Tong",
      "Jindong Chen",
      "Lei Meng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29864": {
    "title": "Well, Now We Know! Unveiling Sarcasm: Initiating and Exploring Multimodal Conversations with Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gopendra Vikram Singh",
      "Mauajama Firdaus",
      "Dushyant Singh Chauhan",
      "Asif Ekbal",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29865": {
    "title": "Preference Ranking Optimization for Human Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feifan Song",
      "Bowen Yu",
      "Minghao Li",
      "Haiyang Yu",
      "Fei Huang",
      "Yongbin Li",
      "Houfeng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29866": {
    "title": "TACIT: A Target-Agnostic Feature Disentanglement Framework for Cross-Domain Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Song",
      "Fausto Giunchiglia",
      "Yingji Li",
      "Mingjie Tian",
      "Hao Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29867": {
    "title": "A Dual-Way Enhanced Framework from Text Matching Point of View for Multimodal Entity Linking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shezheng Song",
      "Shan Zhao",
      "ChengYu Wang",
      "Tianwei Yan",
      "Shasha Li",
      "Xiaoguang Mao",
      "Meng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29868": {
    "title": "RoPDA: Robust Prompt-Based Data Augmentation for Low-Resource Named Entity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sihan Song",
      "Furao Shen",
      "Jian Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29869": {
    "title": "Wikiformer: Pre-training with Structured Information of Wikipedia for Ad-Hoc Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weihang Su",
      "Qingyao Ai",
      "Xiangsheng Li",
      "Jia Chen",
      "Yiqun Liu",
      "Xiaolong Wu",
      "Shengluan Hou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29870": {
    "title": "SIG: Speaker Identification in Literature via Prompt-Based Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenlin Su",
      "Liyan Xu",
      "Jin Xu",
      "Jiangnan Li",
      "Mingdu Huangfu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29871": {
    "title": "Collaborative Synthesis of Patient Records through Multi-Visit Health State Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongda Sun",
      "Hongzhan Lin",
      "Rui Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29872": {
    "title": "SciEval: A Multi-Level Large Language Model Evaluation Benchmark for Scientific Research",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liangtai Sun",
      "Yang Han",
      "Zihan Zhao",
      "Da Ma",
      "Zhennan Shen",
      "Baocai Chen",
      "Lu Chen",
      "Kai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29873": {
    "title": "UMIE: Unified Multimodal Information Extraction with Instruction Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lin  Sun",
      "Kai Zhang",
      "Qingyuan Li",
      "Renze Lou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29874": {
    "title": "InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document Understanding with Instructions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryota Tanaka",
      "Taichi Iki",
      "Kyosuke Nishida",
      "Kuniko Saito",
      "Jun Suzuki"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29875": {
    "title": "Graph Neural Prompting with Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijun Tian",
      "Huan Song",
      "Zichen Wang",
      "Haozhu Wang",
      "Ziqing Hu",
      "Fang Wang",
      "Nitesh V. Chawla",
      "Panpan Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29876": {
    "title": "Adaptive Graph Learning for Multimodal Conversational Emotion Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Geng Tu",
      "Tian Xie",
      "Bin Liang",
      "Hongpeng Wang",
      "Ruifeng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29877": {
    "title": "Dependency Structure-Enhanced Graph Attention Networks for Event Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qizhi Wan",
      "Changxuan Wan",
      "Keli Xiao",
      "Kun Lu",
      "Chenliang Li",
      "Xiping Liu",
      "Dexi Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29878": {
    "title": "ESRL: Efficient Sampling-Based Reinforcement Learning for Sequence Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenglong Wang",
      "Hang Zhou",
      "Yimin Hu",
      "Yifu Huo",
      "Bei Li",
      "Tongran Liu",
      "Tong Xiao",
      "Jingbo Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29879": {
    "title": "Exploring Equation as a Better Intermediate Meaning Representation for Numerical Reasoning of Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dingzirui Wang",
      "Longxu Dou",
      "Wenbin Zhang",
      "Junyu Zeng",
      "Wanxiang Che"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29880": {
    "title": "Manifold-Based Verbalizer Space Re-embedding for Tuning-Free Prompt-Based Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haochun Wang",
      "Sendong Zhao",
      "Chi Liu",
      "Nuwa Xi",
      "MuZhen Cai",
      "Bing Qin ",
      "Ting Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29881": {
    "title": "Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaan Wang",
      "JIanfeng Qu",
      "Kexin Wang",
      "Zhixu Li",
      "Wen Hua",
      "Ximing Li",
      "An Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29882": {
    "title": "Restoring Speaking Lips from Occlusion for Audio-Visual Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiadong Wang",
      "Zexu Pan",
      "Malu Zhang",
      "Robby T. Tan",
      "Haizhou Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29883": {
    "title": "Learning from Failure: Improving Meeting Summarization without Good Samples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Wang",
      "Xiutian Zhao",
      "Wei Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29884": {
    "title": "T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Wang",
      "Yi Hu",
      "Jiabang He",
      "Xing Xu",
      "Ning Liu",
      "Hui Liu",
      "Heng Tao Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29885": {
    "title": "Mitigating the Impact of False Negative in Dense Retrieval with Contrastive Confidence Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiqi Wang",
      "Yeqin Zhang",
      "Cam-Tu Nguyen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29886": {
    "title": "DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinghao Wang",
      "Junliang He",
      "Pengyu Wang",
      "Yunhua Zhou",
      "Tianxiang Sun",
      "Xipeng Qiu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29887": {
    "title": "LLMRG: Improving Recommendations through Large Language Model Reasoning Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Wang",
      "Zhixuan Chu",
      "Xin Ouyang",
      "Simeng Wang",
      "Hongyan Hao",
      "Yue Shen",
      "Jinjie Gu",
      "Siqiao Xue",
      "James Zhang",
      "Qing Cui",
      "Longfei Li",
      "Jun Zhou",
      "Sheng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29888": {
    "title": "A Positive-Unlabeled Metric Learning Framework for Document-Level Relation Extraction with Incomplete Labeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ye Wang",
      "Huazheng Pan",
      "Tao Zhang",
      "Wen Wu",
      "Wenxin Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29889": {
    "title": "Knowledge Graph Prompting for Multi-Document Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Wang",
      "Nedim Lipka",
      "Ryan A. Rossi",
      "Alexa Siu",
      "Ruiyi Zhang",
      "Tyler Derr"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29890": {
    "title": "STAIR: Spatial-Temporal Reasoning with Auditable Intermediate Results for Video Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yueqian Wang",
      "Yuxuan Wang",
      "Kai  Chen",
      "Dongyan Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29891": {
    "title": "Video Event Extraction with Multi-View Interaction Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiwen Wei",
      "Runyan Du",
      "Li Jin",
      "Jian Liu",
      "Jianhua Yin",
      "Linhao Zhang",
      "Jintao Liu",
      "Nayu Liu",
      "Jingyuan Zhang",
      "Zhi Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29892": {
    "title": "ConsistNER: Towards Instructive NER Demonstrations for LLMs with the Consistency of Ontology and Context",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxiao Wu",
      "Wenjun Ke",
      "Peng Wang",
      "Zhizhao Luo",
      "Guozheng Li",
      "Wanyi Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29893": {
    "title": "Mitigating Idiom Inconsistency: A Multi-Semantic Contrastive Learning Method for Chinese Idiom Reading Comprehension",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingmin Wu",
      "Yuxue Hu",
      "Yongcheng Zhang",
      "Zeng Zhi",
      "Guixin Su",
      "Ying Sha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29894": {
    "title": "Improving Open-Domain Dialogue Response Generation with Multi-Source Multilingual Commonsense Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sixing Wu",
      "Jiong Yu",
      "Jiahao Chen",
      "Xiaofan Deng",
      "Wei Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29895": {
    "title": "On the Affinity, Rationality, and Diversity of Hierarchical Topic Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaobao Wu",
      "Fengjun Pan",
      "Thong Nguyen",
      "Yichao Feng",
      "Chaoqun Liu",
      "Cong-Duy Nguyen",
      "Anh Tuan Luu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29896": {
    "title": "MindMap: Constructing Evidence Chains for Multi-Step Reasoning in Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangyu Wu",
      "Xu Han",
      "Wei Song",
      "Miaomiao Cheng",
      "Fei Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29897": {
    "title": "De-biased Attention Supervision for Text Classification with Causality",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiquan Wu",
      "Yifei Liu",
      "Ziyu Zhao",
      "Weiming Lu",
      "Yating Zhang",
      "Changlong Sun",
      "Fei Wu",
      "Kun Kuang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29898": {
    "title": "Get an A in Math: Progressive Rectification Prompting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Wu",
      "Meng Jiang",
      "Chao Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29899": {
    "title": "DIUSum: Dynamic Image Utilization for Multimodal Summarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min Xiao",
      "Junnan Zhu",
      "Feifei Zhai",
      "Yu Zhou",
      "Chengqing Zong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29900": {
    "title": "Automated Defect Report Generation for Enhanced Industrial Quality Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayuan Xie",
      "Zhiping Zhou",
      "Zihan Wu",
      "Xinting Zhang",
      "Jiexin Wang",
      "Yi Cai",
      "Qing Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29901": {
    "title": "ALISON: Fast and Effective Stylometric Authorship Obfuscation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eric Xing",
      "Saranya Venkatraman",
      "Thai Le",
      "Dongwon Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29902": {
    "title": "SECap: Speech Emotion Captioning with Large Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaoxun Xu",
      "Hangting Chen",
      "Jianwei Yu",
      "Qiaochu Huang",
      "Zhiyong Wu",
      "Shi-Xiong Zhang",
      "Guangzhi Li",
      "Yi Luo",
      "Rongzhi Gu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29903": {
    "title": "Question Calibration and Multi-Hop Modeling for Temporal Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Xue",
      "Di Liang",
      "Pengfei Wang",
      "Jing Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29904": {
    "title": "Robust Few-Shot Named Entity Recognition with Boundary Discrimination and Correlation Purification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaojun Xue",
      "Chunxia Zhang",
      "Tianxiang Xu",
      "Zhendong Niu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29905": {
    "title": "Tackling Vision Language Tasks through Learning Inner Monologues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Diji Yang",
      "Kezhen Chen",
      "Jinmeng Rao",
      "Xiaoyuan Guo",
      "Yawen Zhang",
      "Jie Yang",
      "Yi Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29906": {
    "title": "YTCommentQA: Video Question Answerability in Instructional Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saelyne Yang",
      "Sunghyun Park",
      "Yunseok Jang",
      "Moontae Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29907": {
    "title": "Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-World Multi-Turn Dialogue",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songhua Yang",
      "Hanjie Zhao",
      "Senbin Zhu",
      "Guangyu Zhou",
      "Hongfei Xu",
      "Yuxiang Jia",
      "Hongying Zan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29908": {
    "title": "Exploring Post-training Quantization in LLMs from Comprehensive Study to Low Rank Compensation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhewei Yao",
      "Xiaoxia Wu",
      "Cheng Li",
      "Stephen Youn",
      "Yuxiong He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29909": {
    "title": "Investigating the Effectiveness of Task-Agnostic Prefix Prompt for Instruction Following",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seonghyeon Ye",
      "Hyeonbin Hwang",
      "Sohee Yang",
      "Hyeongu Yun",
      "Yireun Kim",
      "Minjoon Seo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29910": {
    "title": "Uni-MIS: United Multiple Intent Spoken Language Understanding via Multi-View Intent-Slot Interaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangjian Yin",
      "Peijie Huang",
      "Yuhong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29911": {
    "title": "TextGT: A Double-View Graph Transformer on Text for Aspect-Based Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Yin",
      "Guoqiang Zhong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29912": {
    "title": "History Matters: Temporal Knowledge Editing in Large Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xunjian Yin",
      "Jin Jiang",
      "Liming Yang",
      "Xiaojun Wan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29913": {
    "title": "Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "YoungJoon Yoo",
      "JongWon Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29914": {
    "title": "CK12: A Rounded K12 Knowledge Graph Based Benchmark for Chinese Holistic Cognition Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weihao You",
      "Pengcheng Wang",
      "Changlong Li",
      "Zhilong Ji",
      "Jinfeng Bai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29915": {
    "title": "Reliable Data Generation and Selection for Low-Resource Relation Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Yu",
      "Xing Wang",
      "Wenliang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29916": {
    "title": "MELO: Enhancing Model Editing with Neuron-Indexed Dynamic LoRA",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lang Yu",
      "Qin Chen",
      "Jie Zhou",
      "Liang He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29917": {
    "title": "SeqGPT: An Out-of-the-Box Large Language Model for Open Domain Sequence Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyu Yu",
      "Chengyue Jiang",
      "Chao Lou",
      "Shen Huang",
      "Xiaobin Wang",
      "Wei Liu",
      "Jiong Cai",
      "Yangning Li",
      "Yinghui Li",
      "Kewei Tu",
      "Hai-Tao Zheng",
      "Ningyu Zhang",
      "Pengjun Xie",
      "Fei Huang",
      "Yong Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29918": {
    "title": "TaskLAMA: Probing the Complex Task Understanding of Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan Yuan",
      "Mehran Kazemi",
      "Xin Xu",
      "Isaac Noble",
      "Vaiva Imbrasaite",
      "Deepak Ramachandran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29919": {
    "title": "An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Urchade Zaratiana",
      "Nadi Tomeh",
      "Pierre Holat",
      "Thierry Charnois"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29920": {
    "title": "Teaching Large Language Models to Translate with Comparison",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiali Zeng",
      "Fandong Meng",
      "Yongjing Yin",
      "Jie Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29921": {
    "title": "InterpretARA: Enhancing Hybrid Automatic Readability Assessment with Linguistic Feature Interpreter and Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinshan Zeng",
      "Xianchao Tong",
      "Xianglong Yu",
      "Wenyan Xiao",
      "Qing Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29922": {
    "title": "ConsistentEE: A Consistent and Hardness-Guided Early Exiting Method for Accelerating Language Models Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqian Zeng",
      "Yihuai Hong",
      "Hongliang Dai",
      "Huiping Zhuang",
      "Cen Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29923": {
    "title": "A Comprehensive Analysis of the Effectiveness of Large Language Models as Automatic Dialogue Evaluators",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Zhang",
      "Luis Fernando D'Haro",
      "Yiming Chen",
      "Malu Zhang",
      "Haizhou Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29924": {
    "title": "PREFER: Prompt Ensemble Learning via Feedback-Reflect-Refine",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenrui Zhang",
      "Lin Liu",
      "Chuyuan Wang",
      "Xiao Sun",
      "Hongyu Wang",
      "Jinpeng Wang",
      "Mingchen Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29925": {
    "title": "Causal Walk: Debiasing Multi-Hop Fact Verification with Front-Door Adjustment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Congzhi Zhang",
      "Linhai Zhang",
      "Deyu Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29926": {
    "title": "Visual Hallucination Elevates Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fang Zhang",
      "Yongxin Zhu",
      "Xiangxiang Wang",
      "Huang Chen",
      "Xing Sun",
      "Linli Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29927": {
    "title": "Quantum Interference Model for Semantic Biases of Glosses in Word Sense Disambiguation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junwei Zhang",
      "Ruifang He",
      "Fengyu Guo",
      "Chang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29928": {
    "title": "Tree-of-Reasoning Question Decomposition for Complex Question Answering with Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Zhang",
      "Jiali Zeng",
      "Fandong Meng",
      "Yuanzhuo Wang",
      "Shiqi Sun",
      "Long Bai",
      "Huawei Shen",
      "Jie Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29929": {
    "title": "What to Remember: Self-Adaptive Continual Learning for Audio Deepfake Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "XiaoHui Zhang",
      "Jiangyan Yi",
      "Chenglong Wang",
      "Chu Yuan Zhang",
      "Siding Zeng",
      "Jianhua Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29930": {
    "title": "A Goal Interaction Graph Planning Framework for Conversational Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaotong Zhang",
      "Xuefang Jia",
      "Han Liu",
      "Xinyue Liu",
      "Xianchao Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29931": {
    "title": "Personalized LoRA for Human-Centered Text Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "You Zhang",
      "Jin Wang",
      "Liang-Chih Yu",
      "Dan Xu",
      "Xuejie Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29932": {
    "title": "StyleSinger: Style Transfer for Out-of-Domain Singing Voice Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Zhang",
      "Rongjie Huang",
      "Ruiqi Li",
      "JinZheng He",
      "Yan Xia",
      "Feiyang Chen",
      "Xinyu Duan",
      "Baoxing Huai",
      "Zhou Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29933": {
    "title": "Seed-Guided Fine-Grained Entity Typing in Science and Engineering Domains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Zhang",
      "Yunyi Zhang",
      "Yanzhen Shen",
      "Yu Deng",
      "Lucian Popa",
      "Larisa  Shwartz",
      "ChengXiang  Zhai",
      "Jiawei Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29934": {
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Zhang",
      "Ming Zhang",
      "Haipeng Yuan",
      "Shichun Liu",
      "Yongyao Shi",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29935": {
    "title": "Coreference Graph Guidance for Mind-Map Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuowei Zhang",
      "Mengting Hu",
      "Yinhao Bai",
      "Zhen Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29936": {
    "title": "ExpeL: LLM Agents Are Experiential Learners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrew Zhao",
      "Daniel Huang",
      "Quentin Xu",
      "Matthieu Lin",
      "Yong-Jin Liu",
      "Gao Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29937": {
    "title": "Conditional Variational Autoencoder for Sign Language Translation with Cross-Modal Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Zhao",
      "Liang Zhang",
      "Biao Fu",
      "Cong Hu",
      "Jinsong Su",
      "Yidong Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29938": {
    "title": "Graph Reasoning Transformers for Knowledge-Aware Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruilin Zhao",
      "Feng Zhao",
      "Liang Hu",
      "Guandong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29939": {
    "title": "MultiSum: A Multi-Facet Approach for Extractive Social Summarization Utilizing Semantic and Sociological Relationships",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tanglong Zhao",
      "Ruifang He",
      "Jing Xu",
      "Bo Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29940": {
    "title": "QPEN: Quantum Projection and Quantum Entanglement Enhanced Network for Cross-Lingual Aspect-Based Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingqiang Zhao",
      "Hai Wan",
      "Kunxun Qi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29941": {
    "title": "SENCR: A Span Enhanced Two-Stage Network with Counterfactual Rethinking for Chinese NER",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Zheng",
      "Qingsong Li",
      "Shen Chen",
      "Yuxuan Liang",
      "Li Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29942": {
    "title": "Reverse Multi-Choice Dialogue Commonsense Inference with Graph-of-Thought",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Zheng",
      "Hao Fei",
      "Fei Li",
      "Bobo Li",
      "Lizi Liao",
      "Donghong Ji",
      "Chong Teng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29943": {
    "title": "FT-GAN: Fine-Grained Tune Modeling for Chinese Opera Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meizhen Zheng",
      "Peng Bai",
      "Xiaodong Shi",
      "Xun Zhou",
      "Yiting Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29944": {
    "title": "Layer-Wise Representation Fusion for Compositional Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yafang Zheng",
      "Lei Lin",
      "Shuangtao Li",
      "Yuxuan Yuan",
      "Zhaohong Lai",
      "Shan Liu",
      "Biao Fu",
      "Yidong Chen",
      "Xiaodong Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29945": {
    "title": "You Only Read Once: Constituency-Oriented Relational Graph Convolutional Network for Multi-Aspect Multi-Sentiment Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongqiang Zheng",
      "Xia Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29946": {
    "title": "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wanjun Zhong",
      "Lianghong Guo",
      "Qiqi Gao",
      "He Ye",
      "Yanlin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29947": {
    "title": "Fine-Grained Distillation for Long Document Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yucheng Zhou",
      "Tao Shen",
      "Xiubo Geng",
      "Chongyang Tao",
      "Jianbing Shen",
      "Guodong Long",
      "Can Xu",
      "Daxin Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29948": {
    "title": "Quantifying and Analyzing Entity-Level Memorization in Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenhong Zhou",
      "Jiuyang Xiang",
      "Chaomeng Chen",
      "Sen Su"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29949": {
    "title": "MathAttack: Attacking Large Language Models towards Math Solving Ability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Zhou",
      "Qiufeng Wang",
      "Mingyu Jin",
      "Jie Yao",
      "Jianan Ye",
      "Wei Liu",
      "Wei Wang",
      "Xiaowei Huang",
      "Kaizhu Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29950": {
    "title": "LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Zhu",
      "Qingyang Zhao",
      "Weiwei Shang",
      "Yuren Wu",
      "Kai Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29951": {
    "title": "Multichannel AV-wav2vec2: A Framework for Learning Multichannel Multi-Modal Speech Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiushi Zhu",
      "Jie Zhang",
      "Yu Gu",
      "Yuchen Hu",
      "Lirong Dai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29952": {
    "title": "Aligner²: Enhancing Joint Multiple Intent Detection and Slot Filling via Adjustive and Forced Cross-Task Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihong Zhu",
      "Xuxin Cheng",
      "Yaowei Li",
      "Hongxiang Li",
      "Yuexian Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29953": {
    "title": "Towards Explainable Joint Models via Information Theory for Multiple Intent Detection and Slot Filling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianwei Zhuang",
      "Xuxin Cheng",
      "Yuexian Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29954": {
    "title": "Video-Context Aligned Transformer for Video Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linlin Zong",
      "Jiahui Wan",
      "Xianchao Zhang",
      "Xinyue Liu",
      "Wenxin Liang",
      "Bo Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29955": {
    "title": "Quality-Diversity Generative Sampling for Learning with Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Allen Chang",
      "Matthew C. Fontaine",
      "Serena Booth",
      "Maja J. Matarić",
      "Stefanos Nikolaidis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29956": {
    "title": "A Cross-View Hierarchical Graph Learning Hypernetwork for Skill Demand-Supply Joint Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenshuo Chao",
      "Zhaopeng Qiu",
      "Likang Wu",
      "Zhuoning Guo",
      "Zhi Zheng",
      "Hengshu Zhu",
      "Hao Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29957": {
    "title": "Conditional Backdoor Attack via JPEG Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiuyu Duan",
      "Zhongyun Hua",
      "Qing Liao",
      "Yushu Zhang",
      "Leo Yu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29958": {
    "title": "Complementary Knowledge Distillation for Robust and Privacy-Preserving Model Serving in Vertical Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dashan Gao",
      "Sheng Wan",
      "Lixin Fan",
      "Xin Yao",
      "Qiang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29959": {
    "title": "Resource Democratization: Is Compute the Binding Constraint on AI Research?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rebecca Gelles",
      "Veronica Kinoshita",
      "Micah Musser",
      "James Dunham"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29960": {
    "title": "How to Overcome Curse-of-Dimensionality for Out-of-Distribution Detection?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soumya Suvra Ghosal",
      "Yiyou Sun",
      "Yixuan Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29961": {
    "title": "Exploiting Discrepancy in Feature Statistic for Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyuan Guan",
      "Jiankang Chen",
      "Shenshen Bu",
      "Yuren Zhou",
      "Wei-Shi Zheng",
      "Ruixuan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29962": {
    "title": "Reward Penalties on Augmented States for Solving Richly Constrained RL Effectively",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Jiang",
      "Tien Mai",
      "Pradeep Varakantham",
      "Huy Hoang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29963": {
    "title": "The Logic of Doxastic Strategies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junli Jiang",
      "Pavel Naumov"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29964": {
    "title": "MERGE: Fast Private Text Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zi Liang",
      "Pinghui Wang",
      "Ruofei Zhang",
      "Nuo Xu",
      "Shuo Zhang",
      "Lifeng Xing",
      "Haitao Bai",
      "Ziyang Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29965": {
    "title": "Does Few-Shot Learning Suffer from Backdoor Attacks?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinwei Liu",
      "Xiaojun Jia",
      "Jindong Gu",
      "Yuan Xun",
      "Siyuan Liang",
      "Xiaochun Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29966": {
    "title": "Towards Model Extraction Attacks in GAN-Based Image Translation via Domain Shift Mitigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Di Mi",
      "Yanjun Zhang",
      "Leo Yu Zhang",
      "Shengshan Hu",
      "Qi Zhong",
      "Haizhuan Yuan",
      "Shirui Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29967": {
    "title": "Towards the Robustness of Differentially Private Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Qi",
      "Huili Wang",
      "Yongfeng Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29968": {
    "title": "Responsibility in Extensive Form Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi SHI"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29969": {
    "title": "Towards Fairness in Online Service with K Servers and Its Application on Fair Food Delivery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daman Deep Singh",
      "Amit Kumar",
      "Abhijnan Chakraborty"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29970": {
    "title": "Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taylor Sorensen",
      "Liwei Jiang",
      "Jena D. Hwang",
      "Sydney Levine",
      "Valentina Pyatkin",
      "Peter West",
      "Nouha Dziri",
      "Ximing Lu",
      "Kavel Rao",
      "Chandra Bhagavatula",
      "Maarten Sap",
      "John Tasioulas",
      "Yejin Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29971": {
    "title": "Moral Uncertainty and the Problem of Fanaticism",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jazon Szabo",
      "Natalia Criado",
      "Jose Such",
      "Sanjay Modgil"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29972": {
    "title": "U-trustworthy Models. Reliability, Competence, and Confidence in Decision-Making",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ritwik Vashistha",
      "Arya Farahi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29973": {
    "title": "TraceEvader: Making DeepFakes More Untraceable via Evading the Forgery Model Attribution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengjie Wu",
      "Jingui Ma",
      "Run Wang",
      "Sidan Zhang",
      "Ziyou Liang",
      "Boheng Li",
      "Chenhao Lin",
      "Liming Fang",
      "Lina Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29974": {
    "title": "SAME: Sample Reconstruction against Model Extraction Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Xie",
      "Jie Zhang",
      "Shiqian Zhao",
      "Tianwei Zhang",
      "Xiaofeng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29975": {
    "title": "High-Fidelity Gradient Inversion in Distributed Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zipeng Ye",
      "Wenjian Luo",
      "Qi Zhou",
      "Yubo Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29976": {
    "title": "Robustness Verification of Deep Reinforcement Learning Based Control Systems Using Reward Martingales",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dapeng Zhi",
      "Peixin Wang",
      "Cheng Chen",
      "Min Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29977": {
    "title": "Regulating AI: Applying Insights from Behavioural Economics and Psychology to the Application of Article 5 of the EU AI Act",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huixin Zhong",
      "Eamonn O'Neill",
      "Janina A. Hoffmann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29978": {
    "title": "Batch Normalization Is Blind to the First and Second Derivatives of the Loss",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhanpeng Zhou",
      "Wen Shen",
      "Huixin Chen",
      "Ling Tang",
      "Yuefeng Chen",
      "Quanshi Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29979": {
    "title": "Block-Level Goal Recognition Design",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tsz-Chiu Au"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29980": {
    "title": "Learning Planning Domains from Non-redundant Fully-Observed Traces: Theoretical Foundations and Complexity Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pascal Bachor",
      "Gregor Behnke"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29981": {
    "title": "Dealing with Numeric and Metric Time Constraints in PDDL3 via Compilation to Numeric Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luigi Bonassi",
      "Alfonso Emilio Gerevini",
      "Enrico Scala"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29982": {
    "title": "The Complexity of Optimizing Atomic Congestion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cornelius Brand",
      "Robert Ganian",
      "Subrahmanyam Kalyanasundaram",
      "Fionn Mc Inerney"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29983": {
    "title": "Stop! Planner Time: Metareasoning for Probabilistic Planning Using Learned Performance Profiles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew Budd",
      "Bruno Lacerda",
      "Nick Hawes"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29984": {
    "title": "Can LLMs Fix Issues with Reasoning Models? Towards More Likely Models for AI Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Turgay Caglar",
      "Sirine Belhaj",
      "Tathagata Chakraborty",
      "Michael Katz",
      "Sarath Sreedharan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29985": {
    "title": "Symbolic Numeric Planning with Patterns",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matteo Cardellini",
      "Enrico Giunchiglia",
      "Marco Maratea"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29986": {
    "title": "Learning Domain-Independent Heuristics for Grounded and Lifted Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dillon Z. Chen",
      "Sylvie Thiébaux",
      "Felipe Trevizan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29987": {
    "title": "Approximate Distance Oracle for Fault-Tolerant Geometric Spanners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyungjin Cho",
      "Jihun Shin",
      "Eunjin Oh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29988": {
    "title": "Optimizing the Optimization of Planning Domains by Automatic Action Schema Splitting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mojtaba Elahi",
      "Jussi Rintanen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29989": {
    "title": "An Effective Polynomial Technique for Compiling Conditional Effects Away",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alfonso Emilio Gerevini",
      "Francesco Percassi",
      "Enrico Scala"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29990": {
    "title": "GOALNET: Interleaving Neural Goal Predicate Inference with Classical Planning for Generalization in Robot Instruction Following",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jigyasa Gupta",
      "Shreya Sharma",
      "Shreshth Tuli",
      "Rohan Paul",
      "Mausam"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29991": {
    "title": "SayCanPay: Heuristic Planning with Large Language Models Using Learnable Domain Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rishi Hazra",
      "Pedro Zuidberg Dos Martires",
      "Luc De Raedt"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29992": {
    "title": "A Surprisingly Simple Continuous-Action POMDP Solver: Lazy Cross-Entropy Search Over Policy Trees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcus Hoerger",
      "Hanna Kurniawati",
      "Dirk Kroese",
      "Nan Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29993": {
    "title": "Optimizing Local Satisfaction of Long-Run Average Objectives in Markov Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Klaška",
      "Antonín Kučera",
      "Vojtěch Kůr",
      "Vít Musil",
      "Vojtěch Řehák"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29994": {
    "title": "Monte Carlo Tree Search in the Presence of Transition Uncertainty",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Farnaz Kohankhaki",
      "Kiarash Aghakasiri",
      "Hongming Zhang",
      "Ting-Han Wei",
      "Chao Gao",
      "Martin Müller"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29995": {
    "title": "Learning Safe Action Models with Partial Observability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai S. Le",
      "Brendan Juba",
      "Roni Stern"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29996": {
    "title": "Generalized Planning for the Abstraction and Reasoning Corpus",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Lei",
      "Nir Lipovetzky",
      "Krista A. Ehinger"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29997": {
    "title": "Simplifying Complex Observation Models in Continuous POMDP Planning with Probabilistic Guarantees and Practice",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Idan Lev-Yehudi",
      "Moran Barenboim",
      "Vadim Indelman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29998": {
    "title": "Learning to Optimize Permutation Flow Shop Scheduling via Graph-Based Imitation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longkang Li",
      "Siyuan Liang",
      "Zihao Zhu",
      "Chris Ding",
      "Hongyuan Zha",
      "Baoyuan Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/29999": {
    "title": "NaRuto: Automatically Acquiring Planning Models from Narrative Texts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiqi Li",
      "Leyang Cui",
      "Songtuan Lin",
      "Patrik Haslum"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30000": {
    "title": "On the Computational Complexity of Plan Verification, (Bounded) Plan-Optimality Verification, and Bounded Plan Existence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songtuan Lin",
      "Conny Olz",
      "Malte Helmert",
      "Pascal Bercher"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30001": {
    "title": "PRP Rebooted: Advancing the State of the Art in FOND Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christian Muise",
      "Sheila A. McIlraith",
      "J. Christopher Beck"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30002": {
    "title": "Abstract Action Scheduling for Optimal Temporal Planning via OMT",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stefan Panjkovic",
      "Andrea Micheli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30003": {
    "title": "Generalising Planning Environment Redesign",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alberto Pozanco",
      "Ramon Fraga Pereira",
      "Daniel Borrajo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30004": {
    "title": "When CEGAR Meets Regression: A Love Story in Optimal Classical Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martín Pozo",
      "Alvaro Torralba",
      "Carlos Linares Lopez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30005": {
    "title": "Efficient Constraint Generation for Stochastic Shortest Path Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johannes Schmalz",
      "Felipe Trevizan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30006": {
    "title": "Generalized Planning in PDDL Domains with Pretrained Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tom Silver",
      "Soham Dan",
      "Kavitha Srinivas",
      "Joshua B. Tenenbaum",
      "Leslie Kaelbling",
      "Michael Katz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30007": {
    "title": "Equity-Transformer: Solving NP-Hard Min-Max Routing Problems as Sequential Generation with Equity Context",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiwoo Son",
      "Minsu Kim",
      "Sanghyeok Choi",
      "Hyeonah Kim",
      "Jinkyoo Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30008": {
    "title": "Distilling Autoregressive Models to Obtain High-Performance Non-autoregressive Solvers for Vehicle Routing Problems with Faster Inference Speed",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yubin Xiao",
      "Di Wang",
      "Boyang Li",
      "Mingzhao Wang",
      "Xuan Wu",
      "Changliang Zhou",
      "You Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30009": {
    "title": "GLOP: Learning Global Partition and Local Construction for Solving Large-Scale Routing Problems in Real-Time",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Ye",
      "Jiarui Wang",
      "Helan Liang",
      "Zhiguang Cao",
      "Yong Li",
      "Fanzhang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30010": {
    "title": "Learning-Augmented Online Algorithm for Two-Level Ski-Rental Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keyuan Zhang",
      "Zhongdong Liu",
      "Nakjung Choi",
      "Bo Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30011": {
    "title": "s-ID: Causal Effect Identification in a Sub-population",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amir Mohammad Abouei",
      "Ehsan Mokhtarian",
      "Negar Kiyavash"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30012": {
    "title": "On Estimating the Gradient of the Expected Information Gain in Bayesian Experimental Design",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqiao Ao",
      "Jinglai  Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30013": {
    "title": "Backward Responsibility in Transition Systems Using General Power Indices",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christel Baier",
      "Roxane van den Bossche",
      "Sascha Klüppelholz",
      "Johannes Lehmann",
      "Jakob Piribauer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30014": {
    "title": "The Expected Loss of Preconditioned Langevin Dynamics Reveals the Hessian Rank",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amitay Bar",
      "Rotem Mulayoff",
      "Tomer Michaeli",
      "Ronen Talmon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30015": {
    "title": "Pandora's Problem with Deadlines",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ben Berger",
      "Tomer Ezra",
      "Michal Feldman",
      "Federico Fusco"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30016": {
    "title": "Minibatch Stochastic Three Points Method for Unconstrained Smooth Minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soumia Boucherouite",
      "Grigory Malinovsky",
      "Peter Richtárik",
      "El Houcine Bergou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30017": {
    "title": "Identification of Causal Structure with Latent Variables Based on Higher Order Cumulants",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Chen",
      "Zhiyi Huang",
      "Ruichu Cai",
      "Zhifeng Hao",
      "Kun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30018": {
    "title": "Direct Amortized Likelihood Ratio Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adam D. Cobb",
      "Brian Matejek",
      "Daniel Elenius",
      "Anirban Roy",
      "Susmit Jha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30019": {
    "title": "Probabilistic Offline Policy Ranking with Approximate Bayesian Computation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longchao Da",
      "Porter Jenkins",
      "Trevor Schwantes",
      "Jeffrey Dotson",
      "Hua Wei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30020": {
    "title": "Generalized Bradley-Terry Models for Score Estimation from Paired Comparisons",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julien Fageot",
      "Sadegh Farhadkhani",
      "Lê-Nguyên Hoang",
      "Oscar Villemaud"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30021": {
    "title": "Identifiability of Direct Effects from Summary Causal Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Ferreira",
      "Charles K. Assaad"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30022": {
    "title": "Model Counting and Sampling via Semiring Extensions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andreas Goral",
      "Joachim Giesen",
      "Mark Blacher",
      "Christoph Staudt",
      "Julien Klaus"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30023": {
    "title": "Identification for Tree-Shaped Structural Causal Models in Polynomial Time",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aaryan Gupta",
      "Markus Bläser"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30024": {
    "title": "Learning GAI-Decomposable Utility Models for Multiattribute Decision Making",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Margot Herin",
      "Patrice Perny",
      "Nataliya Sokolovska"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30025": {
    "title": "Uncertainty Quantification in Heterogeneous Treatment Effect Estimation with Gaussian-Process-Based Partially Linear Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shunsuke Horii",
      "Yoichi Chikahara"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30026": {
    "title": "Learning Diffusions under Uncertainty",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Huang",
      "Qian Yan",
      "Keqi Han",
      "Ting Gan",
      "Jiawei Jiang",
      "Quanqing Xu",
      "Chuanhui Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30027": {
    "title": "Robustly Improving Bandit Algorithms with Confounded and Selection Biased Offline Data: A Causal Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen Huang",
      "Xintao Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30028": {
    "title": "Effectiveness of Constant Stepsize in Markovian LSA and Statistical Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongyan (Lucy) Huo",
      "Yudong Chen",
      "Qiaomin Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30029": {
    "title": "Piecewise Linear Transformation – Propagating Aleatoric Uncertainty in Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Krapf",
      "Michael Hagn",
      "Paul Miethaner",
      "Alexander Schiller",
      "Lucas Luttner",
      "Bernd Heinrich"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30030": {
    "title": "Probabilities of Causation with Nonbinary Treatment and Effect",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ang Li",
      "Judea Pearl"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30031": {
    "title": "Unit Selection with Nonbinary Treatment and Effect",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ang Li",
      "Judea Pearl"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30032": {
    "title": "Solving Satisfiability Modulo Counting for Symbolic and Statistical AI Integration with Provable Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinzhao Li",
      "Nan Jiang",
      "Yexiang Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30033": {
    "title": "TNPAR: Topological Neural Poisson Auto-Regressive Model for Learning Granger Causal Structure from Event Sequences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuequn Liu",
      "Ruichu Cai",
      "Wei Chen",
      "Jie Qiao",
      "Yuguang Yan",
      "Zijian Li",
      "Keli Zhang",
      "Zhifeng Hao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30034": {
    "title": "Colour Passing Revisited: Lifted Model Construction with Commutative Factors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Malte Luttermann",
      "Tanya Braun",
      "Ralf Möller",
      "Marcel Gehrke"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30035": {
    "title": "Root Cause Explanation of Outliers under Noisy Mechanisms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Phuoc Nguyen",
      "Truyen Tran",
      "Sunil Gupta",
      "Thin Nguyen",
      "Svetha Venkatesh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30036": {
    "title": "Identification of Causal Structure in the Presence of Missing Data with Additive Noise Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Qiao",
      "Zhengming Chen",
      "Jianhua Yu",
      "Ruichu Cai",
      "Zhifeng Hao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30037": {
    "title": "Causal Discovery from Poisson Branching Structural Causal Model Using High-Order Cumulant with Path Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Qiao",
      "Yu Xiang",
      "Zhengming Chen",
      "Ruichu Cai",
      "Zhifeng Hao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30038": {
    "title": "A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence Classes with the Same Skeleton",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vidya Sagar Sharma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30039": {
    "title": "Learning Bayesian Network Classifiers to Minimize the Class Variable Parameters",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shouta Sugahara",
      "Koya Kato",
      "Maomi Ueno"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30040": {
    "title": "Bayesian Inference with Complex Knowledge Graph Evidence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Armin Toroghi",
      "Scott Sanner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30041": {
    "title": "Exact, Fast and Expressive Poisson Point Processes via Squared Neural Families",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Russell Tsuchida",
      "Cheng Soon Ong",
      "Dino Sejdinovic"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30042": {
    "title": "Inference and Learning in Dynamic Decision Networks Using Knowledge Compilation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriele Venturato",
      "Vincent Derkinderen",
      "Pedro Zuidberg Dos Martires",
      "Luc De Raedt"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30043": {
    "title": "Linear-Time Algorithms for Front-Door Adjustment in Causal Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcel Wienöbst",
      "Benito van der Zander",
      "Maciej Liśkiewicz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30044": {
    "title": "Neural Causal Abstractions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Xia",
      "Elias Bareinboim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30045": {
    "title": "Federated Contextual Cascading Bandits with Asynchronous Communication and Heterogeneous Users",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hantao Yang",
      "Xutong Liu",
      "Zhiyong Wang",
      "Hong Xie",
      "John C. S. Lui",
      "Defu Lian",
      "Enhong Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30046": {
    "title": "Causal-Driven Skill Prerequisite Structure Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shenbao Yu",
      "Yifeng Zeng",
      "Fan Yang",
      "Yinghui Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30047": {
    "title": "Deep Copula-Based Survival Analysis for Dependent Censoring with Identifiability Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijia Zhang",
      "Chun Kai Ling",
      "Xuanhui Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30048": {
    "title": "DOGE-Train: Discrete Optimization on GPU with End-to-End Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Abbas",
      "Paul Swoboda"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30049": {
    "title": "Delegation-Relegation for Boolean Matrix Factorization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florent Avellaneda",
      "Roger Villemaire"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30050": {
    "title": "An Interpretable Approach to the Solutions of High-Dimensional Partial Differential Equations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lulu Cao",
      "Yufei Liu",
      "Zhenzhong Wang",
      "Dejun Xu",
      "Kai Ye",
      "Kay Chen Tan",
      "Min Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30051": {
    "title": "Sampling for Beyond-Worst-Case Online Ranking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingyun Chen",
      "Sungjin Im",
      "Benjamin Moseley",
      "Chenyang Xu",
      "Ruilong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30052": {
    "title": "Learning Ultrametric Trees for Optimal Transport Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samantha Chen",
      "Puoya Tabaghi",
      "Yusu Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30053": {
    "title": "Parameterized Approximation Algorithms for Sum of Radii Clustering and Variants",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianrun Chen",
      "Dachuan Xu",
      "Yicheng Xu",
      "Yong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30054": {
    "title": "Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Chen",
      "Daniel Harabor",
      "Jiaoyang Li",
      "Peter J. Stuckey"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30055": {
    "title": "Runtime Analysis of the (μ + 1) GA: Provable Speed-Ups from Strong Drift towards Diverse Populations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benjamin Doerr",
      "Aymen Echarghaoui",
      "Mohammed Jamal",
      "Martin S. Krejca"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30056": {
    "title": "Novelty vs. Potential Heuristics: A Comparison of Hardness Measures for Satisficing Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Dold",
      "Malte Helmert"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30057": {
    "title": "Cumulative Regret Analysis of the Piyavskii–Shubert Algorithm and Its Variants for Global Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaan Gokcesu",
      "Hakan Gökcesu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30058": {
    "title": "Efficient Constrained K-center Clustering with Background Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longkun Guo",
      "Chaoqi Jia",
      "Kewen Liao",
      "Zhigang Lu",
      "Minhui Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30059": {
    "title": "Limited Query Graph Connectivity Test",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyu Guo",
      "Jialiang Li",
      "Aneta Neumann",
      "Frank Neumann",
      "Hung Nguyen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30060": {
    "title": "Theoretical Aspects of Generating Instances with Unique Solutions: Pre-assignment Models for Unique Vertex Cover",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takashi Horiyama",
      "Yasuaki Kobayashi",
      "Hirotaka Ono",
      "Kazuhisa Seto",
      "Ryu Suzuki"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30061": {
    "title": "KD-Club: An Efficient Exact Algorithm with New Coloring-Based Upper Bound for the Maximum k-Defective Clique Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingming Jin",
      "Jiongzhi Zheng",
      "Kun He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30062": {
    "title": "Parallel Beam Search Algorithms for Domain-Independent Dynamic Programming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryo Kuroiwa",
      "J. Christopher Beck"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30063": {
    "title": "Rectangle Search: An Anytime Beam Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sofia Lemons",
      "Wheeler Ruml",
      "Rob Holte",
      "Carlos Linares Lopez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30064": {
    "title": "Learning to Stop Cut Generation for Efficient Mixed-Integer Linear Programming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haotian Ling",
      "Zhihai Wang",
      "Jie Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30065": {
    "title": "A Fast Exact Solver with Theoretical Analysis for the Maximum Edge-Weighted Clique Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lu Liu",
      "Mingyu Xiao",
      "Yi Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30066": {
    "title": "Towards Running Time Analysis of Interactive Multi-Objective Evolutionary Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianhao Lu",
      "Chao Bian",
      "Chao Qian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30067": {
    "title": "Accelerating Cutting-Plane Algorithms via Reinforcement Learning Surrogates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyle Mana",
      "Fernando Acero",
      "Stephen Mak",
      "Parisa Zehtabi",
      "Michael Cashmore",
      "Daniele Magazzeni",
      "Manuela Veloso"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30068": {
    "title": "Paths, Proofs, and Perfection: Developing a Human-Interpretable Proof System for Constrained Shortest Paths",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Konstantin Sidorov",
      "Gonçalo Homem de Almeida Correia",
      "Mathijs de Weerdt",
      "Emir Demirović"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30069": {
    "title": "Learning Encodings for Constructive Neural Combinatorial Optimization Needs to Regret",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Sun",
      "Zhi Zheng",
      "Zhenkun Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30070": {
    "title": "COMBHelper: A Neural Approach to Reduce Search Space for Graph Combinatorial Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Tian",
      "Sourav Medya",
      "Wei Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30071": {
    "title": "Improving Neural Network Generalization on Data-Limited Regression with Doubly-Robust Boosting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30072": {
    "title": "Inertial Algorithm with Dry Fraction and Convolutional Sparse Coding for 3D Localization with Light Field Microscopy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofan Wang",
      "Zhiyuan Deng",
      "Changle Wang",
      "Jinjia Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30073": {
    "title": "A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyang Xu",
      "Hu Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30074": {
    "title": "Sample-and-Bound for Non-convex Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaoguang Zhai",
      "Zhizhen Qin",
      "Sicun Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30075": {
    "title": "Threshold-Based Responsive Simulated Annealing for Directed Feedback Vertex Set Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingyun Zhang",
      "Yuming Du",
      "Zhouxing Su",
      "Chu-Min Li",
      "Junzhou Xu",
      "Zhihuai Chen",
      "Zhipeng Lü"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30076": {
    "title": "Jointly Improving the Sample and Communication Complexities in Decentralized Stochastic Minimax Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuan Zhang",
      "Gabriel Mancino-Ball",
      "Necdet Serhat Aybat",
      "Yangyang Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30077": {
    "title": "Runtime Analysis of the SMS-EMOA for Many-Objective Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijie Zheng",
      "Benjamin Doerr"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30078": {
    "title": "How to Use the Metropolis Algorithm for Multi-Objective Optimization?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijie Zheng",
      "Mingfeng Li",
      "Renzhong Deng",
      "Benjamin Doerr"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30079": {
    "title": "Two-Stage Evolutionary Reinforcement Learning for Enhancing Exploration and Exploitation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingling Zhu",
      "Xiaoqiang Wu",
      "Qiuzhen Lin",
      "Wei-Neng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30080": {
    "title": "ImageCaptioner2: Image Captioner for Image Captioning Bias Amplification Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eslam Abdelrahman",
      "Pengzhan Sun",
      "Li Erran Li",
      "Mohamed Elhoseiny"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30081": {
    "title": "A Framework for Data-Driven Explainability in Mathematical Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin-Martin Aigner",
      "Marc Goerigk",
      "Michael Hartisch",
      "Frauke Liers",
      "Arthur Miehlich"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30082": {
    "title": "On the Importance of Application-Grounded Experimental Design for Evaluating Explainable ML Methods",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kasun Amarasinghe",
      "Kit T. Rodolfa",
      "Sérgio Jesus",
      "Valerie Chen",
      "Vladimir Balayan",
      "Pedro Saleiro",
      "Pedro Bizarro",
      "Ameet Talwalkar",
      "Rayid Ghani"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30083": {
    "title": "Risk-Aware Continuous Control with Neural Contextual Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jose A. Ayala-Romero",
      "Andres Garcia-Saavedra",
      "Xavier Costa-Perez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30084": {
    "title": "Robust Uncertainty Quantification Using Conformalised Monte Carlo Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Bethell",
      "Simos Gerasimou",
      "Radu Calinescu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30085": {
    "title": "CCTR: Calibrating Trajectory Prediction for Uncertainty-Aware Motion Planning in Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengtai Cao",
      "Xinhong Chen",
      "Jianping Wang",
      "Qun Song",
      "Rui Tan",
      "Yung-Hui Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30086": {
    "title": "Rethinking the Development of Large Language Models from the Causal Perspective: A Legal Text Prediction Case Study",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haotian Chen",
      "Lingwei Zhang",
      "Yiran Liu",
      "Yang Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30087": {
    "title": "Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models through Intervention without Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongzhi Chen",
      "Xingwu Sun",
      "Xianfeng Jiao",
      "Fengzong Lian",
      "Zhanhui Kang",
      "Di Wang",
      "Chengzhong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30088": {
    "title": "Constrained Meta-Reinforcement Learning for Adaptable Safety Guarantee with Differentiable Convex Programming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minjae Cho",
      "Chuangchuang Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30089": {
    "title": "Conformal Prediction Regions for Time Series Using Linear Complementarity Programming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew Cleaveland",
      "Insup Lee",
      "George J. Pappas",
      "Lars Lindemann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30090": {
    "title": "TTTS: Tree Test Time Simulation for Enhancing Decision Tree Robustness against Adversarial Examples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seffi Cohen",
      "Ofir Arbili",
      "Yisroel Mirsky",
      "Lior Rokach"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30091": {
    "title": "Find the Lady: Permutation and Re-synchronization of Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Carl De Sousa Trias",
      "Mihai Petru Mitrea",
      "Attilio Fiandrotti",
      "Marco Cagnazzo",
      "Sumanta Chaudhuri",
      "Enzo Tartaglione"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30092": {
    "title": "Stability Analysis of Switched Linear Systems with Neural Lyapunov Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Virginie Debauche",
      "Alec Edwards",
      "Raphaël M. Jungers",
      "Alessandro Abate"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30093": {
    "title": "Robustness Verification of Multi-Class Tree Ensembles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Laurens Devos",
      "Lorenzo Cascioli",
      "Jesse Davis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30094": {
    "title": "P2BPO: Permeable Penalty Barrier-Based Policy Optimization for Safe RL",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sumanta Dey",
      "Pallab Dasgupta",
      "Soumyajit Dey"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30095": {
    "title": "Trade-Offs in Fine-Tuned Diffusion Models between Accuracy and Interpretability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mischa Dombrowski",
      "Hadrien Reynaud",
      "Johanna P. Müller",
      "Matthew Baugh",
      "Bernhard Kainz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30096": {
    "title": "From Hope to Safety: Unlearning Biases of Deep Models via Gradient Penalization in Latent Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximilian Dreyer",
      "Frederik Pahde",
      "Christopher J. Anders",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30097": {
    "title": "Automatically Testing Functional Properties of Code Translation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hasan Ferit Eniser",
      "Valentin Wüstholz",
      "Maria Christakis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30098": {
    "title": "A Simple and Yet Fairly Effective Defense for Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sofiane Ennadir",
      "Yassine Abbahaddou",
      "Johannes F. Lutzeyer",
      "Michalis Vazirgiannis",
      "Henrik Boström"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30099": {
    "title": "Invisible Backdoor Attack against 3D Point Cloud Classifier in Graph Spectral Domain",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linkun Fan",
      "Fazhi He",
      "Tongzhen Si",
      "Wei Tang",
      "Bing Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30100": {
    "title": "CASE: Exploiting Intra-class Compactness and Inter-class Separability of Feature Embeddings for Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Feng",
      "Pengsheng Jin",
      "Chongjun Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30101": {
    "title": "Solving Non-rectangular Reward-Robust MDPs via Frequency Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Uri Gadot",
      "Esther Derman",
      "Navdeep Kumar",
      "Maxence Mohamed Elfatihi",
      "Kfir Levy",
      "Shie Mannor"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30102": {
    "title": "Balance Reward and Safety Optimization for Safe Reinforcement Learning: A Perspective of Gradient Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangding Gu",
      "Bilgehan Sel",
      "Yuhao Ding",
      "Lu Wang",
      "Qingwei Lin",
      "Ming Jin",
      "Alois Knoll"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30103": {
    "title": "π-Light: Programmatic Interpretable Reinforcement Learning for Resource-Limited Traffic Signal Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yin Gu",
      "Kai Zhang",
      "Qi Liu",
      "Weibo Gao",
      "Longfei Li",
      "Jun Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30104": {
    "title": "Generative Model for Decision Trees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Riccardo Guidotti",
      "Anna Monreale",
      "Mattia Setzu",
      "Giulia Volpi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30105": {
    "title": "Omega-Regular Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ernst Moritz Hahn",
      "Mateo Perez",
      "Sven Schewe",
      "Fabio Somenzi",
      "Ashutosh Trivedi",
      "Dominik Wojtczak"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30106": {
    "title": "Provable Robustness against a Union of L_0 Adversarial Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zayd Hammoudeh",
      "Daniel Lowd"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30107": {
    "title": "All but One: Surgical Concept Erasing with Model Preservation in Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "SeungHoo Hong",
      "Juhun Lee",
      "Simon S. Woo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30108": {
    "title": "Towards Efficient Verification of Quantized Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pei Huang",
      "Haoze Wu",
      "Yuting Yang",
      "Ieva Daukantas",
      "Min Wu",
      "Yedi Zhang",
      "Clark Barrett"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30109": {
    "title": "On the Concept Trustworthiness in Concept Bottleneck Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihan Huang",
      "Jie Song",
      "Jingwen Hu",
      "Haofei Zhang",
      "Yong Wang",
      "Mingli Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30110": {
    "title": "Personalization as a Shortcut for Few-Shot Backdoor Attack against Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihao Huang",
      "Felix Juefei-Xu",
      "Qing Guo",
      "Jie Zhang",
      "Yutong Wu",
      "Ming Hu",
      "Tianlin Li",
      "Geguang Pu",
      "Yang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30111": {
    "title": "Stronger and Transferable Node Injection Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samyak Jain",
      "Tanima Dutta"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30112": {
    "title": "Learning Fair Policies for Multi-Stage Selection Problems from Observational Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuangzhuang Jia",
      "Grani A. Hanasusanto",
      "Phebe Vayanos",
      "Weijun Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30113": {
    "title": "NeRFail: Neural Radiance Fields-Based Multiview Adversarial Attack",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxiang Jiang",
      "Hanwei Zhang",
      "Xi Wang",
      "Zhongwen Guo",
      "Hao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30114": {
    "title": "Analysis of Differentially Private Synthetic Data: A Measurement Error Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangdi Jiang",
      "Yi Liu",
      "Xiaodong Yan",
      "Anne-Sophie Charest",
      "Linglong Kong",
      "Bei Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30115": {
    "title": "Chasing Fairness in Graphs: A GNN Architecture Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhimeng Jiang",
      "Xiaotian Han",
      "Chao Fan",
      "Zirui Liu",
      "Na Zou",
      "Ali Mostafavi",
      "Xia Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30116": {
    "title": "Assume-Guarantee Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Milad Kazemi",
      "Mateo Perez",
      "Fabio Somenzi",
      "Sadegh Soudjani",
      "Ashutosh Trivedi",
      "Alvaro Velasquez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30117": {
    "title": "DeepBern-Nets: Taming the Complexity of Certifying Neural Networks Using Bernstein Polynomial Activations and Precise Bound Propagation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haitham Khedr",
      "Yasser Shoukry"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30118": {
    "title": "Layer Attack Unlearning: Fast and Accurate Machine Unlearning via Layer Level Attack and Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunjune Kim",
      "Sangyong Lee",
      "Simon S. Woo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30119": {
    "title": "Quilt: Robust Data Segment Selection against Concept Drifts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minsu Kim",
      "Seong-Hyeon Hwang",
      "Steven Euijong Whang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30120": {
    "title": "OUTFOX: LLM-Generated Essay Detection Through In-Context Learning with Adversarially Generated Examples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryuto Koike",
      "Masahiro Kaneko",
      "Naoaki Okazaki"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30121": {
    "title": "Accelerating Adversarially Robust Model Selection for Deep Neural Networks via Racing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthias König",
      "Holger H. Hoos",
      "Jan N. van Rijn"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30122": {
    "title": "Robust Active Measuring under Model Uncertainty",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Merlijn Krale",
      "Thiago D. Simão",
      "Jana Tumova",
      "Nils Jansen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30123": {
    "title": "Towards Large Certified Radius in Randomized Smoothing Using Quasiconcave Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo-Han Kung",
      "Shang-Tse Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30124": {
    "title": "Contrastive Credibility Propagation for Reliable Semi-supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Brody Kutt",
      "Pralay Ramteke",
      "Xavier Mignot",
      "Pamela Toman",
      "Nandini Ramanan",
      "Sujit Rokka Chhetri",
      "Shan Huang",
      "Min Du",
      "William Hewlett"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30125": {
    "title": "Exponent Relaxation of Polynomial Zonotopes and Its Applications in Formal Neural Network Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tobias Ladner",
      "Matthias Althoff"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30126": {
    "title": "I Prefer Not to Say: Protecting User Consent in Models with Optional Personal Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tobias Leemann",
      "Martin Pawelczyk",
      "Christian Thomas Eberle",
      "Gjergji Kasneci"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30127": {
    "title": "Promoting Counterfactual Robustness through Diversity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesco Leofante",
      "Nico Potyka"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30128": {
    "title": "Revisiting the Information Capacity of Neural Network Watermarks: Upper Bound Estimation and Beyond",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangqi Li",
      "Haodong Zhao",
      "Wei Du",
      "Shilin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30129": {
    "title": "PointCVaR: Risk-Optimized Outlier Removal for Robust 3D Point Cloud Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinke Li",
      "Junchi Lu",
      "Henghui Ding",
      "Changsheng Sun",
      "Joey Tianyi Zhou",
      "Yeow Meng Chee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30130": {
    "title": "Game-Theoretic Unlearnable Example Generator",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuang Liu",
      "Yihan Wang",
      "Xiao-Shan Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30131": {
    "title": "Beyond Traditional Threats: A Persistent Backdoor Attack on Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Liu",
      "Yuhang Zhang",
      "Zhu Feng",
      "Zhiqin Yang",
      "Chen Xu",
      "Dapeng Man",
      "Wu Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30132": {
    "title": "Handling Long and Richly Constrained Tasks through Constrained Hierarchical Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxiao Lu",
      "Arunesh Sinha",
      "Pradeep Varakantham"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30133": {
    "title": "Combining Graph Transformers Based Multi-Label Active Learning and Informative Data Augmentation for Chest Xray Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dwarikanath Mahapatra",
      "Behzad Bozorgtabar",
      "Zongyuan Ge",
      "Mauricio Reyes",
      "Jean-Philippe Thiran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30134": {
    "title": "Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Marzari",
      "Davide Corsi",
      "Enrico Marchesini",
      "Alessandro Farinelli",
      "Ferdinando Cicalese"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30135": {
    "title": "Divide-and-Aggregate Learning for Evaluating Performance on Unlabeled Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuyu Miao",
      "Jian Liu",
      "Lin Zheng",
      "Hong Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30136": {
    "title": "SentinelLMs: Encrypted Input Adaptation and Fine-Tuning of Language Models for Private and Secure Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhijit Mishra",
      "Mingda Li",
      "Soham Deo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30137": {
    "title": "Safeguarded Progress in Reinforcement Learning: Safe Bayesian Exploration for Control Policy Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rohan Mitta",
      "Hosein Hasanbeig",
      "Jun Wang",
      "Daniel Kroening",
      "Yiannis Kantaros",
      "Alessandro Abate"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30138": {
    "title": "Feature Unlearning for Pre-trained GANs and VAEs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saemi Moon",
      "Seunghyuk Cho",
      "Dongwoo Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30139": {
    "title": "Reward Certification for Policy Smoothed Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ronghui Mu",
      "Leandro Soriano Marcolino",
      "Yanghao Zhang",
      "Tianle Zhang",
      "Xiaowei Huang",
      "Wenjie Ruan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30140": {
    "title": "EncryIP: A Practical Encryption-Based Framework for Model Intellectual Property Protection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Mu",
      "Yu Wang",
      "Zhengan Huang",
      "Junzuo Lai",
      "Yehong Zhang",
      "Hui Wang",
      "Yue Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30141": {
    "title": "Neural Closure Certificates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alireza Nadali",
      "Vishnu Murali",
      "Ashutosh Trivedi",
      "Majid Zamani"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30142": {
    "title": "SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in Generative Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manish Nagireddy",
      "Lamogha Chiazor",
      "Moninder Singh",
      "Ioana Baldini"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30143": {
    "title": "MaxEnt Loss: Constrained Maximum Entropy for Calibration under Out-of-Distribution Shift",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dexter Neo",
      "Stefan Winkler",
      "Tsuhan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30144": {
    "title": "ORES: Open-Vocabulary Responsible Visual Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minheng Ni",
      "Chenfei Wu",
      "Xiaodong Wang",
      "Shengming Yin",
      "Lijuan Wang",
      "Zicheng Liu",
      "Nan Duan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30145": {
    "title": "Q-SENN: Quantized Self-Explaining Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Norrenbrock",
      "Marco Rudolph",
      "Bodo Rosenhahn"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30146": {
    "title": "Understanding Likelihood of Normalizing Flow and Image Complexity through the Lens of Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Genki Osada",
      "Tsubasa Takahashi",
      "Takashi Nishide"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30147": {
    "title": "Adversarial Initialization with Universal Adversarial Perturbation: A New Approach to Fast Adversarial Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Pan",
      "Qing Li",
      "Xin Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30148": {
    "title": "A PAC Learning Algorithm for LTL and Omega-Regular Objectives in MDPs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mateo Perez",
      "Fabio Somenzi",
      "Ashutosh Trivedi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30149": {
    "title": "Robust Stochastic Graph Generator for Counterfactual Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mario Alfonso Prado-Romero",
      "Bardh Prenkaj",
      "Giovanni Stilo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30150": {
    "title": "Visual Adversarial Examples Jailbreak Aligned Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyu Qi",
      "Kaixuan Huang",
      "Ashwinee Panda",
      "Peter Henderson",
      "Mengdi Wang",
      "Prateek Mittal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30151": {
    "title": "Dissenting Explanations: Leveraging Disagreement to Reduce Model Overreliance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omer Reingold",
      "Judy Hanwen Shen",
      "Aditi Talati"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30152": {
    "title": "I-CEE: Tailoring Explanations of Image Classification Models to User Expertise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao Rong",
      "Peizhu Qian",
      "Vaibhav Unhelkar",
      "Enkelejda Kasneci"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30153": {
    "title": "A Simple and Practical Method for Reducing the Disparate Impact of Differential Privacy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucas Rosenblatt",
      "Julia Stoyanovich",
      "Christopher Musco"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30154": {
    "title": "Interpretability Benchmark for Evaluating Spatial Misalignment of Prototypical Parts Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mikołaj Sacha",
      "Bartosz Jura",
      "Dawid Rymarczyk",
      "Łukasz Struski",
      "Jacek Tabor",
      "Bartosz Zieliński"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30155": {
    "title": "Human-Guided Moral Decision Making in Text-Based Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijing Shi",
      "Meng Fang",
      "Ling Chen",
      "Yali Du",
      "Jun Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30156": {
    "title": "Towards Fairer Centroids in K-means Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stanley Simoes",
      "Deepak P",
      "Muiris MacCarthaigh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30157": {
    "title": "Toward Robustness in Multi-Label Classification: A Data Augmentation Strategy against Imbalance and Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hwanjun Song",
      "Minseok Kim",
      "Jae-Gil Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30158": {
    "title": "Bidirectional Contrastive Split Learning for Visual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuwei Sun",
      "Hideya Ochiai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30159": {
    "title": "Quantile-Based Maximum Likelihood Training for Outlier Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Masoud Taghikhah",
      "Nishant Kumar",
      "Siniša Šegvić",
      "Abouzar Eslami",
      "Stefan Gumhold"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30160": {
    "title": "Sparsity-Guided Holistic Explanation for LLMs with Interpretable Inference-Time Intervention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Tan",
      "Tianlong Chen",
      "Zhenyu Zhang",
      "Huan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30161": {
    "title": "Toward More Generalized Malicious URL Detection Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun-Da Tsai",
      "Cayon Liow",
      "Yin Sheng Siang",
      "Shou-De Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30162": {
    "title": "Self-Supervised Likelihood Estimation with Energy Guidance for Anomaly Segmentation in Urban Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanpeng Tu",
      "Yuxi Li",
      "Boshen Zhang",
      "Liang Liu",
      "Jiangning Zhang",
      "Yabiao Wang",
      "Cairong Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30163": {
    "title": "Pure-Past Action Masking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giovanni Varricchione",
      "Natasha Alechina",
      "Mehdi Dastani",
      "Giuseppe De Giacomo",
      "Brian Logan",
      "Giuseppe Perelli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30164": {
    "title": "Long-Term Safe Reinforcement Learning with Binary Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akifumi Wachi",
      "Wataru Hashimoto",
      "Kazumune Hashimoto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30165": {
    "title": "Identifying Reasons for Bias: An Argumentation-Based Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Madeleine Waller",
      "Odinaldo Rodrigues",
      "Oana Cocarascu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30166": {
    "title": "Would You Like Your Data to Be Trained? A User Controllable Recommendation Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Wang",
      "Xu Chen",
      "Zhenhua Dong",
      "Quanyu Dai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30167": {
    "title": "Moderate Message Passing Improves Calibration: A Universal Way to Mitigate Confidence Bias in Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min Wang",
      "Hao Yang",
      "Jincai Huang",
      "Qing Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30168": {
    "title": "Generating Diagnostic and Actionable Explanations for Fair Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenzhong Wang",
      "Qingyuan Zeng",
      "Wanyu Lin",
      "Min Jiang",
      "Kay Chen Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30169": {
    "title": "Physics-Informed Representation and Learning: Control and Risk Quantification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoyuan Wang",
      "Reece Keller",
      "Xiyu Deng",
      "Kenta Hoshino",
      "Takashi Tanaka",
      "Yorie Nakahira"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30170": {
    "title": "Safe Reinforcement Learning with Instantaneous Constraints: The Role of Aggressive Exploration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Honghao Wei",
      "Xin Liu",
      "Lei Ying"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30171": {
    "title": "Concealing Sensitive Samples against Gradient Leakage in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Wu",
      "Munawar Hayat",
      "Mingyi  Zhou",
      "Mehrtash Harandi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30172": {
    "title": "The Evidence Contraction Issue in Deep Evidential Regression: Discussion and Solution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuefei Wu",
      "Bin Shi",
      "Bo Dong",
      "Qinghua Zheng",
      "Hua Wei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30173": {
    "title": "Byzantine-Robust Decentralized Learning via Remove-then-Clip Aggregation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Caiyi Yang",
      "Javad Ghaderi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30174": {
    "title": "Hypothesis Testing for Class-Conditional Noise Using Local Maximum Likelihood",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weisong Yang",
      "Rafael Poyiadzi",
      "Niall Twomey",
      "Raul Santos-Rodriguez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30175": {
    "title": "Providing Fair Recourse over Plausible Groups",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jayanth Yetukuri",
      "Ian Hardy",
      "Yevgeniy Vorobeychik",
      "Berk Ustun",
      "Yang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30176": {
    "title": "Representation-Based Robustness in Goal-Conditioned Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyu Yin",
      "Sihao Wu",
      "Jiaxu Liu",
      "Meng Fang",
      "Xingyu Zhao",
      "Xiaowei Huang",
      "Wenjie Ruan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30177": {
    "title": "Enhancing Off-Policy Constrained Reinforcement Learning through Adaptive Ensemble C Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hengrui Zhang",
      "Youfang Lin",
      "Shuo Shen",
      "Sheng Han",
      "Kai Lv"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30178": {
    "title": "Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiang Zhang",
      "Qiong Wu",
      "Yiming Xu",
      "Cheng Cao",
      "Zheng Du",
      "Konstantinos Psounis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30179": {
    "title": "LR-XFL: Logical Reasoning-Based Explainable Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanci Zhang",
      "Han Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30180": {
    "title": "GaLileo: General Linear Relaxation Framework for Tightening Robustness Certification of Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunruo Zhang",
      "Lujia Shen",
      "Shanqing Guo",
      "Shouling Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30181": {
    "title": "A Huber Loss Minimization Approach to Byzantine Robust Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Puning Zhao",
      "Fei Yu",
      "Zhiguo Wan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30182": {
    "title": "Responsible Bandit Learning via Privacy-Protected Mean-Volatility Utility",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanshan Zhao",
      "Wenhai Cui",
      "Bei Jiang",
      "Linglong Kong",
      "Xiaodong Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30183": {
    "title": "UMA: Facilitating Backdoor Scanning via Unlearning-Based Model Ablation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Zhao",
      "Congyi Li",
      "Kai Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30184": {
    "title": "AdvST: Revisiting Data Augmentations for Single Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangtao Zheng",
      "Mengdi Huai",
      "Aidong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30185": {
    "title": "Can LLM Replace Stack Overflow? A Study on Robustness and Reliability of Large Language Model Code Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Zhong",
      "Zilong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30186": {
    "title": "DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiachen Zhou",
      "Peizhuo Lv",
      "Yibing Lan",
      "Guozhu Meng",
      "Kai Chen",
      "Hualong Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30187": {
    "title": "Closing the Gap: Achieving Better Accuracy-Robustness Tradeoffs against Query-Based Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pascal Zimmer",
      "Sébastien Andreina",
      "Giorgia Azzurra Marson",
      "Ghassan Karame"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30188": {
    "title": "Coevolutionary Algorithm for Building Robust Decision Trees under Minimax Regret",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adam Żychowski",
      "Andrew Perrault",
      "Jacek Mańdziuk"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30189": {
    "title": "BirdCollect: A Comprehensive Benchmark for Analyzing Dense Bird Flock Attributes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kshitiz .",
      "Sonu Shreshtha",
      "Bikash Dutta",
      "Muskan Dosi",
      "Mayank Vatsa",
      "Richa Singh",
      "Saket Anand",
      "Sudeep Sarkar",
      "Sevaram Mali Parihar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30190": {
    "title": "A Bayesian Spatial Model to Correct Under-Reporting in Urban Crowdsourcing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriel Agostini",
      "Emma Pierson",
      "Nikhil Garg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30191": {
    "title": "Automatic Interpretation of Line Probe Assay Test for Tuberculosis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jatin Agrawal",
      "Mukul Kumar",
      "Avtansh Tiwari",
      "Sachin Danisetty",
      "Soma Dhavala",
      "Nakul Jain",
      "Prasaanth Balraj",
      "Niket Singh",
      "Siddhant Shingi",
      "Jayakrishna Kurada",
      "Raghuram Rao",
      "S Anand",
      "Nishant Kumar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30192": {
    "title": "Physics-Informed Graph Neural Networks for Water Distribution Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Inaam Ashraf",
      "Janine Strotherm",
      "Luca Hermes",
      "Barbara Hammer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30193": {
    "title": "Quantile-Regression-Ensemble: A Deep Learning Algorithm for Downscaling Extreme Precipitation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Bailie",
      "Yun Sing Koh",
      "Neelesh Rampal",
      "Peter B. Gibson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30194": {
    "title": "Early Detection of Extreme Storm Tide Events Using Multimodal Data Processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcel Barros",
      "Andressa Pinto",
      "Andres Monroy",
      "Felipe Moreno",
      "Jefferson Coelho",
      "Aldomar Pietro Silva",
      "Caio Fabricio Deberaldini Netto",
      "José Roberto Leite",
      "Marlon Mathias",
      "Eduardo Tannuri",
      "Artur Jordao",
      "Edson Gomi",
      "Fabio Cozman",
      "Marcelo Dottori",
      "Anna Helena Reali Costa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30195": {
    "title": "Decision-Making for Land Conservation: A Derivative-Free Optimization Framework with Nonlinear Inputs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cassidy K. Buhler",
      "Hande Y. Benson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30196": {
    "title": "CariesXrays: Enhancing Caries Detection in Hospital-Scale Panoramic Dental X-rays via Feature Pyramid Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingzhi Chen",
      "Sisi Fu",
      "Yishu Liu",
      "Jiahui Pan",
      "Guangming Lu",
      "Zheng Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30197": {
    "title": "Referee-Meta-Learning for Fast Adaptation of Locational Fairness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiye Chen",
      "Yiqun Xie",
      "Xiaowei Jia",
      "Erhu He",
      "Han Bao",
      "Bang An",
      "Xun Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30198": {
    "title": "From Artificially Real to Real: Leveraging Pseudo Data from Large Language Models for Low-Resource Molecule Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhan Chen",
      "Nuwa Xi",
      "Yanrui Du",
      "Haochun Wang",
      "Jianyu Chen",
      "Sendong Zhao",
      "Bing Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30199": {
    "title": "Auto311: A Confidence-Guided Automated System for Non-emergency Calls",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zirong Chen",
      "Xutong Sun",
      "Yuanhe Li",
      "Meiyi Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30200": {
    "title": "Blind-Touch: Homomorphic Encryption-Based Distributed Neural Network Inference for Privacy-Preserving Fingerprint Authentication",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunmin Choi",
      "Simon S. Woo",
      "Hyoungshick Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30201": {
    "title": "Identifying Guarantors of War Veterans Using Robust-SEAL: A Case of the Korean War",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jong in Choi",
      "Won Kyung Lee",
      "Jae Hwan Lee",
      "So Young Sohn"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30202": {
    "title": "Fair Sampling in Diffusion Models through Switching Mechanism",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujin Choi",
      "Jinseong Park",
      "Hoki Kim",
      "Jaewook Lee",
      "Saerom Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30203": {
    "title": "Arbitrariness and Social Prediction: The Confounding Role of Variance in Fair Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "A. Feder Cooper",
      "Katherine Lee",
      "Madiha Zahrah Choksi",
      "Solon Barocas",
      "Christopher De Sa",
      "James Grimmelmann",
      "Jon Kleinberg",
      "Siddhartha Sen",
      "Baobao Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30204": {
    "title": "Finding ε and δ of Traditional Disclosure Control Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saswat Das",
      "Keyu Zhu",
      "Christine Task",
      "Pascal Van Hentenryck",
      "Ferdinando Fioretto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30205": {
    "title": "MedAlign: A Clinician-Generated Dataset for Instruction Following with Electronic Medical Records",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Scott L. Fleming",
      "Alejandro Lozano",
      "William J. Haberkorn",
      "Jenelle A. Jindal",
      "Eduardo Reis",
      "Rahul Thapa",
      "Louis Blankemeier",
      "Julian Z. Genkins",
      "Ethan Steinberg",
      "Ashwin Nayak",
      "Birju Patel",
      "Chia-Chun Chiang",
      "Alison Callahan",
      "Zepeng Huo",
      "Sergios Gatidis",
      "Scott Adams",
      "Oluseyi Fayanju",
      "Shreya J. Shah",
      "Thomas Savage",
      "Ethan Goh",
      "Akshay S. Chaudhari",
      "Nima Aghaeepour",
      "Christopher Sharp",
      "Michael A. Pfeffer",
      "Percy Liang",
      "Jonathan H. Chen",
      "Keith E. Morse",
      "Emma P. Brunskill",
      "Jason A. Fries",
      "Nigam H. Shah"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30206": {
    "title": "CLIPSyntel: CLIP and LLM Synergy for Multimodal Question Summarization in Healthcare",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akash Ghosh",
      "Arkadeep Acharya",
      "Raghav Jain",
      "Sriparna Saha",
      "Aman Chadha",
      "Setu Sinha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30207": {
    "title": "Benchmarking Cyber Harassment Dialogue Comprehension through Emotion-Informed Manifestations-Determinants Demarcation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soumitra Ghosh",
      "Gopendra Vikram Singh",
      "Jashn Arora",
      "Asif Ekbal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30208": {
    "title": "Grey-Box Bayesian Optimization for Sensor Placement in Assisted Living Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shadan Golestan",
      "Omid Ardakanian",
      "Pierre Boulanger"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30209": {
    "title": "Federated Learning via Input-Output Collaborative Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuan Gong",
      "Shanglin Li",
      "Yuxiang Bao",
      "Barry Yao",
      "Yawen Huang",
      "Ziyan Wu",
      "Baochang Zhang",
      "Yefeng Zheng",
      "David Doermann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30210": {
    "title": "Scaling Up Pareto Optimization for Tree Structures with Affine Transformations: Evaluating Hybrid Floating Solar-Hydropower Systems in the Amazon",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marc Grimson",
      "Rafael Almeida",
      "Qinru Shi",
      "Yiwei Bai",
      "Héctor Angarita",
      "Felipe Siqueira Pacheco",
      "Rafael Schmitt",
      "Alexander Flecker",
      "Carla P. Gomes"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30211": {
    "title": "Fair Multivariate Adaptive Regression Splines for Ensuring Equity and Transparency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Parian Haghighat",
      "Denisa Gándara",
      "Lulu Kang",
      "Hadis Anahideh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30212": {
    "title": "Fair Graph Learning Using Constraint-Aware Priority Adjustment and Graph Masking in River Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Erhu He",
      "Yiqun Xie",
      "Alexander Sun",
      "Jacob Zwart",
      "Jie Yang",
      "Zhenong Jin",
      "Yang Wang",
      "Hassan Karimi",
      "Xiaowei Jia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30213": {
    "title": "Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liam Hebert",
      "Gaurav Sahu",
      "Yuxuan Guo",
      "Nanda Kishore Sreenivas",
      "Lukasz Golab",
      "Robin Cohen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30214": {
    "title": "Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Beizhe Hu",
      "Qiang Sheng",
      "Juan Cao",
      "Yuhui Shi",
      "Yang Li",
      "Danding Wang",
      "Peng Qi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30215": {
    "title": "Long-Term Fair Decision Making through Deep Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaowei Hu",
      "Yongkai Wu",
      "Lu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30216": {
    "title": "CityPulse: Fine-Grained Assessment of Urban Change with Street View Time Series",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyuan Huang",
      "Zejia Wu",
      "Jiajun Wu",
      "Jackelyn Hwang",
      "Ram Rajagopal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30217": {
    "title": "iTrendRNN: An Interpretable Trend-Aware RNN for Meteorological Spatiotemporal Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Huang",
      "Chuyao Luo",
      "Bowen Zhang",
      "Huiwei Lin",
      "Xutao Li",
      "Yunming Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30218": {
    "title": "Where It Really Matters: Few-Shot Environmental Conservation Media Monitoring for Low-Resource Languages",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sameer Jain",
      "Sedrick Scott Keh",
      "Shova Chhetri",
      "Karun Dewan",
      "Pablo  Izquierdo",
      "Johanna   Prussmann",
      "Pooja Shrestha",
      "César Suárez",
      "Zheyuan Ryan Shi",
      "Lei Li",
      "Fei Fang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30219": {
    "title": "Active Reinforcement Learning for Robust Building Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Doseok Jang",
      "Larry Yan",
      "Lucas Spangher",
      "Costas J. Spanos"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30220": {
    "title": "Adversarial Fairness Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taeuk Jang",
      "Xiaoqian Wang",
      "Heng Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30221": {
    "title": "Unraveling Pain Levels: A Data-Uncertainty Guided Approach for Effective Pain Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinwei Ji",
      "Xiaomin Chang",
      "Wei Li",
      "Albert Y. Zomaya"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30222": {
    "title": "Outlier Ranking for Large-Scale Public Health Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ananya Joshi",
      "Tina Townes",
      "Nolan Gormley",
      "Luke  Neureiter",
      "Roni Rosenfeld",
      "Bryan Wilder"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30223": {
    "title": "Deploying ADVISER: Impact and Lessons from Using Artificial Intelligence for Child Vaccination Uptake in Nigeria",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Opadele Kehinde ",
      "Ruth Abdul",
      "Bose Afolabi",
      "Parminder Vir",
      "Corinne Namblard",
      "Ayan Mukhopadhyay",
      "Abiodun Adereni"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30224": {
    "title": "Vector Field Oriented Diffusion Model for Crystal Material Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Astrid Klipfel",
      "Yaël Fregier",
      "Adlane Sayede",
      "Zied Bouraoui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30225": {
    "title": "Combining Deep Learning and Street View Imagery to Map Smallholder Crop Types",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jordi Laguarta Soler",
      "Thomas Friedel",
      "Sherrie Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30226": {
    "title": "GLH-Water: A Large-Scale Dataset for Global Surface Water Detection in Large-Size Very-High-Resolution Satellite Imagery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yansheng Li",
      "Bo Dang",
      "Wanchun Li",
      "Yongjun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30227": {
    "title": "AutoLTS: Automating Cycling Stress Assessment via Contrastive Learning and Spatial Post-processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Lin",
      "Shoshanna Saxe",
      "Timothy C. Y. Chan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30228": {
    "title": "Depression Detection via Capsule Networks with Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Liu",
      "Changya Li",
      "Xiaotong Zhang",
      "Feng Zhang",
      "Wei Wang",
      "Fenglong Ma",
      "Hongyang Chen",
      "Hong Yu",
      "Xianchao Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30229": {
    "title": "On the Actionability of Outcome Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lydia T. Liu",
      "Solon Barocas",
      "Jon Kleinberg",
      "Karen Levy"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30230": {
    "title": "Hear You Say You: An Efficient Framework for Marine Mammal Sounds' Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangrui  Liu",
      "Xiaoou Liu",
      "Shan Du",
      "Julian  Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30231": {
    "title": "Identifying and Addressing Disparities in Public Libraries with Bayesian Latent Variable Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Liu",
      "Sarah Rankin",
      "Nikhil Garg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30232": {
    "title": "Interpretable Long-Form Legal Question Answering with Retrieval-Augmented Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Antoine Louis",
      "Gijs van Dijck",
      "Gerasimos Spanakis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30233": {
    "title": "T-NET: Weakly Supervised Graph Learning for Combatting Human Trafficking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pratheeksha Nair",
      "Javin Liu",
      "Catalina Vajiac",
      "Andreas Olligschlaeger",
      "Duen Horng Chau",
      "Mirela Cazzolato",
      "Cara Jones",
      "Christos Faloutsos",
      "Reihaneh Rabbany"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30234": {
    "title": "Promoting Fair Vaccination Strategies through Influence Maximization: A Case Study on COVID-19 Spread",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicola Neophytou",
      "Afaf Taik",
      "Golnoosh Farnadi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30235": {
    "title": "DISCount: Counting in Large Image Collections with Detector-Based Importance Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gustavo Perez",
      "Subhransu Maji",
      "Daniel Sheldon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30236": {
    "title": "Discretionary Trees: Understanding Street-Level Bureaucracy via Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gaurab Pokharel",
      "Sanmay Das",
      "Patrick Fowler"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30237": {
    "title": "IndicCONAN: A Multilingual Dataset for Combating Hate Speech in Indian Context",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nihar Ranja Sahoo",
      "Gyana Prakash Beria",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30238": {
    "title": "Carbon Footprint Reduction for Sustainable Data Centers in Real-Time",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soumyendu Sarkar",
      "Avisek Naug",
      "Ricardo Luna",
      "Antonio Guillen",
      "Vineet Gundecha",
      "Sahand Ghorbanpour",
      "Sajad Mousavi",
      "Dejan Markovikj",
      "Ashwin Ramesh Babu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30239": {
    "title": "Evaluating Pre-trial Programs Using Interpretable Machine Learning Matching Algorithms for Causal Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Travis Seale-Carlisle",
      "Saksham Jain",
      "Courtney Lee",
      "Caroline Levenson",
      "Swathi Ramprasad",
      "Brandon Garrett",
      "Sudeepa Roy",
      "Cynthia Rudin",
      "Alexander Volfovsky"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30240": {
    "title": "Self-Supervised Framework Based on Subject-Wise Clustering for Human Subject Time Series Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eunseon Seong",
      "Harim Lee",
      "Dong-Kyu Chae"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30241": {
    "title": "Characterizing Information Seeking Events in Health-Related Social Discourse",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omar Sharif",
      "Madhusudan Basak",
      "Tanzia Parvin",
      "Ava Scharfstein",
      "Alphonso Bradham",
      "Jacob T. Borodovsky",
      "Sarah E. Lord",
      "Sarah M. Preum"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30242": {
    "title": "Nowcasting Temporal Trends Using Indirect Surveys",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ajitesh Srivastava",
      "Juan Marcos Ramirez",
      "Sergio Díaz-Aranda",
      "Jose Aguilar",
      "Antonio Fernández Anta",
      "Antonio Ortega",
      "Rosa Elvira Lillo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30243": {
    "title": "FairPlay: A Multi-Sided Fair Dynamic Pricing Policy for Hotels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Errikos Streviniotis",
      "Athina Georgara",
      "Filippo Bistaffa",
      "Georgios Chalkiadakis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30244": {
    "title": "Stable Matchings in Practice: A Constraint Programming Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaohong Sun",
      "Naoyuki Yamada",
      "Yoshihiro Takenami",
      "Daisuke Moriwaki",
      "Makoto Yokoo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30245": {
    "title": "Social, Legal, Ethical, Empathetic, and Cultural Rules: Compilation and Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Troquard",
      "Martina De Sanctis",
      "Paola Inverardi",
      "Patrizio Pelliccione",
      "Gian Luca Scoccia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30246": {
    "title": "Preventing Eviction-Caused Homelessness through ML-Informed Distribution of Rental Assistance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Catalina Vajiac",
      "Arun Frey",
      "Joachim Baumann",
      "Abigail Smith",
      "Kasun Amarasinghe",
      "Alice Lai",
      "Kit T. Rodolfa",
      "Rayid Ghani"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30247": {
    "title": "RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning and Convolutional Feature Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tanvi Verma",
      "Linh Le Dinh",
      "Nicholas Tan",
      "Xinxing Xu",
      "Chingyu Cheng",
      "Yong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30248": {
    "title": "Deep Reinforcement Learning for Early Diagnosis of Lung Cancer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Wang",
      "Qining Zhang",
      "Lei Ying",
      "Chuan Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30249": {
    "title": "SimFair: Physics-Guided Fairness-Aware Learning with Simulation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihao Wang",
      "Yiqun Xie",
      "Zhili Li",
      "Xiaowei Jia",
      "Zhe Jiang",
      "Aolin Jia",
      "Shuo Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30250": {
    "title": "I Open at the Close: A Deep Reinforcement Learning Evaluation of Open Streets Initiatives",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "R. Teal Witter",
      "Lucas Rosenblatt"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30251": {
    "title": "HarvestNet: A Dataset for Detecting Smallholder Farming Activity Using Harvest Piles and Remote Sensing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonathan Xu",
      "Amna Elmustafa",
      "Liya Weldegebriel",
      "Emnet Negash",
      "Richard Lee",
      "Chenlin Meng",
      "Stefano Ermon",
      "David Lobell"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30252": {
    "title": "Harnessing Network Effect for Fake News Mitigation: Selecting Debunkers via Self-Imitation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofei Xu",
      "Ke Deng",
      "Michael Dann",
      "Xiuzhen Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30253": {
    "title": "Spatial-Logic-Aware Weakly Supervised Learning for Flood Mapping on Earth Imagery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zelin Xu",
      "Tingsong Xiao",
      "Wenchong He",
      "Yu Wang",
      "Zhe Jiang",
      "Shigang  Chen",
      "Yiqun Xie",
      "Xiaowei Jia",
      "Da Yan",
      "Yang Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30254": {
    "title": "Unveiling the Tapestry of Automated Essay Scoring: A Comprehensive Investigation of Accuracy, Fairness, and Generalizability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaixun Yang",
      "Mladen Raković",
      "Yuyang Li",
      "Quanlong Guan",
      "Dragan Gašević",
      "Guangliang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30255": {
    "title": "Graph Bayesian Optimization for Multiplex Influence Maximization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zirui Yuan",
      "Minglai Shao",
      "Zhiqian Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30256": {
    "title": "Fairness-Aware Structured Pruning in Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abdelrahman Zayed",
      "Gonçalo Mordido",
      "Samira Shabanian",
      "Ioana Baldini",
      "Sarath Chandar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30257": {
    "title": "Estimating On-Road Transportation Carbon Emissions from Open Data of Road Network and Origin-Destination Flow Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinwei Zeng",
      "Yu  Liu",
      "Jingtao Ding",
      "Jian Yuan",
      "Yong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30258": {
    "title": "Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijie Zeng",
      "Lele Sha",
      "Yuheng Li",
      "Kaixun Yang",
      "Dragan Gašević",
      "Guangliang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30259": {
    "title": "Pre-trained Online Contrastive Learning for Insurance Fraud Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Zhang",
      "Dawei Cheng",
      "Jie Yang",
      "Yi Ouyang",
      "Xian Wu",
      "Yefeng Zheng",
      "Changjun Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30260": {
    "title": "UV-SAM: Adapting Segment Anything Model for Urban Village Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Zhang",
      "Yu  Liu",
      "Yuming Lin",
      "Qingmin Liao",
      "Yong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30261": {
    "title": "Causally Aware Generative Adversarial Networks for Light Pollution Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyao Zhang",
      "Ke Guo",
      "Xiao Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30262": {
    "title": "Multiple-Source Localization from a Single-Snapshot Observation Using Graph Bayesian Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zonghan Zhang",
      "Zijian Zhang",
      "Zhiqian Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30263": {
    "title": "Leveraging Opposite Gender Interaction Ratio as a Path towards Fairness in Online Dating Recommendations Based on User Sexual Orientation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuying Zhao",
      "Yu Wang",
      "Yi Zhang",
      "Pamela Wisniewski",
      "Charu Aggarwal",
      "Tyler Derr"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30264": {
    "title": "AI-Based Energy Transportation Safety: Pipeline Radial Threat Estimation Using Intelligent Sensing System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengyuan Zhu",
      "Yiyuan Yang",
      "Kaixiang Yang",
      "Haifeng Zhang",
      "Qinmin Yang",
      "C. L. Philip Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30265": {
    "title": "TAU: Trajectory Data Augmentation with Uncertainty for Next POI Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuang Zhuang",
      "Tianxin Wei",
      "Lingbo Liu",
      "Heng Qi",
      "Yanming Shen",
      "Baocai Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30266": {
    "title": "Recommender Ecosystems: A Mechanism Design Perspective on Holistic Modeling and Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Craig Boutilier",
      "Martin Mladenov",
      "Guy Tennenholtz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30267": {
    "title": "Model Reprogramming: Resource-Efficient Cross-Domain Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pin-Yu Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30268": {
    "title": "Conversational Modeling for Constraint Satisfaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eugene C. Freuder"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30269": {
    "title": "Integrated Systems for Computational Scientific Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pat Langley"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30270": {
    "title": "Towards a More Burkean Approach to Computational Social Choice",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omer Lev"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30271": {
    "title": "Regeneration Learning: A Learning Paradigm for Data Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Tan",
      "Tao Qin",
      "Jiang Bian",
      "Tie-Yan Liu",
      "Yoshua Bengio"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30272": {
    "title": "The Fairness Fair: Bringing Human Perception into Collective Decision-Making",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hadi Hosseini"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30273": {
    "title": "Temporal Fairness in Multiwinner Voting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Edith Elkind",
      "Svetlana Obraztsova",
      "Nicholas Teh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30274": {
    "title": "Mixed Fair Division: A Survey",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengxin Liu",
      "Xinhang Lu",
      "Mashbat Suzuki",
      "Toby Walsh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30275": {
    "title": "Adventures of Trustworthy Vision-Language Models: A Survey",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mayank Vatsa",
      "Anubhooti Jain",
      "Richa Singh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30276": {
    "title": "Interactive Theorem Provers: Applications in AI, Opportunities, and Challenges",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Abdulaziz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30277": {
    "title": "Symbolic Reasoning Methods for AI Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gregor Behnke"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30278": {
    "title": "Demystifying Algorithmic Fairness in an Uncertain World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lu Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30279": {
    "title": "Data-Efficient Graph Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaize Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30280": {
    "title": "Making Natural Language Reasoning Explainable and Faithful",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinya Du"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30281": {
    "title": "Towards Robust Visual Understanding: from Recognition to Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tejas Gokhale"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30282": {
    "title": "Continual Learning in an Open and Dynamic World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhui Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30283": {
    "title": "Scaling Offline Evaluation of Reinforcement Learning Agents through Abstraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Josiah P. Hanna"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30284": {
    "title": "Collaborative Learning across Heterogeneous Systems with Pre-Trained Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Trong Nghia Hoang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30285": {
    "title": "Understanding Surprising Generalization Phenomena in Deep Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30286": {
    "title": "Fostering Trustworthiness in Machine Learning Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengdi Huai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30287": {
    "title": "Deep Learning on Graphs: A Data-Centric Exploration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30288": {
    "title": "Quantifying Political Polarization through the Lens of Machine Translation and Vicarious Offense",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ashiqur R. KhudaBukhsh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30289": {
    "title": "Learning Representations for Robust Human-Robot Interaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yen-Ling Kuo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30290": {
    "title": "The Role of Over-Parameterization in Machine Learning – the Good, the Bad, the Ugly",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fanghui Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30291": {
    "title": "Algorithmic Foundation of Federated Learning with Sequential Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingrui Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30292": {
    "title": "When Causal Inference Meets Graph Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30293": {
    "title": "Towards Holistic, Pragmatic and Multimodal Conversational Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pranava Madhyastha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30294": {
    "title": "From Statistical Relational to Neuro-Symbolic Artificial Intelligence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giuseppe Marra"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30295": {
    "title": "Harmonious Mobility for Robots that Work with and around People",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christoforos Mavrogiannis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30296": {
    "title": "Recent Advancements in Inverse Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alberto Maria Metelli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30297": {
    "title": "Exploiting Data Geometry in Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Melanie Weber"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30298": {
    "title": "Towards Trustworthy Deep Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tsui-Wei (Lily) Weng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30299": {
    "title": "Towards Reliable Learning in the Wild: Generalization and Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huaxiu Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30300": {
    "title": "Towards Human-like Learning from Relational Structured Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quanming Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30301": {
    "title": "Fairness with Censorship: Bridging the Gap between Fairness Research and Real-World Deployment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenbin Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30302": {
    "title": "Fair and Optimal Prediction via Post-Processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30303": {
    "title": "Towards Reproducible, Automated, and Scalable Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30304": {
    "title": "Combating Insider Threat in the Open-World Environments: Identification, Monitoring, and Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dawei Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30590": {
    "title": "Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Micheal Abaho",
      "Yousef H. Alfaifi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30591": {
    "title": "Program Synthesis with Best-First Bottom-Up Search (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saqib Ameen",
      "Levi H. S. Lelis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30592": {
    "title": "Monitoring of Perception Systems: Deterministic, Probabilistic, and Learning-Based Fault Detection and Identification (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pasquale Antonante",
      "Heath Nilsen",
      "Luca Carlone"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30593": {
    "title": "A General Model for Aggregating Annotations AcrossSimple, Complex, and Multi-object Annotation Tasks (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Braylan",
      "Madalyn Marabella",
      "Omar Alonso",
      "Matthew Lease"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30594": {
    "title": "Temporal Logic Explanations for Dynamic Decision Systems Using Anchors and Monte Carlo Tree Search (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tzu-Yi Chiu",
      "Jerome Le Ny",
      "Jean-Pierre David"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30595": {
    "title": "Mimicking Behaviors in Separated Domains (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giuseppe De Giacomo",
      "Dror Fried",
      "Fabio Patrizi",
      "Shufang Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30596": {
    "title": "Counterfactual Explanations for Misclassified Images: How Human and Machine Explanations Differ (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eoin Delaney",
      "Arjun Pakrashi",
      "Derek Greene",
      "Mark T. Keane"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30597": {
    "title": "Reasoning about Causality in Games (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lewis Hammond",
      "James Fox",
      "Tom Everitt",
      "Ryan Carey",
      "Alessandro Abate",
      "Michael Wooldridge"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30598": {
    "title": "A Survey of Learning Criteria Going beyond the Usual Risk (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew J. Holland",
      "Kazuki Tanabe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30599": {
    "title": "Sim-to-Lab-to-Real: Safe Reinforcement Learning with Shielding and Generalization Guarantees (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai-Chieh Hsu",
      "Allen Z. Ren",
      "Duy P. Nguyen",
      "Anirudha Majumdar",
      "Jaime F. Fisac"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30600": {
    "title": "FlexiBO: A Decoupled Cost-Aware Multi-objective Optimization Approach for Deep Neural Networks (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Shahriar Iqbal",
      "Jianhai Su",
      "Lars Kotthoff",
      "Pooyan Jamshidi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30601": {
    "title": "Discovering Agents (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zachary Kenton",
      "Ramana Kumar",
      "Sebastian Farquhar",
      "Jonathan Richens",
      "Matt MacDermott",
      "Tom Everitt"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30602": {
    "title": "Reward (Mis)design for Autonomous Driving (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "W. Bradley Knox",
      "Alessandro Allievi",
      "Holger Banzhaf",
      "Felix Schmitt",
      "Peter Stone"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30603": {
    "title": "The Defeat of the Winograd Schema Challenge (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vid Kocijan",
      "Ernest Davis",
      "Thomas Lukasiewicz",
      "Gary Marcus",
      "Leora Morgenstern"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30604": {
    "title": "Convolutional Spectral Kernel Learning with Generalization Guarantees (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Li",
      "Yong Liu",
      "Weiping Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30605": {
    "title": "G–LIME: Statistical Learning for Local Interpretations of Deep Neural Networks Using Global Priors (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuhong Li",
      "Haoyi Xiong",
      "Xingjian Li",
      "Xiao Zhang",
      "Ji Liu",
      "Haiyan Jiang",
      "Zeyu Chen",
      "Dejing Dou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30606": {
    "title": "Exploiting Action Impact Regularity and Exogenous State Variables for Offline Reinforcement Learning (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Liu",
      "James R. Wright",
      "Mrtha White"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30607": {
    "title": "Introduction to the Special Track on Artificial Intelligence and COVID-19 (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martin Michalowski",
      "Robert Moskovitch",
      "Nitesh V. Chawla"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30608": {
    "title": "TEAMSTER: Model-Based Reinforcement Learning for Ad Hoc Teamwork (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "João G. Ribeiro",
      "Gonçalo Rodrigues",
      "Alberto Sardinha",
      "Francisco S. Melo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30609": {
    "title": "Sequential Model-Based Diagnosis by Systematic Search (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Rodler"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30610": {
    "title": "Actor Prioritized Experience Replay (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baturay Saglam",
      "Furkan Mutlu",
      "Dogan Cicek",
      "Suleyman Kozat"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30611": {
    "title": "Accurate Parameter Estimation for Safety-Critical Systems with Unmodeled Dynamics (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arnab Sarker",
      "Peter Fisher",
      "Joseph Gaudio",
      "Anuradha Annaswamy"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30612": {
    "title": "Your Prompt Is My Command: On Assessing the Human-Centred Generality of Multimodal Models (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wout Schellaert",
      "Fernando Martínez-Plumed",
      "Karina Vold",
      "John Burden",
      "Pablo A. M. Casares",
      "Bao Sheng Loe",
      "Roi Reichart",
      "Sean Ó hÉigeartaigh",
      "Anna Korhonen",
      "José Hernández-Orallo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30613": {
    "title": "Reward-Respecting Subtasks for Model-Based Reinforcement Learning (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Richard S. Sutton",
      "Marlos C. Machado",
      "G. Zacharias Holland",
      "David Szepesvari",
      "Finbarr Timbers",
      "Brian Tanner",
      "Adam White"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/30614": {
    "title": "Post-trained Convolution Networks for Single Image Super-resolution (Abstract Reprint)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seid Miad Zandavi"
    ]
  }
}