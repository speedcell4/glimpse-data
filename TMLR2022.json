{
  "https://openreview.net/forum?id=QaDevCcmcg": {
    "title": "Uncertainty-Based Active Learning for Reading Comprehension",
    "volume": "main",
    "abstract": "Recent years have witnessed a surge of successful applications of machine reading comprehension. Of central importance to these tasks is the availability of massive amount of labeled data, which facilitates training of large-scale neural networks. However, in many real-world problems, annotated data are expensive to gather not only because of time cost and budget, but also of certain domain-specific restrictions such as privacy for healthcare data. In this regard, we propose an uncertainty-based active learning algorithm for reading comprehension, which interleaves data annotation and model updating to mitigate the demand of labeling. Our key techniques are two-fold: 1) an unsupervised uncertainty-based sampling scheme that queries the labels of the most informative instances with respect to the currently learned model; and 2) an adaptive loss minimization paradigm that simultaneously fits the data and controls the degree of model updating. We demonstrate on benchmark datasets that 25% less labeled samples suffice to guarantee similar, or even improved performance. Our results show strong evidence that for label-demanding scenarios, the proposed approach offers a practical guide on data collection and model training",
    "checked": true,
    "id": "5350fa166ee3bd093bb031fc3b0aae2b97e18b72",
    "semantic_title": "uncertainty-based active learning for reading comprehension",
    "citation_count": 2,
    "authors": [
      "Jing Wang",
      "Jie Shen",
      "Xiaofei Ma",
      "Andrew Arnold"
    ]
  },
  "https://openreview.net/forum?id=p8gncJbMit": {
    "title": "A geometrical connection between sparse and low-rank matrices and its application to manifold learning",
    "volume": "main",
    "abstract": "We consider when a sparse nonnegative matrix $\\mathbf{S}$ can be recovered, via an elementwise nonlinearity, from a real-valued matrix~$\\mathbf{L}$ of significantly lower rank. Of particular interest is the setting where the positive elements of $\\mathbf{S}$ encode the similarities of nearby points on a low dimensional manifold. The recovery can then be posed as a problem in manifold learning---in this case, how to learn a norm-preserving and neighborhood-preserving mapping of high dimensional inputs into a lower dimensional space. We describe an algorithm for this problem based on a generalized low-rank decomposition of sparse matrices. This decomposition has the interesting property that it can be encoded by a neural network with one layer of rectified linear units; since the algorithm discovers this encoding, it can also be viewed as a layerwise primitive for deep learning. The algorithm regards the inputs $\\mathbf{x}_i$ and $\\mathbf{x}_j$ as similar whenever the cosine of the angle between them exceeds some threshold $\\tau\\in(0,1)$. Given this threshold, the algorithm attempts to discover a mapping $\\mathbf{x}_i\\mapsto\\mathbf{y}_i$ by matching the elements of two sparse matrices; in particular, it seeks a mapping for which $\\mathbf{S}=\\max(0,\\mathbf{L})$, where $S_{ij} = \\max(0,\\mathbf{x}_i\\!\\cdot\\!\\mathbf{x}_j\\! -\\! \\tau\\|\\mathbf{x}_i\\|\\|\\mathbf{x}_j\\|)$ and $L_{ij} = \\mathbf{y}_i\\!\\cdot\\!\\mathbf{y}_j\\! -\\! \\tau\\|\\mathbf{y}_i\\|\\|\\mathbf{y}_j\\|$. We apply the algorithm to data sets where vector magnitudes and small cosine distances have interpretable meanings (e.g., the brightness of an image, the similarity to other words). On these data sets, the algorithm is able to discover much lower dimensional representations that preserve these meanings",
    "checked": true,
    "id": "feba15635b24fb16630fec20c7bd1b7ee82533be",
    "semantic_title": "a geometrical connection between sparse and low-rank matrices and its application to manifold learning",
    "citation_count": 8,
    "authors": [
      "Lawrence K. Saul"
    ]
  },
  "https://openreview.net/forum?id=VipljNfZSZ": {
    "title": "Collaborative Algorithms for Online Personalized Mean Estimation",
    "volume": "main",
    "abstract": "We consider an online estimation problem involving a set of agents. Each agent has access to a (personal) process that generates samples from a real-valued distribution and seeks to estimate its mean. We study the case where some of the distributions have the same mean, and the agents are allowed to actively query information from other agents. The goal is to design an algorithm that enables each agent to improve its mean estimate thanks to communication with other agents. The means as well as the number of distributions with same mean are unknown, which makes the task nontrivial. We introduce a novel collaborative strategy to solve this online personalized mean estimation problem. We analyze its time complexity and introduce variants that enjoy good performance in numerical experiments. We also extend our approach to the setting where clusters of agents with similar means seek to estimate the mean of their cluster",
    "checked": true,
    "id": "ee32f3994f162e928e510843df2cd014672c4f12",
    "semantic_title": "collaborative algorithms for online personalized mean estimation",
    "citation_count": 4,
    "authors": [
      "Mahsa Asadi",
      "Aur√©lien Bellet",
      "Odalric-Ambrym Maillard",
      "Marc Tommasi"
    ]
  },
  "https://openreview.net/forum?id=x4hmIsWu7e": {
    "title": "Indiscriminate Data Poisoning Attacks on Neural Networks",
    "volume": "main",
    "abstract": "Data poisoning attacks, in which a malicious adversary aims to influence a model by injecting ``poisoned'' data into the training process, have attracted significant recent attention. In this work, we take a closer look at existing poisoning attacks and connect them with old and new algorithms for solving sequential Stackelberg games. By choosing an appropriate loss function for the attacker and optimizing with algorithms that exploit second-order information, we design poisoning attacks that are effective on neural networks. We present efficient implementations by parameterizing the attacker and allowing simultaneous and coordinated generation of tens of thousands of poisoned points, in contrast to most existing methods that generate poisoned points one by one. We further perform extensive experiments that empirically explore the effect of data poisoning attacks on deep neural networks. Our paper sets a new benchmark on the possibility of performing indiscriminate data poisoning attacks on modern neural networks",
    "checked": true,
    "id": "3473619be2b2a481c0ac459ec2bf5449119fceb1",
    "semantic_title": "indiscriminate data poisoning attacks on neural networks",
    "citation_count": 26,
    "authors": [
      "Yiwei Lu",
      "Gautam Kamath",
      "Yaoliang Yu"
    ]
  },
  "https://openreview.net/forum?id=HFfJWx60IT": {
    "title": "An empirical study of implicit regularization in deep offline RL",
    "volume": "main",
    "abstract": "Deep neural networks are the most commonly used function approximators in offline reinforcement learning. Prior works have shown that neural nets trained with TD-learning and gradient descent can exhibit implicit regularization that can be characterized by under-parameterization of these networks. Specifically, the rank of the penultimate feature layer, also called effective rank, has been observed to drastically collapse during the training. In turn, this collapse has been argued to reduce the model's ability to further adapt in later stages of learning, leading to the diminished final performance. Such an association between the effective rank and performance makes effective rank compelling for offline RL, primarily for offline policy evaluation. In this work, we conduct a careful empirical study on the relation between effective rank and performance on three offline RL datasets : bsuite, Atari, and DeepMind lab. We observe that a direct association exists only in restricted settings and disappears in the more extensive hyperparameter sweeps. Also, we empirically identify three phases of learning that explain the impact of implicit regularization on the learning dynamics and found that bootstrapping alone is insufficient to explain the collapse of the effective rank. Further, we show that several other factors could confound the relationship between effective rank and performance and conclude that studying this association under simplistic assumptions could be highly misleading",
    "checked": true,
    "id": "8856b6e9a0d79d674d772c175e95fb03e9e4a5f5",
    "semantic_title": "an empirical study of implicit regularization in deep offline rl",
    "citation_count": 17,
    "authors": [
      "Caglar Gulcehre",
      "Srivatsan Srinivasan",
      "Jakub Sygnowski",
      "Georg Ostrovski",
      "Mehrdad Farajtabar",
      "Matthew Hoffman",
      "Razvan Pascanu",
      "Arnaud Doucet"
    ]
  },
  "https://openreview.net/forum?id=sRgvmXjrmg": {
    "title": "Unsupervised Network Embedding Beyond Homophily",
    "volume": "main",
    "abstract": "Network embedding (NE) approaches have emerged as a predominant technique to represent complex networks and have benefited numerous tasks. However, most NE approaches rely on a homophily assumption to learn embeddings with the guidance of supervisory signals, leaving the unsupervised heterophilous scenario relatively unexplored. This problem becomes especially relevant in fields where a scarcity of labels exists. Here, we formulate the unsupervised NE task as an r-ego network discrimination problem and develop the SELENE framework for learning on networks with homophily and heterophily. Specifically, we design a dual-channel feature embedding pipeline to discriminate r-ego networks using node attributes and structural information separately. We employ heterophily adapted self-supervised learning objective functions to optimise the framework to learn intrinsic node embeddings. We show that SELENE's components improve the quality of node embeddings, facilitating the discrimination of connected heterophilous nodes. Comprehensive empirical evaluations on both synthetic and real-world datasets with varying homophily ratios validate the effectiveness of SELENE in homophilous and heterophilous settings showing an up to 12.52% clustering accuracy gain",
    "checked": true,
    "id": "b95ec59a0fd7641f4dc7eaade0014ce89950c415",
    "semantic_title": "unsupervised network embedding beyond homophily",
    "citation_count": 6,
    "authors": [
      "Zhiqiang Zhong",
      "Guadalupe Gonzalez",
      "Daniele Grattarola",
      "Jun Pang"
    ]
  },
  "https://openreview.net/forum?id=eWvBEMTlRq": {
    "title": "Unsupervised Learning of Neurosymbolic Encoders",
    "volume": "main",
    "abstract": "We present a framework for the unsupervised learning of neurosymbolic encoders, which are encoders obtained by composing neural networks with symbolic programs from a domain-specific language. Our framework naturally incorporates symbolic expert knowledge into the learning process, which leads to more interpretable and factorized latent representations compared to fully neural encoders. We integrate modern program synthesis techniques with the variational autoencoding (VAE) framework, in order to learn a neurosymbolic encoder in conjunction with a standard decoder. The programmatic descriptions from our encoders can benefit many analysis workflows, such as in behavior modeling where interpreting agent actions and movements is important. We evaluate our method on learning latent representations for real-world trajectory data from animal biology and sports analytics. We show that our approach offers significantly better separation of meaningful categories than standard VAEs and leads to practical gains on downstream analysis tasks, such as for behavior classification",
    "checked": true,
    "id": "d90d3975f9ee7fb4ffb886ffe1f09dff90b2f951",
    "semantic_title": "unsupervised learning of neurosymbolic encoders",
    "citation_count": 14,
    "authors": [
      "Eric Zhan",
      "Jennifer J. Sun",
      "Ann Kennedy",
      "Yisong Yue",
      "Swarat Chaudhuri"
    ]
  },
  "https://openreview.net/forum?id=4pCjIGIjrt": {
    "title": "Sequentially learning the topological ordering of directed acyclic graphs with likelihood ratio scores",
    "volume": "main",
    "abstract": "Causal discovery, the learning of causality in a data mining scenario, has been of strong scientific and theoretical interest as a starting point to identify \"what causes what?'' Contingent on assumptions and a proper learning algorithm, it is sometimes possible to identify and accurately estimate an underlying directed acyclic graph (DAG), as opposed to a Markov equivalence class of graphs that gives ambiguity of causal directions. The focus of this paper is in highlighting the identifiability and estimation of DAGs through a sequential sorting procedure that orders variables one at a time, starting at root nodes, followed by children of the root nodes, and so on until completion. We demonstrate a novel application of this general sequential approach to estimate the topological ordering of the DAG corresponding to a linear structural equation model with a non-Gaussian error distribution family. At each step of the procedure, only simple likelihood ratio scores are calculated on regression residuals to decide the next node to append to the current partial ordering. The computational complexity of our algorithm on a $p$-node problem is $\\mathcal{O}(pd)$, where $d$ is the maximum neighborhood size. Under mild assumptions, the population version of our procedure provably identifies a true ordering of the underlying DAG. We provide extensive numerical evidence to demonstrate that this sequential procedure scales to possibly thousands of nodes and works well for high-dimensional data. We accompany these numerical experiments with an application to a single-cell gene expression dataset. Our $\\texttt{R}$ package with examples and installation instructions can be found at https://gabriel-ruiz.github.io/scorelingam/",
    "checked": true,
    "id": "8db5a8c6f346177a8caaec22ff0d5144e47fad72",
    "semantic_title": "sequentially learning the topological ordering of directed acyclic graphs with likelihood ratio scores",
    "citation_count": 2,
    "authors": [
      "Gabriel Ruiz",
      "OSCAR HERNAN MADRID PADILLA",
      "Qing Zhou"
    ]
  },
  "https://openreview.net/forum?id=lukVf4VrfP": {
    "title": "Lazy vs hasty: linearization in deep networks impacts learning schedule based on example difficulty",
    "volume": "main",
    "abstract": "Among attempts at giving a theoretical account of the success of deep neural networks, a recent line of work has identified a so-called `lazy' training regime in which the network can be well approximated by its linearization around initialization. Here we investigate the comparative effect of the lazy (linear) and feature learning (non-linear) regimes on subgroups of examples based on their difficulty. Specifically, we show that easier examples are given more weight in feature learning mode, resulting in faster training compared to more difficult ones. In other words, the non-linear dynamics tends to sequentialize the learning of examples of increasing difficulty. We illustrate this phenomenon across different ways to quantify example difficulty, including c-score, label noise, and in the presence of easy-to-learn spurious correlations. Our results reveal a new understanding of how deep networks prioritize resources across example difficulty",
    "checked": true,
    "id": "74692ff84d28e8ef013e08714552dd0f32711152",
    "semantic_title": "lazy vs hasty: linearization in deep networks impacts learning schedule based on example difficulty",
    "citation_count": 6,
    "authors": [
      "Thomas George",
      "Guillaume Lajoie",
      "Aristide Baratin"
    ]
  },
  "https://openreview.net/forum?id=VmTYgjYloM": {
    "title": "Fourier Sensitivity and Regularization of Computer Vision Models",
    "volume": "main",
    "abstract": "Recent work has empirically shown that deep neural networks latch on to the Fourier statistics of training data and show increased sensitivity to Fourier-basis directions in the input. Understanding and modifying this Fourier-sensitivity of computer vision models may help improve their robustness, hence, in this paper we study the frequency sensitivity characteristics of deep neural networks using a principled approach. We first propose a $\\textbf{\\textit{basis trick}}$, proving that unitary transformations of the input-gradient of a function can be used to compute its gradient in the basis induced by the transformation. Using this result, we propose a general measure of any differentiable computer vision model's $\\textit{\\textbf{Fourier-sensitivity}}$ using the unitary Fourier-transform of its input-gradient. When applied to deep neural networks, we find that computer vision models are consistently sensitive to particular frequencies dependent on the dataset, training method and architecture. Based on this measure, we further propose a $\\textit{\\textbf{Fourier-regularization}}$ framework to modify the Fourier-sensitivities and frequency bias of models. Using our proposed regularizer-family, we demonstrate that deep neural networks obtain improved classification accuracy on robustness evaluations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kiran Krishnamachari",
      "See-Kiong Ng",
      "Chuan-Sheng Foo"
    ]
  },
  "https://openreview.net/forum?id=2VWR6JfwNo": {
    "title": "MVSFormer: Multi-View Stereo by Learning Robust Image Features and Temperature-based Depth",
    "volume": "main",
    "abstract": "Feature representation learning is the key recipe for learning-based Multi-View Stereo (MVS). As the common feature extractor of learning-based MVS, vanilla Feature Pyramid Networks (FPNs) suffer from discouraged feature representations for reflection and texture-less areas, which limits the generalization of MVS. Even FPNs worked with pre-trained Convolutional Neural Networks (CNNs) fail to tackle these issues. On the other hand, Vision Transformers (ViTs) have achieved prominent success in many 2D vision tasks. Thus we ask whether ViTs can facilitate feature learning in MVS? In this paper, we propose a pre-trained ViT enhanced MVS network called MVSFormer, which can learn more reliable feature representations benefited by informative priors from ViT. The finetuned MVSFormer with hierarchical ViTs of efficient attention mechanisms can achieve prominent improvement based on FPNs. Besides, the alternative MVSFormer with frozen ViT weights is further proposed. This largely alleviates the training cost with competitive performance strengthened by the attention map from the self-distillation pre-training. MVSFormer can be generalized to various input resolutions with efficient multi-scale training strengthened by gradient accumulation. Moreover, we discuss the merits and drawbacks of classification and regression-based MVS methods, and further propose to unify them with a temperature-based strategy. MVSFormer achieves state-of-the-art performance on the DTU dataset. Particularly, MVSFormer ranks as Top-1 on both intermediate and advanced sets of the highly competitive Tanks-and-Temples leaderboard. Codes and models are released in https://github.com/ewrfcas/MVSFormer",
    "checked": true,
    "id": "0475f5c612a4eb5324a23179eede6680ac0ecdb3",
    "semantic_title": "mvsformer: multi-view stereo by learning robust image features and temperature-based depth",
    "citation_count": 54,
    "authors": [
      "Chenjie Cao",
      "Xinlin Ren",
      "Yanwei Fu"
    ]
  },
  "https://openreview.net/forum?id=Z44YAcLaGw": {
    "title": "Controllable Generative Modeling via Causal Reasoning",
    "volume": "main",
    "abstract": "Deep latent variable generative models excel at generating complex, high-dimensional data, often exhibiting impressive generalization beyond the training distribution. However, many such models in use today are black-boxes trained on large unlabelled datasets with statistical objectives and lack an interpretable understanding of the latent space required for controlling the generative process. We propose CAGE, a framework for controllable generation in latent variable models based on causal reasoning. Given a pair of attributes, CAGE infers the implicit cause-effect relationships between these attributes as induced by a deep generative model. This is achieved by defining and estimating a novel notion of unit-level causal effects in the latent space of the generative model. Thereafter, we use the inferred cause-effect relationships to design a novel strategy for controllable generation based on counterfactual sampling. Through a series of large-scale synthetic and human evaluations, we demonstrate that generating counterfactual samples which respect the underlying causal relationships inferred via CAGE leads to subjectively more realistic images",
    "checked": true,
    "id": "e2bc83185fbac80d61d2ad7c242ebe7425a40d23",
    "semantic_title": "controllable generative modeling via causal reasoning",
    "citation_count": 5,
    "authors": [
      "Joey Bose",
      "Ricardo Pio Monti",
      "Aditya Grover"
    ]
  },
  "https://openreview.net/forum?id=DY1pMrmDkm": {
    "title": "Modeling Bounded Rationality in Multi-Agent Simulations Using Rationally Inattentive Reinforcement Learning",
    "volume": "main",
    "abstract": "Multi-agent reinforcement learning (MARL) is a powerful framework for studying emergent behavior in complex agent-based simulations. However, RL agents are often assumed to be rational and behave optimally, which does not fully reflect human behavior. In this work, we propose a new, more human-like RL agent, which incorporates an established model of human-irrationality, the Rational Inattention (RI) model. RI models the cost of cognitive information processing using mutual information. Our RIRL framework generalizes and is more flexible than prior work by allowing for multi-timestep dynamics and information channels with heterogeneous processing costs. We demonstrate the flexibility of RIRL in versions of a classic economic setting (Principal-Agent setting) with varying complexity. In simple settings, we show using RIRL can lead to optimal agent behavior policy with approximately the same functional form as what is expected from the analysis of prior work, which utilizes theoretical methods. We additionally demonstrate that using RIRL to analyze complex, theoretically intractable settings, yields a rich spectrum of new equilibrium behaviors that differ from those found under rationality assumptions. For example, increasing the cognitive cost experienced by a manager agent results in the other agents increasing the magnitude of their action to compensate. These results suggest RIRL is a powerful tool towards building AI agents that can mimic real human behavior",
    "checked": true,
    "id": "a29c571dfa2af621147adf039c0eaffb32eec49b",
    "semantic_title": "modeling bounded rationality in multi-agent simulations using rationally inattentive reinforcement learning",
    "citation_count": 2,
    "authors": [
      "Tong Mu",
      "Stephan Zheng",
      "Alexander R Trott"
    ]
  },
  "https://openreview.net/forum?id=zFhNBs8GaV": {
    "title": "Calibrated Selective Classification",
    "volume": "main",
    "abstract": "Selective classification allows models to abstain from making predictions (e.g., say ``I don't know'') when in doubt in order to obtain better effective accuracy. While typical selective models can succeed at producing more accurate predictions on average, they may still allow for wrong predictions that have high confidence, or skip correct predictions that have low confidence. Providing calibrated uncertainty estimates alongside predictions---probabilities that correspond to true frequencies---can be as important as having predictions that are simply accurate on average. Uncertainty estimates, however, can sometimes be unreliable. In this paper, we develop a new approach to selective classification in which we propose a method for rejecting examples with ``uncertain'' uncertainties. By doing so, we aim to make predictions with well-calibrated uncertainty estimates over the distribution of accepted examples, a property we call selective calibration. We present a framework for learning selectively calibrated models, where a separate selector network is trained to improve the selective calibration error of a given base model. In particular, our work focuses on achieving robust calibration, where the model is intentionally designed to be tested on out-of-domain data. We achieve this through a training strategy inspired by distributionally robust optimization, in which we apply simulated input perturbations to the known, in-domain training data. We demonstrate the empirical effectiveness of our approach on multiple image classification and lung cancer risk assessment tasks",
    "checked": true,
    "id": "9f6d0f47f4dc0dabd2da6634def89f6d8d5b31b2",
    "semantic_title": "calibrated selective classification",
    "citation_count": 17,
    "authors": [
      "Adam Fisch",
      "Tommi S. Jaakkola",
      "Regina Barzilay"
    ]
  },
  "https://openreview.net/forum?id=29V0xo7jKp": {
    "title": "Unsupervised Mismatch Localization in Cross-Modal Sequential Data with Application to Mispronunciations Localization",
    "volume": "main",
    "abstract": "Content mismatch usually occurs when data from one modality is translated to another, e.g. language learners producing mispronunciations (errors in speech) when reading a sentence (target text) aloud. However, most existing alignment algorithms assume that the content involved in the two modalities is perfectly matched, thus leading to difficulty in locating such mismatch between speech and text. In this work, we develop an unsupervised learning algorithm that can infer the relationship between content-mismatched cross-modal sequential data, especially for speech-text sequences. More specifically, we propose a hierarchical Bayesian deep learning model, dubbed mismatch localization variational autoencoder (ML-VAE), which decomposes the generative process of the speech into hierarchically structured latent variables, indicating the relationship between the two modalities. Training such a model is very challenging due to the discrete latent variables with complex dependencies involved. To address this challenge, we propose a novel and effective training procedure that alternates between estimating the hard assignments of the discrete latent variables over a specifically designed mismatch localization finite-state acceptor (ML-FSA) and updating the parameters of neural networks. In this work, we focus on the mismatch localization problem for speech and text, and our experimental results show that ML-VAE successfully locates the mismatch between text and speech, without the need for human annotations for model training",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Wei",
      "Hengguan Huang",
      "Xiangming Gu",
      "Hao Wang",
      "Ye Wang"
    ]
  },
  "https://openreview.net/forum?id=b4tMhpN0JC": {
    "title": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "volume": "main",
    "abstract": "In this paper, we design and train a Generative Image-to-text Transformer, GIT, to unify vision-language tasks such as image/video captioning and question answering. While generative models provide a consistent network architecture between pre-training and fine-tuning, existing work typically contains complex structures (uni/multi-modal encoder/decoder) and depends on external modules such as object detectors/taggers and optical character recognition (OCR). In GIT, we simplify the architecture as one image encoder and one text decoder under a single language modeling task. We also scale up the pre-training data and the model size to boost the model performance. Without bells and whistles, our GIT establishes new state of the arts on numerous challenging benchmarks with a large margin. For instance, our model surpasses the human performance for the first time on TextCaps (138.2 vs. 125.5 in CIDEr). Furthermore, we present a new scheme of generation-based image classification and scene text recognition, achieving decent performance on standard benchmarks",
    "checked": true,
    "id": "60ee030773ba1b68eb222a265b052ca028353362",
    "semantic_title": "git: a generative image-to-text transformer for vision and language",
    "citation_count": 564,
    "authors": [
      "Jianfeng Wang",
      "Zhengyuan Yang",
      "Xiaowei Hu",
      "Linjie Li",
      "Kevin Lin",
      "Zhe Gan",
      "Zicheng Liu",
      "Ce Liu",
      "Lijuan Wang"
    ]
  },
  "https://openreview.net/forum?id=WXVkgkPXRk": {
    "title": "Concave Utility Reinforcement Learning with Zero-Constraint Violations",
    "volume": "main",
    "abstract": "We consider the problem of tabular infinite horizon concave utility reinforcement learning (CURL) with convex constraints. For this, we propose a model-based learning algorithm that also achieves zero constraint violations. Assuming that the concave objective and the convex constraints have a solution interior to the set of feasible occupation measures, we solve a tighter optimization problem to ensure that the constraints are never violated despite the imprecise model knowledge and model stochasticity. We use Bellman error-based analysis for tabular infinite-horizon setups which allows analyzing stochastic policies. Combining the Bellman error-based analysis and tighter optimization equation, for $T$ interactions with the environment, we obtain a high-probability regret guarantee for objective which grows as $\\Tilde{O}(1/\\sqrt{T})$, excluding other factors. The proposed method can be applied for optimistic algorithms to obtain high-probability regret bounds and also be used for posterior sampling algorithms to obtain a loose Bayesian regret bounds but with significant improvement in computational complexity",
    "checked": true,
    "id": "85d44bb076fa060345132ee5149cd73d30dbe417",
    "semantic_title": "concave utility reinforcement learning with zero-constraint violations",
    "citation_count": 13,
    "authors": [
      "Mridul Agarwal",
      "Qinbo Bai",
      "Vaneet Aggarwal"
    ]
  },
  "https://openreview.net/forum?id=k4iWTEdUSF": {
    "title": "Fast and Accurate Spreading Process Temporal Scale Estimation",
    "volume": "main",
    "abstract": "Spreading processes on graphs arise in a host of application domains, from the study of online social networks to viral marketing to epidemiology. Various discrete-time probabilistic models for spreading processes have been proposed. These are used for downstream statistical estimation and prediction problems, often involving messages or other information that is transmitted along with infections caused by the process. These models generally model cascade behavior at a small time scale but are insufficiently flexible to model cascades that exhibit intermittent behavior governed by multiple scales. We argue that the presence of such time scales that are unaccounted for by a cascade model can result in degradation of performance of models on downstream statistical and time-sensitive optimization tasks. To address these issues, we formulate a model that incorporates multiple temporal scales of cascade behavior. This model is parameterized by a \\emph{clock}, which encodes the times at which sessions of cascade activity start. These sessions are themselves governed by a small-scale cascade model, such as the discretized independent cascade (IC) model. Estimation of the multiscale cascade model parameters leads to the problem of \\emph{clock estimation} in terms of a natural distortion measure that we formulate. Our framework is inspired by the optimization problem posed by DiTursi et al, 2017, which can be seen as providing one possible estimator (a maximum-proxy-likelihood estimator) for the parameters of our generative model. We give a clock estimation algorithm, which we call FastClock, that runs in linear time in the size of its input and is provably statistically accurate for a broad range of model parameters when cascades are generated from any spreading process model with well-concentrated session infection set sizes and when the underlying graph is at least in the semi-sparse regime. We exemplify our algorithm for the case where the small-scale model is the discretized independent cascade process and extend substantially to processes whose infection set sizes satisfy a general martingale difference property. We further evaluate the performance of FastClock empirically in comparison to the state of the art estimator from DiTursi et al, 2017. We find that in a broad parameter range on synthetic networks and on a real network, our algorithm substantially outperforms that algorithm in terms of both running time and accuracy. In all cases, our algorithm's running time is asymptotically lower than that of the baseline",
    "checked": true,
    "id": "e616a197c685b9c0114090e1517501b70f7fda24",
    "semantic_title": "fast and accurate spreading process temporal scale estimation",
    "citation_count": 0,
    "authors": [
      "Abram Magner",
      "Carolyn S Kaminski",
      "Petko Bogdanov"
    ]
  },
  "https://openreview.net/forum?id=RP6G787uD8": {
    "title": "Extracting Local Reasoning Chains of Deep Neural Networks",
    "volume": "main",
    "abstract": "We study how to explain the main steps of inference that a pre-trained deep neural net (DNN) relies on to produce predictions for a (sub)task and its data. This problem is related to network pruning and interpretable machine learning with the following highlighted differences: (1) fine-tuning of any neurons/filters is forbidden; (2) we target a very high pruning rate, e.g., ‚â• 95%, for better interpretability; (3) the interpretation is for the whole inference process on a few data of a task rather than for individual neurons/filters or a single sample. In this paper, we introduce NeuroChains to extract the local inference chains by optimizing differentiable sparse scores for the filters and layers, which reflects their importance in preserving the outputs on a few data drawn from a given (sub)task. Thereby, NeuroChains can extract an extremely small sub-network composed of critical filters exactly copied from the original pre-trained DNN by removing the filters/layers with small scores. For samples from the same class, we can then visualize the inference pathway in the pre-trained DNN by applying existing interpretation techniques to the retained filters and layers. It reveals how the inference process stitches and integrates the information layer by layer and filter by filter. We provide detailed and insightful case studies together with several quantitative analyses over thousands of trials to demonstrate the quality, sparsity, fidelity and accuracy of the interpretation. In extensive empirical studies on VGG, ResNet, and ViT, NeuroChains significantly enriches the interpretation and makes the inner mechanism of DNNs more transparent",
    "checked": true,
    "id": "156070205d9b7f0030c5a394d56ef64ebef4eb25",
    "semantic_title": "extracting local reasoning chains of deep neural networks",
    "citation_count": 0,
    "authors": [
      "Haiyan Zhao",
      "Tianyi Zhou",
      "Guodong Long",
      "Jing Jiang",
      "Chengqi Zhang"
    ]
  },
  "https://openreview.net/forum?id=LdEm0umNcv": {
    "title": "On Sample Complexity of Offline Reinforcement Learning with Deep ReLU Networks in Besov Spaces",
    "volume": "main",
    "abstract": "Offline reinforcement learning (RL) leverages previously collected data for policy optimization without any further active exploration. Despite the recent interest in this problem, its theoretical results in neural network function approximation settings remain elusive. In this paper, we study the statistical theory of offline RL with deep ReLU network function approximation. In particular, we establish the sample complexity of $n = \\tilde{\\mathcal{O}}( H^{4 + 4 \\frac{d}{\\alpha}} \\kappa_{\\mu}^{1 + \\frac{d}{\\alpha}} \\epsilon^{-2 - 2\\frac{d}{\\alpha}} )$ for offline RL with deep ReLU networks, where $\\kappa_{\\mu}$ is a measure of distributional shift, $H = (1-\\gamma)^{-1}$ is the effective horizon length, $d$ is the dimension of the state-action space, $\\alpha$ is a (possibly fractional) smoothness parameter of the underlying Markov decision process (MDP), and $\\epsilon$ is a user-specified error. Notably, our sample complexity holds under two novel considerations: the Besov dynamic closure and the correlated structure. While the Besov dynamic closure subsumes the dynamic conditions for offline RL in the prior works, the correlated structure renders the prior works of offline RL with general/neural network function approximation improper or inefficient in long (effective) horizon problems. To the best of our knowledge, this is the first theoretical characterization of the sample complexity of offline RL with deep neural network function approximation under the general Besov regularity condition that goes beyond the linearity regime in the traditional Reproducing Hilbert kernel spaces and Neural Tangent Kernels",
    "checked": true,
    "id": "f8d5ca8f8140a7475dacdc3ba0c27c4fa2c7c1de",
    "semantic_title": "on sample complexity of offline reinforcement learning with deep relu networks in besov spaces",
    "citation_count": 7,
    "authors": [
      "Thanh Nguyen-Tang",
      "Sunil Gupta",
      "Hung Tran-The",
      "Svetha Venkatesh"
    ]
  },
  "https://openreview.net/forum?id=F2rG2CXsgO": {
    "title": "Distribution Embedding Networks for Generalization from a Diverse Set of Classification Tasks",
    "volume": "main",
    "abstract": "We propose Distribution Embedding Networks (DEN) for classification with small data. In the same spirit of meta-learning, DEN learns from a diverse set of training tasks with the goal to generalize to unseen target tasks. Unlike existing approaches which require the inputs of training and target tasks to have the same dimension with possibly similar distributions, DEN allows training and target tasks to live in heterogeneous input spaces. This is especially useful for tabular-data tasks where labeled data from related tasks are scarce. DEN uses a three-block architecture: a covariate transformation block followed by a distribution embedding block and then a classification block. We provide theoretical insights to show that this architecture allows the embedding and classification blocks to be fixed after pre-training on a diverse set of tasks; only the covariate transformation block with relatively few parameters needs to be fine-tuned for each new task. To facilitate training, we also propose an approach to synthesize binary classification tasks, and demonstrate that DEN outperforms existing methods in a number of synthetic and real tasks in numerical studies",
    "checked": true,
    "id": "6cfcf483bf9468f800cb3fba854f39a60b4fae35",
    "semantic_title": "distribution embedding networks for generalization from a diverse set of classification tasks",
    "citation_count": 5,
    "authors": [
      "Lang Liu",
      "Mahdi Milani Fard",
      "Sen Zhao"
    ]
  },
  "https://openreview.net/forum?id=NXB0rEM2Tq": {
    "title": "COIN++: Neural Compression Across Modalities",
    "volume": "main",
    "abstract": "Neural compression algorithms are typically based on autoencoders that require specialized encoder and decoder architectures for different data modalities. In this paper, we propose COIN++, a neural compression framework that seamlessly handles a wide range of data modalities. Our approach is based on converting data to implicit neural representations, i.e. neural functions that map coordinates (such as pixel locations) to features (such as RGB values). Then, instead of storing the weights of the implicit neural representation directly, we store modulations applied to a meta-learned base network as a compressed code for the data. We further quantize and entropy code these modulations, leading to large compression gains while reducing encoding time by two orders of magnitude compared to baselines. We empirically demonstrate the feasibility of our method by compressing various data modalities, from images and audio to medical and climate data",
    "checked": true,
    "id": "4664d3b1050c246ed0a723f5b9f2afb78c865f1a",
    "semantic_title": "coin++: neural compression across modalities",
    "citation_count": 90,
    "authors": [
      "Emilien Dupont",
      "Hrushikesh Loya",
      "Milad Alizadeh",
      "Adam Golinski",
      "Yee Whye Teh",
      "Arnaud Doucet"
    ]
  },
  "https://openreview.net/forum?id=FTtFAg3pek": {
    "title": "Systematically and efficiently improving $k$-means initialization by pairwise-nearest-neighbor smoothing",
    "volume": "main",
    "abstract": "We present a meta-method for initializing (seeding) the $k$-means clustering algorithm called PNN-smoothing. It consists in splitting a given dataset into $J$ random subsets, clustering each of them individually, and merging the resulting clusterings with the pairwise-nearest-neighbor (PNN) method. It is a meta-method in the sense that when clustering the individual subsets any seeding algorithm can be used. If the computational complexity of that seeding algorithm is linear in the size of the data $N$ and the number of clusters $k$, PNN-smoothing is also almost linear with an appropriate choice of $J$, and quite competitive in practice. We show empirically, using several existing seeding methods and testing on several synthetic and real datasets, that this procedure results in systematically better costs. In particular, our method of enhancing $k$-means++ seeding proves superior in both effectiveness and speed compared to the popular ``greedy'' $k$-means++ variant. Our implementation is publicly available at \\href{https://github.com/carlobaldassi/KMeansPNNSmoothing.jl}{https://github.com/carlobaldassi/KMeansPNNSmoothing.jl}",
    "checked": false,
    "id": "7d03f6867d4e087eedafef2332ec24d6adfce334",
    "semantic_title": "systematically and efficiently improving k-means initialization by pairwise-nearest-neighbor smoothing",
    "citation_count": 0,
    "authors": [
      "Carlo Baldassi"
    ]
  },
  "https://openreview.net/forum?id=tbd9f3HwPy": {
    "title": "GhostSR: Learning Ghost Features for Efficient Image Super-Resolution",
    "volume": "main",
    "abstract": "Modern single image super-resolution (SISR) systems based on convolutional neural networks (CNNs) have achieved impressive performance but require huge computational costs. The problem on feature redundancy has been well studied in visual recognition task, but rarely discussed in SISR. Based on the observation that many features in SISR models are also similar to each other, we propose to use shift operation for generating the redundant features (i.e. ghost features). Compared with depth-wise convolution which is time-consuming on GPU-like devices, shift operation can bring a real inference acceleration for CNNs on common hardware. We analyze the benefits of shift operation in SISR and make the shift orientation learnable based on the Gumbel-Softmax trick. Besides, a clustering procedure is explored based on pre-trained models to identify the intrinsic filters for generating corresponding intrinsic features. The ghost features will be generated by moving these intrinsic features along a certain orientation. Finally, the complete output features are constructed by concatenating the intrinsic and ghost features together. Extensive experiments on several benchmark models and datasets demonstrate that both the non-compact and lightweight SISR CNN models embedded with the proposed method can achieve a comparable performance to the baseline models with a large reduction of parameters, FLOPs and GPU inference latency. For example, we reduce the parameters by 46%, FLOPs by 46% and GPU inference latency by 42% of x2 EDSR model with almost lossless performance. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/GhostSR",
    "checked": true,
    "id": "95042006075799ce0f7734e80584f9974b621c57",
    "semantic_title": "ghostsr: learning ghost features for efficient image super-resolution",
    "citation_count": 24,
    "authors": [
      "Ying Nie",
      "Kai Han",
      "Zhenhua Liu",
      "Chuanjian Liu",
      "Yunhe Wang"
    ]
  },
  "https://openreview.net/forum?id=ygoNPRiLxw": {
    "title": "DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents",
    "volume": "main",
    "abstract": "Diffusion probabilistic models have been shown to generate state-of-the-art results on several competitive image synthesis benchmarks but lack a low-dimensional, interpretable latent space, and are slow at generation. On the other hand, standard Variational Autoencoders (VAEs) typically have access to a low-dimensional latent space but exhibit poor sample quality. We present DiffuseVAE, a novel generative framework that integrates VAE within a diffusion model framework, and leverage this to design novel conditional parameterizations for diffusion models. We show that the resulting model equips diffusion models with a low-dimensional VAE inferred latent code which can be used for downstream tasks like controllable synthesis. The proposed method also improves upon the speed vs quality tradeoff exhibited in standard unconditional DDPM/DDIM models (for instance, \\textbf{FID of 16.47 vs 34.36} using a standard DDIM on the CelebA-HQ-128 benchmark using \\textbf{T=10} reverse process steps) without having explicitly trained for such an objective. Furthermore, the proposed model exhibits synthesis quality comparable to state-of-the-art models on standard image synthesis benchmarks like CIFAR-10 and CelebA-64 while outperforming most existing VAE-based methods. Lastly, we show that the proposed method exhibits inherent generalization to different types of noise in the conditioning signal. For reproducibility, our source code is publicly available at \\url{https://github.com/kpandey008/DiffuseVAE}",
    "checked": true,
    "id": "ce8e3fa6fa6d45b8b92169a2e181dafb20749a2f",
    "semantic_title": "diffusevae: efficient, controllable and high-fidelity generation from low-dimensional latents",
    "citation_count": 121,
    "authors": [
      "Kushagra Pandey",
      "Avideep Mukherjee",
      "Piyush Rai",
      "Abhishek Kumar"
    ]
  },
  "https://openreview.net/forum?id=9tl6zjLYVS": {
    "title": "On the Origins of the Block Structure Phenomenon in Neural Network Representations",
    "volume": "main",
    "abstract": "Recent work by Nguyen et al. (2021) has uncovered a striking phenomenon in large-capacity neural networks: they contain blocks of contiguous hidden layers with highly similar representations. This block structure has two seemingly contradictory properties: on the one hand, its constituent layers exhibit highly similar dominant first principal components (PCs), but on the other hand, their representations, and their common first PC, are highly dissimilar across different random seeds. Our work seeks to reconcile these discrepant properties by investigating the origin of the block structure in relation to the data and training methods. By analyzing properties of the dominant PCs, we find that the block structure arises from dominant datapoints ‚Äî a small group of examples that share similar image statistics (e.g. background color). However, the set of dominant datapoints, and the precise shared image statistic, can vary across random seeds. Thus, the block structure reflects meaningful dataset statistics, but is simultaneously unique to each model. Through studying hidden layer activations and creating synthetic datapoints, we demonstrate that these simple image statistics dominate the representational geometry of the layers inside the block structure. We explore how the phenomenon evolves through training, finding that the block structure takes shape early in training, but the underlying representations and the corresponding dominant datapoints continue to change substantially. Finally, we study the interplay between the block structure and different training mechanisms, introducing a targeted intervention to eliminate the block structure, as well as examining the effects of pre-training and Shake-Shake regularization",
    "checked": true,
    "id": "5fe4f6fbe26f94ff65290c58007185ec71669921",
    "semantic_title": "on the origins of the block structure phenomenon in neural network representations",
    "citation_count": 13,
    "authors": [
      "Thao Nguyen",
      "Maithra Raghu",
      "Simon Kornblith"
    ]
  },
  "https://openreview.net/forum?id=AZIfC91hjM": {
    "title": "Interpretable Node Representation with Attribute Decoding",
    "volume": "main",
    "abstract": "Variational Graph Autoencoders (VGAEs) are powerful models for unsupervised learning of node representations from graph data. In this work, we make a systematic analysis of modeling node attributes in VGAEs and show that attribute decoding is important for node representation learning. We further propose a new learning model, interpretable NOde Representation with Attribute Decoding (NORAD). The model encodes node representations in an interpretable approach: node representations capture community structures in the graph and the relationship between communities and node attributes. We further propose a rectifying procedure to refine node representations of isolated notes, which improves the quality of the representations of these nodes. Our empirical results demonstrate the advantage of the proposed model when learning graph data in an interpretable approach",
    "checked": true,
    "id": "177492be91e39479d2ac7010f6c1b8a7b85162f5",
    "semantic_title": "interpretable node representation with attribute decoding",
    "citation_count": 4,
    "authors": [
      "Xiaohui Chen",
      "Xi Chen",
      "Liping Liu"
    ]
  },
  "https://openreview.net/forum?id=yeT9cBq8Cn": {
    "title": "A Unified Domain Adaptation Framework with Distinctive Divergence Analysis",
    "volume": "main",
    "abstract": "Unsupervised domain adaptation enables knowledge transfer from a labeled source domain to an unlabeled target domain by aligning the learnt features of both domains. The idea is theoretically supported by the generalization bound analysis in Ben-David et al. (2007), which specifies the applicable task (binary classification) and designates a specific distribution divergence measure. Although most distribution-aligning domain adaptation models seek theoretical grounds from this particular bound analysis, they do not actually fit into the stringent conditions. In this paper, we bridge the long-standing theoretical gap in literature by providing a unified generalization bound. Our analysis can well accommodate the classification/regression tasks and most commonly-used divergence measures, and more importantly, it can theoretically recover a large amount of previous models. In addition, we identify the key difference in the distribution divergence measures underlying the diverse models and commit a comprehensive in-depth comparison of the commonly-used divergence measures. Based on the unified generalization bound, we propose new domain adaptation models that achieve transferability through domain-invariant representations and conduct experiments on real-world datasets that corroborate our theoretical findings. We believe these insights are helpful in guiding the future design of distribution-aligning domain adaptation algorithms",
    "checked": true,
    "id": "a97e222f208fd9fda55c57a046d1837610a7dd20",
    "semantic_title": "a unified domain adaptation framework with distinctive divergence analysis",
    "citation_count": 3,
    "authors": [
      "Zhiri YUAN",
      "Xixu HU",
      "Qi WU",
      "Shumin MA",
      "Cheuk Hang LEUNG",
      "Xin Shen",
      "Yiyan HUANG"
    ]
  },
  "https://openreview.net/forum?id=A5tIluhDW6": {
    "title": "Infinitely wide limits for deep Stable neural networks: sub-linear, linear and super-linear activation functions",
    "volume": "main",
    "abstract": "There is a growing literature on the study of large-width properties of deep Gaussian neural networks (NNs), i.e. deep NNs with Gaussian-distributed parameters or weights, and Gaussian stochastic processes. Motivated by some empirical and theoretical studies showing the potential of replacing Gaussian distributions with Stable distributions, namely distributions with heavy tails, in this paper we investigate large-width properties of deep Stable NNs, i.e. deep NNs with Stable-distributed parameters. For sub-linear activation functions, a recent work has characterized the infinitely wide limit of a suitable rescaled deep Stable NN in terms of a Stable stochastic process, both under the assumption of a ``joint growth\" and under the assumption of a ``sequential growth\" of the width over the NN's layers. Here, assuming a ``sequential growth\" of the width, we extend such a characterization to a general class of activation functions, which includes sub-linear, asymptotically linear and super-linear functions. As a novelty with respect to previous works, our results rely on the use of a generalized central limit theorem for heavy tails distributions, which allows for an interesting unified treatment of infinitely wide limits for deep Stable NNs. Our study shows that the scaling of Stable NNs and the stability of their infinitely wide limits may depend on the choice of the activation function, bringing out a critical difference with respect to the Gaussian setting",
    "checked": false,
    "id": "4b27c00b279ff90b7072342c065218915438714a",
    "semantic_title": "large-width asymptotics for relu neural networks with $\\alpha$-stable initializations",
    "citation_count": 2,
    "authors": [
      "Alberto Bordino",
      "Stefano Favaro",
      "Sandra Fortini"
    ]
  },
  "https://openreview.net/forum?id=iGREAJdULX": {
    "title": "Counterfactual Learning with Multioutput Deep Kernels",
    "volume": "main",
    "abstract": "In this paper, we address the challenge of performing counterfactual inference with observational data via Bayesian nonparametric regression adjustment, with a focus on high-dimensional settings featuring multiple actions and multiple correlated outcomes. We present a general class of counterfactual multi-task deep kernels models that estimate causal effects and learn policies proficiently thanks to their sample efficiency gains, while scaling well with high dimensions. In the first part of the work, we rely on Structural Causal Models (SCM) to formally introduce the setup and the problem of identifying counterfactual quantities under observed confounding. We then discuss the benefits of tackling the task of causal effects estimation via stacked coregionalized Gaussian Processes and Deep Kernels. Finally, we demonstrate the use of the proposed methods on simulated experiments that span individual causal effects estimation, off-policy evaluation and optimization",
    "checked": true,
    "id": "c5a6b1f0e4317afa89b070609810dafa01ae05de",
    "semantic_title": "counterfactual learning with multioutput deep kernels",
    "citation_count": 1,
    "authors": [
      "Alberto Caron",
      "Ioanna Manolopoulou",
      "Gianluca Baio"
    ]
  },
  "https://openreview.net/forum?id=gzu4ZbBY7S": {
    "title": "Incorporating Sum Constraints into Multitask Gaussian Processes",
    "volume": "main",
    "abstract": "Machine learning models can be improved by adapting them to respect existing background knowledge. In this paper we consider multitask Gaussian processes, with background knowledge in the form of constraints that require a specific sum of the outputs to be constant. This is achieved by conditioning the prior distribution on the constraint fulfillment. The approach allows for both linear and nonlinear constraints. We demonstrate that the constraints are fulfilled with high precision and that the construction can improve the overall prediction accuracy as compared to the standard Gaussian process",
    "checked": true,
    "id": "876ddef3ba445f7c66918fa30a79e7ca01786f77",
    "semantic_title": "incorporating sum constraints into multitask gaussian processes",
    "citation_count": 3,
    "authors": [
      "Philipp Pilar",
      "Carl Jidling",
      "Thomas B. Sch√∂n",
      "Niklas Wahlstr√∂m"
    ]
  },
  "https://openreview.net/forum?id=P0XO5ZE98j": {
    "title": "Degradation Attacks on Certifiably Robust Neural Networks",
    "volume": "main",
    "abstract": "Certifiably robust neural networks protect against adversarial examples by employing run-time defenses that check if the model is certifiably locally robust at the input under evaluation. We show through examples and experiments that any defense (whether complete or incomplete) based on checking local robustness is inherently over-cautious. Specifically, such defenses flag inputs for which local robustness checks fail, but yet that are not adversarial; i.e., they are classified consistently with all valid inputs within a distance of $\\epsilon$. As a result, while a norm-bounded adversary cannot change the classification of an input, it can use norm-bounded changes to degrade the utility of certifiably robust networks by forcing them to reject otherwise correctly classifiable inputs. We empirically demonstrate the efficacy of such attacks against state-of-the-art certifiable defenses. Our code is available at https://github.com/ravimangal/degradation-attacks",
    "checked": true,
    "id": "4acf1bd971b093ddfb323b70f604a1def5d02d48",
    "semantic_title": "degradation attacks on certifiably robust neural networks",
    "citation_count": 2,
    "authors": [
      "Klas Leino",
      "Chi Zhang",
      "Ravi Mangal",
      "Matt Fredrikson",
      "Bryan Parno",
      "Corina Pasareanu"
    ]
  },
  "https://openreview.net/forum?id=VW4IrC0n0M": {
    "title": "An approximate sampler for energy-based models with divergence diagnostics",
    "volume": "main",
    "abstract": "Energy-based models (EBMs) allow flexible specifications of probability distributions. However, sampling from EBMs is non-trivial, usually requiring approximate techniques such as Markov chain Monte Carlo (MCMC). A major downside of MCMC sampling is that it is often impossible to compute the divergence of the sampling distribution from the target distribution: therefore, the quality of the samples cannot be guaranteed. Here, we introduce quasi-rejection sampling (QRS), a simple extension of rejection sampling that performs approximate sampling, but, crucially, does provide divergence diagnostics (in terms of f-divergences, such as KL divergence and total variation distance). We apply QRS to sampling from discrete EBMs over text for controlled generation. We show that we can sample from such EBMs with arbitrary precision in exchange for sampling efficiency and quantify the trade-off between the two by means of the aforementioned diagnostics",
    "checked": true,
    "id": "ab23ff73e450f6b7e8d639e68320c7952c003694",
    "semantic_title": "an approximate sampler for energy-based models with divergence diagnostics",
    "citation_count": 9,
    "authors": [
      "Bryan Eikema",
      "Germ√°n Kruszewski",
      "Christopher R Dance",
      "Hady Elsahar",
      "Marc Dymetman"
    ]
  },
  "https://openreview.net/forum?id=aRtjVZvbpK": {
    "title": "A Unified Survey on Anomaly, Novelty, Open-Set, and Out of-Distribution Detection: Solutions and Future Challenges",
    "volume": "main",
    "abstract": "Machine learning models often encounter samples that are diverged from the training distribution. Failure to recognize an out-of-distribution (OOD) sample, and consequently assign that sample to an in-class label, significantly compromises the reliability of a model. The problem has gained significant attention due to its importance for safety deploying models in open-world settings. Detecting OOD samples is challenging due to the intractability of modeling all possible unknown distributions. To date, several research domains tackle the problem of detecting unfamiliar samples, including anomaly detection, novelty detection, one-class learning, open set recognition, and out-of-distribution detection. Despite having similar and shared concepts, out-of-distribution, open-set, and anomaly detection have been investigated independently. Accordingly, these research avenues have not crosspollinated, creating research barriers. While some surveys intend to provide an overview of these approaches, they seem to only focus on a specific domain without examining the relationship between different domains. This survey aims to provide a cross-domain and comprehensive review of numerous eminent works in respective areas while identifying their commonalities. Researchers can benefit from the overview of research advances in different fields and develop future methodology synergistically. Furthermore, to the best of our knowledge, while there are surveys in anomaly detection or one-class learning, there is no comprehensive or up-to-date survey on out-of-distribution detection, which this survey covers extensively. Finally, having a unified cross-domain perspective, this study discusses and sheds light on future lines of research, intending to bring these fields closer together",
    "checked": false,
    "id": "8b153cc2c7f5ea9f307f12ea945a5e9196ee5c52",
    "semantic_title": "a unified survey on anomaly, novelty, open-set, and out-of-distribution detection: solutions and future challenges",
    "citation_count": 199,
    "authors": [
      "Mohammadreza Salehi",
      "Hossein Mirzaei",
      "Dan Hendrycks",
      "Yixuan Li",
      "Mohammad Hossein Rohban",
      "Mohammad Sabokrou"
    ]
  },
  "https://openreview.net/forum?id=oRjk5V9eDp": {
    "title": "Bayesian Methods for Constraint Inference in Reinforcement Learning",
    "volume": "main",
    "abstract": "Learning constraints from demonstrations provides a natural and efficient way to improve the safety of AI systems; however, prior work only considers learning a single, point-estimate of the constraints. By contrast, we consider the problem of inferring constraints from demonstrations using a Bayesian perspective. We propose Bayesian Inverse Constraint Reinforcement Learning (BICRL), a novel approach that infers a posterior probability distribution over constraints from demonstrated trajectories. The main advantages of BICRL, compared to prior constraint inference algorithms, are (1) the freedom to infer constraints from partial trajectories and even from disjoint state-action pairs, (2) the ability to infer constraints from suboptimal demonstrations and in stochastic environments, and (3) the opportunity to use the posterior distribution over constraints in order to implement active learning and robust policy optimization techniques. We show that BICRL outperforms pre-existing constraint learning approaches, leading to more accurate constraint inference and consequently safer policies. We further propose Hierarchical BICRL that infers constraints locally in sub-spaces of the entire domain and then composes global constraint estimates leading to accurate and computationally efficient constraint estimation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dimitris Papadimitriou",
      "Usman Anwar",
      "Daniel S. Brown"
    ]
  },
  "https://openreview.net/forum?id=LHAbHkt6Aq": {
    "title": "A Crisis In Simulation-Based Inference? Beware, Your Posterior Approximations Can Be Unfaithful",
    "volume": "main",
    "abstract": "We present extensive empirical evidence showing that current Bayesian simulation-based inference algorithms can produce computationally unfaithful posterior approximations. Our results show that all benchmarked algorithms -- (S)NPE, (S)NRE, SNL and variants of ABC -- can yield overconfident posterior approximations, which makes them unreliable for scientific use cases and falsificationist inquiry. Failing to address this issue may reduce the range of applicability of simulation-based inference. For this reason, we argue that research efforts should be made towards theoretical and methodological developments of conservative approximate inference algorithms and present research directions towards this objective. In this regard, we show empirical evidence that ensembling posterior surrogates provides more reliable approximations and mitigates the issue",
    "checked": true,
    "id": "d386cb044775dfb6f7f6fccbbaa3952b69a3066e",
    "semantic_title": "a crisis in simulation-based inference? beware, your posterior approximations can be unfaithful",
    "citation_count": 25,
    "authors": [
      "Joeri Hermans",
      "Arnaud Delaunoy",
      "Fran√ßois Rozet",
      "Antoine Wehenkel",
      "Volodimir Begy",
      "Gilles Louppe"
    ]
  },
  "https://openreview.net/forum?id=tLG26QxoD8": {
    "title": "On Pseudo-Labeling for Class-Mismatch Semi-Supervised Learning",
    "volume": "main",
    "abstract": "When there are unlabeled Out-Of-Distribution (OOD) data from other classes, Semi-Supervised Learning (SSL) methods suffer from severe performance degradation and even get worse than merely training on labeled data. In this paper, we empirically analyze Pseudo-Labeling (PL) in class-mismatched SSL. PL is a simple and representative SSL method that transforms SSL problems into supervised learning by creating pseudo-labels for unlabeled data according to the model's prediction. We aim to answer two main questions: (1) How do OOD data influence PL? (2) What is the proper usage of OOD data with PL? First, we show that the major problem of PL is imbalanced pseudo-labels on OOD data. Second, we find that OOD data can help classify In-Distribution (ID) data given their OOD ground truth labels. Based on the findings, we propose to improve PL in class-mismatched SSL with two components -- Re-balanced Pseudo-Labeling (RPL) and Semantic Exploration Clustering (SEC). RPL re-balances pseudo-labels of high-confidence data, which simultaneously filters out OOD data and addresses the imbalance problem. SEC uses balanced clustering on low-confidence data to create pseudo-labels on extra classes, simulating the process of training with ground truth. Experiments show that our method achieves steady improvement over supervised baseline and state-of-the-art performance under all class mismatch ratios on different benchmarks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lu Han",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ]
  },
  "https://openreview.net/forum?id=bN2vWLTh0P": {
    "title": "Reinventing Policy Iteration under Time Inconsistency",
    "volume": "main",
    "abstract": "Policy iteration (PI) is a fundamental policy search algorithm in standard reinforcement learning (RL) setting, which can be shown to converge to an optimal policy by policy improvement theorems. However, the standard PI relies on Bellman's Principle of Optimality, which might be violated by some specifications of objectives (also known as time-inconsistent (TIC) objectives), such as non-exponentially discounted reward functions. The use of standard PI under TIC objectives has thus been marked with questions regarding the convergence of its policy improvement scheme and the optimality of its termination policy, often leading to its avoidance. In this paper, we consider an infinite-horizon TIC RL setting and formally present an alternative type of optimality drawn from game theory, i.e., subgame perfect equilibrium (SPE), that attempts to resolve the aforementioned questions. We first analyze standard PI under the SPE type of optimality, revealing its merits and insufficiencies. Drawing on these observations, we propose backward Q-learning (bwdQ), a new algorithm in the approximate PI family that targets SPE policy under non-exponentially discounted reward functions. Finally, with two TIC gridworld environments, we demonstrate the implications of our theoretical findings on the behavior of bwdQ and other approximate PI variants",
    "checked": true,
    "id": "1491714962b285fab35e041ebfd861e483b761e3",
    "semantic_title": "reinventing policy iteration under time inconsistency",
    "citation_count": 4,
    "authors": [
      "Nixie S Lesmana",
      "Huangyuan Su",
      "Chi Seng Pun"
    ]
  },
  "https://openreview.net/forum?id=YiOI0vqJ0n": {
    "title": "Nonparametric Learning of Two-Layer ReLU Residual Units",
    "volume": "main",
    "abstract": "We describe an algorithm that learns two-layer residual units using rectified linear unit (ReLU) activation: suppose the input $\\mathbf{x}$ is from a distribution with support space $\\mathbb{R}^d$ and the ground-truth generative model is a residual unit of this type, given by $\\mathbf{y} = \\boldsymbol{B}^\\ast\\left[\\left(\\boldsymbol{A}^\\ast\\mathbf{x}\\right)^+ + \\mathbf{x}\\right]$, where ground-truth network parameters $\\boldsymbol{A}^\\ast \\in \\mathbb{R}^{d\\times d}$ represent a full-rank matrix with nonnegative entries and $\\boldsymbol{B}^\\ast \\in \\mathbb{R}^{m\\times d}$ is full-rank with $m \\geq d$ and for $\\boldsymbol{c} \\in \\mathbb{R}^d$, $[\\boldsymbol{c}^{+}]_i = \\max\\{0, c_i\\}$. We design layer-wise objectives as functionals whose analytic minimizers express the exact ground-truth network in terms of its parameters and nonlinearities. Following this objective landscape, learning residual units from finite samples can be formulated using convex optimization of a nonparametric function: for each layer, we first formulate the corresponding empirical risk minimization (ERM) as a positive semi-definite quadratic program (QP), then we show the solution space of the QP can be equivalently determined by a set of linear inequalities, which can then be efficiently solved by linear programming (LP). We further prove the strong statistical consistency of our algorithm, and demonstrate its robustness and sample efficiency through experimental results on synthetic data and a set of benchmark regression datasets",
    "checked": true,
    "id": "0f6f91b57e5e4e957fd175e55471c84232fdbda9",
    "semantic_title": "nonparametric learning of two-layer relu residual units",
    "citation_count": 1,
    "authors": [
      "Zhunxuan Wang",
      "Linyun He",
      "Chunchuan Lyu",
      "Shay B Cohen"
    ]
  },
  "https://openreview.net/forum?id=uvDD9rN6Zz": {
    "title": "Stochastic Douglas-Rachford Splitting for Regularized Empirical Risk Minimization: Convergence, Mini-batch, and Implementation",
    "volume": "main",
    "abstract": "In this paper, we study the stochastic Douglas-Rachford splitting (SDRS) for general empirical risk minimization (ERM) problems with regularization. Our first contribution is to prove its convergence for both convex and strongly convex problems; the convergence rates are $O(1/\\sqrt{t})$ and $O(1/t)$, respectively. Since SDRS reduces to the stochastic proximal point algorithm (SPPA) when there is no regularization, it is pleasing to see the result matches that of SPPA, under the same mild conditions. We also propose the mini-batch version of SDRS that handles multiple samples simultaneously while maintaining the same efficiency as that of a single one, which is not a straight-forward extension in the context of stochastic proximal algorithms. We show that the mini-batch SDRS again enjoys the same convergence rate. Furthermore, we demonstrate that, for some of the canonical regularized ERM problems, each iteration of SDRS can be efficiently calculated either in closed form or in close to closed form via bisection---the resulting complexity is identical to, for example, the stochastic (sub)gradient method. Experiments on real data demonstrate its effectiveness in terms of convergence compared to SGD and its variants",
    "checked": true,
    "id": "1bbda32a7549d84237d4ba9fd55920f150de5f72",
    "semantic_title": "stochastic douglas-rachford splitting for regularized empirical risk minimization: convergence, mini-batch, and implementation",
    "citation_count": 0,
    "authors": [
      "Aysegul Bumin",
      "Kejun Huang"
    ]
  },
  "https://openreview.net/forum?id=9nhmKwLAWV": {
    "title": "Does Entity Abstraction Help Generative Transformers Reason?",
    "volume": "main",
    "abstract": "We study the utility of incorporating entity type abstractions into pre-trained Transformers and test these methods on four NLP tasks requiring different forms of logical reasoning: (1) compositional language understanding with text-based relational reasoning (CLUTRR), (2) abductive reasoning (ProofWriter), (3) multi-hop question answering (HotpotQA), and (4) conversational question answering (CoQA). We propose and empirically explore three ways to add such abstraction: (i) as additional input embeddings, (ii) as a separate sequence to encode, and (iii) as an auxiliary prediction task for the model. Overall, our analysis demonstrates that models with abstract entity knowledge performs better than without it. The best abstraction aware models achieved an overall accuracy of 88.8% and 91.8% compared to the baseline model achieving 62.9% and 89.8% on CLUTRR and ProofWriter respectively. However, for HotpotQA and CoQA, we find that F1 scores improve by only 0.5% on average. Our results suggest that the benefit of explicit abstraction is significant in formally defined logical reasoning settings requiring many reasoning hops, but point to the notion that it is less beneficial for NLP tasks having less formal logical structure",
    "checked": true,
    "id": "a85c6a003450ef1e6caed8a6494301ad581957ee",
    "semantic_title": "does entity abstraction help generative transformers reason?",
    "citation_count": 5,
    "authors": [
      "Nicolas Gontier",
      "Siva Reddy",
      "Christopher Pal"
    ]
  },
  "https://openreview.net/forum?id=1PfcmFTXoa": {
    "title": "Complex-Valued Autoencoders for Object Discovery",
    "volume": "main",
    "abstract": "Object-centric representations form the basis of human perception, and enable us to reason about the world and to systematically generalize to new settings. Currently, most works on unsupervised object discovery focus on slot-based approaches, which explicitly separate the latent representations of individual objects. While the result is easily interpretable, it usually requires the design of involved architectures. In contrast to this, we propose a comparatively simple approach ‚Äì the Complex AutoEncoder (CAE) ‚Äì that creates distributed object-centric representations. Following a coding scheme theorized to underlie object representations in biological neurons, its complex-valued activations represent two messages: their magnitudes express the presence of a feature, while the relative phase differences between neurons express which features should be bound together to create joint object representations. In contrast to previous approaches using complex-valued activations for object discovery, we present a fully unsupervised approach that is trained end-to-end ‚Äì resulting in significant improvements in performance and efficiency. Further, we show that the CAE achieves competitive or better unsupervised object discovery performance on simple multi-object datasets compared to a state-of-the-art slot-based approach while being up to 100 times faster to train",
    "checked": true,
    "id": "0bc95645df1845050e642b34dc7593ba9a16072f",
    "semantic_title": "complex-valued autoencoders for object discovery",
    "citation_count": 39,
    "authors": [
      "Sindy L√∂we",
      "Phillip Lippe",
      "Maja Rudolph",
      "Max Welling"
    ]
  },
  "https://openreview.net/forum?id=Sh3RF9JowK": {
    "title": "Learning Algorithms for Markovian Bandits:\\\\Is Posterior Sampling more Scalable than Optimism?",
    "volume": "main",
    "abstract": "In this paper, we study the scalability of model-based algorithms learning the optimal policy of a discounted \\blue{rested} Markovian bandit problem with $n$ arms. There are two categories of model-based reinforcement learning algorithms: Bayesian algorithms (like PSRL), and optimistic algorithms (like UCRL2 or UCBVI). A naive application of these algorithms is not scalable because the state-space is exponential in $n$. In this paper, we construct variants of these algorithms specially tailored to Markovian bandits (MB) that we call MB-PSRL, MB-UCRL2, and MB-UCBVI. \\blue{We consider an episodic setting with geometrically distributed episode length, and measure the performance of the algorithm in terms of regret (Bayesian regret for MB-PSRL and expected regret for MB-UCRL2 and MB-UCBVI)}. We prove that, for this setting, all algorithms have a low regret in $\\tilde{O}(S\\sqrt{nK})$ -- where $K$ is the number of episodes, $n$ is the number of arms and $S$ is the number of states of each arm. Up to a factor $\\sqrt{S}$, these regrets match the \\blue{Bayesian minimax regret} lower bound of $\\Omega(\\sqrt{SnK})$ that we also derive. Even if their theoretical regrets are comparable, the {\\it time complexities} of these algorithms vary greatly: We show that MB-UCRL2, as well as all algorithms that use bonuses on transition matrices have a { time} complexity that grows exponentially in $n$. In contrast, MB-UCBVI does not use bonuses on transition matrices and we show that it can be implemented efficiently, with a time complexity linear in $n$. Our numerical experiments show, however, that its empirical regret is large. Our Bayesian algorithm, MB-PSRL, enjoys the best of both worlds: its running time is linear in the number of arms and its empirical regret is the smallest of all algorithms. This is a new addition in the understanding of the power of Bayesian algorithms, that can often be tailored to the structure of the problems to learn",
    "checked": false,
    "id": "e9770e1fc0f9977a0e890546f4d9062e6a934a28",
    "semantic_title": "learning algorithms for markovian bandits: is posterior sampling more scalable than optimism?",
    "citation_count": 2,
    "authors": [
      "Nicolas Gast",
      "Bruno Gaujal",
      "Kimang Khun"
    ]
  },
  "https://openreview.net/forum?id=NmTMc3uD1G": {
    "title": "Modeling Object Dissimilarity for Deep Saliency Prediction",
    "volume": "main",
    "abstract": "Saliency prediction has made great strides over the past two decades, with current techniques modeling low-level information, such as color, intensity and size contrasts, and high-level ones, such as attention and gaze direction for entire objects. Despite this, these methods fail to account for the dissimilarity between objects, which affects human visual attention. In this paper, we introduce a detection-guided saliency prediction network that explicitly models the differences between multiple objects, such as their appearance and size dissimilarities. Our approach allows us to fuse our object dissimilarities with features extracted by any deep saliency prediction network. As evidenced by our experiments, this consistently boosts the accuracy of the baseline networks, enabling us to outperform the state-of-the-art models on three saliency benchmarks, namely SALICON, MIT300 and CAT2000. Our project page is at https://github.com/IVRL/DisSal",
    "checked": true,
    "id": "5d3828cce5ccce25783aa4486637dc22985aa0f6",
    "semantic_title": "modeling object dissimilarity for deep saliency prediction",
    "citation_count": 3,
    "authors": [
      "Bahar Aydemir",
      "Deblina Bhattacharjee",
      "Tong Zhang",
      "Seungryong Kim",
      "Mathieu Salzmann",
      "Sabine S√ºsstrunk"
    ]
  },
  "https://openreview.net/forum?id=YAVE6jfeJb": {
    "title": "Optimizing Intermediate Representations of Generative Models for Phase Retrieval",
    "volume": "main",
    "abstract": "Phase retrieval is the problem of reconstructing images from magnitude-only measurements. In many real-world applications the problem is underdetermined. When training data is available, generative models allow optimization in a lower-dimensional latent space, hereby constraining the solution set to those images that can be synthesized by the generative model. However, not all possible solutions are within the range of the generator. Instead, they are represented with some error. To reduce this representation error in the context of phase retrieval, we first leverage a novel variation of intermediate layer optimization (ILO) to extend the range of the generator while still producing images consistent with the training data. Second, we introduce new initialization schemes that further improve the quality of the reconstruction. With extensive experiments on the Fourier phase retrieval problem and thorough ablation studies, we can show the benefits of our modified ILO and the new initialization schemes. Additionally, we analyze the performance of our approach on the Gaussian phase retrieval problem",
    "checked": true,
    "id": "a4f718b776b0fc8deea07b6c9df96a7628571094",
    "semantic_title": "optimizing intermediate representations of generative models for phase retrieval",
    "citation_count": 1,
    "authors": [
      "Tobias Uelwer",
      "Sebastian Konietzny",
      "Stefan Harmeling"
    ]
  },
  "https://openreview.net/forum?id=35y5hv9fbb": {
    "title": "Algorithms and Theory for Supervised Gradual Domain Adaptation",
    "volume": "main",
    "abstract": "The phenomenon of data distribution evolving over time has been observed in a range of applications, calling the needs of adaptive learning algorithms. We thus study the problem of supervised gradual domain adaptation, where labeled data from shifting distributions are available to the learner along the trajectory, and we aim to learn a classifier on a target data distribution of interest. Under this setting, we provide the first generalization upper bound on the learning error under mild assumptions. Our results are algorithm agnostic, general for a range of loss functions, and only depend linearly on the averaged learning error across the trajectory. This shows significant improvement compared to the previous upper bound for unsupervised gradual domain adaptation, where the learning error on the target domain depends exponentially on the initial error on the source domain. Compared with the offline setting of learning from multiple domains, our results also suggest the potential benefits of the temporal structure among different domains in adapting to the target one. Empirically, our theoretical results imply that learning proper representations across the domains will effectively mitigate the learning errors. Motivated by these theoretical insights, we propose a min-max learning objective to learn the representation and classifier simultaneously. Experimental results on both semi-synthetic and large-scale real datasets corroborate our findings and demonstrate the effectiveness of our objectives",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Dong",
      "Shiji Zhou",
      "Baoxiang Wang",
      "Han Zhao"
    ]
  },
  "https://openreview.net/forum?id=ph3AYXpwEb": {
    "title": "Teacher's pet: understanding and mitigating biases in distillation",
    "volume": "main",
    "abstract": "Knowledge distillation is widely used as a means of improving the performance of a relatively simple ``student'' model using the predictions from a complex ``teacher'' model. Several works have shown that distillation significantly boosts the student's \\emph{overall} performance; however, are these gains uniform across all data subgroups? In this paper, we show that distillation can \\emph{harm} performance on certain subgroups, {e.g., classes with few associated samples}, compared to the vanilla student trained using the one-hot labels. We trace this behaviour to errors made by the teacher distribution being transferred to and \\emph{amplified} by the student model, and formally prove that distillation can indeed harm underrepresented subgroups in certain regression settings. To mitigate this problem, we present techniques which soften the teacher influence for subgroups where it is less reliable. Experiments on several image classification benchmarks show that these modifications of distillation maintain boost in overall accuracy, while additionally ensuring improvement in subgroup performance",
    "checked": true,
    "id": "b057d01576177dcf055dcc3601471b68190658f6",
    "semantic_title": "teacher's pet: understanding and mitigating biases in distillation",
    "citation_count": 25,
    "authors": [
      "Michal Lukasik",
      "Srinadh Bhojanapalli",
      "Aditya Krishna Menon",
      "Sanjiv Kumar"
    ]
  },
  "https://openreview.net/forum?id=LFkRUCalFt": {
    "title": "An Efficient One-Class SVM for Novelty Detection in IoT",
    "volume": "main",
    "abstract": "One-Class Support Vector Machines (OCSVM) are a common approach for novelty detection, due to their flexibility in fitting complex nonlinear boundaries between {normal} and {novel} data. Novelty detection is important in the Internet of Things (``IoT'') due to the threats these devices can present, and OCSVM often performs well in these environments due to the variety of devices, traffic patterns, and anomalies that IoT devices present. Unfortunately, conventional OCSVMs can introduce prohibitive memory and computational overhead at detection time. This work designs, implements and evaluates an efficient OCSVM for such practical settings. We extend Nystr\\\"om and (Gaussian) Sketching approaches to OCSVM, combining these methods with clustering and Gaussian mixture models to achieve 15-30x speedup in prediction time and 30-40x reduction in memory requirements without sacrificing detection accuracy. Here, the very nature of IoT devices is crucial: they tend to admit few modes of \\emph{normal} operation, allowing for efficient pattern compression",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Yang",
      "Samory Kpotufe",
      "Nick Feamster"
    ]
  },
  "https://openreview.net/forum?id=63sJsCmq6Q": {
    "title": "Competition over data: how does data purchase affect users?",
    "volume": "main",
    "abstract": "As the competition among machine learning (ML) predictors is widespread in practice, it becomes increasingly important to understand the impact and biases arising from such competition. One critical aspect of ML competition is that ML predictors are constantly updated by acquiring additional data during the competition. Although this active data acquisition can largely affect the overall competition environment, it has not been well-studied before. In this paper, we study what happens when ML predictors can purchase additional data during the competition. We introduce a new environment in which ML predictors use active learning algorithms to effectively acquire labeled data within their budgets while competing against each other. We empirically show that the overall performance of an ML predictor improves when predictors can purchase additional labeled data. Surprisingly, however, the quality that users experience---i.e., the accuracy of the predictor selected by each user---can decrease even as the individual predictors get better. We demonstrate that this phenomenon naturally arises due to a trade-off whereby competition pushes each predictor to specialize in a subset of the population while data purchase has the effect of making predictors more uniform. With comprehensive experiments, we show that our findings are robust against different modeling assumptions",
    "checked": true,
    "id": "a993c8842917c1d0e661fc368a3c3a690167772a",
    "semantic_title": "competition over data: how does data purchase affect users?",
    "citation_count": 5,
    "authors": [
      "Yongchan Kwon",
      "Tony A Ginart",
      "James Zou"
    ]
  },
  "https://openreview.net/forum?id=lf0lr4AYM6": {
    "title": "Diffusion Models for Video Prediction and Infilling",
    "volume": "main",
    "abstract": "Predicting and anticipating future outcomes or reasoning about missing information in a sequence are critical skills for agents to be able to make intelligent decisions. This requires strong, temporally coherent generative capabilities. Diffusion models have shown remarkable success in several generative tasks, but have not been extensively explored in the video domain. We present Random-Mask Video Diffusion (RaMViD), which extends image diffusion models to videos using 3D convolutions, and introduces a new conditioning technique during training. By varying the mask we condition on, the model is able to perform video prediction, infilling, and upsampling. Due to our simple conditioning scheme, we can utilize the same architecture as used for unconditional training, which allows us to train the model in a conditional and unconditional fashion at the same time. We evaluate RaMViD on two benchmark datasets for video prediction, on which we achieve state-of-the-art results, and one for video generation. High-resolution videos are provided at https://sites.google.com/view/video-diffusion-prediction",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tobias H√∂ppe",
      "Arash Mehrjou",
      "Stefan Bauer",
      "Didrik Nielsen",
      "Andrea Dittadi"
    ]
  },
  "https://openreview.net/forum?id=Au1LNKmRvh": {
    "title": "Efficient Gradient Flows in Sliced-Wasserstein Space",
    "volume": "main",
    "abstract": "Minimizing functionals in the space of probability distributions can be done with Wasser- stein gradient flows. To solve them numerically, a possible approach is to rely on the Jordan‚ÄìKinderlehrer‚ÄìOtto (JKO) scheme which is analogous to the proximal scheme in Euclidean spaces. However, it requires solving a nested optimization problem at each it- eration, and is known for its computational challenges, especially in high dimension. To alleviate it, very recent works propose to approximate the JKO scheme leveraging Brenier's theorem, and using gradients of Input Convex Neural Networks to parameterize the density (JKO-ICNN). However, this method comes with a high computational cost and stability is- sues. Instead, this work proposes to use gradient flows in the space of probability measures endowed with the sliced-Wasserstein (SW) distance. We argue that this method is more flex- ible than JKO-ICNN, since SW enjoys a closed-form differentiable approximation. Thus, the density at each step can be parameterized by any generative model which alleviates the computational burden and makes it tractable in higher dimensions",
    "checked": true,
    "id": "bd278f7f557857f3938b3f722a52aec2c799d36e",
    "semantic_title": "efficient gradient flows in sliced-wasserstein space",
    "citation_count": 21,
    "authors": [
      "Cl√©ment Bonet",
      "Nicolas Courty",
      "Fran√ßois Septier",
      "Lucas Drumetz"
    ]
  },
  "https://openreview.net/forum?id=Ii7UeHc0mO": {
    "title": "Approximate Policy Iteration with Bisimulation Metrics",
    "volume": "main",
    "abstract": "Bisimulation metrics define a distance measure between states of a Markov decision process (MDP) based on a comparison of reward sequences. Due to this property they provide theoretical guarantees in value function approximation (VFA). In this work we first prove that bisimulation and $\\pi$-bisimulation metrics can be defined via a more general class of Sinkhorn distances, which unifies various state similarity metrics used in recent work. Then we describe an approximate policy iteration (API) procedure that uses a bisimulation-based discretization of the state space for VFA and prove asymptotic performance bounds. Next, we bound the difference between $\\pi$-bisimulation metrics in terms of the change in the policies themselves. Based on these results, we design an API($\\alpha$) procedure that employs conservative policy updates and enjoys better performance bounds than the naive API approach. We discuss how such API procedures map onto practical actor-critic methods that use bisimulation metrics for state representation learning. Lastly, we validate our theoretical results and investigate their practical implications via a controlled empirical analysis based on an implementation of bisimulation-based API for finite MDPs",
    "checked": true,
    "id": "2cc36e4d0b6bf6913ce68f49a80a9c098e3039c7",
    "semantic_title": "approximate policy iteration with bisimulation metrics",
    "citation_count": 8,
    "authors": [
      "Mete Kemertas",
      "Allan Douglas Jepson"
    ]
  },
  "https://openreview.net/forum?id=3v78awEzyB": {
    "title": "Exposing Outlier Exposure: What Can Be Learned From Few, One, and Zero Outlier Images",
    "volume": "main",
    "abstract": "Due to the intractability of characterizing everything that looks unlike the normal data, anomaly detection (AD) is traditionally treated as an unsupervised problem utilizing only normal samples. However, it has recently been found that unsupervised image AD can be drastically improved through the utilization of huge corpora of random images to represent anomalousness; a technique which is known as Outlier Exposure. In this paper we show that specialized AD learning methods seem unnecessary for state-of-the-art performance, and furthermore one can achieve strong performance with just a small collection of Outlier Exposure data, contradicting common assumptions in the field of AD. We find that standard classifiers and semi-supervised one-class methods trained to discern between normal samples and relatively few random natural images are able to outperform the current state of the art on an established AD benchmark with ImageNet. Further experiments reveal that even one well-chosen outlier sample is sufficient to achieve decent performance on this benchmark (79.3% AUC). We investigate this phenomenon and find that one-class methods are more robust to the choice of training outliers, indicating that there are scenarios where these are still more useful than standard classifiers. Additionally, we include experiments that delineate the scenarios where our results hold. Lastly, no training samples are necessary when one uses the representations learned by CLIP, a recent foundation model, which achieves state-of-the-art AD results on CIFAR-10 and ImageNet in a zero-shot setting",
    "checked": true,
    "id": "5b9f294a37799a454543c4ce3d9cb40bdb2ad9a4",
    "semantic_title": "exposing outlier exposure: what can be learned from few, one, and zero outlier images",
    "citation_count": 46,
    "authors": [
      "Philipp Liznerski",
      "Lukas Ruff",
      "Robert A. Vandermeulen",
      "Billy Joe Franks",
      "Klaus Robert Muller",
      "Marius Kloft"
    ]
  },
  "https://openreview.net/forum?id=15SoThZmtU": {
    "title": "Mitigating Catastrophic Forgetting in Spiking Neural Networks through Threshold Modulation",
    "volume": "main",
    "abstract": "Artificial Neural Networks (ANNs) trained with Backpropagation and Stochastic Gradient Descent (SGD) suffer from the problem of Catastrophic Forgetting; when learning tasks sequentially, the ANN tends to abruptly forget previous knowledge upon being trained on a new task. On the other hand, biological neural networks do not suffer from this problem. Spiking Neural Networks (SNNs) are a class of Neural Networks that are closer to biological networks than ANNs and their intrinsic properties inspired from biology could alleviate the problem of Catastrophic Forgetting. In this paper, we investigate if the firing threshold mechanism of SNNs can be used to gate the activity of the network in order to reduce catastrophic forgetting. To this end, we evolve a Neuromodulatory Network that adapts the thresholds of an SNN depending on the spiking activity of the previous layer. Our experiments on different datasets show that the neurmodulated SNN can mitigate forgetting significantly with respect to a fixed threshold SNN. We also show that the evolved Neuromodulatory Network can generalize to multiple new scenarios and analyze its behavior",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ilyass Hammouamri",
      "Timoth√©e Masquelier",
      "Dennis George Wilson"
    ]
  },
  "https://openreview.net/forum?id=1AxQpKmiTc": {
    "title": "ZerO Initialization: Initializing Neural Networks with only Zeros and Ones",
    "volume": "main",
    "abstract": "Deep neural networks are usually initialized with random weights, with adequately selected initial variance to ensure stable signal propagation during training. However, selecting the appropriate variance becomes challenging especially as the number of layers grows. In this work, we replace random weight initialization with a fully deterministic initialization scheme, viz., ZerO, which initializes the weights of networks with only zeros and ones (up to a normalization factor), based on identity and Hadamard transforms. Through both theoretical and empirical studies, we demonstrate that ZerO is able to train networks without damaging their expressivity. Applying ZerO on ResNet achieves state-of-the-art performance on various datasets, including ImageNet, which suggests random weights may be unnecessary for network initialization. In addition, ZerO has many benefits, such as training ultra deep networks (without batch-normalization), exhibiting low-rank learning trajectories that result in low-rank and sparse solutions, and improving training reproducibility",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Zhao",
      "Florian Tobias Schaefer",
      "Anima Anandkumar"
    ]
  },
  "https://openreview.net/forum?id=Y4mgmw9OgV": {
    "title": "A Rigorous Study Of The Deep Taylor Decomposition",
    "volume": "main",
    "abstract": "Saliency methods attempt to explain deep neural networks by highlighting the most salient features of a sample. Some widely used methods are based on a theoretical framework called Deep Taylor Decomposition (DTD), which formalizes the recursive application of the Taylor Theorem to the network's layers. However, recent work has found these methods to be independent of the network's deeper layers and appear to respond only to lower-level image structure. Here, we investigate DTD theory to better understand this perplexing behavior and found that the Deep Taylor Decomposition is equivalent to the basic gradient$\\times$input method when the Taylor root points (an important parameter of the algorithm chosen by the user) are locally constant. If the root points are locally input-dependent, then one can justify any explanation. In this case, the theory is under-constrained. In an empirical evaluation, we find that DTD roots do not lie the same linear regions as the input -- contrary to a fundamental assumption of the Taylor Theorem. The theoretical foundations of DTD were cited as a source of reliability for the explanations. However, our findings urge caution in making such claims",
    "checked": true,
    "id": "c25159007564e22e63d4926c940de75e104b823b",
    "semantic_title": "a rigorous study of the deep taylor decomposition",
    "citation_count": 4,
    "authors": [
      "Leon Sixt",
      "Tim Landgraf"
    ]
  },
  "https://openreview.net/forum?id=e4Bb0b3QgJ": {
    "title": "Fail-Safe Adversarial Generative Imitation Learning",
    "volume": "main",
    "abstract": "For flexible yet safe imitation learning (IL), we propose theory and a modular method, with a safety layer that enables a closed-form probability density/gradient of the safe generative continuous policy, end-to-end generative adversarial training, and worst-case safety guarantees. The safety layer maps all actions into a set of safe actions, and uses the change-of-variables formula plus additivity of measures for the density. The set of safe actions is inferred by first checking safety of a finite sample of actions via adversarial reachability analysis of fallback maneuvers, and then concluding on the safety of these actions' neighborhoods using, e.g., Lipschitz continuity. We provide theoretical analysis showing the robustness advantage of using the safety layer already during training (imitation error linear in the horizon) compared to only using it at test time (up to quadratic error). In an experiment on real-world driver interaction data, we empirically demonstrate tractability, safety and imitation performance of our approach",
    "checked": true,
    "id": "1015c935649824664c206fabe546f13995d156aa",
    "semantic_title": "fail-safe adversarial generative imitation learning",
    "citation_count": 2,
    "authors": [
      "Philipp Geiger",
      "Christoph-Nikolas Straehle"
    ]
  },
  "https://openreview.net/forum?id=MHOAEiTlen": {
    "title": "DHA: End-to-End Joint Optimization of Data Augmentation Policy, Hyper-parameter and Architecture",
    "volume": "main",
    "abstract": "Automated machine learning (AutoML) usually involves several crucial components, such as Data Augmentation (DA) policy, Hyper-Parameter Optimization (HPO), and Neural Architecture Search (NAS). Although many strategies have been developed for automating these components in separation, joint optimization of these components remains challenging due to the largely increased search dimension and the variant input types of each component. In parallel to this, the common practice of searching for the optimal architecture first and then retraining it before deployment in NAS often suffers from the low-performance correlation between the searching and retraining stages. An end-to-end solution that integrates the AutoML components and returns a ready-to-use model at the end of the search is desirable. In view of these, we propose DHA, which achieves joint optimization of Data augmentation policy, Hyper-parameter, and Architecture. Specifically, end-to-end NAS is achieved in a differentiable manner by optimizing a compressed lower-dimensional feature space, while DA policy and HPO are regarded as dynamic schedulers, which adapt themselves to the update of network parameters and network architecture at the same time. Experiments show that DHA achieves state-of-the-art (SOTA) results on various datasets and search spaces. To the best of our knowledge, we are the first to efficiently and jointly optimize DA policy, NAS, and HPO in an end-to-end manner without retraining",
    "checked": true,
    "id": "e62b102e072bb83506f858e15ebd8be5030024be",
    "semantic_title": "dha: end-to-end joint optimization of data augmentation policy, hyper-parameter and architecture",
    "citation_count": 10,
    "authors": [
      "kaichen zhou",
      "Lanqing HONG",
      "Shoukang Hu",
      "Fengwei Zhou",
      "Binxin Ru",
      "Jiashi Feng",
      "Zhenguo Li"
    ]
  },
  "https://openreview.net/forum?id=e7A0B99zJf": {
    "title": "Data Leakage in Federated Averaging",
    "volume": "main",
    "abstract": "Recent attacks have shown that user data can be recovered from FedSGD updates, thus breaking privacy. However, these attacks are of limited practical relevance as federated learning typically uses the FedAvg algorithm. Compared to FedSGD, recovering data from FedAvg updates is much harder as: (i) the updates are computed at unobserved intermediate network weights, (ii) a large number of batches are used, and (iii) labels and network weights vary simultaneously across client steps. In this work, we propose a new optimization-based attack which successfully attacks FedAvg by addressing the above challenges. First, we solve the optimization problem using automatic differentiation that forces a simulation of the client's update that generates the unobserved parameters for the recovered labels and inputs to match the received client update. Second, we address the large number of batches by relating images from different epochs with a permutation invariant prior. Third, we recover the labels by estimating the parameters of existing FedSGD attacks at every FedAvg step. On the popular FEMNIST dataset, we demonstrate that on average we successfully recover >45% of the client's images from realistic FedAvg updates computed on 10 local epochs of 10 batches each with 5 images, compared to only <10% using the baseline. Our findings show many real-world federated learning implementations based on FedAvg are vulnerable",
    "checked": true,
    "id": "4fe85cbbde2185d8515fd9f396d97fe475843e80",
    "semantic_title": "data leakage in federated averaging",
    "citation_count": 32,
    "authors": [
      "Dimitar Iliev Dimitrov",
      "Mislav Balunovic",
      "Nikola Konstantinov",
      "Martin Vechev"
    ]
  },
  "https://openreview.net/forum?id=lE7K4n1Esk": {
    "title": "On the Adversarial Robustness of Vision Transformers",
    "volume": "main",
    "abstract": "Following the success in advancing natural language processing and understanding, transformers are expected to bring revolutionary changes to computer vision. This work provides a comprehensive study on the robustness of vision transformers (ViTs) against adversarial perturbations. Tested on various white-box and transfer attack settings, we find that ViTs possess better adversarial robustness when compared with MLP-Mixer and convolutional neural networks (CNNs) including ConvNeXt, and this observation also holds for certified robustness. Through frequency analysis and feature visualization, we summarize the following main observations contributing to the improved robustness of ViTs: 1) Features learned by ViTs contain less high-frequency patterns that have spurious correlation, which helps explain why ViTs are less sensitive to high-frequency perturbations than CNNs and MLP-Mixer, and there is a high correlation between how much the model learns high-frequency features and its robustness against different frequency-based perturbations. 2) Introducing convolutional or tokens-to-token blocks for learning high-frequency features in ViTs can improve classification accuracy but at the cost of adversarial robustness. 3) Modern CNN designs that borrow techniques from ViTs including activation function, layer norm, larger kernel size to imitate the global attention, and patchify the images as inputs, etc., could help bridge the performance gap between ViTs and CNNs not only in terms of performance, but also certified and empirical adversarial robustness. Moreover, we show adversarial training is also applicable to ViT for training robust models, and sharpness-aware minimization can also help improve robustness, while pre-training with clean images on larger datasets does not significantly improve adversarial robustness",
    "checked": true,
    "id": "0def290ae38abb4a04e35e0bcdc86b71d237f494",
    "semantic_title": "on the adversarial robustness of vision transformers",
    "citation_count": 146,
    "authors": [
      "Rulin Shao",
      "Zhouxing Shi",
      "Jinfeng Yi",
      "Pin-Yu Chen",
      "Cho-Jui Hsieh"
    ]
  },
  "https://openreview.net/forum?id=7iSYW1FRWA": {
    "title": "Behind the Machine's Gaze: Neural Networks with Biologically-inspired Constraints Exhibit Human-like Visual Attention",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3b5361986d79be91e6d490e09fed49d9ee5abab2",
    "semantic_title": "behind the machine's gaze: neural networks with biologically-inspired constraints exhibit human-like visual attention",
    "citation_count": 7,
    "authors": [
      "Leo Schwinn",
      "Doina Precup",
      "Bjoern Eskofier",
      "Dario Zanca"
    ]
  },
  "https://openreview.net/forum?id=cxp7n9q5c4": {
    "title": "Structured Uncertainty in the Observation Space of Variational Autoencoders",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "65fcbc44223f317de139a9fb218b502c830a2f32",
    "semantic_title": "structured uncertainty in the observation space of variational autoencoders",
    "citation_count": 2,
    "authors": [
      "James Langley",
      "Miguel Monteiro",
      "Charles Jones",
      "Nick Pawlowski",
      "Ben Glocker"
    ]
  },
  "https://openreview.net/forum?id=CExeD0jpB6": {
    "title": "Distributed Stochastic Algorithms for High-rate Streaming Principal Component Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haroon Raja",
      "Waheed Bajwa"
    ]
  },
  "https://openreview.net/forum?id=9NjqD9i48M": {
    "title": "Benchmarking Progress to Infant-Level Physical Reasoning in AI",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "414a476f83634e3b452b243ed7460c9ef3d1aaa4",
    "semantic_title": "benchmarking progress to infant-level physical reasoning in ai",
    "citation_count": 16,
    "authors": [
      "Luca Weihs",
      "Amanda Yuile",
      "Ren√©e Baillargeon",
      "Cynthia Fisher",
      "Gary Marcus",
      "Roozbeh Mottaghi",
      "Aniruddha Kembhavi"
    ]
  },
  "https://openreview.net/forum?id=Hp4g7FAXXG": {
    "title": "Linear algebra with transformers",
    "volume": "main",
    "abstract": "Transformers can learn to perform numerical computations from examples only. I study nine problems of linear algebra, from basic matrix operations to eigenvalue decomposition and inversion, and introduce and discuss four encoding schemes to represent real numbers. On all problems, transformers trained on sets of random matrices achieve high accuracies (over 90\\%). The models are robust to noise, and can generalize out of their training distribution. In particular, models trained to predict Laplace-distributed eigenvalues generalize to different classes of matrices: Wigner matrices or matrices with positive eigenvalues. The reverse is not true",
    "checked": true,
    "id": "45ece6f3b0a319dba60c20b3013b5161dd49c58b",
    "semantic_title": "linear algebra with transformers",
    "citation_count": 59,
    "authors": [
      "Francois Charton"
    ]
  },
  "https://openreview.net/forum?id=aIoEkwc2oB": {
    "title": "INR-V: A Continuous Representation Space for Video-based Generative Tasks",
    "volume": "main",
    "abstract": "Generating videos is a complex task that is accomplished by generating a set of temporally coherent images frame-by-frame. This limits the expressivity of videos to only image-based operations on the individual video frames needing network designs to obtain temporally coherent trajectories in the underlying image space. We propose INR-V, a video representation network that learns a continuous space for video-based generative tasks. INR-V parameterizes videos using implicit neural representations (INRs), a multi-layered perceptron that predicts an RGB value for each input pixel location of the video. The INR is predicted using a meta-network which is a hypernetwork trained on neural representations of multiple video instances. Later, the meta-network can be sampled to generate diverse novel videos enabling many downstream video-based generative tasks. Interestingly, we find that conditional regularization and progressive weight initialization play a crucial role in obtaining INR-V. The representation space learned by INR-V is more expressive than an image space showcasing many interesting properties not possible with the existing works. For instance, INR-V can smoothly interpolate intermediate videos between known video instances (such as intermediate identities, expressions, and poses in face videos). It can also in-paint missing portions in videos to recover temporally coherent full videos. In this work, we evaluate the space learned by INR-V on diverse generative tasks such as video interpolation, novel video generation, video inversion, and video inpainting against the existing baselines. INR-V significantly outperforms the baselines on several of these demonstrated tasks, clearly showing the potential of the proposed representation space",
    "checked": true,
    "id": "6310ac90d660b3359df2c375670799d08d5db454",
    "semantic_title": "inr-v: a continuous representation space for video-based generative tasks",
    "citation_count": 7,
    "authors": [
      "Bipasha Sen",
      "Aditya Agarwal",
      "Vinay P Namboodiri",
      "C.V. Jawahar"
    ]
  },
  "https://openreview.net/forum?id=ZPQhzTSWA7": {
    "title": "A Simple Convergence Proof of Adam and Adagrad",
    "volume": "main",
    "abstract": "We provide a simple proof of convergence covering both the Adam and Adagrad adaptive optimization algorithms when applied to smooth (possibly non-convex) objective functions with bounded gradients. We show that in expectation, the squared norm of the objective gradient averaged over the trajectory has an upper-bound which is explicit in the constants of the problem, parameters of the optimizer, the dimension $d$, and the total number of iterations $N$. This bound can be made arbitrarily small, and with the right hyper-parameters, Adam can be shown to converge with the same rate of convergence $O(d\\ln(N)/\\sqrt{N})$. When used with the default parameters, Adam doesn't converge, however, and just like constant step-size SGD, it moves away from the initialization point faster than Adagrad, which might explain its practical success. Finally, we obtain the tightest dependency on the heavy ball momentum decay rate $\\beta_1$ among all previous convergence bounds for non-convex Adam and Adagrad, improving from $O((1-\\beta_1)^{-3})$ to $O((1-\\beta_1)^{-1})$",
    "checked": true,
    "id": "05b4436d504d5615801639a120a2c8eca7cbaabd",
    "semantic_title": "a simple convergence proof of adam and adagrad",
    "citation_count": 159,
    "authors": [
      "Alexandre D√©fossez",
      "Leon Bottou",
      "Francis Bach",
      "Nicolas Usunier"
    ]
  },
  "https://openreview.net/forum?id=atJHLVyBi8": {
    "title": "On the Paradox of Certified Training",
    "volume": "main",
    "abstract": "Certified defenses based on convex relaxations are an established technique for training provably robust models. The key component is the choice of relaxation, varying from simple intervals to tight polyhedra. Counterintuitively, loose interval-based training often leads to higher certified robustness than what can be achieved with tighter relaxations, which is a well-known but poorly understood paradox. While recent works introduced various improvements aiming to circumvent this issue in practice, the fundamental problem of training models with high certified robustness remains unsolved. In this work, we investigate the underlying reasons behind the paradox and identify two key properties of relaxations, beyond tightness, that impact certified training dynamics: continuity and sensitivity. Our extensive experimental evaluation with a number of popular convex relaxations provides strong evidence that these factors can explain the drop in certified robustness observed for tighter relaxations. We also systematically explore modifications of existing relaxations and discover that improving unfavorable properties is challenging, as such attempts often harm other properties, revealing a complex tradeoff. Our findings represent an important first step towards understanding the intricate optimization challenges involved in certified training",
    "checked": true,
    "id": "1b226f93f4ba9cdf2bcd5191015e6588d097b35f",
    "semantic_title": "on the paradox of certified training",
    "citation_count": 13,
    "authors": [
      "Nikola Jovanoviƒá",
      "Mislav Balunovic",
      "Maximilian Baader",
      "Martin Vechev"
    ]
  },
  "https://openreview.net/forum?id=JXCH5N4Ujy": {
    "title": "Time Series Alignment with Global Invariances",
    "volume": "main",
    "abstract": "Multivariate time series are ubiquitous objects in signal processing. Measuring a distance or similarity between two such objects is of prime interest in a variety of applications, including machine learning, but can be very difficult as soon as the temporal dynamics and the representation of the time series, i.e. the nature of the observed quantities, differ from one another. In this work, we propose a novel distance accounting both feature space and temporal variabilities by learning a latent global transformation of the feature space together with a temporal alignment, cast as a joint optimization problem. The versatility of our framework allows for several variants depending on the invariance class at stake. Among other contributions, we define a differentiable loss for time series and present two algorithms for the computation of time series barycenters under this new geometry. We illustrate the interest of our approach on both simulated and real world data and show the robustness of our approach compared to state-of-the-art methods",
    "checked": true,
    "id": "b5a48960a1cb45ab8811dfe92904e3fb46c5231e",
    "semantic_title": "time series alignment with global invariances",
    "citation_count": 17,
    "authors": [
      "Titouan Vayer",
      "Romain Tavenard",
      "Laetitia Chapel",
      "R√©mi Flamary",
      "Nicolas Courty",
      "Yann Soullard"
    ]
  },
  "https://openreview.net/forum?id=jIrOeWjdpc": {
    "title": "Explicit Group Sparse Projection with Applications to Deep Learning and NMF",
    "volume": "main",
    "abstract": "We design a new sparse projection method for a set of vectors that guarantees a desired average sparsity level measured leveraging the popular Hoyer measure (an affine function of the ratio of the $\\ell_1$ and $\\ell_2$ norms). Existing approaches either project each vector individually or require the use of a regularization parameter which implicitly maps to the average $\\ell_0$-measure of sparsity. Instead, in our approach we set the sparsity level for the whole set explicitly and simultaneously project a group of vectors with the sparsity level of each vector tuned automatically. We show that the computational complexity of our projection operator is linear in the size of the problem. Additionally, we propose a generalization of this projection by replacing the $\\ell_1$ norm by its weighted version. We showcase the efficacy of our approach in both supervised and unsupervised learning tasks on image datasets including CIFAR10 and ImageNet. In deep neural network pruning, the sparse models produced by our method on ResNet50 have significantly higher accuracies at corresponding sparsity values compared to existing competitors. In nonnegative matrix factorization, our approach yields competitive reconstruction errors against state-of-the-art algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Riyasat Ohib",
      "Nicolas Gillis",
      "Niccolo Dalmasso",
      "Sameena Shah",
      "Vamsi K. Potluru",
      "Sergey Plis"
    ]
  },
  "https://openreview.net/forum?id=jjtFD8A1Wx": {
    "title": "Reasonable Effectiveness of Random Weighting: A Litmus Test for Multi-Task Learning",
    "volume": "main",
    "abstract": "Multi-Task Learning (MTL) has achieved success in various fields. However, training with equal weights for all tasks may cause unsatisfactory performance for part of tasks. To address this problem, there are many works to carefully design dynamical loss/gradient weighting strategies but the basic random experiments are ignored to examine their effectiveness. In this paper, we propose the Random Weighting (RW) methods, including Random Loss Weighting (RLW) and Random Gradient Weighting (RGW), where an MTL model is trained with random loss/gradient weights sampled from a distribution. To show the effectiveness and necessity of RW methods, theoretically, we analyze the convergence of RW and reveal that RW has a higher probability to escape local minima, resulting in better generalization ability. Empirically, we extensively evaluate the proposed RW methods to compare with twelve state-of-the-art methods on five image datasets and two multilingual problems from the XTREME benchmark to show that RW methods can achieve comparable performance with state-of-the-art baselines. Therefore, we think the RW methods are important baselines for MTL and should attract more attention",
    "checked": true,
    "id": "36f30a2d5d3d0b47fa6caa19b3ac772ef68bb71e",
    "semantic_title": "reasonable effectiveness of random weighting: a litmus test for multi-task learning",
    "citation_count": 100,
    "authors": [
      "Baijiong Lin",
      "Feiyang Ye",
      "Yu Zhang",
      "Ivor Tsang"
    ]
  },
  "https://openreview.net/forum?id=lCPOHiztuw": {
    "title": "Direct Molecular Conformation Generation",
    "volume": "main",
    "abstract": "Molecular conformation generation aims to generate three-dimensional coordinates of all the atoms in a molecule and is an important task in bioinformatics and pharmacology. Previous methods usually first predict the interatomic distances, the gradients of interatomic distances or the local structures (e.g., torsion angles) of a molecule, and then reconstruct its 3D conformation. How to directly generate the conformation without the above intermediate values is not fully explored. In this work, we propose a method that directly predicts the coordinates of atoms: (1) the loss function is invariant to roto-translation of coordinates and permutation of symmetric atoms; (2) the newly proposed model adaptively aggregates the bond and atom information and iteratively refines the coordinates of the generated conformation. Our method achieves the best results on GEOM-QM9 and GEOM-Drugs datasets. Further analysis shows that our generated conformations have closer properties (e.g., HOMO-LUMO gap) with the groundtruth conformations. In addition, our method improves molecular docking by providing better initial conformations. All the results demonstrate the effectiveness of our method and the great potential of the direct approach. The code is released at \\url{https://github.com/DirectMolecularConfGen/DMCG}",
    "checked": true,
    "id": "636aae3d8028ec550c087573238ef0a1f480383d",
    "semantic_title": "direct molecular conformation generation",
    "citation_count": 42,
    "authors": [
      "Jinhua Zhu",
      "Yingce Xia",
      "Chang Liu",
      "Lijun Wu",
      "Shufang Xie",
      "Yusong Wang",
      "Tong Wang",
      "Tao Qin",
      "Wengang Zhou",
      "Houqiang Li",
      "Haiguang Liu",
      "Tie-Yan Liu"
    ]
  },
  "https://openreview.net/forum?id=LTiaPxqe2e": {
    "title": "Symbolic Regression is NP-hard",
    "volume": "main",
    "abstract": "Symbolic regression (SR) is the task of learning a model of data in the form of a mathematical expression. By their nature, SR models have the potential to be accurate and human-interpretable at the same time. Unfortunately, finding such models, i.e., performing SR, appears to be a computationally intensive task. Historically, SR has been tackled with heuristics such as greedy or genetic algorithms and, while some works have hinted at the possible hardness of SR, no proof has yet been given that SR is, in fact, NP-hard. This begs the question: Is there an exact polynomial-time algorithm to compute SR models? We provide evidence suggesting that the answer is probably negative by showing that SR is NP-hard",
    "checked": true,
    "id": "c703a193a48befe47b4c62cfbec8ae9d1a243fdf",
    "semantic_title": "symbolic regression is np-hard",
    "citation_count": 64,
    "authors": [
      "Marco Virgolin",
      "Solon P Pissis"
    ]
  },
  "https://openreview.net/forum?id=e5ILb2Nqst": {
    "title": "Differentially Private Stochastic Expectation Propagation",
    "volume": "main",
    "abstract": "We are interested in privatizing an approximate posterior inference algorithm, called Expectation Propagation (EP). EP approximates the posterior distribution by iteratively refining approximations to the local likelihood terms. By doing so, EP typically provides better posterior uncertainties than variational inference (VI) which globally approximates the likelihood term. However, EP needs a large memory to maintain all local approximations associated with each datapoint in the training data. To overcome this challenge, stochastic expectation propagation (SEP) considers a single unique local factor that captures the average effect of each likelihood term to the posterior and refines it in a way analogous to EP. In terms of privatization, SEP is more tractable than EP. It is because at each factor's refining step we fix the remaining factors, where these factors are independent of other datapoints, which is different from EP. This independence makes the sensitivity analysis straightforward. We provide a theoretical analysis of the privacy-accuracy trade-off in the posterior distributions under our method, which we call differentially private stochastic expectation propagation (DP-SEP). Furthermore, we test the DP-SEP algorithm on both synthetic and real-world datasets and evaluate the quality of posterior estimates at different levels of guaranteed privacy",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Margarita Vinaroz",
      "Mijung Park"
    ]
  },
  "https://openreview.net/forum?id=4FU8Jz1Oyj": {
    "title": "On Noise Abduction for Answering Counterfactual Queries: A Practical Outlook",
    "volume": "main",
    "abstract": "A crucial step in counterfactual inference is abduction - inference of the exogenous noise variables. Deep Learning approaches model an exogenous noise variable as a latent variable. Our ability to infer a latent variable comes at a computational cost as well as a statistical cost. In this paper, we show that it may not be necessary to abduct all the noise variables in a structural causal model (SCM) to answer a counterfactual query. In a fully specified causal model with no unobserved confounding, we also identify exogenous noises that must be abducted for a counterfactual query. We introduce a graphical condition for noise identification from an action consisting of an arbitrary combination of hard and soft interventions. We report experimental results on both synthetic and real-world German Credit Dataset showcasing the promise and usefulness of the proposed exogenous noise identification",
    "checked": true,
    "id": "0fb1b3d51a0556b6b4268fd9c2f2b2ce238af3c7",
    "semantic_title": "on noise abduction for answering counterfactual queries: a practical outlook",
    "citation_count": 6,
    "authors": [
      "Saptarshi Saha",
      "Utpal Garain"
    ]
  },
  "https://openreview.net/forum?id=VBHuLfnOMf": {
    "title": "Failure Detection in Medical Image Classification: A Reality Check and Benchmarking Testbed",
    "volume": "main",
    "abstract": "Failure detection in automated image classification is a critical safeguard for clinical deployment. Detected failure cases can be referred to human assessment, ensuring patient safety in computer-aided clinical decision making. Despite its paramount importance, there is insufficient evidence about the ability of state-of-the-art confidence scoring methods to detect test-time failures of classification models in the context of medical imaging. This paper provides a reality check, establishing the performance of in-domain misclassification detection methods, benchmarking 9 widely used confidence scores on 6 medical imaging datasets with different imaging modalities, in multiclass and binary classification settings. Our experiments show that the problem of failure detection is far from being solved. We found that none of the benchmarked advanced methods proposed in the computer vision and machine learning literature can consistently outperform a simple softmax baseline, demonstrating that improved out-of-distribution detection or model calibration do not necessarily translate to improved in-domain misclassification detection. Our developed testbed facilitates future work in this important area",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "M√©lanie Bernhardt",
      "Fabio De Sousa Ribeiro",
      "Ben Glocker"
    ]
  },
  "https://openreview.net/forum?id=XX8CEN815d": {
    "title": "Bridging Offline and Online Experimentation: Constraint Active Search for Deployed Performance Optimization",
    "volume": "main",
    "abstract": "A common challenge in machine learning model development is that models perform differently between the offline development phase and the eventual deployment phase. Fundamentally, the goal of such a model is to maximize performance during deployment, but such performance cannot be measured offline. As such, we propose to augment the standard offline sample efficient hyperparameter optimization to instead search offline for a diverse set of models which can have potentially superior online performance. To this end, we utilize Constraint Active Search to identify such a diverse set of models, and we study their online performance using a variant of Best Arm Identification to select the best model for deployment. The key contribution of this article is the theoretical analysis of the two-phase development strategy, both in analyzing the probability of improvement over the baseline as well as the number of viable treatments for online testing. We demonstrate the viability of this strategy on synthetic examples, as well as a recommendation system benchmark",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junpei Komiyama",
      "Gustavo Malkomes",
      "Bolong Cheng",
      "Michael McCourt"
    ]
  },
  "https://openreview.net/forum?id=CrimIjBa64": {
    "title": "Multi-Source Causal Inference Using Control Variates under Outcome Selection Bias",
    "volume": "main",
    "abstract": "While many areas of machine learning have benefited from the increasing availability of large and varied datasets, the benefit to causal inference has been limited given the strong assumptions needed to ensure the identifiability of causal effects -- which are often not satisfied in real-world datasets. For example, many large observational datasets (e.g., case-control studies in epidemiology, click-through data in recommender systems) suffer from selection bias on the outcome, which makes the average treatment effect (ATE) non-identifiable. We propose an algorithm to estimate causal effects from multiple data sources, where the ATE may be identifiable only in some datasets but not others. The idea is to construct control variates across the datasets in which the ATE may not be identifiable, which provably reduces the variance of the ATE estimate. We focus on a setting where the observational datasets suffer from outcome selection bias, assuming access to an auxiliary small dataset from which we can obtain a consistent estimate of the ATE. We propose a construction of control variate by taking the difference of the conditional odds ratio estimates from the two datasets. Across simulations and two case studies with real data, we show that the control variate-based ATE estimator has consistently and significantly reduced variance against different baselines",
    "checked": false,
    "id": "7a8d1aaf5873d43707dc75871cdb9e9e0bb36bd8",
    "semantic_title": "multi-source causal inference using control variates",
    "citation_count": 19,
    "authors": [
      "Wenshuo Guo",
      "Serena Lutong Wang",
      "Peng Ding",
      "Yixin Wang",
      "Michael Jordan"
    ]
  },
  "https://openreview.net/forum?id=vd0onGWZbE": {
    "title": "Identifiable Deep Generative Models via Sparse Decoding",
    "volume": "main",
    "abstract": "We develop the sparse VAE for unsupervised representation learning on high-dimensional data. The sparse VAE learns a set of latent factors (representations) which summarize the associations in the observed data features. The underlying model is sparse in that each observed feature (i.e. each dimension of the data) depends on a small subset of the latent factors. As examples, in ratings data each movie is only described by a few genres; in text data each word is only applicable to a few topics; in genomics, each gene is active in only a few biological processes. We prove such sparse deep generative models are identifiable: with infinite data, the true model parameters can be learned. (In contrast, most deep generative models are not identifiable.) We empirically study the sparse VAE with both simulated and real data. We find that it recovers meaningful latent factors and has smaller heldout reconstruction error than related methods",
    "checked": true,
    "id": "0bf88192d02c08661b9185b2b16399306694c4a4",
    "semantic_title": "identifiable deep generative models via sparse decoding",
    "citation_count": 49,
    "authors": [
      "Gemma Elyse Moran",
      "Dhanya Sridhar",
      "Yixin Wang",
      "David Blei"
    ]
  },
  "https://openreview.net/forum?id=QFJ3gtbwHR": {
    "title": "Using unsupervised learning to detect broken symmetries, with relevance to searches for parity violation in nature",
    "volume": "main",
    "abstract": "Testing whether data breaks symmetries of interest can be important to many fields. This paper describes a simple way that machine learning algorithms (whose outputs have been appropriately symmetrised) can be used to detect symmetry breaking. The original motivation for the paper was an important question in Particle Physics: \"Is parity violated at the LHC in some way that no-one has anticipated?\" and so we illustrate the main idea with an example strongly related to that question. However, in order that the key ideas be accessible to readers who are not particle physicists but who are interesting in symmetry breaking, we choose to illustrate the method/approach with a 'toy' example which places a simple discrete source of symmetry breaking (the handedness of human handwriting) within a idealised particle-physics-like context. Readers interested in seeing extensions to continuous symmetries, non-ideal environments or more realistic particle-physics contexts are provided with links to separate papers which delve into such details",
    "checked": true,
    "id": "0c9d931c1ea19ab6a0a407e3d8049f3dfc0794e9",
    "semantic_title": "using unsupervised learning to detect broken symmetries, with relevance to searches for parity violation in nature",
    "citation_count": 7,
    "authors": [
      "Christopher Gorham Lester"
    ]
  },
  "https://openreview.net/forum?id=Kb1lb0vSLa": {
    "title": "Integrating Rankings into Quantized Scores in Peer Review",
    "volume": "main",
    "abstract": "In peer review, reviewers are usually asked to provide scores for the papers. The scores are then used by Area Chairs or Program Chairs in various ways in the decision-making process. The scores are usually elicited in a quantized form to accommodate the limited cognitive ability of humans to describe their opinions in numerical values. It has been found that the quantized scores suffer from a large number of ties, thereby leading to a significant loss of information. To mitigate this issue, conferences have started to ask reviewers to additionally provide a ranking of the papers they have reviewed. There are however two key challenges. First, there is no standard procedure for using this ranking information and Area Chairs may use it in different ways (including simply ignoring them), thereby leading to arbitrariness in the peer-review process. Second, there are no suitable interfaces for judicious use of this data nor methods to incorporate it in existing workflows, thereby leading to inefficiencies. We take a principled approach to integrate the ranking information into the scores. The output of our method is an updated score pertaining to each review that also incorporates the rankings. Our approach addresses the two aforementioned challenges by: (i) ensuring that rankings are incorporated into the updated scores in the same manner for all papers, thereby mitigating arbitrariness, and (ii) allowing to seamlessly use existing interfaces and workflows designed for scores. We empirically evaluate our method on synthetic datasets as well as on peer reviews from the ICLR 2017 conference, and find that it reduces the error by approximately 30% as compared to the best performing baseline on the ICLR 2017 data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusha Liu",
      "Yichong Xu",
      "Nihar B Shah",
      "Aarti Singh"
    ]
  },
  "https://openreview.net/forum?id=CfzIsWWBlo": {
    "title": "Towards Accurate Subgraph Similarity Computation via Neural Graph Pruning",
    "volume": "main",
    "abstract": "Subgraph similarity search, one of the core problems in graph search, concerns whether a target graph approximately contains a query graph. The problem is recently touched by neural methods. However, current neural methods do not consider pruning the target graph, though pruning is critically important in traditional calculations of subgraph similarities. One obstacle to applying pruning in neural methods is the discrete property of pruning. In this work, we convert graph pruning to a problem of node relabeling and then relax it to a differentiable problem. Based on this idea, we further design a novel neural network to approximate a type of subgraph distance: the subgraph edit distance (SED). In particular, we construct the pruning component using a neural structure, and the entire model can be optimized end-to-end. In the design of the model, we propose an attention mechanism to leverage the information about the query graph and guide the pruning of the target graph. Moreover, we develop a multi-head pruning strategy such that the model can better explore multiple ways of pruning the target graph. The proposed model establishes new state-ofthe-art results across seven benchmark datasets. Extensive analysis of the model indicates that the proposed model can reasonably prune the target graph for SED computation",
    "checked": true,
    "id": "4ff9b0f36d37f37e3985f4608f3037f506b3c825",
    "semantic_title": "towards accurate subgraph similarity computation via neural graph pruning",
    "citation_count": 5,
    "authors": [
      "Linfeng Liu",
      "XU HAN",
      "Dawei Zhou",
      "Liping Liu"
    ]
  },
  "https://openreview.net/forum?id=Ox5tmhFBrc": {
    "title": "Learning Two-Step Hybrid Policy for Graph-Based Interpretable Reinforcement Learning",
    "volume": "main",
    "abstract": "We present a two-step hybrid reinforcement learning (RL) policy that is designed to generate interpretable and robust hierarchical policies on the RL problem with graph-based input. Unlike prior deep reinforcement learning policies parameterized by an end-to-end black-box graph neural network, our approach disentangles the decision-making process into two steps. The first step is a simplified classification problem that maps the graph input to an action group where all actions share a similar semantic meaning. The second step implements a sophisticated rule-miner that conducts explicit one-hop reasoning over the graph and identifies decisive edges in the graph input without the necessity of heavy domain knowledge. This two-step hybrid policy presents human-friendly interpretations and achieves better performance in terms of generalization and robustness. Extensive experimental studies on four levels of complex text-based games have demonstrated the superiority of the proposed method compared to the state-of-the-art",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tongzhou Mu",
      "Kaixiang Lin",
      "Feiyang Niu",
      "Govind Thattai"
    ]
  },
  "https://openreview.net/forum?id=UDmH3HxxPp": {
    "title": "Secure Domain Adaptation with Multiple Sources",
    "volume": "main",
    "abstract": "Multi-source unsupervised domain adaptation (MUDA) is a framework to address the challenge of annotated data scarcity in a target domain via transferring knowledge from multiple annotated source domains. When the source domains are distributed, data privacy and security can become significant concerns and protocols may limit data sharing, yet existing MUDA methods overlook these constraints. We develop an algorithm to address MUDA when source domain data cannot be shared with the target or across the source domains. Our method is based on aligning the distributions of source and target domains indirectly via estimating the source feature embeddings and predicting over a confidence based combination of domain specific model predictions. We provide theoretical analysis to support our approach and conduct empirical experiments to demonstrate that our algorithm is effective",
    "checked": true,
    "id": "6ae637ba0c56da24584a2d28f522c65a45e6a460",
    "semantic_title": "secure domain adaptation with multiple sources",
    "citation_count": 13,
    "authors": [
      "Serban Stan",
      "Mohammad Rostami"
    ]
  },
  "https://openreview.net/forum?id=8s8K2UZGTZ": {
    "title": "Teaching Models to Express Their Uncertainty in Words",
    "volume": "main",
    "abstract": "We show that a GPT-3 model can learn to express uncertainty about its own answers in natural language -- without use of model logits. When given a question, the model generates both an answer and a level of confidence (e.g. \"90% confidence\" or \"high confidence\"). These levels map to probabilities that are well calibrated. The model also remains moderately calibrated under distribution shift, and is sensitive to uncertainty in its own answers, rather than imitating human examples. For testing calibration, we introduce the CalibratedMath suite of tasks. We compare the calibration of uncertainty expressed in words (\"verbalized probability\") to uncertainty extracted from model logits. Both kinds of uncertainty are capable of generalizing calibration under distribution shift. We also provide evidence that GPT-3's ability to generalize calibration depends on pre-trained latent representations that correlate with epistemic uncertainty over its answers",
    "checked": true,
    "id": "374dd173491a59a10bbb2b3519ebcfe3649f529d",
    "semantic_title": "teaching models to express their uncertainty in words",
    "citation_count": 425,
    "authors": [
      "Stephanie Lin",
      "Jacob Hilton",
      "Owain Evans"
    ]
  },
  "https://openreview.net/forum?id=Qs3EfpieOh": {
    "title": "The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning",
    "volume": "main",
    "abstract": "Although machine learning models typically experience a drop in performance on out-of-distribution data, accuracies on in- versus out-of-distribution data are widely observed to follow a single linear trend when evaluated across a testbed of models. Models that are more accurate on the out-of-distribution data relative to this baseline exhibit \"effective robustness\" and are exceedingly rare. Identifying such models, and understanding their properties, is key to improving out-of-distribution performance. We conduct a thorough empirical investigation of effective robustness during fine-tuning and surprisingly find that models pre-trained on larger datasets exhibit effective robustness during training that vanishes at convergence. We study how properties of the data influence effective robustness, and we show that it increases with the larger size, more diversity, and higher example difficulty of the dataset. We also find that models that display effective robustness are able to correctly classify 10\\% of the examples that no other current testbed model gets correct. Finally, we discuss several strategies for scaling effective robustness to the high-accuracy regime to improve the out-of-distribution accuracy of state-of-the-art models",
    "checked": true,
    "id": "4b1db6ebbdfcfe8ef67c5db511b6ad169fcc8f7f",
    "semantic_title": "the evolution of out-of-distribution robustness throughout fine-tuning",
    "citation_count": 82,
    "authors": [
      "Anders Johan Andreassen",
      "Yasaman Bahri",
      "Behnam Neyshabur",
      "Rebecca Roelofs"
    ]
  },
  "https://openreview.net/forum?id=JBuCfkmKYu": {
    "title": "Simplifying Node Classification on Heterophilous Graphs with Compatible Label Propagation",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) have been predominant for graph learning tasks; however, recent studies showed that a well-known graph algorithm, Label Propagation (LP), combined with a shallow neural network can achieve comparable performance to GNNs in semi-supervised node classification on graphs with high homophily. In this paper, we show that this approach falls short on graphs with low homophily, where nodes often connect to the nodes of the opposite classes. To overcome this, we carefully design a combination of a base predictor with LP algorithm that enjoys a closed-form solution as well as convergence guarantees. Our algorithm first learns the class compatibility matrix and then aggregates label predictions using LP algorithm weighted by class compatibilities. On a wide variety of benchmarks, we show that our approach achieves the leading performance on graphs with various levels of homophily. Meanwhile, it has orders of magnitude fewer parameters and requires less execution time",
    "checked": true,
    "id": "2cc70191b6f2fd047ab1ac0ed41d48186e66662d",
    "semantic_title": "simplifying node classification on heterophilous graphs with compatible label propagation",
    "citation_count": 9,
    "authors": [
      "Zhiqiang Zhong",
      "Sergei Ivanov",
      "Jun Pang"
    ]
  },
  "https://openreview.net/forum?id=7gzQltQSwr": {
    "title": "Centroids Matching: an efficient Continual Learning approach operating in the embedding space",
    "volume": "main",
    "abstract": "Catastrophic forgetting (CF) occurs when a neural network loses the information previously learned while training on a set of samples from a different distribution, i.e., a new task. Existing approaches have achieved remarkable results in mitigating CF, especially in a scenario called task incremental learning. However, this scenario is not realistic, and limited work has been done to achieve good results on more realistic scenarios. In this paper, we propose a novel regularization method called Centroids Matching, that, inspired by meta-learning approaches, fights CF by operating in the feature space produced by the neural network, achieving good results while requiring a small memory footprint. Specifically, the approach classifies the samples directly using the feature vectors produced by the neural network, by matching those vectors with the centroids representing the classes from the current task, or all the tasks up to that point. Centroids Matching is faster than competing baselines, and it can be exploited to efficiently mitigate CF, by preserving the distances between the embedding space produced by the model when past tasks were over, and the one currently produced, leading to a method that achieves high accuracy on all the tasks, without using an external memory when operating on easy scenarios, or using a small one for more realistic ones. Extensive experiments demonstrate that Centroids Matching achieves accuracy gains on multiple datasets and scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jary Pomponi",
      "Simone Scardapane",
      "Aurelio Uncini"
    ]
  },
  "https://openreview.net/forum?id=nS8A9nOrqp": {
    "title": "Nonstationary Reinforcement Learning with Linear Function Approximation",
    "volume": "main",
    "abstract": "We consider reinforcement learning (RL) in episodic Markov decision processes (MDPs) with linear function approximation under drifting environment. Specifically, both the reward and state transition functions can evolve over time but their total variations do not exceed a \\textit{variation budget}. We first develop $\\texttt{LSVI-UCB-Restart}$ algorithm, an optimistic modification of least-squares value iteration with periodic restart, and bound its dynamic regret when variation budgets are known. Then we propose a parameter-free algorithm \\texttt{Ada-LSVI-UCB-Restart} that extends to unknown variation budgets. We also derive the first minimax dynamic regret lower bound for nonstationary linear MDPs and as a byproduct establish a minimax regret lower bound for linear MDPs unsolved by Jin et al. (2020). Finally, we provide numerical experiments to demonstrate the effectiveness of our proposed algorithms",
    "checked": true,
    "id": "750228d26cb6a33bd7393372983edfde1e09733b",
    "semantic_title": "nonstationary reinforcement learning with linear function approximation",
    "citation_count": 30,
    "authors": [
      "Huozhi Zhou",
      "Jinglin Chen",
      "Lav R. Varshney",
      "Ashish Jagmohan"
    ]
  },
  "https://openreview.net/forum?id=j2Mid5hFUJ": {
    "title": "Enhanced gradient-based MCMC in discrete spaces",
    "volume": "main",
    "abstract": "The recent introduction of gradient-based Markov chain Monte Carlo (MCMC) for discrete spaces holds great promise, and comes with the tantalising possibility of new discrete counterparts to celebrated continuous methods such as the Metropolis-adjusted Langevin algorithm (MALA). Towards this goal, we introduce several discrete Metropolis-Hastings samplers that are conceptually inspired by MALA, and demonstrate their strong empirical performance across a range of challenging sampling problems in Bayesian inference and energy-based modelling. Methodologically, we identify why discrete analogues to \\emph{preconditioned} MALA are generally intractable, motivating us to introduce a new kind of preconditioning based on auxiliary variables and the `Gaussian integral trick'",
    "checked": true,
    "id": "b9bbebe9f719e33229dd0801275f984c8f4f21ae",
    "semantic_title": "enhanced gradient-based mcmc in discrete spaces",
    "citation_count": 17,
    "authors": [
      "Benjamin Rhodes",
      "Michael U. Gutmann"
    ]
  },
  "https://openreview.net/forum?id=w3x20YEcQK": {
    "title": "Flipped Classroom: Effective Teaching for Time Series Forecasting",
    "volume": "main",
    "abstract": "Sequence-to-sequence models based on LSTM and GRU are a most popular choice for forecasting time series data reaching state-of-the-art performance. Training such models can be delicate though. The two most common training strategies within this context are teacher forcing (TF) and free running (FR). TF can be used to help the model to converge faster but may provoke an exposure bias issue due to a discrepancy between training and inference phase. FR helps to avoid this but does not necessarily lead to better results, since it tends to make the training slow and unstable instead. Scheduled sampling was the first approach tackling these issues by picking the best from both worlds and combining it into a curriculum learning (CL) strategy. Although scheduled sampling seems to be a convincing alternative to FR and TF, we found that, even if parametrized carefully, scheduled sampling may lead to premature termination of the training when applied for time series forecasting. To mitigate the problems of the above approaches we formalize CL strategies along the training as well as the training iteration scale. We propose several new curricula, and systematically evaluate their performance in two experimental sets. For our experiments, we utilize six datasets generated from prominent chaotic systems. We found that the newly proposed increasing training scale curricula with a probabilistic iteration scale curriculum consistently outperforms previous training strategies yielding an NRMSE improvement of up to 81% over FR or TF training. For some datasets we additionally observe a reduced number of training iterations. We observed that all models trained with the new curricula yield higher prediction stability allowing for longer prediction horizons",
    "checked": true,
    "id": "304718bd00445304f0834f5462fb131c955b0ad7",
    "semantic_title": "flipped classroom: effective teaching for time series forecasting",
    "citation_count": 8,
    "authors": [
      "Philipp Teutsch",
      "Patrick M√§der"
    ]
  },
  "https://openreview.net/forum?id=mbwm7NdkpO": {
    "title": "Deep Policies for Online Bipartite Matching: A Reinforcement Learning Approach",
    "volume": "main",
    "abstract": "The challenge in the widely applicable online matching problem lies in making irrevocable assignments while there is uncertainty about future inputs. Most theoretically-grounded policies are myopic or greedy in nature. In real-world applications where the matching process is repeated on a regular basis, the underlying data distribution can be leveraged for better decision-making. We present an end-to-end Reinforcement Learning framework for deriving better matching policies based on trial-and-error on historical data. We devise a set of neural network architectures, design feature representations, and empirically evaluate them across two online matching problems: Edge-Weighted Online Bipartite Matching and Online Submodular Bipartite Matching. We show that most of the learning approaches perform consistently better than classical baseline algorithms on four synthetic and real-world datasets. On average, our proposed models improve the matching quality by 3-10% on a variety of synthetic and real-world datasets",
    "checked": true,
    "id": "1a24c19434dd819f48408054321b2eefa799b86f",
    "semantic_title": "deep policies for online bipartite matching: a reinforcement learning approach",
    "citation_count": 22,
    "authors": [
      "Mohammad Ali Alomrani",
      "Reza Moravej",
      "Elias Boutros Khalil"
    ]
  },
  "https://openreview.net/forum?id=X1VzbBU6xZ": {
    "title": "Generative Adversarial Neural Operators",
    "volume": "main",
    "abstract": "We propose the generative adversarial neural operator (GANO), a generative model paradigm for learning probabilities on infinite-dimensional function spaces. The natural sciences and engineering are known to have many types of data that are sampled from infinite- dimensional function spaces, where classical finite-dimensional deep generative adversarial networks (GANs) may not be directly applicable. GANO generalizes the GAN framework and allows for the sampling of functions by learning push-forward operator maps in infinite-dimensional spaces. GANO consists of two main components, a generator neural operator and a discriminator neural functional. The inputs to the generator are samples of functions from a user-specified probability measure, e.g., Gaussian random field (GRF), and the generator outputs are synthetic data functions. The input to the discriminator is either a real or synthetic data function. In this work, we instantiate GANO using the Wasserstein criterion and show how the Wasserstein loss can be computed in infinite-dimensional spaces. We empirically study GANO in controlled cases where both input and output functions are samples from GRFs and compare its performance to the finite-dimensional counterpart GAN. We empirically study the efficacy of GANO on real-world function data of volcanic activities and show its superior performance over GAN",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Ashiqur Rahman",
      "Manuel A Florez",
      "Anima Anandkumar",
      "Zachary E Ross",
      "Kamyar Azizzadenesheli"
    ]
  },
  "https://openreview.net/forum?id=mW6nD3567x": {
    "title": "From Optimization Dynamics to Generalization Bounds via ≈Åojasiewicz Gradient Inequality",
    "volume": "main",
    "abstract": "Optimization and generalization are two essential aspects of statistical machine learning. In this paper, we propose a framework to connect optimization with generalization by analyz- ing the generalization error based on the optimization trajectory under the gradient flow algorithm. The key ingredient of this framework is the Uniform-LGI, a property that is generally satisfied when training machine learning models. Leveraging the Uniform-LGI, we first derive convergence rates for gradient flow algorithm, then we give generalization bounds for a large class of machine learning models. We further apply our framework to three distinct machine learning models: linear regression, kernel regression, and two-layer neural networks. Through our approach, we obtain generalization estimates that match or extend previous results",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fusheng Liu",
      "Haizhao Yang",
      "Soufiane Hayou",
      "Qianxiao Li"
    ]
  },
  "https://openreview.net/forum?id=1l0sClLiPc": {
    "title": "Unimodal Likelihood Models for Ordinal Data",
    "volume": "main",
    "abstract": "Ordinal regression (OR) is the classification of ordinal data, in which the underlying target variable is categorical and considered to have a natural ordinal relation for the explanatory variables. In this study, we suppose the unimodality of the conditional probability distribution of the target variable given a value of the explanatory variables as a natural ordinal relation of the ordinal data. Under this supposition, unimodal likelihood models are considered to be promising for achieving good generalization performance in OR tasks. Demonstrating that previous unimodal likelihood models have a weak representation ability, we thus develop more representable unimodal likelihood models, including the most representable one. OR experiments in this study showed that the developed more representable unimodal likelihood models could yield better generalization performance for real-world ordinal data compared with previous unimodal likelihood models and popular statistical OR models having no unimodality guarantee",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryoya Yamasaki"
    ]
  },
  "https://openreview.net/forum?id=DijnKziche": {
    "title": "Differentiable Model Compression via Pseudo Quantization Noise",
    "volume": "main",
    "abstract": "We propose DiffQ a differentiable method for model compression for quantizing model parameters without gradient approximations (e.g., Straight Through Estimator). We suggest adding independent pseudo quantization noise to model parameters during training to approximate the effect of a quantization operator. DiffQ is differentiable both with respect to the unquantized weights and the number of bits used. Given a single hyper-parameter balancing between the quantized model size and accuracy, DiffQ optimizes the number of bits used per individual weight or groups of weights, in end-to-end training. We experimentally verify that our method is competitive with STE based quantization techniques on several benchmarks and architectures for image classification, language modeling, and audio source separation. For instance, on the ImageNet dataset, DiffQ compresses a 12 layers transformer-based model by more than a factor of 8, (lower than 4 bits precision per weight on average), with a loss of 0.3\\% in model accuracy. Code is available at github.com/facebookresearch/diffq",
    "checked": true,
    "id": "138d7ee8cc618e7b365bda6d8a8f4e6cb85a0c37",
    "semantic_title": "differentiable model compression via pseudo quantization noise",
    "citation_count": 50,
    "authors": [
      "Alexandre D√©fossez",
      "Yossi Adi",
      "Gabriel Synnaeve"
    ]
  },
  "https://openreview.net/forum?id=Zxm0kNe3u7": {
    "title": "Mace: A flexible framework for membership privacy estimation in generative models",
    "volume": "main",
    "abstract": "Generative machine learning models are being increasingly viewed as a way to share sensitive data between institutions. While there has been work on developing differentially private generative modeling approaches, these approaches generally lead to sub-par sample quality, limiting their use in real world applications. Another line of work has focused on developing generative models which lead to higher quality samples but currently lack any formal privacy guarantees. In this work, we propose the first formal framework for membership privacy estimation in generative models. We formulate the membership privacy risk as a statistical divergence between training samples and hold-out samples, and propose sample-based methods to estimate this divergence. Compared to previous works, our framework makes more realistic and flexible assumptions. First, we offer a generalizable metric as an alternative to the accuracy metric (Yeom et al., 2018; Hayes et al., 2019) especially for imbalanced datasets. Second, we loosen the assumption of having full access to the underlying distribution from previous studies (Yeom et al., 2018; Jayaraman et al., 2020), and propose sample-based estimations with theoretical guarantees. Third, along with the population-level membership privacy risk estimation via the optimal membership advantage, we offer the individual-level estimation via the individual privacy risk. Fourth, our framework allows adversaries to access the trained model via a customized query, while prior works require specific attributes (Hayes et al., 2019; Chen et al., 2019; Hilprecht et al., 2019)",
    "checked": true,
    "id": "00fa213314d8e7ee20201a051c3293c16ff549f9",
    "semantic_title": "mace: a flexible framework for membership privacy estimation in generative models",
    "citation_count": 11,
    "authors": [
      "Yixi Xu",
      "Sumit Mukherjee",
      "Xiyang Liu",
      "Shruti Tople",
      "Rahul M Dodhia",
      "Juan M Lavista Ferres"
    ]
  },
  "https://openreview.net/forum?id=Jj0qSbtwdb": {
    "title": "Fingerprints of Super Resolution Networks",
    "volume": "main",
    "abstract": "Several recent studies have demonstrated that deep-learning based image generation models, such as GANs, can be uniquely identified, and possibly even reverse-engineered, by the fingerprints they leave on their output images. We extend this research to single image super-resolution (SISR) networks. Compared to previously studied models, SISR networks are a uniquely challenging class of image generation model from which to extract and analyze fingerprints, as they can often generate images that closely match the corresponding ground truth and thus likely leave little flexibility to embed signatures. We take SISR models as examples to investigate if the findings from the previous work on fingerprints of GAN-based networks are valid for general image generation models. We show that SISR networks with a high upscaling factor or trained using adversarial loss leave highly distinctive fingerprints, and that under certain conditions, some SISR network hyperparameters can be reverse-engineered from these fingerprints",
    "checked": false,
    "id": "4495d0cac49a1c86eff7b7ea3b2898bf2aa19846",
    "semantic_title": "a novel fingerprint image enhancement based on super resolution",
    "citation_count": 8,
    "authors": [
      "Jeremy Vonderfecht",
      "Feng Liu"
    ]
  },
  "https://openreview.net/forum?id=rrMK6hYNSx": {
    "title": "Online Double Oracle",
    "volume": "main",
    "abstract": "Solving strategic games with huge action spaces is a critical yet under-explored topic in economics, operations research and artificial intelligence. This paper proposes new learning algorithms for solving two-player zero-sum normal-form games where the number of pure strategies is prohibitively large. Specifically, we combine no-regret analysis from online learning with Double Oracle (DO) from game theory. Our method---\\emph{Online Double Oracle (ODO)}---is provably convergent to a Nash equilibrium (NE). Most importantly, unlike normal DO, ODO is \\emph{rational} in the sense that each agent in ODO can exploit a strategic adversary with a regret bound of $\\mathcal{O}(\\sqrt{ k \\log(k)/T})$, where $k$ is not the total number of pure strategies, but rather the size of \\emph{effective strategy set}. In many applications, we empirically show that $k$ is linearly dependent on the support size of the NE. On tens of different real-world matrix games, ODO outperforms DO, PSRO, and no-regret algorithms such as Multiplicative Weights Update by a significant margin, both in terms of convergence rate to a NE, and average payoff against strategic adversaries",
    "checked": true,
    "id": "0578a754cc0066347817071c2ce4cfb8695c673a",
    "semantic_title": "online double oracle",
    "citation_count": 32,
    "authors": [
      "Le Cong Dinh",
      "Stephen Marcus McAleer",
      "Zheng Tian",
      "Nicolas Perez-Nieves",
      "Oliver Slumbers",
      "David Henry Mguni",
      "Jun Wang",
      "Haitham Bou Ammar",
      "Yaodong Yang"
    ]
  },
  "https://openreview.net/forum?id=nmFczdJtc2": {
    "title": "Attribute Prediction as Multiple Instance Learning",
    "volume": "main",
    "abstract": "Attribute-based representations help machine learning models perform tasks based on human understandable concepts, allowing a closer human-machine collaboration. However, learning attributes that accurately reflect the content of an image is not always straightforward, as per-image ground truth attributes are often not available. We propose applying the Multiple Instance Learning (MIL) paradigm to attribute learning (AMIL) while only using class-level labels. We allow the model to under-predict the positive attributes, which may be missing in a particular image due to occlusions or unfavorable pose, but not to over-predict the negative ones, which are almost certainly not present. We evaluate it in the zero-shot learning (ZSL) setting, where training and test classes are disjoint, and show that this also allows to profit from knowledge about the semantic relatedness of attributes. In addition, we apply the MIL assumption to ZSL classification and propose MIL-DAP, an attribute-based zero-shot classification method, based on Direct Attribute Prediction (DAP), to evaluate attribute prediction methods when no image-level data is available for evaluation. Experiments on CUB-200-2011, SUN Attributes and AwA2 show improvements on attribute detection, attribute-based zero-shot classification and weakly supervised part localization",
    "checked": true,
    "id": "a941749e380ebc689fd1744ea563cddb6cb07d3f",
    "semantic_title": "attribute prediction as multiple instance learning",
    "citation_count": 2,
    "authors": [
      "Diego Marcos",
      "Aike Potze",
      "Wenjia Xu",
      "Devis Tuia",
      "Zeynep Akata"
    ]
  },
  "https://openreview.net/forum?id=4N6T6Rop6k": {
    "title": "Completeness and Coherence Learning for Fast Arbitrary Style Transfer",
    "volume": "main",
    "abstract": "Style transfer methods put a premium on two objectives: (1) completeness which encourages the encoding of a complete set of style patterns; (2) coherence which discourages the production of spurious artifacts not found in input styles. While existing methods pursue the two objectives either partially or implicitly, we present the Completeness and Coherence Network (CCNet) which jointly learns completeness and coherence components and rejects their incompatibility, both in an explicit manner. Specifically, we develop an attention mechanism integrated with bi-directional softmax operations for explicit imposition of the two objectives and for their collaborative modelling. We also propose CCLoss as a quantitative measure for evaluating the quality of a stylized image in terms of completeness and coherence. Through an empirical evaluation, we demonstrate that compared with existing methods, our method strikes a better tradeoff between computation costs, generalization ability and stylization quality",
    "checked": true,
    "id": "77c9e6e427f8e7ee9fb3c780c13466390c74a952",
    "semantic_title": "completeness and coherence learning for fast arbitrary style transfer",
    "citation_count": 2,
    "authors": [
      "Zhijie Wu",
      "Chunjin Song",
      "Guanxiong Chen",
      "Sheng Guo",
      "Weilin Huang"
    ]
  },
  "https://openreview.net/forum?id=gvSHaaD2wQ": {
    "title": "sigmoidF1: A Smooth F1 Score Surrogate Loss for Multilabel Classification",
    "volume": "main",
    "abstract": "Multilabel classification is the task of attributing multiple labels to examples via predictions. Current models formulate a reduction of the multilabel setting into either multiple binary classifications or multiclass classification, allowing for the use of existing loss functions (sigmoid, cross-entropy, logistic, etc.). These multilabel classification reductions do not accommodate for the prediction of varying numbers of labels per example. Moreover, the loss functions are distant estimates of the performance metrics. We propose sigmoidF1, a loss function that is an approximation of the F1 score that (i) is smooth and tractable for stochastic gradient descent, (ii) naturally approximates a multilabel metric, and (iii) estimates both label suitability and label counts. We show that any confusion matrix metric can be formulated with a smooth surrogate. We evaluate the proposed loss function on text and image datasets, and with a variety of metrics, to account for the complexity of multilabel classification evaluation. sigmoidF1 outperforms other loss functions on one text and two image datasets over several metrics. These results show the effectiveness of using inference-time metrics as loss functions for non-trivial classification problems like multilabel classification",
    "checked": true,
    "id": "29848114ee52606094de50d2634909cfe15adaec",
    "semantic_title": "sigmoidf1: a smooth f1 score surrogate loss for multilabel classification",
    "citation_count": 33,
    "authors": [
      "Gabriel B√©n√©dict",
      "Hendrik Vincent Koops",
      "Daan Odijk",
      "Maarten de Rijke"
    ]
  },
  "https://openreview.net/forum?id=XsPopigZXV": {
    "title": "FLEA: Provably Robust Fair Multisource Learning from Unreliable Training Data",
    "volume": "main",
    "abstract": "Fairness-aware learning aims at constructing classifiers that not only make accurate predictions, but also do not discriminate against specific groups. It is a fast-growing area of machine learning with far-reaching societal impact. However, existing fair learning methods are vulnerable to accidental or malicious artifacts in the training data, which can cause them to unknowingly produce unfair classifiers. In this work we address the problem of fair learning from unreliable training data in the robust multisource setting, where the available training data comes from multiple sources, a fraction of which might not be representative of the true data distribution. We introduce FLEA, a filtering-based algorithm that identifies and suppresses those data sources that would have a negative impact on fairness or accuracy if they were used for training. As such, FLEA is not a replacement of prior fairness-aware learning methods but rather an augmentation that makes any of them robust against unreliable training data. We show the effectiveness of our approach by a diverse range of experiments on multiple datasets. Additionally, we prove formally that ‚Äìgiven enough data‚Äì FLEA protects the learner against corruptions as long as the fraction of affected data sources is less than half. Our source code and documentation are available at https://github.com/ISTAustria-CVML/FLEA",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eugenia Iofinova",
      "Nikola Konstantinov",
      "Christoph H Lampert"
    ]
  },
  "https://openreview.net/forum?id=u8tvSxm4Bs": {
    "title": "GemNet-OC: Developing Graph Neural Networks for Large and Diverse Molecular Simulation Datasets",
    "volume": "main",
    "abstract": "Recent years have seen the advent of molecular simulation datasets that are orders of magnitude larger and more diverse. These new datasets differ substantially in four aspects of complexity: 1. Chemical diversity (number of different elements), 2. system size (number of atoms per sample), 3. dataset size (number of data samples), and 4. domain shift (similarity of the training and test set). Despite these large differences, benchmarks on small and narrow datasets remain the predominant method of demonstrating progress in graph neural networks (GNNs) for molecular simulation, likely due to cheaper training compute requirements. This raises the question -- does GNN progress on small and narrow datasets translate to these more complex datasets? This work investigates this question by first developing the GemNet-OC model based on the large Open Catalyst 2020 (OC20) dataset. GemNet-OC outperforms the previous state-of-the-art on OC20 by 16% while reducing training time by a factor of 10. We then compare the impact of 18 model components and hyperparameter choices on performance in multiple datasets. We find that the resulting model would be drastically different depending on the dataset used for making model choices. To isolate the source of this discrepancy we study six subsets of the OC20 dataset that individually test each of the above-mentioned four dataset aspects. We find that results on the OC-2M subset correlate well with the full OC20 dataset while being substantially cheaper to train on. Our findings challenge the common practice of developing GNNs solely on small datasets, but highlight ways of achieving fast development cycles and generalizable results via moderately-sized, representative datasets such as OC-2M and efficient models such as GemNet-OC. Our code and pretrained model weights are open-sourced",
    "checked": true,
    "id": "aed45120bd674b9c801def63c25577de76348285",
    "semantic_title": "gemnet-oc: developing graph neural networks for large and diverse molecular simulation datasets",
    "citation_count": 70,
    "authors": [
      "Johannes Gasteiger",
      "Muhammed Shuaibi",
      "Anuroop Sriram",
      "Stephan G√ºnnemann",
      "Zachary Ward Ulissi",
      "C. Lawrence Zitnick",
      "Abhishek Das"
    ]
  },
  "https://openreview.net/forum?id=tqDhrbKJLS": {
    "title": "MixTailor: Mixed Gradient Aggregation for Robust Learning Against Tailored Attacks",
    "volume": "main",
    "abstract": "Implementations of SGD on distributed and multi-GPU systems creates new vulnerabilities, which can be identified and misused by one or more adversarial agents. Recently, it has been shown that well-known Byzantine-resilient gradient aggregation schemes are indeed vulnerable to informed attackers that can tailor the attacks (Fang et al., 2020; Xie et al., 2020b). We introduce MixTailor, a scheme based on randomization of the aggregation strategies that makes it impossible for the attacker to be fully informed. Deterministic schemes can be integrated into MixTailor on the fly without introducing any additional hyperparameters. Randomization decreases the capability of a powerful adversary to tailor its attacks, while the resulting randomized aggregation scheme is still competitive in terms of performance. For both iid and non-iid settings, we establish almost sure convergence guarantees that are both stronger and more general than those available in the literature. Our empirical studies across various datasets, attacks, and settings, validate our hypothesis and show that MixTailor successfully defends when well-known Byzantine-tolerant schemes fail",
    "checked": true,
    "id": "d5ac48b67e111766864cff438dc7fce4923d0f71",
    "semantic_title": "mixtailor: mixed gradient aggregation for robust learning against tailored attacks",
    "citation_count": 6,
    "authors": [
      "Ali Ramezani-Kebrya",
      "Iman Tabrizian",
      "Fartash Faghri",
      "Petar Popovski"
    ]
  },
  "https://openreview.net/forum?id=S8eABAy8P3": {
    "title": "LIMIS: Locally Interpretable Modeling using Instance-wise Subsampling",
    "volume": "main",
    "abstract": "Understanding black-box machine learning models is crucial for their widespread adoption. Learning globally interpretable models is one approach, but achieving high performance with them is challenging. An alternative approach is to explain individual predictions using locally interpretable models. For locally interpretable modeling, various methods have been proposed and indeed commonly used, but they suffer from low fidelity, i.e. their explanations do not approximate the predictions well. In this paper, our goal is to push the state-of-the-art in high-fidelity locally interpretable modeling. We propose a novel framework, Locally Interpretable Modeling using Instance-wise Subsampling (LIMIS). LIMIS utilizes a policy gradient to select a small number of instances and distills the black-box model into a low-capacity locally interpretable model using those selected instances. Training is guided with a reward obtained directly by measuring the fidelity of the locally interpretable models. We show on multiple tabular datasets that LIMIS near-matches the prediction accuracy of black-box models, significantly outperforming state-of-the-art locally interpretable models in terms of fidelity and prediction accuracy",
    "checked": false,
    "id": "d19ed42fd63f6d09a7d9dd8ab9f025943fd0c823",
    "semantic_title": "select wisely and explain: active learning and probabilistic local post-hoc explainability",
    "citation_count": 13,
    "authors": [
      "Jinsung Yoon",
      "Sercan O Arik",
      "Tomas Pfister"
    ]
  },
  "https://openreview.net/forum?id=Lgs5pQ1v30": {
    "title": "FedShuffle: Recipes for Better Use of Local Work in Federated Learning",
    "volume": "main",
    "abstract": "The practice of applying several local updates before aggregation across clients has been empirically shown to be a successful approach to overcoming the communication bottleneck in Federated Learning (FL). Such methods are usually implemented by having clients perform one or more epochs of local training per round while randomly reshuffling their finite dataset in each epoch. Data imbalance, where clients have different numbers of local training samples, is ubiquitous in FL applications, resulting in different clients performing different numbers of local updates in each round. In this work, we propose a general recipe, FedShuffle, that better utilizes the local updates in FL, especially in this regime encompassing random reshuffling and heterogeneity. FedShuffle is the first local update method with theoretical convergence guarantees that incorporates random reshuffling, data imbalance, and client sampling ‚Äî features that are essential in large-scale cross-device FL. We present a comprehensive theoretical analysis of FedShuffle and show, both theoretically and empirically, that it does not suffer from the objective function mismatch that is present in FL methods that assume homogeneous updates in heterogeneous FL setups, such as FedAvg (McMahan et al., 2017). In addition, by combining the ingredients above, FedShuffle improves upon FedNova (Wang et al., 2020), which was previously proposed to solve this mismatch. Similar to Mime (Karimireddy et al., 2020), we show that FedShuffle with momentum variance reduction (Cutkosky & Orabona, 2019) improves upon non-local methods under a Hessian similarity assumption",
    "checked": true,
    "id": "1f571c8b972540370b6fb9b48564fd2d8069901f",
    "semantic_title": "fedshuffle: recipes for better use of local work in federated learning",
    "citation_count": 21,
    "authors": [
      "Samuel Horv√°th",
      "Maziar Sanjabi",
      "Lin Xiao",
      "Peter Richt√°rik",
      "Michael Rabbat"
    ]
  },
  "https://openreview.net/forum?id=OslAMMF4ZP": {
    "title": "Faking Interpolation Until You Make It",
    "volume": "main",
    "abstract": "Deep over-parameterized neural networks exhibit the interpolation property on many data sets. Specifically, these models can achieve approximately zero loss on all training samples simultaneously. This property has been exploited to develop optimisation algorithms for this setting. These algorithms use the fact that the optimal loss value is known to employ a variation of a Polyak step size calculated on each stochastic batch of data. We introduce a novel extension of this idea to tasks where the interpolation property does not hold. As we no longer have access to the optimal loss values a priori, we instead estimate them for each sample online. To realise this, we introduce a simple but highly effective heuristic for approximating the optimal value based on previous loss evaluations. We provide rigorous experimentation on a range of problems. From our empirical analysis we demonstrate the effectiveness of our approach, which outperforms other single hyperparameter optimisation methods",
    "checked": true,
    "id": "987deac4428d901f806748a23b7a356b2a3e7f33",
    "semantic_title": "faking interpolation until you make it",
    "citation_count": 0,
    "authors": [
      "Alasdair Paren",
      "Rudra P. K. Poudel",
      "M. Pawan Kumar"
    ]
  },
  "https://openreview.net/forum?id=lIOQFVncY9": {
    "title": "Ensembles of Classifiers: a Bias-Variance Perspective",
    "volume": "main",
    "abstract": "Ensembles are a straightforward, remarkably effective method for improving the accuracy, calibration, and robustness of neural networks on classification tasks. Yet, the reasons underlying their success remain an active area of research. Building upon (Pfau, 2013), we turn to the bias-variance decomposition of Bregman divergences in order to gain insight into the behavior of ensembles under classification losses. Introducing a dual reparameterization of the bias-variance decomposition, we first derive generalized laws of total expectation and variance, then discuss how bias and variance terms can be estimated empirically. Next, we show that the dual reparameterization naturally introduces a way of constructing ensembles which reduces the variance and leaves the bias unchanged. Conversely, we show that ensembles that directly average model outputs can arbitrarily increase or decrease the bias. Empirically, we see that such ensembles of neural networks may reduce the bias. We conclude with an empirical analysis of ensembles over neural network architecture hyperparameters, revealing that these techniques allow for more efficient bias reduction than standard ensembles",
    "checked": true,
    "id": "852a9f09e898c79a9f1b5c8323a5931aa5e9f2dd",
    "semantic_title": "ensembles of classifiers: a bias-variance perspective",
    "citation_count": 10,
    "authors": [
      "Neha Gupta",
      "Jamie Smith",
      "Ben Adlam",
      "Zelda E Mariet"
    ]
  },
  "https://openreview.net/forum?id=LSAAlS7Yts": {
    "title": "GFNet: Geometric Flow Network for 3D Point Cloud Semantic Segmentation",
    "volume": "main",
    "abstract": "Point cloud semantic segmentation from projected views, such as range-view (RV) and bird's-eye-view (BEV), has been intensively investigated. Different views capture different information of point clouds and thus are complementary to each other. However, recent projection-based methods for point cloud semantic segmentation usually utilize a vanilla late fusion strategy for the predictions of different views, failing to explore the complementary information from a geometric perspective during the representation learning. In this paper, we introduce a geometric flow network (GFNet) to explore the geometric correspondence between different views in an align-before-fuse manner. Specifically, we devise a novel geometric flow module (GFM) to bidirectionally align and propagate the complementary information across different views according to geometric relationships under the end-to-end learning scheme. We perform extensive experiments on two widely used benchmark datasets, SemanticKITTI and nuScenes, to demonstrate the effectiveness of our GFNet for project-based point cloud semantic segmentation. Concretely, GFNet not only significantly boosts the performance of each individual view but also achieves state-of-the-art results over all existing projection-based models. Code is available at \\url{https://github.com/haibo-qiu/GFNet}",
    "checked": true,
    "id": "0323d48ee0f1194e34a115bac15cc75db4c1e7ca",
    "semantic_title": "gfnet: geometric flow network for 3d point cloud semantic segmentation",
    "citation_count": 38,
    "authors": [
      "Haibo Qiu",
      "Baosheng Yu",
      "Dacheng Tao"
    ]
  },
  "https://openreview.net/forum?id=tPMQ6Je2rB": {
    "title": "Deep Learning for Bayesian Optimization of Scientific Problems with High-Dimensional Structure",
    "volume": "main",
    "abstract": "Bayesian optimization (BO) is a popular paradigm for global optimization of expensive black-box functions, but there are many domains where the function is not completely a black-box. The data may have some known structure (e.g.\\ symmetries) and/or the data generation process may be a composite process that yields useful intermediate or auxiliary information in addition to the value of the optimization objective. However, surrogate models traditionally employed in BO, such as Gaussian Processes (GPs), scale poorly with dataset size and do not easily accommodate known structure. Instead, we use Bayesian neural networks, a class of scalable and flexible surrogate models with inductive biases, to extend BO to complex, structured problems with high dimensionality. We demonstrate BO on a number of realistic problems in physics and chemistry, including topology optimization of photonic crystal materials using convolutional neural networks, and chemical property optimization of molecules using graph neural networks. On these complex tasks, we show that neural networks often outperform GPs as surrogate models for BO in terms of both sampling efficiency and computational cost",
    "checked": true,
    "id": "9b437a86c4cd410b035754741b48ee7ad42730f4",
    "semantic_title": "deep learning for bayesian optimization of scientific problems with high-dimensional structure",
    "citation_count": 17,
    "authors": [
      "Samuel Kim",
      "Peter Y Lu",
      "Charlotte Loh",
      "Jamie Smith",
      "Jasper Snoek",
      "Marin Soljacic"
    ]
  },
  "https://openreview.net/forum?id=6qMKztPn0n": {
    "title": "Evolving Decomposed Plasticity Rules for Information-Bottlenecked Meta-Learning",
    "volume": "main",
    "abstract": "Artificial neural networks (ANNs) are typically confined to accomplishing pre-defined tasks by learning a set of static parameters. In contrast, biological neural networks (BNNs) can adapt to various new tasks by continually updating the neural connections based on the inputs, which is aligned with the paradigm of learning effective learning rules in addition to static parameters, \\textit{e.g.}, meta-learning. Among various biologically inspired learning rules, Hebbian plasticity updates the neural network weights using local signals without the guide of an explicit target function, thus enabling an agent to learn automatically without human efforts. However, typical plastic ANNs using a large amount of meta-parameters violate the nature of the genomics bottleneck and potentially deteriorate the generalization capacity. This work proposes a new learning paradigm decomposing those connection-dependent plasticity rules into neuron-dependent rules thus accommodating $\\Theta(n^2)$ learnable parameters with only $\\Theta(n)$ meta-parameters. We also thoroughly study the effect of different neural modulation on plasticity. Our algorithms are tested in challenging random 2D maze environments, where the agents have to use their past experiences to shape the neural connections and improve their performances for the future. The results of our experiment validate the following: 1. Plasticity can be adopted to continually update a randomly initialized RNN to surpass pre-trained, more sophisticated recurrent models, especially when coming to long-term memorization. 2. Following the genomics bottleneck, the proposed decomposed plasticity can be comparable to or even more effective than canonical plasticity rules in some instances",
    "checked": true,
    "id": "5eddbfa1aa76b3a9210e754df050887f78f167f8",
    "semantic_title": "evolving decomposed plasticity rules for information-bottlenecked meta-learning",
    "citation_count": 3,
    "authors": [
      "Fan Wang",
      "Hao Tian",
      "Haoyi Xiong",
      "Hua Wu",
      "Jie Fu",
      "Yang Cao",
      "Yu Kang",
      "Haifeng Wang"
    ]
  },
  "https://openreview.net/forum?id=zwRX9kkKzj": {
    "title": "Multitask Online Mirror Descent",
    "volume": "main",
    "abstract": "We introduce and analyze MT-OMD, a multitask generalization of Online Mirror Descent (OMD) which operates by sharing updates between tasks. We prove that the regret of MT-OMD is of order $\\sqrt{1 + \\sigma^2(N-1)}\\sqrt{T}$, where $\\sigma^2$ is the task variance according to the geometry induced by the regularizer, $N$ is the number of tasks, and $T$ is the time horizon. Whenever tasks are similar, that is $\\sigma^2 \\le 1$, our method improves upon the $\\sqrt{NT}$ bound obtained by running independent OMDs on each task. We further provide a matching lower bound, and show that our multitask extensions of Online Gradient Descent and Exponentiated Gradient, two major instances of OMD, enjoy closed-form updates, making them easy to use in practice. Finally, we present experiments which support our theoretical findings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicol√≤ Cesa-Bianchi",
      "Pierre Laforgue",
      "Andrea Paudice",
      "Massimiliano Pontil"
    ]
  },
  "https://openreview.net/forum?id=Ig82l87ZVU": {
    "title": "Approximating 1-Wasserstein Distance with Trees",
    "volume": "main",
    "abstract": "The Wasserstein distance, which measures the discrepancy between distributions, shows efficacy in various types of natural language processing and computer vision applications. One of the challenges in estimating the Wasserstein distance is that it is computationally expensive and does not scale well for many distribution-comparison tasks. In this study, we aim to approximate the 1-Wasserstein distance by the tree-Wasserstein distance (TWD), where the TWD is a 1-Wasserstein distance with tree-based embedding that can be computed in linear time with respect to the number of nodes on a tree. More specifically, we propose a simple yet efficient L1-regularized approach for learning the weights of edges in a tree. To this end, we first demonstrate that the 1-Wasserstein approximation problem can be formulated as a distance approximation problem using the shortest path distance on a tree. We then show that the shortest path distance can be represented by a linear model and formulated as a Lasso-based regression problem. Owing to the convex formulation, we can efficiently obtain a globally optimal solution. We also propose a tree-sliced variant of these methods. Through experiments, we demonstrate that the TWD can accurately approximate the original 1-Wasserstein distance by using the weight estimation technique. Our code can be found in the GitHub repository",
    "checked": true,
    "id": "95d7b8ad43bce4a75988a9f1645f2eb39acf7253",
    "semantic_title": "approximating 1-wasserstein distance with trees",
    "citation_count": 9,
    "authors": [
      "Makoto Yamada",
      "Yuki Takezawa",
      "Ryoma Sato",
      "Han Bao",
      "Zornitsa Kozareva",
      "Sujith Ravi"
    ]
  },
  "https://openreview.net/forum?id=u0n1chY0b6": {
    "title": "Learning Accurate Decision Trees with Bandit Feedback via Quantized Gradient Descent",
    "volume": "main",
    "abstract": "Decision trees provide a rich family of highly non-linear but efficient models, due to which they continue to be the go-to family of predictive models by practitioners across domains. But learning trees is challenging due to their discrete decision boundaries. The state-of-the-art (SOTA) techniques resort to (a) learning soft trees thereby losing logarithmic inference time; or (b) using methods tailored to specific supervised learning settings, requiring access to labeled examples and loss function. In this work, by leveraging techniques like overparameterization and straight-through estimators, we propose a unified method that enables accurate end-to-end gradient based tree training and can be deployed in a variety of settings like offline supervised learning and online learning with bandit feedback. Using extensive validation on standard benchmarks, we demonstrate that our method provides best of both worlds, i.e., it is competitive to, and in some cases more accurate than methods designed specifically for the supervised settings; and in bandit settings, where most existing tree learning techniques are not applicable, our models are still accurate and significantly outperform the applicable SOTA methods",
    "checked": true,
    "id": "de4a65f06327ccb1859149b60523fe31c1f2506e",
    "semantic_title": "learning accurate decision trees with bandit feedback via quantized gradient descent",
    "citation_count": 13,
    "authors": [
      "Ajaykrishna Karthikeyan",
      "Naman Jain",
      "Nagarajan Natarajan",
      "Prateek Jain"
    ]
  },
  "https://openreview.net/forum?id=AEoYjvjKVA": {
    "title": "Probabilistic Autoencoder",
    "volume": "main",
    "abstract": "Principal Component Analysis (PCA) minimizes the reconstruction error given a class of linear models of fixed component dimensionality. Probabilistic PCA adds a probabilistic structure by learning the probability distribution of the PCA latent space weights, thus creating a generative model. Autoencoders (AE) minimize the reconstruction error in a class of nonlinear models of fixed latent space dimensionality and outperform PCA at fixed dimensionality. Here, we introduce the Probabilistic Autoencoder (PAE) that learns the probability distribution of the AE latent space weights using a normalizing flow (NF). The PAE is fast and easy to train and achieves small reconstruction errors, high sample quality, and good performance in downstream tasks. We compare the PAE to Variational AE (VAE), showing that the PAE trains faster, reaches a lower reconstruction error, and produces good sample quality without requiring special tuning parameters or training procedures. We further demonstrate that the PAE is a powerful model for performing the downstream tasks of probabilistic image reconstruction in the context of Bayesian inference of inverse problems for inpainting and denoising applications. Finally, we identify latent space density from NF as a promising outlier detection metric",
    "checked": false,
    "id": "033032b0d5a36561f0a804bbb3051537745642d6",
    "semantic_title": "vanilla probabilistic autoencoder",
    "citation_count": 1,
    "authors": [
      "Vanessa M Boehm",
      "Uros Seljak"
    ]
  },
  "https://openreview.net/forum?id=D3WI0QG7dC": {
    "title": "Decoder Denoising Pretraining for Semantic Segmentation",
    "volume": "main",
    "abstract": "Semantic segmentation labels are expensive and time consuming to acquire. Hence, pretraining is commonly used to improve the label-efficiency of segmentation models. Typically, the encoder of a segmentation model is pretrained as a classifier and the decoder is randomly initialized. Here, we argue that random initialization of the decoder can be suboptimal, especially when few labeled examples are available. We propose a decoder pretraining approach based on denoising, which can be combined with supervised pretraining of the encoder. We find that decoder denoising pretraining on the ImageNet dataset strongly outperforms encoder-only supervised pretraining. Despite its simplicity, decoder denoising pretraining achieves state-of-the-art results on label-efficient semantic segmentation and offers considerable gains on the Cityscapes, Pascal Context, and ADE20K datasets",
    "checked": true,
    "id": "868f052bf099692d4d188675488b21dce35fdd07",
    "semantic_title": "decoder denoising pretraining for semantic segmentation",
    "citation_count": 27,
    "authors": [
      "Emmanuel Asiedu Brempong",
      "Simon Kornblith",
      "Ting Chen",
      "Niki Parmar",
      "Matthias Minderer",
      "Mohammad Norouzi"
    ]
  },
  "https://openreview.net/forum?id=JL6MU9XFzW": {
    "title": "Can You Win Everything with A Lottery Ticket?",
    "volume": "main",
    "abstract": "$\\textit{Lottery ticket hypothesis}$ (LTH) has demonstrated to yield independently trainable and highly sparse neural networks (a.k.a. $\\textit{winning tickets}$), whose test set accuracies can be surprisingly on par or even better than dense models. However, accuracy is far from the only evaluation metric, and perhaps not always the most important one. Hence it might be myopic to conclude that a sparse subnetwork can replace its dense counterpart, even if the accuracy is preserved. Spurred by that, we perform the first comprehensive assessment of lottery tickets from diverse aspects beyond test accuracy, including $\\textit{(i)}$ generalization to distribution shifts, $\\textit{(ii)}$ prediction uncertainty, $\\textit{(iii)}$ interpretability, and $\\textit{(iv)}$ geometry of loss landscapes. With extensive experiments across datasets {CIFAR-10, CIFAR-100, and ImageNet}, model architectures, as well as tens of sparsification methods, we thoroughly characterize the trade-off between model sparsity and the all-dimension model capabilities. We find that an appropriate sparsity (e.g., $20\\%\\sim99.08\\%$) can yield the winning ticket to perform comparably or even better $\\textbf{in all above four aspects}$, although some aspects (generalization to certain distribution shifts, and uncertainty) appear more sensitive to the sparsification than others. We term it as a $\\texttt{LTH-PASS}$. Overall, our results endorse choosing a good sparse subnetwork of a larger dense model, over directly training a small dense model of similar parameter counts. We hope that our study can offer more in-depth insights on pruning, for researchers and engineers who seek to incorporate sparse neural networks for user-facing deployments. Codes are available in: https://github.com/VITA-Group/LTH-Pass",
    "checked": true,
    "id": "7c0b26c232b47b8567be1cdf675154d271209cae",
    "semantic_title": "can you win everything with a lottery ticket?",
    "citation_count": 13,
    "authors": [
      "Tianlong Chen",
      "Zhenyu Zhang",
      "Jun Wu",
      "Randy Huang",
      "Sijia Liu",
      "Shiyu Chang",
      "Zhangyang Wang"
    ]
  },
  "https://openreview.net/forum?id=gCmQK6McbR": {
    "title": "HEAT: Hyperedge Attention Networks",
    "volume": "main",
    "abstract": "Learning from structured data is a core machine learning task. Commonly, such data is represented as graphs, which normally only consider (typed) binary relationships between pairs of nodes. This is a substantial limitation for many domains with highly-structured data. One important such domain is source code, where hypergraph-based representations can better capture the semantically rich and structured nature of code. In this work, we present HEAT, a neural model capable of representing typed and qualified hypergraphs, where each hyperedge explicitly qualifies how participating nodes contribute. It can be viewed as a generalization of both message passing neural networks and Transformers. We evaluate HEAT on knowledge base completion and on bug detection and repair using a novel hypergraph representation of programs. In both settings, it outperforms strong baselines, indicating its power and generality",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dobrik Georgiev Georgiev",
      "Marc Brockschmidt",
      "Miltiadis Allamanis"
    ]
  },
  "https://openreview.net/forum?id=t5HkgbxZp1": {
    "title": "On the Near-Optimality of Local Policies in Large Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "We show that in a cooperative $N$-agent network, one can design locally executable policies for the agents such that the resulting discounted sum of average rewards (value) well approximates the optimal value computed over all (including non-local) policies. Specifically, we prove that, if $|\\mathcal{X}|, |\\mathcal{U}|$ denote the size of state, and action spaces of individual agents, then for sufficiently small discount factor, the approximation error is given by $\\mathcal{O}(e)$ where $e\\triangleq \\frac{1}{\\sqrt{N}}\\left[\\sqrt{|\\mathcal{X}|}+\\sqrt{|\\mathcal{U}|}\\right]$. Moreover, in a special case where the reward and state transition functions are independent of the action distribution of the population, the error improves to $\\mathcal{O}(e)$ where $e\\triangleq \\frac{1}{\\sqrt{N}}\\sqrt{|\\mathcal{X}|}$. Finally, we also devise an algorithm to explicitly construct a local policy. With the help of our approximation results, we further establish that the constructed local policy is within $\\mathcal{O}(\\max\\{e,\\epsilon\\})$ distance of the optimal policy, and the sample complexity to achieve such a local policy is $\\mathcal{O}(\\epsilon^{-3})$, for any $\\epsilon>0$",
    "checked": true,
    "id": "7744326ff1fde9c769b8d6cc23449e4c44f6b6f4",
    "semantic_title": "on the near-optimality of local policies in large cooperative multi-agent reinforcement learning",
    "citation_count": 5,
    "authors": [
      "Washim Uddin Mondal",
      "Vaneet Aggarwal",
      "Satish Ukkusuri"
    ]
  },
  "https://openreview.net/forum?id=n3qLz4eL1l": {
    "title": "Exploring Efficient Few-shot Adaptation for Vision Transformers",
    "volume": "main",
    "abstract": "The task of Few-shot Learning (FSL) aims to do the inference on novel categories containing only few labeled examples, with the help of knowledge learned from base categories containing abundant labeled training samples. While there are numerous works into FSL task, Vision Transformers (ViTs) have rarely been taken as the backbone to FSL with few trials focusing on naive finetuning of whole backbone or classification layer. Essentially, despite ViTs have been shown to enjoy comparable or even better performance on other vision tasks, it is still very nontrivial to efficiently finetune the ViTs in real-world FSL scenarios. To this end, we propose a novel efficient Transformer Tuning (eTT) method that facilitates finetuning ViTs in the FSL tasks. The key novelties come from the newly presented Attentive Prefix Tuning (APT) and Domain Residual Adapter (DRA) for the task and backbone finetuning, individually. Specifically, in APT, the prefix is projected to new key and value pairs that are attached to each self-attention layer to provide the model with task-specific information. Moreover, we design the DRA in the form of learnable offset vectors to handle the potential domain gaps between base and novel data. To ensure the APT would not deviate from the initial task-specific information much, we further propose a novel prototypical regularization, which minimizes the similarity between the projected distribution of prefix and initial prototypes, regularizing the update procedure. Our method receives outstanding performance on the challenging Meta-Dataset. We conduct extensive experiments to show the efficacy of our model. Our model and codes will be released",
    "checked": false,
    "id": "af593c53a9221bd12211f78d4f1ebd6b59cc4e7c",
    "semantic_title": "parameter-efficient model adaptation for vision transformers",
    "citation_count": 91,
    "authors": [
      "Chengming Xu",
      "Siqian Yang",
      "Yabiao Wang",
      "Zhanxiong Wang",
      "Yanwei Fu",
      "Xiangyang Xue"
    ]
  },
  "https://openreview.net/forum?id=w3z3sN1b04": {
    "title": "Weight Expansion: A New Perspective on Dropout and Generalization",
    "volume": "main",
    "abstract": "While dropout is known to be a successful regularization technique, insights into the mechanisms that lead to this success are still lacking. We introduce the concept of weight expansion, an increase in the signed volume of a parallelotope spanned by the column or row vectors of the weight covariance matrix, and show that weight expansion is an effective means of increasing the generalization in a PAC-Bayesian setting. We provide a theoretical argument that dropout leads to weight expansion and extensive empirical support for the correlation between dropout and weight expansion. To support our hypothesis that weight expansion can be regarded as an indicator of the enhanced generalization capability endowed by dropout, and not just as a mere by-product, we have studied other methods that achieve weight expansion (resp.\\ contraction), and found that they generally lead to an increased (resp.\\ decreased) generalization ability. This suggests that dropout is an attractive regularizer, because it is a computationally cheap method for obtaining weight expansion. This insight justifies the role of dropout as a regularizer, while paving the way for identifying regularizers that promise improved generalization through weight expansion",
    "checked": true,
    "id": "6d9c42e0a653a13b0dc4881f3e5f874d12a5a0c0",
    "semantic_title": "weight expansion: a new perspective on dropout and generalization",
    "citation_count": 5,
    "authors": [
      "Gaojie Jin",
      "Xinping Yi",
      "Pengfei Yang",
      "Lijun Zhang",
      "Sven Schewe",
      "Xiaowei Huang"
    ]
  },
  "https://openreview.net/forum?id=HjelcW6wio": {
    "title": "Exploring the Learning Mechanisms of Neural Division Modules",
    "volume": "main",
    "abstract": "Of the four fundamental arithmetic operations (+, -, $\\times$, $\\div$), division is considered the most difficult for both humans and computers. In this paper, we show that robustly learning division in a systematic manner remains a challenge even at the simplest level of dividing two numbers. We propose two novel approaches for division which we call the Neural Reciprocal Unit (NRU) and the Neural Multiplicative Reciprocal Unit (NMRU), and present improvements for an existing division module, the Real Neural Power Unit (Real NPU). In total we measure robustness over 475 different training sets for setups with and without input redundancy. We discover robustness is greatly affected by the input sign for the Real NPU and NRU, input magnitude for the NMRU and input distribution for every module. Despite this issue, we show that the modules can learn as part of larger end-to-end networks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bhumika Mistry",
      "Katayoun Farrahi",
      "Jonathon Hare"
    ]
  },
  "https://openreview.net/forum?id=U8uJAUMzj9": {
    "title": "Domain Invariant Adversarial Learning",
    "volume": "main",
    "abstract": "The phenomenon of adversarial examples illustrates one of the most basic vulnerabilities of deep neural networks. Among the variety of techniques introduced to surmount this inherent weakness, adversarial training has emerged as the most effective strategy for learning robust models. Typically, this is achieved by balancing robust and natural objectives. In this work, we aim to further optimize the trade-off between robust and standard accuracy by enforcing a domain-invariant feature representation. We present a new adversarial training method, Domain Invariant Adversarial Learning (DIAL), which learns a feature representation that is both robust and domain invariant. DIAL uses a variant of Domain Adversarial Neural Network (DANN) on the natural domain and its corresponding adversarial domain. In the case where the source domain consists of natural examples and the target domain is the adversarially perturbed examples, our method learns a feature representation constrained not to discriminate between the natural and adversarial examples, and can therefore achieve a more robust representation. DIAL is a generic and modular technique that can be easily incorporated into any adversarial training method. Our experiments indicate that incorporating DIAL in the adversarial training process improves both robustness and standard accuracy",
    "checked": true,
    "id": "3ce0b4d9787cfb91dffca9126b5724f42115c920",
    "semantic_title": "domain invariant adversarial learning",
    "citation_count": 11,
    "authors": [
      "Matan Levi",
      "Idan Attias",
      "Aryeh Kontorovich"
    ]
  },
  "https://openreview.net/forum?id=Su290sknyQ": {
    "title": "Momentum Capsule Networks",
    "volume": "main",
    "abstract": "Capsule networks are a class of neural networks that aim at solving some limiting factors of Convolutional Neural Networks. However, baseline capsule networks have failed to reach state-of-the-art results on more complex datasets due to the high computation and memory requirements. We tackle this problem by proposing a new network architecture, called Momentum Capsule Network (MoCapsNet). MoCapsNets are inspired by Momentum ResNets, a type of network that applies reversible residual building blocks. Reversible networks allow for recalculating activations of the forward pass in the backpropagation algorithm, so those memory requirements can be drastically reduced. In this paper, we provide a framework on how invertible residual building blocks can be applied to capsule networks. We will show that MoCapsNet beats the accuracy of baseline capsule networks on MNIST, SVHN, CIFAR-10 and CIFAR-100 while using considerably less memory. The source code is available on https://github.com/moejoe95/MoCapsNet",
    "checked": true,
    "id": "635e491b570937bc244f0c5796d53cf72844011c",
    "semantic_title": "momentum capsule networks",
    "citation_count": 1,
    "authors": [
      "Josef Gugglberger",
      "Antonio Rodriguez-sanchez",
      "David Peer"
    ]
  },
  "https://openreview.net/forum?id=7j0GI6tPYi": {
    "title": "ANCER: Anisotropic Certification via Sample-wise Volume Maximization",
    "volume": "main",
    "abstract": "Randomized smoothing has recently emerged as an effective tool that enables certification of deep neural network classifiers at scale. All prior art on randomized smoothing has focused on isotropic $\\ell_p$ certification, which has the advantage of yielding certificates that can be easily compared among isotropic methods via $\\ell_p$-norm radius. However, isotropic certification limits the region that can be certified around an input to worst-case adversaries, i.e., it cannot reason about other \"close\", potentially large, constant prediction safe regions. To alleviate this issue, (i) we theoretically extend the isotropic randomized smoothing $\\ell_1$ and $\\ell_2$ certificates to their generalized anisotropic counterparts following a simplified analysis. Moreover, (ii) we propose evaluation metrics allowing for the comparison of general certificates - a certificate is superior to another if it certifies a superset region - with the quantification of each certificate through the volume of the certified region. We introduce ANCER, a framework for obtaining anisotropic certificates for a given test set sample via volume maximization. We achieve it by generalizing memory-based certification of data-dependent classifiers. Our empirical results demonstrate that ANCER achieves state-of-the-art $\\ell_1$ and $\\ell_2$ certified accuracy on CIFAR-10 and ImageNet in the data-dependence setting, while certifying larger regions in terms of volume, highlighting the benefits of moving away from isotropic analysis",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francisco Eiras",
      "Motasem Alfarra",
      "Philip Torr",
      "M. Pawan Kumar",
      "Puneet K. Dokania",
      "Bernard Ghanem",
      "Adel Bibi"
    ]
  },
  "https://openreview.net/forum?id=caRBFhxXIG": {
    "title": "On the Choice of Interpolation Scheme for Neural CDEs",
    "volume": "main",
    "abstract": "Neural controlled differential equations (Neural CDEs) are a continuous-time extension of recurrent neural networks (RNNs), achieving state-of-the-art (SOTA) performance at modelling functions of irregular time series. In order to interpret discrete data in continuous time, current implementations rely on non-causal interpolations of the data. This is fine when the whole time series is observed in advance, but means that Neural CDEs are not suitable for use in \\textit{online prediction tasks}, where predictions need to be made in real-time: a major use case for recurrent networks. Here, we show how this limitation may be rectified. First, we identify several theoretical conditions that control paths for Neural CDEs should satisfy, such as boundedness and uniqueness. Second, we use these to motivate the introduction of new schemes that address these conditions, offering in particular measurability (for online prediction), and smoothness (for speed). Third, we empirically benchmark our online Neural CDE model on three continuous monitoring tasks from the MIMIC-IV medical database: we demonstrate improved performance on all tasks against ODE benchmarks, and on two of the three tasks against SOTA non-ODE benchmarks",
    "checked": true,
    "id": "23e26bf6a6219caa23609c460aa2a3bfcb0b3d7d",
    "semantic_title": "on the choice of interpolation scheme for neural cdes",
    "citation_count": 17,
    "authors": [
      "James Morrill",
      "Patrick Kidger",
      "Lingyi Yang",
      "Terry Lyons"
    ]
  },
  "https://openreview.net/forum?id=8QoxXTDcsH": {
    "title": "Conformal Prediction Intervals with Temporal Dependence",
    "volume": "main",
    "abstract": "Cross-sectional prediction is common in many domains such as healthcare, including forecasting tasks using electronic health records, where different patients form a cross-section. We focus on the task of constructing valid prediction intervals (PIs) in time series regression with a cross-section. A prediction interval is considered valid if it covers the true response with (a pre-specified) high probability. We first distinguish between two notions of validity in such a setting: cross-sectional and longitudinal. Cross-sectional validity is concerned with validity across the cross-section of the time series data, while longitudinal validity accounts for the temporal dimension. Coverage guarantees along both these dimensions are ideally desirable; however, we show that distribution-free longitudinal validity is theoretically impossible. Despite this limitation, we propose Conformal Prediction with Temporal Dependence (CPTD), a procedure that is able to maintain strict cross-sectional validity while improving longitudinal coverage. CPTD is post-hoc and light-weight, and can easily be used in conjunction with any prediction model as long as a calibration set is available. We focus on neural networks due to their ability to model complicated data such as diagnosis codes for time series regression, and perform extensive experimental validation to verify the efficacy of our approach. We find that CPTD outperforms baselines on a variety of datasets by improving longitudinal coverage and often providing more efficient (narrower) PIs",
    "checked": true,
    "id": "fa1dfdac997c62692d670c3cd9169c7871ed6a01",
    "semantic_title": "conformal prediction intervals with temporal dependence",
    "citation_count": 12,
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ]
  },
  "https://openreview.net/forum?id=Cct7kqbHK6": {
    "title": "Meta-Learning Sparse Compression Networks",
    "volume": "main",
    "abstract": "Recent work in Deep Learning has re-imagined the representation of data as functions mapping from a coordinate space to an underlying continuous signal. When such functions are approximated by neural networks this introduces a compelling alternative to the more common multi-dimensional array representation. Recent work on such Implicit Neural Representations(INRs) has shown that - following careful architecture search - INRs can outperform established compression methods such as JPEG (e.g. Dupont et al., 2021). In this paper, we propose crucial steps towards making such ideas scalable: Firstly, we employ state-of-the-art network sparsification techniques to drastically improve compression. Secondly,introduce the first method allowing for sparsification to be employed in the inner-loop of commonly used Meta-Learning algorithms, drastically improving both compression and the computational cost of learning INRs. The generality of this formalism allows us to present results on diverse data modalities such as images, manifolds, signed distance functions, 3D shapes and scenes, several of which establish new state-of-the-art results",
    "checked": true,
    "id": "2270ebe7d3ee925abbc062b937aa43805c702cf9",
    "semantic_title": "meta-learning sparse compression networks",
    "citation_count": 27,
    "authors": [
      "Jonathan Schwarz",
      "Yee Whye Teh"
    ]
  },
  "https://openreview.net/forum?id=q1Fey9feu7": {
    "title": "Estimating Potential Outcome Distributions with Collaborating Causal Networks",
    "volume": "main",
    "abstract": "Traditional causal inference approaches leverage observational study data to estimate the difference in observed (factual) and unobserved (counterfactual) outcomes for a potential treatment, known as the Conditional Average Treatment Effect (CATE). However, CATE corresponds to the comparison on the first moment alone, and as such may be insufficient in reflecting the full picture of treatment effects. As an alternative, estimating the full potential outcome distributions could provide greater insights. However, existing methods for estimating treatment effect potential outcome distributions often impose restrictive or overly-simplistic assumptions about these distributions. Here, we propose Collaborating Causal Networks (CCN), a novel methodology which goes beyond the estimation of CATE alone by learning the full potential outcome distributions. Estimation of outcome distributions via the CCN framework does not require restrictive assumptions of the underlying data generating process (e.g. Gaussian errors). Additionally, our proposed method facilitates estimation of the utility of each possible treatment and permits individual-specific variation through utility functions (e.g. risk tolerance variability). CCN not only extends outcome estimation beyond traditional risk difference, but also enables a more comprehensive decision making process through definition of flexible comparisons. Under assumptions commonly made in the causal inference literature, we show that CCN learns distributions that asymptotically capture the correct potential outcome distributions. Furthermore, we propose an adjustment approach that is empirically effective in alleviating sample imbalance between treatment groups in observational studies. Finally, we evaluate the performance of CCN in multiple experiments on both synthetic and semi-synthetic data. We demonstrate that CCN learns improved distribution estimates compared to existing Bayesian and deep generative methods as well as improved decisions with respects to a variety of utility functions",
    "checked": true,
    "id": "704203c476d4be7aa650f5799d7f69b2569b2e0c",
    "semantic_title": "estimating potential outcome distributions with collaborating causal networks",
    "citation_count": 8,
    "authors": [
      "Tianhui Zhou",
      "William E Carson IV",
      "David Carlson"
    ]
  },
  "https://openreview.net/forum?id=4GuIi1jJ74": {
    "title": "Sparse Coding with Multi-layer Decoders using Variance Regularization",
    "volume": "main",
    "abstract": "Sparse representations of images are useful in many computer vision applications. Sparse coding with an $l_1$ penalty and a learned linear dictionary requires regularization of the dictionary to prevent a collapse in the $l_1$ norms of the codes. Typically, this regularization entails bounding the Euclidean norms of the dictionary's elements. In this work, we propose a novel sparse coding protocol which prevents a collapse in the codes without the need to regularize the decoder. Our method regularizes the codes directly so that each latent code component has variance greater than a fixed threshold over a set of sparse representations for a given set of inputs. Furthermore, we explore ways to effectively train sparse coding systems with multi-layer decoders since they can model more complex relationships than linear dictionaries. In our experiments with MNIST and natural image patches, we show that decoders learned with our approach have interpretable features both in the linear and multi-layer case. Moreover, we show that sparse autoencoders with multi-layer decoders trained using our variance regularization method produce higher quality reconstructions with sparser representations when compared to autoencoders with linear dictionaries. Additionally, sparse representations obtained with our variance regularization approach are useful in the downstream tasks of denoising and classification in the low-data regime",
    "checked": true,
    "id": "6e08acdb27e83a26ef7e67539a11e9cb3588e822",
    "semantic_title": "sparse coding with multi-layer decoders using variance regularization",
    "citation_count": 10,
    "authors": [
      "Katrina Evtimova",
      "Yann LeCun"
    ]
  },
  "https://openreview.net/forum?id=LnjclqBl8R": {
    "title": "Efficient CDF Approximations for Normalizing Flows",
    "volume": "main",
    "abstract": "Normalizing flows model a complex target distribution in terms of a bijective transform operating on a simple base distribution. As such, they enable tractable computation of a number of important statistical quantities, particularly likelihoods and samples. Despite these appealing properties, the computation of more complex inference tasks, such as the cumulative distribution function (CDF) over a complex region (e.g., a polytope) remains challenging. Traditional CDF approximations using Monte-Carlo techniques are unbiased but have unbounded variance and low sample efficiency. Instead, we build upon the diffeomorphic properties of normalizing flows and leverage the divergence theorem to estimate the CDF over a closed region in target space in terms of the flux across its \\emph{boundary}, as induced by the normalizing flow. We describe both deterministic and stochastic instances of this estimator: while the deterministic variant iteratively improves the estimate by strategically subdividing the boundary, the stochastic variant provides unbiased estimates. Our experiments on popular flow architectures and UCI benchmark datasets show a marked improvement in sample efficiency as compared to traditional estimators",
    "checked": true,
    "id": "0de7f09e12d5ea38145d5cf0e91807f911730a49",
    "semantic_title": "efficient cdf approximations for normalizing flows",
    "citation_count": 1,
    "authors": [
      "Chandramouli Shama Sastry",
      "Andreas Lehrmann",
      "Marcus A Brubaker",
      "Alexander Radovic"
    ]
  },
  "https://openreview.net/forum?id=jKN1pXi7b0": {
    "title": "Unsupervised Dense Information Retrieval with Contrastive Learning",
    "volume": "main",
    "abstract": "Recently, information retrieval has seen the emergence of dense retrievers, using neural networks, as an alternative to classical sparse methods based on term-frequency. These models have obtained state-of-the-art results on datasets and tasks where large training sets are available. However, they do not transfer well to new applications with no training data, and are outperformed by unsupervised term-frequency methods such as BM25. In this work, we explore the limits of contrastive learning as a way to train unsupervised dense retrievers and show that it leads to strong performance in various retrieval settings. On the BEIR benchmark our unsupervised model outperforms BM25 on 11 out of 15 datasets for the Recall@100. When used as pre-training before fine-tuning, either on a few thousands in-domain examples or on the large MS~MARCO dataset, our contrastive model leads to improvements on the BEIR benchmark. Finally, we evaluate our approach for multi-lingual retrieval, where training data is even scarcer than for English, and show that our approach leads to strong unsupervised performance. Our model also exhibits strong cross-lingual transfer when fine-tuned on supervised English data only and evaluated on low resources language such as Swahili. We show that our unsupervised models can perform cross-lingual retrieval between different scripts, such as retrieving English documents from Arabic queries, which would not be possible with term matching methods",
    "checked": true,
    "id": "4f4a409f701f7552d45c46a5b0fea69dca6f8e84",
    "semantic_title": "unsupervised dense information retrieval with contrastive learning",
    "citation_count": 929,
    "authors": [
      "Gautier Izacard",
      "Mathilde Caron",
      "Lucas Hosseini",
      "Sebastian Riedel",
      "Piotr Bojanowski",
      "Armand Joulin",
      "Edouard Grave"
    ]
  },
  "https://openreview.net/forum?id=e7mYYMSyZH": {
    "title": "On the Convergence of Shallow Neural Network Training with Randomly Masked Neurons",
    "volume": "main",
    "abstract": "With the motive of training all the parameters of a neural network, we study why and when one can achieve this by iteratively creating, training, and combining randomly selected subnetworks. Such scenarios have either implicitly or explicitly emerged in the recent literature: see e.g., the Dropout family of regularization techniques, or some distributed ML training protocols that reduce communication/computation complexities, such as the Independent Subnet Training protocol. While these methods are studied empirically and utilized in practice, they often enjoy partial or no theoretical support, especially when applied on neural network-based objectives. In this manuscript, our focus is on overparameterized single hidden layer neural networks with ReLU activations in the lazy training regime. By carefully analyzing $i)$ the subnetworks' neural tangent kernel, $ii)$ the surrogate functions' gradient, and $iii)$ how we sample and combine the surrogate functions, we prove linear convergence rate of the training error --up to a neighborhood around the optimal point-- for an overparameterized single-hidden layer perceptron with a regression loss. Our analysis reveals a dependency of the size of the neighborhood around the optimal point on the number of surrogate models and the number of local training steps for each selected subnetwork. Moreover, the considered framework generalizes and provides new insights on dropout training, multi-sample dropout training, as well as Independent Subnet Training; for each case, we provide convergence results as corollaries of our main theorem",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangshuo Liao",
      "Anastasios Kyrillidis"
    ]
  },
  "https://openreview.net/forum?id=Ee277P3AYC": {
    "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models",
    "volume": "main",
    "abstract": "Exploring large-scale pretrained foundation models is of significant interest in computer vision because these models can be quickly transferred to many downstream tasks. This paper presents Contrastive Captioner (CoCa), a minimalist design to pretrain an image-text encoder-decoder foundation model jointly with contrastive loss and captioning loss, thereby subsuming model capabilities from contrastive approaches like CLIP and generative methods like SimVLM. In contrast to standard encoder-decoder transformers where all decoder layers attend to encoder outputs, CoCa omits cross-attention in the first half of decoder layers to encode unimodal text representations, and cascades the remaining decoder layers which cross-attend to the image encoder for multimodal image-text representations. We apply a contrastive loss between unimodal image and text embeddings, in addition to a captioning loss on the multimodal decoder outputs which predicts text tokens autoregressively. By sharing the same computational graph, the two training objectives are computed efficiently with minimal overhead. CoCa is pretrained end-to-end and from scratch on both web-scale alt-text data and annotated images by treating all labels simply as text, seamlessly unifying natural language supervision for representation learning. Empirically, CoCa achieves state-of-the-art performance with zero-shot transfer or minimal task-specific adaptation on a broad range of downstream tasks, spanning visual recognition (ImageNet, Kinetics-400/600/700, Moments-in-Time), crossmodal retrieval (MSCOCO, Flickr30K, MSR-VTT), multimodal understanding (VQA, SNLI-VE, NLVR2), and image captioning (MSCOCO, NoCaps). Notably on ImageNet classification, CoCa obtains 86.3% zero-shot top-1 accuracy, 90.6% with a frozen encoder and learned classification head, and 91.0% with a finetuned encoder",
    "checked": true,
    "id": "a26a7a74f1e5fd562be95c3611a0680759fbdf84",
    "semantic_title": "coca: contrastive captioners are image-text foundation models",
    "citation_count": 1314,
    "authors": [
      "Jiahui Yu",
      "Zirui Wang",
      "Vijay Vasudevan",
      "Legg Yeung",
      "Mojtaba Seyedhosseini",
      "Yonghui Wu"
    ]
  },
  "https://openreview.net/forum?id=TWSTyYd2Rl": {
    "title": "Attentive Walk-Aggregating Graph Neural Networks",
    "volume": "main",
    "abstract": "Graph neural networks (GNNs) have been shown to possess strong representation power, which can be exploited for downstream prediction tasks on graph-structured data, such as molecules and social networks. They typically learn representations by aggregating information from the $K$-hop neighborhood of individual vertices or from the enumerated walks in the graph. Prior studies have demonstrated the effectiveness of incorporating weighting schemes into GNNs; however, this has been primarily limited to $K$-hop neighborhood GNNs so far. In this paper, we aim to design an algorithm incorporating weighting schemes into walk-aggregating GNNs and analyze their effect. We propose a novel GNN model, called {\\AWARE}, that aggregates information about the walks in the graph using attention schemes. This leads to an end-to-end supervised learning method for graph-level prediction tasks in the standard setting where the input is the adjacency and vertex information of a graph, and the output is a predicted label for the graph. We then perform theoretical, empirical, and interpretability analyses of {\\AWARE}. Our theoretical analysis in a simplified setting identifies successful conditions for provable guarantees, demonstrating how the graph information is encoded in the representation, and how the weighting schemes in {\\AWARE} affect the representation and learning performance. Our experiments demonstrate the strong performance of {\\AWARE} in graph-level prediction tasks in the standard setting in the domains of molecular property prediction and social networks. Lastly, our interpretation study illustrates that {\\AWARE} can successfully capture the important substructures of the input graph. The code is available on \\href{https://github.com/mehmetfdemirel/aware}{GitHub}",
    "checked": true,
    "id": "6ab55155b287249376e3c498b238bff2e6ced34a",
    "semantic_title": "attentive walk-aggregating graph neural networks",
    "citation_count": 10,
    "authors": [
      "Mehmet F Demirel",
      "Shengchao Liu",
      "Siddhant Garg",
      "Zhenmei Shi",
      "Yingyu Liang"
    ]
  },
  "https://openreview.net/forum?id=p5V8P2J61u": {
    "title": "Birds of a Feather Trust Together: Knowing When to Trust a Classifier via Adaptive Neighborhood Aggregation",
    "volume": "main",
    "abstract": "How do we know when the predictions made by a classifier can be trusted? This is a fundamental problem that also has immense practical applicability, especially in safety-critical areas such as medicine and autonomous driving. The de facto approach of using the classifier's softmax outputs as a proxy for trustworthiness suffers from the over-confidence issue; while the most recent works incur problems such as additional retraining cost and accuracy versus trustworthiness trade-off. In this work, we argue that the trustworthiness of a classifier's prediction for a sample is highly associated with two factors: the sample's neighborhood information and the classifier's output. To combine the best of both worlds, we design a model-agnostic post-hoc approach NeighborAGG to leverage the two essential information via an adaptive neighborhood aggregation. Theoretically, we show that NeighborAGG is a generalized version of a one-hop graph convolutional network, inheriting the powerful modeling ability to capture the varying similarity between samples within each class. We also extend our approach to the closely related task of mislabel detection and provide a theoretical coverage guarantee to bound the false negative. Empirically, extensive experiments on image and tabular benchmarks verify our theory and suggest that NeighborAGG outperforms other methods, achieving state-of-the-art trustworthiness performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miao Xiong",
      "Shen Li",
      "Wenjie Feng",
      "Ailin Deng",
      "Jihai Zhang",
      "Bryan Hooi"
    ]
  },
  "https://openreview.net/forum?id=8GvRCWKHIL": {
    "title": "Optimal Client Sampling for Federated Learning",
    "volume": "main",
    "abstract": "It is well understood that client-master communication can be a primary bottleneck in federated learning (FL). In this work, we address this issue with a novel client subsampling scheme, where we restrict the number of clients allowed to communicate their updates back to the master node. In each communication round, all participating clients compute their updates, but only the ones with \"important\" updates communicate back to the master. We show that importance can be measured using only the norm of the update and give a formula for optimal client participation. This formula minimizes the distance between the full update, where all clients participate, and our limited update, where the number of participating clients is restricted. In addition, we provide a simple algorithm that approximates the optimal formula for client participation, which allows for secure aggregation and stateless clients, and thus does not compromise client privacy. We show both theoretically and empirically that for Distributed SGD (DSGD) and Federated Averaging (FedAvg), the performance of our approach can be close to full participation and superior to the baseline where participating clients are sampled uniformly. Moreover, our approach is orthogonal to and compatible with existing methods for reducing communication overhead, such as local methods and communication compression methods",
    "checked": true,
    "id": "238c5ae6a6c45c7a1ffdba24f752640d82190b34",
    "semantic_title": "optimal client sampling for federated learning",
    "citation_count": 201,
    "authors": [
      "Wenlin Chen",
      "Samuel Horv√°th",
      "Peter Richt√°rik"
    ]
  },
  "https://openreview.net/forum?id=VcXNAr5Rur": {
    "title": "DR-DSGD: A Distributionally Robust Decentralized Learning Algorithm over Graphs",
    "volume": "main",
    "abstract": "In this paper, we propose to solve a regularized distributionally robust learning problem in the decentralized setting, taking into account the data distribution shift. By adding a Kullback-Liebler regularization function to the robust min-max optimization problem, the learning problem can be reduced to a modified robust minimization problem and solved efficiently. Leveraging the newly formulated optimization problem, we propose a robust version of Decentralized Stochastic Gradient Descent (DSGD), coined Distributionally Robust Decentralized Stochastic Gradient Descent (DR-DSGD). Under some mild assumptions and provided that the regularization parameter is larger than one, we theoretically prove that DR-DSGD achieves a convergence rate of $\\mathcal{O}\\left(1/\\sqrt{KT} + K/T\\right)$, where $K$ is the number of devices and $T$ is the number of iterations. Simulation results show that our proposed algorithm can improve the worst distribution test accuracy by up to $10\\%$. Moreover, DR-DSGD is more communication-efficient than DSGD since it requires fewer communication rounds (up to $20$ times less) to achieve the same worst distribution test accuracy target. Furthermore, the conducted experiments reveal that DR-DSGD results in a fairer performance across devices in terms of test accuracy",
    "checked": true,
    "id": "c536152448215addf4df0f332b96dcca4471d7b2",
    "semantic_title": "dr-dsgd: a distributionally robust decentralized learning algorithm over graphs",
    "citation_count": 5,
    "authors": [
      "Chaouki Ben Issaid",
      "Anis Elgabli",
      "Mehdi Bennis"
    ]
  },
  "https://openreview.net/forum?id=qzM1Tw5i7N": {
    "title": "SemiNLL: A Framework of Noisy-Label Learning by Semi-Supervised Learning",
    "volume": "main",
    "abstract": "Deep learning with noisy labels is a challenging task, which has received much attention from the machine learning and computer vision communities. Recent prominent methods that build on a specific sample selection (SS) strategy and a specific semi-supervised learning (SSL) model achieved state-of-the-art performance. Intuitively, better performance could be achieved if stronger SS strategies and SSL models are employed. Following this intuition, one might easily derive various effective noisy-label learning methods using different combinations of SS strategies and SSL models, which is, however, simply reinventing the wheel in essence. To prevent this problem, we propose SemiNLL, a versatile framework that investigates how to naturally combine different SS and SSL components based on their effects and efficiencies. We conduct a systematic and detailed analysis of the combinations of possible components based on our framework. Our framework can absorb various SS strategies and SSL backbones, utilizing their power to achieve promising performance. The instantiations of our framework demonstrate substantial improvements over state-of-the-art methods on benchmark-simulated and real-world datasets with noisy labels",
    "checked": true,
    "id": "ef04516658ecc9e42ec978ccf9586c06ecbef4b0",
    "semantic_title": "seminll: a framework of noisy-label learning by semi-supervised learning",
    "citation_count": 17,
    "authors": [
      "ZHUOWEI WANG",
      "Jing Jiang",
      "Bo Han",
      "Lei Feng",
      "Bo An",
      "Gang Niu",
      "Guodong Long"
    ]
  },
  "https://openreview.net/forum?id=qYNfwFCX9a": {
    "title": "SFP: State-free Priors for Exploration in Off-Policy Reinforcement Learning",
    "volume": "main",
    "abstract": "Efficient exploration is a crucial challenge in deep reinforcement learning. Several methods, such as behavioral priors, are able to leverage offline data in order to efficiently accelerate reinforcement learning on complex tasks. However, if the task at hand deviates excessively from the demonstrated task, the effectiveness of such methods is limited. In our work, we propose to learn features from offline data that are shared by a more diverse range of tasks, such as correlation between actions and directedness. Therefore, we introduce state-free priors, which directly model temporal consistency in demonstrated trajectories, and are capable of driving exploration in complex tasks, even when trained on data collected on simpler tasks. Furthermore, we introduce a novel integration scheme for action priors in off-policy reinforcement learning by dynamically sampling actions from a probabilistic mixture of policy and action prior. We compare our approach against strong baselines and provide empirical evidence that it can accelerate reinforcement learning in long-horizon continuous control tasks under sparse reward settings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marco Bagatella",
      "Sammy Joe Christen",
      "Otmar Hilliges"
    ]
  },
  "https://openreview.net/forum?id=h1zuM6cXpH": {
    "title": "Zero-Shot Learning with Common Sense Knowledge Graphs",
    "volume": "main",
    "abstract": "Zero-shot learning relies on semantic class representations such as hand-engineered attributes or learned embeddings to predict classes without any labeled examples. We propose to learn class representations by embedding nodes from common sense knowledge graphs in a vector space. Common sense knowledge graphs are an untapped source of explicit high-level knowledge that requires little human effort to apply to a range of tasks. To capture the knowledge in the graph, we introduce ZSL-KG, a general-purpose framework with a novel transformer graph convolutional network (TrGCN) for generating class representations. Our proposed TrGCN architecture computes non-linear combinations of node neighbourhoods. Our results show that ZSL-KG improves over existing WordNet-based methods on five out of six zero-shot benchmark datasets in language and vision",
    "checked": true,
    "id": "7323239fc698f3aa176b5dd39276326c945556a5",
    "semantic_title": "zero-shot learning with common sense knowledge graphs",
    "citation_count": 37,
    "authors": [
      "Nihal V. Nayak",
      "Stephen Bach"
    ]
  },
  "https://openreview.net/forum?id=Q54jBjc896": {
    "title": "Causal Feature Selection via Orthogonal Search",
    "volume": "main",
    "abstract": "The problem of inferring the direct causal parents of a response variable among a large set of explanatory variables is of high practical importance in many disciplines. However, established approaches often scale at least exponentially with the number of explanatory variables, are difficult to extend to nonlinear relationships and are difficult to extend to cyclic data. Inspired by debiased machine learning methods, we study a one-vs.-the-rest feature selection approach to discover the direct causal parent of the response. We propose an algorithm that works for purely observational data while also offering theoretical guarantees, including the case of partially nonlinear relationships possibly under the presence of cycles. As it requires only one estimation for each variable, our approach is applicable even to large graphs. We demonstrate significant improvements compared to established approaches",
    "checked": true,
    "id": "3592de636051fb38811ce7d139b73e68cfccc3aa",
    "semantic_title": "causal feature selection via orthogonal search",
    "citation_count": 17,
    "authors": [
      "Ashkan Soleymani",
      "Anant Raj",
      "Stefan Bauer",
      "Bernhard Sch√∂lkopf",
      "Michel Besserve"
    ]
  },
  "https://openreview.net/forum?id=urfWb7VjmL": {
    "title": "High Fidelity Visualization of What Your Self-Supervised Representation Knows About",
    "volume": "main",
    "abstract": "Discovering what is learned by neural networks remains a challenge. In self-supervised learning, classification is the most common task used to evaluate how good a representation is. However, relying only on such downstream task can limit our understanding of what information is retained in the representation of a given input. In this work, we showcase the use of a Representation Conditional Diffusion Model (RCDM) to visualize in data space the representations learned by self-supervised models. The use of RCDM is motivated by its ability to generate high-quality samples ---on par with state-of-the-art generative models--- while ensuring that the representations of those samples are faithful i.e. close to the one used for conditioning. By using RCDM to analyze self-supervised models, we are able to clearly show visually that i) SSL (backbone) representation are not invariant to the data augmentations they were trained with -- thus debunking an often restated but mistaken belief; ii) SSL post-projector embeddings appear indeed invariant to these data augmentation, along with many other data symmetries; iii) SSL representations appear more robust to small adversarial perturbation of their inputs than representations trained in a supervised manner; and iv) that SSL-trained representations exhibit an inherent structure that can be explored thanks to RCDM visualization and enables image manipulation",
    "checked": true,
    "id": "4d7c2de7a0de802f0fbfafcd9a4b4ec19e62e49d",
    "semantic_title": "high fidelity visualization of what your self-supervised representation knows about",
    "citation_count": 65,
    "authors": [
      "Florian Bordes",
      "Randall Balestriero",
      "Pascal Vincent"
    ]
  },
  "https://openreview.net/forum?id=fsacLLU35V": {
    "title": "The Fundamental Limits of Neural Networks for Interval Certified Robustness",
    "volume": "main",
    "abstract": "Interval analysis (or interval bound propagation, IBP) is a popular technique for verifying and training provably robust deep neural networks, a fundamental challenge in the area of reliable machine learning. However, despite substantial efforts, progress on addressing this key challenge has stagnated, calling into question whether interval analysis is a viable path forward. In this paper we present a fundamental result on the limitation of neural networks for interval analyzable robust classification. Our main theorem shows that non-invertible functions can not be built such that interval analysis is precise everywhere. Given this, we derive a paradox: while every dataset can be robustly classified, there are simple datasets that can not be provably robustly classified with interval analysis",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew B Mirman",
      "Maximilian Baader",
      "Martin Vechev"
    ]
  },
  "https://openreview.net/forum?id=M8D5iZsnrO": {
    "title": "TITRATED: Learned Human Driving Behavior without Infractions via Amortized Inference",
    "volume": "main",
    "abstract": "Models of human driving behavior have long been used for prediction in autonomous vehicles, but recently have also started being used to create non-playable characters for driving simulations. While such models are in many respects realistic, they tend to suffer from unacceptably high rates of driving infractions, such as collisions or off-road driving, particularly when deployed in map locations with road geometries dissimilar to the training dataset. In this paper we present a novel method for fine-tuning a foundation model of human driving behavior to novel locations where human demonstrations are not available which reduces the incidence of such infractions. The method relies on inference in the foundation model to generate infraction-free trajectories as well as additional penalties applied when fine-tuning the amortized inference behavioral model. We demonstrate this \"titration\" technique using the ITRA foundation behavior model trained on the INTERACTION dataset when transferring to CARLA map locations. We demonstrate a 76-86% reduction in infraction rate and provide evidence that further gains are possible with more computation or better inference algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vasileios Lioutas",
      "Adam Scibior",
      "Frank Wood"
    ]
  },
  "https://openreview.net/forum?id=AiOUi3440V": {
    "title": "No More Pesky Hyperparameters: Offline Hyperparameter Tuning for RL",
    "volume": "main",
    "abstract": "The performance of reinforcement learning (RL) agents is sensitive to the choice of hyperparameters. In real-world settings like robotics or industrial control systems, however, testing different hyperparameter configurations directly on the environment can be financially prohibitive, dangerous, or time consuming. We focus on hyperparameter tuning from offline logs of data, to fully specify the hyperparameters for an RL agent that learns online in the real world. The approach is conceptually simple: we first learn a model of the environment from the offline data, which we call a calibration model, and then simulate learning in the calibration model to identify promising hyperparameters. Though such a natural idea is (likely) being used in industry, it has yet to be systematically investigated. We identify several criteria to make this strategy effective, and develop an approach that satisfies these criteria. We empirically investigate the method in a variety of settings to identify when it is effective and when it fails",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Wang",
      "Archit Sakhadeo",
      "Adam M White",
      "James M Bell",
      "Vincent Liu",
      "Xutong Zhao",
      "Puer Liu",
      "Tadashi Kozuno",
      "Alona Fyshe",
      "Martha White"
    ]
  },
  "https://openreview.net/forum?id=BDqzLH1gEm": {
    "title": "Mean-Field Langevin Dynamics : Exponential Convergence and Annealing",
    "volume": "main",
    "abstract": "Noisy particle gradient descent (NPGD) is an algorithm to minimize convex functions over the space of measures that include an entropy term. In the many-particle limit, this algorithm is described by a Mean-Field Langevin dynamics---a generalization of the Langevin dynamic with a non-linear drift---which is our main object of study. Previous work have shown its convergence to the unique minimizer via non-quantitative arguments. We prove that this dynamics converges at an exponential rate, under the assumption that a certain family of Log-Sobolev inequalities holds. This assumption holds for instance for the minimization of the risk of certain two-layer neural networks, where NPGD is equivalent to standard noisy gradient descent. We also study the annealed dynamics, and show that for a noise decaying at a logarithmic rate, the dynamics converges in value to the global minimizer of the unregularized objective function",
    "checked": true,
    "id": "68729a3e0e626447f93e5abfd41cb0a5287d6042",
    "semantic_title": "mean-field langevin dynamics : exponential convergence and annealing",
    "citation_count": 83,
    "authors": [
      "L√©na√Øc Chizat"
    ]
  },
  "https://openreview.net/forum?id=fudOtITMIZ": {
    "title": "Variational Disentanglement for Domain Generalization",
    "volume": "main",
    "abstract": "Domain generalization aims to learn a domain-invariant model that can generalize well to the unseen target domain. In this paper, based on the assumption that there exists an invariant feature mapping, we propose an evidence upper bound of the divergence between the category-specific feature and its invariant ground-truth using variational inference. To optimize this upper bound, we further propose an efficient Variational Disentanglement Network (VDN) that is capable of disentangling the domain-specific features and category-specific features (which generalize well to the unseen samples). Besides, the generated novel images from VDN are used to further improve the generalization ability. We conduct extensive experiments to verify our method on three benchmarks, and both quantitative and qualitative results illustrate the effectiveness of our method",
    "checked": true,
    "id": "5e83e5e332c8189102364f45204afe5f282b9188",
    "semantic_title": "variational disentanglement for domain generalization",
    "citation_count": 28,
    "authors": [
      "Yufei Wang",
      "Haoliang Li",
      "Hao Cheng",
      "Bihan Wen",
      "Lap-Pui Chau",
      "Alex Kot"
    ]
  },
  "https://openreview.net/forum?id=fXorxxbDvO": {
    "title": "On Robustness to Missing Video for Audiovisual Speech Recognition",
    "volume": "main",
    "abstract": "It has been shown that learning audiovisual features can lead to improved speech recognition performance over audio-only features, especially for noisy speech. However, in many common applications, the visual features are partially or entirely missing, e.g. the speaker might move off screen. Multi-modal models need to be robust: missing video frames should not degrade the performance of an audiovisual model to be worse than that of a single-modality audio-only model. While there have been many attempts at building robust models, there is little consensus on how robustness should be evaluated. To address this, we introduce a framework that allows claims about robustness to be evaluated in a precise and testable way. We also conduct a systematic empirical study of the robustness of common audiovisual speech recognition architectures on a range of acoustic noise conditions and test suites. Finally, we show that an architecture-agnostic solution based on cascades can consistently achieve robustness to missing video, even in settings where existing techniques for robustness like dropout fall short",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oscar Chang",
      "Otavio Braga",
      "Hank Liao",
      "Dmitriy Serdyuk",
      "Olivier Siohan"
    ]
  },
  "https://openreview.net/forum?id=X2BodlyLvT": {
    "title": "Identifying Causal Structure in Dynamical Systems",
    "volume": "main",
    "abstract": "Mathematical models are fundamental building blocks in the design of dynamical control systems. As control systems are becoming increasingly complex and networked, approaches for obtaining such models based on first principles reach their limits. Data-driven methods provide an alternative. However, without structural knowledge, these methods are prone to finding spurious correlations in the training data, which can hamper generalization capabilities of the obtained models. This can significantly lower control and prediction performance when the system is exposed to unknown situations. A preceding causal identification can prevent this pitfall. In this paper, we propose a method that identifies the causal structure of control systems. We design experiments based on the concept of controllability, which provides a systematic way to compute input trajectories that steer the system to specific regions in its state space. We then analyze the resulting data leveraging powerful techniques from causal inference and extend them to control systems. Further, we derive conditions that guarantee the discovery of the true causal structure of the system. Experiments on a robot arm demonstrate reliable causal identification from real-world data and enhanced generalization capabilities",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dominik Baumann",
      "Friedrich Solowjow",
      "Karl Henrik Johansson",
      "Sebastian Trimpe"
    ]
  },
  "https://openreview.net/forum?id=sNxNi54B8b": {
    "title": "Do ReLU Networks Have An Edge When Approximating Compactly-Supported Functions?",
    "volume": "main",
    "abstract": "We study the problem of approximating compactly-supported integrable functions while implementing their support set using feedforward neural networks. Our first main result transcribes this ``structured'' approximation problem into a universality problem. We do this by constructing a refinement of the usual topology on the space $L^1_{\\operatorname{loc}}(\\mathbb{R}^d,\\mathbb{R}^D)$ of locally-integrable functions in which compactly-supported functions can only be approximated in $L^1$-norm by functions with matching discretized support. We establish the universality of ReLU feedforward networks with bilinear pooling layers in this refined topology. Consequentially, we find that ReLU feedforward networks with bilinear pooling can approximate compactly supported functions while implementing their discretized support. We derive a quantitative uniform version of our universal approximation theorem on the dense subclass of compactly-supported Lipschitz functions. This quantitative result expresses the depth, width, and the number of bilinear pooling layers required to construct this ReLU network via the target function's regularity, the metric capacity and diameter of its essential support, and the dimensions of the inputs and output spaces. Conversely, we show that polynomial regressors and analytic feedforward networks are not universal in this space",
    "checked": true,
    "id": "24c6891956efbae1cee760cd109f53ca71a90d7b",
    "semantic_title": "do relu networks have an edge when approximating compactly-supported functions?",
    "citation_count": 3,
    "authors": [
      "Anastasis Kratsios",
      "Behnoosh Zamanlooy"
    ]
  },
  "https://openreview.net/forum?id=dkHfV3wB2l": {
    "title": "Recurrent networks, hidden states and beliefs in partially observable environments",
    "volume": "main",
    "abstract": "Reinforcement learning aims to learn optimal policies from interaction with environments whose dynamics are unknown. Many methods rely on the approximation of a value function to derive near-optimal policies. In partially observable environments, these functions depend on the complete sequence of observations and past actions, called the history. In this work, we show empirically that recurrent neural networks trained to approximate such value functions internally filter the posterior probability distribution of the current state given the history, called the belief. More precisely, we show that, as a recurrent neural network learns the Q-function, its hidden states become more and more correlated with the beliefs of state variables that are relevant to optimal control. This correlation is measured through their mutual information. In addition, we show that the expected return of an agent increases with the ability of its recurrent architecture to reach a high mutual information between its hidden states and the beliefs. Finally, we show that the mutual information between the hidden states and the beliefs of variables that are irrelevant for optimal control decreases through the learning process. In summary, this work shows that in its hidden states, a recurrent neural network approximating the Q-function of a partially observable environment reproduces a sufficient statistic from the history that is correlated to the relevant part of the belief for taking optimal actions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gaspard Lambrechts",
      "Adrien Bolland",
      "Damien Ernst"
    ]
  },
  "https://openreview.net/forum?id=b3v1UrtF6G": {
    "title": "Self-supervise, Refine, Repeat: Improving Unsupervised Anomaly Detection",
    "volume": "main",
    "abstract": "Anomaly detection (AD), separating anomalies from normal data, has many applications across domains, from security to healthcare. While most previous works were shown to be effective for cases with fully or partially labeled data, that setting is in practice less common due to labeling being particularly tedious for this task. In this paper, we focus on fully unsupervised AD, in which the entire training dataset, containing both normal and anomalous samples, is unlabeled. To tackle this problem effectively, we propose to improve the robustness of one-class classification trained on self-supervised representations using a data refinement process. Our proposed data refinement approach is based on an ensemble of one-class classifiers (OCCs), each of which is trained on a disjoint subset of training data. Representations learned by self-supervised learning on the refined data are iteratively updated as the data refinement improves. We demonstrate our method on various unsupervised AD tasks with image and tabular data. With a 10% anomaly ratio on CIFAR-10 image data / 2.5% anomaly ratio on Thyroid tabular data, the proposed method outperforms the state-of-the-art one-class classifier by 6.3 AUC and 12.5 average precision / 22.9 F1-score",
    "checked": true,
    "id": "b9ca44d3501a101200ecedb8812d5a2c7eebc24b",
    "semantic_title": "self-supervise, refine, repeat: improving unsupervised anomaly detection",
    "citation_count": 21,
    "authors": [
      "Jinsung Yoon",
      "Kihyuk Sohn",
      "Chun-Liang Li",
      "Sercan O Arik",
      "Chen-Yu Lee",
      "Tomas Pfister"
    ]
  },
  "https://openreview.net/forum?id=0xENE7HiYm": {
    "title": "Domain-invariant Feature Exploration for Domain Generalization",
    "volume": "main",
    "abstract": "Deep learning has achieved great success in the past few years. However, the performance of deep learning is likely to impede in face of non-IID situations. Domain generalization (DG) enables a model to generalize to an unseen test distribution, i.e., to learn domain-invariant representations. In this paper, we argue that domain-invariant features should be originating from both internal and mutual sides. Internal invariance means that the features can be learned with a single domain and the features capture intrinsic semantics of data, i.e., the property within a domain, which is agnostic to other domains. Mutual invariance means that the features can be learned with multiple domains (cross-domain) and the features contain common information, i.e., the transferable features w.r.t. other domains. We then propose DIFEX for Domain-Invariant Feature EXploration. DIFEX employs a knowledge distillation framework to capture the high-level Fourier phase as the internally-invariant features and learn cross-domain correlation alignment as the mutually-invariant features. We further design an exploration loss to increase the feature diversity for better generalization. Extensive experiments on both time-series and visual benchmarks demonstrate that the proposed DIFEX achieves state-of-the-art performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wang Lu",
      "Jindong Wang",
      "Haoliang Li",
      "Yiqiang Chen",
      "Xing Xie"
    ]
  },
  "https://openreview.net/forum?id=e3S0Bl2RO8": {
    "title": "Stable and Interpretable Unrolled Dictionary Learning",
    "volume": "main",
    "abstract": "The dictionary learning problem, representing data as a combination of a few atoms, has long stood as a popular method for learning representations in statistics and signal processing. The most popular dictionary learning algorithm alternates between sparse coding and dictionary update steps, and a rich literature has studied its theoretical convergence. The success of dictionary learning relies on access to a good initial estimate of the dictionary and the ability of the sparse coding step to provide an unbiased estimate of the code. The growing popularity of unrolled sparse coding networks has led to the empirical finding that backpropagation through such networks performs dictionary learning. We offer the theoretical analysis of these empirical results through PUDLE, a Provable Unrolled Dictionary LEarning method. We provide conditions on the network initialization and data distribution sufficient to recover and preserve the support of the latent code. Additionally, we address two challenges; first, the vanilla unrolled sparse coding computes a biased code estimate, and second, gradients during backpropagated learning can become unstable. We show approaches to reduce the bias of the code estimate in the forward pass, and that of the dictionary estimate in the backward pass. We propose strategies to resolve the learning instability by tuning network parameters and modifying the loss function. Overall, we highlight the impact of loss, unrolling, and backpropagation on convergence. We complement our findings through synthetic and image denoising experiments. Finally, we demonstrate PUDLE's interpretability, a driving factor in designing deep networks based on iterative optimizations, by building a mathematical relation between network weights, its output, and the training set",
    "checked": true,
    "id": "01a483ff33c1936a72d3ef65dfccba4c2680ef74",
    "semantic_title": "stable and interpretable unrolled dictionary learning",
    "citation_count": 16,
    "authors": [
      "Bahareh Tolooshams",
      "Demba E. Ba"
    ]
  },
  "https://openreview.net/forum?id=NPfS5N3jbL": {
    "title": "Exploring Generative Neural Temporal Point Process",
    "volume": "main",
    "abstract": "Temporal point process (TPP) is commonly used to model the asynchronous event sequence featuring occurrence timestamps and revealed by probabilistic models conditioned on historical impacts. While lots of previous works have focused on `goodness-of-fit' of TPP models by maximizing the likelihood, their predictive performance is unsatisfactory, which means the timestamps generated by models are far apart from true observations. Recently, deep generative models such as denoising diffusion and score matching models have achieved great progress in image generating tasks by demonstrating their capability of generating samples of high quality. However, there are no detailed and unified works exploring and studying the potential of generative models in the context of event prediction of TPP. In this work, we try to fill the gap by designing a unified generative framework for neural temporal point process (GNTPP) model to explore their feasibility and effectiveness, and further improve models' predictive performance. Besides, in terms of measuring the historical impacts, we revise the attentive models which summarize influence from historical events with an adaptive reweighting term considering events' type relation and time intervals. Extensive experiments have been conducted to illustrate the improved predictive capability of GNTPP with a line of generative probabilistic decoders, and performance gain from the revised attention. To the best of our knowledge, this is the first work that adapts generative models in a complete unified framework and studies their effectiveness in the context of TPP",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haitao Lin",
      "Lirong Wu",
      "Guojiang Zhao",
      "Liu Pai",
      "Stan Z. Li"
    ]
  },
  "https://openreview.net/forum?id=LJohl5DnZf": {
    "title": "Improving the Trainability of Deep Neural Networks through Layerwise Batch-Entropy Regularization",
    "volume": "main",
    "abstract": "Training deep neural networks is a very demanding task, especially challenging is how to adapt architectures to improve the performance of trained models. We can find that sometimes, shallow networks generalize better than deep networks, and the addition of more layers results in higher training and test errors. The deep residual learning framework addresses this degradation problem by adding skip connections to several neural network layers. It would at first seem counter-intuitive that such skip connections are needed to train deep networks successfully as the expressivity of a network would grow exponentially with depth. In this paper, we first analyze the flow of information through neural networks. We introduce and evaluate the batch-entropy which quantifies the flow of information through each layer of a neural network. We prove empirically and theoretically that a positive batch-entropy is required for gradient descent-based training approaches to optimize a given loss function successfully. Based on those insights, we introduce batch-entropy regularization to enable gradient descent-based training algorithms to optimize the flow of information through each hidden layer individually. With batch-entropy regularization, gradient descent optimizers can transform untrainable networks into trainable networks. We show empirically that we can therefore train a \"vanilla\" fully connected network and convolutional neural network---no skip connections, batch normalization, dropout, or any other architectural tweak---with 500 layers by simply adding the batch-entropy regularization term to the loss function. The effect of batch-entropy regularization is not only evaluated on vanilla neural networks, but also on residual networks, autoencoders, and also transformer models over a wide range of computer vision as well as natural language processing tasks",
    "checked": true,
    "id": "c776bc2389230e6100cf3f4605cc0aad791e90bb",
    "semantic_title": "improving the trainability of deep neural networks through layerwise batch-entropy regularization",
    "citation_count": 6,
    "authors": [
      "David Peer",
      "Bart Keulen",
      "Sebastian Stabinger",
      "Justus Piater",
      "Antonio Rodriguez-sanchez"
    ]
  },
  "https://openreview.net/forum?id=lAv8fShACA": {
    "title": "Online Coresets for Parameteric and Non-Parametric Bregman Clustering",
    "volume": "main",
    "abstract": "We present algorithms that create coresets in an online setting for clustering problems based on a wide subset of Bregman divergences. Notably, our coresets have a small additive error, similar in magnitude to the gap between expected and empirical loss (Bachem et. al. 2017), and take update time $O(d)$ for every incoming point where $d$ is the dimension of the point. Our first algorithm gives online coresets of size $\\tilde{O}(\\mbox{poly}(k,d,\\epsilon,\\mu))$ for $k$-clusterings according to any $\\mu$-similar Bregman divergence. We further extend this algorithm to show the existence of non-parametric coresets, where the coreset size is independent of $k$, the number of clusters, for the same subclass of Bregman divergences. Our non-parametric coresets also function as coresets for non-parametric versions of the Bregman clustering like DP-Means. While these coresets provide additive error guarantees, they are significantly smaller for high dimensional data than the (relative-error) coresets obtained in (Bachem et. al 2015) for DP-Means--- for the input of size $n$ our coresets grow as $O(\\log n)$ while being independent of $d$ as opposed to $O(d^d)$ for points in $\\~R^d$ (Bachem et. al 2015). We also present experiments to compare the performance of our algorithms with other sampling techniques",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Supratim Shit",
      "Anirban Dasgupta",
      "Rachit Chhaya",
      "Jayesh Choudhari"
    ]
  },
  "https://openreview.net/forum?id=bMar2OkxVu": {
    "title": "Max-Affine Spline Insights Into Deep Network Pruning",
    "volume": "main",
    "abstract": "State-of-the-art (SOTA) approaches to deep network (DN) training overparametrize the model and then prune a posteriori to obtain a ``winning ticket'' subnetwork that can achieve high accuracy. Using a recently developed spline interpretation of DNs, we obtain novel insights into how DN pruning affects its mapping. In particular, under the realm of spline operators, we are able to pinpoint the impact of pruning onto the DN's underlying input space partition and per-region affine mappings, opening new avenues in understanding why and when are pruned DNs able to maintain high performance. We also discover that a DN's spline mapping exhibits an early-bird (EB) phenomenon whereby the spline's partition converges at early training stages, bridging the recently developed DN spline theory and lottery ticket hypothesis of DNs. We finally leverage this new insight to develop a principled and efficient pruning strategy whose goal is to prune isolated groups of nodes that have a redundant contribution in the forming of the spline partition. Extensive experiments on four networks and three datasets validate that our new spline-based DN pruning approach reduces training FLOPs by up to 3.5x while achieving similar or even better accuracy than current state-of-the-art methods. Code is available at https://github.com/RICE-EIC/Spline-EB",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran You",
      "Randall Balestriero",
      "Zhihan Lu",
      "Yutong Kou",
      "Huihong Shi",
      "Shunyao Zhang",
      "Shang Wu",
      "Yingyan Lin",
      "Richard Baraniuk"
    ]
  },
  "https://openreview.net/forum?id=NL2L3XjVFx": {
    "title": "Did I do that? Blame as a means to identify controlled effects in reinforcement learning",
    "volume": "main",
    "abstract": "Affordance learning is a crucial ability of intelligent agents. This ability relies on understanding the different ways the environment can be controlled. Approaches encouraging RL agents to model controllable aspects of their environment have repeatedly achieved state-of-the-art results. Despite their success, these approaches have only been studied using generic tasks as a proxy but have not yet been evaluated in isolation. In this work, we study the problem of identifying controlled effects from a causal perspective. Humans compare counterfactual outcomes to assign a degree of blame to their actions. Following this idea, we propose Controlled Effect Network (CEN), a self-supervised method based on the causal concept of blame. CEN is evaluated in a wide range of environments against two state-of-the-art models, showing that it precisely identifies controlled effects",
    "checked": true,
    "id": "ceb4e0c2ad601831c056901e9f1ab5f5500d8520",
    "semantic_title": "did i do that? blame as a means to identify controlled effects in reinforcement learning",
    "citation_count": 3,
    "authors": [
      "Oriol Corcoll",
      "Youssef Sherif Mansour Mohamed",
      "Raul Vicente"
    ]
  },
  "https://openreview.net/forum?id=xwWsiFmUEs": {
    "title": "QuaRL: Quantization for Fast and Environmentally Sustainable Reinforcement Learning",
    "volume": "main",
    "abstract": "Deep reinforcement learning continues to show tremendous potential in achieving task-level autonomy, however, its computational and energy demands remain prohibitively high. In this paper, we tackle this problem by applying quantization to reinforcement learning. To that end, we introduce a novel Reinforcement Learning (RL) training paradigm, \\textit{ActorQ}, to speed up actor-learner distributed RL training. \\textit{ActorQ} leverages 8-bit quantized actors to speed up data collection without affecting learning convergence. Our quantized distributed RL training system, \\textit{ActorQ}, demonstrates end-to-end speedups of $>$ 1.5 $\\times$ - 2.5 $\\times$, and faster convergence over full precision training on a range of tasks (Deepmind Control Suite) and different RL algorithms (D4PG, DQN). Furthermore, we compare the carbon emissions (Kgs of CO2) of \\textit{ActorQ} versus standard reinforcement learning on various tasks. Across various settings, we show that \\textit{ActorQ} enables more environmentally friendly reinforcement learning by achieving 2.8$\\times$ less carbon emission and energy compared to training RL-agents in full-precision. Finally, we demonstrate empirically that aggressively quantized RL-policies (up to 4/5 bits) enable significant speedups on quantization-friendly (supports native quantization) resource-constrained edge devices, without degrading accuracy. We believe that this is the first of many future works on enabling computationally energy-efficient and sustainable reinforcement learning. The source code for QuaRL is available here for the public to use: \\url{https://bit.ly/quarl-tmlr}",
    "checked": false,
    "id": "a32ab8e5e3f92e61b1c7a2fc6af7add4c341d1bf",
    "semantic_title": "quantization for sustainable reinforcement learning",
    "citation_count": 5,
    "authors": [
      "Srivatsan Krishnan",
      "Max Lam",
      "Sharad Chitlangia",
      "Zishen Wan",
      "Gabriel Barth-maron",
      "Aleksandra Faust",
      "Vijay Janapa Reddi"
    ]
  },
  "https://openreview.net/forum?id=ggPhsYCsm9": {
    "title": "NeSF: Neural Semantic Fields for Generalizable Semantic Segmentation of 3D Scenes",
    "volume": "main",
    "abstract": "We present NeSF, a method for producing 3D semantic fields from posed RGB images alone. In place of classical 3D representations, our method builds on recent work in neural fields wherein 3D structure is captured by point-wise functions. We leverage this methodology to recover 3D density fields upon which we then train a 3D semantic segmentation model supervised by posed 2D semantic maps. Despite being trained on 2D signals alone, our method is able to generate 3D-consistent semantic maps from novel camera poses and can be queried at arbitrary 3D points. Notably, NeSF is compatible with any method producing a density field. Our empirical analysis demonstrates comparable quality to competitive 2D and 3D semantic segmentation baselines on complex, realistically-rendered scenes and significantly outperforms a comparable neural radiance field-based method on a series of tasks requiring 3D reasoning. Our method is the first to learn semantics by recognizing patterns in the geometry stored within a 3D neural field representation. NeSF is trained using purely 2D signals and requires as few as one labeled image per-scene at train time. No semantic input is required for inference on novel scenes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suhani Vora",
      "Noha Radwan",
      "Klaus Greff",
      "Henning Meyer",
      "Kyle Genova",
      "Mehdi S. M. Sajjadi",
      "Etienne Pot",
      "Andrea Tagliasacchi",
      "Daniel Duckworth"
    ]
  },
  "https://openreview.net/forum?id=NT9zgedd3I": {
    "title": "Learning to Switch Among Agents in a Team via 2-Layer Markov Decision Processes",
    "volume": "main",
    "abstract": "Reinforcement learning agents have been mostly developed and evaluated under the assumption that they will operate in a fully autonomous manner---they will take all actions. In this work, our goal is to develop algorithms that, by learning to switch control between agents, allow existing reinforcement learning agents to operate under different automation levels. To this end, we first formally define the problem of learning to switch control among agents in a team via a 2-layer Markov decision process. Then, we develop an online learning algorithm that uses upper confidence bounds on the agents' policies and the environment's transition probabilities to find a sequence of switching policies. The total regret of our algorithm with respect to the optimal switching policy is sublinear in the number of learning steps and, whenever multiple teams of agents operate in a similar environment, our algorithm greatly benefits from maintaining shared confidence bounds for the environments' transition probabilities and it enjoys a better regret bound than problem-agnostic algorithms. Simulation experiments in an obstacle avoidance task illustrate our theoretical findings and demonstrate that, by exploiting the specific structure of the problem, our proposed algorithm is superior to problem-agnostic algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vahid Balazadeh",
      "Abir De",
      "Adish Singla",
      "Manuel Gomez Rodriguez"
    ]
  },
  "https://openreview.net/forum?id=ILPFasEaHA": {
    "title": "A Self-Supervised Framework for Function Learning and Extrapolation",
    "volume": "main",
    "abstract": "Understanding how agents learn to generalize ‚Äî and, in particular, to extrapolate ‚Äî in high-dimensional, naturalistic environments remains a challenge for both machine learning and the study of biological agents. One approach to this has been the use of function learning paradigms, which allow agents' empirical patterns of generalization for smooth scalar functions to be described precisely. However, to date, such work has not succeeded in identifying mechanisms that acquire the kinds of general purpose representations over which function learning can operate to exhibit the patterns of generalization observed in human empirical studies. Here, we present a framework for how a learner may acquire such representations, that then support generalization-and extrapolation in particular-in a few-shot fashion in the domain of scalar function learning. Taking inspiration from a classic theory of visual processing, we construct a self-supervised encoder that implements the basic inductive bias of invariance under topological distortions. We show the resulting representations outperform those from other models for unsupervised time series learning in several downstream function learning tasks, including extrapolation",
    "checked": true,
    "id": "7a7145a21e51e6773fb7ecc90e1a978fa50bd5ea",
    "semantic_title": "a self-supervised framework for function learning and extrapolation",
    "citation_count": 1,
    "authors": [
      "Simon Segert",
      "Jonathan Cohen"
    ]
  },
  "https://openreview.net/forum?id=2EOVIvRXlv": {
    "title": "Ranking Recovery under Privacy Considerations",
    "volume": "main",
    "abstract": "We consider the private ranking recovery problem, where a data collector seeks to estimate the permutation/ranking of a data vector given a randomized (privatized) version of it. We aim to establish fundamental trade-offs between the performance of the estimation task, measured in terms of probability of error, and the level of privacy that can be guaranteed when the noise mechanism consists of adding artificial noise. Towards this end, we show the optimality of a low-complexity decision rule (referred to as linear decoder) for the estimation task, under several noise distributions widely used in the privacy literature (e.g., Gaussian, Laplace, and generalized normal model). We derive the Taylor series of the probability of error, which yields its first and second-order approximations when such a linear decoder is employed. We quantify the guaranteed level of privacy using differential privacy (DP) types of metrics, such as $\\epsilon$-DP and $(\\alpha,\\epsilon)$-R√©nyi DP. Finally, we put together the results to characterize trade-offs between privacy and probability of error",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minoh Jeong",
      "Alex Dytso",
      "Martina Cardone"
    ]
  },
  "https://openreview.net/forum?id=tLIBAEYjcv": {
    "title": "Learning the Transformer Kernel",
    "volume": "main",
    "abstract": "In this work we introduce KL-TRANSFORMER, a generic, scalable, data driven framework for learning the kernel function in Transformers. Our framework approximates the Transformer kernel as a dot product between spectral feature maps and learns the kernel by learning the spectral distribution. This not only helps in learning a generic kernel end-to-end, but also reduces the time and space complexity of Transformers from quadratic to linear. We show that KL-TRANSFORMERs achieve performance comparable to existing efficient Transformer architectures, both in terms of accuracy and computational efficiency. Our study also demonstrates that the choice of the kernel has a substantial impact on performance, and kernel learning variants are competitive alternatives to fixed kernel Transformers, both in long as well as short sequence tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sankalan Pal Chowdhury",
      "Adamos Solomou",
      "Kumar Avinava Dubey",
      "Mrinmaya Sachan"
    ]
  },
  "https://openreview.net/forum?id=dpOYN7o8Jm": {
    "title": "Optimizing Functionals on the Space of Probabilities with Input Convex Neural Networks",
    "volume": "main",
    "abstract": "Gradient flows are a powerful tool for optimizing functionals in general metric spaces, including the space of probabilities endowed with the Wasserstein metric. A typical approach to solving this optimization problem relies on its connection to the dynamic formulation of optimal transport and the celebrated Jordan-Kinderlehrer-Otto (JKO) scheme. However, this formulation involves optimization over convex functions, which is challenging, especially in high dimensions. In this work, we propose an approach that relies on the recently introduced input-convex neural networks (ICNN) to parametrize the space of convex functions in order to approximate the JKO scheme, as well as in designing functionals over measures that enjoy convergence guarantees. We derive a computationally efficient implementation of this JKO-ICNN framework and experimentally demonstrate its feasibility and validity in approximating solutions of low-dimensional partial differential equations with known solutions. We also demonstrate its viability in high-dimensional applications through an experiment in controlled generation for molecular discovery",
    "checked": true,
    "id": "8232dd73ee92c22af5815b37c1e36a4f251684cc",
    "semantic_title": "optimizing functionals on the space of probabilities with input convex neural networks",
    "citation_count": 57,
    "authors": [
      "David Alvarez-Melis",
      "Yair Schiff",
      "Youssef Mroueh"
    ]
  },
  "https://openreview.net/forum?id=yVkpxs77cD": {
    "title": "Deformation Robust Roto-Scale-Translation Equivariant CNNs",
    "volume": "main",
    "abstract": "Incorporating group symmetry directly into the learning process has proved to be an effective guideline for model design. By producing features that are guaranteed to transform covariantly to the group actions on the inputs, group-equivariant convolutional neural networks (G-CNNs) achieve significantly improved generalization performance in learning tasks with intrinsic symmetry. General theory and practical implementation of G-CNNs have been studied for planar images under either rotation or scaling transformation, but only individually. We present, in this paper, a roto-scale-translation equivariant CNN ($\\mathcal{RST}$-CNN), that is guaranteed to achieve equivariance jointly over these three groups via coupled group convolutions. Moreover, as symmetry transformations in reality are rarely perfect and typically subject to input deformation, we provide a stability analysis of the equivariance of representation to input distortion, which motivates the truncated expansion of the convolutional filters under (pre-fixed) low-frequency spatial modes. The resulting model provably achieves deformation-robust $\\mathcal{RST}$ equivariance, i.e., the $\\mathcal{RST}$ symmetry is still \"approximately\" preserved when the transformation is \"contaminated\" by a nuisance data deformation, a property that is especially important for out-of-distribution generalization. Numerical experiments on MNIST, Fashion-MNIST, and STL-10 demonstrate that the proposed model yields remarkable gains over prior arts, especially in the small data regime where both rotation and scaling variations are present within the data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liyao Gao",
      "Guang Lin",
      "Wei Zhu"
    ]
  },
  "https://openreview.net/forum?id=2VEUIq9Yff": {
    "title": "Adversarial Feature Augmentation and Normalization for Visual Recognition",
    "volume": "main",
    "abstract": "Recent advances in computer vision take advantage of adversarial data augmentation to improve the generalization of classification models. Here, we present an effective and efficient alternative that advocates adversarial augmentation on intermediate feature embeddings, instead of relying on computationally-expensive pixel-level perturbations. We propose $\\textbf{A}$dversarial $\\textbf{F}$eature $\\textbf{A}$ugmentation and $\\textbf{N}$ormalization (A-FAN), which ($i$) first augments visual recognition models with adversarial features that integrate flexible scales of perturbation strengths, ($ii$) then extracts adversarial feature statistics from batch normalization, and re-injects them into clean features through feature normalization. We validate the proposed approach across diverse visual recognition tasks with representative backbone networks, including ResNets and EfficientNets for classification, Faster-RCNN for detection, and Deeplab V3+ for segmentation. Extensive experiments show that A-FAN yields consistent generalization improvement over strong baselines across various datasets for classification, detection, and segmentation tasks, such as CIFAR-10, CIFAR-100, ImageNet, Pascal VOC2007, Pascal VOC2012, COCO2017, and Cityspaces. Comprehensive ablation studies and detailed analyses also demonstrate that adding perturbations to specific modules and layers of classification/detection/segmentation backbones yields optimal performance. Codes and pre-trained models are available in: https://github.com/VITA-Group/CV_A-FAN",
    "checked": true,
    "id": "83c9549ada3bd15ab280eaa3822009f50ca7ae58",
    "semantic_title": "adversarial feature augmentation and normalization for visual recognition",
    "citation_count": 19,
    "authors": [
      "Tianlong Chen",
      "Yu Cheng",
      "Zhe Gan",
      "Jianfeng Wang",
      "Lijuan Wang",
      "Jingjing Liu",
      "Zhangyang Wang"
    ]
  },
  "https://openreview.net/forum?id=aRsLetumx1": {
    "title": "How Expressive are Transformers in Spectral Domain for Graphs?",
    "volume": "main",
    "abstract": "The recent works proposing transformer-based models for graphs have proven the inadequacy of Vanilla Transformer for graph representation learning. To understand this inadequacy, there is a need to investigate if spectral analysis of the transformer will reveal insights into its expressive power. Similar studies already established that spectral analysis of Graph neural networks (GNNs) provides extra perspectives on their expressiveness. In this work, we systematically study and establish the link between the spatial and spectral domain in the realm of the transformer. We further provide a theoretical analysis that the spatial attention mechanism in the transformer cannot effectively capture the desired frequency response, thus, inherently limiting its expressiveness in spectral space. Therefore, we propose FeTA, a framework that aims to perform attention over the entire graph spectrum (i.e. actual frequency components of the graph) analogous to the attention in spatial space. Empirical results suggest that FeTA provides homogeneous performance gain against vanilla transformer across all tasks on standard benchmarks and can easily be extended to GNN-based models with low-pass characteristics (e.g., GAT)",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anson Bastos",
      "Abhishek Nadgeri",
      "Kuldeep Singh",
      "Hiroki Kanezashi",
      "Toyotaro Suzumura",
      "Isaiah Onando Mulang'"
    ]
  },
  "https://openreview.net/forum?id=ak6Bds2DcI": {
    "title": "Robust and Data-efficient Q-learning by Composite Value-estimation",
    "volume": "main",
    "abstract": "In the past few years, off-policy reinforcement learning methods have shown promising results in their application to robot control. Q-learning based methods, however, still suffer from poor data-efficiency and are susceptible to stochasticity or noise in the immediate reward, which is limiting with regard to real-world applications. We alleviate this problem by proposing two novel off-policy Temporal-Difference formulations: (1) Truncated Q-functions which represent the return for the first $n$ steps of a target-policy rollout with respect to the full action-value and (2) Shifted Q-functions, acting as the farsighted return after this truncated rollout. This decomposition allows us to optimize both parts with their individual learning rates, achieving significant learning speedup and robustness to variance in the reward signal, leading to the Composite Q-learning algorithm. We show the efficacy of Composite Q-learning in the tabular case and furthermore employ Composite Q-learning within TD3. We compare Composite TD3 with TD3 and TD3($\\Delta$), which we introduce as an off-policy variant of TD($\\Delta$). Moreover, we show that Composite TD3 outperforms TD3 as well as TD3($\\Delta$) significantly in terms of data-efficiency in multiple simulated robot tasks and that Composite Q-learning is robust to stochastic immediate rewards",
    "checked": true,
    "id": "2d2cb2a8c738fb38bff02281a0cddcd0f8905964",
    "semantic_title": "robust and data-efficient q-learning by composite value-estimation",
    "citation_count": 2,
    "authors": [
      "Gabriel Kalweit",
      "Maria Kalweit",
      "Joschka Boedecker"
    ]
  },
  "https://openreview.net/forum?id=xyt4wfdo4J": {
    "title": "Iterative State Estimation in Non-linear Dynamical Systems Using Approximate Expectation Propagation",
    "volume": "main",
    "abstract": "Bayesian inference in non-linear dynamical systems seeks to find good posterior approximations of a latent state given a sequence of observations. Gaussian filters and smoothers, including the (extended/unscented) Kalman filter/smoother, which are commonly used in engineering applications, yield Gaussian posteriors on the latent state. While they are computationally efficient, they are often criticised for their crude approximation of the posterior state distribution. In this paper, we address this criticism by proposing a message passing scheme for iterative state estimation in non-linear dynamical systems, which yields more informative (Gaussian) posteriors on the latent states. Our message passing scheme is based on expectation propagation (EP). We prove that classical Rauch--Tung--Striebel (RTS) smoothers, such as the extended Kalman smoother (EKS) or the unscented Kalman smoother (UKS), are special cases of our message passing scheme. Running the message passing scheme more than once can lead to significant improvements of the classical RTS smoothers, so that more informative state estimates can be obtained. We address potential convergence issues of EP by generalising our state estimation framework to damped updates and the consideration of general $\\alpha$-divergences",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanket Kamthe",
      "So Takao",
      "Shakir Mohamed",
      "Marc Peter Deisenroth"
    ]
  },
  "https://openreview.net/forum?id=SEUGkraMPi": {
    "title": "The Graph Cut Kernel for Ranked Data",
    "volume": "main",
    "abstract": "Many algorithms for ranked data become computationally intractable as the number of objects grows due to the complex geometric structure induced by rankings. An additional challenge is posed by partial rankings, i.e. rankings in which the preference is only known for a subset of all objects. For these reasons, state-of-the-art methods cannot scale to real-world applications, such as recommender systems. We address this challenge by exploiting the geometric structure of ranked data and additional available information about the objects to derive a kernel for ranking based on the graph cut function. The graph cut kernel combines the efficiency of submodular optimization with the theoretical properties of kernel-based methods. We demonstrate that our novel kernel drastically reduces the computational cost while maintaining the same accuracy as state-of-the-art methods",
    "checked": true,
    "id": "5ebff195b662b53b0a46236c04573cab20ab86e2",
    "semantic_title": "the graph cut kernel for ranked data",
    "citation_count": 0,
    "authors": [
      "Michelangelo Conserva",
      "Marc Peter Deisenroth",
      "K S Sesh Kumar"
    ]
  },
  "https://openreview.net/forum?id=zlQXV7xtZs": {
    "title": "NoiLin: Improving adversarial training and correcting stereotype of noisy labels",
    "volume": "main",
    "abstract": "Adversarial training (AT) formulated as the minimax optimization problem can effectively enhance the model's robustness against adversarial attacks. The existing AT methods mainly focused on manipulating the inner maximization for generating quality adversarial variants or manipulating the outer minimization for designing effective learning objectives. However, empirical results of AT always exhibit the robustness at odds with accuracy and the existence of the cross-over mixture problem, which motivates us to study some label randomness for benefiting the AT. First, we thoroughly investigate noisy labels (NLs) injection into AT's inner maximization and outer minimization, respectively and obtain some observations on when NL injection benefits AT. Second, based on the observations, we propose a simple but effective method---NoiLIn that randomly injects NLs into training data at each training epoch and dynamically increases the NL injection rate once robust overfitting occurs. Empirically, NoiLIn can significantly mitigate the AT's undesirable issue of robust overfitting and even further improve the generalization of the state-of-the-art AT methods. Philosophically, NoiLIn sheds light on a new perspective of learning with NLs: NLs should not always be deemed detrimental, and even in the absence of NLs in the training set, we may consider injecting them deliberately",
    "checked": true,
    "id": "c66eb4446673199f9a7c95d8a9e6f2caad7cf585",
    "semantic_title": "noilin: improving adversarial training and correcting stereotype of noisy labels",
    "citation_count": 9,
    "authors": [
      "Jingfeng Zhang",
      "Xilie Xu",
      "Bo Han",
      "Tongliang Liu",
      "Lizhen Cui",
      "Gang Niu",
      "Masashi Sugiyama"
    ]
  },
  "https://openreview.net/forum?id=tnPjQpYk7D": {
    "title": "Multi-Agent Off-Policy TDC with Near-Optimal Sample and Communication Complexities",
    "volume": "main",
    "abstract": "The finite-time convergence of off-policy temporal difference (TD) learning has been comprehensively studied recently. However, such a type of convergence has not been established for off-policy TD learning in the multi-agent setting, which covers broader reinforcement learning applications and is fundamentally more challenging. This work develops a decentralized TD with correction (TDC) algorithm for multi-agent off-policy TD learning under Markovian sampling. In particular, our algorithm avoids sharing the actions, policies and rewards of the agents, and adopts mini-batch sampling to reduce the sampling variance and communication frequency. Under Markovian sampling and linear function approximation, we proved that the finite-time sample complexity of our algorithm for achieving an $\\epsilon$-accurate solution is in the order of $\\mathcal{O}\\big(\\frac{M\\ln\\epsilon^{-1}}{\\epsilon(1-\\sigma_2)^2}\\big)$, where $M$ denotes the total number of agents and $\\sigma_2$ is a network parameter. This matches the sample complexity of the centralized TDC. Moreover, our algorithm achieves the optimal communication complexity $\\mathcal{O}\\big(\\frac{\\sqrt{M}\\ln\\epsilon^{-1}}{1-\\sigma_2}\\big)$ for synchronizing the value function parameters, which is order-wise lower than the communication complexity of the existing decentralized TD(0). Numerical simulations corroborate our theoretical findings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyi Chen",
      "Yi Zhou",
      "Rong-Rong Chen"
    ]
  },
  "https://openreview.net/forum?id=GvF9ktXI1V": {
    "title": "Benchmarking and Analyzing Unsupervised Network Representation Learning and the Illusion of Progress",
    "volume": "main",
    "abstract": "A number of methods have been developed for unsupervised network representation learning -- ranging from classical methods based on the graph spectra to recent random walk based methods and from deep learning based methods to matrix factorization based methods. Each new study inevitably seeks to establish the relative superiority of the proposed method over others. The lack of a standard assessment protocol and benchmark suite often leave practitioners wondering if a new idea represents a significant scientific advance. In this work, we articulate a clear and pressing need to systematically and rigorously benchmark such methods. Our overall assessment -- a result of a careful benchmarking of 15 methods for unsupervised network representation learning on 16 non-attributed graphs (several with different characteristics) - is that many recently proposed improvements are somewhat of an illusion when assessed through the lens of downstream tasks such as link prediction and node classification. Specifically, we find that several proposed improvements are marginal at best and that aspects of many of these datasets often render such small differences insignificant, especially when viewed from a rigorous statistical lens. A more detailed analysis of our results identify several new insights: first, we find that classical methods, often dismissed or not considered by recent efforts, can compete on certain types of datasets if they are tuned appropriately; second, we find that from a qualitative standpoint, a couple of methods based on matrix factorization offer a small but not always consistent advantage over alternative methods; third, no single method completely outperforms other embedding methods on both node classification and link prediction tasks. Finally, we also present several analysis that reveals settings under which certain algorithms perform well (e.g., the role of neighborhood context and dataset properties that impact performance). An important outcome of this study is the benchmark and evaluation protocol, which practitioners may find useful for future research in this area",
    "checked": true,
    "id": "44b7903158323426053dca317b8c29d8cd64c635",
    "semantic_title": "benchmarking and analyzing unsupervised network representation learning and the illusion of progress",
    "citation_count": 3,
    "authors": [
      "Saket Gurukar",
      "Priyesh Vijayan",
      "srinivasan parthasarathy",
      "Balaraman Ravindran",
      "Aakash Srinivasan",
      "Goonmeet Bajaj",
      "Chen Cai",
      "Moniba Keymanesh",
      "Saravana Kumar",
      "Pranav Maneriker",
      "Anasua Mitra",
      "Vedang Patel"
    ]
  },
  "https://openreview.net/forum?id=ZPBJPGX3Bz": {
    "title": "Decoding EEG With Spiking Neural Networks on Neuromorphic Hardware",
    "volume": "main",
    "abstract": "Decoding motor activity accurately and reliably from electroencephalography (EEG) signals is essential for several portable brain-computer interface (BCI) applications ranging from neural prosthetics to the control of industrial and mobile robots. Spiking neural networks (SNNs) is an emerging brain-inspired architecture that is well-suited for decoding EEG signals due to their built-in ability to integrate information at multiple timescales, leading to energy-efficient solutions for portable BCI. In practice, however, current SNN solutions suffer from i) an inefficient spike encoding of the EEG signals; ii) non-specialized network architectures that cannot capture EEG priors of spatiotemporal dependencies; and iii) the limited generalizability of the local learning rules commonly used to train the networks. These untapped challenges result in a performance gap between the current SNN approaches and the state-of-the-art deep neural network (DNN) methods. Moreover, the black-box nature of most current SNN solutions masks their correspondence with the underlying neurophysiology, further hindering their reliability for real-world applications. Here, we propose an SNN architecture with an input encoding and network design that exploits the priors of spatial and temporal dependencies in the EEG signal. To extract spatiotemporal features, the network comprised of spatial convolutional, temporal convolutional, and recurrent layers. The network weights and the neuron membrane parameters were trained jointly using gradient descent and our method was validated in classifying movement on two datasets: i) an in-house dataset comprising of complex components of movement, namely reaction time and directions, and ii) the publicly available eegmmidb dataset for motor imagery and movement. We deployed our SNN on Intel's Loihi neuromorphic processor, and show that our method consumed 95\\% less energy per inference than the state-of-the-art DNN methods on NVIDIA Jeston TX2, while achieving similar levels of classification performance. Finally, we interpreted the SNN using a network perturbation study to identify the spectral bands and brain activity that correlated with the SNN outputs. The results were in agreement with the current neurophysiological knowledge implicating the activation patterns in the low-frequency oscillations over the motor cortex for hand movement and imagery tasks. Overall, our approach demonstrates the effectiveness of SNNs in accurately and reliably decoding EEG while availing the computational advantages offered by neuromorphic computing, and paves the way for employing neuromorphic methods in portable BCI systems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neelesh Kumar",
      "Guangzhi Tang",
      "Raymond Yoo",
      "Konstantinos P. Michmizos"
    ]
  },
  "https://openreview.net/forum?id=8HuyXvbvqX": {
    "title": "Understanding Linearity of Cross-Lingual Word Embedding Mappings",
    "volume": "main",
    "abstract": "The technique of Cross-Lingual Word Embedding (CLWE) plays a fundamental role in tackling Natural Language Processing challenges for low-resource languages. Its dominant approaches assumed that the relationship between embeddings could be represented by a linear mapping, but there has been no exploration of the conditions under which this assumption holds. Such a research gap becomes very critical recently, as it has been evidenced that relaxing mappings to be non-linear can lead to better performance in some cases. We, for the first time, present a theoretical analysis that identifies the preservation of analogies encoded in monolingual word embeddings as a *necessary and sufficient* condition for the ground-truth CLWE mapping between those embeddings to be linear. On a novel cross-lingual analogy dataset that covers five representative analogy categories for twelve distinct languages, we carry out experiments which provide direct empirical support for our theoretical claim. These results offer additional insight into the observations of other researchers and contribute inspiration for the development of more effective cross-lingual representation learning strategies",
    "checked": true,
    "id": "bf3dd9a71535ac8ed6403ffda2dfa353d05fca2d",
    "semantic_title": "understanding linearity of cross-lingual word embedding mappings",
    "citation_count": 5,
    "authors": [
      "Xutan Peng",
      "Mark Stevenson",
      "Chenghua Lin",
      "Chen Li"
    ]
  },
  "https://openreview.net/forum?id=Euf7KofunK": {
    "title": "Clustering units in neural networks: upstream vs downstream information",
    "volume": "main",
    "abstract": "It has been hypothesized that some form of \"modular\" structure in artificial neural networks should be useful for learning, compositionality, and generalization. However, defining and quantifying modularity remains an open problem. We cast the problem of detecting functional modules into the problem of detecting clusters of similar-functioning units. This begs the question of what makes two units functionally similar. For this, we consider two broad families of methods: those that define similarity based on how units respond to structured variations in inputs (\"upstream\"), and those based on how variations in hidden unit activations affect outputs (\"downstream\"). We conduct an empirical study quantifying modularity of hidden layer representations of a collection of feedforward networks trained on classification tasks, across a range of hyperparameters. For each model, we quantify pairwise associations between hidden units in each layer using a variety of both upstream and downstream measures, then cluster them by maximizing their \"modularity score\" using established tools from network science. We find two surprising results: first, dropout dramatically increased modularity, while other forms of weight regularization had more modest effects. Second, although we observe that there is usually good agreement about clusters within both upstream methods and downstream methods, there is little agreement about the cluster assignments across these two families of methods. This has important implications for representation-learning, as it suggests that finding modular representations that reflect structure in inputs (e.g. disentanglement) may be a distinct goal from learning modular representations that reflect structure in outputs (e.g. compositionality)",
    "checked": true,
    "id": "ebdd22411e27a05191d736f7f04be2d56fd77baa",
    "semantic_title": "clustering units in neural networks: upstream vs downstream information",
    "citation_count": 11,
    "authors": [
      "Richard D Lange",
      "David Rolnick",
      "Konrad Kording"
    ]
  },
  "https://openreview.net/forum?id=0ZbPmmB61g": {
    "title": "Boosting Search Engines with Interactive Agents",
    "volume": "main",
    "abstract": "This paper presents first successful steps in designing search agents that learn meta-strategies for iterative query refinement in information-seeking tasks. Our approach uses machine reading to guide the selection of refinement terms from aggregated search results. Agents are then empowered with simple but effective search operators to exert fine-grained and transparent control over queries and search results. We develop a novel way of generating synthetic search sessions, which leverages the power of transformer-based language models through (self-)supervised learning. We also present a reinforcement learning agent with dynamically constrained actions that learns interactive search strategies from scratch. Our search agents obtain retrieval and answer quality performance comparable to recent neural methods, using only a traditional term-based BM25 ranking function and interpretable discrete reranking and filtering actions",
    "checked": true,
    "id": "8319c672980360ce38d853a6d674352f03943434",
    "semantic_title": "boosting search engines with interactive agents",
    "citation_count": 24,
    "authors": [
      "Leonard Adolphs",
      "Benjamin B√∂rschinger",
      "Christian Buck",
      "Michelle Chen Huebscher",
      "Massimiliano Ciaramita",
      "Lasse Espeholt",
      "Thomas Hofmann",
      "Yannic Kilcher",
      "Sascha Rothe",
      "Pier Giuseppe Sessa",
      "Lierni Sestorain"
    ]
  },
  "https://openreview.net/forum?id=P1DuPJzVTN": {
    "title": "Greedy Bayesian Posterior Approximation with Deep Ensembles",
    "volume": "main",
    "abstract": "Ensembles of independently trained neural networks are a state-of-the-art approach to estimate predictive uncertainty in Deep Learning, and can be interpreted as an approximation of the posterior distribution via a mixture of delta functions. The training of ensembles relies on non-convexity of the loss landscape and random initialization of their individual members, making the resulting posterior approximation uncontrolled. This paper proposes a novel and principled method to tackle this limitation, minimizing an $f$-divergence between the true posterior and a kernel density estimator (KDE) in a function space. We analyze this objective from a combinatorial point of view, and show that it is submodular with respect to mixture components for any $f$. Subsequently, we consider the problem of greedy ensemble construction. From the marginal gain on the negative $f$-divergence, which quantifies an improvement in posterior approximation yielded by adding a new component into the KDE, we derive a novel diversity term for ensemble methods. The performance of our approach is demonstrated on computer vision out-of-distribution detection benchmarks in a range of architectures trained on multiple datasets. The source code of our method is made publicly available at https://github.com/Oulu-IMEDS/greedy_ensembles_training",
    "checked": true,
    "id": "504f0aa3808009aa61ed67894bb27243dd6a8608",
    "semantic_title": "greedy bayesian posterior approximation with deep ensembles",
    "citation_count": 4,
    "authors": [
      "Aleksei Tiulpin",
      "Matthew B. Blaschko"
    ]
  },
  "https://openreview.net/forum?id=KKeCMim5VN": {
    "title": "Auto-Lambda: Disentangling Dynamic Task Relationships",
    "volume": "main",
    "abstract": "Understanding the structure of multiple related tasks allows for multi-task learning to improve the generalisation ability of one or all of them. However, it usually requires training each pairwise combination of tasks together in order to capture task relationships, at an extremely high computational cost. In this work, we learn task relationships via an automated weighting framework, named Auto-Lambda. Unlike previous methods where task relationships are assumed to be fixed, i.e., task should either be trained together or not trained together, Auto-Lambda explores continuous, dynamic task relationships via task-specific weightings, and can optimise any choice of combination of tasks through the formulation of a meta-loss; where the validation loss automatically influences task weightings throughout training. We apply the proposed framework to both multi-task and auxiliary learning problems in computer vision and robotics, and show that AutoLambda achieves state-of-the-art performance, even when compared to optimisation strategies designed specifically for each problem and data domain. Finally, we observe that Auto-Lambda can discover interesting learning behaviors, leading to new insights in multi-task learning. Code is available at https://github.com/lorenmt/auto-lambda",
    "checked": true,
    "id": "96a1a24fb75635bd5a27b8e4034d0faef5f99ad5",
    "semantic_title": "auto-lambda: disentangling dynamic task relationships",
    "citation_count": 78,
    "authors": [
      "Shikun Liu",
      "Stephen James",
      "Andrew Davison",
      "Edward Johns"
    ]
  },
  "https://openreview.net/forum?id=4nPswr1KcP": {
    "title": "How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers",
    "volume": "main",
    "abstract": "Vision Transformers (ViT) have been shown to attain highly competitive performance for a wide range of vision applications, such as image classification, object detection and semantic image segmentation. In comparison to convolutional neural networks, the Vision Transformer's weaker inductive bias is generally found to cause an increased reliance on model regularization or data augmentation (``AugReg'' for short) when training on smaller training datasets. We conduct a systematic empirical study in order to better understand the interplay between the amount of training data, AugReg, model size and compute budget. As one result of this study we find that the combination of increased compute and AugReg can yield models with the same performance as models trained on an order of magnitude more training data: we train ViT models of various sizes on the public ImageNet-21k dataset which either match or outperform their counterparts trained on the larger, but not publicly available JFT-300M dataset",
    "checked": true,
    "id": "cf5e6e3c50a798d87033e0e108e88b3647738bbe",
    "semantic_title": "how to train your vit? data, augmentation, and regularization in vision transformers",
    "citation_count": 639,
    "authors": [
      "Andreas Peter Steiner",
      "Alexander Kolesnikov",
      "Xiaohua Zhai",
      "Ross Wightman",
      "Jakob Uszkoreit",
      "Lucas Beyer"
    ]
  },
  "https://openreview.net/forum?id=3gfpBR1ncr": {
    "title": "On Characterizing the Trade-off in Invariant Representation Learning",
    "volume": "featured",
    "abstract": "Many applications of representation learning, such as privacy preservation, algorithmic fairness, and domain adaptation, desire explicit control over semantic information being discarded. This goal is formulated as satisfying two objectives: maximizing utility for predicting a target attribute while simultaneously being invariant (independent) to a known semantic attribute. Solutions to invariant representation learning (IRepL) problems lead to a trade-off between utility and invariance when they are competing. While existing works study bounds on this trade-off, two questions remain outstanding: 1) What is the exact trade-off between utility and invariance? and 2) What are the encoders (mapping the data to a representation) that achieve the trade-off, and how can we estimate it from training data? This paper addresses these questions for IRepLs in reproducing kernel Hilbert spaces (RKHS)s. Under the assumption that the distribution of a low-dimensional projection of high-dimensional data is approximately normal, we derive a closed-form solution for the global optima of the underlying optimization problem for encoders in RKHSs. This yields closed formulae for a near-optimal trade-off, corresponding optimal representation dimensionality, and the corresponding encoder(s). We also numerically quantify the trade-off on representative problems and compare them to those achieved by baseline IRepL algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bashir Sadeghi",
      "Sepehr Dehdashtian",
      "Vishnu Boddeti"
    ]
  },
  "https://openreview.net/forum?id=1ikK0kHjvj": {
    "title": "A Generalist Agent",
    "volume": "outstanding",
    "abstract": "Inspired by progress in large-scale language modeling, we apply a similar approach towards building a single generalist agent beyond the realm of text outputs. The agent, which we refer to as Gato, works as a multi-modal, multi-task, multi-embodiment generalist policy. The same network with the same weights can play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens. In this report we describe the model and the data, and document the current capabilities of Gato",
    "checked": true,
    "id": "5922f437512158970c417f4413bface021df5f78",
    "semantic_title": "a generalist agent",
    "citation_count": 827,
    "authors": [
      "Scott Reed",
      "Konrad Zolna",
      "Emilio Parisotto",
      "Sergio G√≥mez Colmenarejo",
      "Alexander Novikov",
      "Gabriel Barth-maron",
      "Mai Gim√©nez",
      "Yury Sulsky",
      "Jackie Kay",
      "Jost Tobias Springenberg",
      "Tom Eccles",
      "Jake Bruce",
      "Ali Razavi",
      "Ashley Edwards",
      "Nicolas Heess",
      "Yutian Chen",
      "Raia Hadsell",
      "Oriol Vinyals",
      "Mahyar Bordbar",
      "Nando de Freitas"
    ]
  },
  "https://openreview.net/forum?id=AFDcYJKhND": {
    "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation",
    "volume": "featured",
    "abstract": "We present the Pathways Autoregressive Text-to-Image (Parti) model, which generates high-fidelity photorealistic images and supports content-rich synthesis involving complex compositions and world knowledge. Parti treats text-to-image generation as a sequence-to-sequence modeling problem, akin to machine translation, with sequences of image tokens as the target outputs rather than text tokens in another language. This strategy can naturally tap into the rich body of prior work on large language models, which have seen continued advances in capabilities and performance through scaling data and model sizes. Our approach is simple: First, Parti uses a Transformer-based image tokenizer, ViT-VQGAN, to encode images as sequences of discrete tokens. Second, we achieve consistent quality improvements by scaling the encoder-decoder Transformer model up to 20B parameters, with a new state-of-the-art zero-shot FID score of 7.23 and finetuned FID score of 3.22 on MS-COCO. Our detailed analysis on Localized Narratives as well as PartiPrompts (P2), a new holistic benchmark of over 1600 English prompts, demonstrate the effectiveness of Parti across a wide variety of categories and difficulty aspects. We also explore and highlight limitations of our models in order to define and exemplify key areas of focus for further improvements",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahui Yu",
      "Yuanzhong Xu",
      "Jing Yu Koh",
      "Thang Luong",
      "Gunjan Baid",
      "Zirui Wang",
      "Vijay Vasudevan",
      "Alexander Ku",
      "Yinfei Yang",
      "Burcu Karagol Ayan",
      "Ben Hutchinson",
      "Wei Han",
      "Zarana Parekh",
      "Xin Li",
      "Han Zhang",
      "Jason Baldridge",
      "Yonghui Wu"
    ]
  },
  "https://openreview.net/forum?id=oLvlPJheCD": {
    "title": "Queried Unlabeled Data Improves and Robustifies Class-Incremental Learning",
    "volume": "featured",
    "abstract": "Class-incremental learning (CIL) suffers from the notorious dilemma between learning newly added classes and preserving previously learned class knowledge. That catastrophic forgetting issue could be mitigated by storing historical data for replay, which yet would cause memory overheads as well as imbalanced prediction updates. To address this dilemma, we propose to leverage \"free\" external unlabeled data querying in continual learning. We first present a CIL with Queried Unlabeled Data (CIL-QUD) scheme, where we only store a handful of past training samples as anchors and use them to query relevant unlabeled examples each time. Along with new and past stored data, the queried unlabeled are effectively utilized, through learning-without-forgetting (LwF) regularizers and class-balance training. Besides preserving model generalization over past and current tasks, we next study the problem of adversarial robustness for CIL-QUD. Inspired by the recent success of learning robust models with unlabeled data, we explore a new robustness-aware CIL setting, where the learned adversarial robustness has to resist forgetting and be transferred as new tasks come in continually. While existing options easily fail, we show queried unlabeled data can continue to benefit, and seamlessly extend CIL-QUD into its robustified versions, RCIL-QUD. Extensive experiments demonstrate that CIL-QUD achieves substantial accuracy gains on CIFAR-10 and CIFAR-100, compared to previous state-of-the-art CIL approaches. Moreover, RCIL-QUD establishes the first strong milestone for robustness-aware CIL. Codes are available in https://github.com/VITA-Group/CIL-QUD",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianlong Chen",
      "Sijia Liu",
      "Shiyu Chang",
      "Lisa Amini",
      "Zhangyang Wang"
    ]
  },
  "https://openreview.net/forum?id=GFK1FheE7F": {
    "title": "Deconstructing Self-Supervised Monocular Reconstruction: The Design Decisions that Matter",
    "volume": "reprod",
    "abstract": "",
    "checked": true,
    "id": "e707a2e087a791467cc42b61ec6d6dcc9d55ee19",
    "semantic_title": "deconstructing self-supervised monocular reconstruction: the design decisions that matter",
    "citation_count": 22,
    "authors": [
      "Jaime Spencer",
      "Chris Russell",
      "Simon Hadfield",
      "Richard Bowden"
    ]
  },
  "https://openreview.net/forum?id=sX9d3gfwtE": {
    "title": "Non-Deterministic Behavior of Thompson Sampling with Linear Payoffs and How to Avoid It",
    "volume": "reprod",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Doruk Kilitcioglu",
      "Serdar Kadioglu"
    ]
  },
  "https://openreview.net/forum?id=vwOKBldzFu": {
    "title": "A Snapshot of the Frontiers of Client Selection in Federated Learning",
    "volume": "survey",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gergely D√°niel N√©meth",
      "Miguel Angel Lozano",
      "Novi Quadrianto",
      "Nuria M Oliver"
    ]
  },
  "https://openreview.net/forum?id=NljBlZ6hmG": {
    "title": "Action Noise in Off-Policy Deep Reinforcement Learning: Impact on Exploration and Performance",
    "volume": "survey",
    "abstract": "",
    "checked": true,
    "id": "3f66a70a181e9cd1cd8d0760c6c5e7a6f3ff2006",
    "semantic_title": "action noise in off-policy deep reinforcement learning: impact on exploration and performance",
    "citation_count": 21,
    "authors": [
      "Jakob Hollenstein",
      "Sayantan Auddy",
      "Matteo Saveriano",
      "Erwan Renaudo",
      "Justus Piater"
    ]
  },
  "https://openreview.net/forum?id=yzkSU5zdwD": {
    "title": "Emergent Abilities of Large Language Models",
    "volume": "survey",
    "abstract": "Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models. Thus, emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence raises the question of whether additional scaling could potentially further expand the range of capabilities of language models",
    "checked": true,
    "id": "dac3a172b504f4e33c029655e9befb3386e5f63a",
    "semantic_title": "emergent abilities of large language models",
    "citation_count": 2527,
    "authors": [
      "Jason Wei",
      "Yi Tay",
      "Rishi Bommasani",
      "Colin Raffel",
      "Barret Zoph",
      "Sebastian Borgeaud",
      "Dani Yogatama",
      "Maarten Bosma",
      "Denny Zhou",
      "Donald Metzler",
      "Ed H. Chi",
      "Tatsunori Hashimoto",
      "Oriol Vinyals",
      "Percy Liang",
      "Jeff Dean",
      "William Fedus"
    ]
  },
  "https://openreview.net/forum?id=ywr5sWqQt4": {
    "title": "A Comprehensive Study of Real-Time Object Detection Networks Across Multiple Domains: A Survey",
    "volume": "survey",
    "abstract": "Deep neural network based object detectors are continuously evolving and are used in a multitude of applications, each having its own set of requirements. While safety-critical applications need high accuracy and reliability, low-latency tasks need resource and energy-efficient networks. Real-time detection networks, which are a necessity in high-impact real-world applications, are continuously proposed but they overemphasize the improvements in accuracy and speed while other capabilities such as versatility, robustness, resource, and energy efficiency are omitted. A reference benchmark for existing networks does not exist nor does a standard evaluation guideline for designing new networks, which results in ambiguous and inconsistent comparisons. We, therefore, conduct a comprehensive study on multiple real-time detection networks (anchor-based, keypoint-based, and transformer-based) on a wide range of datasets and report results on an extensive set of metrics. We also study the impact of variables such as image size, anchor dimensions, confidence thresholds, and architecture layers on the overall performance. We analyze the robustness of detection networks against distribution shift, natural corruptions, and adversarial attacks. Also, we provide the calibration analysis to gauge the reliability of the predictions. Finally, to highlight the real-world impact, we conduct two unique case studies, on autonomous driving and healthcare application. To further gauge the capability of networks in critical real-time applications, we report the performance after deploying the detection networks on edge devices. Our extensive empirical study can act as a guideline for the industrial community to make an informed choice on the existing networks. We also hope to inspire the research community towards a new direction of design and evaluation of networks that focuses on the bigger and holistic overview for a far-reaching impact",
    "checked": true,
    "id": "e5348590528ec3f785efe841ebba53881db2addf",
    "semantic_title": "a comprehensive study of real-time object detection networks across multiple domains: a survey",
    "citation_count": 28,
    "authors": [
      "Elahe Arani",
      "Shruthi Gowda",
      "Ratnajit Mukherjee",
      "Omar Magdy",
      "Senthilkumar Sockalingam Kathiresan",
      "Bahram Zonooz"
    ]
  },
  "https://openreview.net/forum?id=LTyqvLEv5b": {
    "title": "On the link between conscious function and general intelligence in humans and machines",
    "volume": "survey",
    "abstract": "In popular media, there is often a connection drawn between the advent of awareness in artificial agents and those same agents simultaneously achieving human or superhuman level intelligence. In this work, we explore the validity and potential application of this seemingly intuitive link between consciousness and intelligence. We do so by examining the cognitive abilities associated with three contemporary theories of conscious function: Global Workspace Theory (GWT), Information Generation Theory (IGT), and Attention Schema Theory (AST). We find that all three theories specifically relate conscious function to some aspect of domain-general intelligence in humans. With this insight, we turn to the field of Artificial Intelligence (AI) and find that, while still far from demonstrating general intelligence, many state-of-the-art deep learning methods have begun to incorporate key aspects of each of the three functional theories. Having identified this trend, we use the motivating example of mental time travel in humans to propose ways in which insights from each of the three theories may be combined into a single unified and implementable model. Given that it is made possible by cognitive abilities underlying each of the three functional theories, artificial agents capable of mental time travel would not only possess greater general intelligence than current approaches, but also be more consistent with our current understanding of the functional role of consciousness in humans, thus making it a promising near-term goal for AI research",
    "checked": true,
    "id": "0f4fff63f5f637e0f807532e37462e0619c86568",
    "semantic_title": "on the link between conscious function and general intelligence in humans and machines",
    "citation_count": 26,
    "authors": [
      "Arthur Juliani",
      "Kai Arulkumaran",
      "Shuntaro Sasai",
      "Ryota Kanai"
    ]
  },
  "https://openreview.net/forum?id=gzhEGhcsnN": {
    "title": "Structural Learning in Artificial Neural Networks: A Neural Operator Perspective",
    "volume": "survey",
    "abstract": "Over the history of Artificial Neural Networks (ANNs), only a minority of algorithms integrate structural changes of the network architecture into the learning process. Modern neuroscience has demonstrated that biological learning is largely structural, with mechanisms such as synaptogenesis and neurogenesis present in adult brains and considered important for learning. Despite this history of artificial methods and biological inspiration, and furthermore the recent resurgence of neural methods in deep learning, relatively few current ANN methods include structural changes in learning compared to those that only adjust synaptic weights during the training process. We aim to draw connections between different approaches of structural learning that have similar abstractions in order to encourage collaboration and development. In this review, we provide a survey on structural learning methods in deep ANNs, including a new neural operator framework from a cellular neuroscience context and perspective aimed at motivating research on this challenging topic. We then provide an overview of ANN methods which include structural changes within the neural operator framework in the learning process, characterizing each neural operator in detail and drawing connections to their biological counterparts. Finally, we present overarching trends in how these operators are implemented and discuss the open challenges in structural learning in ANNs",
    "checked": true,
    "id": "90266d568b9ad0d5113b16f77907579660d1098c",
    "semantic_title": "structural learning in artificial neural networks: a neural operator perspective",
    "citation_count": 7,
    "authors": [
      "Kaitlin Maile",
      "Luga Herv√©",
      "Dennis George Wilson"
    ]
  },
  "https://openreview.net/forum?id=P9Cj6RJmN2": {
    "title": "A Stochastic Optimization Framework for Fair Risk Minimization",
    "volume": "expert",
    "abstract": "Despite the success of large-scale empirical risk minimization (ERM) at achieving high accuracy across a variety of machine learning tasks, fair ERM is hindered by the incompatibility of fairness constraints with stochastic optimization. We consider the problem of fair classification with discrete sensitive attributes and potentially large models and data sets, requiring stochastic solvers. Existing in-processing fairness algorithms are either impractical in the large-scale setting because they require large batches of data at each iteration or they are not guaranteed to converge. In this paper, we develop the first stochastic in-processing fairness algorithm with guaranteed convergence. For demographic parity, equalized odds, and equal opportunity notions of fairness, we provide slight variations of our algorithm‚Äìcalled FERMI‚Äìand prove that each of these variations converges in stochastic optimization with any batch size. Empirically, we show that FERMI is amenable to stochastic solvers with multiple (non-binary) sensitive attributes and non-binary targets, performing well even with minibatch size as small as one. Extensive experiments show that FERMI achieves the most favorable tradeoffs between fairness violation and test accuracy across all tested setups compared with state-of-the-art baselines for demographic parity, equalized odds, equal opportunity. These benefits are especially significant with small batch sizes and for non-binary classification with large number of sensitive attributes, making FERMI a practical, scalable fairness algorithm. The code for all of the experiments in this paper is available at: https://github.com/optimization-for-data-driven-science/FERMI",
    "checked": true,
    "id": "9e99a264ec35057069b754497469679d03e93fd9",
    "semantic_title": "a stochastic optimization framework for fair risk minimization",
    "citation_count": 21,
    "authors": [
      "Andrew Lowy",
      "Sina Baharlouei",
      "Rakesh Pavan",
      "Meisam Razaviyayn",
      "Ahmad Beirami"
    ]
  },
  "https://openreview.net/forum?id=vqRzLv6POg": {
    "title": "If your data distribution shifts, use self-learning",
    "volume": "expert",
    "abstract": "We demonstrate that self-learning techniques like entropy minimization and pseudo-labeling are simple and effective at improving performance of a deployed computer vision model under systematic domain shifts. We conduct a wide range of large-scale experiments and show consistent improvements irrespective of the model architecture, the pre-training technique or the type of distribution shift. At the same time, self-learning is simple to use in practice because it does not require knowledge or access to the original training data or scheme, is robust to hyperparameter choices, is straight-forward to implement and requires only a few adaptation epochs. This makes self-learning techniques highly attractive for any practitioner who applies machine learning algorithms in the real world. We present state-of-the-art adaptation results on CIFAR10-C (8.5% error), ImageNet-C (22.0% mCE), ImageNet-R (17.4% error) and ImageNet-A (14.8% error), theoretically study the dynamics of self-supervised adaptation methods and propose a new classification dataset (ImageNet-D) which is challenging even with adaptation",
    "checked": true,
    "id": "1c08331ef62dd4ddaa30bdd35b26ee0cfc241ec7",
    "semantic_title": "if your data distribution shifts, use self-learning",
    "citation_count": 33,
    "authors": [
      "Evgenia Rusak",
      "Steffen Schneider",
      "George Pachitariu",
      "Luisa Eck",
      "Peter Vincent Gehler",
      "Oliver Bringmann",
      "Wieland Brendel",
      "Matthias Bethge"
    ]
  },
  "https://openreview.net/forum?id=UVDAKQANOW": {
    "title": "Unifying Approaches in Active Learning and Active Sampling via Fisher Information and Information-Theoretic Quantities",
    "volume": "expert",
    "abstract": "Recently proposed methods in data subset selection, that is active learning and active sampling, use Fisher information, Hessians, similarity matrices based on gradients, and gradient lengths to estimate how informative data is for a model's training. Are these different approaches connected, and if so, how? We revisit the fundamentals of Bayesian optimal experiment design and show that these recently proposed methods can be understood as approximations to information-theoretic quantities: among them, the mutual information between predictions and model parameters, known as expected information gain or BALD in machine learning, and the mutual information between predictions of acquisition candidates and test samples, known as expected predictive information gain. We develop a comprehensive set of approximations using Fisher information and observed information and derive a unified framework that connects seemingly disparate literature. Although Bayesian methods are often seen as separate from non-Bayesian ones, the sometimes fuzzy notion of \"informativeness\" expressed in various non-Bayesian objectives leads to the same couple of information quantities, which were, in principle, already known by Lindley (1956) and MacKay (1992)",
    "checked": true,
    "id": "ccffe716578d5d6ec3a89002a113f6158fb2a774",
    "semantic_title": "unifying approaches in active learning and active sampling via fisher information and information-theoretic quantities",
    "citation_count": 23,
    "authors": [
      "Andreas Kirsch",
      "Yarin Gal"
    ]
  },
  "https://openreview.net/forum?id=MhK5aXo3gB": {
    "title": "Convergence of denoising diffusion models under the manifold hypothesis",
    "volume": "expert",
    "abstract": "Denoising diffusion models are a recent class of generative models exhibiting state-of-the-art performance in image and audio synthesis. Such models approximate the time-reversal of a forward noising process from a target distribution to a reference measure, which is usually Gaussian. Despite their strong empirical results, the theoretical analysis of such models remains limited. In particular, all current approaches crucially assume that the target density admits a density w.r.t. the Lebesgue measure. This does not cover settings where the target distribution is supported on a lower-dimensional manifold or is given by some empirical distribution. In this paper, we bridge this gap by providing the first convergence results for diffusion models in this setting. In particular, we provide quantitative bounds on the Wasserstein distance of order one between the target data distribution and the generative distribution of the diffusion model",
    "checked": true,
    "id": "1b89413384801db90059abe4b6c00d8d6b0375ce",
    "semantic_title": "convergence of denoising diffusion models under the manifold hypothesis",
    "citation_count": 171,
    "authors": [
      "Valentin De Bortoli"
    ]
  },
  "https://openreview.net/forum?id=oRP8urZ8Fx": {
    "title": "A Note on \"Assessing Generalization of SGD via Disagreement",
    "volume": "expert",
    "abstract": "Several recent works find empirically that the average test error of deep neural networks can be estimated via the prediction disagreement of models, which does not require labels. In particular, Jiang et al. (2022) show for the disagreement between two separately trained networks that this `Generalization Disagreement Equality' follows from the well-calibrated nature of deep ensembles under the notion of a proposed `class-aggregated calibration.' In this reproduction, we show that the suggested theory might be impractical because a deep ensemble's calibration can deteriorate as prediction disagreement increases, which is precisely when the coupling of test error and disagreement is of interest, while labels are needed to estimate the calibration on new datasets. Further, we simplify the theoretical statements and proofs, showing them to be straightforward within a probabilistic context, unlike the original hypothesis space view employed by Jiang et al. (2022)",
    "checked": true,
    "id": "db4cfd1b9cd200eb2a32b026a568713b0c34562f",
    "semantic_title": "a note on \"assessing generalization of sgd via disagreement",
    "citation_count": 16,
    "authors": [
      "Andreas Kirsch",
      "Yarin Gal"
    ]
  },
  "https://openreview.net/forum?id=vUuHPRrWs2": {
    "title": "Practicality of generalization guarantees for unsupervised domain adaptation with neural networks",
    "volume": "expert",
    "abstract": "Understanding generalization is crucial to confidently engineer and deploy machine learning models, especially when deployment implies a shift in the data domain. For such domain adaptation problems, we seek generalization bounds which are tractably computable and tight. If these desiderata can be reached, the bounds can serve as guarantees for adequate performance in deployment. However, in applications where deep neural networks are the models of choice, deriving results which fulfill these remains an unresolved challenge; most existing bounds are either vacuous or has non-estimable terms, even in favorable conditions. In this work, we evaluate existing bounds from the literature with potential to satisfy our desiderata on domain adaptation image classification tasks, where deep neural networks are preferred. We find that all bounds are vacuous and that sample generalization terms account for much of the observed looseness, especially when these terms interact with measures of domain shift. To overcome this and arrive at the tightest possible results, we combine each bound with recent data-dependent PAC-Bayes analysis, greatly improving the guarantees. We find that, when domain overlap can be assumed, a simple importance weighting extension of previous work provides the tightest estimable bound. Finally, we study which terms dominate the bounds and identify possible directions for further improvement",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adam Breitholtz",
      "Fredrik Daniel Johansson"
    ]
  },
  "https://openreview.net/forum?id=EQpGkw5rvL": {
    "title": "Lookback for Learning to Branch",
    "volume": "expert",
    "abstract": "The expressive and computationally inexpensive bipartite Graph Neural Networks (GNN) have been shown to be an important component of deep learning based Mixed-Integer Linear Program (MILP) solvers. Recent works have demonstrated the effectiveness of such GNNs in replacing the branching (variable selection) heuristic in branch-and-bound B&B solvers. These GNNs are trained, offline and on a collection of MILPs, to imitate a very good but computationally expensive branching heuristic, strong branching. Given that B&B results in a tree of sub-MILPs, we ask (a) whether there are strong dependencies exhibited by the target heuristic among the neighboring nodes of the B&B tree, and (b) if so, whether we can incorporate them in our training procedure. Specifically, we find that with the strong branching heuristic, a child node's best choice was often the parent's second-best choice. We call this the \"lookback\" phenomenon. Surprisingly, the typical branching GNN of Gasse et al. (2019) often misses this simple \"answer\". To imitate the target behavior more closely by incorporating the lookback phenomenon in GNNs, we propose two methods: (a) target smoothing for the standard cross-entropy loss function, and (b) adding a Parent-as-Target (PAT) Lookback regularizer term. Finally, we propose a model selection framework to incorporate harder-to-formulate objectives such as solving time in the final models. Through extensive experimentation on standard benchmark instances, we show that our proposal results in up to 22% decrease in the size of the B&B tree and up to 15% improvement in the solving times",
    "checked": true,
    "id": "3ba3760b969dc5d1ff7cf265979b272ea2f80b20",
    "semantic_title": "lookback for learning to branch",
    "citation_count": 28,
    "authors": [
      "Prateek Gupta",
      "Elias Boutros Khalil",
      "Didier Ch√©telat",
      "Maxime Gasse",
      "Andrea Lodi",
      "Yoshua Bengio",
      "M. Pawan Kumar"
    ]
  },
  "https://openreview.net/forum?id=EDAk6F8yMM": {
    "title": "Local Kernel Ridge Regression for Scalable, Interpolating, Continuous Regression",
    "volume": "expert",
    "abstract": "We study a localized version of kernel ridge regression that can continuously, smoothly interpolate the underlying function values which are highly non-linear with observed data points. This new method can deal with the data of which (a) local density is highly uneven and (b) the function values change dramatically in certain small but unknown regions. By introducing a new rank-based interpolation scheme, the interpolated values provided by our local method continuously vary with query points. Our method is scalable by avoiding the full matrix inverse, compared with traditional kernel ridge regression",
    "checked": true,
    "id": "f9a228c6c98436e74bf93c5949e5ee569d654aa8",
    "semantic_title": "local kernel ridge regression for scalable, interpolating, continuous regression",
    "citation_count": 2,
    "authors": [
      "Mingxuan Han",
      "Chenglong Ye",
      "Jeff Phillips"
    ]
  },
  "https://openreview.net/forum?id=i0ZM36d2qU": {
    "title": "Sparse MoEs meet Efficient Ensembles",
    "volume": "expert",
    "abstract": "Machine learning models based on the aggregated outputs of submodels, either at the activation or prediction levels, often exhibit strong performance compared to individual models. We study the interplay of two popular classes of such models: ensembles of neural networks and sparse mixture of experts (sparse MoEs). First, we show that the two approaches have complementary features whose combination is beneficial. This includes a comprehensive evaluation of sparse MoEs in uncertainty related benchmarks. Then, we present efficient ensemble of experts (E$^3$), a scalable and simple ensemble of sparse MoEs that takes the best of both classes of models, while using up to 45% fewer FLOPs than a deep ensemble. Extensive experiments demonstrate the accuracy, log-likelihood, few-shot learning, robustness, and uncertainty improvements of E$^3$ over several challenging vision Transformer-based baselines. E$^3$ not only preserves its efficiency while scaling to models with up to 2.7B parameters, but also provides better predictive performance and uncertainty estimates for larger models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James Urquhart Allingham",
      "Florian Wenzel",
      "Zelda E Mariet",
      "Basil Mustafa",
      "Joan Puigcerver",
      "Neil Houlsby",
      "Ghassen Jerfel",
      "Vincent Fortuin",
      "Balaji Lakshminarayanan",
      "Jasper Snoek",
      "Dustin Tran",
      "Carlos Riquelme Ruiz",
      "Rodolphe Jenatton"
    ]
  },
  "https://openreview.net/forum?id=qrGKGZZvH0": {
    "title": "Do better ImageNet classifiers assess perceptual similarity better?",
    "volume": "expert",
    "abstract": "Perceptual distances between images, as measured in the space of pre-trained deep features, have outperformed prior low-level, pixel-based metrics on assessing image similarity. While the capabilities of older and less accurate models such as AlexNet and VGG to capture perceptual similarity are well known, modern and more accurate models are less studied. In this paper, we present a large-scale empirical study to assess how well ImageNet classifiers perform on perceptual similarity. First, we observe a inverse correlation between ImageNet accuracy and Perceptual Scores of modern networks such as ResNets, EfficientNets, and Vision Transformers: that is better classifiers achieve worse Perceptual Scores. Then, we examine the ImageNet accuracy/Perceptual Score relationship on varying the depth, width, number of training steps, weight decay, label smoothing, and dropout. Higher accuracy improves Perceptual Score up to a certain point, but we uncover a Pareto frontier between accuracies and Perceptual Score in the mid-to-high accuracy regime. We explore this relationship further using a number of plausible hypotheses such as distortion invariance, spatial frequency sensitivity, and alternative perceptual functions. Interestingly we discover shallow ResNets and ResNets trained for less than 5 epochs only on ImageNet, whose emergent Perceptual Score matches the prior best networks trained directly on supervised human perceptual judgements",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manoj Kumar",
      "Neil Houlsby",
      "Nal Kalchbrenner",
      "Ekin Dogus Cubuk"
    ]
  },
  "https://openreview.net/forum?id=3IqqJh2Ycy": {
    "title": "Equivariant Mesh Attention Networks",
    "volume": "expert",
    "abstract": "Equivariance to symmetries has proven to be a powerful inductive bias in deep learning research. Recent works on mesh processing have concentrated on various kinds of natural symmetries, including translations, rotations, scaling, node permutations, and gauge transformations. To date, no existing architecture is equivariant to all of these transformations. In this paper, we present an attention-based architecture for mesh data that is provably equivariant to all transformations mentioned above. Our pipeline relies on the use of relative tangential features: a simple, effective, equivariance-friendly alternative to raw node positions as inputs. Experiments on the FAUST and TOSCA datasets confirm that our proposed architecture achieves improved performance on these benchmarks and is indeed equivariant, and therefore robust, to a wide variety of local/global transformations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sourya Basu",
      "Jose Gallego-Posada",
      "Francesco Vigan√≤",
      "James Rowbottom",
      "Taco Cohen"
    ]
  },
  "https://openreview.net/forum?id=whJPugmP5I": {
    "title": "Finding and Fixing Spurious Patterns with Explanations",
    "volume": "expert",
    "abstract": "Image classifiers often use spurious patterns, such as \"relying on the presence of a person to detect a tennis racket,\" which do not generalize. In this work, we present an end-to-end pipeline for identifying and mitigating spurious patterns for such models, under the assumption that we have access to pixel-wise object-annotations. We start by identifying patterns such as \"the model's prediction for tennis racket changes 63% of the time if we hide the people.\" Then, if a pattern is spurious, we mitigate it via a novel form of data augmentation. We demonstrate that our method identifies a diverse set of spurious patterns and that it mitigates them by producing a model that is both more accurate on a distribution where the spurious pattern is not helpful and more robust to distribution shift",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gregory Plumb",
      "Marco Tulio Ribeiro",
      "Ameet Talwalkar"
    ]
  },
  "https://openreview.net/forum?id=IKhEPWGdwK": {
    "title": "Understanding AdamW through Proximal Methods and Scale-Freeness",
    "volume": "expert",
    "abstract": "Adam has been widely adopted for training deep neural networks due to less hyperparameter tuning and remarkable performance. To improve generalization, Adam is typically used in tandem with a squared $\\ell_2$ regularizer (referred to as Adam-$\\ell_2$). However, even better performance can be obtained with AdamW, which decouples the gradient of the regularizer from the update rule of Adam-$\\ell_2$. Yet, we are still lacking a complete explanation of the advantages of AdamW. In this paper, we tackle this question from both an optimization and an empirical point of view. First, we show how to re-interpret AdamW as an approximation of a proximal gradient method, which takes advantage of the closed-form proximal mapping of the regularizer instead of only utilizing its gradient information as in Adam-$\\ell_2$. Next, we consider the property of \"scale-freeness\" enjoyed by AdamW and by its proximal counterpart: their updates are invariant to component-wise rescaling of the gradients. We provide empirical evidence across a wide range of deep learning experiments showing a correlation between the problems in which AdamW exhibits an advantage over Adam-$\\ell_2$ and the degree to which we expect the gradients of the network to exhibit multiple scales, thus motivating the hypothesis that the advantage of AdamW could be due to the scale-free updates",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenxun Zhuang",
      "Mingrui Liu",
      "Ashok Cutkosky",
      "Francesco Orabona"
    ]
  },
  "https://openreview.net/forum?id=0nEZCVshxS": {
    "title": "Diagnosing and Fixing Manifold Overfitting in Deep Generative Models",
    "volume": "expert",
    "abstract": "Likelihood-based, or explicit, deep generative models use neural networks to construct flexible high-dimensional densities. This formulation directly contradicts the manifold hypothesis, which states that observed data lies on a low-dimensional manifold embedded in high-dimensional ambient space. In this paper we investigate the pathologies of maximum-likelihood training in the presence of this dimensionality mismatch. We formally prove that degenerate optima are achieved wherein the manifold itself is learned but not the distribution on it, a phenomenon we call manifold overfitting. We propose a class of two-step procedures consisting of a dimensionality reduction step followed by maximum-likelihood density estimation, and prove that they recover the data-generating distribution in the nonparametric regime, thus avoiding manifold overfitting. We also show that these procedures enable density estimation on the manifolds learned by implicit models, such as generative adversarial networks, hence addressing a major shortcoming of these models. Several recently proposed methods are instances of our two-step procedures; we thus unify, extend, and theoretically justify a large class of models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriel Loaiza-Ganem",
      "Brendan Leigh Ross",
      "Jesse C Cresswell",
      "Anthony L. Caterini"
    ]
  },
  "https://openreview.net/forum?id=Id7hTt78FV": {
    "title": "Deep Classifiers with Label Noise Modeling and Distance Awareness",
    "volume": "expert",
    "abstract": "Uncertainty estimation in deep learning has recently emerged as a crucial area of interest to advance reliability and robustness in safety-critical applications. While there have been many proposed methods that either focus on distance-aware model uncertainties for out-of-distribution detection or on input-dependent label uncertainties for in-distribution calibration, both of these types of uncertainty are often necessary. In this work, we propose the HetSNGP method for jointly modeling the model and data uncertainty. We show that our proposed model affords a favorable combination between these two types of uncertainty and thus outperforms the baseline methods on some challenging out-of-distribution datasets, including CIFAR-100C, ImageNet-C, and ImageNet-A. Moreover, we propose HetSNGP Ensemble, an ensembled version of our method which additionally models uncertainty over the network parameters and outperforms other ensemble baselines",
    "checked": true,
    "id": "a5a5c917cb1a1ae583b5795a8297cd0836ff625d",
    "semantic_title": "deep classifiers with label noise modeling and distance awareness",
    "citation_count": 11,
    "authors": [
      "Vincent Fortuin",
      "Mark Collier",
      "Florian Wenzel",
      "James Urquhart Allingham",
      "Jeremiah Zhe Liu",
      "Dustin Tran",
      "Balaji Lakshminarayanan",
      "Jesse Berent",
      "Rodolphe Jenatton",
      "Effrosyni Kokiopoulou"
    ]
  },
  "https://openreview.net/forum?id=berNQMTYWZ": {
    "title": "Your Policy Regularizer is Secretly an Adversary",
    "volume": "expert",
    "abstract": "Policy regularization methods such as maximum entropy regularization are widely used in reinforcement learning to improve the robustness of a learned policy. In this paper, we unify and extend recent work showing that this robustness arises from hedging against worst-case perturbations of the reward function, which are chosen from a limited set by an implicit adversary. Using convex duality, we characterize the robust set of adversarial reward perturbations under KL- and $\\alpha$-divergence regularization, which includes Shannon and Tsallis entropy regularization as special cases. Importantly, generalization guarantees can be given within this robust set. We provide detailed discussion of the worst-case reward perturbations, and present intuitive empirical examples to illustrate this robustness and its relationship with generalization. Finally, we discuss how our analysis complements previous results on adversarial reward robustness and path consistency optimality conditions",
    "checked": true,
    "id": "9f6a1e4b2bf4eb32afa81950dc0dbfec83603ac9",
    "semantic_title": "your policy regularizer is secretly an adversary",
    "citation_count": 14,
    "authors": [
      "Rob Brekelmans",
      "Tim Genewein",
      "Jordi Grau-Moya",
      "Gregoire Detetang",
      "Markus Kunesch",
      "Shane Legg",
      "Pedro A Ortega"
    ]
  },
  "https://openreview.net/forum?id=86fhqdBUbx": {
    "title": "TLDR: Twin Learning for Dimensionality Reduction",
    "volume": "expert",
    "abstract": "Dimensionality reduction methods are unsupervised approaches which learn low-dimensional spaces where some properties of the initial space, typically the notion of \"neighborhood\", are preserved. Such methods usually require propagation on large k-NN graphs or complicated optimization solvers. On the other hand, self-supervised learning approaches, typically used to learn representations from scratch, rely on simple and more scalable frameworks for learning. In this paper, we propose TLDR, a dimensionality reduction method for generic input spaces that is porting the recent self-supervised learning framework of Zbontar et al. (2021) to the specific task of dimensionality reduction, over arbitrary representations. We propose to use nearest neighbors to build pairs from a training set and a redundancy reduction loss to learn an encoder that produces representations invariant across such pairs. TLDR is a method that is simple, easy to train, and of broad applicability; it consists of an offline nearest neighbor computation step that can be highly approximated, and a straightforward learning process. Aiming for scalability, we focus on improving linear dimensionality reduction, and show consistent gains on image and document retrieval tasks, e.g. gaining +4% mAP over PCA on ROxford for GeM- AP, improving the performance of DINO on ImageNet or retaining it with a 10√ó compression",
    "checked": true,
    "id": "8d79a919efeebde4349a504bf83d668b1693f70a",
    "semantic_title": "tldr: twin learning for dimensionality reduction",
    "citation_count": 11,
    "authors": [
      "Yannis Kalantidis",
      "Carlos Eduardo Rosar Kos Lassance",
      "Jon Almaz√°n",
      "Diane Larlus"
    ]
  }
}