{
  "https://aclanthology.org/W19-6601": {
    "title": "Online Sentence Segmentation for Simultaneous Interpretation using Multi-Shifted Recurrent Neural Network",
    "abstract": "This paper is devoted to developing a recurrent neural network (RNN) solution for segmenting the unpunctuated transcripts generated by automatic speech recognition for simultaneous interpretation. RNNs are effective in capturing long-distance dependencies and straightforward for online decoding. Thus, they are ideal for the task compared to the conventional n-gram language model (LM) based approaches and recent neural machine translation based approaches. This paper proposes a multishifted RNN to address the trade-off between accuracy and latency, which is one of the key characteristics of the task. Experiments show that our proposed method improves the segmentation accuracy measured in F1 by 21.1% while maintains approximately the same latency, and reduces the BLEU loss to the oracle segmentation by 28.6%, when compared to a strong baseline of the RNN LM-based method. Our online sentence segmentation toolkit is open-sourced1 to promote the field",
    "volume": "main",
    "checked": true,
    "id": "5ad100eac980b11d6f2f143bdee4df1328810545",
    "citation_count": 13
  },
  "https://aclanthology.org/W19-6602": {
    "title": "Robust Document Representations for Cross-Lingual Information Retrieval in Low-Resource Settings",
    "abstract": "The goal of cross-lingual information retrieval (CLIR) is to find relevant documents written in languages different from that of the query. Robustness to translation errors is one of the main challenges for CLIR, especially in low-resource settings where there is limited training data for building machine translation (MT) systems or bilingual dictionaries. If the test collection contains speech documents, additional errors from automatic speech recognition (ASR) makes translation even more difficult. We propose a robust document representation that combines N-best translations and a novel bag-of-phrases output from various ASR/MT systems. We perform a comprehensive empirical analysis on three challenging collections; they consist of Somali, Swahili, and Tagalog speech/text documents to be retrieved by English queries. By comparing various ASR/MT systems with different error profiles, our results demonstrate that a richer document representation can consistently overcome issues in low translation accuracy for CLIR in low-resource settings",
    "volume": "main",
    "checked": true,
    "id": "f2e493d61bb1868a3fdd0dce863d62449a73491a",
    "citation_count": 17
  },
  "https://aclanthology.org/W19-6603": {
    "title": "Enhancing Transformer for End-to-end Speech-to-Text Translation",
    "abstract": "Neural end-to-end architectures have been recently proposed for spoken language translation (SLT), following the state-ofthe-art results obtained in machine translation (MT) and speech recognition (ASR). Motivated by this contiguity, we propose an SLT adaptation of Transformer (the state-of-the-art architecture in MT), which exploits the integration of ASR solutions to cope with long input sequences featuring low information density. Long audio representations hinder the training of large models due to Transformer’s quadratic memory complexity. Moreover, for the sake of translation quality, handling such sequences requires capturing both shortand long-range dependencies between bidimensional features. Focusing on Transformer’s encoder, our adaptation is based on: i) downsampling the input with convolutional neural networks, which enables model training on non cutting-edge GPUs, ii) modeling the bidimensional nature of the audio spectrogram with 2D components, and iii) adding a distance penalty to the attention, which is able to bias it towards short-range dependencies. Our experiments show that our SLT-adapted Transformer outperforms the RNN-based baseline both in translation quality and training time, setting the state-of-the-art performance on six language directions. ∗Work done during a summer internship at the Machine Translation Research Unit at Fondazione Bruno Kessler. ∗c © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND",
    "volume": "main",
    "checked": true,
    "id": "8aa61bb041dce5f5bdcdfa26bb99040e435d5d5b",
    "citation_count": 43
  },
  "https://aclanthology.org/W19-6604": {
    "title": "Debiasing Word Embeddings Improves Multimodal Machine Translation",
    "abstract": "In recent years, pretrained word embeddings have proved useful for multimodal neural machine translation (NMT) models to address the shortage of available datasets. However, the integration of pretrained word embeddings has not yet been explored extensively. Further, pretrained word embeddings in high dimensional spaces have been reported to suffer from the hubness problem. Although some debiasing techniques have been proposed to address this problem for other natural language processing tasks, they have seldom been studied for multimodal NMT models. In this study, we examine various kinds of word embeddings and introduce two debiasing techniques for three multimodal NMT models and two language pairs -- English-German translation and English-French translation. With our optimal settings, the overall performance of multimodal models was improved by up to +1.93 BLEU and +2.02 METEOR for English-German translation and +1.73 BLEU and +0.95 METEOR for English-French translation",
    "volume": "main",
    "checked": true,
    "id": "377177b65f0a5af1580f7d7421e919ab59d321a9",
    "citation_count": 5
  },
  "https://aclanthology.org/W19-6605": {
    "title": "Translator2Vec: Understanding and Representing Human Post-Editors",
    "abstract": "The combination of machines and humans for translation is effective, with many studies showing productivity gains when humans post-edit machine-translated output instead of translating from scratch. To take full advantage of this combination, we need a fine-grained understanding of how human translators work, and which post-editing styles are more effective than others. In this paper, we release and analyze a new dataset with document-level post-editing action sequences, including edit operations from keystrokes, mouse actions, and waiting times. Our dataset comprises 66,268 full document sessions post-edited by 332 humans, the largest of the kind released to date. We show that action sequences are informative enough to identify post-editors accurately, compared to baselines that only look at the initial and final text. We build on this to learn and visualize continuous representations of post-editors, and we show that these representations improve the downstream task of predicting post-editing time",
    "volume": "main",
    "checked": true,
    "id": "810110f1a6ffe0ae0d545bf873de38358f2ecc6c",
    "citation_count": 4
  },
  "https://aclanthology.org/W19-6606": {
    "title": "Domain Adaptation for MT: A Study with Unknown and Out-of-Domain Tasks",
    "abstract": "Translation quality could degrade nongracefully outside the desired domain for MT. Meanwhile, translation requests are often unknown and potentially out-ofdomain in practice. This paper shows that having an ecosystem with a range of pretrained domain-specific MT systems can reduce the effect: a translation task can be out of scope of most pre-trained MT systems, but a few others can be capable of handling the task. But how to obtain the best translation from an ecosystem for such translation requests? We contribute two frameworks to address the problem. Experiments show that our frameworks give the performance in the middle between top rank MT systems with reasonably large-scale ecosystems",
    "volume": "main",
    "checked": true,
    "id": "5faf37c570fd5c11f28702b5dc01d6546f7dd7e2",
    "citation_count": 0
  },
  "https://aclanthology.org/W19-6607": {
    "title": "What is the impact of raw MT on Japanese users of Word: preliminary results of a usability study using eye-tracking",
    "abstract": "This paper presents preliminary results of a study of Japanese native speakers working with the Microsoft Word application in two modalities: the released Japanese version and a machine translated (MT) version (the raw MT strings incorporated into the MS Word interface). To explore the effect of translation modality on task completion, time and satisfaction, an experiment using an eye-tracker was set up with a group of 42 users: 22 native Japanese and 20 native English speakers. The results suggest that Japanese-native speakers have higher completion scores and are more efficient when working with the released versions of the product than with the MT version, but these differences are not significant. Their self-reported satisfaction, however, is significantly higher when working with the released product as opposed to the raw MT version",
    "volume": "main",
    "checked": true,
    "id": "2d1ccdac37b361cf2efa030a5de2cffe6e689b7d",
    "citation_count": 2
  },
  "https://aclanthology.org/W19-6608": {
    "title": "MAGMATic: A Multi-domain Academic Gold Standard with Manual Annotation of Terminology for Machine Translation Evaluation",
    "abstract": "This paper presents MAGMATic (Multidomain Academic Gold Standard with Manual Annotation of Terminology), a novel Italian–English benchmark which allows MT evaluation focused on terminology translation. The data set comprises 2,056 parallel sentences extracted from institutional academic texts, namely course unit and degree program descriptions. This text type is particularly interesting since it contains terminology from multiple domains, e.g. education and different academic disciplines described in the texts. All terms in the English target side of the data set were manually identified and annotated with a domain label, for a total of 7,517 annotated terms. Due to their peculiar features, institutional academic texts represent an interesting test bed for MT. As a further contribution of this paper, we investigate the feasibility of exploiting MT for the translation of this type of documents. To this aim, we evaluate two stateof-the-art Neural MT systems on MAGMATic, focusing on their ability to translate domain-specific terminology",
    "volume": "main",
    "checked": true,
    "id": "ba743e0a96bea8eae1e4e140cbcec3ce7f583c43",
    "citation_count": 0
  },
  "https://aclanthology.org/W19-6609": {
    "title": "Automatic error classification with multiple error labels",
    "abstract": "Although automatic classification of machine translation errors still cannot provide the same detailed granularity as manual error classification, it is an important task which enables estimation of translation errors and better understanding of the analyzed MT system, in a short time and on a large scale. State-of-the-art methods use hard decisions to assign single error labels to each word. This work presents first results of a new error classification method, which assigns multiple error labels to each word. We assign fractional counts for each label, which can be interpreted as a confidence for the label. Our method generates sensible multi-error suggestions, and improves the correlation between manual and automatic error distributions",
    "volume": "main",
    "checked": true,
    "id": "876bf82c1ac4540b8466dd93dfaae41dd8600ca9",
    "citation_count": 0
  },
  "https://aclanthology.org/W19-6610": {
    "title": "Interactive-Predictive Neural Machine Translation through Reinforcement and Imitation",
    "abstract": "We propose an interactive-predictive neural machine translation framework for easier model personalization using reinforcement and imitation learning. During the interactive translation process, the user is asked for feedback on uncertain locations identified by the system. Responses are weak feedback in the form of \"keep\" and \"delete\" edits, and expert demonstrations in the form of \"substitute\" edits. Conditioning on the collected feedback, the system creates alternative translations via constrained beam search. In simulation experiments on two language pairs our systems get close to the performance of supervised training with much less human effort",
    "volume": "main",
    "checked": true,
    "id": "ff9f4fa43b695017dbd49d856d520e7b2f179308",
    "citation_count": 12
  },
  "https://aclanthology.org/W19-6611": {
    "title": "An Intrinsic Nearest Neighbor Analysis of Neural Machine Translation Architectures",
    "abstract": "Earlier approaches indirectly studied the information captured by the hidden states of recurrent and non-recurrent neural machine translation models by feeding them into different classifiers. In this paper, we look at the encoder hidden states of both transformer and recurrent machine translation models from the nearest neighbors perspective. We investigate to what extent the nearest neighbors share information with the underlying word embeddings as well as related WordNet entries. Additionally, we study the underlying syntactic structure of the nearest neighbors to shed light on the role of syntactic similarities in bringing the neighbors together. We compare transformer and recurrent models in a more intrinsic way in terms of capturing lexical semantics and syntactic structures, in contrast to extrinsic approaches used by previous works. In agreement with the extrinsic evaluations in the earlier works, our experimental results show that transformers are superior in capturing lexical semantics, but not necessarily better in capturing the underlying syntax. Additionally, we show that the backward recurrent layer in a recurrent model learns more about the semantics of words, whereas the forward recurrent layer encodes more context",
    "volume": "main",
    "checked": true,
    "id": "4a241266e5ce68119e390c3ae368b0cf6216a11a",
    "citation_count": 2
  },
  "https://aclanthology.org/W19-6612": {
    "title": "Improving Neural Machine Translation Using Noisy Parallel Data through Distillation",
    "abstract": "Due to the scarcity of parallel training data for many language pairs, quasi-parallel or comparable training data provides an important alternative resource for training machine translation systems for such language pairs. Since comparable corpora are not of as high quality as manually annotated parallel data, using them for training can have a negative effect on the translation performance of an NMT model. We propose distillation as a remedy to effectively leverage comparable data where the training of a student model on combined clean and comparable data is guided by a teacher model trained on the high-quality, clean data only. Our experiments for Arabic-English, ChineseEnglish, and German-English translation demonstrate that distillation yields significant improvements compared to off-theshelf use of comparable data and performs comparable to state-of-the-art methods for noise filtering",
    "volume": "main",
    "checked": true,
    "id": "aa4d08d2b4bbb5b56061718787fa22429bd7a01e",
    "citation_count": 3
  },
  "https://aclanthology.org/W19-6613": {
    "title": "Exploiting Out-of-Domain Parallel Data through Multilingual Transfer Learning for Low-Resource Neural Machine Translation",
    "abstract": "This paper proposes a novel multilingual multistage fine-tuning approach for low-resource neural machine translation (NMT), taking a challenging Japanese--Russian pair for benchmarking. Although there are many solutions for low-resource scenarios, such as multilingual NMT and back-translation, we have empirically confirmed their limited success when restricted to in-domain data. We therefore propose to exploit out-of-domain data through transfer learning, by using it to first train a multilingual NMT model followed by multistage fine-tuning on in-domain parallel and back-translated pseudo-parallel data. Our approach, which combines domain adaptation, multilingualism, and back-translation, helps improve the translation quality by more than 3.7 BLEU points, over a strong baseline, for this extremely low-resource scenario",
    "volume": "main",
    "checked": true,
    "id": "8d7777b3b45b50bbabdbc352df6f4d956eb376f3",
    "citation_count": 25
  },
  "https://aclanthology.org/W19-6614": {
    "title": "Improving Anaphora Resolution in Neural Machine Translation Using Curriculum Learning",
    "abstract": "Modeling anaphora resolution is critical for proper pronoun translation in neural machine translation. Recently it has been addressed by context-aware models with varying success. In this work, we propose a carefully designed training curriculum that facilitates better anaphora resolution in context-aware NMT. As a baseline, we train context-aware models as was done in previous work. We leverage oracle information speciﬁc to anaphora resolution during training. Following the intuition behind curriculum learning, we are able to train context-aware models which are improved with respect to coreference resolution, even though both the baseline and the improved system have access to exactly the same information at test time. We test our approach using two pronoun-speciﬁc evaluation metrics for MT",
    "volume": "main",
    "checked": true,
    "id": "3fb1a26a328cb1c2293a7a791ac13f4d954b6fb6",
    "citation_count": 17
  },
  "https://aclanthology.org/W19-6615": {
    "title": "Improving American Sign Language Recognition with Synthetic Data",
    "abstract": "There is a need for real-time communication between the deaf and hearing without the aid of an interpreter. Developing a machine translation (MT) system between sign and spoken languages is a multimodal task since sign language is a visual language, which involves the automatic recognition and translation of video images. In this paper, we present the research we have been carrying out to build an automated sign language recognizer (ASLR), which is the core component of a machine translation (MT) system between American Sign Language (ASL) and English. Developing an ASLR is a challenging task due to the lack of sufficient quantities of annotated ASL-English parallel corpora for training, testing and developing an ASLR. This paper describes the research we have been conducting to explore a range of different techniques for automatically generating synthetic data from existing datasets to improve the accuracy of ASLR. This work involved experimentation with several algorithms with varying amounts of synthetic data and evaluations of their effectiveness. It was demonstrated that automatically creating valid synthetic training data through simple image manipulation of ASL video recordings improves the performance of the ASLR task. c © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND",
    "volume": "main",
    "checked": true,
    "id": "17b4a6094a57e86be294e914256bb1c83b9e36a2",
    "citation_count": 7
  },
  "https://aclanthology.org/W19-6616": {
    "title": "Selecting Informative Context Sentence by Forced Back-Translation",
    "abstract": "As one of the contributions of this paper, this paper first explores the upper bound of context-based neural machine translation and attempt to utilize previously unused context information. We found that, if we could appropriately select the most informative context sentence for a given input source sentence, we could boost translation accuracy as much as approximately 10 BLEU points. This paper next explores a criterion to select the most informative context sentences that give the highest BLEU score. Applying the proposed criterion, context sentences that yield the highest forced back-translation probability when back-translating into the source sentence are selected. Experimental results with Japanese and English parallel sentences from the OpenSubtitles2018 corpus demonstrate that, when the context length of five preceding and five subsequent sentences are examined, the proposed approach achieved significant improvements of 0.74 (Japanese to English) and 1.14 (English to Japanese) BLEU scores compared to the baseline 2-to-2 model, where the oracle translation achieved upper bounds improvements of 5.88 (Japanese to English) and 9.10 (English to Japanese) BLEU scores",
    "volume": "main",
    "checked": true,
    "id": "273ff4cd9630483b03f7c4e0d2babc169c867442",
    "citation_count": 5
  },
  "https://aclanthology.org/W19-6617": {
    "title": "Memory-Augmented Neural Networks for Machine Translation",
    "abstract": "Memory-augmented neural networks (MANNs) have been shown to outperform other recurrent neural network architectures on a series of artificial sequence learning tasks, yet they have had limited application to real-world tasks. We evaluate direct application of Neural Turing Machines (NTM) and Differentiable Neural Computers (DNC) to machine translation. We further propose and evaluate two models which extend the attentional encoder-decoder with capabilities inspired by memory augmented neural networks. We evaluate our proposed models on IWSLT Vietnamese to English and ACL Romanian to English datasets. Our proposed models and the memory augmented neural networks perform similarly to the attentional encoder-decoder on the Vietnamese to English translation task while have a 0.3-1.9 lower BLEU score for the Romanian to English task. Interestingly, our analysis shows that despite being equipped with additional flexibility and being randomly initialized memory augmented neural networks learn an algorithm for machine translation almost identical to the attentional encoder-decoder",
    "volume": "main",
    "checked": true,
    "id": "819ac109a6454a1a76cecfcac3c16882a61d7563",
    "citation_count": 5
  },
  "https://aclanthology.org/W19-6618": {
    "title": "An Exploration of Placeholding in Neural Machine Translation",
    "abstract": "Phrase-based machine translation provides the system developer with controls that enable fine-grained control over machine translation output. One approach to provide similar control in neural machine translation is placeholding (herein called masking), which replaces input tokens with masks which are replaced with the original input text in post-processing. But is this a good idea? We undertake an exploration of masking in French–English and Japanese–English using Transformer architectures. We attempt to quantify whether (and where) masking is necessary with analysis of a baseline system, and then explore numerous parameterization of masking, including post-processing techniques for replacing the masks. Our analysis shows this to be a thorny matter; masks solve some problems but are not perfectly translated themselves",
    "volume": "main",
    "checked": true,
    "id": "7a7bf17883c5414757bf0f4295f12f604151ae6b",
    "citation_count": 6
  },
  "https://aclanthology.org/W19-6619": {
    "title": "Controlling the Reading Level of Machine Translation Output",
    "abstract": "Today’s machine translation systems output the same translation for a given input, despite important differences between users. In practice, translations should be customized for each reader, for instance when translating for children versus in a business setting. In this paper, we introduce the task of reading level control to machine translation, and provide the ﬁrst results. Our methods can be used to raise or lower the reading level of output translations. In our ﬁrst approach, source-side sentences in the training corpus are tagged based on the reading level (read-ability) of the matching target sentences. Our second approach alters the traditional encoder-decoder architecture by specifying a joint encoder and separate decoders for simple and complex decoding modes, with training data partitioned by reading level. We demonstrate control over output readability score on three test sets in the Spanish–English language direction",
    "volume": "main",
    "checked": true,
    "id": "b7e03e82d597571f00aa8802699a9d7e7164ae92",
    "citation_count": 20
  },
  "https://aclanthology.org/W19-6620": {
    "title": "A Call for Prudent Choice of Subword Merge Operations in Neural Machine Translation",
    "abstract": "Most neural machine translation systems are built upon subword units extracted by methods such as Byte-Pair Encoding (BPE) or wordpiece. However, the choice of number of merge operations is generally made by following existing recipes. In this paper, we conduct a systematic exploration of different BPE merge operations to understand how it interacts with the model architecture, the strategy to build vocabularies and the language pair. Our exploration could provide guidance for selecting proper BPE configurations in the future. Most prominently: we show that for LSTM-based architectures, it is necessary to experiment with a wide range of different BPE operations as there is no typical optimal BPE configuration, whereas for Transformer architectures, smaller BPE size tends to be a typically optimal choice. We urge the community to make prudent choices with subword merge operations, as our experiments indicate that a sub-optimal BPE configuration alone could easily reduce the system performance by 3-4 BLEU points",
    "volume": "main",
    "checked": true,
    "id": "f9160d669a65b1283636d2eae524144ef4f0f658",
    "citation_count": 48
  },
  "https://aclanthology.org/W19-6621": {
    "title": "The Impact of Preprocessing on Arabic-English Statistical and Neural Machine Translation",
    "abstract": "Neural networks have become the state-of-the-art approach for machine translation (MT) in many languages. While linguistically-motivated tokenization techniques were shown to have significant effects on the performance of statistical MT, it remains unclear if those techniques are well suited for neural MT. In this paper, we systematically compare neural and statistical MT models for Arabic-English translation on data preprecossed by various prominent tokenization schemes. Furthermore, we consider a range of data and vocabulary sizes and compare their effect on both approaches. Our empirical results show that the best choice of tokenization scheme is largely based on the type of model and the size of data. We also show that we can gain significant improvements using a system selection that combines the output from neural and statistical MT",
    "volume": "main",
    "checked": true,
    "id": "f89df2ef9cd3a4e5f7becaf8123c4d66fcbddd35",
    "citation_count": 18
  },
  "https://aclanthology.org/W19-6622": {
    "title": "Lost in Translation: Loss and Decay of Linguistic Richness in Machine Translation",
    "abstract": "This work presents an empirical approach to quantifying the loss of lexical richness in Machine Translation (MT) systems compared to Human Translation (HT). Our experiments show how current MT systems indeed fail to render the lexical diversity of human generated or translated text. The inability of MT systems to generate diverse outputs and its tendency to exacerbate already frequent patterns while ignoring less frequent ones, might be the underlying cause for, among others, the currently heavily debated issues related to gender biased output. Can we indeed, aside from biased data, talk about an algorithm that exacerbates seen biases?",
    "volume": "main",
    "checked": true,
    "id": "278f7495e50db8b3d01112ba36223e8976f73b60",
    "citation_count": 59
  },
  "https://aclanthology.org/W19-6623": {
    "title": "Identifying Fluently Inadequate Output in Neural and Statistical Machine Translation",
    "abstract": "With the impressive fluency of modern machine translation output, systems may produce output that is fluent but not adequate (fluently inadequate). We seek to identify these errors and quantify their frequency in MT output of varying quality. To that end, we introduce a method for automatically predicting whether translated segments are fluently inadequate by predicting fluency using grammaticality scores and predicting adequacy by augmenting sentence BLEU with a novel Bag-of-Vectors Sentence Similarity (BVSS). We then apply this technique to analyze the outputs of statistical and neural systems for six language pairs with different levels of translation quality. We find that neural models are consistently more prone to this type of error than traditional statistical models. However, improving the overall quality of the MT system such as through domain adaptation reduces these errors",
    "volume": "main",
    "checked": true,
    "id": "7be9fb36d56822e83be0a98ee1214f7c810b5306",
    "citation_count": 19
  },
  "https://aclanthology.org/W19-6624": {
    "title": "Character-Aware Decoder for Translation into Morphologically Rich Languages",
    "abstract": "Neural machine translation (NMT) systems operate primarily on words (or sub-words), ignoring lower-level patterns of morphology. We present a character-aware decoder designed to capture such patterns when translating into morphologically rich languages. We achieve character-awareness by augmenting both the softmax and embedding layers of an attention-based encoder-decoder model with convolutional neural networks that operate on the spelling of a word. To investigate performance on a wide variety of morphological phenomena, we translate English into 14 typologically diverse target languages using the TED multi-target dataset. In this low-resource setting, the character-aware decoder provides consistent improvements with BLEU score gains of up to $+3.05$. In addition, we analyze the relationship between the gains obtained and properties of the target language and find evidence that our model does indeed exploit morphological patterns",
    "volume": "main",
    "checked": true,
    "id": "039efff933d1faf4a7d1dca4f6509426b73a7b94",
    "citation_count": 4
  },
  "https://aclanthology.org/W19-6625": {
    "title": "Improving Translations by Combining Fuzzy-Match Repair with Automatic Post-Editing",
    "abstract": "Two of the more predominant technologies that professional translators have at their disposal for improving productivity are machine translation (MT) and computeraided translation (CAT) tools based on translation memories (TM). When translators use MT, they can use automatic postediting (APE) systems to automate part of the post-editing work and get further productivity gains. When they use TMbased CAT tools, productivity may improve if they rely on fuzzy-match repair (FMR) methods. In this paper we combine FMR and APE: first a FMR proposal is produced from the translation unit proposed by the TM, then this proposal is further improved by an APE system specially tuned for this purpose. Experiments conducted on the translation of English texts into German show that, with the two combined technologies, the quality of the translations improves up to 23% compared to a pure MT system. The improvement over a pure FMR system is of 16%, showing the effectiveness of our joint solution",
    "volume": "main",
    "checked": true,
    "id": "6d57043fabec83b66e7e5b278ced7154c66f24eb",
    "citation_count": 3
  },
  "https://aclanthology.org/W19-6626": {
    "title": "Post-editing Productivity with Neural Machine Translation: An Empirical Assessment of Speed and Quality in the Banking and Finance Domain",
    "abstract": "Neural machine translation (NMT) has set new quality standards in automatic translation, yet its effect on post-editing productivity is still pending thorough investigation. We empirically test how the inclusion of NMT, in addition to domain-specific translation memories and termbases, impacts speed and quality in professional translation of financial texts. We find that even with language pairs that have received little attention in research settings and small amounts of in-domain data for system adaptation, NMT post-editing allows for substantial time savings and leads to equal or slightly better quality",
    "volume": "main",
    "checked": true,
    "id": "46fa62ebd27e6b30b861db8f86563d865817cca2",
    "citation_count": 18
  },
  "https://aclanthology.org/W19-6627": {
    "title": "Post-editese: an Exacerbated Translationese",
    "abstract": "Post-editing (PE) machine translation (MT) is widely used for dissemination because it leads to higher productivity than human translation from scratch (HT). In addition, PE translations are found to be of equal or better quality than HTs. However, most such studies measure quality solely as the number of errors. We conduct a set of computational analyses in which we compare PE against HT on three different datasets that cover five translation directions with measures that address different translation universals and laws of translation: simplification, normalisation and interference. We find out that PEs are simpler and more normalised and have a higher degree of interference from the source language than HTs",
    "volume": "main",
    "checked": true,
    "id": "165334554f8c73a29de148fe2223ffbcbe1b51f0",
    "citation_count": 48
  },
  "https://aclanthology.org/W19-6701": {
    "title": "Competitiveness Analysis of the European Machine Translation Market",
    "abstract": "This paper presents the key results of a study on the global competitiveness of the European Machine Translation market in comparison to North America and Asia. The study focuses on seven dimensions that have been selected to characterize the machine translation market. The study concludes that while Europe still has strong positions in Research and Innovation, it lags behind North America and Asia in Industry and Investments, and is also weaker than North America in Infrastructure, Data availability, and Market visibility",
    "volume": "main",
    "checked": true,
    "id": "b69f40e0c53ed100abaa1c946d73818ed5d12e50",
    "citation_count": 3
  },
  "https://aclanthology.org/W19-6702": {
    "title": "Improving CAT Tools in the Translation Workflow: New Approaches and Evaluation",
    "abstract": "This paper describes strategies to improve an existing web-based computer-aided translation (CAT) tool entitled CATaLog Online. CATaLog Online provides a post-editing environment with simple yet helpful project management tools. It offers translation suggestions from translation memories (TM), machine translation (MT), and automatic post-editing (APE) and records detailed logs of post-editing activities. To test the new approaches proposed in this paper, we carried out a user study on an English--German translation task using CATaLog Online. User feedback revealed that the users preferred using CATaLog Online over existing CAT tools in some respects, especially by selecting the output of the MT system and taking advantage of the color scheme for TM suggestions",
    "volume": "main",
    "checked": true,
    "id": "98cbd4369734031edc83b3354b80cd8a2d5e77fd",
    "citation_count": 7
  },
  "https://aclanthology.org/W19-6703": {
    "title": "Hungarian translators' perceptions of Neural Machine Translation in the European Commission",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "3637e9fce4e0321858f07a3106b3e65a5817f3cd",
    "citation_count": 1
  },
  "https://aclanthology.org/W19-6704": {
    "title": "Applying Machine Translation to Psychology: Automatic Translation of Personality Adjectives",
    "abstract": "We introduce our approach to apply machine translation to psychology, especially to translate English adjectives in a psychological personality questionnaire. We first extend seed English personality adjectives with a word2vec model trained with web sentences, and then feed the acquired words to a phrase-based machine translation model. We use Moses trained with bilingual corpora that consist of TED subtitles, movie’ subtitles and Wikipedia. We collect Japanese translations whose translation probabilities are higher than .01 and filter them based on human evaluations. This resulted in 507 Japanese personality descriptors. We conducted a web-survey (N=17,751) and finalized a personality questionnaire. Statistical analyses supported the five-factor structure, reliability and criterion-validity of the newly developed questionnaire. This shows the potential applicability of machine translation to psychology. We discuss further issues related to machine translation application to psychology",
    "volume": "main",
    "checked": true,
    "id": "fad2e321b1d62815c36b49db5ccd946cb924977c",
    "citation_count": 2
  },
  "https://aclanthology.org/W19-6705": {
    "title": "Evaluating machine translation in a low-resource language combination: Spanish-Galician",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "65f73c9d8e69082935c9028b96e663571424c70e",
    "citation_count": 3
  },
  "https://aclanthology.org/W19-6706": {
    "title": "MTPE in Patents: A Successful Business Story",
    "abstract": "This paper illustrates how we successfully implemented MTPE in our workflow and how the decision of having our own engine turned out to be decisive. After having compared different solutions, we decided to choose an MT provider that could train an engine on our behalf with our material (TMs and glossary in the field of mechanics) to translate patents upon customers’ request. After the training, we tested the new engine to evaluate the MT output. Because the quality was so good, we decided to create an in-house team of post-editors, coordinated by one of our senior translators. Due to the increasing request from some of our customers, we needed also some external post-editors to count on, so we contacted an LSP specialized in post-editing and we offered them training in patents post-editing. The challenge for the future is to involve more freelancers and to be able to overcome the resistance that many of them still have towards Machine Translation",
    "volume": "main",
    "checked": true,
    "id": "35b0be9fb9adaed763565a7630e5ce550a86544a",
    "citation_count": 1
  },
  "https://aclanthology.org/W19-6707": {
    "title": "User expectations towards machine translation: A case study",
    "abstract": "Neural machine translation (NMT) systems have emerged as powerful platforms for providing fluent translations in a variety of languages and domains. The widespread adoption of NMT has heightened the need for studying the results and impact of these systems. Although acceptance of machine translation has been analyzed, the expectations of users towards NMT have not received much attention yet. This paper investigates the expectations of novice translators enrolled on a postgraduate program in specialized translation. In addition, it examines the confirmation or disconfirmation of expectations towards machine translation (MT) output among this user group. A three-step mixed-method approach was applied: a quantitative questionnaire and two recurrent (pre-trial and post-trial) evaluations of raw MT outputs. The evaluations consisted of the identification and classification of errors in NMT output according to the Multidimensional Quality Metrics. The respondents expected the MT output to be of rather low quality, but the quality of NMT output was not as high as the participants expected. Compared to the expected frequency of error types in the MT output, the reported frequency differed significantly. This paper argues that the users’ experience and expectations have an impact on the use and evaluation of ma-",
    "volume": "main",
    "checked": true,
    "id": "a016e2529e914dacdd1e8f5ddfe5a3b19d358648",
    "citation_count": 5
  },
  "https://aclanthology.org/W19-6708": {
    "title": "Does NMT make a difference when post-editing closely related languages? The case of Spanish-Catalan",
    "abstract": "In the last years, we have witnessed an increase in the use of post-editing of machine translation (PEMT) in the translation industry. It has been included as part of the translation workflow because it increases productivity of translators. Currently, many Language Service Providers offer PEMT as a service. For many years now, (closely) related languages have been post-edited using rulebased and phrase-based machine translation (MT) systems because they present less challenges due to their morphological and syntactic similarities. Given the recent popularity of neural MT (NMT), this paper analyzes the performance of this approach compared to phrase-based statistical MT (PBSMT) on in-domain and general domain documents. We use standard automatic measures and temporal and technical effort to assess if NMT yields a real improvement when it comes to post-editing the Spanish-Catalan language pair",
    "volume": "main",
    "checked": true,
    "id": "48f0fcf73e18bd502a7642ed0fea70fc41ad7963",
    "citation_count": 4
  },
  "https://aclanthology.org/W19-6709": {
    "title": "Machine Translation in the Financial Services Industry: A Case Study",
    "abstract": "The use of Machine Translation is spreading quickly in the translation industry. While its implementation is smooth in some contexts, in the regulated services industry it certainly seems trickier. In particular, the financial services industry can be considered a less conventional scenario within which to implement MT. This paper explains how MT was successfully implemented in the workflow of a translation company specialized in financial services, and how freelance translators got positively involved in the process",
    "volume": "main",
    "checked": true,
    "id": "cb39ffadea36b7864bf9a33b75b28c596676b143",
    "citation_count": 2
  },
  "https://aclanthology.org/W19-6710": {
    "title": "Pre-editing Plus Neural Machine Translation for Subtitling: Effective Pre-editing Rules for Subtitling of TED Talks",
    "abstract": "In this study, the authors developed a set of pre-editing rules for TED Talk subtitling to translate Japanese source text into English. The simplified rules optimized for NMT (@TexTra® Minnano jido hon’yaku) were intended for use by a monolingual pre-editor of content to be disseminated in English. The rules were a) insert punctuation b) make implied subjects and objects explicit, and c) write proper nouns in English. The effectiveness of the rules was evaluated by human raters and BLEU score. Quality improvement was confirmed significant on human evaluation, although in some cases no changes or even degrade in quality were observed. However, one of the main concerns about the feasibility of this approach, the 21-character limit specified in the TED subtitling guidelines, was validated. The authors hold that pre-editing plus NMT is a promising approach to translating TED Talk subtitles",
    "volume": "main",
    "checked": true,
    "id": "409ac456def290f65f8c2bfaaf1fd5e23e5dd94d",
    "citation_count": 6
  },
  "https://aclanthology.org/W19-6711": {
    "title": "Do translator trainees trust machine translation? An experiment on post-editing and revision",
    "abstract": "Despite the importance of trust in any work environment, this concept has rarely been investigated for MT. The present contribution aims at filling this gap by presenting a post-editing experiment carried out with translator trainees. An institutional academic text was translated from Italian into English. All participants worked on the same target text. Half of them were told that the text was a human translation needing revision, while the other half was told that it was an MT output to be postedited. Temporal and technical effort were measured based on words per second and HTER. Results were complemented with a manual analysis of a subset of the observations",
    "volume": "main",
    "checked": true,
    "id": "432bf4b2beb18c02528a622af6778be7f70f700a",
    "citation_count": 3
  },
  "https://aclanthology.org/W19-6712": {
    "title": "On reducing translation shifts in translations intended for MT evaluation",
    "abstract": "Automatic evaluation of machine translation (MT) is based on the idea that the quality of the MT output is better if it is more similar to human translation (HT). Whereas automatic metrics based on this similarity idea enable fast and large-scale evaluation of MT progress and therefore are widely used, they have certain limitations. One is the fact that the automatic metrics are not able to recognise acceptable differences between MT and HT. The frequent cause of these differences are translation shifts, the optional departures from theoretical formal correspondence between source and target language units for the sake of adapting the text to the norms and conventions of the target language. This work is based on the author’s own translation experience related to the evaluation of MT output compared to the experience unrelated to MT. The main observation is that, although without any instructions in this direction, fewer translation shifts were performed than when translating for other purposes. This finding will hopefully initialise further systematic research both from the aspect of MT as well as from the aspect of translation studies (TS) and bring translation theory and MT closer together",
    "volume": "main",
    "checked": true,
    "id": "b98649801c4ff5610e821d3fe423ac72aad91c12",
    "citation_count": 4
  },
  "https://aclanthology.org/W19-6713": {
    "title": "Comparative Analysis of Errors in MT Output and Computer-assisted Translation: Effect of the Human Factor",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "8ace00785a430999b8e378dc4a4b5743e5da0c21",
    "citation_count": 1
  },
  "https://aclanthology.org/W19-6714": {
    "title": "A Comparative Study of English-Chinese Translations of Court Texts by Machine and Human Translators and the Word2Vec Based Similarity Measure's Ability To Gauge Human Evaluation Biases",
    "abstract": "In this comparative study, a jury instruction scenario was used to test the translating capabilities of multiple machine translation tools and a human translator with extensive court experience. Three certified translators/interpreters subjectively evaluated the target texts generated using adequacy and fluency as the evaluation metrics. This subjective evaluation found that the machine generated results had much poorer adequacy and fluency compared with results produced by their human counterpart. Human translators can use strategic omission and explicitation strategies such as addition, paraphrasing, substitution, and repetition to remove ambiguity, and achieve a natural flow in the target language. We also investigate instances where human evaluators have major disagreements and found that human experts could have very biased views. On the other hand, a word2vec based algorithm, if given a good reference translation, can serve as a robust and reliable similarity reference to quantify human evalutors’ biases beacuse it was trained on a large corpus using neural network models. Even though the machine generated versions had better fluency performance compared to their adequacy © 2019 The authors. This article is licensed under a Creative Commons 4.0 license, no derivative works, attribution, CCBY-ND. performance, the human translator’s fluency performance was still far superior. The lack of understanding by machine translators led to inaccurate and improper word/phrase selections, which led to bad fluency",
    "volume": "main",
    "checked": true,
    "id": "f080e7f62cc50b8f1e922102414ca21a01647076",
    "citation_count": 2
  },
  "https://aclanthology.org/W19-6715": {
    "title": "Translating Terminologies: A Comparative Examination of NMT and PBSMT Systems",
    "abstract": "Terminology translation is a critical aspect in translation quality assurance, as it requires exact forms not typically expected of conventional translation. Recent studies have examined the quality of machine translation, but little work has focused specifically on the translation of terms. We present a comparative evaluation of the success of NMT and PBSMT systems in term translation. We selected eight language pairs among English, French, German, Finnish, and Romanian, taking into account their diverse language families and resource abundance. Based on the evaluation of Exact Match (EM) and recall scores, we concluded that NMT, in general, performs better with context, but PBSMT outperforms when translating without context, and found that significant differences often arise from language nature",
    "volume": "main",
    "checked": true,
    "id": "677483a7c848fe03e6c589230989401747d9fa4e",
    "citation_count": 0
  },
  "https://aclanthology.org/W19-6716": {
    "title": "NEC TM Data Project",
    "abstract": "The objective of project NEC TM Data is to organise unexploited national bilingual assets that can be used as open data and general data for machine learning, in order to lower translation costs at a national level and across member states. It runs a study on the expenditure at the national level on translation contracts, as well as at the regional and municipal levels. The software will help member states centralise these language assets with the NEC TM database, following industry best practices. NEC TM is based on the ElasticSearch (Gormley, 2015) ActivaTM server which is a centralised translation memory (TM) server independent of any computer-assisted translation (CAT) tool for efficient data sharing, TM matching, TM retrieval, and domain categorisation of resources. In short, ActivaTM separates the need of every CAT tool to have its own TM server. It is possible to store bilingual assets and later retrieve them through any CAT tool using the API calls to NEC TM Translators can translate and access each other’s work simultaneously from different CAT tools. ActivaTM is the basis for the NEC TM (fork-out) for the scope of this project. It has been selected as a CEF (Connecting Europe Facility) project by the European Commission as the database of choice to provide unified translation memory © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. services to EU public administrations and collect and build bilingual big data from public translation contracts. Each European country will be able to install their own NEC TM and new translation contracts from translation companies will benefit from fuzzy matching analysis and will be able to work online and connect to each national NEC TM server. Translation data will be categorised in NEC TM, and a connection provided to eTranslation and ELRC. The consortium for the project is composed by Pangeanic, Tilde, Ciklopea and Secretary of State for Digital Progress (SEAD) of Spain. The NEC TM Data project consortium advocates for the facilitation of a single digital market. It will act as a meeting point for European data gathering efforts and the collection of national digital big data. By building a data bridge between public administrations and translation vendors, NEC TM Data project will promote the free flow of data between Public Administrations and translation professionals",
    "volume": "main",
    "checked": true,
    "id": "0cc6bb672af9ac3b75b9c8e90c4365ea4ddcac3a",
    "citation_count": 0
  },
  "https://aclanthology.org/W19-6717": {
    "title": "APE-QUEST",
    "abstract": "The APE-QUEST project (2018–2020) sets up a quality gate and crowdsourcing workflow for the eTranslation system of EC’s Connecting Europe Facility to improve translation quality in specific domains. It packages these services as a translation portal for machine-to-machine and machine-to-human scenarios",
    "volume": "main",
    "checked": true,
    "id": "54eb63b798e125368cb717acdc14a502df6950ce",
    "citation_count": 1
  },
  "https://aclanthology.org/W19-6718": {
    "title": "PRINCIPLE: Providing Resources in Irish, Norwegian, Croatian and Icelandic for the Purposes of Language Engineering",
    "abstract": "PRINCIPLE is a new 2-year project starting in September 2019 funded by the European Commission under the Connecting Europe Facility (CEF) programme. Parallel data for Croatian, Icelandic, Irish and Norwegian are in relatively short supply, so that the quality of the eTranslation machine translation (MT) engines is less than would be the case if larger parallel corpora were available. PRINCIPLE will gather parallel data for these languages and English, evaluate the quality of the gathered resources via MT, and deliver corpora deemed to be of high quality to eTranslation for improved MT engine training. 1 Languages, Activities and Partners The PRINCIPLE project focuses on the identification, collection and processing of language resources (LRs) for four under-resourced European languages: Croatian, Icelandic, Irish, and Norwegian (covering both varieties: Bokmål and Nynorsk). It focuses on providing data to improve translation quality in two Digital Service Infrastructures (DSIs) – eJustice and eProcurement – via domain-specific MT engines, over a 2-year period (September 2019 to August 2021). © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. 1 https://ec.europa.eu/digital-singleThe main activities in PRINCIPLE are: (i) use-case analysis, data requirements and data preparation, (ii) identification and collection of LRs, (iii) development, evaluation and deployment of MT systems, (iv) exploitation and sustainability, and",
    "volume": "main",
    "checked": true,
    "id": "affd3bebd6ae07d1ed59a271cc5760692e3184f5",
    "citation_count": 3
  },
  "https://aclanthology.org/W19-6719": {
    "title": "iADAATPA Project: Pangeanic use cases",
    "abstract": "The iADAATPA1 project coded as N◦ 2016-EU-IA-0132 that ended in February 2019 is made for building of customized, domain-specific engines for public administrations from EU Member States. The consortium of the project decided to use neural machine translation at the beginning of the project. This represented a challenge for all involved, and the positive aspect is that all public administrations engaged in the iADAATPA project were able to try, test and use state-of-the-art neural technology with a high level of satisfaction. One of the main challenges faced by all partners was data availability. Although all public administrations had some data available, it was clearly insufficient for high-level customization. In some cases, we had merely a few hundred words or several tens of thousand words. Each domain (field) has its own unique word distribution and neural machine translation systems are known to suffer a decrease in performance when data is out-of-domain. Pangeanic is a language service provider (LSP) specialised in natural language processing and machine translation. It provides solutions to cognitive companies, institutions, translation professionals, and corporations. The problem faced by the iADAATPA project at Pangeanic was twofold: c © 2019 The authors. This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CCBY-ND. http://iadaatpa.com/ 1. Availability of training data in some language combinations. 2. How to successfully train a translation model on multi-domain data. Language pairs and domains Pangeanic’s use cases are for 2 Spanish public administrations: (1) Generalitat Valenciana (regional administration) translating from Spanish into and out of English, French, Catalan/Valencian, German, Italian, Russian and (2) SEGITTUR2 (tourism administration) translating from Spanish into and out of English, French, German, Italian, Portuguese. Data acquisition For translation from Spanish to Russian there was no available in-domain data. Therefore, 2 translators were contracted as part of the project to create 30,000 segments of in-domain data, translating public administrations websites. They also cleaned United Nations material and post-edited general-domain data that was previously filtered as indomain following the “invitation model” (Hoang and Sima’an, 2014). For the other language pairs, the input material was 30,000 post-edited segments. The main part of the training corpora (approximately 75%) was part of Pangeanic’s own repository harvested through web crawling and also OpenSubtitles (Tiedemann, 2012). The rest of the corpus was automatically validated synthetic material using general data from Leipzig (Goldhahn et al., 2012). https://www.segittur.es/es/inicio/index.html Proceedings of MT Summit XVII, volume 2 Dublin, Aug. 19-23, 2019 | p. 114 Engine customization The data was cleaned using the Bicleaner tool (SánchezCartagena et al., 2018). The data was lowercased and extra embeddings were added in order to keep the case information. The tokenization used was the one provided by OpenNMT3 and words were divided in subwords according to the BPE (Sennrich et al., 2016) approach. The models were trained with multi-domain data and we improved performance following a domainmixing approach (Britz et al., 2017). The domain information was prepended with special tokens for each target sequence. The domain prediction was based only on the source as the extra token was added at target-side and there was no need for apriori domain information. This approach allowed the model to improve the quality for each domain. Acknowledgements The work reported in this paper was conducted during the iADAATPA project, which was funded by INEA through grant N◦ 2016-EU-IA-0132 as part of the EU’s CEF Telecom Programme",
    "volume": "main",
    "checked": true,
    "id": "63134c50303ce8c2ae0c4d171a802265ca9877e3",
    "citation_count": 0
  },
  "https://aclanthology.org/W19-6720": {
    "title": "MICE",
    "abstract": "The MICE project (2018 – 2020) will deliver a middleware layer for improving the output quality of the eTranslation system of the European Commission’s Connecting Europe Facility, through additional services, such as domain adaptation and named-entity recognition. It will also deliver a user portal, allowing for human post-editing",
    "volume": "main",
    "checked": true,
    "id": "fb1210ff05eec32742d4a11f070f388d968b6d6a",
    "citation_count": 33
  },
  "https://aclanthology.org/W19-6721": {
    "title": "ParaCrawl: Web-scale parallel corpora for the languages of the EU",
    "abstract": "We describe two projects funded by the Connecting Europe Facility, Provision of Web-Scale Parallel Corpora for Official European Languages (2016-EU-IA-0114, completed) and Broader Web-Scale Provision of Parallel Corpora for European Languages (2017-EU-IA-0178, ongoing), which aim at harvesting parallel corpora from the Internet for languages used in the European Union. In addition to parallel corpora, the project releases successive versions of the free/open-source web crawling software used",
    "volume": "main",
    "checked": true,
    "id": "6ddcbbbdb5ca8ea72f278691307225ebb3715390",
    "citation_count": 81
  },
  "https://aclanthology.org/W19-6722": {
    "title": "Pivot Machine Translation in INTERACT Project",
    "abstract": "The INTERnAtional network on Crisis Translation (INTERACT) project under EU Marie Skłodowska-Curie Actions (MSCA) Research and Innovation Staff Exchange (RISE) Programme aimed at researching translation in crisis scenarios. In this extended abstract, we present the work on Pivot Machine Translation under the INTERACT project",
    "volume": "main",
    "checked": true,
    "id": "ae83632de305219194dab935143cbcb27acabb3c",
    "citation_count": 0
  },
  "https://aclanthology.org/W19-6723": {
    "title": "Global Under-Resourced Media Translation (GoURMET)",
    "abstract": "We present the EU H2020 GoURMET project (2019-2021) which aims to tackle the challenge of low-resource machine translation for our media partners. This will help them to both monitor news in a wider range of languages, and also more efficiently produce content especially for languages from Africa and India",
    "volume": "main",
    "checked": true,
    "id": "507c48176d1a80ca4ec9071cdb8debca9bf00ab5",
    "citation_count": 7
  },
  "https://aclanthology.org/W19-6724": {
    "title": "Neural machine translation system for the Kazakh language",
    "abstract": "The lack of big parallel data is present for the Kazakh language. This problem seriously impairs the quality of machine translation from and into Kazakh. This article considers the neural machine translation of the Kazakh language on the basis of synthetic corpora. The Kazakh language belongs to the Turkic languages, which are characterised by rich morphology. Neural machine translation of natural languages requires large training data. The article will show the model for the creation of synthetic corpora, namely the generation of sentences based on complete suffixes for the Kazakh language. The novelty of this approach of the synthetic corpora generation for the Kazakh language is the generation of sentences on the basis of the complete system of suffixes of the Kazakh language. By using generated synthetic corpora we are improving the translation quality in neural machine translation of Kazakh-English and Kazakh-Russian pairs",
    "volume": "main",
    "checked": true,
    "id": "f9645cc85f748c5169093fadabe1ae7abadc73d3",
    "citation_count": 0
  },
  "https://aclanthology.org/W19-6725": {
    "title": "Leveraging Rule-Based Machine Translation Knowledge for Under-Resourced Neural Machine Translation Models",
    "abstract": "This publication has emanated from research supported in part by a research grant from Science \nFoundation Ireland (SFI) under Grant Number \nSFI/12/RC/2289, co-funded by the European Regional Development Fund, and the Enterprise Ireland (EI) Innovation Partnership Programme under \ngrant agreement No IP20180729, NURS – Neural \nMachine Translation for Under-Resourced Scenarios",
    "volume": "main",
    "checked": true,
    "id": "3eeb03e3f9708d74d9908513a4ca6d5931f17dfb",
    "citation_count": 12
  },
  "https://aclanthology.org/W19-6726": {
    "title": "Bootstrapping a Natural Language Interface to a Cyber Security Event Collection System using a Hybrid Translation Approach",
    "abstract": "This paper presents a system that can be used to generate Elasticsearch (database) query strings for English-speaking cyberthreat hunters, security analysts or responders (agents) using a natural language interface. This system relies on a hybrid translation approach combining translation memory, information extraction and text classification techniques. The resulting queries may be used to (i) speed up the on-boarding of agents that are not (too) familiar with a specific, flexible database schema and (ii) collect question-to-query mappings with a view to train future models using a more robust framework (e.g. NMT). The system presented in this paper supports multiple data sources, including an industry-standard knowledge base and collections of existing queries provided by individual or corporate threat hunters. It allows users to ask questions about specific cybersecurity event or incident details and generates Elasticsearch query strings that can be executed against a database containing security event data. This paper presents the key components of the backend system and highlights some of the user interface design choices that were made to maximize user adoption",
    "volume": "main",
    "checked": true,
    "id": "a17d6ca036a1e62a57c4ba4a677b6f7fdb4a9d9e",
    "citation_count": 1
  },
  "https://aclanthology.org/W19-6727": {
    "title": "Improving Robustness in Real-World Neural Machine Translation Engines",
    "abstract": "As a commercial provider of machine translation, we are constantly training engines for a variety of uses, languages, and content types. In each case, there can be many variables, such as the amount of training data available, and the quality requirements of the end user. These variables can have an impact on the robustness of Neural MT engines. On the whole, Neural MT cures many ills of other MT paradigms, but at the same time, it has introduced a new set of challenges to address. In this paper, we describe some of the specific issues with practical NMT and the approaches we take to improve model robustness in real-world scenarios",
    "volume": "main",
    "checked": true,
    "id": "afa90eb29d4059617d90bd8ba2dabcddf0fc6a1c",
    "citation_count": 3
  },
  "https://aclanthology.org/W19-6728": {
    "title": "Surveying the potential of using speech technologies for post-editing purposes in the context of international organizations: What do professional translators think?",
    "abstract": "The present study has surveyed professional translators working in six international organizations in order to know more about their views and attitudes with regard to new translation workflows involving two different types of technologies, i.e. machine translation and speech recognition. The main aim of this survey was to identify how feasible it is to implement new post-editing workflows in an international organization using speech as an input method to edit inaccurate machine translation outputs. Overall, the results suggest that the surveyed translators do not hold a negative view on the use of ASR as part of their translation workflow, which provides a promising first step towards investigating the integration of speech based post-editing to translation workflows for productivity and ergonomic gains",
    "volume": "main",
    "checked": true,
    "id": "8023c1ab8c0d4ded5b197de233013cf4c9ac98f2",
    "citation_count": 1
  },
  "https://aclanthology.org/W19-6729": {
    "title": "Automatic Translation for Software with Safe Velocity",
    "abstract": "We report on a model for machine translation (MT) of software, without review, for the Microsoft Office product range. We have deployed an automated localisation workflow, known as Automated Translation (AT) for software, which identifies resource strings as suitable and safe for MT without post-editing. The model makes use of string profiling, user impact assessment, MT quality estimation, and customer feedback mechanisms. This allows us to introduce automatic translation at a safe velocity, with a minimal risk to customer satisfaction. Quality constraints limit the volume of MT in relation to human translation, with published low-quality MT limited to not exceed 10% of total word count. The AT for software model has been deployed into production for most of the Office product range, for 37 languages. It allows us to MT and publish without review over 20% of the word count for some languages and products. To date, we have processed more than 1 million words with this model, and so far have not seen any measurable negative impact on customer satisfaction",
    "volume": "main",
    "checked": true,
    "id": "9b3e9b04207dd52781cc70ab84501ec9ae19427b",
    "citation_count": 7
  },
  "https://aclanthology.org/W19-6730": {
    "title": "Application of Post-Edited Machine Translation in Fashion eCommerce",
    "abstract": "Machine translation (MT) and post-edited machine translation (PEMT) have traditionally been explored primarily in the context of legal and medical content types, where MT results are often easier to predict due to the heavily standardised language structure and unambiguous nature of terminology used. Each content type and domain presents its unique challenges to both MT systems and linguists performing the post-editing tasks. This paper describes how PEMT can be applied in the fashion eCommerce domain, taking a popular British fashion brand – Topshop – as an example. This paper aims to explore different aspects of delivering PEMT to a fashion eCommerce client, the most prominent being linguists’ involvement in machine translation-related activities, including their key role in transitioning from human translation to statistical machine translation (SMT), and then from SMT to neural machine translation (NMT). The implications of switching from full human translation to PEMT for the end client and overall learnings made by the language service provider (LSP) during these transitions will be also discussed",
    "volume": "main",
    "checked": true,
    "id": "f8dfb9b8b5496cc1cae7ddb276ce08154032c588",
    "citation_count": 2
  },
  "https://aclanthology.org/W19-6731": {
    "title": "Morphological Neural Pre- and Post-Processing for Slavic Languages",
    "abstract": "While developing NMT systems for our customers involving Slavic languages, we encountered certain issues that do not affect Latin or Germanic languages. The most striking of these is the morphological complexity inherent in a remarkable number of unique synthetic forms. For each language combination, the aim is always to find the best balance between the size of the vocabulary, the quality of the translation and the performance of the MT model (both training time and translation time). When working with Slavic idioms, the variety of cases and genders makes this challenge even more difficult and engaging. For Slavic source languages, our solution is to add an extra pre-processing step before the actual translation, in which the inflected word is reduced to its components; naturally, in the opposite direction this requires a symmetrical post-processing technique. Tests have proven high-quality results for Slavic languages, either source or target, confirming this as an effective approach",
    "volume": "main",
    "checked": true,
    "id": "2c174776b25708d90f91b7fcd56825c6018e017e",
    "citation_count": 0
  },
  "https://aclanthology.org/W19-6732": {
    "title": "Large-scale Machine Translation Evaluation of the iADAATPA Project",
    "abstract": "This paper reports the results of an indepth evaluation of 34 state-of-the-art domain-adapted machine translation (MT) systems that were built by four leading MT companies as part of the EU-funded iADAATPA project. These systems support a wide variety of languages for several domains. The evaluation combined automatic metrics and human methods, namely assessments of adequacy, ﬂuency, and comparative ranking. The paper also discusses the most effective techniques to build domain-adapted MT systems for the relevant language combinations and domains",
    "volume": "main",
    "checked": true,
    "id": "cbbbea2c1fd303fd58a89d57a69211919ad485a7",
    "citation_count": 5
  }
}