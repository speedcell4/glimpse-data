{
  "https://aclanthology.org/2023.tacl-1.2": {
    "title": "Assessing the Capacity of Transformer to Abstract Syntactic Representations: A Contrastive Analysis Based on Long-distance Agreement",
    "volume": "main",
    "abstract": "Many studies have shown that transformers are able to predict subject-verb agreement, demonstrating their ability to uncover an abstract representation of the sentence in an unsupervised way. Recently, Li et al. (2021) found that transformers were also able to predict the object-past participle agreement in French, the modeling of which in formal grammar is fundamentally different from that of subject-verb agreement and relies on a movement and an anaphora resolution. To better understand transformers' internal working, we propose to contrast how they handle these two kinds of agreement. Using probing and counterfactual analysis methods, our experiments on French agreements show that (i) the agreement task suffers from several confounders that partially question the conclusions drawn so far and (ii) transformers handle subject-verb and object-past participle agreements in a way that is consistent with their modeling in theoretical linguistics",
    "checked": true,
    "id": "52a14dbf77de839fe3eab4898c13df80993cc54d",
    "semantic_title": "assessing the capacity of transformer to abstract syntactic representations: a contrastive analysis based on long-distance agreement",
    "citation_count": 2,
    "authors": [
      "Bingzhi Li",
      "Guillaume Wisniewski",
      "Benoît Crabbé"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.3": {
    "title": "On the Role of Negative Precedent in Legal Outcome Prediction",
    "volume": "main",
    "abstract": "Every legal case sets a precedent by developing the law in one of the following two ways. It either expands its scope, in which case it sets positive precedent, or it narrows it, in which case it sets negative precedent. Legal outcome prediction, the prediction of positive outcome, is an increasingly popular task in AI. In contrast, we turn our focus to negative outcomes here, and introduce a new task of negative outcome prediction. We discover an asymmetry in existing models' ability to predict positive and negative outcomes. Where the state-of-the-art outcome prediction model we used predicts positive outcomes at 75.06 F1, it predicts negative outcomes at only 10.09 F1, worse than a random baseline. To address this performance gap, we develop two new models inspired by the dynamics of a court process. Our first model significantly improves positive outcome prediction score to 77.15 F1 and our second model more than doubles the negative outcome prediction performance to 24.01 F1. Despite this improvement, shifting focus to negative outcomes reveals that there is still much room for improvement for outcome prediction models. https://github.com/valvoda/Negative-Precedent-in-Legal-Outcome-Prediction",
    "checked": true,
    "id": "0f3873c4b60074bcdd8880d34ccda61d778df2c7",
    "semantic_title": "on the role of negative precedent in legal outcome prediction",
    "citation_count": 7,
    "authors": [
      "Josef Valvoda",
      "Ryan Cotterell",
      "Simone Teufel"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.4": {
    "title": "Meta-Learning a Cross-lingual Manifold for Semantic Parsing",
    "volume": "main",
    "abstract": "Localizing a semantic parser to support new languages requires effective cross-lingual generalization. Recent work has found success with machine-translation or zero-shot methods, although these approaches can struggle to model how native speakers ask questions. We consider how to effectively leverage minimal annotated examples in new languages for few-shot cross-lingual semantic parsing. We introduce a first-order meta-learning algorithm to train a semantic parser with maximal sample efficiency during cross-lingual transfer. Our algorithm uses high-resource languages to train the parser and simultaneously optimizes for cross-lingual generalization to lower-resource languages. Results across six languages on ATIS demonstrate that our combination of generalization steps yields accurate semantic parsers sampling ≤10% of source training data in each new language. Our approach also trains a competitive model on Spider using English with generalization to Chinese similarly sampling ≤10% of training data.1",
    "checked": true,
    "id": "3081f957d5ef4760e1875e2cd350b320f9026bc3",
    "semantic_title": "meta-learning a cross-lingual manifold for semantic parsing",
    "citation_count": 7,
    "authors": [
      "Tom Sherborne",
      "Mirella Lapata"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.5": {
    "title": "OPAL: Ontology-Aware Pretrained Language Model for End-to-End Task-Oriented Dialogue",
    "volume": "main",
    "abstract": "This paper presents an ontology-aware pretrained language model (OPAL) for end-to-end task-oriented dialogue (TOD). Unlike chit-chat dialogue models, task-oriented dialogue models fulfill at least two task-specific modules: Dialogue state tracker (DST) and response generator (RG). The dialogue state consists of the domain-slot-value triples, which are regarded as the user's constraints to search the domain-related databases. The large-scale task-oriented dialogue data with the annotated structured dialogue state usually are inaccessible. It prevents the development of the pretrained language model for the task-oriented dialogue. We propose a simple yet effective pretraining method to alleviate this problem, which consists of two pretraining phases. The first phase is to pretrain on large-scale contextual text data, where the structured information of the text is extracted by the information extracting tool. To bridge the gap between the pretraining method and downstream tasks, we design two pretraining tasks: ontology-like triple recovery and next-text generation, which simulates the DST and RG, respectively. The second phase is to fine-tune the pretrained model on the TOD data. The experimental results show that our proposed method achieves an exciting boost and obtains competitive performance even without any TOD data on CamRest676 and MultiWOZ benchmarks",
    "checked": true,
    "id": "5db7d2b1b537fa5eea0108fac477677448531d0d",
    "semantic_title": "opal: ontology-aware pretrained language model for end-to-end task-oriented dialogue",
    "citation_count": 4,
    "authors": [
      "Zhi Chen",
      "Yuncong Liu",
      "Lu Chen",
      "Su Zhu",
      "Mengyue Wu",
      "Kai Yu"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.6": {
    "title": "Helpful Neighbors: Leveraging Neighbors in Geographic Feature Pronunciation",
    "volume": "main",
    "abstract": "If one sees the place name Houston Mercer Dog Run in New York, how does one know how to pronounce it? Assuming one knows that Houston in New York is pronounced /ˈhaʊstən/ and not like the Texas city (/ˈhjuːstən/), then one can probably guess that /ˈhaʊstən/ is also used in the name of the dog park. We present a novel architecture that learns to use the pronunciations of neighboring names in order to guess the pronunciation of a given target feature. Applied to Japanese place names, we demonstrate the utility of the model to finding and proposing corrections for errors in Google Maps. To demonstrate the utility of this approach to structurally similar problems, we also report on an application to a totally different task: Cognate reflex prediction in comparative historical linguistics. A version of the code has been open-sourced.1",
    "checked": true,
    "id": "a2b77b69a69743b3d63b51c43c1dce585cf3c1a2",
    "semantic_title": "helpful neighbors: leveraging neighbors in geographic feature pronunciation",
    "citation_count": 1,
    "authors": [
      "Llion Jones",
      "Richard Sproat",
      "Haruko Ishikawa",
      "Alexander Gutkin"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.7": {
    "title": "Locally Typical Sampling",
    "volume": "main",
    "abstract": "Today's probabilistic language generators fall short when it comes to producing coherent and fluent text despite the fact that the underlying models perform well under standard metrics (e.g., perplexity). This discrepancy has puzzled the language generation community for the last few years. In this work, we posit that the abstraction of natural language generation as a discrete stochastic process—which allows for an information-theoretic analysis—can provide new insights into the behavior of probabilistic language generators, for example, why high-probability texts can be dull or repetitive. Humans use language as a means of communicating information, aiming to do so in a simultaneously efficient and error-minimizing manner; in fact, psycholinguistics research suggests humans choose each word in a string with this subconscious goal in mind. We formally define the set of strings that meet this criterion: Those for which each word has an information content close to the expected information content, namely, the conditional entropy of our model. We then propose a simple and efficient procedure for enforcing this criterion when generating from probabilistic models, which we call locally typical sampling. Automatic and human evaluations show that, in comparison to nucleus and top-k sampling, locally typical sampling offers competitive performance (in both abstractive summarization and story generation) in terms of quality while consistently reducing degenerate repetitions",
    "checked": true,
    "id": "3d849136e0070f6d038dd96985ed67ead5aedb69",
    "semantic_title": "locally typical sampling",
    "citation_count": 42,
    "authors": [
      "Clara Meister",
      "Tiago Pimentel",
      "Gian Wiher",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.8": {
    "title": "Improving Low-Resource Cross-lingual Parsing with Expected Statistic Regularization",
    "volume": "main",
    "abstract": "We present Expected Statistic Regulariza tion (ESR), a novel regularization technique that utilizes low-order multi-task structural statistics to shape model distributions for semi- supervised learning on low-resource datasets. We study ESR in the context of cross-lingual transfer for syntactic analysis (POS tagging and labeled dependency parsing) and present several classes of low-order statistic functions that bear on model behavior. Experimentally, we evaluate the proposed statistics with ESR for unsupervised transfer on 5 diverse target languages and show that all statistics, when estimated accurately, yield improvements to both POS and LAS, with the best statistic improving POS by +7.0 and LAS by +8.5 on average. We also present semi-supervised transfer and learning curve experiments that show ESR provides significant gains over strong cross-lingual-transfer-plus-fine-tuning baselines for modest amounts of label data. These results indicate that ESR is a promising and complementary approach to model-transfer approaches for cross-lingual parsing.1",
    "checked": true,
    "id": "90d928fcd348ba8073952e665a24e28061a65018",
    "semantic_title": "improving low-resource cross-lingual parsing with expected statistic regularization",
    "citation_count": 0,
    "authors": [
      "Thomas Effland",
      "Michael Collins"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.9": {
    "title": "Cross-Lingual Dialogue Dataset Creation via Outline-Based Generation",
    "volume": "main",
    "abstract": "Multilingual task-oriented dialogue (ToD) facilitates access to services and information for many (communities of) speakers. Nevertheless, its potential is not fully realized, as current multilingual ToD datasets—both for modular and end-to-end modeling—suffer from severe limitations. 1) When created from scratch, they are usually small in scale and fail to cover many possible dialogue flows. 2) Translation-based ToD datasets might lack naturalness and cultural specificity in the target language. In this work, to tackle these limitations we propose a novel outline-based annotation process for multilingual ToD datasets, where domain-specific abstract schemata of dialogue are mapped into natural language outlines. These in turn guide the target language annotators in writing dialogues by providing instructions about each turn's intents and slots. Through this process we annotate a new large-scale dataset for evaluation of multilingual and cross-lingual ToD systems. Our Cross-lingual Outline-based Dialogue dataset (cod) enables natural language understanding, dialogue state tracking, and end-to-end dialogue evaluation in 4 diverse languages: Arabic, Indonesian, Russian, and Kiswahili. Qualitative and quantitative analyses of cod versus an equivalent translation-based dataset demonstrate improvements in data quality, unlocked by the outline-based approach. Finally, we benchmark a series of state-of-the-art systems for cross-lingual ToD, setting reference scores for future work and demonstrating that cod prevents over-inflated performance, typically met with prior translation-based ToD datasets",
    "checked": true,
    "id": "564992c12097a87c279a90a1459eb72bbd007090",
    "semantic_title": "cross-lingual dialogue dataset creation via outline-based generation",
    "citation_count": 17,
    "authors": [
      "Olga Majewska",
      "Evgeniia Razumovskaia",
      "Edoardo M. Ponti",
      "Ivan Vulić",
      "Anna Korhonen"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.10": {
    "title": "Modeling Emotion Dynamics in Song Lyrics with State Space Models",
    "volume": "main",
    "abstract": "Most previous work in music emotion recognition assumes a single or a few song-level labels for the whole song. While it is known that different emotions can vary in intensity within a song, annotated data for this setup is scarce and difficult to obtain. In this work, we propose a method to predict emotion dynamics in song lyrics without song-level supervision. We frame each song as a time series and employ a State Space Model (SSM), combining a sentence-level emotion predictor with an Expectation-Maximization (EM) procedure to generate the full emotion dynamics. Our experiments show that applying our method consistently improves the performance of sentence-level baselines without requiring any annotated songs, making it ideal for limited training data scenarios. Further analysis through case studies shows the benefits of our method while also indicating the limitations and pointing to future directions",
    "checked": true,
    "id": "5fe2e41813036cf6829433fdb18c2ef24d437245",
    "semantic_title": "modeling emotion dynamics in song lyrics with state space models",
    "citation_count": 0,
    "authors": [
      "Yingjin Song",
      "Daniel Beck"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.11": {
    "title": "FeelingBlue: A Corpus for Understanding the Emotional Connotation of Color in Context",
    "volume": "main",
    "abstract": "While the link between color and emotion has been widely studied, how context-based changes in color impact the intensity of perceived emotions is not well understood. In this work, we present a new multimodal dataset for exploring the emotional connotation of color as mediated by line, stroke, texture, shape, and language. Our dataset, FeelingBlue, is a collection of 19,788 4-tuples of abstract art ranked by annotators according to their evoked emotions and paired with rationales for those annotations. Using this corpus, we present a baseline for a new task: Justified Affect Transformation. Given an image I, the task is to 1) recolor I to enhance a specified emotion e and 2) provide a textual justification for the change in e. Our model is an ensemble of deep neural networks which takes I, generates an emotionally transformed color palette p conditioned on I, applies p to I, and then justifies the color transformation in text via a visual-linguistic model. Experimental results shed light on the emotional connotation of color in context, demonstrating both the promise of our approach on this challenging task and the considerable potential for future investigations enabled by our corpus.1",
    "checked": true,
    "id": "69df56aeb1efbebc79468d51103b65021502d33d",
    "semantic_title": "feelingblue: a corpus for understanding the emotional connotation of color in context",
    "citation_count": 0,
    "authors": [
      "Amith Ananthram",
      "Olivia Winn",
      "Smaranda Muresan"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.12": {
    "title": "An Empirical Survey of Data Augmentation for Limited Data Learning in NLP",
    "volume": "main",
    "abstract": "NLP has achieved great progress in the past decade through the use of neural models and large labeled datasets. The dependence on abundant data prevents NLP models from being applied to low-resource settings or novel tasks where significant time, money, or expertise is required to label massive amounts of textual data. Recently, data augmentation methods have been explored as a means of improving data efficiency in NLP. To date, there has been no systematic empirical overview of data augmentation for NLP in the limited labeled data setting, making it difficult to understand which methods work in which settings. In this paper, we provide an empirical survey of recent progress on data augmentation for NLP in the limited labeled data setting, summarizing the landscape of methods (including token-level augmentations, sentence-level augmentations, adversarial augmentations, and hidden-space augmentations) and carrying out experiments on 11 datasets covering topics/news classification, inference tasks, paraphrasing tasks, and single-sentence tasks. Based on the results, we draw several conclusions to help practitioners choose appropriate augmentations in different settings and discuss the current challenges and future directions for limited data learning in NLP",
    "checked": true,
    "id": "013eb12ce5468f79d58bf859653f4929c5a2bd14",
    "semantic_title": "an empirical survey of data augmentation for limited data learning in nlp",
    "citation_count": 71,
    "authors": [
      "Jiaao Chen",
      "Derek Tam",
      "Colin Raffel",
      "Mohit Bansal",
      "Diyi Yang"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.13": {
    "title": "Coreference Resolution through a seq2seq Transition-Based System",
    "volume": "main",
    "abstract": "Most recent coreference resolution systems use search algorithms over possible spans to identify mentions and resolve coreference. We instead present a coreference resolution system that uses a text-to-text (seq2seq) paradigm to predict mentions and links jointly. We implement the coreference system as a transition system and use multilingual T5 as an underlying language model. We obtain state-of-the-art accuracy on the CoNLL-2012 datasets with 83.3 F1-score for English (a 2.3 higher F1-score than previous work [Dobrovolskii, 2021]) using only CoNLL data for training, 68.5 F1-score for Arabic (+4.1 higher than previous work), and 74.3 F1-score for Chinese (+5.3). In addition we use the SemEval-2010 data sets for experiments in the zero-shot setting, a few-shot setting, and supervised setting using all available training data. We obtain substantially higher zero-shot F1-scores for 3 out of 4 languages than previous approaches and significantly exceed previous supervised state-of-the-art results for all five tested languages. We provide the code and models as open source.1",
    "checked": true,
    "id": "be25cd72db91d40d305d9bf870e23a16fda813be",
    "semantic_title": "coreference resolution through a seq2seq transition-based system",
    "citation_count": 5,
    "authors": [
      "Bernd Bohnet",
      "Chris Alberti",
      "Michael Collins"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.14": {
    "title": "Transformers for Tabular Data Representation: A Survey of Models and Applications",
    "volume": "main",
    "abstract": "In the last few years, the natural language processing community has witnessed advances in neural representations of free texts with transformer-based language models (LMs). Given the importance of knowledge available in tabular data, recent research efforts extend LMs by developing neural representations for structured data. In this article, we present a survey that analyzes these efforts. We first abstract the different systems according to a traditional machine learning pipeline in terms of training data, input representation, model training, and supported downstream tasks. For each aspect, we characterize and compare the proposed solutions. Finally, we discuss future work directions",
    "checked": true,
    "id": "18ff1542d5a2a4490c7b3f21522bf1343889f700",
    "semantic_title": "transformers for tabular data representation: a survey of models and applications",
    "citation_count": 13,
    "authors": [
      "Gilbert Badaro",
      "Mohammed Saeed",
      "Paolo Papotti"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.15": {
    "title": "Generative Spoken Dialogue Language Modeling",
    "volume": "main",
    "abstract": "We introduce dGSLM, the first \"textless\" model able to generate audio samples of naturalistic spoken dialogues. It uses recent work on unsupervised spoken unit discovery coupled with a dual-tower transformer architecture with cross-attention trained on 2000 hours of two-channel raw conversational audio (Fisher dataset) without any text or labels. We show that our model is able to generate speech, laughter, and other paralinguistic signals in the two channels simultaneously and reproduces more naturalistic and fluid turn taking compared to a text-based cascaded model.1,2",
    "checked": true,
    "id": "5a29401272d58c20bcd95728f646c186f62b6c48",
    "semantic_title": "generative spoken dialogue language modeling",
    "citation_count": 36,
    "authors": [
      "Tu Anh Nguyen",
      "Eugene Kharitonov",
      "Jade Copet",
      "Yossi Adi",
      "Wei-Ning Hsu",
      "Ali Elkahky",
      "Paden Tomasello",
      "Robin Algayres",
      "Benoît Sagot",
      "Abdelrahman Mohamed",
      "Emmanuel Dupoux"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.16": {
    "title": "Discontinuous Combinatory Constituency Parsing",
    "volume": "main",
    "abstract": "We extend a pair of continuous combinator-based constituency parsers (one binary and one multi-branching) into a discontinuous pair. Our parsers iteratively compose constituent vectors from word embeddings without any grammar constraints. Their empirical complexities are subquadratic. Our extension includes 1) a swap action for the orientation-based binary model and 2) biaffine attention for the chunker-based multi-branching model. In tests conducted with the Discontinuous Penn Treebank and TIGER Treebank, we achieved state-of-the-art discontinuous accuracy with a significant speed advantage",
    "checked": true,
    "id": "925f9c904349b64ed45bb5327dafe2da5f745891",
    "semantic_title": "discontinuous combinatory constituency parsing",
    "citation_count": 0,
    "authors": [
      "Zhousi Chen",
      "Mamoru Komachi"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.17": {
    "title": "Efficient Long-Text Understanding with Short-Text Models",
    "volume": "main",
    "abstract": "Transformer-based pretrained language models (LMs) are ubiquitous across natural language understanding, but cannot be applied to long sequences such as stories, scientific articles, and long documents due to their quadratic complexity. While a myriad of efficient transformer variants have been proposed, they are typically based on custom implementations that require expensive pretraining from scratch. In this work, we propose SLED: SLiding-Encoder and Decoder, a simple approach for processing long sequences that re-uses and leverages battle-tested short-text pretrained LMs. Specifically, we partition the input into overlapping chunks, encode each with a short-text LM encoder and use the pretrained decoder to fuse information across chunks (fusion-in-decoder). We illustrate through controlled experiments that SLED offers a viable strategy for long text understanding and evaluate our approach on SCROLLS, a benchmark with seven datasets across a wide range of language understanding tasks. We find that SLED is competitive with specialized models that are up to 50x larger and require a dedicated and expensive pretraining step",
    "checked": true,
    "id": "732e3faec4e5be4d144256f2c379b9dc49f0b227",
    "semantic_title": "efficient long-text understanding with short-text models",
    "citation_count": 15,
    "authors": [
      "Maor Ivgi",
      "Uri Shaham",
      "Jonathan Berant"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.18": {
    "title": "Hate Speech Classifiers Learn Normative Social Stereotypes",
    "volume": "main",
    "abstract": "Social stereotypes negatively impact individuals' judgments about different groups and may have a critical role in understanding language directed toward marginalized groups. Here, we assess the role of social stereotypes in the automated detection of hate speech in the English language by examining the impact of social stereotypes on annotation behaviors, annotated datasets, and hate speech classifiers. Specifically, we first investigate the impact of novice annotators' stereotypes on their hate-speech-annotation behavior. Then, we examine the effect of normative stereotypes in language on the aggregated annotators' judgments in a large annotated corpus. Finally, we demonstrate how normative stereotypes embedded in language resources are associated with systematic prediction errors in a hate-speech classifier. The results demonstrate that hate-speech classifiers reflect social stereotypes against marginalized groups, which can perpetuate social inequalities when propagated at scale. This framework, combining social-psychological and computational-linguistic methods, provides insights into sources of bias in hate-speech moderation, informing ongoing debates regarding machine learning fairness",
    "checked": true,
    "id": "1bacf2e89e157599f642981b9739133e4c589376",
    "semantic_title": "hate speech classifiers learn normative social stereotypes",
    "citation_count": 4,
    "authors": [
      "Aida Mostafazadeh Davani",
      "Mohammad Atari",
      "Brendan Kennedy",
      "Morteza Dehghani"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.19": {
    "title": "Domain-Specific Word Embeddings with Structure Prediction",
    "volume": "main",
    "abstract": "Complementary to finding good general word embeddings, an important question for representation learning is to find dynamic word embeddings, for example, across time or domain. Current methods do not offer a way to use or predict information on structure between sub-corpora, time or domain and dynamic embeddings can only be compared after post-alignment. We propose novel word embedding methods that provide general word representations for the whole corpus, domain- specific representations for each sub-corpus, sub-corpus structure, and embedding alignment simultaneously. We present an empirical evaluation on New York Times articles and two English Wikipedia datasets with articles on science and philosophy. Our method, called Word2Vec with Structure Prediction (W2VPred), provides better performance than baselines in terms of the general analogy tests, domain-specific analogy tests, and multiple specific word embedding evaluations as well as structure prediction performance when no structure is given a priori. As a use case in the field of Digital Humanities we demonstrate how to raise novel research questions for high literature from the German Text Archive",
    "checked": true,
    "id": "28accfdc9b7328cae086e9ed6031461e2f5736df",
    "semantic_title": "domain-specific word embeddings with structure prediction",
    "citation_count": 0,
    "authors": [
      "David Lassner",
      "Stephanie Brandl",
      "Anne Baillot",
      "Shinichi Nakajima"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.20": {
    "title": "Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?",
    "volume": "main",
    "abstract": "This work presents a linguistic analysis into why larger Transformer-based pre-trained language models with more parameters and lower perplexity nonetheless yield surprisal estimates that are less predictive of human reading times. First, regression analyses show a strictly monotonic, positive log-linear relationship between perplexity and fit to reading times for the more recently released five GPT-Neo variants and eight OPT variants on two separate datasets, replicating earlier results limited to just GPT-2 (Oh et al., 2022). Subsequently, analysis of residual errors reveals a systematic deviation of the larger variants, such as underpredicting reading times of named entities and making compensatory overpredictions for reading times of function words such as modals and conjunctions. These results suggest that the propensity of larger Transformer-based models to ‘memorize' sequences during training makes their surprisal estimates diverge from humanlike expectations, which warrants caution in using pre-trained language models to study human language processing",
    "checked": true,
    "id": "eaee0b647d336c6fc8b844812675ec35cddf14a1",
    "semantic_title": "why does surprisal from larger transformer-based language models provide a poorer fit to human reading times?",
    "citation_count": 18,
    "authors": [
      "Byung-Doh Oh",
      "William Schuler"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.21": {
    "title": "On the Robustness of Dialogue History Representation in Conversational Question Answering: A Comprehensive Study and a New Prompt-based Method",
    "volume": "main",
    "abstract": "Most work on modeling the conversation history in Conversational Question Answering (CQA) reports a single main result on a common CQA benchmark. While existing models show impressive results on CQA leaderboards, it remains unclear whether they are robust to shifts in setting (sometimes to more realistic ones), training data size (e.g., from large to small sets) and domain. In this work, we design and conduct the first large-scale robustness study of history modeling approaches for CQA. We find that high benchmark scores do not necessarily translate to strong robustness, and that various methods can perform extremely differently under different settings. Equipped with the insights from our study, we design a novel prompt-based history modeling approach and demonstrate its strong robustness across various settings. Our approach is inspired by existing methods that highlight historic answers in the passage. However, instead of highlighting by modifying the passage token embeddings, we add textual prompts directly in the passage text. Our approach is simple, easy to plug into practically any model, and highly effective, thus we recommend it as a starting point for future model developers. We also hope that our study and insights will raise awareness to the importance of robustness-focused evaluation, in addition to obtaining high leaderboard scores, leading to better CQA systems.1",
    "checked": true,
    "id": "3eba01e41208e69942fc0cdaca391d4ed49a99e7",
    "semantic_title": "on the robustness of dialogue history representation in conversational question answering: a comprehensive study and a new prompt-based method",
    "citation_count": 2,
    "authors": [
      "Zorik Gekhman",
      "Nadav Oved",
      "Orgad Keller",
      "Idan Szpektor",
      "Roi Reichart"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.22": {
    "title": "Bridging the Gap between Synthetic and Natural Questions via Sentence Decomposition for Semantic Parsing",
    "volume": "main",
    "abstract": "Semantic parsing maps natural language questions into logical forms, which can be executed against a knowledge base for answers. In real-world applications, the performance of a parser is often limited by the lack of training data. To facilitate zero-shot learning, data synthesis has been widely studied to automatically generate paired questions and logical forms. However, data synthesis methods can hardly cover the diverse structures in natural languages, leading to a large gap in sentence structure between synthetic and natural questions. In this paper, we propose a decomposition-based method to unify the sentence structures of questions, which benefits the generalization to natural questions. Experiments demonstrate that our method significantly improves the semantic parser trained on synthetic data (+7.9% on KQA and +8.9% on ComplexWebQuestions in terms of exact match accuracy). Extensive analysis demonstrates that our method can better generalize to natural questions with novel text expressions compared with baselines. Besides semantic parsing, our idea potentially benefits other semantic understanding tasks by mitigating the distracting structure features. To illustrate this, we extend our method to the task of sentence embedding learning, and observe substantial improvements on sentence retrieval (+13.1% for Hit@1)",
    "checked": true,
    "id": "3d16f935ed586baee8bb95574862606df67e518d",
    "semantic_title": "bridging the gap between synthetic and natural questions via sentence decomposition for semantic parsing",
    "citation_count": 0,
    "authors": [
      "Yilin Niu",
      "Fei Huang",
      "Wei Liu",
      "Jianwei Cui",
      "Bin Wang",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.23": {
    "title": "Naturalistic Causal Probing for Morpho-Syntax",
    "volume": "main",
    "abstract": "Probing has become a go-to methodology for interpreting and analyzing deep neural models in natural language processing. However, there is still a lack of understanding of the limitations and weaknesses of various types of probes. In this work, we suggest a strategy for input-level intervention on naturalistic sentences. Using our approach, we intervene on the morpho-syntactic features of a sentence, while keeping the rest of the sentence unchanged. Such an intervention allows us to causally probe pre-trained models. We apply our naturalistic causal probing framework to analyze the effects of grammatical gender and number on contextualized representations extracted from three pre-trained models in Spanish, the multilingual versions of BERT, RoBERTa, and GPT-2. Our experiments suggest that naturalistic interventions lead to stable estimates of the causal effects of various linguistic properties. Moreover, our experiments demonstrate the importance of naturalistic causal probing when analyzing pre-trained models. https://github.com/rycolab/naturalistic-causal-probing",
    "checked": true,
    "id": "aa0c9285bb76c7a4c3f32a5b122f1d5eb171c5d6",
    "semantic_title": "naturalistic causal probing for morpho-syntax",
    "citation_count": 5,
    "authors": [
      "Afra Amini",
      "Tiago Pimentel",
      "Clara Meister",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.24": {
    "title": "Tracking Brand-Associated Polarity-Bearing Topics in User Reviews",
    "volume": "main",
    "abstract": "Monitoring online customer reviews is important for business organizations to measure customer satisfaction and better manage their reputations. In this paper, we propose a novel dynamic Brand-Topic Model (dBTM) which is able to automatically detect and track brand-associated sentiment scores and polarity-bearing topics from product reviews organized in temporally ordered time intervals. dBTM models the evolution of the latent brand polarity scores and the topic-word distributions over time by Gaussian state space models. It also incorporates a meta learning strategy to control the update of the topic-word distribution in each time interval in order to ensure smooth topic transitions and better brand score predictions. It has been evaluated on a dataset constructed from MakeupAlley reviews and a hotel review dataset. Experimental results show that dBTM outperforms a number of competitive baselines in brand ranking, achieving a good balance of topic coherence and uniqueness, and extracting well-separated polarity-bearing topics across time intervals.1",
    "checked": true,
    "id": "78724ed1f105973e3105f0b40db34a62216a6ce5",
    "semantic_title": "tracking brand-associated polarity-bearing topics in user reviews",
    "citation_count": 0,
    "authors": [
      "Runcong Zhao",
      "Lin Gui",
      "Hanqi Yan",
      "Yulan He"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.25": {
    "title": "Dubbing in Practice: A Large Scale Study of Human Localization With Insights for Automatic Dubbing",
    "volume": "main",
    "abstract": "We investigate how humans perform the task of dubbing video content from one language into another, leveraging a novel corpus of 319.57 hours of video from 54 professionally produced titles. This is the first such large-scale study we are aware of. The results challenge a number of assumptions commonly made in both qualitative literature on human dubbing and machine-learning literature on automatic dubbing, arguing for the importance of vocal naturalness and translation quality over commonly emphasized isometric (character length) and lip-sync constraints, and for a more qualified view of the importance of isochronic (timing) constraints. We also find substantial influence of the source-side audio on human dubs through channels other than the words of the translation, pointing to the need for research on ways to preserve speech characteristics, as well as transfer of semantic properties such as emphasis and emotion, in automatic dubbing systems",
    "checked": true,
    "id": "d6dbc76d06d7324c6a46249fa99358c5772fa55d",
    "semantic_title": "dubbing in practice: a large scale study of human localization with insights for automatic dubbing",
    "citation_count": 7,
    "authors": [
      "William Brannon",
      "Yogesh Virkar",
      "Brian Thompson"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.26": {
    "title": "Aggretriever: A Simple Approach to Aggregate Textual Representations for Robust Dense Passage Retrieval",
    "volume": "main",
    "abstract": "Pre-trained language models have been successful in many knowledge-intensive NLP tasks. However, recent work has shown that models such as BERT are not \"structurally ready\" to aggregate textual information into a [CLS] vector for dense passage retrieval (DPR). This \"lack of readiness\" results from the gap between language model pre-training and DPR fine-tuning. Previous solutions call for computationally expensive techniques such as hard negative mining, cross-encoder distillation, and further pre-training to learn a robust DPR model. In this work, we instead propose to fully exploit knowledge in a pre-trained language model for DPR by aggregating the contextualized token embeddings into a dense vector, which we call agg★. By concatenating vectors from the [CLS] token and agg★, our Aggretriever model substantially improves the effectiveness of dense retrieval models on both in-domain and zero-shot evaluations without introducing substantial training overhead. Code is available at https://github.com/castorini/dhr",
    "checked": true,
    "id": "6764157d4e955d712509b842106fb180c9628868",
    "semantic_title": "aggretriever: a simple approach to aggregate textual representations for robust dense passage retrieval",
    "citation_count": 9,
    "authors": [
      "Sheng-Chieh Lin",
      "Minghan Li",
      "Jimmy Lin"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.27": {
    "title": "InSCIt: Information-Seeking Conversations with Mixed-Initiative Interactions",
    "volume": "main",
    "abstract": "In an information-seeking conversation, a user may ask questions that are under-specified or unanswerable. An ideal agent would interact by initiating different response types according to the available knowledge sources. However, most current studies either fail to or artificially incorporate such agent-side initiative. This work presents InSCIt, a dataset for Information-Seeking Conversations with mixed-initiative Interactions. It contains 4.7K user-agent turns from 805 human-human conversations where the agent searches over Wikipedia and either directly answers, asks for clarification, or provides relevant information to address user queries. The data supports two subtasks, evidence passage identification and response generation, as well as a human evaluation protocol to assess model performance. We report results of two systems based on state-of-the-art models of conversational knowledge identification and open-domain question answering. Both systems significantly underperform humans, suggesting ample room for improvement in future studies.1",
    "checked": true,
    "id": "4f1df08368d0925109e8f88a8184af3a01f5aedf",
    "semantic_title": "inscit: information-seeking conversations with mixed-initiative interactions",
    "citation_count": 5,
    "authors": [
      "Zeqiu Wu",
      "Ryu Parish",
      "Hao Cheng",
      "Sewon Min",
      "Prithviraj Ammanabrolu",
      "Mari Ostendorf",
      "Hannaneh Hajishirzi"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.28": {
    "title": "Sub-Character Tokenization for Chinese Pretrained Language Models",
    "volume": "main",
    "abstract": "Tokenization is fundamental to pretrained language models (PLMs). Existing tokenization methods for Chinese PLMs typically treat each character as an indivisible token. However, they ignore the unique feature of the Chinese writing system where additional linguistic information exists below the character level, i.e., at the sub-character level. To utilize such information, we propose sub-character (SubChar for short) tokenization. Specifically, we first encode the input text by converting each Chinese character into a short sequence based on its glyph or pronunciation, and then construct the vocabulary based on the encoded text with sub-word segmentation. Experimental results show that SubChar tokenizers have two main advantages over existing tokenizers: 1) They can tokenize inputs into much shorter sequences, thus improving the computational efficiency. 2) Pronunciation-based SubChar tokenizers can encode Chinese homophones into the same transliteration sequences and produce the same tokenization output, hence being robust to homophone typos. At the same time, models trained with SubChar tokenizers perform competitively on downstream tasks. We release our code and models at https://github.com/thunlp/SubCharTokenization to facilitate future work",
    "checked": true,
    "id": "5dee4ece8ec1725a7d071b74bf60f4f5fd2e78ad",
    "semantic_title": "sub-character tokenization for chinese pretrained language models",
    "citation_count": 2,
    "authors": [
      "Chenglei Si",
      "Zhengyan Zhang",
      "Yingfa Chen",
      "Fanchao Qi",
      "Xiaozhi Wang",
      "Zhiyuan Liu",
      "Yasheng Wang",
      "Qun Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.29": {
    "title": "Erasure of Unaligned Attributes from Neural Representations",
    "volume": "main",
    "abstract": "We present the Assignment-Maximization Spectral Attribute removaL (AMSAL) algorithm, which erases information from neural representations when the information to be erased is implicit rather than directly being aligned to each input example. Our algorithm works by alternating between two steps. In one, it finds an assignment of the input representations to the information to be erased, and in the other, it creates projections of both the input representations and the information to be erased into a joint latent space. We test our algorithm on an extensive array of datasets, including a Twitter dataset with multiple guarded attributes, the BiasBios dataset, and the BiasBench benchmark. The latter benchmark includes four datasets with various types of protected attributes. Our results demonstrate that bias can often be removed in our setup. We also discuss the limitations of our approach when there is a strong entanglement between the main task and the information to be erased.1",
    "checked": true,
    "id": "de55ebf5109a862a9ae350b09ff5186c38e985b2",
    "semantic_title": "erasure of unaligned attributes from neural representations",
    "citation_count": 4,
    "authors": [
      "Shun Shao",
      "Yftah Ziser",
      "Shay B. Cohen"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.30": {
    "title": "Less is More: Mitigate Spurious Correlations for Open-Domain Dialogue Response Generation Models by Causal Discovery",
    "volume": "main",
    "abstract": "In this paper, we conduct the first study on spurious correlations for open-domain response generation models based on a corpus CGDialog curated by ourselves. The current models indeed suffer from spurious correlations and have a tendency to generate irrelevant and generic responses. Inspired by causal discovery algorithms, we propose a novel model-agnostic method for training and inference using a conditional independence classifier. The classifier is trained by a constrained self-training method, coined ConSTrain, to overcome data sparsity. The experimental results based on both human and automatic evaluation show that our method significantly outperforms the competitive baselines in terms of relevance, informativeness, and fluency",
    "checked": true,
    "id": "36c8d3ef11c1ebe311489c27dffca56d19369c38",
    "semantic_title": "less is more: mitigate spurious correlations for open-domain dialogue response generation models by causal discovery",
    "citation_count": 0,
    "authors": [
      "Tao Feng",
      "Lizhen Qu",
      "Gholamreza Haffari"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.31": {
    "title": "The Parallelism Tradeoff: Limitations of Log-Precision Transformers",
    "volume": "main",
    "abstract": "Despite their omnipresence in modern NLP, characterizing the computational power of transformer neural nets remains an interesting open question. We prove that transformers whose arithmetic precision is logarithmic in the number of input tokens (and whose feedforward nets are computable using space linear in their input) can be simulated by constant-depth logspace-uniform threshold circuits. This provides insight on the power of transformers using known results in complexity theory. For example, if L≠P (i.e., not all poly-time problems can be solved using logarithmic space), then transformers cannot even accurately solve linear equalities or check membership in an arbitrary context-free grammar with empty productions. Our result intuitively emerges from the transformer architecture's high parallelizability. We thus speculatively introduce the idea of a fundamental parallelism tradeoff: any model architecture as parallelizable as the transformer will obey limitations similar to it. Since parallelism is key to training models at massive scale, this suggests a potential inherent weakness of the scaling paradigm",
    "checked": true,
    "id": "7c36e34274c578acd913449f99e8bf673a406e1a",
    "semantic_title": "the parallelism tradeoff: limitations of log-precision transformers",
    "citation_count": 8,
    "authors": [
      "William Merrill",
      "Ashish Sabharwal"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.32": {
    "title": "Understanding and Detecting Hallucinations in Neural Machine Translation via Model Introspection",
    "volume": "main",
    "abstract": "Neural sequence generation models are known to \"hallucinate\", by producing outputs that are unrelated to the source text. These hallucinations are potentially harmful, yet it remains unclear in what conditions they arise and how to mitigate their impact. In this work, we first identify internal model symptoms of hallucinations by analyzing the relative token contributions to the generation in contrastive hallucinated vs. non-hallucinated outputs generated via source perturbations. We then show that these symptoms are reliable indicators of natural hallucinations, by using them to design a lightweight hallucination detector which outperforms both model-free baselines and strong classifiers based on quality estimation or large pre-trained models on manually annotated English-Chinese and German-English translation test beds",
    "checked": true,
    "id": "3e96f3c5fc25821ad2153d6c7c71fb8be6576cb7",
    "semantic_title": "understanding and detecting hallucinations in neural machine translation via model introspection",
    "citation_count": 6,
    "authors": [
      "Weijia Xu",
      "Sweta Agrawal",
      "Eleftheria Briakou",
      "Marianna J. Martindale",
      "Marine Carpuat"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.33": {
    "title": "Visual Writing Prompts: Character-Grounded Story Generation with Curated Image Sequences",
    "volume": "main",
    "abstract": "Current work on image-based story generation suffers from the fact that the existing image sequence collections do not have coherent plots behind them. We improve visual story generation by producing a new image-grounded dataset, Visual Writing Prompts (VWP). VWP contains almost 2K selected sequences of movie shots, each including 5-10 images. The image sequences are aligned with a total of 12K stories which were collected via crowdsourcing given the image sequences and a set of grounded characters from the corresponding image sequence. Our new image sequence collection and filtering process has allowed us to obtain stories that are more coherent, diverse, and visually grounded compared to previous work. We also propose a character-based story generation model driven by coherence as a strong baseline. Evaluations show that our generated stories are more coherent, visually grounded, and diverse than stories generated with the current state-of-the-art model. Our code, image features, annotations and collected stories are available at https://vwprompt.github.io/",
    "checked": true,
    "id": "b3628b58bbed1d427182bf766cbf454b7c10a43a",
    "semantic_title": "visual writing prompts: character-grounded story generation with curated image sequences",
    "citation_count": 5,
    "authors": [
      "Xudong Hong",
      "Asad Sayeed",
      "Khushboo Mehra",
      "Vera Demberg",
      "Bernt Schiele"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.34": {
    "title": "Unleashing the True Potential of Sequence-to-Sequence Models for Sequence Tagging and Structure Parsing",
    "volume": "main",
    "abstract": "Sequence-to-Sequence (S2S) models have achieved remarkable success on various text generation tasks. However, learning complex structures with S2S models remains challenging as external neural modules and additional lexicons are often supplemented to predict non-textual outputs. We present a systematic study of S2S modeling using contained decoding on four core tasks: part-of-speech tagging, named entity recognition, constituency, and dependency parsing, to develop efficient exploitation methods costing zero extra parameters. In particular, 3 lexically diverse linearization schemas and corresponding constrained decoding methods are designed and evaluated. Experiments show that although more lexicalized schemas yield longer output sequences that require heavier training, their sequences being closer to natural language makes them easier to learn. Moreover, S2S models using our constrained decoding outperform other S2S approaches using external resources. Our best models perform better than or comparably to the state-of-the-art for all 4 tasks, lighting a promise for S2S models to generate non-sequential structures",
    "checked": true,
    "id": "2a17c170afd50830276455b297f58b0b413e68dc",
    "semantic_title": "unleashing the true potential of sequence-to-sequence models for sequence tagging and structure parsing",
    "citation_count": 0,
    "authors": [
      "Han He",
      "Jinho D. Choi"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.35": {
    "title": "Questions Are All You Need to Train a Dense Passage Retriever",
    "volume": "main",
    "abstract": "We introduce ART, a new corpus-level autoencoding approach for training dense retrieval models that does not require any labeled training data. Dense retrieval is a central challenge for open-domain tasks, such as Open QA, where state-of-the-art methods typically require large supervised datasets with custom hard-negative mining and denoising of positive examples. ART, in contrast, only requires access to unpaired inputs and outputs (e.g., questions and potential answer passages). It uses a new passage-retrieval autoencoding scheme, where (1) an input question is used to retrieve a set of evidence passages, and (2) the passages are then used to compute the probability of reconstructing the original question. Training for retrieval based on question reconstruction enables effective unsupervised learning of both passage and question encoders, which can be later incorporated into complete Open QA systems without any further finetuning. Extensive experiments demonstrate that ART obtains state-of-the-art results on multiple QA retrieval benchmarks with only generic initialization from a pre-trained language model, removing the need for labeled data and task-specific losses.1 Our code and model checkpoints are available at: https://github.com/DevSinghSachan/art",
    "checked": true,
    "id": "624b2ea0ba57ce67a4524e029ac11f748a0782fa",
    "semantic_title": "questions are all you need to train a dense passage retriever",
    "citation_count": 18,
    "authors": [
      "Devendra Singh Sachan",
      "Mike Lewis",
      "Dani Yogatama",
      "Luke Zettlemoyer",
      "Joelle Pineau",
      "Manzil Zaheer"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.36": {
    "title": "Transparency Helps Reveal When Language Models Learn Meaning",
    "volume": "main",
    "abstract": "Many current NLP systems are built from language models trained to optimize unsupervised objectives on large amounts of raw text. Under what conditions might such a procedure acquire meaning? Our systematic experiments with synthetic data reveal that, with languages where all expressions have context-independent denotations (i.e., languages with strong transparency), both autoregressive and masked language models successfully learn to emulate semantic relations between expressions. However, when denotations are changed to be context-dependent with the language otherwise unmodified, this ability degrades. Turning to natural language, our experiments with a specific phenomenon—referential opacity—add to the growing body of evidence that current language models do not represent natural language semantics well. We show this failure relates to the context-dependent nature of natural language form-meaning mappings",
    "checked": true,
    "id": "eee70790ced38b0fcf50351dbb3dcbdb582467e8",
    "semantic_title": "transparency helps reveal when language models learn meaning",
    "citation_count": 1,
    "authors": [
      "Zhaofeng Wu",
      "William Merrill",
      "Hao Peng",
      "Iz Beltagy",
      "Noah A. Smith"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.37": {
    "title": "Visual Spatial Reasoning",
    "volume": "main",
    "abstract": "Spatial relations are a basic part of human cognition. However, they are expressed in natural language in a variety of ways, and previous work has suggested that current vision-and-language models (VLMs) struggle to capture relational information. In this paper, we present Visual Spatial Reasoning (VSR), a dataset containing more than 10k natural text-image pairs with 66 types of spatial relations in English (e.g., under, in front of, facing). While using a seemingly simple annotation format, we show how the dataset includes challenging linguistic phenomena, such as varying reference frames. We demonstrate a large gap between human and model performance: The human ceiling is above 95%, while state-of-the-art models only achieve around 70%. We observe that VLMs' by-relation performances have little correlation with the number of training examples and the tested models are in general incapable of recognising relations concerning the orientations of objects.1",
    "checked": true,
    "id": "354b48677e314ef2f47512c5a81723cfd17dd05d",
    "semantic_title": "visual spatial reasoning",
    "citation_count": 29,
    "authors": [
      "Fangyu Liu",
      "Guy Emerson",
      "Nigel Collier"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.38": {
    "title": "How Much Do Language Models Copy From Their Training Data? Evaluating Linguistic Novelty in Text Generation Using RAVEN",
    "volume": "main",
    "abstract": "Current language models can generate high-quality text. Are they simply copying text they have seen before, or have they learned generalizable linguistic abstractions? To tease apart these possibilities, we introduce RAVEN, a suite of analyses for assessing the novelty of generated text, focusing on sequential structure (n-grams) and syntactic structure. We apply these analyses to four neural language models trained on English (an LSTM, a Transformer, Transformer-XL, and GPT-2). For local structure—e.g., individual dependencies—text generated with a standard sampling scheme is substantially less novel than our baseline of human-generated text from each model's test set. For larger-scale structure—e.g., overall sentence structure—model-generated text is as novel or even more novel than the human-generated baseline, but models still sometimes copy substantially, in some cases duplicating passages over 1,000 words long from the training set. We also perform extensive manual analysis, finding evidence that GPT-2 uses both compositional and analogical generalization mechanisms and showing that GPT-2's novel text is usually well-formed morphologically and syntactically but has reasonably frequent semantic issues (e.g., being self-contradictory)",
    "checked": true,
    "id": "04db9b694280134f09af5fa787a306907edba29d",
    "semantic_title": "how much do language models copy from their training data? evaluating linguistic novelty in text generation using raven",
    "citation_count": 43,
    "authors": [
      "R. Thomas McCoy",
      "Paul Smolensky",
      "Tal Linzen",
      "Jianfeng Gao",
      "Asli Celikyilmaz"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.39": {
    "title": "FRMT: A Benchmark for Few-Shot Region-Aware Machine Translation",
    "volume": "main",
    "abstract": "We present FRMT, a new dataset and evaluation benchmark for Few-shot Region-aware Machine Translation, a type of style-targeted translation. The dataset consists of professional translations from English into two regional variants each of Portuguese and Mandarin Chinese. Source documents are selected to enable detailed analysis of phenomena of interest, including lexically distinct terms and distractor terms. We explore automatic evaluation metrics for FRMT and validate their correlation with expert human evaluation across both region-matched and mismatched rating scenarios. Finally, we present a number of baseline models for this task, and offer guidelines for how researchers can train, evaluate, and compare their own models. Our dataset and evaluation code are publicly available: https://bit.ly/frmt-task",
    "checked": true,
    "id": "d70974c3fea2aed8d7fb10dcc74e3a8a8b8def68",
    "semantic_title": "frmt: a benchmark for few-shot region-aware machine translation",
    "citation_count": 5,
    "authors": [
      "Parker Riley",
      "Timothy Dozat",
      "Jan A. Botha",
      "Xavier Garcia",
      "Dan Garrette",
      "Jason Riesa",
      "Orhan Firat",
      "Noah Constant"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.40": {
    "title": "OpenFact: Factuality Enhanced Open Knowledge Extraction",
    "volume": "main",
    "abstract": "We focus on the factuality property during the extraction of an OpenIE corpus named OpenFact, which contains more than 12 million high-quality knowledge triplets. We break down the factuality property into two important aspects—expressiveness and groundedness—and we propose a comprehensive framework to handle both aspects. To enhance expressiveness, we formulate each knowledge piece in OpenFact based on a semantic frame. We also design templates, extra constraints, and adopt human efforts so that most OpenFact triplets contain enough details. For groundedness, we require the main arguments of each triplet to contain linked Wikidata1 entities. A human evaluation suggests that the OpenFact triplets are much more accurate and contain denser information compared to OPIEC-Linked (Gashteovski et al., 2019), one recent high-quality OpenIE corpus grounded to Wikidata. Further experiments on knowledge base completion and knowledge base question answering show the effectiveness of OpenFact over OPIEC-Linked as supplementary knowledge to Wikidata as the major KG",
    "checked": true,
    "id": "c15e57285a25c5fb941269bb55d91dce628c2ba1",
    "semantic_title": "openfact: factuality enhanced open knowledge extraction",
    "citation_count": 0,
    "authors": [
      "Linfeng Song",
      "Ante Wang",
      "Xiaoman Pan",
      "Hongming Zhang",
      "Dian Yu",
      "Lifeng Jin",
      "Haitao Mi",
      "Jinsong Su",
      "Yue Zhang",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.41": {
    "title": "On Graph-based Reentrancy-free Semantic Parsing",
    "volume": "main",
    "abstract": "We propose a novel graph-based approach for semantic parsing that resolves two problems observed in the literature: (1) seq2seq models fail on compositional generalization tasks; (2) previous work using phrase structure parsers cannot cover all the semantic parses observed in treebanks. We prove that both MAP inference and latent tag anchoring (required for weakly-supervised learning) are NP-hard problems. We propose two optimization algorithms based on constraint smoothing and conditional gradient to approximately solve these inference problems. Experimentally, our approach delivers state-of-the-art results on GeoQuery, Scan, and Clevr, both for i.i.d. splits and for splits that test for compositional generalization",
    "checked": true,
    "id": "b4b3d45a2498e47aae0a52014a5e7974f984e2df",
    "semantic_title": "on graph-based reentrancy-free semantic parsing",
    "citation_count": 1,
    "authors": [
      "Alban Petit",
      "Caio Corro"
    ]
  },
  "https://aclanthology.org/2023.tacl-1.42": {
    "title": "Supervised Gradual Machine Learning for Aspect-Term Sentiment Analysis",
    "volume": "main",
    "abstract": "Recent work has shown that Aspect-Term Sentiment Analysis (ATSA) can be effectively performed by Gradual Machine Learning (GML). However, the performance of the current unsupervised solution is limited by inaccurate and insufficient knowledge conveyance. In this paper, we propose a supervised GML approach for ATSA, which can effectively exploit labeled training data to improve knowledge conveyance. It leverages binary polarity relations between instances, which can be either similar or opposite, to enable supervised knowledge conveyance. Besides the explicit polarity relations indicated by discourse structures, it also separately supervises a polarity classification DNN and a binary Siamese network to extract implicit polarity relations. The proposed approach fulfills knowledge conveyance by modeling detected relations as binary features in a factor graph. Our extensive experiments on real benchmark data show that it achieves the state-of-the-art performance across all the test workloads. Our work demonstrates clearly that, in collaboration with DNN for feature extraction, GML outperforms pure DNN solutions",
    "checked": true,
    "id": "031ae5475d38367db9064b340db79a7cfaf61528",
    "semantic_title": "supervised gradual machine learning for aspect-term sentiment analysis",
    "citation_count": 1,
    "authors": [
      "Yanyan Wang",
      "Qun Chen",
      "Murtadha H.M. Ahmed",
      "Zhaoqiang Chen",
      "Jing Su",
      "Wei Pan",
      "Zhanhuai Li"
    ]
  }
}