{
  "https://openreview.net/forum?id=7YfHla7IxBJ": {
    "title": "Encoding Recurrence into Transformers",
    "volume": "oral",
    "abstract": "This paper novelly breaks down with ignorable loss an RNN layer into a sequence of simple RNNs, each of which can be further rewritten into a lightweight positional encoding matrix of a self-attention, named the Recurrence Encoding Matrix (REM). Thus, recurrent dynamics introduced by the RNN layer can be encapsulated into the positional encodings of a multihead self-attention, and this makes it possible to seamlessly incorporate these recurrent dynamics into a Transformer, leading to a new module, Self-Attention with Recurrence (RSA). The proposed module can leverage the recurrent inductive bias of REMs to achieve a better sample efficiency than its corresponding baseline Transformer, while the self-attention is used to model the remaining non-recurrent signals. The relative proportions of these two components are controlled by a data-driven gated mechanism, and the effectiveness of RSA modules are demonstrated by four sequential learning tasks",
    "checked": true,
    "id": "ccf84c100fa78c599d0e901a3754ff044aa6bd9e",
    "semantic_title": "encoding recurrence into transformers",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=l6CpxixmUg": {
    "title": "Modeling content creator incentives on algorithm-curated platforms",
    "volume": "oral",
    "abstract": "Content creators compete for user attention. Their reach crucially depends on algorithmic choices made by developers on online platforms. To maximize exposure, many creators adapt strategically, as evidenced by examples like the sprawling search engine optimization industry. This begets competition for the finite user attention pool. We formalize these dynamics in what we call an exposure game, a model of incentives induced by modern algorithms including factorization and (deep) two-tower architectures. We prove that seemingly innocuous algorithmic choices—e.g., non-negative vs. unconstrained factorization—significantly affect the existence and character of (Nash) equilibria in exposure games. We proffer use of creator behavior models like ours for an (ex-ante) pre-deployment audit. Such an audit can identify misalignment between desirable and incentivized content, and thus complement post-hoc measures like content filtering and moderation. To this end, we propose tools for numerically finding equilibria in exposure games, and illustrate results of an audit on the MovieLens and LastFM datasets. Among else, we find that the strategically produced content exhibits strong dependence between algorithmic exploration and content diversity, and between model expressivity and bias towards gender-based user and creator groups",
    "checked": true,
    "id": "740dbd216cb102c8e2816bdbb08365ecc3340525",
    "semantic_title": "modeling content creator incentives on algorithm-curated platforms",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=paGvsrl4Ntr": {
    "title": "Transfer NAS with Meta-learned Bayesian Surrogates",
    "volume": "oral",
    "abstract": "While neural architecture search (NAS) is an intensely-researched area, approaches typically still suffer from either (i) high computational costs or (ii) lack of robustness across datasets and experiments. Furthermore, most methods start searching for an optimal architecture from scratch, ignoring prior knowledge. This is in contrast to the manual design process by researchers and engineers that leverage previous deep learning experiences by, e.g., transferring architectures from previously solved, related problems. We propose to adopt this human design strategy and introduce a novel surrogate for NAS, that is meta-learned across prior architecture evaluations across different datasets. We utilizes Bayesian Optimization (BO) with deep-kernel Gaussian Processes, graph neural networks for the architecture embeddings and a transformer-based set encoder of datasets. As a result, our method consistently achieves state-of-the-art results on six computer vision datasets, while being as fast as one-shot NAS methods",
    "checked": true,
    "id": "05a4880bc44ee91b846541a330ba5aa7a874cdf0",
    "semantic_title": "transfer nas with meta-learned bayesian surrogates",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=067CGykiZTS": {
    "title": "Scaling Up Probabilistic Circuits by Latent Variable Distillation",
    "volume": "oral",
    "abstract": "Probabilistic Circuits (PCs) are a unified framework for tractable probabilistic models that support efficient computation of various probabilistic queries (e.g., marginal probabilities). One key challenge is to scale PCs to model large and high-dimensional real-world datasets: we observe that as the number of parameters in PCs increases, their performance immediately plateaus. This phenomenon suggests that the existing optimizers fail to exploit the full expressive power of large PCs. We propose to overcome such bottleneck by latent variable distillation: we leverage the less tractable but more expressive deep generative models to provide extra supervision over the latent variables of PCs. Specifically, we extract information from Transformer-based generative models to assign values to latent variables of PCs, providing guidance to PC optimizers. Experiments on both image and language modeling benchmarks (e.g., ImageNet and WikiText-2) show that latent variable distillation substantially boosts the performance of large PCs compared to their counterparts without latent variable distillation. In particular, on the image modeling benchmarks, PCs achieve competitive performance against some of the widely-used deep generative models, including variational autoencoders and flow-based models, opening up new avenues for tractable generative modeling. Our code can be found at https://github.com/UCLA-StarAI/LVD",
    "checked": true,
    "id": "af6e8ef9352ed2a82b168032c6d35655afc54f57",
    "semantic_title": "scaling up probabilistic circuits by latent variable distillation",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=6H_uOfcwiVh": {
    "title": "A Kernel Perspective of Skip Connections in Convolutional Networks",
    "volume": "oral",
    "abstract": "Over-parameterized residual networks (ResNets) are amongst the most successful convolutional neural architectures for image processing. Here we study their properties through their Gaussian Process and Neural Tangent kernels. We derive explicit formulas for these kernels, analyze their spectra, and provide bounds on their implied condition numbers. Our results indicate that (1) with ReLU activation, the eigenvalues of these residual kernels decay polynomially at a similar rate compared to the same kernels when skip connections are not used, thus maintaining a similar frequency bias; (2) however, residual kernels are more locally biased. Our analysis further shows that the matrices obtained by these residual kernels yield favorable condition numbers at finite depths than those obtained without the skip connections, enabling therefore faster convergence of training with gradient descent",
    "checked": true,
    "id": "9a3b2b0755d1a53ceaeda57e1a843912b74e6aad",
    "semantic_title": "a kernel perspective of skip connections in convolutional networks",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=vaxnu-Utr4l": {
    "title": "WikiWhy: Answering and Explaining Cause-and-Effect Questions",
    "volume": "oral",
    "abstract": "As large language models (LLMs) grow larger and more sophisticated, assessing their \"reasoning\" capabilities in natural language grows more challenging. Recent question answering (QA) benchmarks that attempt to assess reasoning are often limited by a narrow scope of covered situations and subject matters. We introduce WikiWhy, a QA dataset built around a novel auxiliary task: explaining why an answer is true in natural language. WikiWhy contains over 9,000 \"why\" question-answer-rationale triples, grounded on Wikipedia facts across a diverse set of topics. Each rationale is a set of supporting statements connecting the question to the answer. WikiWhy serves as a benchmark for the reasoning capabilities of LLMs because it demands rigorous explicit rationales for each answer to demonstrate the acquisition of implicit commonsense knowledge, which is unlikely to be easily memorized. GPT-3 baselines achieve only 38.7% human-evaluated correctness in the end-to-end answer & explain condition, leaving significant room for future improvements",
    "checked": true,
    "id": "8345d757e9127eff382d5285fef99312eaf283cd",
    "semantic_title": "wikiwhy: answering and explaining cause-and-effect questions",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=CQsmMYmlP5T": {
    "title": "Git Re-Basin: Merging Models modulo Permutation Symmetries",
    "volume": "oral",
    "abstract": "The success of deep learning is due in large part to our ability to solve certain massive non-convex optimization problems with relative ease. Though non-convex optimization is NP-hard, simple algorithms -- often variants of stochastic gradient descent -- exhibit surprising effectiveness in fitting large neural networks in practice. We argue that neural network loss landscapes often contain (nearly) a single basin after accounting for all possible permutation symmetries of hidden units a la Entezari et al. 2021. We introduce three algorithms to permute the units of one model to bring them into alignment with a reference model in order to merge the two models in weight space. This transformation produces a functionally equivalent set of weights that lie in an approximately convex basin near the reference model. Experimentally, we demonstrate the single basin phenomenon across a variety of model architectures and datasets, including the first (to our knowledge) demonstration of zero-barrier linear mode connectivity between independently trained ResNet models on CIFAR-10. Additionally, we identify intriguing phenomena relating model width and training time to mode connectivity. Finally, we discuss shortcomings of the linear mode connectivity hypothesis, including a counterexample to the single basin theory",
    "checked": true,
    "id": "a9e20180153f6c139a4b6f2791b535fa6ffc3959",
    "semantic_title": "git re-basin: merging models modulo permutation symmetries",
    "citation_count": 375,
    "authors": []
  },
  "https://openreview.net/forum?id=LQIjzPdDt3q": {
    "title": "The Role of Coverage in Online Reinforcement Learning",
    "volume": "oral",
    "abstract": "Coverage conditions---which assert that the data logging distribution adequately covers the state space---play a fundamental role in determining the sample complexity of offline reinforcement learning. While such conditions might seem irrelevant to online reinforcement learning at first glance, we establish a new connection by showing---somewhat surprisingly---that the mere existence of a data distribution with good coverage can enable sample-efficient online RL. Concretely, we show that coverability---that is, existence of a data distribution that satisfies a ubiquitous coverage condition called concentrability---can be viewed as a structural property of the underlying MDP, and can be exploited by standard algorithms for sample-efficient exploration, even when the agent does not know said distribution. We complement this result by proving that several weaker notions of coverage, despite being sufficient for offline RL, are insufficient for online RL. We also show that existing complexity measures for online RL, including Bellman rank and Bellman-Eluder dimension, fail to optimally capture coverability, and propose a new complexity measure, the self-normalized coefficient, to provide a unification",
    "checked": true,
    "id": "3d444eafdd2cd17af73cc88cdbe35e6e21795ff2",
    "semantic_title": "the role of coverage in online reinforcement learning",
    "citation_count": 61,
    "authors": []
  },
  "https://openreview.net/forum?id=FZdJQgy05rz": {
    "title": "Is the Performance of My Deep Network Too Good to Be True? A Direct Approach to Estimating the Bayes Error in Binary Classification",
    "volume": "oral",
    "abstract": "There is a fundamental limitation in the prediction performance that a machine learning model can achieve due to the inevitable uncertainty of the prediction target. In classification problems, this can be characterized by the Bayes error, which is the best achievable error with any classifier. The Bayes error can be used as a criterion to evaluate classifiers with state-of-the-art performance and can be used to detect test set overfitting. We propose a simple and direct Bayes error estimator, where we just take the mean of the labels that show \\emph{uncertainty} of the class assignments. Our flexible approach enables us to perform Bayes error estimation even for weakly supervised data. In contrast to others, our method is model-free and even instance-free. Moreover, it has no hyperparameters and gives a more accurate estimate of the Bayes error than several baselines empirically. Experiments using our method suggest that recently proposed deep networks such as the Vision Transformer may have reached, or is about to reach, the Bayes error for benchmark datasets. Finally, we discuss how we can study the inherent difficulty of the acceptance/rejection decision for scientific articles, by estimating the Bayes error of the ICLR papers from 2017 to 2023",
    "checked": true,
    "id": "0d564d688e4e25bf640adf46387f0baf31beefbb",
    "semantic_title": "is the performance of my deep network too good to be true? a direct approach to estimating the bayes error in binary classification",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=4-k7kUavAj": {
    "title": "Offline Q-learning on Diverse Multi-Task Data Both Scales And Generalizes",
    "volume": "oral",
    "abstract": "The potential of offline reinforcement learning (RL) is that high-capacity models trained on large, heterogeneous datasets can lead to agents that generalize broadly, analogously to similar advances in vision and NLP. However, recent works argue that offline RL methods encounter unique challenges to scaling up model capacity. Drawing on the learnings from these works, we re-examine previous design choices and find that with appropriate choices: ResNets, cross-entropy based distributional backups, and feature normalization, offline Q-learning algorithms exhibit strong performance that scales with model capacity. Using multi-task Atari as a testbed for scaling and generalization, we train a single policy on 40 games with near-human performance using up-to 80 million parameter networks, finding that model performance scales favorably with capacity. In contrast to prior work, we extrapolate beyond dataset performance even when trained entirely on a large (400M transitions) but highly suboptimal dataset (51% human-level performance). Compared to return-conditioned supervised approaches, offline Q-learning scales similarly with model capacity and has better performance, especially when the dataset is suboptimal. Finally, we show that offline Q-learning with a diverse dataset is sufficient to learn powerful representations that facilitate rapid transfer to novel games and fast online learning on new variations of a training game, improving over existing state-of-the-art representation learning approaches",
    "checked": true,
    "id": "9bdad7f737c1303f199384c5b65dc67da7e5c4d8",
    "semantic_title": "offline q-learning on diverse multi-task data both scales and generalizes",
    "citation_count": 62,
    "authors": []
  },
  "https://openreview.net/forum?id=0g0X4H8yN4I": {
    "title": "What learning algorithm is in-context learning? Investigations with linear models",
    "volume": "oral",
    "abstract": "Neural sequence models, especially transformers, exhibit a remarkable capacity for in-context learning. They can construct new predictors from sequences of labeled examples $(x, f(x))$ presented in the input without further parameter updates. We investigate the hypothesis that transformer-based in-context learners implement standard learning algorithms implicitly, by encoding context-specific parametric models in their hidden representations, and updating these implicit models as new examples appear in the context. Using linear regression as a model problem, we offer three sources of evidence for this hypothesis. First, we prove by construction that transformers can implement learning algorithms for linear models based on gradient descent and closed-form computation of regression parameters. Second, we show that trained in-context learners closely match the predictors computed by gradient descent, ridge regression, and exact least-squares regression, transitioning between different predictors as transformer depth and dataset noise vary. Third, we present preliminary evidence that in-context learners share algorithmic features with these predictors: learners' late layers encode weight vectors and moment matrices. These results suggest that in-context learning is understandable in algorithmic terms, and that (at least in the linear case) learners may work by rediscovering standard estimation algorithms",
    "checked": true,
    "id": "7aa801b907b59b8ee4cfb1296d9dac22c5164c5d",
    "semantic_title": "what learning algorithm is in-context learning? investigations with linear models",
    "citation_count": 547,
    "authors": []
  },
  "https://openreview.net/forum?id=Uuf2q9TfXGA": {
    "title": "Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning",
    "volume": "oral",
    "abstract": "We formally study how \\emph{ensemble} of deep learning models can improve test accuracy, and how the superior performance of ensemble can be distilled into a single model using \\emph{knowledge distillation}. We consider the challenging case where the ensemble is simply an average of the outputs of a few independently trained neural networks with the \\emph{same} architecture, trained using the \\emph{same} algorithm on the \\emph{same} data set, and they only differ by the random seeds used in the initialization. We show that ensemble/knowledge distillation in \\emph{deep learning} works very differently from traditional learning theory (such as boosting or NTKs). We develop a theory showing that when data has a structure we refer to as ``multi-view'', then ensemble of independently trained neural networks can provably improve test accuracy, and such superior test accuracy can also be provably distilled into a single model. Our result sheds light on how ensemble works in deep learning in a way that is completely different from traditional theorems, and how the ``dark knowledge'' is hidden in the outputs of the ensemble and can be used in distillation",
    "checked": false,
    "id": "d4838211d7f65628f56b9f6faab30a95ff7b51f8",
    "semantic_title": "for prediction city region re-weighting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KRLUvxh8uaX": {
    "title": "When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?",
    "volume": "oral",
    "abstract": "Despite the success of large vision and language models (VLMs) in many downstream applications, it is unclear how well they encode the compositional relationships between objects and attributes. Here, we create the Attribution, Relation, and Order (ARO) benchmark to systematically evaluate the ability of VLMs to understand different types of relationships, attributes, and order information. ARO consists of \\emph{Visual Genome Attribution}, to test the understanding of objects' properties; \\emph{Visual Genome Relation}, to test for relational understanding; and \\emph{COCO-Order \\& Flickr30k-Order}, to test for order sensitivity in VLMs. ARO is orders of magnitude larger than previous benchmarks of compositionality, with more than 50,000 test cases. We present the settings where state-of-the-art VLMs behave like bags-of-words---i.e. when they have poor relational understanding, can blunder when linking objects to their attributes, and demonstrate a severe lack of order sensitivity. VLMs are predominantly trained and evaluated on large scale datasets with rich compositional structure in the images and captions. Yet, training on these datasets has not been enough to address the lack of compositional understanding, and evaluating on these datasets has failed to surface this deficiency. To understand why these limitations emerge and are not represented in the standard tests, we zoom into the evaluation and training procedures. We demonstrate that it is possible to perform well on image-text retrieval over existing datasets without using the composition and order information. This further motivates the value of using ARO to benchmark VLMs. Given that contrastive pretraining optimizes for retrieval on large datasets with similar shortcuts, we hypothesize that this can explain why the models do not need to learn to represent compositional information. This finding suggests a natural solution: composition-aware hard negative mining. We show that a simple-to-implement modification of contrastive learning significantly improves the performance on tasks requiring understanding of order and compositionality",
    "checked": true,
    "id": "10667c1ae4b49808772b5a377c5b52196701267f",
    "semantic_title": "when and why vision-language models behave like bags-of-words, and what to do about it?",
    "citation_count": 466,
    "authors": []
  },
  "https://openreview.net/forum?id=Zeb5mTuqT5": {
    "title": "Confidence-Conditioned Value Functions for Offline Reinforcement Learning",
    "volume": "oral",
    "abstract": "Offline reinforcement learning (RL) promises the ability to learn effective policies solely using existing, static datasets, without any costly online interaction. To do so, offline RL methods must handle distributional shift between the dataset and the learned policy. The most common approach is to learn conservative, or lower-bound, value functions, which underestimate the return of OOD actions. However, such methods exhibit one notable drawback: policies optimized on such value functions can only behave according to a fixed, possibly suboptimal, degree of conservatism. However, this can be alleviated if we instead are able to learn policies for varying degrees of conservatism at training time and devise a method to dynamically choose one of them during evaluation. To do so, in this work, we propose learning value functions that additionally condition on the degree of conservatism, which we dub confidence-conditioned value functions. We derive a new form of a Bellman backup that simultaneously learns Q-values for any degree of confidence with high probability. By conditioning on confidence, our value functions enable adaptive strategies during online evaluation by controlling for confidence level using the history of observations thus far. This approach can be implemented in practice by conditioning the Q-function from existing conservative algorithms on the confidence. We theoretically show that our learned value functions produce conservative estimates of the true value at any desired confidence. Finally, we empirically show that our algorithm outperforms existing conservative offline RL algorithms on multiple discrete control domains",
    "checked": true,
    "id": "e9565e0242aed311888bf4dcc6fef06faf6fc61a",
    "semantic_title": "confidence-conditioned value functions for offline reinforcement learning",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=hJqGbUpDGV": {
    "title": "On the Sensitivity of Reward Inference to Misspecified Human Models",
    "volume": "oral",
    "abstract": "Inferring reward functions from human behavior is at the center of value alignment – aligning AI objectives with what we, humans, actually want. But doing so relies on models of how humans behave given their objectives. After decades of research in cognitive science, neuroscience, and behavioral economics, obtaining accurate human models remains an open research topic. This begs the question: how accurate do these models need to be in order for the reward inference to be accurate? On the one hand, if small errors in the model can lead to catastrophic error in inference, the entire framework of reward learning seems ill-fated, as we will never have perfect models of human behavior. On the other hand, if as our models improve, we can have a guarantee that reward accuracy also improves, this would show the benefit of more work on the modeling side. We study this question both theoretically and empirically. We do show that it is unfortunately possible to construct small adversarial biases in behavior that lead to arbitrarily large errors in the inferred reward. However, and arguably more importantly, we are also able to identify reasonable assumptions under which the reward inference error can be bounded linearly in the error in the human model. Finally, we verify our theoretical insights in discrete and continuous control tasks with simulated and human data",
    "checked": true,
    "id": "aef62643b561991d7db70ff29b009822065641d8",
    "semantic_title": "on the sensitivity of reward inference to misspecified human models",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=H3HcEJA2Um": {
    "title": "Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection",
    "volume": "oral",
    "abstract": "While recent camera-only 3D detection methods leverage multiple timesteps, the limited history they use significantly hampers the extent to which temporal fusion can improve object perception. Observing that existing works' fusion of multi-frame images are instances of temporal stereo matching, we find that performance is hindered by the interplay between 1) the low granularity of matching resolution and 2) the sub-optimal multi-view setup produced by limited history usage. Our theoretical and empirical analysis demonstrates that the optimal temporal difference between views varies significantly for different pixels and depths, making it necessary to fuse many timesteps over long-term history. Building on our investigation, we propose to generate a cost volume from a long history of image observations, compensating for the coarse but efficient matching resolution with a more optimal multi-view matching setup. Further, we augment the per-frame monocular depth predictions used for long-term, coarse matching with short-term, fine-grained matching and find that long and short term temporal fusion are highly complementary. While maintaining high efficiency, our framework sets new state-of-the-art on nuScenes, achieving first place on the test set and outperforming previous best art by 5.2% mAP and 3.7% NDS on the validation set. Code will be released here: https://github.com/Divadi/SOLOFusion",
    "checked": true,
    "id": "ebde9fbe26c8d3a04a3d159ad7d127ce2df7305c",
    "semantic_title": "time will tell: new outlooks and a baseline for temporal multi-view 3d object detection",
    "citation_count": 181,
    "authors": []
  },
  "https://openreview.net/forum?id=DEGjDDV22pI": {
    "title": "Dichotomy of Control: Separating What You Can Control from What You Cannot",
    "volume": "oral",
    "abstract": "Future- or return-conditioned supervised learning is an emerging paradigm for offline reinforcement learning (RL), in which the future outcome (i.e., return) associated with a sequence of actions in an offline dataset is used as input to a policy trained to imitate those same actions. While return-conditioning is at the heart of popular algorithms such as decision transformer (DT), these methods tend to perform poorly in highly stochastic environments, where an occasional high return associated with a sequence of actions may be due more to the randomness of the environment than to the actions themselves. Such situations can lead to a learned policy that is inconsistent with its conditioning inputs; i.e., using the policy – while conditioned on a specific desired return – to act in the environment can lead to a distribution of real returns that is wildly different than desired. In this work, we propose the dichotomy of control (DoC), a future-conditioned supervised learning framework that separates mechanisms within a policy's control (actions) from those outside of a policy's control (environment stochasticity). We achieve this by conditioning the policy on a latent variable representation of the future and designing a mutual information constraint that removes any future information from the latent variable that is only due to randomness of the environment. Theoretically, we show that DoC yields policies that are consistent with their conditioning inputs, ensuring that conditioning a learned policy on a desired high-return future outcome will correctly induce high-return behavior. Empirically, we show that DoC is able to achieve significantly better performance than DT on environments with highly stochastic rewards (e.g., Bandit) and transitions (e.g., FrozenLake)",
    "checked": true,
    "id": "834c8c95ff1129eb197bfdfa18f6bdf3c11c205c",
    "semantic_title": "dichotomy of control: separating what you can control from what you cannot",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=en9V5F8PR-": {
    "title": "Learning where and when to reason in neuro-symbolic inference",
    "volume": "oral",
    "abstract": "The integration of hard constraints on neural network outputs is a very desirable capability. This allows to instill trust in AI by guaranteeing the sanity of that neural network predictions with respect to domain knowledge. Recently, this topic has received a lot of attention. However, all the existing methods usually either impose the constraints in a \"weak\" form at training time, with no guarantees at inference, or fail to provide a general framework that supports different tasks and constraint types. We tackle this open problem from a neuro-symbolic perspective. Our pipeline enhances a conventional neural predictor with (1) a symbolic reasoning module capable of correcting structured prediction errors and (2) a neural attention module that learns to direct the reasoning effort to focus on potential prediction errors, while keeping other outputs unchanged. This framework provides an appealing trade-off between the efficiency of constraint-free neural inference and the prohibitive cost of exhaustive reasoning at inference time. We show that our method outperforms the state of the art on visual-Sudoku, and can also benefit visual scene graph prediction. Furthermore, it can improve the performance of existing neuro-symbolic systems that lack our explicit reasoning during inference",
    "checked": true,
    "id": "2e48527e9ea8d8fe02050af2c355d010a990d5be",
    "semantic_title": "learning where and when to reason in neuro-symbolic inference",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=kDEL91Dufpa": {
    "title": "On the duality between contrastive and non-contrastive self-supervised learning",
    "volume": "oral",
    "abstract": "Recent approaches in self-supervised learning of image representations can be categorized into different families of methods and, in particular, can be divided into contrastive and non-contrastive approaches. While differences between the two families have been thoroughly discussed to motivate new approaches, we focus more on the theoretical similarities between them. By designing contrastive and covariance based non-contrastive criteria that can be related algebraically and shown to be equivalent under limited assumptions, we show how close those families can be. We further study popular methods and introduce variations of them, allowing us to relate this theoretical result to current practices and show the influence (or lack thereof) of design choices on downstream performance. Motivated by our equivalence result, we investigate the low performance of SimCLR and show how it can match VICReg's with careful hyperparameter tuning, improving significantly over known baselines. We also challenge the popular assumption that non-contrastive methods need large output dimensions. Our theoretical and quantitative results suggest that the numerical gaps between contrastive and non-contrastive methods in certain regimes can be closed given better network design choices and hyperparameter tuning. The evidence shows that unifying different SOTA methods is an important direction to build a better understanding of self-supervised learning",
    "checked": true,
    "id": "11c16254f7b61687b5d9b7637de032461a6ebb5f",
    "semantic_title": "on the duality between contrastive and non-contrastive self-supervised learning",
    "citation_count": 99,
    "authors": []
  },
  "https://openreview.net/forum?id=FjNys5c7VyY": {
    "title": "DreamFusion: Text-to-3D using 2D Diffusion",
    "volume": "oral",
    "abstract": "Recent breakthroughs in text-to-image synthesis have been driven by diffusion models trained on billions of image-text pairs. Adapting this approach to 3D synthesis would require large-scale datasets of labeled 3D or multiview data and efficient architectures for denoising 3D data, neither of which currently exist. In this work, we circumvent these limitations by using a pretrained 2D text-to-image diffusion model to perform text-to-3D synthesis. We introduce a loss based on probability density distillation that enables the use of a 2D diffusion model as a prior for optimization of a parametric image generator. Using this loss in a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or NeRF) via gradient descent such that its 2D renderings from random angles achieve a low loss. The resulting 3D model of the given text can be viewed from any angle, relit by arbitrary illumination, or composited into any 3D environment. Our approach requires no 3D training data and no modifications to the image diffusion model, demonstrating the effectiveness of pretrained image diffusion models as priors",
    "checked": true,
    "id": "4c94d04afa4309ec2f06bdd0fe3781f91461b362",
    "semantic_title": "dreamfusion: text-to-3d using 2d diffusion",
    "citation_count": 2784,
    "authors": []
  },
  "https://openreview.net/forum?id=zyLVMgsZ0U_": {
    "title": "Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions",
    "volume": "oral",
    "abstract": "We provide theoretical convergence guarantees for score-based generative models (SGMs) such as denoising diffusion probabilistic models (DDPMs), which constitute the backbone of large-scale real-world generative models such as DALL$\\cdot$E 2. Our main result is that, assuming accurate score estimates, such SGMs can efficiently sample from essentially any realistic data distribution. In contrast to prior works, our results (1) hold for an $L^2$-accurate score estimate (rather than $L^\\infty$-accurate); (2) do not require restrictive functional inequality conditions that preclude substantial non-log-concavity; (3) scale polynomially in all relevant problem parameters; and (4) match state-of-the-art complexity guarantees for discretization of the Langevin diffusion, provided that the score error is sufficiently small. We view this as strong theoretical justification for the empirical success of SGMs. We also examine SGMs based on the critically damped Langevin diffusion (CLD). Contrary to conventional wisdom, we provide evidence that the use of the CLD does *not* reduce the complexity of SGMs",
    "checked": true,
    "id": "7309bf7607f4b4339f4ae288f3ad4fc36d139b5a",
    "semantic_title": "sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions",
    "citation_count": 323,
    "authors": []
  },
  "https://openreview.net/forum?id=88nT0j5jAn": {
    "title": "Universal Few-shot Learning of Dense Prediction Tasks with Visual Token Matching",
    "volume": "oral",
    "abstract": "Dense prediction tasks are a fundamental class of problems in computer vision. As supervised methods suffer from high pixel-wise labeling cost, a few-shot learning solution that can learn any dense task from a few labeled images is desired. Yet, current few-shot learning methods target a restricted set of tasks such as semantic segmentation, presumably due to challenges in designing a general and unified model that is able to flexibly and efficiently adapt to arbitrary tasks of unseen semantics. We propose Visual Token Matching (VTM), a universal few-shot learner for arbitrary dense prediction tasks. It employs non-parametric matching on patch-level embedded tokens of images and labels that encapsulates all tasks. Also, VTM flexibly adapts to any task with a tiny amount of task-specific parameters that modulate the matching algorithm. We implement VTM as a powerful hierarchical encoder-decoder architecture involving ViT backbones where token matching is performed at multiple feature hierarchies. We experiment VTM on a challenging variant of Taskonomy dataset and observe that it robustly few-shot learns various unseen dense prediction tasks. Surprisingly, it is competitive with fully supervised baselines using only 10 labeled examples of novel tasks ($0.004\\%$ of full supervision) and sometimes outperforms using $0.1\\%$ of full supervision. Codes are available at https://github.com/GitGyun/visual_token_matching",
    "checked": true,
    "id": "f17119316ada03dd7f05511457c4a15c69f7e866",
    "semantic_title": "universal few-shot learning of dense prediction tasks with visual token matching",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=dLAYGdKTi2": {
    "title": "Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach",
    "volume": "oral",
    "abstract": "Many machine learning problems today have multiple objective functions. They appear either in learning with multiple criteria where learning has to make a trade-off between multiple performance metrics such as fairness, safety and accuracy; or, in multi-task learning where multiple tasks are optimized jointly, sharing inductive bias between them. This problems are often tackled by the multi-objective optimization framework. However, existing stochastic multi-objective gradient methods and its variants (e.g., MGDA, PCGrad, CAGrad, etc.) all adopt a biased noisy gradient direction, which leads to degraded empirical performance. To this end, we develop a stochastic multi-objective gradient correction (MoCo) method for multi-objective optimization. The unique feature of our method is that it can guarantee convergence without increasing the batch size even in the nonconvex setting. Simulations on multi-task supervised and reinforcement learning demonstrate the effectiveness of our method relative to the state-of-the-art methods",
    "checked": true,
    "id": "3b1dcf6d1a0e3b37641d751471bef5398f2ee3ac",
    "semantic_title": "mitigating gradient bias in multi-objective learning: a provably convergent approach",
    "citation_count": 50,
    "authors": []
  },
  "https://openreview.net/forum?id=WE_vluYUL-X": {
    "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "volume": "oral",
    "abstract": "While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples",
    "checked": true,
    "id": "99832586d55f540f603637e458a292406a0ed75d",
    "semantic_title": "react: synergizing reasoning and acting in language models",
    "citation_count": 3973,
    "authors": []
  },
  "https://openreview.net/forum?id=ayPPc0SyLv1": {
    "title": "Do We Really Need Complicated Model Architectures For Temporal Networks?",
    "volume": "oral",
    "abstract": "Recurrent neural network (RNN) and self-attention mechanism (SAM) are the de facto methods to extract spatial-temporal information for temporal graph learning. Interestingly, we found that although both RNN and SAM could lead to a good performance, in practice neither of them is always necessary. In this paper, we propose GraphMixer, a conceptually and technically simple architecture that consists of three components: (1) a link-encoder that is only based on multi-layer perceptrons (MLP) to summarize the information from temporal links, (2) a node-encoder that is only based on neighbor mean-pooling to summarize node information, and (3) an MLP-based link classifier that performs link prediction based on the outputs of the encoders. Despite its simplicity, GraphMixer attains an outstanding performance on temporal link prediction benchmarks with faster convergence and better generalization performance. These results motivate us to rethink the importance of simpler model architecture",
    "checked": true,
    "id": "ed23b5871365c873f3958210f2accce353c20db6",
    "semantic_title": "do we really need complicated model architectures for temporal networks?",
    "citation_count": 136,
    "authors": []
  },
  "https://openreview.net/forum?id=sP1fo2K9DFG": {
    "title": "Is Conditional Generative Modeling all you need for Decision Making?",
    "volume": "oral",
    "abstract": "Recent improvements in conditional generative modeling have made it possible to generate high-quality images from language descriptions alone. We investigate whether these methods can directly address the problem of sequential decision-making. We view decision-making not through the lens of reinforcement learning (RL), but rather through conditional generative modeling. To our surprise, we find that our formulation leads to policies that can outperform existing offline RL approaches across standard benchmarks. By modeling a policy as a return-conditional generative model, we avoid the need for dynamic programming and subsequently eliminate many of the complexities that come with traditional offline RL. We further demonstrate the advantages of modeling policies as conditional generative models by considering two other conditioning variables: constraints and skills. Conditioning on a single constraint or skill during training leads to behaviors at test-time that can satisfy several constraints together or demonstrate a composition of skills. Our results illustrate that conditional generative modeling is a powerful tool for decision-making",
    "checked": false,
    "id": "f19dfc360088922cf1d423c538662aae8d542c28",
    "semantic_title": "is conditional generative modeling all you need for decision-making?",
    "citation_count": 464,
    "authors": []
  },
  "https://openreview.net/forum?id=JL7Va5Vy15J": {
    "title": "The Lie Derivative for Measuring Learned Equivariance",
    "volume": "oral",
    "abstract": "Equivariance guarantees that a model's predictions capture key symmetries in data. When an image is translated or rotated, an equivariant model's representation of that image will translate or rotate accordingly. The success of convolutional neural networks has historically been tied to translation equivariance directly encoded in their architecture. The rising success of vision transformers, which have no explicit architectural bias towards equivariance, challenges this narrative and suggests that augmentations and training data might also play a significant role in their performance. In order to better understand the role of equivariance in recent vision models, we apply the Lie derivative, a method for measuring equivariance with strong mathematical foundations and minimal hyperparameters. Using the Lie derivative, we study the equivariance properties of hundreds of pretrained models, spanning CNNs, transformers, and Mixer architectures. The scale of our analysis allows us to separate the impact of architecture from other factors like model size or training method. Surprisingly, we find that many violations of equivariance can be linked to spatial aliasing in ubiquitous network layers, such as pointwise non-linearities, and that as models get larger and more accurate they tend to display more equivariance, regardless of architecture. For example, transformers can be more equivariant than convolutional neural networks after training",
    "checked": true,
    "id": "4721210fb0359d43edcea934d0ecb21aa9d9e98e",
    "semantic_title": "the lie derivative for measuring learned equivariance",
    "citation_count": 46,
    "authors": []
  },
  "https://openreview.net/forum?id=K7CbYQbyYhY": {
    "title": "Agree to Disagree: Diversity through Disagreement for Better Transferability",
    "volume": "oral",
    "abstract": "Gradient-based learning algorithms have an implicit \\emph{simplicity bias} which in effect can limit the diversity of predictors being sampled by the learning procedure. This behavior can hinder the transferability of trained models by (i) favoring the learning of simpler but spurious features --- present in the training data but absent from the test data --- and (ii) by only leveraging a small subset of predictive features. Such an effect is especially magnified when the test distribution does not exactly match the train distribution---referred to as the Out of Distribution (OOD) generalization problem. However, given only the training data, it is not always possible to apriori assess if a given feature is spurious or transferable. Instead, we advocate for learning an ensemble of models which capture a diverse set of predictive features. Towards this, we propose a new algorithm D-BAT (Diversity-By-disAgreement Training), which enforces agreement among the models on the training data, but disagreement on the OOD data. We show how D-BAT naturally emerges from the notion of generalized discrepancy, as well as demonstrate in multiple experiments how the proposed method can mitigate shortcut-learning, enhance uncertainty and OOD detection, as well as improve transferability",
    "checked": true,
    "id": "962466ca8a3bf432a2d45b656ab5dbcc9caf5b16",
    "semantic_title": "agree to disagree: diversity through disagreement for better transferability",
    "citation_count": 78,
    "authors": []
  },
  "https://openreview.net/forum?id=dJruFeSRym1": {
    "title": "Efficient Conditionally Invariant Representation Learning",
    "volume": "oral",
    "abstract": "We introduce the Conditional Independence Regression CovariancE (CIRCE), a measure of conditional independence for multivariate continuous-valued variables. CIRCE applies as a regularizer in settings where we wish to learn neural features $\\varphi(X)$ of data $X$ to estimate a target $Y$, while being conditionally independent of a distractor $Z$ given $Y$. Both $Z$ and $Y$ are assumed to be continuous-valued but relatively low dimensional, whereas $X$ and its features may be complex and high dimensional. Relevant settings include domain-invariant learning, fairness, and causal learning. The procedure requires just a single ridge regression from $Y$ to kernelized features of $Z$, which can be done in advance. It is then only necessary to enforce independence of $\\varphi(X)$ from residuals of this regression, which is possible with attractive estimation properties and consistency guarantees. By contrast, earlier measures of conditional feature dependence require multiple regressions for each step of feature learning, resulting in more severe bias and variance, and greater computational cost. When sufficiently rich features are used, we establish that CIRCE is zero if and only if $\\varphi(X) \\perp \\!\\!\\! \\perp Z \\mid Y$. In experiments, we show superior performance to previous methods on challenging benchmarks, including learning conditionally invariant image features. Code for image data experiments is available at github.com/namratadeka/circe",
    "checked": true,
    "id": "422b68799bfc5cae91febc5c33d59e28b067a368",
    "semantic_title": "efficient conditionally invariant representation learning",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=SMYdcXjJh1q": {
    "title": "Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness",
    "volume": "oral",
    "abstract": "While some state-of-the-art artificial neural network systems in computer vision are strikingly accurate models of the corresponding primate visual processing, there are still many discrepancies between these models and the behavior of primates on object recognition tasks. Many current models suffer from extreme sensitivity to adversarial attacks and often do not align well with the image-by-image behavioral error patterns observed in humans. Previous research has provided strong evidence that primate object recognition behavior can be very accurately predicted by neural population activity in the inferior temporal (IT) cortex, a brain area in the late stages of the visual processing hierarchy. Therefore, here we directly test whether making the late stage representations of models more similar to that of macaque IT produces new models that exhibit more robust, primate-like behavior. We conducted chronic, large-scale multi-electrode recordings across the IT cortex in six non-human primates (rhesus macaques). We then use these data to fine-tune (end-to-end) the model \"IT\" representations such that they are more aligned with the biological IT representations, while preserving accuracy on object recognition tasks. We generate a cohort of models with a range of IT similarity scores validated on held-out animals across two image sets with distinct statistics. Across a battery of optimization conditions, we observed a strong correlation between the models' IT-likeness and alignment with human behavior, as well as an increase in its adversarial robustness. We further assessed the limitations of this approach and find that the improvements in behavioral alignment and adversarial robustness generalize across different image statistics, but not to object categories outside of those covered in our IT training set. Taken together, our results demonstrate that building models that are more aligned with the primate brain leads to more robust and human-like behavior, and call for larger neural data-sets to further augment these gains",
    "checked": true,
    "id": "4ce6d229d5f44239c948fd56ad744c012aae22e0",
    "semantic_title": "aligning model and macaque inferior temporal cortex representations improves model-to-human behavioral alignment and adversarial robustness",
    "citation_count": 45,
    "authors": []
  },
  "https://openreview.net/forum?id=De4FYqjFueZ": {
    "title": "Transformers Learn Shortcuts to Automata",
    "volume": "oral",
    "abstract": "Algorithmic reasoning requires capabilities which are most naturally understood through recurrent models of computation, like the Turing machine. However, Transformer models, while lacking recurrence, are able to perform such reasoning using far fewer layers than the number of reasoning steps. This raises the question: what solutions are these shallow and non-recurrent models finding? We investigate this question in the setting of learning automata, discrete dynamical systems naturally suited to recurrent modeling and expressing algorithmic tasks. Our theoretical results completely characterize shortcut solutions, whereby a shallow Transformer with only $o(T)$ layers can exactly replicate the computation of an automaton on an input sequence of length $T$. By representing automata using the algebraic structure of their underlying transformation semigroups, we obtain $O(\\log T)$-depth simulators for all automata and $O(1)$-depth simulators for all automata whose associated groups are solvable. Empirically, we perform synthetic experiments by training Transformers to simulate a wide variety of automata, and show that shortcut solutions can be learned via standard training. We further investigate the brittleness of these solutions and propose potential mitigations",
    "checked": true,
    "id": "e82e3f4347674b75c432cb80604d38ee630d4bf6",
    "semantic_title": "transformers learn shortcuts to automata",
    "citation_count": 206,
    "authors": []
  },
  "https://openreview.net/forum?id=hy0a5MMPUv": {
    "title": "In-context Reinforcement Learning with Algorithm Distillation",
    "volume": "oral",
    "abstract": "We propose Algorithm Distillation (AD), a method for distilling reinforcement learning (RL) algorithms into neural networks by modeling their training histories with a causal sequence model. Algorithm Distillation treats learning to reinforcement learn as an across-episode sequential prediction problem. A dataset of learning histories is generated by a source RL algorithm, and then a causal transformer is trained by autoregressively predicting actions given their preceding learning histories as context. Unlike sequential policy prediction architectures that distill post-learning or expert sequences, AD is able to improve its policy entirely in-context without updating its network parameters. We demonstrate that AD can reinforcement learn in-context in a variety of environments with sparse rewards, combinatorial task structure, and pixel-based observations, and find that AD learns a more data-efficient RL algorithm than the one that generated the source data",
    "checked": true,
    "id": "860bc4f071f35d6d8529a52c2c1858d030779a6a",
    "semantic_title": "in-context reinforcement learning with algorithm distillation",
    "citation_count": 156,
    "authors": []
  },
  "https://openreview.net/forum?id=3Pf3Wg6o-A4": {
    "title": "Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning",
    "volume": "oral",
    "abstract": "Large language models (LLMs) have been shown to be capable of impressive few-shot generalisation to new tasks. However, they still tend to perform poorly on multi-step logical reasoning problems. Here we carry out a comprehensive evaluation of LLMs on 46 tasks that probe different aspects of logical reasoning. We show that language models tend to perform fairly well at single step inference or entailment tasks, but struggle to chain together multiple reasoning steps to solve more complex problems. In light of this, we propose a Selection-Inference (SI) framework that exploits pre-trained LLMs as general processing modules, and alternates between selection and inference to generate a series of interpretable, casual reasoning steps leading to the final answer. We show that a 7B parameter LLM used within the SI framework in a 5-shot generalisation setting, with no fine-tuning, yields a performance improvement of over 100% compared to an equivalent vanilla baseline on a suite of 10 logical reasoning tasks. The same model in the same setting even outperforms a significantly larger 280B parameter baseline on the same suite of tasks. Moreover, answers produced by the SI framework are accompanied by a causal natural-language-based reasoning trace, which has important implications for the safety and trustworthiness of the system",
    "checked": true,
    "id": "d48b29889241551e1ee6622fa78c3fa4159255dd",
    "semantic_title": "selection-inference: exploiting large language models for interpretable logical reasoning",
    "citation_count": 387,
    "authors": []
  },
  "https://openreview.net/forum?id=Y5SEe3dfniJ": {
    "title": "Compressing multidimensional weather and climate data into neural networks",
    "volume": "oral",
    "abstract": "Weather and climate simulations produce petabytes of high-resolution data that are later analyzed by researchers in order to understand climate change or severe weather. We propose a new method of compressing this multidimensional weather and climate data: a coordinate-based neural network is trained to overfit the data, and the resulting parameters are taken as a compact representation of the original grid-based data. While compression ratios range from 300x to more than 3,000x, our method outperforms the state-of-the-art compressor SZ3 in terms of weighted RMSE, MAE. It can faithfully preserve important large scale atmosphere structures and does not introduce significant artifacts. When using the resulting neural network as a 790x compressed dataloader to train the WeatherBench forecasting model, its RMSE increases by less than 2%. The three orders of magnitude compression democratizes access to high-resolution climate data and enables numerous new research directions",
    "checked": true,
    "id": "21ae428fe2742641f4af6c46e805ce359203d836",
    "semantic_title": "compressing multidimensional weather and climate data into neural networks",
    "citation_count": 38,
    "authors": []
  },
  "https://openreview.net/forum?id=iIfDQVyuFD": {
    "title": "Confidential-PROFITT: Confidential PROof of FaIr Training of Trees",
    "volume": "oral",
    "abstract": "Post hoc auditing of model fairness suffers from potential drawbacks: (1) auditing may be highly sensitive to the test samples chosen; (2) the model and/or its training data may need to be shared with an auditor thereby breaking confidentiality. We address these issues by instead providing a certificate that demonstrates that the learning algorithm itself is fair, and hence, as a consequence, so too is the trained model. We introduce a method to provide a confidential proof of fairness for training, in the context of widely used decision trees, which we term Confidential-PROFITT. We propose novel fair decision tree learning algorithms along with customized zero-knowledge proof protocols to obtain a proof of fairness that can be audited by a third party. Using zero-knowledge proofs enables us to guarantee confidentiality of both the model and its training data. We show empirically that bounding the information gain of each node with respect to the sensitive attributes reduces the unfairness of the final tree. In extensive experiments on the COMPAS, Communities and Crime, Default Credit, and Adult datasets, we demonstrate that a company can use Confidential-PROFITT to certify the fairness of their decision tree to an auditor in less than 2 minutes, thus indicating the applicability of our approach. This is true for both the demographic parity and equalized odds definitions of fairness. Finally, we extend Confidential-PROFITT to apply to ensembles of trees",
    "checked": true,
    "id": "283cefcba35b032b7286be90ea892700e201b0dc",
    "semantic_title": "confidential-profitt: confidential proof of fair training of trees",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=Nc1ZkRW8Vde": {
    "title": "Near-optimal Coresets for Robust Clustering",
    "volume": "oral",
    "abstract": "We consider robust clustering problems in $\\mathbb{R}^d$, specifically $k$-clustering problems (e.g., $k$-Median and $k$-Means) with $m$ \\emph{outliers}, where the cost for a given center set $C \\subset \\mathbb{R}^d$ aggregates the distances from $C$ to all but the furthest $m$ data points, instead of all points as in classical clustering. We focus on the $\\epsilon$-coreset for robust clustering, a small proxy of the dataset that preserves the clustering cost within $\\epsilon$-relative error for all center sets. Our main result is an $\\epsilon$-coreset of size $O(m + \\mathrm{poly}(k \\epsilon^{-1}))$ that can be constructed in near-linear time. This significantly improves previous results, which either suffers an exponential dependence on $(m + k)$ [Feldman and Schulman, SODA'12], or has a weaker bi-criteria guarantee [Huang et al., FOCS'18]. Furthermore, we show this dependence in $m$ is nearly-optimal, and the fact that it is isolated from other factors may be crucial for dealing with large number of outliers. We construct our coresets by adapting to the outlier setting a recent framework [Braverman et al., FOCS'22] which was designed for capacity-constrained clustering, overcoming a new challenge that the participating terms in the cost, particularly the excluded $m$ outlier points, are dependent on the center set $C$. We validate our coresets on various datasets, and we observe a superior size-accuracy tradeoff compared with popular baselines including uniform sampling and sensitivity sampling. We also achieve a significant speedup of existing approximation algorithms for robust clustering using our coresets",
    "checked": true,
    "id": "0aec562c8cc3d1004ea86f601b6b42734454466b",
    "semantic_title": "near-optimal coresets for robust clustering",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=0Ij9_q567Ma": {
    "title": "Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives",
    "volume": "oral",
    "abstract": "Motivated by various practical applications, we propose a novel and general formulation of targeted multi-objective hyperparameter optimization. Our formulation allows a clear specification of an automatable optimization goal using lexicographic preference over multiple objectives. We then propose a randomized directed search method named LexiFlow to solve this problem. We demonstrate the strong empirical performance of the proposed algorithm in multiple hyperparameter optimization tasks",
    "checked": true,
    "id": "c90b845f86dd8389d971a176184e6ad6b00ad7b8",
    "semantic_title": "targeted hyperparameter optimization with lexicographic preferences over multiple objectives",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=F61FwJTZhb": {
    "title": "Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning",
    "volume": "oral",
    "abstract": "No-press Diplomacy is a complex strategy game involving both cooperation and competition that has served as a benchmark for multi-agent AI research. While self-play reinforcement learning has resulted in numerous successes in purely adversarial games like chess, Go, and poker, self-play alone is insufficient for achieving optimal performance in domains involving cooperation with humans. We address this shortcoming by first introducing a planning algorithm we call DiL-piKL that regularizes a reward-maximizing policy toward a human imitation-learned policy. We prove that this is a no-regret learning algorithm under a modified utility function. We then show that DiL-piKL can be extended into a self-play reinforcement learning algorithm we call RL-DiL-piKL that provides a model of human play while simultaneously training an agent that responds well to this human model. We used RL-DiL-piKL to train an agent we name Diplodocus. In a 200-game no-press Diplomacy tournament involving 62 human participants spanning skill levels from beginner to expert, two Diplodocus agents both achieved a higher average score than all other participants who played more than two games, and ranked first and third according to an Elo ratings model",
    "checked": true,
    "id": "7842368bf1afde87deb63333871760ae848f01f9",
    "semantic_title": "mastering the game of no-press diplomacy via human-regularized reinforcement learning and planning",
    "citation_count": 50,
    "authors": []
  },
  "https://openreview.net/forum?id=G-uNfHKrj46": {
    "title": "Efficient Attention via Control Variates",
    "volume": "oral",
    "abstract": "Random-feature-based attention (RFA) is an efficient approximation of softmax attention with linear runtime and space complexity. However, the approximation gap between RFA and conventional softmax attention is not well studied. Built upon previous progress of RFA, we characterize this gap through the lens of control variates and show that RFA can be decomposed into a sum of multiple control variate estimators for each element in the sequence. This new framework reveals that exact softmax attention can be recovered from RFA by manipulating each control variate. Besides, it allows us to develop a more flexible form of control variates, resulting in a novel attention mechanism that significantly reduces the approximation gap while maintaining linear complexity. Extensive experiments demonstrate that our model outperforms state-of-the-art efficient attention mechanisms on both vision and language tasks",
    "checked": true,
    "id": "ac608a4a6b19b3208e560eee5daadb3cc18638a2",
    "semantic_title": "efficient attention via control variates",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=k4fevFqSQcX": {
    "title": "SAM as an Optimal Relaxation of Bayes",
    "volume": "oral",
    "abstract": "Sharpness-aware minimization (SAM) and related adversarial deep-learning methods can drastically improve generalization, but their underlying mechanisms are not yet fully understood. Here, we establish SAM as a relaxation of the Bayes objective where the expected negative-loss is replaced by the optimal convex lower bound, obtained by using the so-called Fenchel biconjugate. The connection enables a new Adam-like extension of SAM to automatically obtain reasonable uncertainty estimates, while sometimes also improving its accuracy. By connecting adversarial and Bayesian methods, our work opens a new path to robustness",
    "checked": true,
    "id": "a872902f3e216419fc16b3702d4669ee1c03c9a0",
    "semantic_title": "sam as an optimal relaxation of bayes",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=q0nmYciuuZN": {
    "title": "Learning on Large-scale Text-attributed Graphs via Variational Inference",
    "volume": "oral",
    "abstract": "This paper studies learning on text-attributed graphs (TAGs), where each node is associated with a text description. An ideal solution for such a problem would be integrating both the text and graph structure information with large language models and graph neural networks (GNNs). However, the problem becomes very challenging when graphs are large due to the high computational complexity brought by training large language models and GNNs together. In this paper, we propose an efficient and effective solution to learning on large text-attributed graphs by fusing graph structure and language learning with a variational Expectation-Maximization (EM) framework, called GLEM. Instead of simultaneously training large language models and GNNs on big graphs, GLEM proposes to alternatively update the two modules in the E-step and M-step. Such a procedure allows training the two modules separately while simultaneously allowing the two modules to interact and mutually enhance each other. Extensive experiments on multiple data sets demonstrate the efficiency and effectiveness of the proposed approach",
    "checked": true,
    "id": "8bb37e8ae7dd6fa8cab2407f63a61f697152717f",
    "semantic_title": "learning on large-scale text-attributed graphs via variational inference",
    "citation_count": 158,
    "authors": []
  },
  "https://openreview.net/forum?id=SJ0Lde3tRL": {
    "title": "Extreme Q-Learning: MaxEnt RL without Entropy",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "2c2180fbe7f38e88b1123e5fab43785b66814e5d",
    "semantic_title": "extreme q-learning: maxent rl without entropy",
    "citation_count": 89,
    "authors": []
  },
  "https://openreview.net/forum?id=mjzm6btqgV": {
    "title": "Efficiently Computing Nash Equilibria in Adversarial Team Markov Games",
    "volume": "oral",
    "abstract": "Computing Nash equilibrium policies is a central problem in multi-agent reinforcement learning that has received extensive attention both in theory and in practice. However, in light of computational intractability barriers in general-sum games, provable guarantees have been thus far either limited to fully competitive or cooperative scenarios or impose strong assumptions that are difficult to meet in most practical applications. In this work, we depart from those prior results by investigating infinite-horizon \\emph{adversarial team Markov games}, a natural and well-motivated class of games in which a team of identically-interested players---in the absence of any explicit coordination or communication---is competing against an adversarial player. This setting allows for a unifying treatment of zero-sum Markov games and Markov potential games, and serves as a step to model more realistic strategic interactions that feature both competing and cooperative interests. Our main contribution is the first algorithm for computing stationary $\\epsilon$-approximate Nash equilibria in adversarial team Markov games with computational complexity that is polynomial in all the natural parameters of the game, as well as $1/\\epsilon$. The proposed algorithm is based on performing independent policy gradient steps for each player in the team, in tandem with best responses from the side of the adversary; in turn, the policy for the adversary is then obtained by solving a carefully constructed linear program. Our analysis leverages non-standard techniques to establish the KKT optimality conditions for a nonlinear program with nonconvex constraints, thereby leading to a natural interpretation of the induced Lagrange multipliers",
    "checked": true,
    "id": "7ba026ef54575acf209b381cee4cfe2ad5646eb2",
    "semantic_title": "efficiently computing nash equilibria in adversarial team markov games",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=Ai8Hw3AXqks": {
    "title": "Simplified State Space Layers for Sequence Modeling",
    "volume": "oral",
    "abstract": "Models using structured state space sequence (S4) layers have achieved state-of-the-art performance on long-range sequence modeling tasks. An S4 layer combines linear state space models (SSMs), the HiPPO framework, and deep learning to achieve high performance. We build on the design of the S4 layer and introduce a new state space layer, the S5 layer. Whereas an S4 layer uses many independent single-input, single-output SSMs, the S5 layer uses one multi-input, multi-output SSM. We establish a connection between S5 and S4, and use this to develop the initialization and parameterization used by the S5 model. The result is a state space layer that can leverage efficient and widely implemented parallel scans, allowing S5 to match the computational efficiency of S4, while also achieving state-of-the-art performance on several long-range sequence modeling tasks. S5 averages $87.4\\%$ on the long range arena benchmark, and $98.5\\%$ on the most difficult Path-X task",
    "checked": true,
    "id": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74",
    "semantic_title": "simplified state space layers for sequence modeling",
    "citation_count": 682,
    "authors": []
  },
  "https://openreview.net/forum?id=vmjctNUSWI": {
    "title": "Moving Forward by Moving Backward: Embedding Action Impact over Action Semantics",
    "volume": "oral",
    "abstract": "A common assumption when training embodied agents is that the impact of taking an action is stable; for instance, executing the ``move ahead'' action will always move the agent forward by a fixed distance, perhaps with some small amount of actuator-induced noise. This assumption is limiting; an agent may encounter settings that dramatically alter the impact of actions: a move ahead action on a wet floor may send the agent twice as far as it expects and using the same action with a broken wheel might transform the expected translation into a rotation. Instead of relying that the impact of an action stably reflects its pre-defined semantic meaning, we propose to model the impact of actions on-the-fly using latent embeddings. By combining these latent action embeddings with a novel, transformer-based, policy head, we design an Action Adaptive Policy (AAP). We evaluate our AAP on two challenging visual navigation tasks in the AI2-THOR and Habitat environments and show that our AAP is highly performant even when faced, at inference-time, with missing actions and, previously unseen, perturbed action spaces. Moreover, we observe significant improvement in robustness against these actions when evaluating in real-world scenarios",
    "checked": true,
    "id": "cecd400cb0bdd14aa4b2568015b197d6862ede63",
    "semantic_title": "moving forward by moving backward: embedding action impact over action semantics",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=EKpMeEV0hOo": {
    "title": "SimPer: Simple Self-Supervised Learning of Periodic Targets",
    "volume": "oral",
    "abstract": "From human physiology to environmental evolution, important processes in nature often exhibit meaningful and strong periodic or quasi-periodic changes. Due to their inherent label scarcity, learning useful representations for periodic tasks with limited or no supervision is of great benefit. Yet, existing self-supervised learning (SSL) methods overlook the intrinsic periodicity in data, and fail to learn representations that capture periodic or frequency attributes. In this paper, we present SimPer, a simple contrastive SSL regime for learning periodic information in data. To exploit the periodic inductive bias, SimPer introduces customized augmentations, feature similarity measures, and a generalized contrastive loss for learning efficient and robust periodic representations. Extensive experiments on common real-world tasks in human behavior analysis, environmental sensing, and healthcare domains verify the superior performance of SimPer compared to state-of-the-art SSL methods, highlighting its intriguing properties including better data efficiency, robustness to spurious correlations, and generalization to distribution shifts",
    "checked": true,
    "id": "c0d116bea6af35c0cf1f9180a754b44512bd1cda",
    "semantic_title": "simper: simple self-supervised learning of periodic targets",
    "citation_count": 50,
    "authors": []
  },
  "https://openreview.net/forum?id=mWVoBz4W0u": {
    "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model",
    "volume": "oral",
    "abstract": "Effective scaling and a flexible task interface enable large language models to excel at many tasks. We present PaLI, a model that extends this approach to the joint modeling of language and vision. PaLI generates text based on visual and textual inputs, and with this interface performs many vision, language, and multimodal tasks, in many languages. To train PaLI, we make use of large pretrained encoder-decoder language models and Vision Transformers (ViTs). This allows us to capitalize on their existing capabilities and leverage the substantial cost of training them. We find that joint scaling of the vision and language components is important. Since existing Transformers for language are much larger than their vision counterparts, we train a large, 4-billion parameter ViT (ViT-e) to quantify the benefits from even larger-capacity vision models. To train PaLI, we create a large multilingual mix of pretraining tasks, based on a new image-text training set containing 10B images and texts in over 100 languages. PaLI achieves state-of-the-art in multiple vision and language tasks (such as captioning, visual question-answering, scene-text understanding), while retaining a simple, modular, and scalable design",
    "checked": true,
    "id": "28630034bb29760df01ab033b743e30b37f336ae",
    "semantic_title": "pali: a jointly-scaled multilingual language-image model",
    "citation_count": 822,
    "authors": []
  },
  "https://openreview.net/forum?id=OpC-9aBBVJe": {
    "title": "Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier",
    "volume": "oral",
    "abstract": "Increasing the replay ratio, the number of updates of an agent's parameters per environment interaction, is an appealing strategy for improving the sample efficiency of deep reinforcement learning algorithms. In this work, we show that fully or partially resetting the parameters of deep reinforcement learning agents causes better replay ratio scaling capabilities to emerge. We push the limits of the sample efficiency of carefully-modified algorithms by training them using an order of magnitude more updates than usual, significantly improving their performance in the Atari 100k and DeepMind Control Suite benchmarks. We then provide an analysis of the design choices required for favorable replay ratio scaling to be possible and discuss inherent limits and tradeoffs",
    "checked": true,
    "id": "33d84b1531f88d2bd2e516e1574f22e139133065",
    "semantic_title": "sample-efficient reinforcement learning by breaking the replay ratio barrier",
    "citation_count": 129,
    "authors": []
  },
  "https://openreview.net/forum?id=Wc5bmZZU9cy": {
    "title": "Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness",
    "volume": "oral",
    "abstract": "Neural text-to-SQL models have achieved remarkable performance in translating natural language questions into SQL queries. However, recent studies reveal that text-to-SQL models are vulnerable to task-specific perturbations. Previous curated robustness test sets usually focus on individual phenomena. In this paper, we propose a comprehensive robustness benchmark based on Spider, a cross-domain text-to-SQL benchmark, to diagnose the model robustness. We design 17 perturbations on databases, natural language questions, and SQL queries to measure the robustness from different angles. In order to collect more diversified natural question perturbations, we utilize large pretrained language models (PLMs) to simulate human behaviors in creating natural questions. We conduct a diagnostic study of the state-of-the-art models on the robustness set. Experimental results reveal that even the most robust model suffers from a 14.0% performance drop overall and a 50.7% performance drop on the most challenging perturbation. We also present a breakdown analysis regarding text-to-SQL model designs and provide insights for improving model robustness",
    "checked": true,
    "id": "7195ed3c7f11220f29634cecb68b1d39db2e36d9",
    "semantic_title": "dr.spider: a diagnostic evaluation benchmark towards text-to-sql robustness",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=sWOsRj4nT1n": {
    "title": "Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks",
    "volume": "oral",
    "abstract": "Temporal domain generalization is a promising yet extremely challenging area where the goal is to learn models under temporally changing data distributions and generalize to unseen data distributions following the trends of the change. The advancement of this area is challenged by: 1) characterizing data distribution drift and its impacts on models, 2) expressiveness in tracking the model dynamics, and 3) theoretical guarantee on the performance. To address them, we propose a Temporal Domain Generalization with Drift-Aware Dynamic Neural Network (DRAIN) framework. Specifically, we formulate the problem into a Bayesian framework that jointly models the relation between data and model dynamics. We then build a recurrent graph generation scenario to characterize the dynamic graph-structured neural networks learned across different time points. It captures the temporal drift of model parameters and data distributions and can predict models in the future without the presence of future data. In addition, we explore theoretical guarantees of the model performance under the challenging temporal DG setting and provide theoretical analysis, including uncertainty and generalization error. Finally, extensive experiments on several real-world benchmarks with temporal drift demonstrate the proposed method's effectiveness and efficiency",
    "checked": false,
    "id": "85a7c8523f5e1688896e9da7f36f081d5db21876",
    "semantic_title": "temporal domain generalization with drift-aware dynamic neural network",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=SMa9EAovKMC": {
    "title": "Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs",
    "volume": "oral",
    "abstract": "The formalization of existing mathematical proofs is a notoriously difficult process. Despite decades of research on automation and proof assistants, writing formal proofs remains arduous and only accessible to a few experts. While previous studies to automate formalization focused on powerful search algorithms, no attempts were made to take advantage of available informal proofs. In this work, we introduce Draft, Sketch, and Prove (DSP), a method that maps informal proofs to formal proof sketches, and uses the sketches to guide an automated prover by directing its search to easier sub-problems. We investigate two relevant setups where informal proofs are either written by humans or generated by a language model. Our experiments and ablation studies show that large language models are able to produce well-structured formal sketches that follow the same reasoning steps as the informal proofs. Guiding an automated prover with these sketches enhances its performance from $20.9\\%$ to $39.3\\%$ on a collection of mathematical competition problems",
    "checked": true,
    "id": "7de36d6b14aadc8cdb6ad1340b9ca64b15375bca",
    "semantic_title": "draft, sketch, and prove: guiding formal theorem provers with informal proofs",
    "citation_count": 209,
    "authors": []
  },
  "https://openreview.net/forum?id=uVcDssQff_": {
    "title": "REVISITING PRUNING AT INITIALIZATION THROUGH THE LENS OF RAMANUJAN GRAPH",
    "volume": "oral",
    "abstract": "Pruning neural networks at initialization (PaI) has received an upsurge of interest due to its end-to-end saving potential. PaI is able to find sparse subnetworks at initialization that can achieve comparable performance to the full networks. These methods can surpass the trivial baseline of random pruning but suffer from a significant performance gap compared to post-training pruning. Previous approaches firmly rely on weights, gradients, and sanity checks as primary signals when conducting PaI analysis. To better understand the underlying mechanism of PaI, we propose to interpret it through the lens of the Ramanujan Graph - a class of expander graphs that are sparse while being highly connected. It is often believed there should be a strong correlation between the Ramanujan graph and PaI since both are about finding sparse and well-connected neural networks. However, the finer-grained link relating highly sparse and connected networks to their relative performance (i.e., ranking of difference sparse structures at the same specific global sparsity) is still missing. We observe that not only the Ramanujan property for sparse networks shows no significant relationship to PaI's relative performance, but maximizing it can also lead to the formation of pseudo-random graphs with no structural meanings. We reveal the underlying cause to be Ramanujan Graph's strong assumption on the upper bound of the largest nontrivial eigenvalue (µˆ) of layers belonging to highly sparse networks. We hence propose Iterative Mean Difference of Bound (IMDB) as a mean to relax the µˆ upper bound. Likewise, we also show there exists a lower bound for µˆ, which we call the Normalized Random Coefficient (NaRC), that gives us an accurate assessment for when sparse but highly connected structure degenerates into naive randomness. Finally, we systematically analyze the behavior of various PaI methods and demonstrate the utility of our proposed metrics in characterizing PaI performance. We show that subnetworks preserving better the IMDB property correlate higher in performance, while NaRC provides us with a possible mean to locate the region where highly connected, highly sparse, and non-trivial Ramanujan expanders exist. Our code is available at: https://github.com/VITA-Group/ramanujan-on-pai",
    "checked": true,
    "id": "fda9a8f0664456dc4accb4018cfad2e6fde2d460",
    "semantic_title": "revisiting pruning at initialization through the lens of ramanujan graph",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=5N0wtJZ89r9": {
    "title": "Embedding Fourier for Ultra-High-Definition Low-Light Image Enhancement",
    "volume": "oral",
    "abstract": "Ultra-High-Definition (UHD) photo has gradually become the standard configuration in advanced imaging devices. The new standard unveils many issues in existing approaches for low-light image enhancement (LLIE), especially in dealing with the intricate issue of joint luminance enhancement and noise removal while remaining efficient. Unlike existing methods that address the problem in the spatial domain, we propose a new solution, UHDFour, that embeds Fourier transform into a cascaded network. Our approach is motivated by a few unique characteristics in the Fourier domain: 1) most luminance information concentrates on amplitudes while noise is closely related to phases, and 2) a high-resolution image and its low-resolution version share similar amplitude patterns. Through embedding Fourier into our network, the amplitude and phase of a low-light image are separately processed to avoid amplifying noise when enhancing luminance. Besides, UHDFour is scalable to UHD images by implementing amplitude and phase enhancement under the low-resolution regime and then adjusting the high-resolution scale with few computations. We also contribute the first real UHD LLIE dataset, UHD-LL, that contains 2,150 low-noise/normal-clear 4K image pairs with diverse darkness and noise levels captured in different scenarios. With this dataset, we systematically analyze the performance of existing LLIE methods for processing UHD images and demonstrate the advantage of our solution. We believe our new framework, coupled with the dataset, would push the frontier of LLIE towards UHD. The code and dataset are available at https://li-chongyi.github.io/UHDFour/",
    "checked": true,
    "id": "fe6ccdd4688d0cfc5a921c8a345a71feb3852c4d",
    "semantic_title": "embedding fourier for ultra-high-definition low-light image enhancement",
    "citation_count": 120,
    "authors": []
  },
  "https://openreview.net/forum?id=YnkGMIh0gvX": {
    "title": "A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification",
    "volume": "oral",
    "abstract": "Reliable application of machine learning-based decision systems in the wild is one of the major challenges currently investigated by the field. A large portion of established approaches aims to detect erroneous predictions by means of assigning confidence scores. This confidence may be obtained by either quantifying the model's predictive uncertainty, learning explicit scoring functions, or assessing whether the input is in line with the training distribution. Curiously, while these approaches all state to address the same eventual goal of detecting failures of a classifier upon real-world application, they currently constitute largely separated research fields with individual evaluation protocols, which either exclude a substantial part of relevant methods or ignore large parts of relevant failure sources. In this work, we systematically reveal current pitfalls caused by these inconsistencies and derive requirements for a holistic and realistic evaluation of failure detection. To demonstrate the relevance of this unified perspective, we present a large-scale empirical study for the first time enabling benchmarking confidence scoring functions w.r.t all relevant methods and failure sources. The revelation of a simple softmax response baseline as the overall best performing method underlines the drastic shortcomings of current evaluation in the plethora of publicized research on confidence scoring. Code and trained models are at https://github.com/https://github.com/IML-DKFZ/fd-shifts",
    "checked": true,
    "id": "4b6f6f69d6400d4f0daa6a174b33925bb76696c1",
    "semantic_title": "a call to reflect on evaluation practices for failure detection in image classification",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=7JsGYvjE88d": {
    "title": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal Search",
    "volume": "oral",
    "abstract": "Complex reasoning problems contain states that vary in the computational cost required to determine the right action plan. To take advantage of this property, we propose Adaptive Subgoal Search (AdaSubS), a search method that adaptively adjusts the planning horizon. To this end, AdaSubS generates diverse sets of subgoals at different distances. A verification mechanism is employed to filter out unreachable subgoals swiftly, making it possible to focus on feasible further subgoals. In this way, AdaSubS benefits from the efficiency of planning with longer-term subgoals and the fine control with shorter-term ones, and thus scales well to difficult planning problems. We show that AdaSubS significantly surpasses hierarchical planning algorithms on three complex reasoning tasks: Sokoban, the Rubik's Cube, and the inequality-proving benchmark INT",
    "checked": true,
    "id": "67da27828fcea2edb09ea7e9c316864244db9b92",
    "semantic_title": "fast and precise: adjusting planning horizon with adaptive subgoal search",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=N9Pk5iSCzAn": {
    "title": "Towards Open Temporal Graph Neural Networks",
    "volume": "oral",
    "abstract": "Graph neural networks (GNNs) for temporal graphs have recently attracted increasing attentions, where a common assumption is that the class set for nodes is closed. However, in real-world scenarios, it often faces the open set problem with the dynamically increased class set as the time passes by. This will bring two big challenges to the existing dynamic GNN methods: (i) How to dynamically propagate appropriate information in an open temporal graph, where new class nodes are often linked to old class nodes. This case will lead to a sharp contradiction. This is because typical GNNs are prone to make the embeddings of connected nodes become similar, while we expect the embeddings of these two interactive nodes to be distinguishable since they belong to different classes. (ii) How to avoid catastrophic knowledge forgetting over old classes when learning new classes occurred in temporal graphs. In this paper, we propose a general and principled learning approach for open temporal graphs, called OTGNet, with the goal of addressing the above two challenges. We assume the knowledge of a node can be disentangled into class-relevant and class-agnostic one, and thus explore a new message passing mechanism by extending the information bottleneck principle to only propagate class-agnostic knowledge between nodes of different classes, avoiding aggregating conflictive information. Moreover, we devise a strategy to select both important and diverse triad sub-graph structures for effective class-incremental learning. Extensive experiments on three real-world datasets of different domains demonstrate the superiority of our method, compared to the baselines",
    "checked": true,
    "id": "e9b973e5fb4ab649e0d229cd346919a9dbe6e7dc",
    "semantic_title": "towards open temporal graph neural networks",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=SrC-nwieGJ": {
    "title": "Relative representations enable zero-shot latent space communication",
    "volume": "oral",
    "abstract": "Neural networks embed the geometric structure of a data manifold lying in a high-dimensional space into latent representations. Ideally, the distribution of the data points in the latent space should depend only on the task, the data, the loss, and other architecture-specific constraints. However, factors such as the random weights initialization, training hyperparameters, or other sources of randomness in the training phase may induce incoherent latent spaces that hinder any form of reuse. Nevertheless, we empirically observe that, under the same data and modeling choices, the angles between the encodings within distinct latent spaces do not change. In this work, we propose the latent similarity between each sample and a fixed set of anchors as an alternative data representation, demonstrating that it can enforce the desired invariances without any additional training. We show how neural architectures can leverage these relative representations to guarantee, in practice, invariance to latent isometries and rescalings, effectively enabling latent space communication: from zero-shot model stitching to latent space comparison between diverse settings. We extensively validate the generalization capability of our approach on different datasets, spanning various modalities (images, text, graphs), tasks (e.g., classification, reconstruction) and architectures (e.g., CNNs, GCNs, transformers)",
    "checked": true,
    "id": "f56d363635bc378a196bae6d886ddd2d2899a220",
    "semantic_title": "relative representations enable zero-shot latent space communication",
    "citation_count": 137,
    "authors": []
  },
  "https://openreview.net/forum?id=FkSp8VW8RjH": {
    "title": "Language Modelling with Pixels",
    "volume": "oral",
    "abstract": "Language models are defined over a finite set of inputs, which creates a vocabulary bottleneck when we attempt to scale the number of supported languages. Tackling this bottleneck results in a trade-off between what can be represented in the embedding matrix and computational issues in the output layer. This paper introduces PIXEL, the Pixel-based Encoder of Language, which suffers from neither of these issues. PIXEL is a pretrained language model that renders text as images, making it possible to transfer representations across languages based on orthographic similarity or the co-activation of pixels. PIXEL is trained to reconstruct the pixels of masked patches instead of predicting a distribution over tokens. We pretrain the 86M parameter PIXEL model on the same English data as BERT and evaluate on syntactic and semantic tasks in typologically diverse languages, including various non-Latin scripts. We find that PIXEL substantially outperforms BERT on syntactic and semantic processing tasks on scripts that are not found in the pretraining data, but PIXEL is slightly weaker than BERT when working with Latin scripts. Furthermore, we find that PIXEL is more robust than BERT to orthographic attacks and linguistic code-switching, further confirming the benefits of modelling language with pixels",
    "checked": true,
    "id": "23f4b6432b74e5db05da04e354341807f5044f7e",
    "semantic_title": "language modelling with pixels",
    "citation_count": 50,
    "authors": []
  },
  "https://openreview.net/forum?id=M95oDwJXayG": {
    "title": "Addressing Parameter Choice Issues in Unsupervised Domain Adaptation by Aggregation",
    "volume": "oral",
    "abstract": "We study the problem of choosing algorithm hyper-parameters in unsupervised domain adaptation, i.e., with labeled data in a source domain and unlabeled data in a target domain, drawn from a different input distribution. We follow the strategy to compute several models using different hyper-parameters, and, to subsequently compute a linear aggregation of the models. While several heuristics exist that follow this strategy, methods are still missing that rely on thorough theories for bounding the target error. In this turn, we propose a method that extends weighted least squares to vector-valued functions, e.g., deep neural networks. We show that the target error of the proposed algorithm is asymptotically not worse than twice the error of the unknown optimal aggregation. We also perform a large scale empirical comparative study on several datasets, including text, images, electroencephalogram, body sensor signals and signals from mobile phones. Our method outperforms deep embedded validation (DEV) and importance weighted validation (IWV) on all datasets, setting a new state-of-the-art performance for solving parameter choice issues in unsupervised domain adaptation with theoretical error guarantees. We further study several competitive heuristics, all outperforming IWV and DEV on at least five datasets. However, our method outperforms each heuristic on at least five of seven datasets",
    "checked": true,
    "id": "9064ead1b2fa00cef3fbcc50d2b5e3fedc246b87",
    "semantic_title": "addressing parameter choice issues in unsupervised domain adaptation by aggregation",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=ZTK3SefE8_Z": {
    "title": "Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search",
    "volume": "oral",
    "abstract": "Nonlinear dynamics is ubiquitous in nature and commonly seen in various science and engineering disciplines. Distilling analytical expressions that govern nonlinear dynamics from limited data remains vital but challenging. To tackle this fundamental issue, we propose a novel Symbolic Physics Learner (SPL) machine to discover the mathematical structure of nonlinear dynamics. The key concept is to interpret mathematical operations and system state variables by computational rules and symbols, establish symbolic reasoning of mathematical formulas via expression trees, and employ a Monte Carlo tree search (MCTS) agent to explore optimal expression trees based on measurement data. The MCTS agent obtains an optimistic selection policy through the traversal of expression trees, featuring the one that maps to the arithmetic expression of underlying physics. Salient features of the proposed framework include search flexibility and enforcement of parsimony for discovered equations. The efficacy and superiority of the SPL machine are demonstrated by numerical examples, compared with state-of-the-art baselines",
    "checked": true,
    "id": "925d82383ba96485ed1d85c41cbe63e329cb4c18",
    "semantic_title": "symbolic physics learner: discovering governing equations via monte carlo tree search",
    "citation_count": 60,
    "authors": []
  },
  "https://openreview.net/forum?id=rFQfjDC9Mt": {
    "title": "Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only",
    "volume": "oral",
    "abstract": "Multi-label models have been widely used in various applications including image annotation and object detection. The fly in the ointment is its inherent vulnerability to backdoor attacks due to the adoption of deep learning techniques. However, all existing backdoor attacks exclusively require to modify training inputs (e.g., images), which may be impractical in real-world applications. In this paper, we aim to break this wall and propose the first clean-image backdoor attack, which only poisons the training labels without touching the training samples. Our key insight is that in a multi-label learning task, the adversary can just manipulate the annotations of training samples consisting of a specific set of classes to activate the backdoor. We design a novel trigger exploration method to find convert and effective triggers to enhance the attack performance. We also propose three target label selection strategies to achieve different goals. Experimental results indicate that our clean-image backdoor can achieve a 98% attack success rate while preserving the model's functionality on the benign inputs. Besides, the proposed clean-image backdoor can evade existing state-of-the-art defenses",
    "checked": true,
    "id": "a2c7b25b2646aa2b6a2b80cdfe9f94c895cf6fd4",
    "semantic_title": "clean-image backdoor: attacking multi-label models with poisoned labels only",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=m1oqEOAozQU": {
    "title": "Graph Neural Networks for Link Prediction with Subgraph Sketching",
    "volume": "oral",
    "abstract": "Many Graph Neural Networks (GNNs) perform poorly compared to simple heuristics on Link Prediction (LP) tasks. This is due to limitations in expressive power such as the inability to count triangles (the backbone of most LP heuristics) and because they can not distinguish automorphic nodes (those having identical structural roles). Both expressiveness issues can be alleviated by learning link (rather than node) representations and incorporating structural features such as triangle counts. Since explicit link representations are often prohibitively expensive, recent works resorted to subgraph-based methods, which have achieved state-of-the-art performance for LP, but suffer from poor efficiency due to high levels of redundancy between subgraphs. We analyze the components of subgraph GNN (SGNN) methods for link prediction. Based on our analysis, we propose a novel full-graph GNN called ELPH (Efficient Link Prediction with Hashing) that passes subgraph sketches as messages to approximate the key components of SGNNs without explicit subgraph construction. ELPH is provably more expressive than Message Passing GNNs (MPNNs). It outperforms existing SGNN models on many standard LP benchmarks while being orders of magnitude faster. However, it shares the common GNN limitation that it is only efficient when the dataset fits in GPU memory. Accordingly, we develop a highly scalable model, called BUDDY, which uses feature precomputation to circumvent this limitation without sacrificing predictive performance. Our experiments show that BUDDY also outperforms SGNNs on standard LP benchmarks while being highly scalable and faster than ELPH",
    "checked": true,
    "id": "68baa11061a8da3a9e6c6cd0ff075bd5cc72376d",
    "semantic_title": "graph neural networks for link prediction with subgraph sketching",
    "citation_count": 99,
    "authors": []
  },
  "https://openreview.net/forum?id=_2bDpAtr7PI": {
    "title": "Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction",
    "volume": "oral",
    "abstract": "Predicting the pose of objects from a single image is an important but difficult computer vision problem. Methods that predict a single point estimate do not predict the pose of objects with symmetries well and cannot represent uncertainty. Alternatively, some works predict a distribution over orientations in $\\mathrm{SO}(3)$. However, training such models can be computation- and sample-inefficient. Instead, we propose a novel mapping of features from the image domain to the 3D rotation manifold. Our method then leverages $\\mathrm{SO}(3)$ equivariant layers, which are more sample efficient, and outputs a distribution over rotations that can be sampled at arbitrary resolution. We demonstrate the effectiveness of our method at object orientation prediction, and achieve state-of-the-art performance on the popular PASCAL3D+ dataset. Moreover, we show that our method can model complex object symmetries, without any modifications to the parameters or loss function. Code is available at \\url{https://dmklee.github.io/image2sphere}",
    "checked": true,
    "id": "326f04f657dff3f3ec9ff8d1dc686e7695b342a0",
    "semantic_title": "image to sphere: learning equivariant features for efficient pose prediction",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=zt53IDUR1U": {
    "title": "MICN: Multi-scale Local and Global Context Modeling for Long-term Series Forecasting",
    "volume": "oral",
    "abstract": "Recently, Transformer-based methods have achieved surprising performance in the field of long-term series forecasting, but the attention mechanism for computing global correlations entails high complexity. And they do not allow for targeted modeling of local features as CNN structures do. To solve the above problems, we propose to combine local features and global correlations to capture the overall view of time series (e.g., fluctuations, trends). To fully exploit the underlying information in the time series, a multi-scale branch structure is adopted to model different potential patterns separately. Each pattern is extracted with down-sampled convolution and isometric convolution for local features and global correlations, respectively. In addition to being more effective, our proposed method, termed as Multi-scale Isometric Convolution Network (MICN), is more efficient with linear complexity about the sequence length with suitable convolution kernels. Our experiments on six benchmark datasets show that compared with state-of-the-art methods, MICN yields 17.2% and 21.6% relative improvements for multivariate and univariate time series, respectively",
    "checked": true,
    "id": "6f370b047624dafea4e59df20ac4cbec538dc44a",
    "semantic_title": "micn: multi-scale local and global context modeling for long-term series forecasting",
    "citation_count": 310,
    "authors": []
  },
  "https://openreview.net/forum?id=SXZr8aDKia": {
    "title": "Personalized Federated Learning with Feature Alignment and Classifier Collaboration",
    "volume": "oral",
    "abstract": "Data heterogeneity is one of the most challenging issues in federated learning, which motivates a variety of approaches to learn personalized models for participating clients. One such approach in deep neural networks based tasks is employing a shared feature representation and learning a customized classifier head for each client. However, previous works do not utilize the global knowledge during local representation learning and also neglect the fine-grained collaboration between local classifier heads, which limits the model generalization ability. In this work, we conduct explicit local-global feature alignment by leveraging global semantic knowledge for learning a better representation. Moreover, we quantify the benefit of classifier combination for each client as a function of the combining weights and derive an optimization problem for estimating optimal weights. Finally, extensive evaluation results on benchmark datasets with various heterogeneous data scenarios demonstrate the effectiveness of our proposed method",
    "checked": true,
    "id": "f52e2e84bb1dbae264da4c51419f899a770dd47a",
    "semantic_title": "personalized federated learning with feature alignment and classifier collaboration",
    "citation_count": 131,
    "authors": []
  },
  "https://openreview.net/forum?id=c7rM7F7jQjN": {
    "title": "From Play to Policy: Conditional Behavior Generation from Uncurated Robot Data",
    "volume": "oral",
    "abstract": "While large-scale sequence modelling from offline data has led to impressive performance gains in natural language generation and image generation, directly translating such ideas to robotics has been challenging. One critical reason for this is that uncurated robot demonstration data, i.e. play data, collected from non-expert human demonstrators are often noisy, diverse, and distributionally multi-modal. This makes extracting useful, task-centric behaviors from such data a difficult generative modelling problem. In this work, we present Conditional Behavior Transformers (C-BeT), a method that combines the multi-modal generation ability of Behavior Transformer with future-conditioned goal specification. On a suite of simulated benchmark tasks, we find that C-BeT improves upon prior state-of-the-art work in learning from play data by an average of 45.7%. Further, we demonstrate for the first time that useful task-centric behaviors can be learned on a real-world robot purely from play data without any task labels or reward information. Robot videos are best viewed on our project website: play-to-policy.github.io",
    "checked": true,
    "id": "9b5f4aab169fba588e214c010345232053f8ae76",
    "semantic_title": "from play to policy: conditional behavior generation from uncurated robot data",
    "citation_count": 104,
    "authors": []
  },
  "https://openreview.net/forum?id=jlAjNL8z5cs": {
    "title": "Visual Classification via Description from Large Language Models",
    "volume": "oral",
    "abstract": "Vision-language models such as CLIP have shown promising performance on a variety of recognition tasks using the standard zero-shot classification procedure -- computing similarity between the query image and the embedded words for each category. By only using the category name, they neglect to make use of the rich context of additional information that language affords. The procedure gives no intermediate understanding of why a category is chosen, and furthermore provides no mechanism for adjusting the criteria used towards this decision. We present an alternative framework for classification with VLMs, which we call classification by description. We ask VLMs to check for descriptive features rather than broad categories: to find a tiger, look for its stripes; its claws; and more. By basing decisions on these descriptors, we can provide additional cues that encourage using the features we want to be used. In the process, we can get a clear idea of what the model ``thinks\" it is seeing to make its decision; it gains some level of inherent explainability. We query large language models (e.g., GPT-3) for these descriptors to obtain them in a scalable way. Extensive experiments show our framework has numerous advantages past interpretability. We show improvements in accuracy on ImageNet across distribution shifts; demonstrate the ability to adapt VLMs to recognize concepts unseen during training; and illustrate how descriptors can be edited to effectively mitigate bias compared to the baseline",
    "checked": true,
    "id": "a42b091adaf29b06a092b67192ac07cb93312f2a",
    "semantic_title": "visual classification via description from large language models",
    "citation_count": 342,
    "authors": []
  },
  "https://openreview.net/forum?id=w0QXrZ3N-s": {
    "title": "The Modality Focusing Hypothesis: Towards Understanding Crossmodal Knowledge Distillation",
    "volume": "oral",
    "abstract": "Crossmodal knowledge distillation (KD) extends traditional knowledge distillation to the area of multimodal learning and demonstrates great success in various applications. To achieve knowledge transfer across modalities, a pretrained network from one modality is adopted as the teacher to provide supervision signals to a student network learning from the other modality. In contrast to the empirical success reported in prior works, the working mechanism of crossmodal KD remains a mystery. In this paper, we present a thorough understanding of crossmodal KD. We begin by providing two failure cases and demonstrate that KD is not a universal cure in crossmodal knowledge transfer. We then present the modality Venn diagram to understand modality relationships and the modality focusing hypothesis revealing the decisive factor in the efficacy of crossmodal KD. Experimental results on 6 multimodal datasets help justify our hypothesis, diagnose failure cases, and point directions to improve crossmodal knowledge transfer in the future",
    "checked": true,
    "id": "af54c8a1b08b15cb77db1e6231827c3d173c9317",
    "semantic_title": "the modality focusing hypothesis: towards understanding crossmodal knowledge distillation",
    "citation_count": 50,
    "authors": []
  },
  "https://openreview.net/forum?id=OJ8aSjCaMNK": {
    "title": "Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve",
    "volume": "oral",
    "abstract": "Variational autoencoders (VAEs) are powerful tools for learning latent representations of data used in a wide range of applications. In practice, VAEs usually require multiple training rounds to choose the amount of information the latent variable should retain. This trade-off between the reconstruction error (distortion) and the KL divergence (rate) is typically parameterized by a hyperparameter $\\beta$. In this paper, we introduce Multi-Rate VAE (MR-VAE), a computationally efficient framework for learning optimal parameters corresponding to various $\\beta$ in a single training run. The key idea is to explicitly formulate a response function using hypernetworks that maps $\\beta$ to the optimal parameters. MR-VAEs construct a compact response hypernetwork where the pre-activations are conditionally gated based on $\\beta$. We justify the proposed architecture by analyzing linear VAEs and showing that it can represent response functions exactly for linear VAEs. With the learned hypernetwork, MR-VAEs can construct the rate-distortion curve without additional training and can be deployed with significantly less hyperparameter tuning. Empirically, our approach is competitive and often exceeds the performance of multiple $\\beta$-VAEs training with minimal computation and memory overheads",
    "checked": true,
    "id": "d10b6a8a4543af29380cac09cd8b277c25066e6b",
    "semantic_title": "multi-rate vae: train once, get the full rate-distortion curve",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=3OR2tbtnYC-": {
    "title": "Near-optimal Policy Identification in Active Reinforcement Learning",
    "volume": "oral",
    "abstract": "Many real-world reinforcement learning tasks require control of complex dynamical systems that involve both costly data acquisition processes and large state spaces. In cases where the expensive transition dynamics can be readily evaluated at specified states (e.g., via a simulator), agents can operate in what is often referred to as planning with a \\emph{generative model}. We propose the AE-LSVI algorithm for best policy identification, a novel variant of the kernelized least-squares value iteration (LSVI) algorithm that combines optimism with pessimism for active exploration (AE). AE-LSVI provably identifies a near-optimal policy \\emph{uniformly} over an entire state space and achieves polynomial sample complexity guarantees that are independent of the number of states. When specialized to the recently introduced offline contextual Bayesian optimization setting, our algorithm achieves improved sample complexity bounds. Experimentally, we demonstrate that AE-LSVI outperforms other RL algorithms in a variety of environments when robustness to the initial state is required",
    "checked": true,
    "id": "445f4e1d4c9fcbab2e1aaf89c27599ddfaad82f5",
    "semantic_title": "near-optimal policy identification in active reinforcement learning",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=LFHFQbjxIiP": {
    "title": "Conditional Antibody Design as 3D Equivariant Graph Translation",
    "volume": "oral",
    "abstract": "Antibody design is valuable for therapeutic usage and biological research. Existing deep-learning-based methods encounter several key issues: 1) incomplete context for Complementarity-Determining Regions (CDRs) generation; 2) incapability of capturing the entire 3D geometry of the input structure; 3) inefficient prediction of the CDR sequences in an autoregressive manner. In this paper, we propose Multi-channel Equivariant Attention Network (MEAN) to co-design 1D sequences and 3D structures of CDRs. To be specific, MEAN formulates antibody design as a conditional graph translation problem by importing extra components including the target antigen and the light chain of the antibody. Then, MEAN resorts to E(3)-equivariant message passing along with a proposed attention mechanism to better capture the geometrical correlation between different components. Finally, it outputs both the 1D sequences and 3D structure via a multi-round progressive full-shot scheme, which enjoys more efficiency and precision against previous autoregressive approaches. Our method significantly surpasses state-of-the-art models in sequence and structure modeling, antigen-binding CDR design, and binding affinity optimization. Specifically, the relative improvement to baselines is about 23\\% in antigen-binding CDR design and 34\\% for affinity optimization",
    "checked": true,
    "id": "071e69ad14880d1de98855cb3e1773db7c41977a",
    "semantic_title": "conditional antibody design as 3d equivariant graph translation",
    "citation_count": 94,
    "authors": []
  },
  "https://openreview.net/forum?id=DeG07_TcZvT": {
    "title": "Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task",
    "volume": "oral",
    "abstract": "Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network and create \"latent saliency maps\" that can help explain predictions in human terms",
    "checked": true,
    "id": "d5295f7ddcf281f3d30a7579d5ce482036a8e27c",
    "semantic_title": "emergent world representations: exploring a sequence model trained on a synthetic task",
    "citation_count": 334,
    "authors": []
  },
  "https://openreview.net/forum?id=VELL0PlWfc": {
    "title": "Tailoring Language Generation Models under Total Variation Distance",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "14a26bd4d9213e40325e2a04f136279115bf248d",
    "semantic_title": "tailoring language generation models under total variation distance",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=vhFu1Acb0xb": {
    "title": "Transformers are Sample-Efficient World Models",
    "volume": "oral",
    "abstract": "",
    "checked": false,
    "id": "235303a8bc1e4892efd525a38ead657422d8a519",
    "semantic_title": "transformers are sample efficient world models",
    "citation_count": 226,
    "authors": []
  },
  "https://openreview.net/forum?id=TD7AnQjNzR6": {
    "title": "Statistical Efficiency of Score Matching: The View from Isoperimetry",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "bdc52aeaaa366316642b558b7495991676541201",
    "semantic_title": "statistical efficiency of score matching: the view from isoperimetry",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=0ypGZvm0er0": {
    "title": "View Synthesis with Sculpted Neural Points",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "ab0ead190ad6e19d82cfa8a43365e842c8ee62a1",
    "semantic_title": "view synthesis with sculpted neural points",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=GcM7qfl5zY": {
    "title": "AutoGT: Automated Graph Transformer Architecture Search",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "5d00e8f305d20ad937938fa4db054a33186626f7",
    "semantic_title": "autogt: automated graph transformer architecture search",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=vSVLM2j9eie": {
    "title": "Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "fb45d31cc89207aec392dbac8908cc24db2df871",
    "semantic_title": "crossformer: transformer utilizing cross-dimension dependency for multivariate time series forecasting",
    "citation_count": 644,
    "authors": []
  },
  "https://openreview.net/forum?id=LV_MeMS38Q9": {
    "title": "Betty: An Automatic Differentiation Library for Multilevel Optimization",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "5be4f2074e4811fec280248e10e2f7b2faee54dd",
    "semantic_title": "betty: an automatic differentiation library for multilevel optimization",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=ueYYgo2pSSU": {
    "title": "Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "18d82f2a4aa1e2c1c4b447876c95b8f7e717e1a1",
    "semantic_title": "offline rl with no ood actions: in-sample learning via implicit value regularization",
    "citation_count": 92,
    "authors": []
  },
  "https://openreview.net/forum?id=CPdc77SQfQ5": {
    "title": "Win: Weight-Decay-Integrated Nesterov Acceleration for Adaptive Gradient Algorithms",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "c99be6b5cd24ae05f60256989efbefc7252c7717",
    "semantic_title": "win: weight-decay-integrated nesterov acceleration for adaptive gradient algorithms",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=g2YraF75Tj": {
    "title": "Towards Stable Test-time Adaptation in Dynamic Wild World",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "f849b873e94f28e1f2a3e1dc4d7bef17eb64adab",
    "semantic_title": "towards stable test-time adaptation in dynamic wild world",
    "citation_count": 324,
    "authors": []
  },
  "https://openreview.net/forum?id=2QGJXyMNoPz": {
    "title": "MocoSFL: enabling cross-client collaborative self-supervised learning",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "15af33590302d09cf0b5a90e3f3fac26cc2bd6a6",
    "semantic_title": "mocosfl: enabling cross-client collaborative self-supervised learning",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=1NAzMofMnWl": {
    "title": "DaxBench: Benchmarking Deformable Object Manipulation with Differentiable Physics",
    "volume": "oral",
    "abstract": "",
    "checked": false,
    "id": "fc715a1aac98fd5f5609e8fae16905ec3b85a057",
    "semantic_title": "benchmarking deformable object manipulation with differentiable physics",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=U2WjB9xxZ9q": {
    "title": "3D generation on ImageNet",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "e750fd59b0239788c811af8809969285071ee71c",
    "semantic_title": "3d generation on imagenet",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=r9hNv76KoT3": {
    "title": "Rethinking the Expressive Power of GNNs via Graph Biconnectivity",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "e3d1175f5b522220c31f96c5c6753a0757aae471",
    "semantic_title": "rethinking the expressive power of gnns via graph biconnectivity",
    "citation_count": 136,
    "authors": []
  },
  "https://openreview.net/forum?id=RecZ9nB9Q4": {
    "title": "Sparse Mixture-of-Experts are Domain Generalizable Learners",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "9c08d8fca57bac1998b79235f773cde27319a209",
    "semantic_title": "sparse mixture-of-experts are domain generalizable learners",
    "citation_count": 78,
    "authors": []
  },
  "https://openreview.net/forum?id=JroZRaRw7Eu": {
    "title": "Token Merging: Your ViT But Faster",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "1dff6b1b35e2d45d4db57c8b4e4395486c3e365f",
    "semantic_title": "token merging: your vit but faster",
    "citation_count": 584,
    "authors": []
  },
  "https://openreview.net/forum?id=FeWvD0L_a4": {
    "title": "Learnable Behavior Control: Breaking Atari Human World Records via Sample-Efficient Behavior Selection",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "bb1a3404a677154c99f6309e2ae709f44589c4cf",
    "semantic_title": "learnable behavior control: breaking atari human world records via sample-efficient behavior selection",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=awnvqZja69": {
    "title": "Image as Set of Points",
    "volume": "oral",
    "abstract": "",
    "checked": true,
    "id": "72862e6e858c44ebd94d6ba90dc420963d9d0f39",
    "semantic_title": "image as set of points",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=N_g8TT9Cy7f": {
    "title": "Human-Guided Fair Classification for Natural Language Processing",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "4ae163ad7dac91bae435eff844d0fd084f0399ec",
    "semantic_title": "human-guided fair classification for natural language processing",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=X5ZMzRYqUjB": {
    "title": "Humanly Certifying Superhuman Classifiers",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "2bf280fb550a852e6cb40c31bb75d200f731f388",
    "semantic_title": "humanly certifying superhuman classifiers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4F1gvduDeL": {
    "title": "Few-Shot Domain Adaptation For End-to-End Communication",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "d85ad141f2d0e800dd8a151857193d06ef2d5c1a",
    "semantic_title": "few-shot domain adaptation for end-to-end communication",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=688hNNMigVX": {
    "title": "Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "352361e1531c9859e4c0b12d61551e458ccefc34",
    "semantic_title": "learning a data-driven policy network for pre-training automated feature engineering",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=75O7S_L4oY": {
    "title": "Learning Group Importance using the Differentiable Hypergeometric Distribution",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "459aaba88972ecf483df51521f16b82595c9eadb",
    "semantic_title": "learning group importance using the differentiable hypergeometric distribution",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=oiwXWPDTyNk": {
    "title": "Concept-level Debugging of Part-Prototype Networks",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "1557669e5b43c7dbffe7a9f23b80264098cdc7ea",
    "semantic_title": "concept-level debugging of part-prototype networks",
    "citation_count": 56,
    "authors": []
  },
  "https://openreview.net/forum?id=6BHlZgyPOZY": {
    "title": "Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "2cd4233bf08e45760645f1e79be0acbd4262163e",
    "semantic_title": "neuroevolution is a competitive alternative to reinforcement learning for skill discovery",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=JpbLyEI5EwW": {
    "title": "Implicit Bias in Leaky ReLU Networks Trained on High-Dimensional Data",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "a5dad5a2343a1e48790c39b377dfa7f7e0da9e2d",
    "semantic_title": "implicit bias in leaky relu networks trained on high-dimensional data",
    "citation_count": 47,
    "authors": []
  },
  "https://openreview.net/forum?id=O5rKg7IRQIO": {
    "title": "Guarded Policy Optimization with Imperfect Online Demonstrations",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "c28c30a846d97f7e9c0722fbc35bb88aba3c6b04",
    "semantic_title": "guarded policy optimization with imperfect online demonstrations",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=M2unceRvqhh": {
    "title": "Learning with Logical Constraints but without Shortcut Satisfaction",
    "volume": "spotlight",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7oFuxtJtUMH": {
    "title": "Certified Training: Small Boxes are All You Need",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "a2f519580930421aec9501d5cbbc365893877750",
    "semantic_title": "certified training: small boxes are all you need",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=dKkMnCWfVmm": {
    "title": "Multi-Objective Online Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "fbb265bb6bc64b61defd8f4b79981a6a3be191f2",
    "semantic_title": "multi-objective online learning",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=3ULaIHxn9u7": {
    "title": "Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": false,
    "id": "9d0d494c4ab60b4d8e72b761c6972f0d980d6b5b",
    "semantic_title": "seeing differently, acting similarly: imitation learning with heterogeneous observations",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=wkg_b4-IwTZ": {
    "title": "A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "22faadbcfe2c2886899c68dbe2d4e88d8860e54b",
    "semantic_title": "a closer look at model adaptation using feature distortion and simplicity bias",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=WzGdBqcBicl": {
    "title": "Understanding and Adopting Rational Behavior by Bellman Score Estimation",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "2a733c6c5af9aa58f1ff58605e9f9ac830412640",
    "semantic_title": "understanding and adopting rational behavior by bellman score estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=_xlsjehDvlY": {
    "title": "STUNT: Few-shot Tabular Learning with Self-generated Tasks from Unlabeled Tables",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "b50a12cce08050c49f5cda13a76fd32cab2d07ce",
    "semantic_title": "stunt: few-shot tabular learning with self-generated tasks from unlabeled tables",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=bhUPJnS2g0X": {
    "title": "Ask Me Anything: A simple strategy for prompting language models",
    "volume": "spotlight",
    "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt that demonstrates how to perform the task and no additional training. Prompting is a brittle process wherein small modifications to the prompt can cause large variations in the model predictions, and therefore significant effort is dedicated towards designing a painstakingly crafted \"perfect prompt\" for a task. To mitigate the high degree of effort, we instead ask whether collecting multiple decent, yet imperfect, prompts and aggregating them can lead to a high quality prompting strategy. Our observations motivate our proposed method, Ask Me Anything (AMA). We first develop an understanding of the effective prompt formats, finding question-answering (QA) prompts, which encourage open-ended generation (\"Who went to the park?\") tend to outperform those that restrict the model outputs (\"John went to the park. True or False?\"). AMA recursively uses the LLM to transform task inputs to the effective QA format. AM generates multiple questions per input and applies these prompts to collect several noisy \"votes\" for the input's true label. We find the prompts have varying accuracies and dependencies and thus propose to use weak supervision, a procedure for combining the noisy predictions, to produce the final predictions. We evaluate AMA across open-source model families (EleutherAI, BLOOM, OPT, and T0) and sizes (125M-175B parameters), demonstrating an average performance lift of 10.2\\% over the few-shot baseline. This simple strategy enables the open-source GPT-J-6B model to match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular benchmarks. Averaged across these tasks, the GPT-J-6B model outperforms few-shot GPT3-175B. We release our code here: https://github.com/HazyResearch/ama_prompting",
    "checked": true,
    "id": "fb49e88c6bd676516898e911e42b4f8479e6f1bf",
    "semantic_title": "ask me anything: a simple strategy for prompting language models",
    "citation_count": 238,
    "authors": []
  },
  "https://openreview.net/forum?id=cP2QVK-uygd": {
    "title": "On Representing Linear Programs by Graph Neural Networks",
    "volume": "spotlight",
    "abstract": "Learning to optimize is a rapidly growing area that aims to solve optimization problems or improve existing optimization algorithms using machine learning (ML). In particular, the graph neural network (GNN) is considered a suitable ML model for optimization problems whose variables and constraints are permutation--invariant, for example, the linear program (LP). While the literature has reported encouraging numerical results, this paper establishes the theoretical foundation of applying GNNs to solving LPs. Given any size limit of LPs, we construct a GNN that maps different LPs to different outputs. We show that properly built GNNs can reliably predict feasibility, boundedness, and an optimal solution for each LP in a broad class. Our proofs are based upon the recently--discovered connections between the Weisfeiler--Lehman isomorphism test and the GNN. To validate our results, we train a simple GNN and present its accuracy in mapping LPs to their feasibilities and solutions",
    "checked": true,
    "id": "e0fe6efa4e0046f6b03d83e5bad4516277c22cee",
    "semantic_title": "on representing linear programs by graph neural networks",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=VZ5EaTI6dqa": {
    "title": "Scale-invariant Bayesian Neural Networks with Connectivity Tangent Kernel",
    "volume": "spotlight",
    "abstract": "Studying the loss landscapes of neural networks is critical to identifying generalizations and avoiding overconfident predictions. Flatness, which measures the perturbation resilience of pre-trained parameters for loss values, is widely acknowledged as an essential predictor of generalization. While the concept of flatness has been formalized as a PAC-Bayes bound, it has been observed that the generalization bounds can vary arbitrarily depending on the scale of the model parameters. Despite previous attempts to address this issue, generalization bounds remain vulnerable to function-preserving scaling transformations or are limited to impractical network structures. In this paper, we introduce new PAC-Bayes prior and posterior distributions invariant to scaling transformations, achieved through the \\textit{decomposition of perturbations into scale and connectivity components}. In this way, this approach expands the range of networks to which the resulting generalization bound can be applied, including those with practical transformations such as weight decay with batch normalization. Moreover, we demonstrate that scale-dependency issues of flatness can adversely affect the uncertainty calibration of Laplace approximation, and we propose a solution using our invariant posterior. Our proposed invariant posterior allows for effective measurement of flatness and calibration with low complexity while remaining invariant to practical parameter transformations, also applying it as a reliable predictor of neural network generalization",
    "checked": true,
    "id": "ae5b0395a1b2d41aebe18d8d91c86b3284b0309b",
    "semantic_title": "scale-invariant bayesian neural networks with connectivity tangent kernel",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=nN_nBVKAhhD": {
    "title": "Minimalistic Unsupervised Representation Learning with the Sparse Manifold Transform",
    "volume": "spotlight",
    "abstract": "We describe a minimalistic and interpretable method for unsupervised representation learning that does not require data augmentation, hyperparameter tuning, or other engineering designs, but nonetheless achieves performance close to the state-of-the-art (SOTA) SSL methods. Our approach leverages the sparse manifold transform, which unifies sparse coding, manifold learning, and slow feature analysis. With a one-layer deterministic (one training epoch) sparse manifold transform, it is possible to achieve $99.3\\%$ KNN top-1 accuracy on MNIST, $81.1\\%$ KNN top-1 accuracy on CIFAR-10, and $53.2\\%$ on CIFAR-100. With simple gray-scale augmentation, the model achieves $83.2\\%$ KNN top-1 accuracy on CIFAR-10 and $57\\%$ on CIFAR-100. These results significantly close the gap between simplistic ``white-box'' methods and SOTA methods. We also provide visualization to illustrate how an unsupervised representation transform is formed. The proposed method is closely connected to latent-embedding self-supervised methods and can be treated as the simplest form of VICReg. Though a small performance gap remains between our simple constructive model and SOTA methods, the evidence points to this as a promising direction for achieving a principled and white-box approach to unsupervised representation learning, which has potential to significantly improve learning efficiency",
    "checked": true,
    "id": "0380271e23c5a3348f9f8ad1906b692b22f8b75e",
    "semantic_title": "minimalistic unsupervised representation learning with the sparse manifold transform",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=aKcS3xojnwY": {
    "title": "GEASS: Neural causal feature selection for high-dimensional biological data",
    "volume": "spotlight",
    "abstract": "Identifying nonlinear causal relationships in high-dimensional biological data is an important task. However, current neural network based causality detection approaches for such data suffer from poor interpretability and cannot scale well to the high dimensional regime. Here we present GEASS (Granger fEAture Selection of Spatiotemporal data), which identifies sparse Granger causality mechanisms of high dimensional spatiotemporal data by a single neural network. GEASS maximizes sparsity-regularized modified transfer entropy with a theoretical guarantee of recovering features with spatial/temporal Granger causal relationships. The sparsity regularization is achieved by a novel combinatorial stochastic gate layer to select sparse non-overlapping feature subsets. We demonstrate the efficacy of GEASS in several synthetic datasets and real biological data from single-cell RNA sequencing and spatial transcriptomics",
    "checked": true,
    "id": "944b76bcdf4618b047245c6dc324ee2fbbb24e8c",
    "semantic_title": "geass: neural causal feature selection for high-dimensional biological data",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=i9UlAr1T_xl": {
    "title": "SmartFRZ: An Efficient Training Framework using Attention-Based Layer Freezing",
    "volume": "spotlight",
    "abstract": "There has been a proliferation of artificial intelligence applications, where model training is key to promising high-quality services for these applications. However, the model training process is both time-intensive and energy-intensive, inevitably affecting the user's demand for application efficiency. Layer freezing, an efficient model training technique, has been proposed to improve training efficiency. Although existing layer freezing methods demonstrate the great potential to reduce model training costs, they still remain shortcomings such as lacking generalizability and compromised accuracy. For instance, existing layer freezing methods either require the freeze configurations to be manually defined before training, which does not apply to different networks, or use heuristic freezing criteria that is hard to guarantee decent accuracy in different scenarios. Therefore, there lacks a generic and smart layer freezing method that can automatically perform ``in-situation'' layer freezing for different networks during training processes. To this end, we propose a generic and efficient training framework (SmartFRZ). The core proposed technique in SmartFRZ is attention-guided layer freezing, which can automatically select the appropriate layers to freeze without compromising accuracy. Experimental results show that SmartFRZ effectively reduces the amount of computation in training and achieves significant training acceleration, and outperforms the state-of-the-art layer freezing approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u-RuvyDYqCM": {
    "title": "The In-Sample Softmax for Offline Reinforcement Learning",
    "volume": "spotlight",
    "abstract": "Reinforcement learning (RL) agents can leverage batches of previously collected data to extract a reasonable control policy. An emerging issue in this offline RL setting, however, is that the bootstrapping update underlying many of our methods suffers from insufficient action-coverage: standard max operator may select a maximal action that has not been seen in the dataset. Bootstrapping from these inaccurate values can lead to overestimation and even divergence. There are a growing number of methods that attempt to approximate an in-sample max, that only uses actions well-covered by the dataset. We highlight a simple fact: it is more straightforward to approximate an in-sample softmax using only actions in the dataset. We show that policy iteration based on the in-sample softmax converges, and that for decreasing temperatures it approaches the in-sample max. We derive an In-Sample Actor-Critic (AC), using this in-sample softmax, and show that it is consistently better or comparable to existing offline RL methods, and is also well-suited to fine-tuning. We release the code at github.com/hwang-ua/inac_pytorch",
    "checked": true,
    "id": "488fb301e6a18df78bf3e3cb6a79a8a776296ab2",
    "semantic_title": "the in-sample softmax for offline reinforcement learning",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=TdTGGj7fYYJ": {
    "title": "Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning",
    "volume": "spotlight",
    "abstract": "Unsupervised meta-learning aims to learn generalizable knowledge across a distribution of tasks constructed from unlabeled data. Here, the main challenge is how to construct diverse tasks for meta-learning without label information; recent works have proposed to create, e.g., pseudo-labeling via pretrained representations or creating synthetic samples via generative models. However, such a task construction strategy is fundamentally limited due to heavy reliance on the immutable pseudo-labels during meta-learning and the quality of the representations or the generated samples. To overcome the limitations, we propose a simple yet effective unsupervised meta-learning framework, coined Pseudo-supervised Contrast (PsCo), for few-shot classification. We are inspired by the recent self-supervised learning literature; PsCo utilizes a momentum network and a queue of previous batches to improve pseudo-labeling and construct diverse tasks in a progressive manner. Our extensive experiments demonstrate that PsCo outperforms existing unsupervised meta-learning methods under various in-domain and cross-domain few-shot classification benchmarks. We also validate that PsCo is easily scalable to a large-scale benchmark, while recent prior-art meta-schemes are not",
    "checked": true,
    "id": "704fac2b3a69da67b7e742147f1c4cf4b315bd4d",
    "semantic_title": "unsupervised meta-learning via few-shot pseudo-supervised contrastive learning",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=CZmHHj9MgkP": {
    "title": "Guiding Energy-based Models via Contrastive Latent Variables",
    "volume": "spotlight",
    "abstract": "An energy-based model (EBM) is a popular generative framework that offers both explicit density and architectural flexibility, but training them is difficult since it is often unstable and time-consuming. In recent years, various training techniques have been developed, e.g., better divergence measures or stabilization in MCMC sampling, but there often exists a large gap between EBMs and other generative frameworks like GANs in terms of generation quality. In this paper, we propose a novel and effective framework for improving EBMs via contrastive representation learning (CRL). To be specific, we consider representations learned by contrastive methods as the true underlying latent variable. This contrastive latent variable could guide EBMs to understand the data structure better, so it can improve and accelerate EBM training significantly. To enable the joint training of EBM and CRL, we also design a new class of latent-variable EBMs for learning the joint density of data and the contrastive latent variable. Our experimental results demonstrate that our scheme achieves lower FID scores, compared to prior-art EBM methods (e.g., additionally using variational autoencoders or diffusion techniques), even with significantly faster and more memory-efficient training. We also show conditional and compositional generation abilities of our latent-variable EBMs as their additional benefits, even without explicit conditional training. The code is available at https://github.com/hankook/CLEL",
    "checked": true,
    "id": "7f74086d2772cdb40196ece48830b3644f0a7ae2",
    "semantic_title": "guiding energy-based models via contrastive latent variables",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=ZzdBhtEH9yB": {
    "title": "Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent",
    "volume": "spotlight",
    "abstract": "It is well known that the finite step-size ($h$) in Gradient descent (GD) implicitly regularizes solutions to flatter minimas. A natural question to ask is \\textit{Does the momentum parameter $\\beta$ (say) play a role in implicit regularization in Heavy-ball (H.B) momentum accelerated gradient descent (GD+M)?}. To answer this question, first, we show that the trajectory traced by discrete H.B momentum update (GD+M) is $O(h^2)$ close to a continuous trajectory induced by a modified loss, which consists of an original loss and an implicit regularizer. This implicit regularizer for (GD+M) is indeed stronger than that of (GD) by factor of $(\\frac{1+\\beta}{1-\\beta})$, thus explaining why (GD+M) shows better generalization performance and higher test accuracy than (GD). Furthermore, we extend our analysis to stochastic version of gradient descent with momentum (SGD+M) and propose a deterministic continuous trajectory that is $O(h^2)$ close to the discrete update of (SGD+M) in a strong approximation sense. We explore the implicit regularization in (SGD+M) and (GD+M) through a series of experiments validating our theory",
    "checked": true,
    "id": "bed75393db4c3216470f93d7ec21803ec40b3c72",
    "semantic_title": "implicit regularization in heavy-ball momentum accelerated stochastic gradient descent",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=M_MvkWgQSt": {
    "title": "Real-time variational method for learning neural trajectory and its dynamics",
    "volume": "spotlight",
    "abstract": "Latent variable models have become instrumental in computational neuroscience for reasoning about neural computation. This has fostered the development of powerful offline algorithms for extracting latent neural trajectories from neural recordings. However, despite the potential of real-time alternatives to give immediate feedback to experimentalists, and enhance experimental design, they have received markedly less attention. In this work, we introduce the exponential family variational Kalman filter (eVKF), an online recursive Bayesian method aimed at inferring latent trajectories while simultaneously learning the dynamical system generating them. eVKF works for arbitrary likelihoods and utilizes the constant base measure exponential family to model the latent state stochasticity. We derive a closed-form variational analog to the predict step of the Kalman filter which leads to a provably tighter bound on the ELBO compared to another online variational method. We validate our method on synthetic and real-world data, and, notably, show that it achieves competitive performance",
    "checked": true,
    "id": "ca22a7638c775dbeaac338773e8aa3f45a518b9e",
    "semantic_title": "real-time variational method for learning neural trajectory and its dynamics",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=ZMz-sW6gCLF": {
    "title": "Energy-Inspired Self-Supervised Pretraining for Vision Models",
    "volume": "spotlight",
    "abstract": "Motivated by the fact that forward and backward passes of a deep network naturally form symmetric mappings between input and output representations, we introduce a simple yet effective self-supervised vision model pretraining framework inspired by energy-based models (EBMs). In the proposed framework, we model energy estimation and data restoration as the forward and backward passes of a single network without any auxiliary components, e.g., an extra decoder. For the forward pass, we fit a network to an energy function that assigns low energy scores to samples that belong to an unlabeled dataset, and high energy otherwise. For the backward pass, we restore data from corrupted versions iteratively using gradient-based optimization along the direction of energy minimization. In this way, we naturally fold the encoder-decoder architecture widely used in masked image modeling into the forward and backward passes of a single vision model. Our framework accepts a wide range of pretext tasks with different data corruption methods, and permits models to be pretrained from masked image modeling, patch sorting, and image restoration, including super-resolution, denoising, and colorization. We support our findings with extensive experiments, and show the proposed method delivers comparable and even better performance with remarkably fewer epochs of training compared to the state-of-the-art self-supervised vision model pretraining methods. Our findings shed light on further exploring self-supervised vision model pretraining and pretext tasks beyond masked image modeling",
    "checked": true,
    "id": "07ba6023e5aed51a68dd178a46e79e74ee009e1a",
    "semantic_title": "energy-inspired self-supervised pretraining for vision models",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=lH1PV42cbF": {
    "title": "Binding Language Models in Symbolic Languages",
    "volume": "spotlight",
    "abstract": "Though end-to-end neural approaches have recently been dominating NLP tasks in both performance and ease-of-use, they lack interpretability and robustness. We propose Binder, a training-free neural-symbolic framework that maps the task input to a program, which (1) allows binding a unified API of language model (LM) functionalities to a programming language (e.g., SQL, Python) to extend its grammar coverage and thus tackle more diverse questions, (2) adopts an LM as both the program parser and the underlying model called by the API during execution, and (3) requires only a few in-context exemplar annotations. Specifically, we employ GPT-3 Codex as the LM. In the parsing stage, with only a few in-context exemplars, Codex is able to identify the part of the task input that cannot be answerable by the original programming language, correctly generate API calls to prompt Codex to solve the unanswerable part, and identify where to place the API calls while being compatible with the original grammar. In the execution stage, Codex can perform versatile functionalities (e.g., commonsense QA, information extraction) given proper prompts in the API calls. Binder achieves state-of-the-art results on WikiTableQuestions and TabFact datasets, with explicit output programs that benefit human debugging. Note that previous best systems are all finetuned on tens of thousands of task-specific samples, while Binder only uses dozens of annotations as in-context exemplars without any training. Our code is available at anonymized",
    "checked": true,
    "id": "f58ca7ba4a08b7082e86b7a5989b4b0fda2107ab",
    "semantic_title": "binding language models in symbolic languages",
    "citation_count": 238,
    "authors": []
  },
  "https://openreview.net/forum?id=Z4s73sJYQM": {
    "title": "Evolve Smoothly, Fit Consistently: Learning Smooth Latent Dynamics For Advection-Dominated Systems",
    "volume": "spotlight",
    "abstract": "We present a data-driven, space-time continuous framework to learn surrogate models for complex physical systems described by advection-dominated partial differential equations. Those systems have slow-decaying Kolmogorov n-width that hinders standard methods, including reduced order modeling, from producing high-fidelity simulations at low cost. In this work, we construct hypernetwork-based latent dynamical models directly on the parameter space of a compact representation network. We leverage the expressive power of the network and a specially designed consistency-inducing regularization to obtain latent trajectories that are both low-dimensional and smooth. These properties render our surrogate models highly efficient at inference time. We show the efficacy of our framework by learning models that generate accurate multi-step rollout predictions at much faster inference speed compared to competitors, for several challenging examples",
    "checked": true,
    "id": "f5b6f673726e6c3347329180f20cd6cc6490b3ed",
    "semantic_title": "evolve smoothly, fit consistently: learning smooth latent dynamics for advection-dominated systems",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=Ovnwe_sDQW": {
    "title": "BC-IRL: Learning Generalizable Reward Functions from Demonstrations",
    "volume": "spotlight",
    "abstract": "How well do reward functions learned with inverse reinforcement learning (IRL) generalize? We illustrate that state-of-the-art IRL algorithms, which maximize a maximum-entropy objective, learn rewards that overfit to the demonstrations. Such rewards struggle to provide meaningful rewards for states not covered by the demonstrations, a major detriment when using the reward to learn policies in new situations. We introduce BC-IRL a new inverse reinforcement learning method that learns reward functions that generalize better when compared to maximum-entropy IRL approaches. In contrast to the MaxEnt framework, which learns to maximize rewards around demonstrations, BC-IRL updates reward parameters such that the policy trained with the new reward matches the expert demonstrations better. We show that BC-IRL learns rewards that generalize better on an illustrative simple task and two continuous robotic control tasks, achieving over twice the success rate of baselines in challenging generalization settings",
    "checked": true,
    "id": "d8c0b2fbacdade8bde676feff9da9aaeda244839",
    "semantic_title": "bc-irl: learning generalizable reward functions from demonstrations",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=z9C5dGip90": {
    "title": "Phase2vec: dynamical systems embedding with a physics-informed convolutional network",
    "volume": "spotlight",
    "abstract": "Dynamical systems are found in innumerable forms across the physical and biological sciences, yet all these systems fall naturally into equivalence classes: conservative or dissipative, stable or unstable, compressible or incompressible. Predicting these classes from data remains an essential open challenge in computational physics on which existing time-series classification methods struggle. Here, we propose, phase2vec, an embedding method that learns high-quality, physically-meaningful representations of low-dimensional dynamical systems without supervision. Our embeddings are produced by a convolutional backbone that extracts geometric features from flow data and minimizes a physically-informed vector field reconstruction loss. The trained architecture can not only predict the equations of unseen data, but also produces embeddings that encode meaningful physical properties of input data (e.g. stability of fixed points, conservation of energy, and the incompressibility of flows) more faithfully than standard blackbox classifiers and state-of-the-art time series classification techniques. We additionally apply our embeddings to the analysis of meteorological data, showing we can detect climatically meaningful features. Collectively, our results demonstrate the viability of embedding approaches for the discovery of dynamical features in physical systems",
    "checked": true,
    "id": "1f2848abe8ebbc1ef5d227831d793c93fb4e1e07",
    "semantic_title": "phase2vec: dynamical systems embedding with a physics-informed convolutional network",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=1hKE9qjvz-": {
    "title": "gDDIM: Generalized denoising diffusion implicit models",
    "volume": "spotlight",
    "abstract": "Our goal is to extend the denoising diffusion implicit model (DDIM) to general diffusion models~(DMs) besides isotropic diffusions. Instead of constructing a non-Markov noising process as in the original DDIM, we examine the mechanism of DDIM from a numerical perspective. We discover that the DDIM can be obtained by using some specific approximations of the score when solving the corresponding stochastic differential equation. We present an interpretation of the accelerating effects of DDIM that also explains the advantages of a deterministic sampling scheme over the stochastic one for fast sampling. Building on this insight, we extend DDIM to general DMs, coined generalized DDIM (gDDIM), with a small but delicate modification in parameterizing the score network. We validate gDDIM in two non-isotropic DMs: Blurring diffusion model (BDM) and Critically-damped Langevin diffusion model (CLD). We observe more than 20 times acceleration in BDM. In the CLD, a diffusion model by augmenting the diffusion process with velocity, our algorithm achieves an FID score of 2.26, on CIFAR10, with only 50 number of score function evaluations~(NFEs) and an FID score of 2.86 with only 27 NFEs",
    "checked": true,
    "id": "670bab7b71be5e432b0dc60f406a6115cf6c0633",
    "semantic_title": "gddim: generalized denoising diffusion implicit models",
    "citation_count": 135,
    "authors": []
  },
  "https://openreview.net/forum?id=IPrzNbddXV": {
    "title": "FedExP: Speeding Up Federated Averaging via Extrapolation",
    "volume": "spotlight",
    "abstract": "Federated Averaging (FedAvg) remains the most popular algorithm for Federated Learning (FL) optimization due to its simple implementation, stateless nature, and privacy guarantees combined with secure aggregation. Recent work has sought to generalize the vanilla averaging in FedAvg to a generalized gradient descent step by treating client updates as pseudo-gradients and using a server step size. While the use of a server step size has been shown to provide performance improvement theoretically, the practical benefit of the server step size has not been seen in most existing works. In this work, we present FedExP, a method to adaptively determine the server step size in FL based on dynamically varying pseudo-gradients throughout the FL process. We begin by considering the overparameterized convex regime, where we reveal an interesting similarity between FedAvg and the Projection Onto Convex Sets (POCS) algorithm. We then show how FedExP can be motivated as a novel extension to the extrapolation mechanism that is used to speed up POCS. Our theoretical analysis later also discusses the implications of FedExP in underparameterized and non-convex settings. Experimental results show that FedExP consistently converges faster than FedAvg and competing baselines on a range of realistic FL datasets",
    "checked": true,
    "id": "2b04a0c88f4533c12d107e1c06234a95120bb0e0",
    "semantic_title": "fedexp: speeding up federated averaging via extrapolation",
    "citation_count": 69,
    "authors": []
  },
  "https://openreview.net/forum?id=T-qVtA3pAxG": {
    "title": "Serving Graph Compression for Graph Neural Networks",
    "volume": "spotlight",
    "abstract": "Serving a GNN model online is challenging --- in many applications when testing nodes are connected to training nodes, one has to propagate information from training nodes to testing nodes to achieve the best performance, and storing the whole training set (including training graph and node features) during inference stage is prohibitive for large-scale problems. In this paper, we study graph compression to reduce the storage requirement for GNN in serving. Given a GNN model to be served, we propose to construct a compressed graph with a smaller number of nodes. In serving time, one just needs to replace the original training set graph by this compressed graph, without the need of changing the actual GNN model and the forward pass. We carefully analyze the error in the forward pass and derive simple ways to construct the compressed graph to minimize the approximation error. Experimental results on semi-supervised node classification demonstrate that the proposed method can significantly reduce the serving space requirement for GNN inference",
    "checked": true,
    "id": "145c76206afac4958b4eb768e1f648ad980a2abb",
    "semantic_title": "serving graph compression for graph neural networks",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=Cs3r5KLdoj": {
    "title": "Learning MLPs on Graphs: A Unified View of Effectiveness, Robustness, and Efficiency",
    "volume": "spotlight",
    "abstract": "While Graph Neural Networks (GNNs) have demonstrated their efficacy in dealing with non-Euclidean structural data, they are difficult to be deployed in real applications due to the scalability constraint imposed by the multi-hop data dependency. Existing methods attempt to address this scalability issue by training student multi-layer perceptrons (MLPs) exclusively on node content features using labels derived from the teacher GNNs. However, the trained MLPs are neither effective nor robust. In this paper, we ascribe the lack of effectiveness and robustness to three significant challenges: 1) the misalignment between content feature and label spaces, 2) the strict hard matching to teacher's output, and 3) the sensitivity to node feature noises. To address the challenges, we propose NOSMOG, a novel method to learn NOise-robust Structure-aware MLPs On Graphs, with remarkable effectiveness, robustness, and efficiency. Specifically, we first address the misalignment by complementing node content with position features to capture the graph structural information. We then design an innovative representational similarity distillation strategy to inject soft node similarities into MLPs. Finally, we introduce adversarial feature augmentation to ensure stable learning against feature noises. Extensive experiments and theoretical analyses demonstrate the superiority of NOSMOG by comparing it to GNNs and the state-of-the-art method in both transductive and inductive settings across seven datasets. Codes are available at https://github.com/meettyj/NOSMOG",
    "checked": true,
    "id": "889ea8c9210f49ff6e1690f5c06e626bbb1d17b0",
    "semantic_title": "learning mlps on graphs: a unified view of effectiveness, robustness, and efficiency",
    "citation_count": 63,
    "authors": []
  },
  "https://openreview.net/forum?id=QPtMRyk5rb": {
    "title": "Contrastive Audio-Visual Masked Autoencoder",
    "volume": "spotlight",
    "abstract": "In this paper, we first extend the recent Masked Auto-Encoder (MAE) model from a single modality to audio-visual multi-modalities. Subsequently, we propose the Contrastive Audio-Visual Masked Auto-Encoder (CAV-MAE) by combining contrastive learning and masked data modeling, two major self-supervised learning frameworks, to learn a joint and coordinated audio-visual representation. Our experiments show that the contrastive audio-visual correspondence learning objective not only enables the model to perform audio-visual retrieval tasks, but also helps the model learn a better joint representation. As a result, our fully self-supervised pretrained CAV-MAE achieves a new SOTA accuracy of 65.9% on VGGSound, and is comparable with the previous best supervised pretrained model on AudioSet in the audio-visual event classification task. Code and pretrained models are at https://github.com/yuangongnd/cav-mae",
    "checked": true,
    "id": "3fa1505ec327b82416987a7db3dadab8b12601ea",
    "semantic_title": "contrastive audio-visual masked autoencoder",
    "citation_count": 148,
    "authors": []
  },
  "https://openreview.net/forum?id=IM4xp7kGI5V": {
    "title": "The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks",
    "volume": "spotlight",
    "abstract": "In this work, we explore the maximum-margin bias of quasi-homogeneous neural networks trained with gradient flow on an exponential loss and past a point of separability. We introduce the class of quasi-homogeneous models, which is expressive enough to describe nearly all neural networks with homogeneous activations, even those with biases, residual connections, and normalization layers, while structured enough to enable geometric analysis of its gradient dynamics. Using this analysis, we generalize the existing results of maximum-margin bias for homogeneous networks to this richer class of models. We find that gradient flow implicitly favors a subset of the parameters, unlike in the case of a homogeneous model where all parameters are treated equally. We demonstrate through simple examples how this strong favoritism toward minimizing an asymmetric norm can degrade the robustness of quasi-homogeneous models. On the other hand, we conjecture that this norm-minimization discards, when possible, unnecessary higher-order parameters, reducing the model to a sparser parameterization. Lastly, by applying our theorem to sufficiently expressive neural networks with normalization layers, we reveal a universal mechanism behind the empirical phenomenon of Neural Collapse",
    "checked": true,
    "id": "c716f71a74ec79caade004da6090489256bd1ceb",
    "semantic_title": "the asymmetric maximum margin bias of quasi-homogeneous neural networks",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=MhuFzFsrfvH": {
    "title": "Optimal Transport for Offline Imitation Learning",
    "volume": "spotlight",
    "abstract": "With the advent of large datasets, offline reinforcement learning is a promising framework for learning good decision-making policies without the need to interact with the real environment. However, offline RL requires the dataset to be reward-annotated, which presents practical challenges when reward engineering is difficult or when obtaining reward annotations is labor-intensive. In this paper, we introduce Optimal Transport Relabeling (OTR), an imitation learning algorithm that can automatically relabel offline data of mixed and unknown quality with rewards from a few good demonstrations. OTR's key idea is to use optimal transport to compute an optimal alignment between an unlabeled trajectory in the dataset and an expert demonstration to obtain a similarity measure that can be interpreted as a reward, which can then be used by an offline RL algorithm to learn the policy. OTR is easy to implement and computationally efficient. On D4RL benchmarks, we demonstrate that OTR with a single demonstration can consistently match the performance of offline RL with ground-truth rewards",
    "checked": true,
    "id": "81724b808ae215844bdd841236f4e903f97e335c",
    "semantic_title": "optimal transport for offline imitation learning",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=8aHzds2uUyB": {
    "title": "Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization",
    "volume": "spotlight",
    "abstract": "We tackle the problem of aligning pre-trained large language models (LMs) with human preferences. If we view text generation as a sequential decision-making problem, reinforcement learning (RL) appears to be a natural conceptual framework. However, using RL for LM-based generation faces empirical challenges, including training instability due to the combinatorial action space, as well as a lack of open-source libraries and benchmarks customized for LM alignment. Thus, a question rises in the research community: is RL a practical paradigm for NLP? To help answer this, we first introduce an open-source modular library, $RL4LMs$ (Reinforcement Learning for Language Models), for optimizing language generators with RL. The library consists of on-policy RL algorithms that can be used to train any encoder or encoder-decoder LM in the HuggingFace library (Wolf et al. 2020) with an arbitrary reward function. Next, we present the $GRUE$ (General Reinforced-language Understanding Evaluation) benchmark, a set of 6 language generation tasks which are supervised not by target strings, but by reward functions which capture automated measures of human preference.GRUE is the first leaderboard-style evaluation of RL algorithms for NLP tasks. Finally, we introduce an easy-to-use, performant RL algorithm, $NLPO$ (Natural Language Policy Optimization)} that learns to effectively reduce the combinatorial action space in language generation. We show 1) that RL techniques are generally better than supervised methods at aligning LMs to human preferences; and 2) that NLPO exhibits greater stability and performance than previous policy gradient methods (e.g., PPO (Schulman et al. 2017)), based on both automatic and human evaluations",
    "checked": true,
    "id": "aa46002c3c36a4b474da65793d57efe4a57d2116",
    "semantic_title": "is reinforcement learning (not) for natural language processing: benchmarks, baselines, and building blocks for natural language policy optimization",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=VZX2I_VVJKH": {
    "title": "Learning multi-scale local conditional probability models of images",
    "volume": "spotlight",
    "abstract": "Deep neural networks can learn powerful prior probability models for images, as evidenced by the high-quality generations obtained with recent score-based diffusion methods. But the means by which these networks capture complex global statistical structure, apparently without suffering from the curse of dimensionality, remain a mystery. To study this, we incorporate diffusion methods into a multi-scale decomposition, reducing dimensionality by assuming a stationary local Markov model for wavelet coefficients conditioned on coarser-scale coefficients. We instantiate this model using convolutional neural networks (CNNs) with local receptive fields, which enforce both the stationarity and Markov properties. Global structures are captured using a CNN with receptive fields covering the entire (but small) low-pass image. We test this model on a dataset of face images, which are highly non-stationary and contain large-scale geometric structures. Remarkably, denoising, super-resolution, and image synthesis results all demonstrate that these structures can be captured with significantly smaller conditioning neighborhoods than required by a Markov model implemented in the pixel domain. Our results show that score estimation for large complex images can be reduced to low-dimensional Markov conditional models across scales, alleviating the curse of dimensionality",
    "checked": true,
    "id": "aeab6599b9203e9f4a4f14313c326aed28954e4d",
    "semantic_title": "learning multi-scale local conditional probability models of images",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=9Z_GfhZnGH": {
    "title": "Disentanglement with Biological Constraints: A Theory of Functional Cell Types",
    "volume": "spotlight",
    "abstract": "Neurons in the brain are often finely tuned for specific task variables. Moreover, such disentangled representations are highly sought after in machine learning. Here we mathematically prove that simple biological constraints on neurons, namely nonnegativity and energy efficiency in both activity and weights, promote such sought after disentangled representations by enforcing neurons to become selective for single factors of task variation. We demonstrate these constraints lead to disentanglement in a variety of tasks and architectures, including variational autoencoders. We also use this theory to explain why the brain partitions its cells into distinct cell types such as grid and object-vector cells, and also explain when the brain instead entangles representations in response to entangled task factors. Overall, this work provides a mathematical understanding of why single neurons in the brain often represent single human-interpretable factors, and steps towards an understanding task structure shapes the structure of brain representation",
    "checked": true,
    "id": "43694ae3de01d0ebd730485b5890ed84094f7ad1",
    "semantic_title": "disentanglement with biological constraints: a theory of functional cell types",
    "citation_count": 55,
    "authors": []
  },
  "https://openreview.net/forum?id=J7Uh781A05p": {
    "title": "Learning rigid dynamics with face interaction graph networks",
    "volume": "spotlight",
    "abstract": "Simulating rigid collisions among arbitrary shapes is notoriously difficult due to complex geometry and the strong non-linearity of the interactions. While graph neural network (GNN)-based models are effective at learning to simulate complex physical dynamics, such as fluids, cloth and articulated bodies, they have been less effective and efficient on rigid-body physics, except with very simple shapes. Existing methods that model collisions through the meshes' nodes are often inaccurate because they struggle when collisions occur on faces far from nodes. Alternative approaches that represent the geometry densely with many particles are prohibitively expensive for complex shapes. Here we introduce the ``Face Interaction Graph Network'' (FIGNet) which extends beyond GNN-based methods, and computes interactions between mesh faces, rather than nodes. Compared to learned node- and particle-based methods, FIGNet is around 4x more accurate in simulating complex shape interactions, while also 8x more computationally efficient on sparse, rigid meshes. Moreover, FIGNet can learn frictional dynamics directly from real-world data, and can be more accurate than analytical solvers given modest amounts of training data. FIGNet represents a key step forward in one of the few remaining physical domains which have seen little competition from learned simulators, and offers allied fields such as robotics, graphics and mechanical design a new tool for simulation and model-based planning",
    "checked": true,
    "id": "d6fdd8fc0c5fc052d040687e72638fb4297661cc",
    "semantic_title": "learning rigid dynamics with face interaction graph networks",
    "citation_count": 47,
    "authors": []
  },
  "https://openreview.net/forum?id=6iDHce-0B-a": {
    "title": "Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions",
    "volume": "spotlight",
    "abstract": "We show that the representation cost of fully connected neural networks with homogeneous nonlinearities - which describes the implicit bias in function space of networks with $L_2$-regularization or with losses such as the cross-entropy - converges as the depth of the network goes to infinity to a notion of rank over nonlinear functions. We then inquire under which conditions the global minima of the loss recover the `true' rank of the data: we show that for too large depths the global minimum will be approximately rank 1 (underestimating the rank); we then argue that there is a range of depths which grows with the number of datapoints where the true rank is recovered. Finally, we discuss the effect of the rank of a classifier on the topology of the resulting class boundaries and show that autoencoders with optimal nonlinear rank are naturally denoising",
    "checked": true,
    "id": "58135342c0300d54760f735123092c3559d4c3c8",
    "semantic_title": "implicit bias of large depth networks: a notion of rank for nonlinear functions",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=uzFQpkEzOo": {
    "title": "Depth Separation with Multilayer Mean-Field Networks",
    "volume": "spotlight",
    "abstract": "Depth separation—why a deeper network is more powerful than a shallow one—has been a major problem in deep learning theory. Previous results often focus on representation power, for example, Safran et al. (2019) constructed a function that is easy to approximate using a 3-layer network but not approximable by any 2-layer network. In this paper, we show that this separation is in fact algorithmic: one can learn the function constructed by Safran et al. (2019) using an overparametrized network with polynomially many neurons efﬁciently. Our result relies on a new way of extending the mean-ﬁeld limit to multilayer networks, and a decomposition of loss that factors out the error introduced by the discretization of inﬁnite-width mean-ﬁeld networks",
    "checked": true,
    "id": "9364149ffcb3156ad2ad265be64b55f4fc0c9af3",
    "semantic_title": "depth separation with multilayer mean-field networks",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=i_1rbq8yFWC": {
    "title": "Rhino: Deep Causal Temporal Relationship Learning with History-dependent Noise",
    "volume": "spotlight",
    "abstract": "Discovering causal relationships between different variables from time series data has been a long-standing challenge for many domains. For example, in stock markets, the announcement of acquisitions from leading companies may have immediate effects on stock prices and increase the uncertainty of the future market due to this past action. To discover causal relations in such case, the model needs to consider non-linear relations between variables, instantaneous effect and the change of noise distribution due to past actions. We name the latter as history-dependent noise. However, previous works do not offer a solution addressing all these problems together. In this paper, we propose a structural equation model, called Rhino, which combines vector auto-regression, deep learning and variational inference to model non-linear relationships with instantaneous effects while allowing the noise distribution to be modulated by history observations. Theoretically, we prove the structural identifiability of Rhino. Our empirical results from extensive synthetic experiments and two real-world benchmarks demonstrate better discovery performance compared to relevant baselines, with ablation studies revealing its robustness under model misspecification",
    "checked": true,
    "id": "87d2722c58c25fe9878ab4b29def9bb27675541d",
    "semantic_title": "rhino: deep causal temporal relationship learning with history-dependent noise",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=VD-AYtP0dve": {
    "title": "Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "507465f8d46489a68a527cb5304d76bdb6c31ed9",
    "semantic_title": "semantic uncertainty: linguistic invariances for uncertainty estimation in natural language generation",
    "citation_count": 398,
    "authors": []
  },
  "https://openreview.net/forum?id=cMJo1FTwBTQ": {
    "title": "DINO as a von Mises-Fisher mixture model",
    "volume": "spotlight",
    "abstract": "",
    "checked": false,
    "id": "df183cedd2990f966cc768ecf9b9e0064e15a122",
    "semantic_title": "trajectory poisson multi-bernoulli mixture filter for traffic monitoring using a drone",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=ZCStthyW-TD": {
    "title": "Associative Memory Augmented Asynchronous Spatiotemporal Representation Learning for Event-based Perception",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "24fbb2b0da93c92f3553994f2e5b5fbf04a1441f",
    "semantic_title": "associative memory augmented asynchronous spatiotemporal representation learning for event-based perception",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=9piH3Hg8QEf": {
    "title": "SMART: Self-supervised Multi-task pretrAining with contRol Transformers",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "abba9a6f99d877fdd1b8412ddfcc26fdac6163dc",
    "semantic_title": "smart: self-supervised multi-task pretraining with control transformers",
    "citation_count": 43,
    "authors": []
  },
  "https://openreview.net/forum?id=gSHyqBijPFO": {
    "title": "TEMPERA: Test-Time Prompt Editing via Reinforcement Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": false,
    "id": "66c5a0fbde7e06bf0ef179e660b6a211bcd80aac",
    "semantic_title": "tempera: test-time prompting via reinforcement learning",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=ThXqBsRI-cY": {
    "title": "Provable Defense Against Geometric Transformations",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "32e5d216816786c8cdaedeb64097ef3265661f21",
    "semantic_title": "provable defense against geometric transformations",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=Zb6c8A-Fghk": {
    "title": "Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "14a3aae8060338e3fbefc2af694890b019874d4f",
    "semantic_title": "last layer re-training is sufficient for robustness to spurious correlations",
    "citation_count": 380,
    "authors": []
  },
  "https://openreview.net/forum?id=hWwY_Jq0xsN": {
    "title": "Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "c0de7a5e50976bbd56a89a5de21c0e2c76cfa03f",
    "semantic_title": "towards interpretable deep reinforcement learning with human-friendly prototypes",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=P4MUGRM4Acu": {
    "title": "The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "19b8f213ba5c70afc9bf5dd5945a0771e12f9ef5",
    "semantic_title": "the surprising effectiveness of equivariant models in domains with latent symmetry",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=j8IiQUM33s": {
    "title": "Task-customized Masked Autoencoder via Mixture of Cluster-conditional Experts",
    "volume": "spotlight",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uyqks-LILZX": {
    "title": "Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "bf908f36468fc3869e7969b3ffdbd19b967debea",
    "semantic_title": "modeling the data-generating process is necessary for out-of-distribution generalization",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=eR2dG8yjnQ": {
    "title": "Using Language to Extend to Unseen Domains",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "762b4fc658bfd36115c3d693ed398c5094db759b",
    "semantic_title": "using language to extend to unseen domains",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=eQzLwwGyQrb": {
    "title": "Can We Find Nash Equilibria at a Linear Rate in Markov Games?",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "8428cff0746ac0b9ad8477f0ac057058f9b9c965",
    "semantic_title": "can we find nash equilibria at a linear rate in markov games?",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=8gd4M-_Rj1": {
    "title": "Hebbian Deep Learning Without Feedback",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "dee626dcedf3686399294cb1ce707f1ecda89e29",
    "semantic_title": "hebbian deep learning without feedback",
    "citation_count": 60,
    "authors": []
  },
  "https://openreview.net/forum?id=kt-dcBQcSA": {
    "title": "A probabilistic framework for task-aligned intra- and inter-area neural manifold estimation",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "e00d7f6a030d96830b3534b5c0ee1e6b827d52ab",
    "semantic_title": "a probabilistic framework for task-aligned intra- and inter-area neural manifold estimation",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=PvLnIaJbt9": {
    "title": "Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "33fd110d1e4ca5f91d1b7ca7ff24ce1e9335359e",
    "semantic_title": "metadata archaeology: unearthing data subsets by leveraging training dynamics",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=gm0VZ-h-hPy": {
    "title": "Proposal-Contrastive Pretraining for Object Detection from Fewer Data",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "dbeeb2eb58a77a2175104e455186b739d6674948",
    "semantic_title": "proposal-contrastive pretraining for object detection from fewer data",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=HXz7Vcm3VgM": {
    "title": "ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "32c1408d4b50f1ae5cb76fb3089372b0d4f6c708",
    "semantic_title": "imagenet-x: understanding model mistakes with factor of variation annotations",
    "citation_count": 47,
    "authors": []
  },
  "https://openreview.net/forum?id=b7SBTEBFnC": {
    "title": "Canary in a Coalmine: Better Membership Inference with Ensembled Adversarial Queries",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "049e016d5241eb2eab9c7e015394aa7dc8bf2b40",
    "semantic_title": "canary in a coalmine: better membership inference with ensembled adversarial queries",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PhkWyijGi5b": {
    "title": "Choreographer: Learning and Adapting Skills in Imagination",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "cfd232ade1fdee8f00d90a0c1e6148b8ee530e29",
    "semantic_title": "choreographer: learning and adapting skills in imagination",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=sKc6fgce1zs": {
    "title": "Learning About Progress From Experts",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "10c045a0e1e9b68a3e8a6cc2adb66bec96659984",
    "semantic_title": "learning about progress from experts",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=1_OGWcP1s9w": {
    "title": "Learning Fair Graph Representations via Automated Data Augmentations",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "adcd41e985a168530921d5e871e01788fbcc25d1",
    "semantic_title": "learning fair graph representations via automated data augmentations",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=lTt4KjHSsyl": {
    "title": "Emergence of Maps in the Memories of Blind Navigation Agents",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "e5774f164dbf5ad3642a4feee61cf9fad8a6bd36",
    "semantic_title": "emergence of maps in the memories of blind navigation agents",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=DjzBCrMBJ_p": {
    "title": "Spectral Augmentation for Self-Supervised Learning on Graphs",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "4fac6a8d86261484983729f3c7d466677d4cf359",
    "semantic_title": "spectral augmentation for self-supervised learning on graphs",
    "citation_count": 52,
    "authors": []
  },
  "https://openreview.net/forum?id=WOquZTLCBO1": {
    "title": "VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "7d200b868cb92657a68ac64c112a2cd0a4045f87",
    "semantic_title": "viper: provably efficient algorithm for offline rl with neural function approximation",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=8uu6JStuYm": {
    "title": "Self-supervised learning with rotation-invariant kernels",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "cde535c74312f61d71a7649afb474259c600433d",
    "semantic_title": "self-supervised learning with rotation-invariant kernels",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=QubsmJT_A0": {
    "title": "Neuromechanical Autoencoders: Learning to Couple Elastic and Neural Network Nonlinearity",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "7d882f565384d54043f3f2f61ca4530f14ff1018",
    "semantic_title": "neuromechanical autoencoders: learning to couple elastic and neural network nonlinearity",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=YJ7o2wetJ2": {
    "title": "VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "3fbe2e8413df0207c26ff393c9aaa8488e3ca4c3",
    "semantic_title": "vip: towards universal visual reward and representation via value-implicit pre-training",
    "citation_count": 354,
    "authors": []
  },
  "https://openreview.net/forum?id=74A-FDAyiL": {
    "title": "Subquadratic Algorithms for Kernel Matrices via Kernel Density Estimation",
    "volume": "spotlight",
    "abstract": "",
    "checked": false,
    "id": "c7ce06fad686f60649f0ebe38702ad16ab3353bb",
    "semantic_title": "sub-quadratic algorithms for kernel matrices via kernel density estimation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=aMXD8gqsIiC": {
    "title": "A Higher Precision Algorithm for Computing the $1$-Wasserstein Distance",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "495d7bae37257bf844e6b3e52de6241d89b02a3f",
    "semantic_title": "a higher precision algorithm for computing the $1$-wasserstein distance",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=HPdxC1THU8T": {
    "title": "Revisiting adapters with adversarial training",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "7bbd4e4d8405ffce1c58d1a33a8ae5b69e755529",
    "semantic_title": "revisiting adapters with adversarial training",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=Mj7K4lglGyj": {
    "title": "UNICORN: A Unified Backdoor Trigger Inversion Framework",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "984db0dc4dea4a6bd2cd48f5b497027492266761",
    "semantic_title": "unicorn: a unified backdoor trigger inversion framework",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=xkev3_np08z": {
    "title": "ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "ee5ceab9fa5f3bad231469923a03ad16184b51b9",
    "semantic_title": "expressive: a spatio-functional embedding for knowledge graph completion",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=-k7Lvk0GpBl": {
    "title": "Localized Randomized Smoothing for Collective Robustness Certification",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "7ee017cf2cbd83fe23f94280b0931bbf5416b1f0",
    "semantic_title": "localized randomized smoothing for collective robustness certification",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=cXMHQD-xQas": {
    "title": "Learning Probabilistic Topological Representations Using Discrete Morse Theory",
    "volume": "spotlight",
    "abstract": "Accurate delineation of fine-scale structures is a very important yet challenging problem. Existing methods use topological information as an additional training loss, but are ultimately making pixel-wise predictions. In this paper, we propose a novel deep learning based method to learn topological/structural. We use discrete Morse theory and persistent homology to construct a one-parameter family of structures as the topological/structural representation space. Furthermore, we learn a probabilistic model that can perform inference tasks in such a topological/structural representation space. Our method generates true structures rather than pixel-maps, leading to better topological integrity in automatic segmentation tasks. It also facilitates semi-automatic interactive annotation/proofreading via the sampling of structures and structure-aware uncertainty",
    "checked": true,
    "id": "0b25039487e493c60a92a797f40aa14d84283715",
    "semantic_title": "learning probabilistic topological representations using discrete morse theory",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=Vk-34OQ7rFo": {
    "title": "Model-based Causal Bayesian Optimization",
    "volume": "spotlight",
    "abstract": "How should we intervene on an unknown structural equation model to maximize a downstream variable of interest? This setting, also known as causal Bayesian optimization (CBO), has important applications in medicine, ecology, and manufacturing. Standard Bayesian optimization algorithms fail to effectively leverage the underlying causal structure. Existing CBO approaches assume noiseless measurements and do not come with guarantees. We propose the {\\em model-based causal Bayesian optimization algorithm (MCBO)} that learns a full system model instead of only modeling intervention-reward pairs. MCBO propagates epistemic uncertainty about the causal mechanisms through the graph and trades off exploration and exploitation via the optimism principle. We bound its cumulative regret, and obtain the first non-asymptotic bounds for CBO. Unlike in standard Bayesian optimization, our acquisition function cannot be evaluated in closed form, so we show how the reparameterization trick can be used to apply gradient-based optimizers. The resulting practical implementation of MCBO compares favorably with state-of-the-art approaches empirically",
    "checked": true,
    "id": "b8dc2c6f9ca7c0d55b0379d5067f67b3e834ee80",
    "semantic_title": "model-based causal bayesian optimization",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=KzkLAE49H9b": {
    "title": "Training language models to summarize narratives improves brain alignment",
    "volume": "spotlight",
    "abstract": "Building systems that achieve a deeper understanding of language is one of the central goals of natural language processing (NLP). Towards this goal, recent works have begun to train language models on narrative datasets which require extracting the most critical information by integrating across long contexts. However, it is still an open question whether these models are learning a deeper understanding of the text, or if the models are simply learning a heuristic to complete the task. This work investigates this further by turning to the one language processing system that truly understands complex language: the human brain. We show that training language models for deeper narrative understanding results in richer representations that have improved alignment to human brain activity. We further find that the improvements in brain alignment are larger for character names than for other discourse features, which indicates that these models are learning important narrative elements. Taken together, these results suggest that this type of training can indeed lead to deeper language understanding. These findings have consequences both for cognitive neuroscience by revealing some of the significant factors behind brain-NLP alignment, and for NLP by highlighting that understanding of long-range context can be improved beyond language modeling",
    "checked": true,
    "id": "357569763e23ebeab6ca1da8f33cde493e05dbc0",
    "semantic_title": "training language models to summarize narratives improves brain alignment",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=hhvkdRdWt1F": {
    "title": "Dual Algorithmic Reasoning",
    "volume": "spotlight",
    "abstract": "Neural Algorithmic Reasoning is an emerging area of machine learning which seeks to infuse algorithmic computation in neural networks, typically by training neural models to approximate steps of classical algorithms. In this context, much of the current work has focused on learning reachability and shortest path graph algorithms, showing that joint learning on similar algorithms is beneficial for generalisation. However, when targeting more complex problems, such \"similar\" algorithms become more difficult to find. Here, we propose to learn algorithms by exploiting duality of the underlying algorithmic problem. Many algorithms solve optimisation problems. We demonstrate that simultaneously learning the dual definition of these optimisation problems in algorithmic learning allows for better learning and qualitatively better solutions. Specifically, we exploit the max-flow min-cut theorem to simultaneously learn these two algorithms over synthetically generated graphs, demonstrating the effectiveness of the proposed approach. We then validate the real-world utility of our dual algorithmic reasoner by deploying it on a challenging brain vessel classification task, which likely depends on the vessels' flow properties. We demonstrate a clear performance gain when using our model within such a context, and empirically show that learning the max-flow and min-cut algorithms together is critical for achieving such a result",
    "checked": true,
    "id": "d996bfdcb5664c370293bd965080ce5178d59cc3",
    "semantic_title": "dual algorithmic reasoning",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=U_T8-5hClV": {
    "title": "A Primal-Dual Framework for Transformers and Neural Networks",
    "volume": "spotlight",
    "abstract": "Self-attention is key to the remarkable success of transformers in sequence modeling tasks including many applications in natural language processing and computer vision. Like neural network layers, these attention mechanisms are often developed by heuristics and experience. To provide a principled framework for constructing attention layers in transformers, we show that the self-attention corresponds to the support vector expansion derived from a support vector regression problem, whose primal formulation has the form of a neural network layer. Using our framework, we derive popular attention layers used in practice and propose two new attentions: 1) the Batch Normalized Attention (Attention-BN) derived from the batch normalization layer and 2) the Attention with Scaled Head (Attention-SH) derived from using less training data to fit the SVR model. We empirically demonstrate the advantages of the Attention-BN and Attention-SH in reducing head redundancy, increasing the model's accuracy, and improving the model's efficiency in a variety of practical applications including image and time-series classification",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=c9lAOPvQHS": {
    "title": "Fisher-Legendre (FishLeg) optimization of deep neural networks",
    "volume": "spotlight",
    "abstract": "Incorporating second-order gradient information (curvature) into optimization can dramatically reduce the number of iterations required to train machine learning models. In natural gradient descent, such information comes from the Fisher information matrix which yields a number of desirable properties. As exact natural gradient updates are intractable for large models, successful methods such as KFAC and sequels approximate the Fisher in a structured form that can easily be inverted. However, this requires model/layer-specific tensor algebra and certain approximations that are often difficult to justify. Here, we use ideas from Legendre-Fenchel duality to learn a direct and efficiently evaluated model for the product of the inverse Fisher with any vector, in an online manner, leading to natural gradient steps that get progressively more accurate over time despite noisy gradients. We prove that the resulting \"Fisher-Legendre\" (FishLeg) optimizer converges to a (global) minimum of non-convex functions satisfying the PL condition, which applies in particular to deep linear networks. On standard auto-encoder benchmarks, we show empirically that FishLeg outperforms standard first-order optimization methods, and performs on par with or better than other second-order methods, especially when using small batches. Thanks to its generality, we expect our approach to facilitate the handling of a variety neural network layers in future work",
    "checked": true,
    "id": "522d806be48fba2be02eeb11b7fbd9d0a88ab3b2",
    "semantic_title": "fisher-legendre (fishleg) optimization of deep neural networks",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=0Vv4H4Ch0la": {
    "title": "Capturing the Motion of Every Joint: 3D Human Pose and Shape Estimation with Independent Tokens",
    "volume": "spotlight",
    "abstract": "In this paper we present a novel method to estimate 3D human pose and shape from monocular videos. This task requires directly recovering pixel-alignment 3D human pose and body shape from monocular images or videos, which is challenging due to its inherent ambiguity. To improve precision, existing methods highly rely on the initialized mean pose and shape as prior estimates and parameter regression with an iterative error feedback manner. In addition, video-based approaches model the overall change over the image-level features to temporally enhance the single-frame feature, but fail to capture the rotational motion at the joint level, and cannot guarantee local temporal consistency. To address these issues, we propose a novel Transformer-based model with a design of independent tokens. First, we introduce three types of tokens independent of the image feature: \\textit{joint rotation tokens, shape token, and camera token}. By progressively interacting with image features through Transformer layers, these tokens learn to encode the prior knowledge of human 3D joint rotations, body shape, and position information from large-scale data, and are updated to estimate SMPL parameters conditioned on a given image. Second, benefiting from the proposed token-based representation, we further use a temporal model to focus on capturing the rotational temporal information of each joint, which is empirically conducive to preventing large jitters in local parts. Despite being conceptually simple, the proposed method attains superior performances on the 3DPW and Human3.6M datasets. Using ResNet-50 and Transformer architectures, it obtains 42.0 mm error on the PA-MPJPE metric of the challenging 3DPW, outperforming state-of-the-art counterparts by a large margin. Code will be publicly available\\footnote{\\url{https://github.com/yangsenius/INT_HMR_Model}}",
    "checked": true,
    "id": "79139657e26e4dca31405b36ac79ba69823c836a",
    "semantic_title": "capturing the motion of every joint: 3d human pose and shape estimation with independent tokens",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=lJdOlWg8td": {
    "title": "Efficient recurrent architectures through activity sparsity and sparse back-propagation through time",
    "volume": "spotlight",
    "abstract": "Recurrent neural networks (RNNs) are well suited for solving sequence tasks in resource-constrained systems due to their expressivity and low computational requirements. However, there is still a need to bridge the gap between what RNNs are capable of in terms of efficiency and performance and real-world application requirements. The memory and computational requirements arising from propagating the activations of all the neurons at every time step to every connected neuron, together with the sequential dependence of activations, contribute to the inefficiency of training and using RNNs. We propose a solution inspired by biological neuron dynamics that makes the communication between RNN units sparse and discrete. This makes the backward pass with backpropagation through time (BPTT) computationally sparse and efficient as well. We base our model on the gated recurrent unit (GRU), extending it with units that emit discrete events for communication triggered by a threshold so that no information is communicated to other units in the absence of events. We show theoretically that the communication between units, and hence the computation required for both the forward and backward passes, scales with the number of events in the network. Our model achieves efficiency without compromising task performance, demonstrating competitive performance compared to state-of-the-art recurrent network models in real-world tasks, including language modeling. The dynamic activity sparsity mechanism also makes our model well suited for novel energy-efficient neuromorphic hardware. Code is available at https://github.com/KhaleelKhan/EvNN/",
    "checked": true,
    "id": "30977307de111a3374f8afcf662e134d860e976f",
    "semantic_title": "efficient recurrent architectures through activity sparsity and sparse back-propagation through time",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=XVjTT1nw5z": {
    "title": "Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow",
    "volume": "spotlight",
    "abstract": "We present rectified flow, a simple approach to learning (neural) ordinary differential equation (ODE) models to transport between two empirically observed distributions $\\pi_0$ and $\\pi_1$, hence providing a unified solution to generative modeling and domain transfer, among various other tasks involving distribution transport. The idea of rectified flow is to learn the ODE to follow the straight paths connecting the points drawn from $\\pi_0$ and $\\pi_1$ as much as possible. This is achieved by solving a straightforward nonlinear least squares optimization problem, which can be easily scaled to large models without introducing extra parameters beyond standard supervised learning. The straight paths are the shortest paths between two points, and can be simulated exactly without time discretization and hence yield computationally efficient models. We show that, by learning a rectified flow from data, we effectively turn an arbitrary coupling of $\\pi_0$ and $\\pi_1$ to a new deterministic coupling with provably non-increasing convex transport costs. In addition, with a ``reflow\" procedure that iteratively learns a new rectified flow from the data bootstrapped from the previous one, we obtain a sequence of flows with increasingly straight paths, which can be simulated accurately with coarse time discretization in the inference phase. In empirical studies, we show that rectified flow performs superbly on image generation, image-to-image translation, and domain adaptation. In particular, on image generation and translation, our method yields nearly straight flows that give high quality results even with \\emph{a single Euler discretization step}. Code is available at \\url{https://github.com/gnobitab/RectifiedFlow}",
    "checked": true,
    "id": "244054a4254a2147e43a3dad9c124b9b7eb4a04a",
    "semantic_title": "flow straight and fast: learning to generate and transfer data with rectified flow",
    "citation_count": 1491,
    "authors": []
  },
  "https://openreview.net/forum?id=4t9q35BxGr": {
    "title": "Inequality phenomenon in $l_{\\infty}$-adversarial training, and its unrealized threats",
    "volume": "spotlight",
    "abstract": "The appearance of adversarial examples raises attention from both academia and industry. Along with the attack-defense arms race, adversarial training is the most effective against adversarial examples. However, we find inequality phenomena occur during the $l_{\\infty}$-adversarial training, that few features dominate the prediction made by the adversarially trained model. We systematically evaluate such inequality phenomena by extensive experiments and find such phenomena become more obvious when performing adversarial training with increasing adversarial strength (evaluated by $\\epsilon$). We hypothesize such inequality phenomena make $l_{\\infty}$-adversarially trained model less reliable than the standard trained model when few ``important features\" are influenced. To validate our hypothesis, we proposed two simple attacks that either perturb or replace important features with noise or occlusion. Experiments show that $l_{\\infty}$-adversarially trained model can be easily attacked when the few important features are influenced. Our work shed light on the limitation of the practicality of $l_{\\infty}$-adversarial training",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WH1yCa0TbB": {
    "title": "Learning Diffusion Bridges on Constrained Domains",
    "volume": "spotlight",
    "abstract": "Diffusion models have achieved promising results on generative learning recently. However, because diffusion processes are most naturally applied on the unconstrained Euclidean space $\\mathrm{R}^d$, key challenges arise for developing diffusion based models for learning data on constrained and structured domains. We present a simple and unified framework to achieve this that can be easily adopted to various types of domains, including product spaces of any type (be it bounded/unbounded, continuous/discrete, categorical/ordinal, or their mix). In our model, the diffusion process is driven by a drift force that is a sum of two terms: one singular force designed by $Doob's~ h$-$transform$ that ensures all outcomes of the process to belong to the desirable domain, and one non-singular neural force field that is trained to make sure the outcome follows the data distribution statistically. Experiments show that our methods perform superbly on generating tabular data, images, semantic segments and 3D point clouds",
    "checked": true,
    "id": "13fd50a1d3455501703176c7aec614886a2dfb42",
    "semantic_title": "learning diffusion bridges on constrained domains",
    "citation_count": 43,
    "authors": []
  },
  "https://openreview.net/forum?id=1_jFneF07YC": {
    "title": "Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations",
    "volume": "spotlight",
    "abstract": "In this paper, we show that recent advances in self-supervised representation learning enable unsupervised object discovery and semantic segmentation with a performance that matches the state of the field on supervised semantic segmentation 10 years ago. We propose a methodology based on unsupervised saliency masks and self-supervised feature clustering to kickstart object discovery followed by training a semantic segmentation network on pseudo-labels to bootstrap the system on images with multiple objects. We show that while being conceptually simple our proposed baseline is surprisingly strong. We present results on PASCAL VOC that go far beyond the current state of the art (50.0 mIoU), and we report for the first time results on MS COCO for the whole set of 81 classes: our method discovers 34 categories with more than 20% IoU, while obtaining an average IoU of 19.6 for all 81 categories",
    "checked": true,
    "id": "c399b8d44dac36982b0d0b2b037c74740fa3dca7",
    "semantic_title": "unsupervised semantic segmentation with self-supervised object-centric representations",
    "citation_count": 54,
    "authors": []
  },
  "https://openreview.net/forum?id=f0a_dWEYg-Td": {
    "title": "Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning",
    "volume": "spotlight",
    "abstract": "Indiscriminate data poisoning attacks are quite effective against supervised learning. However, not much is known about their impact on unsupervised contrastive learning (CL). This paper is the first to consider indiscriminate poisoning attacks of contrastive learning. We propose Contrastive Poisoning (CP), the first effective such attack on CL. We empirically show that Contrastive Poisoning, not only drastically reduces the performance of CL algorithms, but also attacks supervised learning models, making it the most generalizable indiscriminate poisoning attack. We also show that CL algorithms with a momentum encoder are more robust to indiscriminate poisoning, and propose a new countermeasure based on matrix completion. Code is available at: https://github.com/kaiwenzha/contrastive-poisoning",
    "checked": true,
    "id": "491eb37da128ef8c266636acbc7e1ba780e5c34f",
    "semantic_title": "indiscriminate poisoning attacks on unsupervised contrastive learning",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=lKOfilXucGB": {
    "title": "Decompositional Generation Process for Instance-Dependent Partial Label Learning",
    "volume": "spotlight",
    "abstract": "Partial label learning (PLL) is a typical weakly supervised learning problem, where each training example is associated with a set of candidate labels among which only one is true. Most existing PLL approaches assume that the incorrect labels in each training example are randomly picked as the candidate labels and model the generation process of the candidate labels in a simple way. However, these approaches usually do not perform as well as expected due to the fact that the generation process of the candidate labels is always instance-dependent. Therefore, it deserves to be modeled in a refined way. In this paper, we consider instance-dependent PLL and assume that the generation process of the candidate labels could decompose into two sequential parts, where the correct label emerges first in the mind of the annotator but then the incorrect labels related to the feature are also selected with the correct label as candidate labels due to uncertainty of labeling. Motivated by this consideration, we propose a novel PLL method that performs Maximum A Posterior(MAP) based on an explicitly modeled generation process of candidate labels via decomposed probability distribution models. Extensive experiments on manually corrupted benchmark datasets and real-world datasets validate the effectiveness of the proposed method",
    "checked": false,
    "id": "bbda9fb21942552d84d4d8ac70ee2236693bfc7a",
    "semantic_title": "decomposition-based generation process for instance-dependent partial label learning",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=UKr0MwZM6fL": {
    "title": "Building a Subspace of Policies for Scalable Continual Learning",
    "volume": "spotlight",
    "abstract": "The ability to continuously acquire new knowledge and skills is crucial for autonomous agents. Existing methods are typically based on either fixed-size models that struggle to learn a large number of diverse behaviors, or growing-size models that scale poorly with the number of tasks. In this work, we aim to strike a better balance between scalability and performance by designing a method whose size grows adaptively depending on the task sequence. We introduce Continual Subspace of Policies (CSP), a new approach that incrementally builds a subspace of policies for training a reinforcement learning agent on a sequence of tasks. The subspace's high expressivity allows CSP to perform well for many different tasks while growing more slowly than the number of tasks. Our method does not suffer from forgetting and also displays positive transfer to new tasks. CSP outperforms a number of popular baselines on a wide range of scenarios from two challenging domains, Brax (locomotion) and Continual World (robotic manipulation). Interactive visualizations of the subspace can be found at https://share.streamlit.io/continual-subspace/policies/main",
    "checked": true,
    "id": "bdcd8dd1c2051f063b651e3e94b47596c9827a3b",
    "semantic_title": "building a subspace of policies for scalable continual learning",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=KGV-GBh8fb": {
    "title": "Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization",
    "volume": "spotlight",
    "abstract": "Recent work has achieved remarkable zero-shot performance with multi-task prompted pretraining, but little has been understood. For the first time, we show that training on a small number of key tasks beats using all the training tasks, while removing these key tasks substantially hurts performance. We also find that these key tasks are mostly question answering (QA) tasks. These novel findings combined deepen our understanding about zero-shot generalization—training on certain tasks such as QA encodes general knowledge transferable to a wide range of tasks. In addition, to automate this procedure, we devise a method that (1) identifies key training tasks without observing the test tasks by examining the pairwise generalization results and (2) resamples training tasks for better data distribution. Empirically, our approach achieves improved results across various model scales and tasks",
    "checked": true,
    "id": "ab5f4f8ed92549a1765c89d1c467ab8d8b1992be",
    "semantic_title": "not all tasks are born equal: understanding zero-shot generalization",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=RQY2AXFMRiu": {
    "title": "Solving Constrained Variational Inequalities via a First-order Interior Point-based Method",
    "volume": "spotlight",
    "abstract": "We develop an interior-point approach to solve constrained variational inequality (cVI) problems. Inspired by the efficacy of the alternating direction method of multipliers (ADMM) method in the single-objective context, we generalize ADMM to derive a first-order method for cVIs, that we refer to as ADMM-based interior-point method for constrained VIs (ACVI). We provide convergence guarantees for ACVI in two general classes of problems: (i) when the operator is $\\xi$-monotone, and (ii) when it is monotone, some constraints are active and the game is not purely rotational. When the operator is in addition L-Lipschitz for the latter case, we match known lower bounds on rates for the gap function of $\\mathcal{O}(1/\\sqrt{K})$ and $\\mathcal{O}(1/K)$ for the last and average iterate, respectively. To the best of our knowledge, this is the first presentation of a first-order interior-point method for the general cVI problem that has a global convergence guarantee. Moreover, unlike previous work in this setting, ACVI provides a means to solve cVIs when the constraints are nontrivial. Empirical analyses demonstrate clear advantages of ACVI over common first-order methods. In particular, (i) cyclical behavior is notably reduced as our methods approach the solution from the analytic center, and (ii) unlike projection-based methods that zigzag when near a constraint, ACVI efficiently handles the constraints",
    "checked": true,
    "id": "b25fa22af7c3570342bd7ae30f114cdeee4fd0d2",
    "semantic_title": "solving constrained variational inequalities via a first-order interior point-based method",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=K96AogLDT2K": {
    "title": "Symmetric Pruning in Quantum Neural Networks",
    "volume": "spotlight",
    "abstract": "Many fundamental properties of a quantum system are captured by its Hamiltonian and ground state. Despite the significance, ground states preparation (GSP) is classically intractable for large-scale Hamiltonians. Quantum neural networks (QNNs), which exert the power of modern quantum machines, have emerged as a leading protocol to conquer this issue. As such, the performance enhancement of QNNs becomes the core in GSP. Empirical evidence showed that QNNs with handcraft symmetric ans\\\"atze generally experience better trainability than those with asymmetric ans\\\"atze, while theoretical explanations remain vague. To fill this knowledge gap, here we propose the effective quantum neural tangent kernel (EQNTK) and connect this concept with over-parameterization theory to quantify the convergence of QNNs towards the global optima. We uncover that the advance of symmetric ans\\\"atze attributes to their large EQNTK value with low effective dimension, which requests few parameters and quantum circuit depth to reach the over-parameterization regime permitting a benign loss landscape and fast convergence. Guided by EQNTK, we further devise a symmetric pruning (SP) scheme to automatically tailor a symmetric ansatz from an over-parameterized and asymmetric one to greatly improve the performance of QNNs when the explicit symmetry information of Hamiltonian is unavailable. Extensive numerical simulations are conducted to validate the analytical results of EQNTK and the effectiveness of SP",
    "checked": true,
    "id": "ff1e394c63e4487dff4e3a3b9d94b0dba7d82792",
    "semantic_title": "symmetric pruning in quantum neural networks",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=vuD2xEtxZcj": {
    "title": "Minimum Variance Unbiased N:M Sparsity for the Neural Gradients",
    "volume": "spotlight",
    "abstract": "In deep learning, fine-grained N:M sparsity reduces the data footprint and bandwidth of a General Matrix multiply (GEMM) up to x2, and doubles throughput by skipping computation of zero values. So far, it was mainly only used to prune weights to accelerate the forward and backward phases. We examine how this method can be used also for the neural gradients (i.e. loss gradients with respect to the intermediate neural layer outputs). To this end, we first establish a tensor-level optimality criteria. Previous works aimed to minimize the mean-square-error (MSE) of each pruned block. We show that while minimization of the MSE works fine for pruning the weights and activations, it catastrophically fails for the neural gradients. Instead, we show that accurate pruning of the neural gradients requires an unbiased minimum-variance pruning mask. We design such specialized masks, and find that in most cases, 1:2 sparsity is sufficient for training, and 2:4 sparsity is usually enough when this is not the case. Further, we suggest combining several such methods together in order to potentially speed up training even more. A reference implementation is supplied in the supplementary material",
    "checked": false,
    "id": "b96fc157c6035978188ac8bb24c469fcd24ab5d5",
    "semantic_title": "minimum variance unbiased n: m sparsity for the neural gradients",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=a2jNdqE2102": {
    "title": "Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models",
    "volume": "spotlight",
    "abstract": "Fully-parametric language models generally require a huge number of model parameters to store the necessary knowledge for solving multiple natural language tasks in zero/few-shot settings. In addition, it is hard to adapt to the evolving world knowledge without the costly model re-training. In this paper, we develop a novel semi-parametric language model architecture, Knowledge-in-Context (KiC), which empowers a parametric text-to-text language model with a knowledge-rich external memory. Specifically, the external memory contains six different types of knowledge: entity, dictionary, commonsense, event, script, and causality knowledge. For each input instance, the KiC model adaptively selects a knowledge type and retrieves the most helpful pieces of knowledge. The input instance along with its knowledge augmentation is fed into a text-to-text model (e.g., T5) to generate the output answer, where both the input and the output are in natural language forms after prompting. Interestingly, we find that KiC can be identified as a special mixture-of-experts (MoE) model, where the knowledge selector plays the role of a router that is used to determine the sequence-to-expert assignment in MoE. This key observation inspires us to develop a novel algorithm for training KiC with an instance-adaptive knowledge selector. As a knowledge-rich semi-parametric language model, KiC only needs a much smaller parametric part to achieve superior zero-shot performance on unseen tasks. By evaluating on 40+ different tasks, we show that KiC-Large with 770M parameters easily outperforms large language models that are 4-39x larger. In addition, KiC also exhibits emergent abilities at a much smaller model scale compared to the fully-parametric models",
    "checked": true,
    "id": "7ffb3a27a2a4da5c35472bd3a3a4dee8d40a6d86",
    "semantic_title": "knowledge-in-context: towards knowledgeable semi-parametric language models",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=JAezPMehaUu": {
    "title": "Mosaic Representation Learning for Self-supervised Visual Pre-training",
    "volume": "spotlight",
    "abstract": "Self-supervised learning has achieved significant success in learning visual representations without the need for manual annotation. To obtain generalizable representations, a meticulously designed data augmentation strategy is one of the most crucial parts. Recently, multi-crop strategies utilizing a set of small crops as positive samples have been shown to learn spatially structured features. However, it overlooks the diverse contextual backgrounds, which reduces the variance of the input views and degenerates the performance. To address this problem, we propose a mosaic representation learning framework (MosRep), consisting of a new data augmentation strategy that enriches the backgrounds of each small crop and improves the quality of visual representations. Specifically, we randomly sample numbers of small crops from different input images and compose them into a mosaic view, which is equivalent to introducing different background information for each small crop. Additionally, we further jitter the mosaic view to prevent memorizing the spatial locations of each crop. Along with optimization, our MosRep gradually extracts more discriminative features. Extensive experimental results demonstrate that our method improves the performance far greater than the multi-crop strategy on a series of downstream tasks, e.g., +7.4% and +4.9% than the multi-crop strategy on ImageNet-1K with 1% label and 10% label, respectively. Code is available at https://github.com/DerrickWang005/MosRep.git",
    "checked": true,
    "id": "a31c4426423e8e61bf53a196c8c0e851b0a2c3b4",
    "semantic_title": "mosaic representation learning for self-supervised visual pre-training",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=Cp-io_BoFaE": {
    "title": "FluidLab: A Differentiable Environment for Benchmarking Complex Fluid Manipulation",
    "volume": "spotlight",
    "abstract": "Humans manipulate various kinds of fluids in their everyday life: creating latte art, scooping floating objects from water, rolling an ice cream cone, etc. Using robots to augment or replace human labors in these daily settings remain as a challenging task due to the multifaceted complexities of fluids. Previous research in robotic fluid manipulation mostly consider fluids governed by an ideal, Newtonian model in simple task settings (e.g., pouring water into a container). However, the vast majority of real-world fluid systems manifest their complexities in terms of the fluid's complex material behaviors (e.g., elastoplastic deformation) and multi-component interactions (e.g. coffee and frothed milk when making latte art), both of which were well beyond the scope of the current literature. To evaluate robot learning algorithms on understanding and interacting with such complex fluid systems, a comprehensive virtual platform with versatile simulation capabilities and well-established tasks is needed. In this work, we introduce FluidLab, a simulation environment with a diverse set of manipulation tasks involving complex fluid dynamics. These tasks address interactions between solid and fluid as well as among multiple fluids. At the heart of our platform is a fully differentiable physics simulator, FluidEngine, providing GPU-accelerated simulations and gradient calculations for various material types and their couplings, extending the scope of the existing differentiable simulation engines. We identify several challenges for fluid manipulation learning by evaluating a set of reinforcement learning and trajectory optimization methods on our platform. To address these challenges, we propose several domain-specific optimization schemes coupled with differentiable physics, which are empirically shown to be effective in tackling optimization problems featured by fluid system's non-convex and non-smooth properties. Furthermore, we demonstrate reasonable sim-to-real transfer by deploying optimized trajectories in real-world settings. FluidLab is publicly available at: https://fluidlab2023.github.io",
    "checked": true,
    "id": "73003cb9f5c1b30cd495f31f70323b1b17b24ff3",
    "semantic_title": "fluidlab: a differentiable environment for benchmarking complex fluid manipulation",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=PqvMRDCJT9t": {
    "title": "Flow Matching for Generative Modeling",
    "volume": "spotlight",
    "abstract": "We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples---which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers",
    "checked": true,
    "id": "af68f10ab5078bfc519caae377c90ee6d9c504e9",
    "semantic_title": "flow matching for generative modeling",
    "citation_count": 2031,
    "authors": []
  },
  "https://openreview.net/forum?id=tVkrbkz42vc": {
    "title": "PAC-NeRF: Physics Augmented Continuum Neural Radiance Fields for Geometry-Agnostic System Identification",
    "volume": "spotlight",
    "abstract": "Existing approaches to system identification (estimating the physical parameters of an object) from videos assume known object geometries. This precludes their applicability in a vast majority of scenes where object geometries are complex or unknown. In this work, we aim to identify parameters characterizing a physical system from a set of multi-view videos without any assumption on object geometry or topology. To this end, we propose \"Physics Augmented Continuum Neural Radiance Fields\" (PAC-NeRF), to estimate both the unknown geometry and physical parameters of highly dynamic objects from multi-view videos. We design PAC-NeRF to only ever produce physically plausible states by enforcing the neural radiance field to follow the conservation laws of continuum mechanics. For this, we design a hybrid Eulerian-Lagrangian representation of the neural radiance field, i.e., we use the Eulerian grid representation for NeRF density and color fields, while advecting the neural radiance fields via Lagrangian particles. This hybrid Eulerian-Lagrangian representation seamlessly blends efficient neural rendering with the material point method (MPM) for robust differentiable physics simulation. We validate the effectiveness of our proposed framework on geometry and physical parameter estimation over a vast range of materials, including elastic bodies, plasticine, sand, Newtonian and non-Newtonian fluids, and demonstrate significant performance gain on most tasks",
    "checked": true,
    "id": "fa430898844074e44f7a855565378f8bd203ea8d",
    "semantic_title": "pac-nerf: physics augmented continuum neural radiance fields for geometry-agnostic system identification",
    "citation_count": 102,
    "authors": []
  },
  "https://openreview.net/forum?id=iPWiwWHc1V": {
    "title": "CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks",
    "volume": "spotlight",
    "abstract": "In this paper, we propose CLIP-Dissect, a new technique to automatically describe the function of individual hidden neurons inside vision networks. CLIP-Dissect leverages recent advances in multimodal vision/language models to label internal neurons with open-ended concepts without the need for any labeled data or human examples. We show that CLIP-Dissect provides more accurate descriptions than existing methods for last layer neurons where the ground-truth is available as well as qualitatively good descriptions for hidden layer neurons. In addition, our method is very flexible: it is model agnostic, can easily handle new concepts and can be extended to take advantage of better multimodal models in the future. Finally CLIP-Dissect is computationally efficient and can label all neurons from five layers of ResNet-50 in just 4 minutes, which is more than 10$\\times$ faster than existing methods. Our code is available at https://github.com/Trustworthy-ML-Lab/CLIP-dissect",
    "checked": true,
    "id": "57b064db445c8c1e6b08bc7a8499e6f2c8b67dbc",
    "semantic_title": "clip-dissect: automatic description of neuron representations in deep vision networks",
    "citation_count": 103,
    "authors": []
  },
  "https://openreview.net/forum?id=27uBgHuoSQ": {
    "title": "Data Continuity Matters: Improving Sequence Modeling with Lipschitz Regularizer",
    "volume": "spotlight",
    "abstract": "Sequence modeling is a core problem in machine learning, and various neural networks have been designed to process different types of sequence data. However, few attempts have been made to understand the inherent data property of sequence data, neglecting the critical factor that may significantly affect the performance of sequence modeling. In this paper, we theoretically and empirically analyze a generic property of sequence data, i.e., continuity, and connect this property with the performance of deep models. First, we empirically observe that different kinds of models for sequence modeling prefer data with different continuity. Then, we theoretically analyze the continuity preference of different models in both time and frequency domains. To further utilize continuity to improve sequence modeling, we propose a simple yet effective Lipschitz Regularizer, that can flexibly adjust data continuity according to model preferences, and bring very little extra computational cost. Extensive experiments on various tasks demonstrate that altering data continuity via Lipschitz Regularizer can largely improve the performance of many deep models for sequence modeling",
    "checked": true,
    "id": "4df628b6811ee63340ada6f687124941069f4881",
    "semantic_title": "data continuity matters: improving sequence modeling with lipschitz regularizer",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=iaYcJKpY2B_": {
    "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis",
    "volume": "spotlight",
    "abstract": "Program synthesis strives to generate a computer program as a solution to a given problem specification, expressed with input-output examples or natural language descriptions. The prevalence of large language models advances the state-of-the-art for program synthesis, though limited training resources and data impede open access to such models. To democratize this, we train and release a family of large language models up to 16.1B parameters, called CODEGEN, on natural language and programming language data, and open source the training library JAXFORMER. We show the utility of the trained model by demonstrating that it is competitive with the previous state-of-the-art on zero-shot Python code generation on HumanEval. We further investigate the multi-step paradigm for program synthesis, where a single program is factorized into multiple prompts specifying subproblems. To this end, we construct an open benchmark, Multi-Turn Programming Benchmark (MTPB), consisting of 115 diverse problem sets that are factorized into multi-turn prompts. Our analysis on MTPB shows that the same intent provided to CODEGEN in multi-turn fashion significantly improves program synthesis over that provided as a single turn. We make the training library JAXFORMER and model checkpoints available as open source contribution: https://github.com/salesforce/CodeGen",
    "checked": true,
    "id": "38115e80d805fb0fb8f090dc88ced4b24be07878",
    "semantic_title": "codegen: an open large language model for code with multi-turn program synthesis",
    "citation_count": 1184,
    "authors": []
  },
  "https://openreview.net/forum?id=xYlJRpzZtsY": {
    "title": "ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning",
    "volume": "spotlight",
    "abstract": "Large language models show improved downstream task performance when prompted to generate step-by-step reasoning to justify their final answers. These reasoning steps greatly improve model interpretability and verification, but objectively studying their correctness (independent of the final answer) is difficult without reliable methods for automatic evaluation. We simply do not know how often the stated reasoning steps actually support the final end task predictions. In this work, we present ROSCOE, a suite of interpretable, unsupervised automatic scores that improve and extend previous text generation evaluation metrics. To evaluate ROSCOE against baseline metrics, we design a typology of reasoning errors and collect synthetic and human evaluation scores on commonly used reasoning datasets. In contrast with existing metrics, ROSCOE can measure semantic consistency, logicality, informativeness, fluency, and factuality — among other traits — by leveraging properties of step-by-step rationales. We empirically verify the strength of our metrics on five human annotated and six programmatically perturbed diagnostics datasets - covering a diverse set of tasks that require reasoning skills and show that ROSCOE can consistently outperform baseline metrics",
    "checked": true,
    "id": "fe4e77394faf9bcc9d2b8ef16b42a75b2e2dd389",
    "semantic_title": "roscoe: a suite of metrics for scoring step-by-step reasoning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WUWJIV2Yxtp": {
    "title": "Re-calibrating Feature Attributions for Model Interpretation",
    "volume": "spotlight",
    "abstract": "The ability to interpret machine learning models is critical for high-stakes applications. Due to its desirable theoretical properties, path integration is a widely used scheme for feature attribution to interpret model predictions. However, the methods implementing this scheme currently rely on absolute attribution scores to eventually provide sensible interpretations. This not only contradicts the premise that the features with larger attribution scores are more relevant to the model prediction, but also conflicts with the theoretical settings for which the desirable properties of the attributions are proven. We address this by devising a method to first compute an appropriate reference for the path integration scheme. This reference further helps in identifying valid interpolation points on a desired integration path. The reference is computed in a gradient ascending direction on the model's loss surface, while the interpolations are performed by analyzing the model gradients and variations between the reference and the input. The eventual integration is effectively performed along a non-linear path. Our scheme can be incorporated into the existing integral-based attribution methods. We also devise an effective sampling and integration procedure that enables employing our scheme with multi-reference path integration efficiently. We achieve a marked performance boost for a range of integral-based attribution methods on both local and global evaluation metrics by enhancing them with our scheme. Our extensive results also show improved sensitivity, sanity preservation and model robustness with the proposed re-calibration of the attribution techniques with our method",
    "checked": true,
    "id": "723022abbc57e8dd7c6749610b16f1e2e2ab02e4",
    "semantic_title": "re-calibrating feature attributions for model interpretation",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=uLE3WF3-H_5": {
    "title": "Adversarial Diversity in Hanabi",
    "volume": "spotlight",
    "abstract": "Many Dec-POMDPs admit a qualitatively diverse set of ''reasonable'' joint policies, where reasonableness is indicated by symmetry equivariance, non-sabotaging behaviour and the graceful degradation of performance when paired with ad-hoc partners. Some of the work in diversity literature is concerned with generating these policies. Unfortunately, existing methods fail to produce teams of agents that are simultaneously diverse, high performing, and reasonable. In this work, we propose a novel approach, adversarial diversity (ADVERSITY), which is designed for turn-based Dec-POMDPs with public actions. ADVERSITY relies on off-belief learning to encourage reasonableness and skill, and on ''repulsive'' fictitious transitions to encourage diversity. We use this approach to generate new agents with distinct but reasonable play styles for the card game Hanabi and open-source our agents to be used for future research on (ad-hoc) coordination",
    "checked": true,
    "id": "09f6d1afea9ff7879725cd814cd027c55e56dec3",
    "semantic_title": "adversarial diversity in hanabi",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=ZsvWb6mJnMv": {
    "title": "Optimal Conservative Offline RL with General Function Approximation via Augmented Lagrangian",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "63888b247d2e42c9b9a64e15bbf4a89877fd797f",
    "semantic_title": "optimal conservative offline rl with general function approximation via augmented lagrangian",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=ZTCxT2t2Ru": {
    "title": "DocPrompting: Generating Code by Retrieving the Docs",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "0a39442979d6e678dd36bb443ad529c14e86a86e",
    "semantic_title": "docprompting: generating code by retrieving the docs",
    "citation_count": 163,
    "authors": []
  },
  "https://openreview.net/forum?id=HcUf-QwZeFh": {
    "title": "A System for Morphology-Task Generalization via Unified Representation and Behavior Distillation",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "8745c5b9522c11818418f64fdc880894faeaed16",
    "semantic_title": "a system for morphology-task generalization via unified representation and behavior distillation",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=9XFSbDPmdW": {
    "title": "Progress measures for grokking via mechanistic interpretability",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "f680d47a51a0e470fcb228bf0110c026535ead1b",
    "semantic_title": "progress measures for grokking via mechanistic interpretability",
    "citation_count": 532,
    "authors": []
  },
  "https://openreview.net/forum?id=oMsN9TYwJ0j": {
    "title": "PiFold: Toward effective and efficient protein inverse folding",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "61faa3d2d74dc98a098579008f64d35ada55a07a",
    "semantic_title": "pifold: toward effective and efficient protein inverse folding",
    "citation_count": 123,
    "authors": []
  },
  "https://openreview.net/forum?id=6qeBuZSo7Pr": {
    "title": "Planning Goals for Exploration",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "5045c2a64a4ea41d8da9ee8eb279498db1ff3d78",
    "semantic_title": "planning goals for exploration",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=Do9MOlwWHu0": {
    "title": "Learning Sparse Group Models Through Boolean Relaxation",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "819942d9ca2d5aa00b9a280c3a20a5ea8e20d0de",
    "semantic_title": "learning sparse group models through boolean relaxation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0cpM2ApF9p6": {
    "title": "MeshDiffusion: Score-based Generative 3D Mesh Modeling",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "b7a783e3897baed760fb91cd1289dd0e353377f5",
    "semantic_title": "meshdiffusion: score-based generative 3d mesh modeling",
    "citation_count": 183,
    "authors": []
  },
  "https://openreview.net/forum?id=n05upKp02kQ": {
    "title": "Partially Observable RL with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "7d23c472507450c1ac386cc2b1c20419d86da780",
    "semantic_title": "partially observable rl with b-stability: unified structural condition and sharp sample-efficient algorithms",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=fk7RbGibe1": {
    "title": "Domain Generalization via Heckman-type Selection Models",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "f445045eeb96f322aa219616382dd2b61398104d",
    "semantic_title": "domain generalization via heckman-type selection models",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=mbxz9Cjehr": {
    "title": "A CMDP-within-online framework for Meta-Safe Reinforcement Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": false,
    "id": "d27ec858f86a12cae3d6addf3426ecd2b3539344",
    "semantic_title": "provable guarantees for meta-safe reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P-73JPgRs0R": {
    "title": "Effects of Graph Convolutions in Multi-layer Networks",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "373d3b20dc5728d73d6e4323235bec50418a0395",
    "semantic_title": "effects of graph convolutions in multi-layer networks",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=nA5AZ8CEyow": {
    "title": "Post-hoc Concept Bottleneck Models",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "8545e249ab7a49f4a5abcfade395b90ffadb687a",
    "semantic_title": "post-hoc concept bottleneck models",
    "citation_count": 227,
    "authors": []
  },
  "https://openreview.net/forum?id=u2Pd6x794I": {
    "title": "When Source-Free Domain Adaptation Meets Learning with Noisy Labels",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "549f026dfe0dcd86ff8f081584f3385e5696fd8e",
    "semantic_title": "when source-free domain adaptation meets learning with noisy labels",
    "citation_count": 47,
    "authors": []
  },
  "https://openreview.net/forum?id=6taykzqcPD": {
    "title": "Neural Networks Efficiently Learn Low-Dimensional Representations with SGD",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "60b43c4ba92f14cd5a8a4c68ff232b592d9b19cd",
    "semantic_title": "neural networks efficiently learn low-dimensional representations with sgd",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=MYEap_OcQI": {
    "title": "Does Zero-Shot Reinforcement Learning Exist?",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "ac134b312d64b0bf01ccf15e60be4fa3016ee101",
    "semantic_title": "does zero-shot reinforcement learning exist?",
    "citation_count": 55,
    "authors": []
  },
  "https://openreview.net/forum?id=TfBHFLgv77": {
    "title": "Hyperbolic Deep Reinforcement Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "34b977f14fbe8e37d09eb64e88e92386ba42c36d",
    "semantic_title": "hyperbolic deep reinforcement learning",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=PbfgkZ2HdbE": {
    "title": "Learning Controllable Adaptive Simulation for Multi-resolution Physics",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "75cb343edaaa6a5322588bf6f3ef160742e9fbc0",
    "semantic_title": "learning controllable adaptive simulation for multi-resolution physics",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=Mpa3tRJFBb": {
    "title": "Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "fc721f4fd6260ed3b86c64eaa204375e18863aad",
    "semantic_title": "where to begin? on the impact of pre-training and initialization in federated learning",
    "citation_count": 89,
    "authors": []
  },
  "https://openreview.net/forum?id=F_EhNDSamN": {
    "title": "Parametrizing Product Shape Manifolds by Composite Networks",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "f7346fbddd4d3a433dbbd14f964905226427cdc1",
    "semantic_title": "parametrizing product shape manifolds by composite networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zKvm1ETDOq": {
    "title": "Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning?",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "2418bc3f97d1ee8d0caec7656af78343b83cabe3",
    "semantic_title": "is adversarial training really a silver bullet for mitigating data poisoning?",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=P3PJokAqGW": {
    "title": "Learning with Stochastic Orders",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "873faa4e9c3aefd5990746bb7380102d0f039820",
    "semantic_title": "learning with stochastic orders",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=6ve2CkeQe5S": {
    "title": "MEDFAIR: Benchmarking Fairness for Medical Imaging",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "bca9c389bdcc185eefc6cb2b57f5d93a2e4250c7",
    "semantic_title": "medfair: benchmarking fairness for medical imaging",
    "citation_count": 74,
    "authors": []
  },
  "https://openreview.net/forum?id=TUBpc5rqGA": {
    "title": "Neural Design for Genetic Perturbation Experiments",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "f52de3bba5becb383834ccaf03aba7790d87b793",
    "semantic_title": "neural design for genetic perturbation experiments",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=R98ZfMt-jE": {
    "title": "Efficient Discrete Multi Marginal Optimal Transport Regularization",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "0d18cc7327eea01378a07b52dcfca09b61ce743b",
    "semantic_title": "efficient discrete multi marginal optimal transport regularization",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=xSsW2Am-ukZ": {
    "title": "Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning Ticket's Mask?",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "3de645f0c1993cd3f3374ad747640a1aa6658a82",
    "semantic_title": "unmasking the lottery ticket hypothesis: what's encoded in a winning ticket's mask?",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=TatRHT_1cK": {
    "title": "Quantifying Memorization Across Neural Language Models",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "28c7e583d90ccfc5c3078dfc1d6b80a9ad90248d",
    "semantic_title": "quantifying memorization across neural language models",
    "citation_count": 703,
    "authors": []
  },
  "https://openreview.net/forum?id=AWZgXGmsbA": {
    "title": "Powderworld: A Platform for Understanding Generalization via Rich Task Distributions",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "2d41c403c8e9cff035778961e6be45b5e8182d1d",
    "semantic_title": "powderworld: a platform for understanding generalization via rich task distributions",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=kJUS5nD0vPB": {
    "title": "Out-of-Distribution Detection and Selective Generation for Conditional Language Models",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "94b6f6822f364cf7b1a3a9984667c009e2ec6a65",
    "semantic_title": "out-of-distribution detection and selective generation for conditional language models",
    "citation_count": 140,
    "authors": []
  },
  "https://openreview.net/forum?id=3UHoYrglYkG": {
    "title": "Differentially Private $L_2$-Heavy Hitters in the Sliding Window Model",
    "volume": "spotlight",
    "abstract": "",
    "checked": false,
    "id": "53bf4fafae1fcfe1621e5b00b15139f521ea3bcf",
    "semantic_title": "differentially private l2-heavy hitters in the sliding window model",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=ApF0dmi1_9K": {
    "title": "NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "7f26566298dd9b89eb3446cc0f4bd2d2fa8aceed",
    "semantic_title": "ntfields: neural time fields for physics-informed robot motion planning",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=rwo-ls5GqGn": {
    "title": "ZiCo: Zero-shot NAS via inverse Coefficient of Variation on Gradients",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "ef174c117cbe749517e5b282bc68b0e4e567bcba",
    "semantic_title": "zico: zero-shot nas via inverse coefficient of variation on gradients",
    "citation_count": 73,
    "authors": []
  },
  "https://openreview.net/forum?id=hQ9V5QN27eS": {
    "title": "Pink Noise Is All You Need: Colored Noise Exploration in Deep Reinforcement Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "4a06ec48e4b413ab2563273981018df82faac32e",
    "semantic_title": "pink noise is all you need: colored noise exploration in deep reinforcement learning",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=1mNssCWt_v": {
    "title": "STaSy: Score-based Tabular data Synthesis",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "6349332c9226c14561f9eb82162a198142cb2965",
    "semantic_title": "stasy: score-based tabular data synthesis",
    "citation_count": 73,
    "authors": []
  },
  "https://openreview.net/forum?id=k71IGLC8cfc": {
    "title": "A Unified Algebraic Perspective on Lipschitz Neural Networks",
    "volume": "spotlight",
    "abstract": "Important research efforts have focused on the design and training of neural networks with a controlled Lipschitz constant. The goal is to increase and sometimes guarantee the robustness against adversarial attacks. Recent promising techniques draw inspirations from different backgrounds to design 1-Lipschitz neural networks, just to name a few: convex potential layers derive from the discretization of continuous dynamical systems, Almost-Orthogonal-Layer proposes a tailored method for matrix rescaling. However, it is today important to consider the recent and promising contributions in the field under a common theoretical lens to better design new and improved layers. This paper introduces a novel algebraic perspective unifying various types of 1-Lipschitz neural networks, including the ones previously mentioned, along with methods based on orthogonality and spectral methods. Interestingly, we show that many existing techniques can be derived and generalized via finding analytical solutions of a common semidefinite programming (SDP) condition. We also prove that AOL biases the scaled weight to the ones which are close to the set of orthogonal matrices in a certain mathematical manner. Moreover, our algebraic condition, combined with the Gershgorin circle theorem, readily leads to new and diverse parameterizations for 1-Lipschitz network layers. Our approach, called SDP-based Lipschitz Layers (SLL), allows us to design non-trivial yet efficient generalization of convex potential layers. Finally, the comprehensive set of experiments on image classification shows that SLLs outperform previous approaches on certified robust accuracy. Code is available at https://github.com/araujoalexandre/Lipschitz-SLL-Networks",
    "checked": true,
    "id": "897759be42a5b59ab7c01c8021ec6a2e1079e043",
    "semantic_title": "a unified algebraic perspective on lipschitz neural networks",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=nZ2NtpolC5-": {
    "title": "The Influence of Learning Rule on Representation Dynamics in Wide Neural Networks",
    "volume": "spotlight",
    "abstract": "It is unclear how changing the learning rule of a deep neural network alters its learning dynamics and representations. To gain insight into the relationship between learned features, function approximation, and the learning rule, we analyze infinite-width deep networks trained with gradient descent (GD) and biologically-plausible alternatives including feedback alignment (FA), direct feedback alignment (DFA), and error modulated Hebbian learning (Hebb), as well as gated linear networks (GLN). We show that, for each of these learning rules, the evolution of the output function at infinite width is governed by a time varying effective neural tangent kernel (eNTK). In the lazy training limit, this eNTK is static and does not evolve, while in the rich mean-field regime this kernel's evolution can be determined self-consistently with dynamical mean field theory (DMFT). This DMFT enables comparisons of the feature and prediction dynamics induced by each of these learning rules. In the lazy limit, we find that DFA and Hebb can only learn using the last layer features, while full FA can utilize earlier layers with a scale determined by the initial correlation between feedforward and feedback weight matrices. In the rich regime, DFA and FA utilize a temporally evolving and depth-dependent NTK. Counterintuitively, we find that FA networks trained in the rich regime exhibit more feature learning if initialized with smaller correlation between the forward and backward pass weights. GLNs admit a very simple formula for their lazy limit kernel and preserve conditional Gaussianity of their preactivations under gating functions. Error modulated Hebb rules show very small task-relevant alignment of their kernels and perform most task relevant learning in the last layer",
    "checked": true,
    "id": "28553431f0da6329a6d3722036e2511c2d8a1da2",
    "semantic_title": "the influence of learning rule on representation dynamics in wide neural networks",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=sCYXJr3QJM8": {
    "title": "Few-shot Cross-domain Image Generation via Inference-time Latent-code Learning",
    "volume": "spotlight",
    "abstract": "In this work, our objective is to adapt a Deep generative model trained on a large-scale source dataset to multiple target domains with scarce data. Specifically, we focus on adapting a pre-trained Generative Adversarial Network (GAN) to a target domain without re-training the generator. Our method draws the motivation from the fact that out-of-distribution samples can be `embedded' onto the latent space of a pre-trained source-GAN. We propose to train a small latent-generation network during the inference stage, each time a batch of target samples is to be generated. These target latent codes are fed to the source-generator to obtain novel target samples. Despite using the same small set of target samples and the source generator, multiple independent training episodes of the latent-generation network results in the diversity of the generated target samples. Our method, albeit simple, can be used to generate data from multiple target distributions using a generator trained on a single source distribution. We demonstrate the efficacy of our surprisingly simple method in generating multiple target datasets with only a single source generator and a few target samples",
    "checked": true,
    "id": "ba68c0997556ae7b78ae31b2302e1a2740ef367e",
    "semantic_title": "few-shot cross-domain image generation via inference-time latent-code learning",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=DJEEqoAq7to": {
    "title": "RLx2: Training a Sparse Deep Reinforcement Learning Model from Scratch",
    "volume": "spotlight",
    "abstract": "Training deep reinforcement learning (DRL) models usually requires high computation costs. Therefore, compressing DRL models possesses immense potential for training acceleration and model deployment. However, existing methods that generate small models mainly adopt the knowledge distillation-based approach by iteratively training a dense network. As a result, the training process still demands massive computing resources. Indeed, sparse training from scratch in DRL has not been well explored and is particularly challenging due to non-stationarity in bootstrap training. In this work, we propose a novel sparse DRL training framework, \"the Rigged Reinforcement Learning Lottery\" (RLx2), which builds upon gradient-based topology evolution and is capable of training a sparse DRL model based entirely on a sparse network. Specifically, RLx2 introduces a novel multi-step TD target mechanism with a dynamic-capacity replay buffer to achieve robust value learning and efficient topology exploration in sparse models. It also reaches state-of-the-art sparse training performance in several tasks, showing $7.5\\times$-$20\\times$ model compression with less than $3\\%$ performance degradation and up to $20\\times$ and $50\\times$ FLOPs reduction for training and inference, respectively",
    "checked": true,
    "id": "b831edf994dcfba95706bb93790c7e2cf697ab80",
    "semantic_title": "rlx2: training a sparse deep reinforcement learning model from scratch",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=J6F3lLg4Kdp": {
    "title": "Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!",
    "volume": "spotlight",
    "abstract": "Sparse Neural Networks (SNNs) have received voluminous attention predominantly due to growing computational and memory footprints of consistently exploding parameter count in large-scale models. Similar to their dense counterparts, recent SNNs generalize just as well and are equipped with numerous favorable benefits (e.g., low complexity, high scalability, and robustness), sometimes even better than the original dense networks. As research effort is focused on developing increasingly sophisticated sparse algorithms, it is startling that a comprehensive benchmark to evaluate the effectiveness of these algorithms has been highly overlooked. In absence of a carefully crafted evaluation benchmark, most if not all, sparse algorithms are evaluated against fairly simple and naive tasks (eg. CIFAR-10/100, ImageNet, GLUE, etc.), which can potentially camouflage many advantages as well unexpected predicaments of SNNs. In pursuit of a more general evaluation and unveiling the true potential of sparse algorithms, we introduce \"Sparsity May Cry\" Benchmark (SMC-Bench), a collection of carefully-curated 4 diverse tasks with 10 datasets, that accounts for capturing a wide range of domain-specific and sophisticated knowledge. Our systemic evaluation of the most representative sparse algorithms reveals an important obscured observation: the state-of-the-art magnitude- and/or gradient-based sparse algorithms seemingly fail to perform on SMC-Bench when applied out-of-the-box, sometimes at significantly trivial sparsity as low as 5%. The observations seek the immediate attention of the sparsity research community to reconsider the highly proclaimed benefits of SNNs. We further conduct a thorough investigation into the reasons for the failure of common SNNs. Our analysis points out that such failure is intimately related to the \"lazy regime\" of large model training, which hints us with stronger pruning recipes that alleviate the failure on SMC-Bench (though still more or less suffering). By incorporating these well-thought and diverse tasks, SMC-Bench is designed to favor and encourage the development of more scalable and generalizable sparse algorithms. We open-source SMC-Bench to assist researchers in building next-generation sparse algorithms that scale and generalize: https://github.com/VITA-Group/SMC-Bench",
    "checked": true,
    "id": "fdacdbc6a00eeb42efe7f81848b0bc09be5ca997",
    "semantic_title": "sparsity may cry: let us fail (current) sparse neural networks together!",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=w1hwFUb_81": {
    "title": "Sparse MoE as the New Dropout: Scaling Dense and Self-Slimmable Transformers",
    "volume": "spotlight",
    "abstract": "Despite their remarkable achievement, gigantic transformers encounter significant drawbacks, including exorbitant computational and memory footprints during training, as well as severe collapse evidenced by a high degree of parameter redundancy. Sparsely-activated Mixture-of-Experts (SMoEs) have shown promise to mitigate the issue of training efficiency, yet they are prone to (1) $\\textit{redundant experts}$ due to representational collapse; and (2) $\\textit{poor expert scalability for inference and downstream fine-tuning}$, primarily due to overfitting of the learned routing policy to the number of activated experts during training. As recent research efforts are predominantly focused on improving routing policies to encourage expert specializations, this work focuses on $\\textit{exploring the overlooked scalability bottleneck of SMoEs}$ and leveraging it to effectively $\\textbf{scale dense transformers}$. To this end, we propose a new plug-and-play training framework, $\\textbf{SMoE-Dropout}$, to enable scaling transformers to better accuracy in their full capacity without collapse. Specifically, SMoE-Dropout consists of a $\\textit{randomly initialized and fixed}$ router network to activate experts and gradually increases the activated expert number as training progresses over time. Transformers trained by SMoE-Dropout naturally exhibit a $\\textbf{``self-slimmable\"}$ property subject to resource availability, offering smooth and consistent performance boosts with an increase in activated experts during inference or fine-tuning. Our extensive experiments across diverse transformer architectures on a variety of tasks demonstrate the superior performance and substantial computation savings of SMoE-Dropout, compared to dense training baselines with equivalent parameter counts. In particular, our trained BERT outperforms its densely trained counterpart with consistent improvements of {$1.03\\%$, $0.78\\%$, $1.09\\%$} on challenging reasoning tasks {$\\texttt{ASDiv-A}$, $\\texttt{MAWPS}$, $\\texttt{SVAMP}$}, respectively. Codes and models are available in https://github.com/VITA-Group/Random-MoE-as-Dropout",
    "checked": true,
    "id": "1462a0e5b7db47301bb0995db56426e1f4a0ac7d",
    "semantic_title": "sparse moe as the new dropout: scaling dense and self-slimmable transformers",
    "citation_count": 59,
    "authors": []
  },
  "https://openreview.net/forum?id=LfdEuhjR5GV": {
    "title": "Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks",
    "volume": "spotlight",
    "abstract": "Monocular Depth Estimation (MDE) is a critical component in applications such as autonomous driving. There are various attacks against MDE networks. These attacks, especially the physical ones, pose a great threat to the security of such systems. Traditional adversarial training method requires ground-truth labels and hence cannot be directly applied to self-supervised MDE that does not have depth ground truth. Some self-supervised model hardening technique (e.g., contrastive learning) ignores the domain knowledge of MDE and can hardly achieve optimal performance. In this work, we propose a novel adversarial training method for self-supervised MDE models based on view synthesis without using the depth ground truth. We improve adversarial robustness against physical-world attacks using $L_0$-norm-bounded perturbation in training. We compare our method with supervised learning-based and contrastive learning-based methods that are tailored for MDE. Results on two representative MDE networks show that we achieve better robustness against various adversarial attacks with nearly no benign performance degradation",
    "checked": true,
    "id": "32e07cc454af5249d34f005e277c307fdc2f638d",
    "semantic_title": "adversarial training of self-supervised monocular depth estimation against physical-world attacks",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=yHY9NbQJ5BP": {
    "title": "Sparsity-Constrained Optimal Transport",
    "volume": "spotlight",
    "abstract": "Regularized optimal transport (OT) is now increasingly used as a loss or as a matching layer in neural networks. Entropy-regularized OT can be computed using the Sinkhorn algorithm but it leads to fully-dense transportation plans, meaning that all sources are (fractionally) matched with all targets. To address this issue, several works have investigated quadratic regularization instead. This regularization preserves sparsity and leads to unconstrained and smooth (semi) dual objectives, that can be solved with off-the-shelf gradient methods. Unfortunately, quadratic regularization does not give direct control over the cardinality (number of nonzeros) of the transportation plan. We propose in this paper a new approach for OT with explicit cardinality constraints on the transportation plan. Our work is motivated by an application to sparse mixture of experts, where OT can be used to match input tokens such as image patches with expert models such as neural networks. Cardinality constraints ensure that at most $k$ tokens are matched with an expert, which is crucial for computational performance reasons. Despite the nonconvexity of cardinality constraints, we show that the corresponding (semi) dual problems are tractable and can be solved with first-order gradient methods. Our method can be thought as a middle ground between unregularized OT (recovered in the limit case $k=1$) and quadratically-regularized OT (recovered when $k$ is large enough). The smoothness of the objectives increases as $k$ increases, giving rise to a trade-off between convergence speed and sparsity of the optimal plan",
    "checked": true,
    "id": "a27d5e6140269f292da02c3e88b4235c83f49e9e",
    "semantic_title": "sparsity-constrained optimal transport",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=mMNimwRb7Gr": {
    "title": "Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection",
    "volume": "spotlight",
    "abstract": "Deep neural networks have witnessed huge successes in many challenging prediction tasks and yet they often suffer from out-of-distribution (OoD) samples, misclassifying them with high confidence. Recent advances show promising OoD detection performance for centralized training, and however, OoD detection in federated learning (FL) is largely overlooked, even though many security sensitive applications such as autonomous driving and voice recognition authorization are commonly trained using FL for data privacy concerns. The main challenge that prevents previous state-of-the-art OoD detection methods from being incorporated to FL is that they require large amount of real OoD samples. However, in real-world scenarios, such large-scale OoD training data can be costly or even infeasible to obtain, especially for resource-limited local devices. On the other hand, a notorious challenge in FL is data heterogeneity where each client collects non-identically and independently distributed (non-iid) data. We propose to take advantage of such heterogeneity and turn the curse into a blessing that facilitates OoD detection in FL. The key is that for each client, non-iid data from other clients (unseen external classes) can serve as an alternative to real OoD samples. Specifically, we propose a novel Federated Out-of-Distribution Synthesizer (FOSTER), which learns a class-conditional generator to synthesize virtual external-class OoD samples, and maintains data confidentiality and communication efficiency required by FL. Experimental results show that our method outperforms the state-of-the-art by 2.49%, 2.88%, 1.42% AUROC, and 0.01%, 0.89%, 1.74% ID accuracy, on CIFAR-10, CIFAR-100, and STL10, respectively",
    "checked": true,
    "id": "195d86d6b6a8420e9553fdbfc67cdfa4c87179aa",
    "semantic_title": "turning the curse of heterogeneity in federated learning into a blessing for out-of-distribution detection",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=j6zUzrapY3L": {
    "title": "DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion",
    "volume": "spotlight",
    "abstract": "Real-world data generation often involves complex inter-dependencies among instances, violating the IID-data hypothesis of standard learning paradigms and posing a challenge for uncovering the geometric structures for learning desired instance representations. To this end, we introduce an energy constrained diffusion model which encodes a batch of instances from a dataset into evolutionary states that progressively incorporate other instances' information by their interactions. The diffusion process is constrained by descent criteria w.r.t. a principled energy function that characterizes the global consistency of instance representations over latent structures. We provide rigorous theory that implies closed-form optimal estimates for the pairwise diffusion strength among arbitrary instance pairs, which gives rise to a new class of neural encoders, dubbed as DIFFormer (diffusion-based Transformers), with two instantiations: a simple version with linear complexity for prohibitive instance numbers, and an advanced version for learning complex structures. Experiments highlight the wide applicability of our model as a general-purpose encoder backbone with superior performance in various tasks, such as node classification on large graphs, semi-supervised image/text classification, and spatial-temporal dynamics prediction. The codes are available at https://github.com/qitianwu/DIFFormer",
    "checked": true,
    "id": "9b4f564e5d33625fa88fc4e1045e9d5681fa0cca",
    "semantic_title": "difformer: scalable (graph) transformers induced by energy constrained diffusion",
    "citation_count": 108,
    "authors": []
  },
  "https://openreview.net/forum?id=d3QNWD_pcFv": {
    "title": "Neural Lagrangian Schr\\\"{o}dinger Bridge: Diffusion Modeling for Population Dynamics",
    "volume": "spotlight",
    "abstract": "Population dynamics is the study of temporal and spatial variation in the size of populations of organisms and is a major part of population ecology. One of the main difficulties in analyzing population dynamics is that we can only obtain observation data with coarse time intervals from fixed-point observations due to experimental costs or measurement constraints. Recently, modeling population dynamics by using continuous normalizing flows (CNFs) and dynamic optimal transport has been proposed to infer the sample trajectories from a fixed-point observed population. While the sample behavior in CNFs is deterministic, the actual sample in biological systems moves in an essentially random yet directional manner. Moreover, when a sample moves from point A to point B in dynamical systems, its trajectory typically follows the principle of least action in which the corresponding action has the smallest possible value. To satisfy these requirements of the sample trajectories, we formulate the Lagrangian Schrödinger bridge (LSB) problem and propose to solve it approximately by modeling the advection-diffusion process with regularized neural SDE. We also develop a model architecture that enables faster computation of the loss function. Experimental results show that the proposed method can efficiently approximate the population-level dynamics even for high-dimensional data and that using the prior knowledge introduced by the Lagrangian enables us to estimate the sample-level dynamics with stochastic behavior",
    "checked": false,
    "id": "a48678440842cdf7681cb1560d5ad2971b9d4052",
    "semantic_title": "neural lagrangian schrödinger bridge",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=QC10RmRbZy9": {
    "title": "Loss Landscapes are All You Need: Neural Network Generalization Can Be Explained Without the Implicit Bias of Gradient Descent",
    "volume": "spotlight",
    "abstract": "It is commonly believed that the implicit regularization of optimizers is needed for neural networks to generalize in the overparameterized regime. In this paper, we observe experimentally that this implicit regularization behavior is {\\em generic}, i.e. it does not depend strongly on the choice of optimizer. We demonstrate this by training neural networks using several gradient-free optimizers, which do not benefit from properties that are often attributed to gradient-based optimizers. This includes a guess-and-check optimizer that generates uniformly random parameter vectors until finding one that happens to achieve perfect train accuracy, and a zeroth-order Pattern Search optimizer that uses no gradient computations. In the low sample and few-shot regimes, where zeroth order optimizers are most computationally tractable, we find that these non-gradient optimizers achieve test accuracy comparable to SGD. The code to reproduce results can be found at https://github.com/Ping-C/optimizer",
    "checked": true,
    "id": "e4f0ab1408504c3873a849d341ec63fbca899534",
    "semantic_title": "loss landscapes are all you need: neural network generalization can be explained without the implicit bias of gradient descent",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=h5OpjGd_lo6": {
    "title": "Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning",
    "volume": "spotlight",
    "abstract": "There is a rising interest in further exploring the zero-shot learning potential of large pre-trained language models (PLMs). A new paradigm called data-generation-based zero-shot learning has achieved impressive success. In this paradigm, the synthesized data from the PLM acts as the carrier of knowledge, which is used to train a task-specific model with orders of magnitude fewer parameters than the PLM, achieving both higher performance and efficiency than prompt-based zero-shot learning methods on PLMs. The main hurdle of this approach is that the synthesized data from PLM usually contains a significant portion of low-quality samples. Fitting on such data will greatly hamper the performance of the task-specific model, making it unreliable for deployment. Previous methods remedy this issue mainly by filtering synthetic data using heuristic metrics(e.g., output confidence), or refining the data with the help of a human expert, which comes with excessive manual tuning or expensive costs. In this paper, we propose a novel noise-robust re-weighting framework SunGen to automatically construct high-quality data for zero-shot classification problems. Our framework features the ability to learn the sample weights indicating data quality without requiring any human annotation. We theoretically and empirically verify the ability of our method to help construct good-quality synthetic datasets. Notably, SunGen-LSTM yields a 9.8% relative improvement than the baseline on average accuracy across eight different established text classification tasks",
    "checked": true,
    "id": "6f7e03e4ccd26c762090e25dc5d2eb1e1f8c641d",
    "semantic_title": "self-guided noise-free data generation for efficient zero-shot learning",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=aBWnqqsuot7": {
    "title": "D4FT: A Deep Learning Approach to Kohn-Sham Density Functional Theory",
    "volume": "spotlight",
    "abstract": "Kohn-Sham Density Functional Theory (KS-DFT) has been traditionally solved by the Self-Consistent Field (SCF) method. Behind the SCF loop is the physics intuition of solving a system of non-interactive single-electron wave functions under an effective potential. In this work, we propose a deep learning approach to KS-DFT. First, in contrast to the conventional SCF loop, we propose to directly minimize the total energy by reparameterizing the orthogonal constraint as a feed-forward computation. We prove that such an approach has the same expressivity as the SCF method, yet reduces the computational complexity from O(N^4) to O(N^3). Second, the numerical integration which involves a summation over the quadrature grids can be amortized to the optimization steps. At each step, stochastic gradient descent (SGD) is performed with a sampled minibatch of the grids. Extensive experiments are carried out to demonstrate the advantage of our approach in terms of efficiency and stability. In addition, we show that our approach enables us to explore more complex neural-based wave functions",
    "checked": true,
    "id": "3991a235714f622aeaa2f1a5036398fcaf7d0fa2",
    "semantic_title": "d4ft: a deep learning approach to kohn-sham density functional theory",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=kPLzOfPfA2l": {
    "title": "Warping the Space: Weight Space Rotation for Class-Incremental Few-Shot Learning",
    "volume": "spotlight",
    "abstract": "Class-incremental few-shot learning, where new sets of classes are provided sequentially with only a few training samples, presents a great challenge due to catastrophic forgetting of old knowledge and overfitting caused by lack of data. During finetuning on new classes, the performance on previous classes deteriorates quickly even when only a small fraction of parameters are updated, since the previous knowledge is broadly associated with most of the model parameters in the original parameter space. In this paper, we introduce WaRP, the \\textit{weight space rotation process}, which transforms the original parameter space into a new space so that we can push most of the previous knowledge compactly into only a few important parameters. By properly identifying and freezing these key parameters in the new weight space, we can finetune the remaining parameters without affecting the knowledge of previous classes. As a result, WaRP provides an additional room for the model to effectively learn new classes in future incremental sessions. Experimental results confirm the effectiveness of our solution and show the improved performance over the state-of-the-art methods",
    "checked": true,
    "id": "a49d885d13d3aa763f0966acdb947708751a3750",
    "semantic_title": "warping the space: weight space rotation for class-incremental few-shot learning",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=tYIMtogyee": {
    "title": "Pre-training via Denoising for Molecular Property Prediction",
    "volume": "spotlight",
    "abstract": "Many important problems involving molecular property prediction from 3D structures have limited data, posing a generalization challenge for neural networks. In this paper, we describe a pre-training technique based on denoising that achieves a new state-of-the-art in molecular property prediction by utilizing large datasets of 3D molecular structures at equilibrium to learn meaningful representations for downstream tasks. Relying on the well-known link between denoising autoencoders and score-matching, we show that the denoising objective corresponds to learning a molecular force field -- arising from approximating the Boltzmann distribution with a mixture of Gaussians -- directly from equilibrium structures. Our experiments demonstrate that using this pre-training objective significantly improves performance on multiple benchmarks, achieving a new state-of-the-art on the majority of targets in the widely used QM9 dataset. Our analysis then provides practical insights into the effects of different factors -- dataset sizes, model size and architecture, and the choice of upstream and downstream datasets -- on pre-training",
    "checked": true,
    "id": "082aa5c92202719a5740c8e2edee65cc4bf3ccfa",
    "semantic_title": "pre-training via denoising for molecular property prediction",
    "citation_count": 136,
    "authors": []
  },
  "https://openreview.net/forum?id=-9PVqZ-IR_": {
    "title": "Martingale Posterior Neural Processes",
    "volume": "spotlight",
    "abstract": "A Neural Process (NP) estimates a stochastic process implicitly defined with neural networks given a stream of data, rather than pre-specifying priors already known, such as Gaussian processes. An ideal NP would learn everything from data without any inductive biases, but in practice, we often restrict the class of stochastic processes for the ease of estimation. One such restriction is the use of a finite-dimensional latent variable accounting for the uncertainty in the functions drawn from NPs. Some recent works show that this can be improved with more \"data-driven\" source of uncertainty such as bootstrapping. In this work, we take a different approach based on the martingale posterior, a recently developed alternative to Bayesian inference. For the martingale posterior, instead of specifying prior-likelihood pairs, a predictive distribution for future data is specified. Under specific conditions on the predictive distribution, it can be shown that the uncertainty in the generated future data actually corresponds to the uncertainty of the implicitly defined Bayesian posteriors. Based on this result, instead of assuming any form of the latent variables, we equip a NP with a predictive distribution implicitly defined with neural networks and use the corresponding martingale posteriors as the source of uncertainty. The resulting model, which we name as Martingale Posterior Neural Process (MPNP), is demonstrated to outperform baselines on various tasks",
    "checked": true,
    "id": "f63d6770bc9a7ee235b791f839cfc1edfbfe2c9b",
    "semantic_title": "martingale posterior neural processes",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=bvpkw7UIRdU": {
    "title": "On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation",
    "volume": "spotlight",
    "abstract": "A good automatic evaluation metric for language generation ideally correlates highly with human judgements of text quality. Yet, there is a dearth of such metrics, which inhibits the rapid and efficient progress of language generators. One exception is the recently proposed Mauve. In theory, Mauve measures an information-theoretic divergence between two probability distributions over strings: one representing the language generator under evaluation; the other representing the true natural language distribution. Mauve's authors argue that its success comes from the qualitative properties of their proposed divergence. Yet in practice, as this divergence is uncomputable, Mauve approximates it by measuring the divergence between multinomial distributions over clusters instead, where cluster assignments are attained by grouping strings based on a pretrained language model's embeddings. As we show, however, this is not a tight approximation---in either theory or practice. This begs the question: why does Mauve work so well? In this work, we show that \\mauve was right for the wrong reasons, and that its newly proposed divergence is not necessary for its high performance. In fact, classical divergences paired with its proposed cluster-based approximation may actually serve as better evaluation metrics. We finish the paper with a probing analysis; this analysis leads us to conclude that---by encoding syntactic- and coherence-level features of text, while ignoring surface-level features---such cluster-based approximations to string distributions may simply be better for evaluating state-of-the-art language generators",
    "checked": true,
    "id": "8ce3f729c24c50882d5e4fc2e3f7de882c99308a",
    "semantic_title": "on the usefulness of embeddings, clusters and strings for text generation evaluation",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=C-xa_D3oTj6": {
    "title": "DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems",
    "volume": "spotlight",
    "abstract": "Muscle-actuated organisms are capable of learning an unparalleled diversity of dexterous movements despite their vast amount of muscles. Reinforcement learning (RL) on large musculoskeletal models, however, has not been able to show similar performance. We conjecture that ineffective exploration in large overactuated action spaces is a key problem. This is supported by the finding that common exploration noise strategies are inadequate in synthetic examples of overactuated systems. We identify differential extrinsic plasticity (DEP), a method from the domain of self-organization, as being able to induce state-space covering exploration within seconds of interaction. By integrating DEP into RL, we achieve fast learning of reaching and locomotion in musculoskeletal systems, outperforming current approaches in all considered tasks in sample efficiency and robustness",
    "checked": true,
    "id": "04615a9955bce148aa7ba29e864389c26e10523a",
    "semantic_title": "dep-rl: embodied exploration for reinforcement learning in overactuated and musculoskeletal systems",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=PEgBEB74JjB": {
    "title": "The Symmetric Generalized Eigenvalue Problem as a Nash Equilibrium",
    "volume": "spotlight",
    "abstract": "The symmetric generalized eigenvalue problem (SGEP) is a fundamental concept in numerical linear algebra. It captures the solution of many classical machine learning problems such as canonical correlation analysis, independent components analysis, partial least squares, linear discriminant analysis, principal components and others. Despite this, most general solvers are prohibitively expensive when dealing with *streaming data sets* (i.e., minibatches) and research has instead concentrated on finding efficient solutions to specific problem instances. In this work, we develop a game-theoretic formulation of the top-$k$ SGEP whose Nash equilibrium is the set of generalized eigenvectors. We also present a parallelizable algorithm with guaranteed asymptotic convergence to the Nash. Current state-of-the-art methods require $\\mathcal{O}(d^2k)$ runtime complexity per iteration which is prohibitively expensive when the number of dimensions ($d$) is large. We show how to modify this parallel approach to achieve $\\mathcal{O}(dk)$ runtime complexity. Empirically we demonstrate that this resulting algorithm is able to solve a variety of SGEP problem instances including a large-scale analysis of neural network activations",
    "checked": true,
    "id": "63f11a67a80a6795f7c3ce18d2761a3f42faac1e",
    "semantic_title": "the symmetric generalized eigenvalue problem as a nash equilibrium",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n-bvaLSCC78": {
    "title": "EA-HAS-Bench: Energy-aware Hyperparameter and Architecture Search Benchmark",
    "volume": "spotlight",
    "abstract": "The energy consumption for training deep learning models is increasing at an alarming rate due to the growth of training data and model scale, resulting in a negative impact on carbon neutrality. Energy consumption is an especially pressing issue for AutoML algorithms because it usually requires repeatedly training large numbers of computationally intensive deep models to search for optimal configurations. This paper takes one of the most essential steps in developing energy-aware (EA) NAS methods, by providing a benchmark that makes EA-NAS research more reproducible and accessible. Specifically, we present the first large-scale energy-aware benchmark that allows studying AutoML methods to achieve better trade-offs between performance and search energy consumption, named EA-HAS-Bench. EA-HAS-Bench provides a large-scale architecture/hyperparameter joint search space, covering diversified configurations related to energy consumption. Furthermore, we propose a novel surrogate model specially designed for large joint search space, which proposes a Bezier curve-based model to predict learning curves with unlimited shape and length. Based on the proposed dataset, we new energy-aware AutoML method that arms existing AutoML algorithms to consider the search energy consumption, and our experiments show that the modified energy-aware AutoML methods achieve a better trade-off between energy consumption and model performance",
    "checked": true,
    "id": "4863d3546ee8cd591d2e18f4b1bfaf492de4ea3e",
    "semantic_title": "ea-has-bench: energy-aware hyperparameter and architecture search benchmark",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=WAgXmT8BeRj": {
    "title": "MARS: Meta-learning as Score Matching in the Function Space",
    "volume": "spotlight",
    "abstract": "Meta-learning aims to extract useful inductive biases from a set of related datasets. In Bayesian meta-learning, this is typically achieved by constructing a prior distribution over neural network parameters. However, specifying families of computationally viable prior distributions over the high-dimensional neural network parameters is difficult. As a result, existing approaches resort to meta-learning restrictive diagonal Gaussian priors, severely limiting their expressiveness and performance. To circumvent these issues, we approach meta-learning through the lens of functional Bayesian neural network inference which views the prior as a stochastic process and performs inference in the function space. Specifically, we view the meta-training tasks as samples from the data-generating process and formalize meta-learning as empirically estimating the law of this stochastic process. Our approach can seamlessly acquire and represent complex prior knowledge by meta-learning the score function of the data-generating process marginals instead of parameter space priors. In a comprehensive benchmark, we demonstrate that our method achieves state-of-the-art performance in terms of predictive accuracy and substantial improvements in the quality of uncertainty estimates",
    "checked": true,
    "id": "a6b51458ebfa5160c0d292a413c93ec83a228ffd",
    "semantic_title": "mars: meta-learning as score matching in the function space",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=KDhFkA6MQsW": {
    "title": "Faster Gradient-Free Methods for Escaping Saddle Points",
    "volume": "spotlight",
    "abstract": "Escaping from saddle points has become an important research topic in non-convex optimization. In this paper, we study the case when calculations of explicit gradients are expensive or even infeasible, and only function values are accessible. Currently, there have two types of gradient-free (zeroth-order) methods based on random perturbation and negative curvature finding proposed to escape saddle points efficiently and converge to an $\\epsilon$-approximate second-order stationary point. Nesterov's accelerated gradient descent (AGD) method can escape saddle points faster than gradient descent (GD) which have been verified in first-order algorithms. However, whether AGD could accelerate the gradient-free methods is still unstudied. To unfold this mystery, in this paper, we propose two accelerated variants for the two types of gradient-free methods of escaping saddle points. We show that our algorithms can find an $\\epsilon$-approximate second-order stationary point with $\\tilde{\\mathcal{O}}(1/\\epsilon^{1.75})$ iteration complexity and $\\tilde{\\mathcal{O}}(d/\\epsilon^{1.75})$ oracle complexity, where $d$ is the problem dimension. Thus, our methods achieve a comparable convergence rate to their first-order counterparts and have fewer oracle complexity compared to prior derivative-free methods for finding second-order stationary points",
    "checked": true,
    "id": "825e35abd5c40969132e6b643cde5e6cb4f92046",
    "semantic_title": "faster gradient-free methods for escaping saddle points",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=xjxUjHa_Wpa": {
    "title": "VA-DepthNet: A Variational Approach to Single Image Depth Prediction",
    "volume": "spotlight",
    "abstract": "We introduce VA-DepthNet, a simple, effective, and accurate deep neural network approach for the single-image depth prediction (SIDP) problem. The proposed approach advocates using classical first-order variational constraints for this problem. While state-of-the-art deep neural network methods for SIDP learn the scene depth from images in a supervised setting, they often overlook the invaluable invariances and priors in the rigid scene space, such as the regularity of the scene. The paper's main contribution is to reveal the benefit of classical and well-founded variational constraints in the neural network design for the SIDP task. It is shown that imposing first-order variational constraints in the scene space together with popular encoder-decoder-based network architecture design provides excellent results for the supervised SIDP task. The imposed first-order variational constraint makes the network aware of the depth gradient in the scene space, i.e., regularity. The paper demonstrates the usefulness of the proposed approach via extensive evaluation and ablation analysis over several benchmark datasets, such as KITTI, NYU Depth V2, and SUN RGB-D. The VA-DepthNet at test time shows considerable improvements in depth prediction accuracy compared to the prior art and is accurate also at high-frequency regions in the scene space. At the time of writing this paper, our method---labeled as VA-DepthNet, when tested on the KITTI depth-prediction evaluation set benchmarks, shows state-of-the-art results, and is the top-performing published approach",
    "checked": true,
    "id": "4983b3555f3abf02c2bb00808f2b0d48881eaf32",
    "semantic_title": "va-depthnet: a variational approach to single image depth prediction",
    "citation_count": 65,
    "authors": []
  },
  "https://openreview.net/forum?id=_CDixzkzeyb": {
    "title": "Prompt-to-Prompt Image Editing with Cross-Attention Control",
    "volume": "spotlight",
    "abstract": "Recent large-scale text-driven synthesis diffusion models have attracted much attention thanks to their remarkable capabilities of generating highly diverse images that follow given text prompts. Therefore, it is only natural to build upon these synthesis models to provide text-driven image editing capabilities. However, Editing is challenging for these generative models, since an innate property of an editing technique is to preserve some content from the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome. State-of-the-art methods mitigate this by requiring the users to provide a spatial mask to localize the edit, hence, ignoring the original structure and content within the masked region. In this paper, we pursue an intuitive prompt-to-prompt editing framework, where the edits are controlled by text only. We analyze a text-conditioned model in depth and observe that the cross-attention layers are the key to controlling the relation between the spatial layout of the image to each word in the prompt. With this observation, we propose to control the attention maps along the diffusion process. Our approach enables us to monitor the synthesis process by editing the textual prompt only, paving the way to a myriad of caption-based editing applications such as localized editing by replacing a word, global editing by adding a specification, and even controlling the extent to which a word is reflected in the image. We present our results over diverse images and prompts with different text-to-image models, demonstrating high-quality synthesis and fidelity to the edited prompts",
    "checked": false,
    "id": "04e541391e8dce14d099d00fb2c21dbbd8afe87f",
    "semantic_title": "prompt-to-prompt image editing with cross attention control",
    "citation_count": 2068,
    "authors": []
  },
  "https://openreview.net/forum?id=3lge0p5o-M-": {
    "title": "DiffEdit: Diffusion-based semantic image editing with mask guidance",
    "volume": "spotlight",
    "abstract": "Image generation has recently seen tremendous advances, with diffusion models allowing to synthesize convincing images for a large variety of text prompts. In this article, we propose DiffEdit, a method to take advantage of text-conditioned diffusion models for the task of semantic image editing, where the goal is to edit an image based on a text query. Semantic image editing is an extension of image generation, with the additional constraint that the generated image should be as similar as possible to a given input image. Current editing methods based on diffusion models usually require to provide a mask, making the task much easier by treating it as a conditional inpainting task. In contrast, our main contribution is able to automatically generate a mask highlighting regions of the input image that need to be edited, by contrasting predictions of a diffusion model conditioned on different text prompts. Moreover, we rely on latent inference to preserve content in those regions of interest and show excellent synergies with mask-based diffusion. DiffEdit achieves state-of-the-art editing performance on ImageNet. In addition, we evaluate semantic image editing in more challenging settings, using images from the COCO dataset as well as text-based generated images",
    "checked": true,
    "id": "064ccebc03d3afabaae30fe29a457c1cfcdff7e3",
    "semantic_title": "diffedit: diffusion-based semantic image editing with mask guidance",
    "citation_count": 586,
    "authors": []
  },
  "https://openreview.net/forum?id=JTGimap_-F": {
    "title": "Rarity Score : A New Metric to Evaluate the Uncommonness of Synthesized Images",
    "volume": "spotlight",
    "abstract": "Evaluation metrics in image synthesis play a key role to measure performances of generative models. However, most metrics mainly focus on image fidelity. Existing diversity metrics are derived by comparing distributions, and thus they cannot quantify the diversity or rarity degree of each generated image. In this work, we propose a new evaluation metric, called `rarity score', to measure both image-wise uncommonness and model-wise diversified generation performance. We first show empirical observation that typical samples are close to each other and distinctive samples are far from each other in nearest-neighbor distances on latent spaces represented by feature extractor networks such as VGG16. We then show that one can effectively filter typical or distinctive samples with the proposed metric. We also use our metric to demonstrate that the extent to which different generative models produce rare images can be effectively compared. Further, our metric can be used to compare rarities between datasets that share the same concept such as CelebA-HQ and FFHQ. Finally, we analyze the use of metrics in different designs of feature extractors to better understand the relationship between feature spaces and resulting high-rarity images. Code will be publicly available for the research community",
    "checked": true,
    "id": "d181656b2e40f17c34b04d6ee69a3015e2e56479",
    "semantic_title": "rarity score : a new metric to evaluate the uncommonness of synthesized images",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=09hVcSDkea": {
    "title": "Corrupted Image Modeling for Self-Supervised Visual Pre-Training",
    "volume": "spotlight",
    "abstract": "We introduce Corrupted Image Modeling (CIM) for self-supervised visual pre-training. CIM uses an auxiliary generator with a small trainable BEiT to corrupt the input image instead of using artificial [MASK] tokens, where some patches are randomly selected and replaced with plausible alternatives sampled from the BEiT output distribution. Given this corrupted image, an enhancer network learns to either recover all the original image pixels, or predict whether each visual token is replaced by a generator sample or not. The generator and the enhancer are simultaneously trained and synergistically updated. After pre-training, the enhancer can be used as a high-capacity visual encoder for downstream tasks. CIM is a general and flexible visual pre-training framework that is suitable for various network architectures. For the first time, CIM demonstrates that both ViT and CNN can learn rich visual representations using a unified, non-Siamese framework. Experimental results show that our approach achieves compelling results in vision benchmarks, such as ImageNet classification and ADE20K semantic segmentation",
    "checked": true,
    "id": "9d054fa2ce6b0b3160aa52712f44f7967057205b",
    "semantic_title": "corrupted image modeling for self-supervised visual pre-training",
    "citation_count": 90,
    "authors": []
  },
  "https://openreview.net/forum?id=sd90a2ytrt": {
    "title": "Semi-Implicit Variational Inference via Score Matching",
    "volume": "spotlight",
    "abstract": "Semi-implicit variational inference (SIVI) greatly enriches the expressiveness of variational families by considering implicit variational distributions defined in a hierarchical manner. However, due to the intractable densities of variational distributions, current SIVI approaches often use surrogate evidence lower bounds (ELBOs) or employ expensive inner-loop MCMC runs for unbiased ELBOs for training. In this paper, we propose SIVI-SM, a new method for SIVI based on an alternative training objective via score matching. Leveraging the hierarchical structure of semi-implicit variational families, the score matching objective allows a minimax formulation where the intractable variational densities can be naturally handled with denoising score matching. We show that SIVI-SM closely matches the accuracy of MCMC and outperforms ELBO-based SIVI methods in a variety of Bayesian inference tasks",
    "checked": true,
    "id": "aa02c9b676c9aedc8d6693a73ac7c7af02d182af",
    "semantic_title": "semi-implicit variational inference via score matching",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=fxjzKOdw9wb": {
    "title": "Exploring Temporally Dynamic Data Augmentation for Video Recognition",
    "volume": "spotlight",
    "abstract": "Data augmentation has recently emerged as an essential component of modern training recipes for visual recognition tasks. However, data augmentation for video recognition has been rarely explored despite its effectiveness. Few existing augmentation recipes for video recognition naively extend the image augmentation methods by applying the same operations to the whole video frames. Our main idea is that the magnitude of augmentation operations for each frame needs to be changed over time to capture the real-world video's temporal variations. These variations should be generated as diverse as possible using fewer additional hyper-parameters during training. Through this motivation, we propose a simple yet effective video data augmentation framework, DynaAugment. The magnitude of augmentation operations on each frame is changed by an effective mechanism, Fourier Sampling that parameterizes diverse, smooth, and realistic temporal variations. DynaAugment also includes an extended search space suitable for video for automatic data augmentation methods. DynaAugment experimentally demonstrates that there are additional performance rooms to be improved from static augmentations on diverse video models. Specifically, we show the effectiveness of DynaAugment on various video datasets and tasks: large-scale video recognition (Kinetics-400 and Something-Something-v2), small-scale video recognition (UCF-101 and HMDB-51), fine-grained video recognition (Diving-48 and FineGym), video action segmentation on Breakfast, video action localization on THUMOS'14, and video object detection on MOT17Det",
    "checked": true,
    "id": "5ca0180552cc0e1c74dd755ff11851bde207c42a",
    "semantic_title": "exploring temporally dynamic data augmentation for video recognition",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=dqITIpZ5Z4b": {
    "title": "A General Framework for Sample-Efficient Function Approximation in Reinforcement Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "6aafc286baae51ecce2ee54330eb8f26d8d44867",
    "semantic_title": "a general framework for sample-efficient function approximation in reinforcement learning",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=bBpT6dEjeRG": {
    "title": "Adversarial Attacks on Adversarial Bandits",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "b2eb421f668be678a9c4314223717b86a255d336",
    "semantic_title": "adversarial attacks on adversarial bandits",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=QVcDQJdFTG": {
    "title": "Ensuring DNN Solution Feasibility for Optimization Problems with Linear Constraints",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "57f3e6511cd0b6c95904ed2f17f81439636c9892",
    "semantic_title": "ensuring dnn solution feasibility for optimization problems with linear constraints",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=FKXVK9dyMM": {
    "title": "LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "1b06e507f7e2af3dc7cf28086ac34083709c3150",
    "semantic_title": "lightgcl: simple yet effective graph contrastive learning for recommendation",
    "citation_count": 260,
    "authors": []
  },
  "https://openreview.net/forum?id=j9m-mVnndbm": {
    "title": "MIMT: Masked Image Modeling Transformer for Video Compression",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "1054668810e6925ed0530aa0978430f73dde937b",
    "semantic_title": "mimt: masked image modeling transformer for video compression",
    "citation_count": 38,
    "authors": []
  },
  "https://openreview.net/forum?id=COZDy0WYGg": {
    "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "5a77b508302771fc083bf24e0bcda8553c9b5421",
    "semantic_title": "hungry hungry hippos: towards language modeling with state space models",
    "citation_count": 477,
    "authors": []
  },
  "https://openreview.net/forum?id=4fZc_79Lrqs": {
    "title": "ACMP: Allen-Cahn Message Passing with Attractive and Repulsive Forces for Graph Neural Networks",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "fea03f338db94581753f9588bd07937996aee63d",
    "semantic_title": "acmp: allen-cahn message passing with attractive and repulsive forces for graph neural networks",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=cFuMmbWiN6": {
    "title": "Relational Attention: Generalizing Transformers for Graph-Structured Tasks",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "a84b33c93222d525abcee154698aa937e110fb77",
    "semantic_title": "relational attention: generalizing transformers for graph-structured tasks",
    "citation_count": 43,
    "authors": []
  },
  "https://openreview.net/forum?id=99RpBVpLiX": {
    "title": "Distilling Model Failures as Directions in Latent Space",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "b21d7d2f52a06380a18e272863efebf77dc69f90",
    "semantic_title": "distilling model failures as directions in latent space",
    "citation_count": 93,
    "authors": []
  },
  "https://openreview.net/forum?id=8qjSA5QACb40": {
    "title": "Combinatorial-Probabilistic Trade-Off: P-Values of Community Properties Test in the Stochastic Block Models",
    "volume": "spotlight",
    "abstract": "",
    "checked": false,
    "id": "04685cd6cb60e2b0de16410eab4d0e1a7c7e1692",
    "semantic_title": "combinatorial-probabilistic trade-off: p-values of community property test in the stochastic block models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=yYbhKqdi7Hz": {
    "title": "Continuized Acceleration for Quasar Convex Functions in Non-Convex Optimization",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "d1d6c791badca60b285163ce3342aec135b519fb",
    "semantic_title": "continuized acceleration for quasar convex functions in non-convex optimization",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=8sSnD78NqTN": {
    "title": "Learning Soft Constraints From Constrained Expert Demonstrations",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "bec89199faf9a7aa6b1605f1d506c8d215f036f1",
    "semantic_title": "learning soft constraints from constrained expert demonstrations",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=cDYRS5iZ16f": {
    "title": "Learning to Grow Pretrained Models for Efficient Transformer Training",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "a7a40b35b6f37c554f1c5c2038892ed70c693a64",
    "semantic_title": "learning to grow pretrained models for efficient transformer training",
    "citation_count": 64,
    "authors": []
  },
  "https://openreview.net/forum?id=hQwb-lbM6EL": {
    "title": "InCoder: A Generative Model for Code Infilling and Synthesis",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "5288b9f3a9f575543f44c39e1d3b78b3ca4c99da",
    "semantic_title": "incoder: a generative model for code infilling and synthesis",
    "citation_count": 718,
    "authors": []
  },
  "https://openreview.net/forum?id=E01k9048soZ": {
    "title": "UNIFIED-IO: A Unified Model for Vision, Language, and Multi-modal Tasks",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "8b5eab31e1c5689312fff3181a75bfbf5c13e51c",
    "semantic_title": "unified-io: a unified model for vision, language, and multi-modal tasks",
    "citation_count": 446,
    "authors": []
  },
  "https://openreview.net/forum?id=3k5CUGDLNdd": {
    "title": "Benchmarking Offline Reinforcement Learning on Real-Robot Hardware",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "d91591feb96936237167c9e569b8f74e0b2bfcc3",
    "semantic_title": "benchmarking offline reinforcement learning on real-robot hardware",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=RgUPdudkWlN": {
    "title": "CUDA: Curriculum of Data Augmentation for Long-tailed Recognition",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "fe47aebdcad5a934dfd44f383c2d0f314699b934",
    "semantic_title": "cuda: curriculum of data augmentation for long-tailed recognition",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=5ktFNz_pJLK": {
    "title": "Learning to Estimate Shapley Values with Vision Transformers",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "a71b9fc58d8df11d4ae725568308fb5ace3da24a",
    "semantic_title": "learning to estimate shapley values with vision transformers",
    "citation_count": 46,
    "authors": []
  },
  "https://openreview.net/forum?id=Iuubb9W6Jtk": {
    "title": "A framework for benchmarking Class-out-of-distribution detection and its application to ImageNet",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "85e3375ff47be23ad3cee66f379284c416a57e2c",
    "semantic_title": "a framework for benchmarking class-out-of-distribution detection and its application to imagenet",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=vDFA1tpuLvk": {
    "title": "Retrieval-based Controllable Molecule Generation",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "ea4ff70180e4563fe12b51dfce0f57b36639aacf",
    "semantic_title": "retrieval-based controllable molecule generation",
    "citation_count": 43,
    "authors": []
  },
  "https://openreview.net/forum?id=_s1N-DnxdyT": {
    "title": "Stochastic Multi-Person 3D Motion Forecasting",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "800eb5ca1b94097837fd768879944c558fafdb8c",
    "semantic_title": "stochastic multi-person 3d motion forecasting",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=Q-UHqMorzil": {
    "title": "Sign and Basis Invariant Networks for Spectral Graph Representation Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "eb984b142db9965b10a3b5ae5813eeb3e0f6e676",
    "semantic_title": "sign and basis invariant networks for spectral graph representation learning",
    "citation_count": 163,
    "authors": []
  },
  "https://openreview.net/forum?id=7C9aRX2nBf2": {
    "title": "Sequential Latent Variable Models for Few-Shot High-Dimensional Time-Series Forecasting",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "72ce406751efe050681eecc3862c5681f7374aef",
    "semantic_title": "sequential latent variable models for few-shot high-dimensional time-series forecasting",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=XomEU3eNeSQ": {
    "title": "Code Translation with Compiler Representations",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "593edb7f66bf6ec3eef943691c18aec9f976bc51",
    "semantic_title": "code translation with compiler representations",
    "citation_count": 71,
    "authors": []
  },
  "https://openreview.net/forum?id=zDiHoIWa0q1": {
    "title": "Omnigrok: Grokking Beyond Algorithmic Data",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "ad065eed8e1f727a8b0d8675802e4ffb1fcb87b4",
    "semantic_title": "omnigrok: grokking beyond algorithmic data",
    "citation_count": 97,
    "authors": []
  },
  "https://openreview.net/forum?id=XCTVFJwS9LJ": {
    "title": "Flow Annealed Importance Sampling Bootstrap",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "201940ec4311c65a98bdb794297ef07ba2b7bc24",
    "semantic_title": "flow annealed importance sampling bootstrap",
    "citation_count": 109,
    "authors": []
  },
  "https://openreview.net/forum?id=ih0uFRFhaZZ": {
    "title": "Continual Unsupervised Disentangling of Self-Organizing Representations",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "7dbbe26585fa0349b9afaa4659a6dd8dbc97d37b",
    "semantic_title": "continual unsupervised disentangling of self-organizing representations",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=5VBBA91N6n": {
    "title": "LMC: Fast Training of GNNs via Subgraph Sampling with Provable Convergence",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "36ce239097627ffc1bcf4a45f62bb0c2579fc837",
    "semantic_title": "lmc: fast training of gnns via subgraph sampling with provable convergence",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=rZ-wylY5VI": {
    "title": "Programmatically Grounded, Compositionally Generalizable Robotic Manipulation",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "da3b810e10638507be9901e1b5cb94db126c8166",
    "semantic_title": "programmatically grounded, compositionally generalizable robotic manipulation",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=4eJ43EN2g6l": {
    "title": "SketchKnitter: Vectorized Sketch Generation with Diffusion Models",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "142062cc51352367c07afc48021db8f5f0bf0855",
    "semantic_title": "sketchknitter: vectorized sketch generation with diffusion models",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=S07feAlQHgM": {
    "title": "A Model or 603 Exemplars: Towards Memory-Efficient Class-Incremental Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "09bdd06f70f509b6a1513565cb6974076ec7d791",
    "semantic_title": "a model or 603 exemplars: towards memory-efficient class-incremental learning",
    "citation_count": 164,
    "authors": []
  },
  "https://openreview.net/forum?id=IxmWsm4xrua": {
    "title": "Toeplitz Neural Network for Sequence Modeling",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "f35f5aedc30e2c5ded210d9c91ba6e84bd029425",
    "semantic_title": "toeplitz neural network for sequence modeling",
    "citation_count": 46,
    "authors": []
  },
  "https://openreview.net/forum?id=isiQ5KIXbjj": {
    "title": "QuAnt: Quantum Annealing with Learnt Couplings",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "73531f551386d469271c06f5b19ffed5ab848518",
    "semantic_title": "quant: quantum annealing with learnt couplings",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=q3F0UBAruO": {
    "title": "Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "70f1e2291235c53e5676512964976d3993f46569",
    "semantic_title": "towards effective and interpretable human-agent collaboration in moba games: a communication perspective",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=uqg3FhRZaq": {
    "title": "On the complexity of nonsmooth automatic differentiation",
    "volume": "spotlight",
    "abstract": "Using the notion of conservative gradient, we provide a simple model to estimate the computational costs of the backward and forward modes of algorithmic differentiation for a wide class of nonsmooth programs. The complexity overhead of the backward mode turns out to be independent of the dimension when using programs with locally Lipschitz semi-algebraic or definable elementary functions. This extends considerably the Baur-Strassen's smooth cheap gradient principle. We illustrate our results by establishing fast backpropagation results of conservative gradients through feedforward neural networks with standard activation and loss functions. Nonsmooth backpropagation's cheapness contrasts with concurrent forward approaches, which have, to this day, dimensional-dependent worst case overhead estimates. We provide further results suggesting the superiority of backward propagation of conservative gradients. Indeed, we relate the complexity of computing a large number of directional derivatives to that of matrix multiplication, and we show that finding two subgradients in the Clarke subdifferential of a function is a NP-hard problem",
    "checked": true,
    "id": "2121052a7337cc9a668c0b2c9fce8cbb56afa2ee",
    "semantic_title": "on the complexity of nonsmooth automatic differentiation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=OnD9zGAGT0k": {
    "title": "Diffusion Posterior Sampling for General Noisy Inverse Problems",
    "volume": "spotlight",
    "abstract": "Diffusion models have been recently studied as powerful generative inverse problem solvers, owing to their high quality reconstructions and the ease of combining existing iterative solvers. However, most works focus on solving simple linear inverse problems in noiseless settings, which significantly under-represents the complexity of real-world problems. In this work, we extend diffusion solvers to efficiently handle general noisy (non)linear inverse problems via the Laplace approximation of the posterior sampling. Interestingly, the resulting posterior sampling scheme is a blended version of diffusion sampling with the manifold constrained gradient without a strict measurement consistency projection step, yielding a more desirable generative path in noisy settings compared to the previous studies. Our method demonstrates that diffusion models can incorporate various measurement noise statistics such as Gaussian and Poisson, and also efficiently handle noisy nonlinear inverse problems such as Fourier phase retrieval and non-uniform deblurring",
    "checked": true,
    "id": "61e46884567be7cad12e999365b16a8d3414b678",
    "semantic_title": "diffusion posterior sampling for general noisy inverse problems",
    "citation_count": 1045,
    "authors": []
  },
  "https://openreview.net/forum?id=MkbcAHIYgyS": {
    "title": "Mass-Editing Memory in a Transformer",
    "volume": "spotlight",
    "abstract": "Recent work has shown exciting promise in updating large language models with new memories, so as to replace obsolete information or add specialized knowledge. However, this line of work is predominantly limited to updating single associations. We develop MEMIT, a method for directly updating a language model with many memories, demonstrating experimentally that it can scale up to thousands of associations for GPT-J (6B) and GPT-NeoX (20B), exceeding prior work by an order of magnitude. Our code and data will be open-sourced upon publication",
    "checked": true,
    "id": "2fe1ac0b09cc0f50eb83eef6c7c6b45ac8b12413",
    "semantic_title": "mass-editing memory in a transformer",
    "citation_count": 696,
    "authors": []
  },
  "https://openreview.net/forum?id=iV9Cs8s8keU": {
    "title": "Learning the Positions in CountSketch",
    "volume": "spotlight",
    "abstract": "We consider sketching algorithms which first compress data by multiplication with a random sketch matrix, and then apply the sketch to quickly solve an optimization problem, e.g., low-rank approximation and regression. In the learning-based sketching paradigm proposed by Indyk et al., the sketch matrix is found by choosing a random sparse matrix, e.g., CountSketch, and then the values of its non-zero entries are updated by running gradient descent on a training data set. Despite the growing body of work on this paradigm, a noticeable omission is that the locations of the non-zero entries of previous algorithms were fixed, and only their values were learned. In this work, we propose the first learning-based algorithms that also optimize the locations of the non-zero entries. Our first proposed algorithm is based on a greedy algorithm. However, one drawback of the greedy algorithm is its slower training time. We fix this issue and propose approaches for learning a sketching matrix for both low-rank approximation and Hessian approximation for second-order optimization. The latter is helpful for a range of constrained optimization problems, such as LASSO and matrix estimation with a nuclear norm constraint. Both approaches achieve good accuracy with a fast running time. Moreover, our experiments suggest that our algorithm can still reduce the error significantly even if we only have a very limited number of training matrices",
    "checked": false,
    "id": "500994f747554cafa7d601a92a6e3905b50f1833",
    "semantic_title": "bi-matching mechanism to combat the long tail of word sense disambiguation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v69itrHLEu": {
    "title": "Outcome-directed Reinforcement Learning by Uncertainty \\& Temporal Distance-Aware Curriculum Goal Generation",
    "volume": "spotlight",
    "abstract": "Current reinforcement learning (RL) often suffers when solving a challenging exploration problem where the desired outcomes or high rewards are rarely observed. Even though curriculum RL, a framework that solves complex tasks by proposing a sequence of surrogate tasks, shows reasonable results, most of the previous works still have difficulty in proposing curriculum due to the absence of a mechanism for obtaining calibrated guidance to the desired outcome state without any prior domain knowledge. To alleviate it, we propose an uncertainty \\& temporal distance-aware curriculum goal generation method for the outcome-directed RL via solving a bipartite matching problem. It could not only provide precisely calibrated guidance of the curriculum to the desired outcome states but also bring much better sample efficiency and geometry-agnostic curriculum goal proposal capability compared to previous curriculum RL methods. We demonstrate that our algorithm significantly outperforms these prior methods in a variety of challenging navigation tasks and robotic manipulation tasks in a quantitative and qualitative way",
    "checked": false,
    "id": "b093a3fa79512c48524f81c754bddec7b16afb17",
    "semantic_title": "outcome-directed reinforcement learning by uncertainty & temporal distance-aware curriculum goal generation",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=Mvetq8DO05O": {
    "title": "A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation Estimation",
    "volume": "spotlight",
    "abstract": "Estimating the 3DoF rotation from a single RGB image is an important yet challenging problem. Probabilistic rotation regression has raised more and more attention with the benefit of expressing uncertainty information along with the prediction. Though modeling noise using Gaussian-resembling Bingham distribution and matrix Fisher distribution is natural, they are shown to be sensitive to outliers for the nature of quadratic punishment to deviations. In this paper, we draw inspiration from multivariate Laplace distribution and propose a novel Rotation Laplace distribution on SO(3). Rotation Laplace distribution is robust to the disturbance of outliers and enforces much gradient to the low-error region, resulting in a better convergence. Our extensive experiments show that our proposed distribution achieves state-of-the-art performance for rotation regression tasks over both probabilistic and non-probabilistic baselines. Our project page is at pku-epic.github.io/RotationLaplace",
    "checked": true,
    "id": "cc755f586df6ca5f509b1e99753e3065b57638c2",
    "semantic_title": "a laplace-inspired distribution on so(3) for probabilistic rotation estimation",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=3F6I-0-57SC": {
    "title": "HiViT: A Simpler and More Efficient Design of Hierarchical Vision Transformer",
    "volume": "spotlight",
    "abstract": "There has been a debate on the choice of plain vs. hierarchical vision transformers, where researchers often believe that the former (e.g., ViT) has a simpler design but the latter (e.g., Swin) enjoys higher recognition accuracy. Recently, the emerge of masked image modeling (MIM), a self-supervised visual pre-training method, raised a new challenge to vision transformers in terms of flexibility, i.e., part of image patches or tokens are to be discarded, which seems to claim the advantages of plain vision transformers. In this paper, we delve deep into the comparison between ViT and Swin, revealing that (i) the performance gain of Swin is mainly brought by a deepened backbone and relative positional encoding, (ii) the hierarchical design of Swin can be simplified into hierarchical patch embedding (proposed in this work), and (iii) other designs such as shifted-window attentions can be removed. By removing the unnecessary operations, we come up with a new architecture named HiViT (short for hierarchical ViT), which is simpler and more efficient than Swin yet further improves its performance on fully-supervised and self-supervised visual representation learning. In particular, after pre-trained using masked autoencoder (MAE) on ImageNet-1K, HiViT-B reports a 84.6% accuracy on ImageNet-1K classification, a 53.3% box AP on COCO detection, and a 52.8% mIoU on ADE20K segmentation, significantly surpassing the baseline. Code is available at https://github.com/zhangxiaosong18/hivit",
    "checked": true,
    "id": "689bc24f71f8f22784534c764d59baa93a62c2e0",
    "semantic_title": "hivit: a simpler and more efficient design of hierarchical vision transformer",
    "citation_count": 80,
    "authors": []
  },
  "https://openreview.net/forum?id=kIPyTuEZuAK": {
    "title": "A Minimalist Dataset for Systematic Generalization of Perception, Syntax, and Semantics",
    "volume": "spotlight",
    "abstract": "Inspired by humans' exceptional ability to master arithmetic and generalize to new problems, we present a new dataset, HINT, to examine machines' capability of learning generalizable concepts at three levels: perception, syntax, and semantics. In HINT, machines are tasked with learning how concepts are perceived from raw signals such as images (i.e., perception), how multiple concepts are structurally combined to form a valid expression (i.e., syntax), and how concepts are realized to afford various reasoning tasks (i.e., semantics), all in a weakly supervised manner. Focusing on systematic generalization, we carefully design a five-fold test set to evaluate both the interpolation and the extrapolation of learned concepts w.r.t the three levels. Further, we design a few-shot learning split to determine whether or not models can rapidly learn new concepts and generalize them to more complex scenarios. To comprehend existing models' limitations, we undertake extensive experiments with various sequence-to-sequence models, including RNNs, Transformers, and GPT-3 (with the chain of thought prompting). The results indicate that current models struggle to extrapolate to long-range syntactic dependency and semantics. Models exhibit a considerable gap toward human-level generalization when evaluated with new concepts in a few-shot setting. Moreover, we discover that it is infeasible to solve HINT by merely scaling up the dataset and the model size; this strategy contributes little to the extrapolation of syntax and semantics. Finally, in zero-shot GPT-3 experiments, the chain of thought prompting exhibits impressive results and significantly boosts the test accuracy. We believe the HINT dataset and the experimental findings are of great interest to the learning community on systematic generalization.%",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gOZ_pKANaPW": {
    "title": "Unsupervised Model Selection for Time Series Anomaly Detection",
    "volume": "spotlight",
    "abstract": "Anomaly detection in time-series has a wide range of practical applications. While numerous anomaly detection methods have been proposed in the literature, a recent survey concluded that no single method is the most accurate across various datasets. To make matters worse, anomaly labels are scarce and rarely available in practice. The practical problem of selecting the most accurate model for a given dataset without labels has received little attention in the literature. This paper answers this question \\textit{i.e.} Given an unlabeled dataset and a set of candidate anomaly detectors, how can we select the most accurate model? To this end, we identify three classes of surrogate (unsupervised) metrics, namely, \\textit{prediction error}, \\textit{model centrality}, and \\textit{performance on injected synthetic anomalies}, and show that some metrics are highly correlated with standard supervised anomaly detection performance metrics such as the $F_1$ score, but to varying degrees. We formulate metric combination with multiple imperfect surrogate metrics as a robust rank aggregation problem. We then provide theoretical justification behind the proposed approach. Large-scale experiments on multiple real-world datasets demonstrate that our proposed unsupervised approach is as effective as selecting the most accurate model based on partially labeled data",
    "checked": false,
    "id": "0265761ce77c5a05485e543ef376d57b2da0ac7e",
    "semantic_title": "unsupervised model selection for time-series anomaly detection",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=vtVDI3w_BLL": {
    "title": "AANG : Automating Auxiliary Learning",
    "volume": "spotlight",
    "abstract": "Auxiliary objectives, supplementary learning signals that are introduced to help aid learning on data-starved or highly complex end-tasks, are commonplace in machine learning. Whilst much work has been done to formulate useful auxiliary objectives, their construction is still an art which proceeds by slow and tedious hand-design. Intuition for how and when these objectives improve end-task performance has also had limited theoretical backing. In this work, we present an approach for automatically generating a suite of auxiliary objectives. We achieve this by deconstructing existing objectives within a novel unified taxonomy, identifying connections between them, and generating new ones based on the uncovered structure. Next, we theoretically formalize widely-held intuitions about how auxiliary learning improves generalization on the end-task. This leads us to a principled and efficient algorithm for searching the space of generated objectives to find those most useful to a specified end-task. With natural language processing (NLP) as our domain of study, we demonstrate that our automated auxiliary learning pipeline leads to strong improvements over competitive baselines across continued training experiments on a pre-trained model on 5 NLP end-tasks",
    "checked": false,
    "id": "55b901b3f5a0ec6788cbad0c0acdd4aa0f35c72f",
    "semantic_title": "aang: automating auxiliary learning",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=9gfir3fSy3J": {
    "title": "NeRN: Learning Neural Representations for Neural Networks",
    "volume": "spotlight",
    "abstract": "Neural Representations have recently been shown to effectively reconstruct a wide range of signals from 3D meshes and shapes to images and videos. We show that, when adapted correctly, neural representations can be used to directly represent the weights of a pre-trained convolutional neural network, resulting in a Neural Representation for Neural Networks (NeRN). Inspired by coordinate inputs of previous neural representation methods, we assign a coordinate to each convolutional kernel in our network based on its position in the architecture, and optimize a predictor network to map coordinates to their corresponding weights. Similarly to the spatial smoothness of visual scenes, we show that incorporating a smoothness constraint over the original network's weights aids NeRN towards a better reconstruction. In addition, since slight perturbations in pre-trained model weights can result in a considerable accuracy loss, we employ techniques from the field of knowledge distillation to stabilize the learning process. We demonstrate the effectiveness of NeRN in reconstructing widely used architectures on CIFAR-10, CIFAR-100, and ImageNet. Finally, we present two applications using NeRN, demonstrating the capabilities of the learned representations",
    "checked": true,
    "id": "aa5cc9b82b862c528ab1189b674a13990aa55a50",
    "semantic_title": "nern: learning neural representations for neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=-P7G-8dmSh4": {
    "title": "Formal Mathematics Statement Curriculum Learning",
    "volume": "spotlight",
    "abstract": "We explore the use of expert iteration in the context of language modeling applied to formal mathematics. We show that at same compute budget, expert iteration, by which we mean proof search interleaved with learning, dramatically outperforms proof search only. We also observe that when applied to a collection of formal statements of sufficiently varied difficulty, expert iteration is capable of finding and solving a curriculum of increasingly difficult problems, without the need for associated ground-truth proofs. Finally, by applying this expert iteration to a manually curated set of problem statements, we surpass previous state-of-the-art on the miniF2F benchmark, automatically solving multiple challenging problems drawn from high school olympiads",
    "checked": true,
    "id": "916a06a6d51aa93de27aac2f3e14faed08dd6706",
    "semantic_title": "formal mathematics statement curriculum learning",
    "citation_count": 137,
    "authors": []
  },
  "https://openreview.net/forum?id=6fuPIe9tbnC": {
    "title": "Multifactor Sequential Disentanglement via Structured Koopman Autoencoders",
    "volume": "spotlight",
    "abstract": "Disentangling complex data to its latent factors of variation is a fundamental task in representation learning. Existing work on sequential disentanglement mostly provides two factor representations, i.e., it separates the data to time-varying and time-invariant factors. In contrast, we consider multifactor disentanglement in which multiple (more than two) semantic disentangled components are generated. Key to our approach is a strong inductive bias where we assume that the underlying dynamics can be represented linearly in the latent space. Under this assumption, it becomes natural to exploit the recently introduced Koopman autoencoder models. However, disentangled representations are not guaranteed in Koopman approaches, and thus we propose a novel spectral loss term which leads to structured Koopman matrices and disentanglement. Overall, we propose a simple and easy to code new deep model that is fully unsupervised and it supports multifactor disentanglement. We showcase new disentangling abilities such as swapping of individual static factors between characters, and an incremental swap of disentangled factors from the source to the target. Moreover, we evaluate our method extensively on two factor standard benchmark tasks where we significantly improve over competing unsupervised approaches, and we perform competitively in comparison to weakly- and self-supervised state-of-the-art approaches. The code is available at https://github.com/azencot-group/SKD",
    "checked": true,
    "id": "76bd4ab6432228c73f78110be6e0093eedc0d3c5",
    "semantic_title": "multifactor sequential disentanglement via structured koopman autoencoders",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=XXTyv1zD9zD": {
    "title": "Packed Ensembles for efficient uncertainty estimation",
    "volume": "spotlight",
    "abstract": "Deep Ensembles (DE) are a prominent approach for achieving excellent performance on key metrics such as accuracy, calibration, uncertainty estimation, and out-of-distribution detection. However, hardware limitations of real-world systems constrain to smaller ensembles and lower-capacity networks, significantly deteriorating their performance and properties. We introduce Packed-Ensembles (PE), a strategy to design and train lightweight structured ensembles by carefully modulating the dimension of their encoding space. We leverage grouped convolutions to parallelize the ensemble into a single shared backbone and forward pass to improve training and inference speeds. PE is designed to operate within the memory limits of a standard neural network. Our extensive research indicates that PE accurately preserves the properties of DE, such as diversity, and performs equally well in terms of accuracy, calibration, out-of-distribution detection, and robustness to distribution shift. We make our code available at https://github.com/ENSTA-U2IS/torch-uncertainty",
    "checked": false,
    "id": "00961426bef856073e7a57d785883b1b0a2f6050",
    "semantic_title": "packed-ensembles for efficient uncertainty estimation",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=9y0HFvaAYD6": {
    "title": "Hidden Markov Transformer for Simultaneous Machine Translation",
    "volume": "spotlight",
    "abstract": "Simultaneous machine translation (SiMT) outputs the target sequence while receiving the source sequence, and hence learning when to start translating each target token is the core challenge for SiMT task. However, it is non-trivial to learn the optimal moment among many possible moments of starting translating, as the moments of starting translating always hide inside the model and can only be supervised with the observed target sequence. In this paper, we propose a Hidden Markov Transformer (HMT), which treats the moments of starting translating as hidden events and the target sequence as the corresponding observed events, thereby organizing them as a hidden Markov model. HMT explicitly models multiple moments of starting translating as the candidate hidden events, and then selects one to generate the target token. During training, by maximizing the marginal likelihood of the target sequence over multiple moments of starting translating, HMT learns to start translating at the moments that target tokens can be generated more accurately. Experiments on multiple SiMT benchmarks show that HMT outperforms strong baselines and achieves state-of-the-art performance",
    "checked": true,
    "id": "9ce604efe716d9f85bb3af198bf63d9ceacf1deb",
    "semantic_title": "hidden markov transformer for simultaneous machine translation",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=U2g8OGONA_V": {
    "title": "Multi-domain image generation and translation with identifiability guarantees",
    "volume": "spotlight",
    "abstract": "Multi-domain image generation and unpaired image-to-to-image translation are two important and related computer vision problems. The common technique for the two tasks is the learning of a joint distribution from multiple marginal distributions. However, it is well known that there can be infinitely many joint distributions that can derive the same marginals. Hence, it is necessary to formulate suitable constraints to address this highly ill-posed problem. Inspired by the recent advances in nonlinear Independent Component Analysis (ICA) theory, we propose a new method to learn the joint distribution from the marginals by enforcing a specific type of minimal change across domains. We report one of the first results connecting multi-domain generative models to identifiability and shows why identifiability is essential and how to achieve it theoretically and practically. We apply our method to five multi-domain image generation and six image-to-image translation tasks. The superior performance of our model supports our theory and demonstrates the effectiveness of our method. The training code are available at https://github.com/Mid-Push/i-stylegan",
    "checked": true,
    "id": "6fef47eb674d445835e9126655075b522c08c2cc",
    "semantic_title": "multi-domain image generation and translation with identifiability guarantees",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=Zy350cRstc6": {
    "title": "Continual evaluation for lifelong learning: Identifying the stability gap",
    "volume": "spotlight",
    "abstract": "Time-dependent data-generating distributions have proven to be difficult for gradient-based training of neural networks, as the greedy updates result in catastrophic forgetting of previously learned knowledge. Despite the progress in the field of continual learning to overcome this forgetting, we show that a set of common state-of-the-art methods still suffers from substantial forgetting upon starting to learn new tasks, except that this forgetting is temporary and followed by a phase of performance recovery. We refer to this intriguing but potentially problematic phenomenon as the stability gap. The stability gap had likely remained under the radar due to standard practice in the field of evaluating continual learning models only after each task. Instead, we establish a framework for continual evaluation that uses per-iteration evaluation and we define a new set of metrics to quantify worst-case performance. Empirically we show that experience replay, constraint-based replay, knowledge-distillation, and parameter regularization methods are all prone to the stability gap; and that the stability gap can be observed in class-, task-, and domain-incremental learning benchmarks. Additionally, a controlled experiment shows that the stability gap increases when tasks are more dissimilar. Finally, by disentangling gradients into plasticity and stability components, we propose a conceptual explanation for the stability gap",
    "checked": true,
    "id": "58fc91ecbedf05e663495ff8f92b97279b9c2e3c",
    "semantic_title": "continual evaluation for lifelong learning: identifying the stability gap",
    "citation_count": 46,
    "authors": []
  },
  "https://openreview.net/forum?id=pxStyaf2oJ5": {
    "title": "Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation",
    "volume": "spotlight",
    "abstract": "Previous studies have shown that leveraging \"domain index\" can significantly boost domain adaptation performance (Wang et al., 2020; Xu et al., 2022). However, such domain indices are not always available. To address this challenge, we first provide a formal definition of domain index from the probabilistic perspective, and then propose an adversarial variational Bayesian framework that infers domain indices from multi-domain data, thereby providing additional insight on domain relations and improving domain adaptation performance. Our theoretical analysis shows that our adversarial variational Bayesian framework finds the optimal domain index at equilibrium. Empirical results on both synthetic and real data verify that our model can produce interpretable domain indices which enable us to achieve superior performance compared to state-of-the-art domain adaptation methods. Code is available at https://github.com/Wang-ML-Lab/VDI",
    "checked": true,
    "id": "ef018596c581fa37e83e9544b6412beeb15e31fa",
    "semantic_title": "domain-indexing variational bayes: interpretable domain index for domain adaptation",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=p7G8t5FVn2h": {
    "title": "One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks",
    "volume": "spotlight",
    "abstract": "Unlearnable examples (ULEs) aim to protect data from unauthorized usage for training DNNs. Existing work adds $\\ell_\\infty$-bounded perturbations to the original sample so that the trained model generalizes poorly. Such perturbations, however, are easy to eliminate by adversarial training and data augmentations. In this paper, we resolve this problem from a novel perspective by perturbing only one pixel in each image. Interestingly, such a small modification could effectively degrade model accuracy to almost an untrained counterpart. Moreover, our produced \\emph{One-Pixel Shortcut (OPS)} could not be erased by adversarial training and strong augmentations. To generate OPS, we perturb in-class images at the same position to the same target value that could mostly and stably deviate from all the original images. Since such generation is only based on images, OPS needs significantly less computation cost than the previous methods using DNN generators. Based on OPS, we introduce an unlearnable dataset called CIFAR-10-S, which is indistinguishable from CIFAR-10 by humans but induces the trained model to extremely low accuracy. Even under adversarial training, a ResNet-18 trained on CIFAR-10-S has only 10.61% accuracy, compared to 83.02% by the existing error-minimizing method",
    "checked": true,
    "id": "3d4a385e9fe28e69a20b09471e22adf05979ccda",
    "semantic_title": "one-pixel shortcut: on the learning preference of deep neural networks",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=g8wBdhnstYz": {
    "title": "Deterministic training of generative autoencoders using invertible layers",
    "volume": "spotlight",
    "abstract": "In this work, we provide a deterministic alternative to the stochastic variational training of generative autoencoders. We refer to these new generative autoencoders as AutoEncoders within Flows (AEF), since the encoder and decoder are defined as affine layers of an overall invertible architecture. This results in a deterministic encoding of the data, as opposed to the stochastic encoding of VAEs. The paper introduces two related families of AEFs. The first family relies on a partition of the ambient space and is trained by exact maximum-likelihood. The second family exploits a deterministic expansion of the ambient space and is trained by maximizing the log-probability in this extended space. This latter case leaves complete freedom in the choice of encoder, decoder and prior architectures, making it a drop-in replacement for the training of existing VAEs and VAE-style models. We show that these AEFs can have strikingly higher performance than architecturally identical VAEs in terms of log-likelihood and sample quality, especially for low dimensional latent spaces. Importantly, we show that AEF samples are substantially sharper than VAE samples",
    "checked": true,
    "id": "944ca0b8eeda90274478e79352a54d056950c4d0",
    "semantic_title": "deterministic training of generative autoencoders using invertible layers",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=aFzaXRImWE": {
    "title": "A Holistic View of Label Noise Transition Matrix in Deep Learning and Beyond",
    "volume": "spotlight",
    "abstract": "In this paper, we explore learning statistically consistent classifiers under label noise by estimating the noise transition matrix T. We first provide a holistic view of existing T-estimation methods including those with or without anchor point assumptions. We unified them into the Minimum Geometric Envelope Operator (MGEO) framework, which tries to find the smallest T (in terms of a certain metric) that elicits a convex hull to enclose the posteriors of all the training data. Although MGEO methods show appealing theoretical properties and empirical results, we find them prone to failing when the noisy posterior estimation is imperfect, which is inevitable in practice. Specifically, we show that MGEO methods are in-consistent even with infinite samples if the noisy posterior is not estimated accurately. In view of this, we make the first effort to address this issue by proposing a novel T-estimation framework via the lens of bilevel optimization, and term it RObust Bilevel OpTimzation (ROBOT). ROBOT paves a new road beyond MGEO framework, which enjoys strong theoretical properties: identifibility, consistency and finite-sample generalization guarantees. Notably, ROBOT neither requires the perfect posterior estimation nor assumes the existence of anchor points. We further theoretically demonstrate that ROBOT is more robust in the case where MGEO methods fail. Experimentally, our framework also shows superior performance across multiple benchmarks",
    "checked": true,
    "id": "cee36fe5bf94d6351de2d29b947b4a36fcdf8d4b",
    "semantic_title": "a holistic view of label noise transition matrix in deep learning and beyond",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=ZTMuZ68B1g": {
    "title": "Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle",
    "volume": "spotlight",
    "abstract": "Acquiring labeled data is challenging in many machine learning applications with limited budgets. Active learning gives a procedure to select the most informative data points and improve data efficiency by reducing the cost of labeling. The info-max learning principle maximizing mutual information such as BALD has been successful and widely adapted in various active learning applications. However, this pool-based specific objective inherently introduces a redundant selection and further requires a high computational cost for batch selection. In this paper, we design and propose a new uncertainty measure, Balanced Entropy Acquisition (BalEntAcq), which captures the information balance between the uncertainty of underlying softmax probability and the label variable. To do this, we approximate each marginal distribution by Beta distribution. Beta approximation enables us to formulate BalEntAcq as a ratio between an augmented entropy and the marginalized joint entropy. The closed-form expression of BalEntAcq facilitates parallelization by estimating two parameters in each marginal Beta distribution. BalEntAcq is a purely standalone measure without requiring any relational computations with other data points. Nevertheless, BalEntAcq captures a well-diversified selection near the decision boundary with a margin, unlike other existing uncertainty measures such as BALD, Entropy, or Mean Standard Deviation (MeanSD). Finally, we demonstrate that our balanced entropy learning principle with BalEntAcq consistently outperforms well-known linearly scalable active learning methods, including a recently proposed PowerBALD, a simple but diversified version of BALD, by showing experimental results obtained from MNIST, CIFAR-100, SVHN, and TinyImageNet datasets",
    "checked": true,
    "id": "26b5963bcdac9abf5941357acd60fdbe25560e29",
    "semantic_title": "active learning in bayesian neural networks with balanced entropy learning principle",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=i9ogGQHYbkY": {
    "title": "Near-Optimal Adversarial Reinforcement Learning with Switching Costs",
    "volume": "spotlight",
    "abstract": "Switching costs, which capture the costs for changing policies, are regarded as a critical metric in reinforcement learning (RL), in addition to the standard metric of losses (or rewards). However, existing studies on switching costs (with a coefficient that is strictly positive and is independent of the time horizon) have mainly focused on static RL, where the loss distribution is assumed to be fixed during the learning process, and thus practical scenarios where the loss distribution could be non-stationary or even adversarial are not considered. While adversarial RL better models this type of practical scenarios, an open problem remains: how to develop a provably efficient algorithm for adversarial RL with switching costs? This paper makes the first effort towards solving this problem. First, we provide a regret lower-bound that shows that the regret of any algorithm must be larger than $\\tilde{\\Omega}( ( H S A )^{1/3} T^{2/3} )$, where $T$, $S$, $A$ and $H$ are the number of episodes, states, actions and layers in each episode, respectively. Our lower bound indicates that, due to the fundamental challenge of switching costs in adversarial RL, the best achieved regret (whose dependency on $T$ is $\\tilde{O}(\\sqrt{T})$) in static RL with switching costs (as well as adversarial RL without switching costs) is no longer achievable. Moreover, we propose two novel switching-reduced algorithms with regrets that match our lower bound when the transition function is known, and match our lower bound within a small factor of $\\tilde{O}( H^{1/3} )$ when the transition function is unknown. Our regret analysis demonstrates the near-optimal performance of them",
    "checked": true,
    "id": "272ec7c5cd1b1c1f550a55cdbbea1a21096f8035",
    "semantic_title": "near-optimal adversarial reinforcement learning with switching costs",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=IowKt5rYWsK": {
    "title": "GPViT: A High Resolution Non-Hierarchical Vision Transformer with Group Propagation",
    "volume": "spotlight",
    "abstract": "We present the Group Propagation Vision Transformer (GPViT): a novel non- hierarchical (i.e. non-pyramidal) transformer model designed for general visual recognition with high-resolution features. High-resolution features (or tokens) are a natural fit for tasks that involve perceiving fine-grained details such as detection and segmentation, but exchanging global information between these features is expensive in memory and computation because of the way self-attention scales. We provide a highly efficient alternative Group Propagation Block (GP Block) to exchange global information. In each GP Block, features are first grouped to- gether by a fixed number of learnable group tokens; we then perform Group Propagation where global information is exchanged between the grouped fea- tures; finally, global information in the updated grouped features is returned back to the image features through a transformer decoder. We evaluate GPViT on a variety of visual recognition tasks including image classification, semantic seg- mentation, object detection, and instance segmentation. Our method achieves significant performance gains over previous works across all tasks, especially on tasks that require high-resolution outputs, for example, our GPViT-L3 out- performs Swin Transformer-B by 2.0 mIoU on ADE20K semantic segmentation with only half as many parameters. Code and pre-trained models are available at https://github.com/ChenhongyiYang/GPViT",
    "checked": true,
    "id": "79086146a558905f16570f72a82f99446da0f9b8",
    "semantic_title": "gpvit: a high resolution non-hierarchical vision transformer with group propagation",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=d8CBRlWNkqH": {
    "title": "Neural Optimal Transport",
    "volume": "spotlight",
    "abstract": "We present a novel neural-networks-based algorithm to compute optimal transport maps and plans for strong and weak transport costs. To justify the usage of neural networks, we prove that they are universal approximators of transport plans between probability distributions. We evaluate the performance of our optimal transport algorithm on toy examples and on the unpaired image-to-image translation",
    "checked": true,
    "id": "2272b7d70951426e8d2dba2307f9b4d07c049d7b",
    "semantic_title": "neural optimal transport",
    "citation_count": 109,
    "authors": []
  },
  "https://openreview.net/forum?id=4WM4cy42B81": {
    "title": "Dirichlet-based Uncertainty Calibration for Active Domain Adaptation",
    "volume": "spotlight",
    "abstract": "Active domain adaptation (DA) aims to maximally boost the model adaptation on a new target domain by actively selecting limited target data to annotate, whereas traditional active learning methods may be less effective since they do not consider the domain shift issue. Despite active DA methods address this by further proposing targetness to measure the representativeness of target domain characteristics, their predictive uncertainty is usually based on the prediction of deterministic models, which can easily be miscalibrated on data with distribution shift. Considering this, we propose a Dirichlet-based Uncertainty Calibration (DUC) approach for active DA, which simultaneously achieves the mitigation of miscalibration and the selection of informative target samples. Specifically, we place a Dirichlet prior on the prediction and interpret the prediction as a distribution on the probability simplex, rather than a point estimate like deterministic models. This manner enables us to consider all possible predictions, mitigating the miscalibration of unilateral prediction. Then a two-round selection strategy based on different uncertainty origins is designed to select target samples that are both representative of target domain and conducive to discriminability. Extensive experiments on cross-domain image classification and semantic segmentation validate the superiority of DUC",
    "checked": true,
    "id": "a34225690ce8eccdda3e81f6a533771401d76894",
    "semantic_title": "dirichlet-based uncertainty calibration for active domain adaptation",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=IloMJ5rqfnt": {
    "title": "Accurate Image Restoration with Attention Retractable Transformer",
    "volume": "spotlight",
    "abstract": "Recently, Transformer-based image restoration networks have achieved promising improvements over convolutional neural networks due to parameter-independent global interactions. To lower computational cost, existing works generally limit self-attention computation within non-overlapping windows. However, each group of tokens are always from a dense area of the image. This is considered as a dense attention strategy since the interactions of tokens are restrained in dense regions. Obviously, this strategy could result in restricted receptive fields. To address this issue, we propose \\textbf{A}ttention \\textbf{R}etractable \\textbf{T}ransformer (ART) for image restoration, which presents both dense and sparse attention modules in the network. The sparse attention module allows tokens from sparse areas to interact and thus provides a wider receptive field. Furthermore, the alternating application of dense and sparse attention modules greatly enhances representation ability of Transformer while providing retractable attention on the input image.We conduct extensive experiments on image super-resolution, denoising, and JPEG compression artifact reduction tasks. Experimental results validate that our proposed ART outperforms state-of-the-art methods on various benchmark datasets both quantitatively and visually. We also provide code and models at~\\url{https://github.com/gladzhang/ART}",
    "checked": true,
    "id": "a1f7f5597fdbc54e58f1f2a1a640bf355e87a978",
    "semantic_title": "accurate image restoration with attention retractable transformer",
    "citation_count": 115,
    "authors": []
  },
  "https://openreview.net/forum?id=C2fsSj3ZGiU": {
    "title": "Neural Episodic Control with State Abstraction",
    "volume": "spotlight",
    "abstract": "Existing Deep Reinforcement Learning (DRL) algorithms suffer from sample inefficiency. Generally, episodic control-based approaches are solutions that leverage highly rewarded past experiences to improve sample efficiency of DRL algorithms. However, previous episodic control-based approaches fail to utilize the latent information from the historical behaviors (\\eg, state transitions, topological similarities, \\etc) and lack scalability during DRL training. This work introduces Neural Episodic Control with State Abstraction (NECSA), a simple but effective state abstraction-based episodic control containing a more comprehensive episodic memory, a novel state evaluation, and a multi-step state analysis. We evaluate our approach to the MuJoCo and Atari tasks in OpenAI gym domains. The experimental results indicate that NECSA achieves higher sample efficiency than the state-of-the-art episodic control-based approaches. Our data and code are available at the project website\\footnote{\\url{https://sites.google.com/view/drl-necsa}}",
    "checked": true,
    "id": "4875b7cdb20e23c4ada3ef58d48389b0c76052e3",
    "semantic_title": "neural episodic control with state abstraction",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=4oXTQ6m_ws8": {
    "title": "The Role of ImageNet Classes in Fréchet Inception Distance",
    "volume": "spotlight",
    "abstract": "Fréchet Inception Distance (FID) is the primary metric for ranking models in data-driven generative modeling. While remarkably successful, the metric is known to sometimes disagree with human judgement. We investigate a root cause of these discrepancies, and visualize what FID \"looks at\" in generated images. We show that the feature space that FID is (typically) computed in is so close to the ImageNet classifications that aligning the histograms of Top-$N$ classifications between sets of generated and real images can reduce FID substantially — without actually improving the quality of results. Thus, we conclude that FID is prone to intentional or accidental distortions. As a practical example of an accidental distortion, we discuss a case where an ImageNet pre-trained FastGAN achieves a FID comparable to StyleGAN2, while being worse in terms of human evaluation",
    "checked": true,
    "id": "75348e1f3c800fcdce2d4d64b5a6aa3c69a1fb7d",
    "semantic_title": "the role of imagenet classes in fréchet inception distance",
    "citation_count": 227,
    "authors": []
  },
  "https://openreview.net/forum?id=pd1P2eUBVfq": {
    "title": "Diffusion Models Already Have A Semantic Latent Space",
    "volume": "spotlight",
    "abstract": "Diffusion models achieve outstanding generative performance in various domains. Despite their great success, they lack semantic latent space which is essential for controlling the generative process. To address the problem, we propose asymmetric reverse process (Asyrp) which discovers the semantic latent space in frozen pretrained diffusion models. Our semantic latent space, named h-space, has nice properties for accommodating semantic image manipulation: homogeneity, linearity, robustness, and consistency across timesteps. In addition, we measure editing strength and quality deficiency of a generative process at timesteps to provide a principled design of the process for versatility and quality improvements. Our method is applicable to various architectures (DDPM++, iDDPM, and ADM) and datasets (CelebA-HQ, AFHQ-dog, LSUN-church, LSUN-bedroom, and METFACES)",
    "checked": true,
    "id": "a02313d56a6f71be9aafe43628e0f3a1d0cb858e",
    "semantic_title": "diffusion models already have a semantic latent space",
    "citation_count": 294,
    "authors": []
  },
  "https://openreview.net/forum?id=mRieQgMtNTQ": {
    "title": "Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "3a75ed3e9e81c9db573ef73d20e2c66c12aaedf8",
    "semantic_title": "zero-shot image restoration using denoising diffusion null-space model",
    "citation_count": 516,
    "authors": []
  },
  "https://openreview.net/forum?id=CrfhZAsJDsZ": {
    "title": "Nonlinear Reconstruction for Operator Learning of PDEs with Discontinuities",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "ace25e6421a2d21cb4519895e8e26ae1b73fcae1",
    "semantic_title": "nonlinear reconstruction for operator learning of pdes with discontinuities",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=k60XE_b0Ix6": {
    "title": "Learning Label Encodings for Deep Regression",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "d785bded41e43ea695466d917059e75b8562c671",
    "semantic_title": "learning label encodings for deep regression",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Z3IClM_bzvP": {
    "title": "Multi-skill Mobile Manipulation for Object Rearrangement",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "344cba18285949fe409fc0b332831bc186cfeb17",
    "semantic_title": "multi-skill mobile manipulation for object rearrangement",
    "citation_count": 62,
    "authors": []
  },
  "https://openreview.net/forum?id=3RhuF8foyPW": {
    "title": "Single-shot General Hyper-parameter Optimization for Federated Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "73d5f34e826440b956db1b071a43ad583e489cf8",
    "semantic_title": "single-shot general hyper-parameter optimization for federated learning",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=RWtGreRpovS": {
    "title": "Simplicial Embeddings in Self-Supervised Learning and Downstream Classification",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "f005116ddb524a4cc3df83b24a1d15bb3b4ef87a",
    "semantic_title": "simplicial embeddings in self-supervised learning and downstream classification",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=plKu2GByCNW": {
    "title": "Vision Transformer Adapter for Dense Predictions",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "c431408780586268e8bcf2483b01a80728d10960",
    "semantic_title": "vision transformer adapter for dense predictions",
    "citation_count": 653,
    "authors": []
  },
  "https://openreview.net/forum?id=hVrXUps3LFA": {
    "title": "Divide to Adapt: Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "db20ae433d93486c45d1beacefc01f8129c84b0e",
    "semantic_title": "divide to adapt: mitigating confirmation bias for domain adaptation of black-box predictors",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=zqwryBoXYnh": {
    "title": "PLOT: Prompt Learning with Optimal Transport for Vision-Language Models",
    "volume": "spotlight",
    "abstract": "",
    "checked": false,
    "id": "0d5103378a9f4f6e08bfcd364da207f93b31b8b7",
    "semantic_title": "prompt learning with optimal transport for vision-language models",
    "citation_count": 69,
    "authors": []
  },
  "https://openreview.net/forum?id=VA1YpcNr7ul": {
    "title": "DASHA: Distributed Nonconvex Optimization with Communication Compression and Optimal Oracle Complexity",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "c760172c08c2aa6ecdb84a3915df445dde5a64cc",
    "semantic_title": "dasha: distributed nonconvex optimization with communication compression and optimal oracle complexity",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=JJuP86nBl4q": {
    "title": "LAVA: Data Valuation without Pre-Specified Learning Algorithms",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "4cc3fbdd9c07c16fd3c363363ac33e729b8021e6",
    "semantic_title": "lava: data valuation without pre-specified learning algorithms",
    "citation_count": 68,
    "authors": []
  },
  "https://openreview.net/forum?id=SEh5SfEQtqB": {
    "title": "Meta-prediction Model for Distillation-Aware NAS on Unseen Datasets",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "2fd5bb847862b29e1c5680ffeabe6737b71f58c5",
    "semantic_title": "meta-prediction model for distillation-aware nas on unseen datasets",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=rLwC0_MG-4w": {
    "title": "Denoising Diffusion Error Correction Codes",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "bd3ac574978fa0eefb2c68a19321660822de64c0",
    "semantic_title": "denoising diffusion error correction codes",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=2RwXVje1rAh": {
    "title": "Exploring Active 3D Object Detection from a Generalization Perspective",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "3b463a75c924affa60c65f7a27ef4be5b523ebc7",
    "semantic_title": "exploring active 3d object detection from a generalization perspective",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=iOc57X9KM54": {
    "title": "Neuro-Symbolic Procedural Planning with Commonsense Prompting",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "418085c9726669bf53f3d66e0018f2b08ffc4ce6",
    "semantic_title": "neuro-symbolic procedural planning with commonsense prompting",
    "citation_count": 39,
    "authors": []
  },
  "https://openreview.net/forum?id=urF_CBK5XC0": {
    "title": "Generative Augmented Flow Networks",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "1c6035ba208d64d119b7cf6a895f9e71d662b90c",
    "semantic_title": "generative augmented flow networks",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=rvsbw2YthH_": {
    "title": "The Trade-off between Universality and Label Efficiency of Representations from Contrastive Learning",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "9d3463da77f6288da6fa16631034293a733bd719",
    "semantic_title": "the trade-off between universality and label efficiency of representations from contrastive learning",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=FUORz1tG8Og": {
    "title": "CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural Representations",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "74d6a587d97bb13d0ca69bb326b454e2d87b9261",
    "semantic_title": "crom: continuous reduced-order modeling of pdes using implicit neural representations",
    "citation_count": 54,
    "authors": []
  },
  "https://openreview.net/forum?id=G2Q2Mh3avow": {
    "title": "Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "ada81a4de88a6ce474df2e2446ad11fea480616e",
    "semantic_title": "socratic models: composing zero-shot multimodal reasoning with language",
    "citation_count": 626,
    "authors": []
  },
  "https://openreview.net/forum?id=Bo7eeXm6An8": {
    "title": "Multi-lingual Evaluation of Code Generation Models",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "2577d053f8aab912d29b424e1f09133d83740fd2",
    "semantic_title": "multi-lingual evaluation of code generation models",
    "citation_count": 190,
    "authors": []
  },
  "https://openreview.net/forum?id=B_pCIsX8KL_": {
    "title": "GRACE-C: Generalized Rate Agnostic Causal Estimation via Constraints",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "9db8bfc43f7ee13d07e43e76c9b93ab177ce4b73",
    "semantic_title": "grace-c: generalized rate agnostic causal estimation via constraints",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=KwmPfARgOTD": {
    "title": "Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs",
    "volume": "spotlight",
    "abstract": "",
    "checked": true,
    "id": "1ede15a0aa5204de1f3013d7616a93dbd46fd849",
    "semantic_title": "equiformer: equivariant graph attention transformer for 3d atomistic graphs",
    "citation_count": 284,
    "authors": []
  },
  "https://openreview.net/forum?id=CWmvjOEhgH-": {
    "title": "MPCFORMER: FAST, PERFORMANT AND PRIVATE TRANSFORMER INFERENCE WITH MPC",
    "volume": "spotlight",
    "abstract": "Enabling private inference is crucial for many cloud inference services that are based on Transformer models. However, existing private inference solutions can increase the inference latency by more than 60$\\times$ or significantly compromise the inference quality. In this paper, we design the framework MPCFORMER as a practical solution, using Secure Multi-Party Computation (MPC) and Knowledge Distillation (KD). Through extensive evaluations, we show that MPCFORMER significantly speeds up Transformer inference in MPC settings while achieving similar ML performance to the input model. On the IMDb dataset, it achieves similar performance to $\\text{BERT}_\\text{BASE}$, while being 5.3$\\times$ faster. On the GLUE benchmark, it achieves 97% performance of $\\text{BERT}_\\text{BASE}$ with a 2.2$\\times$ speedup. MPCFORMER remains effective with different trained Transformer weights such as $\\text{ROBERTA}_\\text{BASE}$ and larger models including $\\text{BERT}_\\text{LARGE}$. Code is available at https://github.com/MccRee177/MPCFormer",
    "checked": true,
    "id": "2701d5b55ddacbdc82bc33901451f593a92127f1",
    "semantic_title": "mpcformer: fast, performant and private transformer inference with mpc",
    "citation_count": 100,
    "authors": []
  },
  "https://openreview.net/forum?id=qLOaeRvteqbx": {
    "title": "Disparate Impact in Differential Privacy from Gradient Misalignment",
    "volume": "spotlight",
    "abstract": "As machine learning becomes more widespread throughout society, aspects including data privacy and fairness must be carefully considered, and are crucial for deployment in highly regulated industries. Unfortunately, the application of privacy enhancing technologies can worsen unfair tendencies in models. In particular, one of the most widely used techniques for private model training, differentially private stochastic gradient descent (DPSGD), frequently intensifies disparate impact on groups within data. In this work we study the fine-grained causes of unfairness in DPSGD and identify gradient misalignment due to inequitable gradient clipping as the most significant source. This observation leads us to a new method for reducing unfairness by preventing gradient misalignment in DPSGD",
    "checked": true,
    "id": "e125db480c8a84d9b17f67fbbe577a8304dd9485",
    "semantic_title": "disparate impact in differential privacy from gradient misalignment",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=cp5PvcI6w8_": {
    "title": "TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second",
    "volume": "spotlight",
    "abstract": "We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the $18$ datasets in the OpenML-CC18 suite that contain up to 1000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with up to $230\\times$ speedup. This increases to a $5\\,700\\times$ speedup when using a GPU. We also validate these results on an additional 67 small numerical datasets from OpenML. We provide all our code, the trained TabPFN, an interactive browser demo and a Colab notebook at https://github.com/automl/TabPFN",
    "checked": true,
    "id": "4c4f0fcf1ce04f12290d8c876abfbe57817de430",
    "semantic_title": "tabpfn: a transformer that solves small tabular classification problems in a second",
    "citation_count": 401,
    "authors": []
  },
  "https://openreview.net/forum?id=SJ1kSyO2jwu": {
    "title": "Human Motion Diffusion Model",
    "volume": "spotlight",
    "abstract": "Natural and expressive human motion generation is the holy grail of computer animation. It is a challenging task, due to the diversity of possible motion, human perceptual sensitivity to it, and the difficulty of accurately describing it. Therefore, current generative solutions are either low-quality or limited in expressiveness. Diffusion models are promising candidates for the human motion domain since they have already shown remarkable generative capabilities in other domains, and their many-to-many nature. In this paper, we introduce Motion Diffusion Model (MDM), a carefully adapted classifier-free diffusion-based generative model for human motion data. MDM is transformer-based, combining insights from motion generation literature. A notable design-choice is that it predicts the sample itself rather than the noise in each step to facilitate the use of established geometric losses on the locations and velocities of the motion, such as the foot contact loss. As we demonstrate, MDM is a generic approach, enabling different modes of conditioning, and different generation tasks. We show that our model is trained with lightweight resources and yet achieves state-of-the-art results on leading benchmarks for text-to-motion, action-to-motion, and unconditioned motion generation",
    "checked": true,
    "id": "15736f7c205d961c00378a938daffaacb5a0718d",
    "semantic_title": "human motion diffusion model",
    "citation_count": 898,
    "authors": []
  },
  "https://openreview.net/forum?id=CsKwavjr7A": {
    "title": "Visual Recognition with Deep Nearest Centroids",
    "volume": "spotlight",
    "abstract": "We devise deep nearest centroids (DNC), a conceptually elegant yet surprisingly effective network for large-scale visual recognition, by revisiting Nearest Centroids, one of the most classic and simple classifiers. Current deep models learn the classifier in a fully parametric manner, ignoring the latent data structure and lacking simplicity and explainability. DNC instead conducts nonparametric, case-based reasoning; it utilizes sub-centroids of training samples to describe class distributions and clearly explains the classification as the proximity of test data and the class sub-centroids in the feature space. Due to the distance-based nature, the network output dimensionality is flexible, and all the learnable parameters are only for data embedding. That means all the knowledge learnt for ImageNet classification can be completely transferred for pixel recognition learning, under the ‘pre-training and fine-tuning' paradigm. Apart from its nested simplicity and intuitive decision-making mechanism, DNC can even possess ad-hoc explainability when the sub-centroids are selected as actual training images that humans can view and inspect. Compared with parametric counterparts, DNC performs better on image classification (CIFAR-10, ImageNet) and greatly boots pixel recognition (ADE20K, Cityscapes), with improved transparency and fewer learnable parameters, using various network architectures (ResNet, Swin) and segmentation models (FCN, DeepLabV3, Swin). We feel this work brings fundamental insights into related fields. Our code is available at https://github.com/ChengHan111/DNC",
    "checked": true,
    "id": "5b1a2d2016fdb87572a07baf65fb0d64cffdf03c",
    "semantic_title": "visual recognition with deep nearest centroids",
    "citation_count": 105,
    "authors": []
  },
  "https://openreview.net/forum?id=B73niNjbPs": {
    "title": "Continuous PDE Dynamics Forecasting with Implicit Neural Representations",
    "volume": "spotlight",
    "abstract": "Effective data-driven PDE forecasting methods often rely on fixed spatial and / or temporal discretizations. This raises limitations in real-world applications like weather prediction where flexible extrapolation at arbitrary spatiotemporal locations is required. We address this problem by introducing a new data-driven approach, DINo, that models a PDE's flow with continuous-time dynamics of spatially continuous functions. This is achieved by embedding spatial observations independently of their discretization via Implicit Neural Representations in a small latent space temporally driven by a learned ODE. This separate and flexible treatment of time and space makes DINo the first data-driven model to combine the following advantages. It extrapolates at arbitrary spatial and temporal locations; it can learn from sparse irregular grids or manifolds; at test time, it generalizes to new grids or resolutions. DINo outperforms alternative neural PDE forecasters in a variety of challenging generalization scenarios on representative PDE systems",
    "checked": true,
    "id": "d39ad86d4617e069d89b6d62c760c2ba268a2b85",
    "semantic_title": "continuous pde dynamics forecasting with implicit neural representations",
    "citation_count": 62,
    "authors": []
  },
  "https://openreview.net/forum?id=3Y5Uhf5KgGK": {
    "title": "No Reason for No Supervision: Improved Generalization in Supervised Models",
    "volume": "spotlight",
    "abstract": "We consider the problem of training a deep neural network on a given classification task, e.g., ImageNet-1K (IN1K), so that it excels at both the training task as well as at other (future) transfer tasks. These two seemingly contradictory properties impose a trade-off between improving the model's generalization and maintaining its performance on the original task. Models trained with self-supervised learning tend to generalize better than their supervised counterparts for transfer learning; yet, they still lag behind supervised models on IN1K. In this paper, we propose a supervised learning setup that leverages the best of both worlds. We extensively analyze supervised training using multi-scale crops for data augmentation and an expendable projector head, and reveal that the design of the projector allows us to control the trade-off between performance on the training task and transferability. We further replace the last layer of class weights with class prototypes computed on the fly using a memory bank and derive two models: t-ReX that achieves a new state of the art for transfer learning and outperforms top methods such as DINO and PAWS on IN1K, and t-ReX* that matches the highly optimized RSB-A1 model on IN1K while performing better on transfer tasks. Code and pretrained models: https://europe.naverlabs.com/t-rex",
    "checked": true,
    "id": "f4d2644c8c03196212d00c3bee6d941e91678400",
    "semantic_title": "no reason for no supervision: improved generalization in supervised models",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=g7U9jD_2CUr": {
    "title": "EVA3D: Compositional 3D Human Generation from 2D Image Collections",
    "volume": "spotlight",
    "abstract": "Inverse graphics aims to recover 3D models from 2D observations. Utilizing differentiable rendering, recent 3D-aware generative models have shown impressive results of rigid object generation using 2D images. However, it remains challenging to generate articulated objects, like human bodies, due to their complexity and diversity in poses and appearances. In this work, we propose, EVA3D, an unconditional 3D human generative model learned from 2D image collections only. EVA3D can sample 3D humans with detailed geometry and render high-quality images (up to 512x256) without bells and whistles (e.g. super resolution). At the core of EVA3D is a compositional human NeRF representation, which divides the human body into local parts. Each part is represented by an individual volume. This compositional representation enables 1) inherent human priors, 2) adaptive allocation of network parameters, 3) efficient training and rendering. Moreover, to accommodate for the characteristics of sparse 2D human image collections (e.g. imbalanced pose distribution), we propose a pose-guided sampling strategy for better GAN learning. Extensive experiments validate that EVA3D achieves state-of-the-art 3D human generation performance regarding both geometry and texture quality. Notably, EVA3D demonstrates great potential and scalability to \"inverse-graphics\" diverse human bodies with a clean framework",
    "checked": true,
    "id": "8cb9f266e2a051301352493b3e8c480195c08424",
    "semantic_title": "eva3d: compositional 3d human generation from 2d image collections",
    "citation_count": 128,
    "authors": []
  },
  "https://openreview.net/forum?id=DSy8tP4WctmZ": {
    "title": "Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction",
    "volume": "spotlight",
    "abstract": "Neural surface reconstruction aims to reconstruct accurate 3D surfaces based on multi-view images. Previous methods based on neural volume rendering mostly train a fully implicit model with MLPs, which typically require hours of training for a single scene. Recent efforts explore the explicit volumetric representation to accelerate the optimization via memorizing significant information with learnable voxel grids. However, existing voxel-based methods often struggle in reconstructing fine-grained geometry, even when combined with an SDF-based volume rendering scheme. We reveal that this is because 1) the voxel grids tend to break the color-geometry dependency that facilitates fine-geometry learning, and 2) the under-constrained voxel grids lack spatial coherence and are vulnerable to local minima. In this work, we present Voxurf, a voxel-based surface reconstruction approach that is both efficient and accurate. Voxurf addresses the aforementioned issues via several key designs, including 1) a two-stage training procedure that attains a coherent coarse shape and recovers fine details successively, 2) a dual color network that maintains color-geometry dependency, and 3) a hierarchical geometry feature to encourage information propagation across voxels. Extensive experiments show that Voxurf achieves high efficiency and high quality at the same time. On the DTU benchmark, Voxurf achieves higher reconstruction quality with a 20x training speedup compared to previous fully implicit methods. Our code is publicly available at https://github.com/wutong16/Voxurf/",
    "checked": true,
    "id": "9ff6afe3ac617ab819dcf720282ea63561c4a524",
    "semantic_title": "voxurf: voxel-based efficient and accurate neural surface reconstruction",
    "citation_count": 111,
    "authors": []
  },
  "https://openreview.net/forum?id=UkU05GOH7_6": {
    "title": "Generating Diverse Cooperative Agents by Learning Incompatible Policies",
    "volume": "spotlight",
    "abstract": "Training a robust cooperative agent requires diverse partner agents. However, obtaining those agents is difficult. Previous works aim to learn diverse behaviors by changing the state-action distribution of agents. But, without information about the task's goal, the diversified agents are not guided to find other important, albeit sub-optimal, solutions: the agents might learn only variations of the same solution. In this work, we propose to learn diverse behaviors via policy compatibility. Conceptually, policy compatibility measures whether policies of interest can coordinate effectively. We theoretically show that incompatible policies are not similar. Thus, policy compatibility—which has been used exclusively as a measure of robustness—can be used as a proxy for learning diverse behaviors. Then, we incorporate the proposed objective into a population-based training scheme to allow concurrent training of multiple agents. Additionally, we use state-action information to induce local variations of each policy. Empirically, the proposed method consistently discovers more solutions than baseline methods across various multi-goal cooperative environments. Finally, in multi-recipe Overcooked, we show that our method produces populations of behaviorally diverse agents, which enables generalist agents trained with such a population to be more robust. See our project page at https://bit.ly/marl-lipo",
    "checked": true,
    "id": "15521311d6d47218e54c9b9ca0cda8283fb36c52",
    "semantic_title": "generating diverse cooperative agents by learning incompatible policies",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=KbYevcLjnc": {
    "title": "PEER: A Collaborative Language Model",
    "volume": "spotlight",
    "abstract": "Textual content is often the output of a collaborative writing process: We start with an initial draft, ask for suggestions, and repeatedly make changes. Agnostic of this process, today's language models are trained to generate only the final result. As a consequence, they lack several abilities crucial for collaborative writing: They are unable to update existing texts, difficult to control and incapable of verbally planning or explaining their actions. To address these shortcomings, we introduce PEER, a collaborative language model that is trained to imitate the entire writing process itself. PEER can write drafts, add suggestions, propose edits and provide explanations for its actions. Crucially, we train multiple instances of PEER able to infill various parts of the writing process, enabling the use of self-training techniques for increasing the quality, amount and diversity of training data. This unlocks PEER's full potential by making it applicable in domains for which no edit histories are available and improving its ability to follow instructions, to write useful comments, and to explain its actions. We show that PEER achieves strong performance across various domains and editing tasks",
    "checked": true,
    "id": "a938ff4539b09a785a66669844f1a35f76169218",
    "semantic_title": "peer: a collaborative language model",
    "citation_count": 102,
    "authors": []
  },
  "https://openreview.net/forum?id=GMRodZ8OlVr": {
    "title": "ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation",
    "volume": "spotlight",
    "abstract": "Text-guided 3D shape generation remains challenging due to the absence of large paired text-shape dataset, the substantial semantic gap between these two modalities, and the structural complexity of 3D shapes. This paper presents a new framework called Image as Stepping Stone (ISS) for the task by introducing 2D image as a stepping stone to connect the two modalities and to eliminate the need for paired text-shape data. Our key contribution is a two-stage feature-space-alignment approach that maps CLIP features to shapes by harnessing a pre-trained single-view reconstruction (SVR) model with multi-view supervisions: first map the CLIP image feature to the detail-rich shape space in the SVR model, then map the CLIP text feature to the shape space and optimize the mapping by encouraging CLIP consistency between the input text and the rendered images. Further, we formulate a textguided shape stylization module to dress up the output shapes with novel structures and textures. Beyond existing works on 3D shape generation from text, our new approach is general for creating shapes in a broad range of categories, without requiring paired text-shape data. Experimental results manifest that our approach outperforms the state-of-the-arts and our baselines in terms of fidelity and consistency with text. Further, our approach can stylize the generated shapes with both realistic and fantasy structures and textures. Codes are available at https://github.com/liuzhengzhe/ISS-Image-as-Stepping-Stone-for-Text-Guided-3D-Shape-Generation",
    "checked": true,
    "id": "b8076c9f2daffeca047301ddb319dc4391a2272b",
    "semantic_title": "iss: image as stepping stone for text-guided 3d shape generation",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=1C_kSW1-k0": {
    "title": "STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK",
    "volume": "spotlight",
    "abstract": "We introduce STREET, a unified multi-task and multi-domain natural language reasoning and explanation benchmark. Unlike most existing question-answering (QA) datasets, we expect models to not only answer questions, but also produce step-by-step structured explanations describing how premises in the question are used to produce intermediate conclusions that can prove the correctness of a certain answer. We perform extensive evaluation with popular language models such as few-shot prompting GPT-3 and fine-tuned T5. We find that these models still lag behind human performance when producing such structured reasoning steps. We believe this work will provide a way for the community to better train and test systems on multi-step reasoning and explanations in natural language",
    "checked": true,
    "id": "a3a241e9397fe29b37f96cb5e8f4b8bebed3d3da",
    "semantic_title": "street: a multi-task structured reasoning and explanation benchmark",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=y5W8tpojhtJ": {
    "title": "Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class-Incremental Learning",
    "volume": "spotlight",
    "abstract": "Few-shot class-incremental learning (FSCIL) has been a challenging problem as only a few training samples are accessible for each novel class in the new sessions. Finetuning the backbone or adjusting the classifier prototypes trained in the prior sessions would inevitably cause a misalignment between the feature and classifier of old classes, which explains the well-known catastrophic forgetting problem. In this paper, we deal with this misalignment dilemma in FSCIL inspired by the recently discovered phenomenon named neural collapse, which reveals that the last-layer features of the same class will collapse into a vertex, and the vertices of all classes are aligned with the classifier prototypes, which are formed as a simplex equiangular tight frame (ETF). It corresponds to an optimal geometric structure for classification due to the maximized Fisher Discriminant Ratio. We propose a neural collapse inspired framework for FSCIL. A group of classifier prototypes are pre-assigned as a simplex ETF for the whole label space, including the base session and all the incremental sessions. During training, the classifier prototypes are not learnable, and we adopt a novel loss function that drives the features into their corresponding prototypes. Theoretical analysis shows that our method holds the neural collapse optimality and does not break the feature-classifier alignment in an incremental fashion. Experiments on the miniImageNet, CUB-200, and CIFAR-100 datasets demonstrate that our proposed framework outperforms the state-of-the-art performances. Code address: https://github.com/NeuralCollapseApplications/FSCIL",
    "checked": false,
    "id": "85fa07886672bc19429295ea7f69c3f2888fe80f",
    "semantic_title": "neural collapse inspired feature-classifier alignment for few-shot class incremental learning",
    "citation_count": 135,
    "authors": []
  },
  "https://openreview.net/forum?id=WbxHAzkeQcn": {
    "title": "Neural Networks and the Chomsky Hierarchy",
    "volume": "spotlight",
    "abstract": "Reliable generalization lies at the heart of safe ML and AI. However, understanding when and how neural networks generalize remains one of the most important unsolved problems in the field. In this work, we conduct an extensive empirical study (20'910 models, 15 tasks) to investigate whether insights from the theory of computation can predict the limits of neural network generalization in practice. We demonstrate that grouping tasks according to the Chomsky hierarchy allows us to forecast whether certain architectures will be able to generalize to out-of-distribution inputs. This includes negative results where even extensive amounts of data and training time never lead to any non-trivial generalization, despite models having sufficient capacity to fit the training data perfectly. Our results show that, for our subset of tasks, RNNs and Transformers fail to generalize on non-regular tasks, LSTMs can solve regular and counter-language tasks, and only networks augmented with structured memory (such as a stack or memory tape) can successfully generalize on context-free and context-sensitive tasks",
    "checked": true,
    "id": "c6d38add1b7bbc10f0da37a90e3f1b51ee5fb617",
    "semantic_title": "neural networks and the chomsky hierarchy",
    "citation_count": 174,
    "authors": []
  },
  "https://openreview.net/forum?id=D1Iqfm7WTkk": {
    "title": "Neural ePDOs: Spatially Adaptive Equivariant Partial Differential Operator Based Networks",
    "volume": "spotlight",
    "abstract": "Endowing deep learning models with symmetry priors can lead to a considerable performance improvement. As an interesting bridge between physics and deep learning, the equivariant partial differential operators (PDOs) have drawn much researchers' attention recently. However, to ensure the PDOs translation equivariance, previous works have to require coefficient matrices to be constant and spatially shared for their linearity, which could lead to the sub-optimal feature learning at each position. In this work, we propose a novel nonlinear PDOs scheme that is both spatially adaptive and translation equivariant. The coefficient matrices are obtained by local features through a generator rather than spatially shared. Besides, we establish a new theory on incorporating more equivariance like rotations for such PDOs. Based on our theoretical results, we efficiently implement the generator with an equivariant multilayer perceptron (EMLP). As such equivariant PDOs are generated by neural networks, we call them Neural ePDOs. In experiments, we show that our method can significantly improve previous works with smaller model size in various datasets. Especially, we achieve the state-of-the-art performance on the MNIST-rot dataset with only half parameters of the previous best model",
    "checked": true,
    "id": "bf172883d10dfe6fda9b3387e37b880eb8929302",
    "semantic_title": "neural epdos: spatially adaptive equivariant partial differential operator based networks",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=NAQvF08TcyG": {
    "title": "An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion",
    "volume": "spotlight",
    "abstract": "Text-to-image models offer unprecedented freedom to guide creation through natural language. Yet, it is unclear how such freedom can be exercised to generate images of specific unique concepts, modify their appearance, or compose them in new roles and novel scenes. In other words, we ask: how can we use language-guided models to turn *our* cat into a painting, or imagine a new product based on *our* favorite toy? Here we present a simple approach that allows such creative freedom. Using only $3$-$5$ images of a user-provided concept, like an object or a style, we learn to represent it through new ``words\" in the embedding space of a frozen text-to-image model. These ``words\" can be composed into natural language sentences, guiding *personalized* creation in an intuitive way. Notably, we find evidence that a *single* word embedding is sufficient for capturing unique and varied concepts. We compare our approach to a wide range of baselines, and demonstrate that it can more faithfully portray the concepts across a range of applications and tasks. Our code, data and new words will be available",
    "checked": true,
    "id": "5406129d9d7d00dc310671c43597101b0ee93629",
    "semantic_title": "an image is worth one word: personalizing text-to-image generation using textual inversion",
    "citation_count": 2164,
    "authors": []
  },
  "https://openreview.net/forum?id=nUmCcZ5RKF": {
    "title": "IS SYNTHETIC DATA FROM GENERATIVE MODELS READY FOR IMAGE RECOGNITION?",
    "volume": "spotlight",
    "abstract": "Recent text-to-image generation models have shown promising results in generating high-fidelity photo-realistic images. Though the results are astonishing to human eyes, how applicable these generated images are for recognition tasks remains under-explored. In this work, we extensively study whether and how synthetic images generated from state-of-the-art text-to-image generation models can be used for image recognition tasks, and focus on two perspectives: synthetic data for improving classification models in the data-scare settings (i.e. zero-shot and few-shot), and synthetic data for large-scale model pre-training for transfer learning. We showcase the powerfulness and shortcomings of synthetic data from existing generative models, and propose strategies for better applying synthetic data for recognition tasks. Code: https://github.com/CVMI-Lab/SyntheticData",
    "checked": true,
    "id": "2a29e1bcbed17c588ffbae1fea2af3baaab924b8",
    "semantic_title": "is synthetic data from generative models ready for image recognition?",
    "citation_count": 338,
    "authors": []
  },
  "https://openreview.net/forum?id=k7p_YAO7yE": {
    "title": "MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction",
    "volume": "spotlight",
    "abstract": "High-definition (HD) map provides abundant and precise environmental information of the driving scene, serving as a fundamental and indispensable component for planning in autonomous driving system. We present MapTR, a structured end-to-end Transformer for efficient online vectorized HD map construction. We propose a unified permutation-equivalent modeling approach, i.e., modeling map element as a point set with a group of equivalent permutations, which accurately describes the shape of map element and stabilizes the learning process. We design a hierarchical query embedding scheme to flexibly encode structured map information and perform hierarchical bipartite matching for map element learning. MapTR achieves the best performance and efficiency with only camera input among existing vectorized map construction approaches on nuScenes dataset. In particular, MapTR-nano runs at real-time inference speed ($25.1$ FPS) on RTX 3090, $8\\times$ faster than the existing state-of-the-art camera-based method while achieving $5.0$ higher mAP. Even compared with the existing state-of-the-art multi-modality method, MapTR-nano achieves $0.7$ higher mAP and $8\\times$ faster inference speed, and MapTR-tiny achieves $13.5$ higher mAP and $3\\times$ faster inference speed. Abundant qualitative results show that MapTR maintains stable and robust map construction quality in complex and various driving scenes. MapTR is of great application value in autonomous driving. Code and more demos are available at https://github.com/hustvl/MapTR",
    "checked": true,
    "id": "e26ea26f3195cfc7675f5ae3795b4960b76b97d4",
    "semantic_title": "maptr: structured modeling and learning for online vectorized hd map construction",
    "citation_count": 288,
    "authors": []
  },
  "https://openreview.net/forum?id=zEn1BhaNYsC": {
    "title": "Minimax Optimal Kernel Operator Learning via Multilevel Training",
    "volume": "spotlight",
    "abstract": "Learning mappings between infinite-dimensional function spaces have achieved empirical success in many disciplines of machine learning, including generative modeling, functional data analysis, causal inference, and multi-agent reinforcement learning. In this paper, we study the statistical limit of learning a Hilbert-Schmidt operator between two infinite-dimensional Sobolev reproducing kernel Hilbert spaces. We establish the information-theoretic lower bound in terms of the Sobolev Hilbert-Schmidt norm and show that a regularization that learns the spectral components below the bias contour and ignores the ones above the variance contour can achieve the optimal learning rate. At the same time, the spectral components between the bias and variance contours give us flexibility in designing computationally feasible machine learning algorithms. Based on this observation, we develop a multilevel kernel operator learning algorithm that is optimal when learning linear operators between infinite-dimensional function spaces",
    "checked": true,
    "id": "c038c1a5f0e54b002521925ce6b40e426f0d1421",
    "semantic_title": "minimax optimal kernel operator learning via multilevel training",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=NRxydtWup1S": {
    "title": "Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling",
    "volume": "spotlight",
    "abstract": "We identify and overcome two key obstacles in extending the success of BERT-style pre-training, or masked image modeling, to convolutional networks (convnets): (i) convolution operation cannot handle irregular, randomly masked input images; (ii) the single-scale nature of BERT pre-training is inconsistent with convnet's hierarchical structure. For (i), we treat unmasked pixels as sparse voxels of 3D point clouds and use sparse convolution to encode. This is the first use of sparse convolution for 2D masked modeling. For (ii), we develop a hierarchical decoder to reconstruct images from multi-scale encoded features. Our method, called Sparse masKed modeling (SparK), is general: it can be used directly on any convolutional model without backbone modifications. We validate it on both classical (ResNet) and modern (ConvNeXt) models: on three downstream tasks, it surpasses both state-of-the-art contrastive learning and transformer-based masked modeling by similarly large margins (around +1.0%). The improvements on object detection and instance segmentation are more significant (up to +3.5%), validating the strong transferability of features learned. We also find SparK's favorable scaling behavior by observing more gains on larger networks. All of these findings support the promising future of generative pre-training on convnets. Both codes and pre-trained models have been released at https://github.com/keyu-tian/SparK",
    "checked": true,
    "id": "e45c0a415b01b13d25e7dbced9f651261be0feaf",
    "semantic_title": "designing bert for convolutional networks: sparse and hierarchical masked modeling",
    "citation_count": 123,
    "authors": []
  },
  "https://openreview.net/forum?id=RUzSobdYy0V": {
    "title": "Quantifying and Mitigating the Impact of Label Errors on Model Disparity Metrics",
    "volume": "poster",
    "abstract": "Errors in labels obtained via human annotation adversely affect a trained model's performance. Existing approaches propose ways to mitigate the effect of label error on a model's downstream accuracy, yet little is known about its impact on a model's group-based disparity metrics\\footnote{Group-based disparity metrics like subgroup calibration, false positive rate, false negative rate, equalized odds, and equal opportunity are more often known, colloquially, as \\textit{fairness metrics} in the literature. We use the term group-based disparity metrics in this work.}. Here we study the effect of label error on a model's group-based disparity metrics like group calibration. We empirically characterize how varying levels of label error, in both training and test data, affect these disparity metrics. We find that group calibration and other metrics are sensitive to train-time and test-time label error---particularly for minority groups. For the same level of label error, the percentage change in group calibration error for the minority group is on average 1.5 times larger than the change for the majority group. Towards mitigating the impact of training-time label error, we present an approach to estimate how changing a single training input's label affects a model's group disparity metric on a test set. We empirically assess the proposed approach on a variety of datasets and find a 10-40\\% improvement, compared to alternative approaches, in identifying training inputs that improve a model's disparity metric. The proposed approach can help surface training inputs that may need to be corrected for improving a model's group-based disparity metrics",
    "checked": true,
    "id": "e531451e6e2cd5d776cc0dd75a5a1068066ed2f7",
    "semantic_title": "quantifying and mitigating the impact of label errors on model disparity metrics",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=tmIiMPl4IPa": {
    "title": "Factorized Fourier Neural Operators",
    "volume": "poster",
    "abstract": "We propose the Factorized Fourier Neural Operator (F-FNO), a learning-based approach for simulating partial differential equations (PDEs). Starting from a recently proposed Fourier representation of flow fields, the F-FNO bridges the performance gap between pure machine learning approaches to that of the best numerical or hybrid solvers. This is achieved with new representations – separable spectral layers and improved residual connections – and a combination of training strategies such as the Markov assumption, Gaussian noise, and cosine learning rate decay. On several challenging benchmark PDEs on regular grids, structured meshes, and point clouds, the F-FNO can scale to deeper networks and outperform both the FNO and the geo-FNO, reducing the error by 83% on the Navier-Stokes problem, 31% on the elasticity problem, 57% on the airfoil flow problem, and 60% on the plastic forging problem. Compared to the state-of-the-art pseudo-spectral method, the F-FNO can take a step size that is an order of magnitude larger in time and achieve an order of magnitude speedup to produce the same solution quality",
    "checked": true,
    "id": "50bfb95187503caf0bd0daa6077f6df9de4c7456",
    "semantic_title": "factorized fourier neural operators",
    "citation_count": 193,
    "authors": []
  },
  "https://openreview.net/forum?id=mhnHqRqcjYU": {
    "title": "DFPC: Data flow driven pruning of coupled channels without data",
    "volume": "poster",
    "abstract": "Modern, multi-branched neural network architectures often possess complex interconnections between layers, which we call coupled channels (CCs). Structured pruning of CCs in these multi-branch networks is an under-researched problem, as most existing works are typically designed for pruning single-branch models like VGG-nets. While these methods yield accurate subnetworks, the improvements in inference times when applied to multi-branch networks are comparatively modest, as these methods do not prune CCs, which we observe contribute significantly to inference time. For instance, layers with CCs as input or output take more than 66% of the inference time in ResNet-50. Moreover, pruning in the data-free regime, where data is not used for pruning, is gaining traction owing to privacy concerns and computational costs associated with fine-tuning. Motivated by this, we study the problem of pruning CCs in the data-free regime. To facilitate the development of algorithms to prune CCs, we define Data Flow Couplings (DFCs) to enumerate the layers that constitute coupled connections and the associated transformation. Additionally, saliencies for pruning CCs cannot be gauged in isolation, as there may be discrepancies among the layerwise importance of CCs using conventional scoring strategies. This necessitates finding grouped saliencies to gauge the importance of all corresponding coupled elements in a network. We thus propose the Backwards Graph-based Saliency Computation (BGSC) algorithm, a data-free method that computes saliencies by estimating an upper bound to the reconstruction error of intermediate layers; we call this pruning strategy Data Flow driven Pruning of Coupled channels (DFPC). Finally, we show the efficacy of DFPC for models trained on standard datasets. Since we pruned coupled channels, we achieve up to 1.66x improvements in inference time for ResNet-101 trained on CIFAR-10 with a 5% accuracy drop without fine-tuning. With access to the ImageNet training set, we achieve significant improvements over the data-free method and see an improvement of at least 47.1% in speedup for a 2.3% accuracy drop for ResNet-50 against our baselines",
    "checked": true,
    "id": "57a2f56f2f44de8ab892c4e8c3f1744530a55399",
    "semantic_title": "dfpc: data flow driven pruning of coupled channels without data",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=sZI1Oj9KBKy": {
    "title": "TVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning",
    "volume": "poster",
    "abstract": "Achieving structured, data-free sparsity of deep neural networks (DNNs) remains an open area of research. In this work, we address the challenge of pruning filters without access to the original training set or loss function. We propose the discriminative filters hypothesis, that well-trained models possess discriminative filters, and any non-discriminative filters can be pruned without impacting the predictive performance of the classifier. Based on this hypothesis, we propose a new paradigm for pruning neural networks: distributional pruning, wherein we only require access to the distributions that generated the original datasets. Our approach to solving the problem of formalising and quantifying the discriminating ability of filters is through the total variation (TV) distance between the class-conditional distributions of the filter outputs. We present empirical results that, using this definition of discriminability, support our hypothesis on a variety of datasets and architectures. Next, we define the LDIFF score, a heuristic to quantify the extent to which a layer possesses a mixture of discriminative and non-discriminative filters. We empirically demonstrate that the LDIFF score is indicative of the performance of random pruning for a given layer, and thereby indicates the extent to which a layer may be pruned. Our main contribution is a novel one-shot pruning algorithm, called TVSPrune, that identifies non-discriminative filters for pruning. We extend this algorithm to IterTVSPrune, wherein we iteratively apply TVSPrune, thereby enabling us to achieve greater sparsity. Last, we demonstrate the efficacy of the TVSPrune on a variety of datasets, and show that in some cases, we can prune up to 60% of parameters with only a 2% loss of accuracy without any fine-tuning of the model, beating the nearest baseline by almost 10%",
    "checked": true,
    "id": "49215392c790076064c86c5d6ac301e951d8d42b",
    "semantic_title": "tvsprune - pruning non-discriminative filters via total variation separability of intermediate representations without fine tuning",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=I3HCE7Ro78H": {
    "title": "Finding Actual Descent Directions for Adversarial Training",
    "volume": "poster",
    "abstract": "Adversarial Training using a strong first-order adversary (PGD) is the gold standard for training Deep Neural Networks that are robust to adversarial examples. We show that, contrary to the general understanding of the method, the gradient at an optimal adversarial example may increase, rather than decrease, the adversarially robust loss. This holds independently of the learning rate. More precisely, we provide a counterexample to a corollary of Danskin's Theorem presented in the seminal paper of Madry et al. (2018) which states that a solution of the inner maximization problem can yield a descent direction for the adversarially robust loss. Based on a correct interpretation of Danskin's Theorem, we propose Danskin's Descent Direction (DDi) and we verify experimentally that it provides better directions than those obtained by a PGD adversary. Using the CIFAR10 dataset we further provide a real world example showing that our method achieves a steeper increase in robustness levels in the early stages of training, and is more stable than the PGD baseline. As a limitation, PGD training of ReLU+BatchNorm networks still performs better, but current theory is unable to explain this",
    "checked": true,
    "id": "3e6da1517c593108cc3f1c0b858b3ad7fbbf85dc",
    "semantic_title": "finding actual descent directions for adversarial training",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=6iEoTr-jeB7": {
    "title": "Learning Continuous Normalizing Flows For Faster Convergence To Target Distribution via Ascent Regularizations",
    "volume": "poster",
    "abstract": "Normalizing flows (NFs) have been shown to be advantageous in modeling complex distributions and improving sampling efficiency for unbiased sampling. In this work, we propose a new class of continuous NFs, ascent continuous normalizing flows (ACNFs), that makes a base distribution converge faster to a target distribution. As solving such a flow is non-trivial and barely possible, we propose a practical implementation to learn flexibly parametric ACNFs via ascent regularization and apply it in two learning cases: maximum likelihood learning for density estimation and minimizing reverse KL divergence for unbiased sampling and variational inference. The learned ACNFs demonstrate faster convergence towards the target distributions, therefore, achieving better density estimations, unbiased sampling and variational approximation at lower computational costs. Furthermore, the flows show to stabilize themselves to mitigate performance deterioration and are less sensitive to the choice of training flow length $T$",
    "checked": true,
    "id": "b8d2482005f6cb87d3b4b8a47b5d5cc7dfe67463",
    "semantic_title": "learning continuous normalizing flows for faster convergence to target distribution via ascent regularizations",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=HTJE5Krui0g": {
    "title": "Softened Symbol Grounding for Neuro-symbolic Systems",
    "volume": "poster",
    "abstract": "Neuro-symbolic learning generally consists of two separated worlds, i.e., neural network training and symbolic constraint solving, whose success hinges on symbol grounding, a fundamental problem in AI. This paper presents a novel, softened symbol grounding process, bridging the gap between the two worlds, and resulting in an effective and efficient neuro-symbolic learning framework. Technically, the framework features (1) modeling of symbol solution states as a Boltzmann distribution, which avoids expensive state searching and facilitates mutually beneficial interactions between network training and symbolic reasoning; (2) a new MCMC technique leveraging projection and SMT solvers, which efficiently samples from disconnected symbol solution spaces; (3) an annealing mechanism that can escape from sub-optimal symbol groundings. Experiments with three representative neuro-symbolic learning tasks demonstrate that, owing to its superior symbol grounding capability, our framework successfully solves problems well beyond the frontier of the existing proposals",
    "checked": false,
    "id": "104c0f48db425b01d0c3fd0fc4bf570e48f4da39",
    "semantic_title": "ymbol g rounding for n euro - symbolic",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jREF4bkfi_S": {
    "title": "Mini-batch k -means terminates within O ( d / ϵ ) iterations",
    "volume": "poster",
    "abstract": "We answer the question: \"Does \\emph{local} progress (on batches) imply \\emph{global} progress (on the entire dataset) for mini-batch $k$-means?\". Specifically, we consider mini-batch $k$-means which terminates only when the improvement in the quality of the clustering on the sampled batch is below some threshold. Although at first glance it appears that this algorithm might execute forever, we answer the above question in the affirmative and show that if the batch is of size $\\tilde{\\Omega}((d/\\epsilon)^2)$, it must terminate within $O(d/\\epsilon)$ iterations with high probability, where $d$ is the dimension of the input, and $\\epsilon$ is a threshold parameter for termination. This is true \\emph{regardless} of how the centers are initialized. When the algorithm is initialized with the $k$-means++ initialization scheme, it achieves an approximation ratio of $O(\\log k)$ (the same as the full-batch version). Finally, we show the applicability of our results to the mini-batch $k$-means algorithm implemented in the scikit-learn (sklearn) python library",
    "checked": false,
    "id": "82aa0cf79eca312bde0ff92e489690a686140958",
    "semantic_title": "mini-batch k-means terminates within o(d/ε) iterations",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=pWVASryOyFw": {
    "title": "Learning Uncertainty for Unknown Domains with Zero-Target-Assumption",
    "volume": "poster",
    "abstract": "We introduce our Maximum-Entropy Rewarded Reinforcement Learning (MERRL) framework that selects training data for more accurate Natural Language Processing (NLP). Because conventional data selection methods select training samples based on the test domain knowledge and not on real life data, they frequently fail in unknown domains like patent and Twitter. Our approach selects training samples that maximize information uncertainty measured by entropy, including observation entropy like empirical Shannon entropy, Min-entropy, R\\'enyi entropy, and prediction entropy using mutual information, to cover more possible queries that may appear in unknown worlds. Our MERRL using regularized A2C and SAC achieves up to -99.7 perplexity decrease (-43.4\\% relatively) in language modeling, +25.0 accuracy increase (+40.0\\% relatively) in sentiment analysis, and +5.0 F1 score increase (+30.8\\% relatively) in named entity recognition over various domains, demonstrating strong generalization power on unknown test sets",
    "checked": true,
    "id": "b83308201eba0bfffd0c55396906fbf2c3c8f406",
    "semantic_title": "learning uncertainty for unknown domains with zero-target-assumption",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=ULzyv9M1j5": {
    "title": "Transformer-based model for symbolic regression via joint supervised learning",
    "volume": "poster",
    "abstract": "Symbolic regression (SR) is an important technique for discovering hidden mathematical expressions from observed data. Transformer-based approaches have been widely used for machine translation due to their high performance, and are recently highly expected to be used for SR. They input the data points, then output the expression skeleton, and finally optimize the coefficients. However, recent transformer-based methods for SR focus more attention on large scale training data and ignore the ill-posed problem: the lack of sufficient supervision, i.e., expressions that may be completely different have the same supervision because of their same skeleton, which makes it challenging to deal with data that may be from the same expression skeleton but with different coefficients. Therefore, we present a transformer-based model for SR with the ability to alleviate this problem. Specifically, we leverage a feature extractor based on pure residual MLP networks to obtain more information about data points. Furthermore, the core idea is that we propose a joint learning mechanism combining supervised contrastive learning, which makes features of data points from expressions with the same skeleton more similar so as to effectively alleviates the ill-posed problem. The benchmark results show that the proposed method is up to 25% higher with respect to the recovery rate of skeletons than typical transformer-based methods. Moreover, our method outperforms state-of-the-art SR methods based on reinforcement learning and genetic programming in terms of the coefficient of determination ($R^2$)",
    "checked": true,
    "id": "e0e129b95b624e50778095f62f65e3f9ab4668d2",
    "semantic_title": "transformer-based model for symbolic regression via joint supervised learning",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=gNI4_85Cyve": {
    "title": "QAID: Question Answering Inspired Few-shot Intent Detection",
    "volume": "poster",
    "abstract": "Intent detection with semantically similar fine-grained intents is a challenging task. To address it, we reformulate intent detection as a question-answering retrieval task by treating utterances and intent names as questions and answers. To that end, we utilize a question-answering retrieval architecture and adopt a two stages training schema with batch contrastive loss. In the pre-training stage, we improve query representations through self-supervised training. Then, in the fine-tuning stage, we increase contextualized token-level similarity scores between queries and answers from the same intent. Our results on three few-shot intent detection benchmarks achieve state-of-the-art performance",
    "checked": true,
    "id": "c27210604ad9626e4cf928c5073678493dd9c8fe",
    "semantic_title": "qaid: question answering inspired few-shot intent detection",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=ejR4E1jaH9k": {
    "title": "Solving stochastic weak Minty variational inequalities without increasing batch size",
    "volume": "poster",
    "abstract": "This paper introduces a family of stochastic extragradient-type algorithms for a class of nonconvex-nonconcave problems characterized by the weak Minty variational inequality (MVI). Unlike existing results on extragradient methods in the monotone setting, employing diminishing stepsizes is no longer possible in the weak MVI setting. This has led to approaches such as increasing batch sizes per iteration which can however be prohibitively expensive. In contrast, our proposed methods involves two stepsizes and only requires one additional oracle evaluation per iteration. We show that it is possible to keep one fixed stepsize while it is only the second stepsize that is taken to be diminishing, making it interesting even in the monotone setting. Almost sure convergence is established and we provide a unified analysis for this family of schemes which contains a nonlinear generalization of the celebrated primal dual hybrid gradient algorithm",
    "checked": true,
    "id": "c4020d85eb25b3782c634cb36dd5d00c4300b43c",
    "semantic_title": "solving stochastic weak minty variational inequalities without increasing batch size",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=r9fX833CsuN": {
    "title": "Curriculum-based Co-design of Morphology and Control of Voxel-based Soft Robots",
    "volume": "poster",
    "abstract": "Co-design of morphology and control of a Voxel-based Soft Robot (VSR) is challenging due to the notorious bi-level optimization. In this paper, we present a Curriculum-based Co-design (CuCo) method for learning to design and control VSRs through an easy-to-difficult process. Specifically, we expand the design space from a small size to the target size gradually through a predefined curriculum. At each learning stage of the curriculum, we use reinforcement learning to simultaneously train the design policy and the control policy, which is enabled by incorporating the design process into the environment and using differentiable policy representations. The converged morphology and the learned policies from last stage are inherited and then serve as the starting point for the next stage. In empirical studies, we show that CuCo is more efficient in creating larger robots with better performance by reusing the practical design and control patterns learned within each stage, in comparison to prior approaches that learn from scratch in the space of target size",
    "checked": true,
    "id": "599811e35d6218e7b7db74e06bfdf1e4e13cb2d5",
    "semantic_title": "curriculum-based co-design of morphology and control of voxel-based soft robots",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=tPKKXeW33YU": {
    "title": "WiNeRT: Towards Neural Ray Tracing for Wireless Channel Modelling and Differentiable Simulations",
    "volume": "poster",
    "abstract": "In this paper, we work towards a neural surrogate to model wireless electro-magnetic propagation effects in indoor environments. Such neural surrogates provide a fast, differentiable, and continuous representation of the environment and enables end-to-end optimization for downstream tasks (e.g., network planning). Specifically, the goal of the paper is to render the wireless signal (e.g., time-of-flights, power of each path) in an environment as a function of the sensor's spatial configuration (e.g., placement of transmit and receive antennas). NeRF-based approaches have shown promising results in the visual setting (RGB image signal, with a camera sensor), where the key idea is to algorithmically evaluate the 'global' signal (e.g., using volumetric rendering) by breaking it down in a sequence of 'local' evaluations (e.g., using co-ordinate neural networks). In a similar spirit, we model the time-angle channel impulse response (the global wireless signal) as a superposition of multiple paths. The wireless characteristics (e.g., power) of each path is a result of multiple evaluations of a neural network that learns implicit ray-surface interaction properties. We evaluate our approach in multiple indoor scenarios and demonstrate that our model achieves strong performance (e.g., $<$0.33ns error in time-of-flight predictions). Furthermore, we demonstrate that our neural surrogate whitens the `black-box' wireless simulators, and thus enables inverse rendering applications (e.g., user localization)",
    "checked": true,
    "id": "e113d13819cf35029c11d171ff039ab01e61226c",
    "semantic_title": "winert: towards neural ray tracing for wireless channel modelling and differentiable simulations",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=o3Q4m8jg4BR": {
    "title": "LS-IQ: Implicit Reward Regularization for Inverse Reinforcement Learning",
    "volume": "poster",
    "abstract": "Recent methods for imitation learning directly learn a $Q$-function using an implicit reward formulation rather than an explicit reward function. However, these methods generally require implicit reward regularization to improve stability and often mistreat absorbing states. Previous works show that a squared norm regularization on the implicit reward function is effective, but do not provide a theoretical analysis of the resulting properties of the algorithms. In this work, we show that using this regularizer under a mixture distribution of the policy and the expert provides a particularly illuminating perspective: the original objective can be understood as squared Bellman error minimization, and the corresponding optimization problem minimizes a bounded $\\chi^2$-Divergence between the expert and the mixture distribution. This perspective allows us to address instabilities and properly treat absorbing states. We show that our method, Least Squares Inverse Q-Learning (LS-IQ), outperforms state-of-the-art algorithms, particularly in environments with absorbing states. Finally, we propose to use an inverse dynamics model to learn from observations only. Using this approach, we retain performance in settings where no expert actions are available",
    "checked": true,
    "id": "c8bd100b509367e831881c177a1ba41f4828d41f",
    "semantic_title": "ls-iq: implicit reward regularization for inverse reinforcement learning",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=oJpVVGXu9i": {
    "title": "Share Your Representation Only: Guaranteed Improvement of the Privacy-Utility Tradeoff in Federated Learning",
    "volume": "poster",
    "abstract": "Repeated parameter sharing in federated learning causes significant information leakage about private data, thus defeating its main purpose: data privacy. Mitigating the risk of this information leakage, using state of the art differentially private algorithms, also does not come for free. Randomized mechanisms can prevent convergence of models on learning even the useful representation functions, especially if there is more disagreement between local models on the classification functions (due to data heterogeneity). In this paper, we consider a representation federated learning objective that encourages various parties to collaboratively refine the consensus part of the model, with differential privacy guarantees, while separately allowing sufficient freedom for local personalization (without releasing it). We prove that in the linear representation setting, while the objective is non-convex, our proposed new algorithm \\DPFEDREP\\ converges to a ball centered around the \\emph{global optimal} solution at a linear rate, and the radius of the ball is proportional to the reciprocal of the privacy budget. With this novel utility analysis, we improve the SOTA utility-privacy trade-off for this problem by a factor of $\\sqrt{d}$, where $d$ is the input dimension. We empirically evaluate our method with the image classification task on CIFAR10, CIFAR100, and EMNIST, and observe a significant performance improvement over the prior work under the same small privacy budget. The code can be found in this link, https://github.com/shenzebang/CENTAUR-Privacy-Federated-Representation-Learning",
    "checked": true,
    "id": "3ab8343bd8494a8370c1115007081f94e57ddca8",
    "semantic_title": "share your representation only: guaranteed improvement of the privacy-utility tradeoff in federated learning",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=eDLwjKmtYFt": {
    "title": "EquiMod: An Equivariance Module to Improve Visual Instance Discrimination",
    "volume": "poster",
    "abstract": "Recent self-supervised visual representation methods are closing the gap with supervised learning performance. Most of these successful methods rely on maximizing the similarity between embeddings of related synthetic inputs created through data augmentations. This can be seen as a task that encourages embeddings to leave out factors modified by these augmentations, i.e. to be invariant to them. However, this only considers one side of the trade-off in the choice of the augmentations: they need to strongly modify the images to avoid simple solution shortcut learning (e.g. using only color histograms), but on the other hand, augmentations-related information may be lacking in the representations for some downstream tasks (e.g. literature shows that color is important for bird and flower classification). Few recent works proposed to mitigate this problem of using only an invariance task by exploring some form of equivariance to augmentations. This has been performed by learning additional embeddings space(s), where some augmentation(s) cause embeddings to differ, yet in a non-controlled way. In this work, we introduce EquiMod a generic equivariance module that structures the learned latent space, in the sense that our module learns to predict the displacement in the embedding space caused by the augmentations. We show that applying that module to state-of-the-art invariance models, such as BYOL and SimCLR, increases the performances on the usual CIFAR10 and ImageNet datasets. Moreover, while our model could collapse to a trivial equivariance, i.e. invariance, we observe that it instead automatically learns to keep some augmentations-related information beneficial to the representations",
    "checked": true,
    "id": "c0241327a3ca4d2756dc64c5c50a89c4172d37da",
    "semantic_title": "equimod: an equivariance module to improve visual instance discrimination",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=-M0TNnyWFT5": {
    "title": "Task-Aware Information Routing from Common Representation Space in Lifelong Learning",
    "volume": "poster",
    "abstract": "Intelligent systems deployed in the real world suffer from catastrophic forgetting when exposed to a sequence of tasks. Humans, on the other hand, acquire, consolidate, and transfer knowledge between tasks that rarely interfere with the consolidated knowledge. Accompanied by self-regulated neurogenesis, continual learning in the brain is governed by the rich set of neurophysiological processes that harbor different types of knowledge which are then integrated by the conscious processing. Thus, inspired by Global Workspace Theory of conscious information access in the brain, we propose TAMiL, a continual learning method that entails task-attention modules to capture task-specific information from the common representation space. We employ simple, undercomplete autoencoders to create a communication bottleneck between the common representation space and the global workspace, allowing only the task-relevant information to the global workspace, thereby greatly reducing task interference. Experimental results show that our method outperforms state-of-the-art rehearsal-based and dynamic sparse approaches and bridges the gap between fixed capacity and parameter isolation approaches while being scalable. We also show that our method effectively mitigates catastrophic forgetting while being well-calibrated with reduced task-recency bias",
    "checked": true,
    "id": "7b64984a059c8b56feec5ebf4ecace0d71870326",
    "semantic_title": "task-aware information routing from common representation space in lifelong learning",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=htL4UZ344nF": {
    "title": "CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code",
    "volume": "poster",
    "abstract": "Recent works have widely adopted large language model pretraining for source code, suggested source code-specific pretraining objectives and investigated the applicability of various Transformer-based language model architectures for source code. This work investigates another important aspect of such models, the effect of different subtokenization options, and aims at identifying most effective and length-efficient subtokenizations, taking into account source code specifics. We propose subtokenziation that reduces average length by 17--40% without downstream performance drop, and show that a carefully chosen subtokenization may improve quality by 0.5-2%, possibly with some length increase",
    "checked": true,
    "id": "e6b73466bab5e52ce0db19dd06d9353c26557dae",
    "semantic_title": "codebpe: investigating subtokenization options for large language model pretraining on source code",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=x-mXzBgCX3a": {
    "title": "FairGBM: Gradient Boosting with Fairness Constraints",
    "volume": "poster",
    "abstract": "Tabular data is prevalent in many high-stakes domains, such as financial services or public policy. Gradient Boosted Decision Trees (GBDT) are popular in these settings due to their scalability, performance, and low training cost. While fairness in these domains is a foremost concern, existing in-processing Fair ML methods are either incompatible with GBDT, or incur in significant performance losses while taking considerably longer to train. We present FairGBM, a dual ascent learning framework for training GBDT under fairness constraints, with little to no impact on predictive performance when compared to unconstrained GBDT. Since observational fairness metrics are non-differentiable, we propose smooth convex error rate proxies for common fairness criteria, enabling gradient-based optimization using a ``proxy-Lagrangian'' formulation. Our implementation shows an order of magnitude speedup in training time relative to related work, a pivotal aspect to foster the widespread adoption of FairGBM by real-world practitioners",
    "checked": true,
    "id": "814a5a6f75c1b47b5f2b6ae0c6a359711669975d",
    "semantic_title": "fairgbm: gradient boosting with fairness constraints",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=18XzeuYZh_": {
    "title": "Online Bias Correction for Task-Free Continual Learning",
    "volume": "poster",
    "abstract": "Task-free continual learning is the machine-learning setting where a model is trained online with data generated by a nonstationary stream. Conventional wisdom suggests that, in this setting, models are trained using an approach called experience replay, where the risk is computed both with respect to current stream observations and to a small subset of past observations. In this work, we explain both theoretically and empirically how experience replay biases the outputs of the model towards recent stream observations. Moreover, we propose a simple approach to mitigate this bias online, by changing how the output layer of the model is optimized. We show that our approach improves significantly the learning performance of experience-replay approaches over different datasets. Our findings suggest that, when performing experience replay, the output layer of the model should be optimized separately from the preceding layers",
    "checked": true,
    "id": "6009d662a2f4b220aec9ad0abdc7c4932c51e6b7",
    "semantic_title": "online bias correction for task-free continual learning",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=TN9gQ4x0Ep3": {
    "title": "Don't fear the unlabelled: safe semi-supervised learning via debiasing",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "eda9d680ea91462bdd8356285ef0d68ea131b4f9",
    "semantic_title": "don't fear the unlabelled: safe semi-supervised learning via debiasing",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=bjPPypbLre": {
    "title": "Making Substitute Models More Bayesian Can Enhance Transferability of Adversarial Examples",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7a121f973165f96188049570be03933a4bb114c3",
    "semantic_title": "making substitute models more bayesian can enhance transferability of adversarial examples",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=pvgEL1yS3Ql": {
    "title": "Cross-Layer Retrospective Retrieving via Layer Attention",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "db3d7316f72d6cc283c556e12db31a2d47727d7f",
    "semantic_title": "cross-layer retrospective retrieving via layer attention",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=kqHkCVS7wbj": {
    "title": "Decision S4: Efficient Sequence-Based RL via State Spaces Layers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "56a78b4012f87587a81d17b060277047bfb3956c",
    "semantic_title": "decision s4: efficient sequence-based rl via state spaces layers",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=mnVf1W6ipGm": {
    "title": "Unveiling the sampling density in non-uniform geometric graphs",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "cd9b3be09e6eb66d4a15ff9114561bd843b5174e",
    "semantic_title": "unveiling the sampling density in non-uniform geometric graphs",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=LNpMtk15AS4": {
    "title": "Boosting Causal Discovery via Adaptive Sample Reweighting",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "cc9ff6df3d5a0a8199820e720ee604ad8bce8368",
    "semantic_title": "boosting causal discovery via adaptive sample reweighting",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=SEcSahl0Ql": {
    "title": "Iterative Circuit Repair Against Formal Specifications",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "757442d72dc516737abfb12ea9700aaac5c47316",
    "semantic_title": "iterative circuit repair against formal specifications",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=UazgYBMS9-W": {
    "title": "Can BERT Refrain from Forgetting on Sequential Tasks? A Probing Study",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "201047e827ed9587158fc71256c576c8544e3dfc",
    "semantic_title": "can bert refrain from forgetting on sequential tasks? a probing study",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=3c13LptpIph": {
    "title": "Behavior Proximal Policy Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b6b1b3b9ee2ef36a195b43477ba8bd690c07dd0c",
    "semantic_title": "behavior proximal policy optimization",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=xfqDe72zh41": {
    "title": "Actionable Neural Representations: Grid Cells from Minimal Constraints",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bc7417738a7f7186ce9b06933072c4ddd39ce4b1",
    "semantic_title": "actionable neural representations: grid cells from minimal constraints",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=jevY-DtiZTR": {
    "title": "Mole-BERT: Rethinking Pre-training Graph Neural Networks for Molecules",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f470ac3537339514bb9d88fcad9c075441906d45",
    "semantic_title": "mole-bert: rethinking pre-training graph neural networks for molecules",
    "citation_count": 157,
    "authors": []
  },
  "https://openreview.net/forum?id=_q7A0m3vXH0": {
    "title": "Geometrically regularized autoencoders for non-Euclidean data",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5726b2cfa9aedf18ad5b5008d3686179a93b25b3",
    "semantic_title": "geometrically regularized autoencoders for non-euclidean data",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=VBTJqqWjxMv": {
    "title": "A Message Passing Perspective on Learning Dynamics of Contrastive Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0ea5511cc66906b0142d8154d9a891c29ed22341",
    "semantic_title": "a message passing perspective on learning dynamics of contrastive learning",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=n1bLgxHW6jW": {
    "title": "Zeroth-Order Optimization with Trajectory-Informed Derivative Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "af5cfa2fe0b3b4694dd5b86ea3eaa2a2bef1e9ea",
    "semantic_title": "zeroth-order optimization with trajectory-informed derivative estimation",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=_JScUk9TBUn": {
    "title": "Uniform-in-time propagation of chaos for the mean-field gradient Langevin dynamics",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3cc39cd6809669f0087e278968146b9e53954b3e",
    "semantic_title": "uniform-in-time propagation of chaos for the mean-field gradient langevin dynamics",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=_i0-12XqVJZ": {
    "title": "Asynchronous Distributed Bilevel Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2c5f6080a69efe76cf56d225808324fb5b692c1b",
    "semantic_title": "asynchronous distributed bilevel optimization",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=YPKBIILy-Kt": {
    "title": "Confidence-Based Feature Imputation for Graphs with Partially Known Features",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "132009e5f1d256b8806442bbf3924946b32a4b5a",
    "semantic_title": "confidence-based feature imputation for graphs with partially known features",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=WHlt5tLz12T": {
    "title": "LiftedCL: Lifting Contrastive Learning for Human-Centric Perception",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "617d80ab4307c5ea8a8178fe4cd108a52f51fb27",
    "semantic_title": "liftedcl: lifting contrastive learning for human-centric perception",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=JmC_Tld3v-f": {
    "title": "Individual Privacy Accounting with Gaussian Differential Privacy",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "77d2d951c1a69bb7d7c6b4c1f8ebbfdfee15b544",
    "semantic_title": "individual privacy accounting with gaussian differential privacy",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=CBfYffLqWqb": {
    "title": "Evolving Populations of Diverse RL Agents with MAP-Elites",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8b7d33373f018535adb24bdc80b312549c2f488f",
    "semantic_title": "evolving populations of diverse rl agents with map-elites",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=rmoMvptXK7M": {
    "title": "Gray-Box Gaussian Processes for Automated Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "91eda1866f77a31d40bc4a1a12124c3326508bb2",
    "semantic_title": "gray-box gaussian processes for automated reinforcement learning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=pRCMXcfdihq": {
    "title": "Protein Sequence and Structure Co-Design with Equivariant Translation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bc9185f8ae42c952edf84492721f27255ff2745d",
    "semantic_title": "protein sequence and structure co-design with equivariant translation",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=z0_V5O9cmNw": {
    "title": "Learning in temporally structured environments",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4d02858645b8be621eb8cc3f545164e2e907e51c",
    "semantic_title": "learning in temporally structured environments",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=cB4N3G5udUS": {
    "title": "RandProx: Primal-Dual Optimization Algorithms with Randomized Proximal Updates",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0e1fb583eb2a6ae20029c3e73404f0a73fe103eb",
    "semantic_title": "randprox: primal-dual optimization algorithms with randomized proximal updates",
    "citation_count": 39,
    "authors": []
  },
  "https://openreview.net/forum?id=NI7StoWHJPT": {
    "title": "Preserving Pre-trained Features Helps Calibrate Fine-tuned Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bd0d6a6bd10f80726b870450f6275f0530c24afb",
    "semantic_title": "preserving pre-trained features helps calibrate fine-tuned language models",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=UxqUgchwXkK": {
    "title": "Fast Nonlinear Vector Quantile Regression",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e89ba5d9bbe6c6e849708e8081c4e23884e61ed9",
    "semantic_title": "fast nonlinear vector quantile regression",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=yKbprarjc5B": {
    "title": "Leveraging Large Language Models for Multiple Choice Question Answering",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ed38c6b157c11476939c426ec6871c926f2f3524",
    "semantic_title": "leveraging large language models for multiple choice question answering",
    "citation_count": 217,
    "authors": []
  },
  "https://openreview.net/forum?id=h9O0wsmL-cT": {
    "title": "Regression with Label Differential Privacy",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f5e31faabc0d77fb85110e39af812a7edfecd7e8",
    "semantic_title": "regression with label differential privacy",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=fGG6vHp3W9W": {
    "title": "Hierarchical Abstraction for Combinatorial Generalization in Object Rearrangement",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3dc25449a9db4deecbcb50c8eaf6d4a59c245d70",
    "semantic_title": "hierarchical abstraction for combinatorial generalization in object rearrangement",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=tyZ1ChGZIKO": {
    "title": "Selective Frequency Network for Image Restoration",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6af728164e4424218967fd356b3448f5037acd88",
    "semantic_title": "selective frequency network for image restoration",
    "citation_count": 138,
    "authors": []
  },
  "https://openreview.net/forum?id=Tl8OmiibP99": {
    "title": "Improving Differentiable Neural Architecture Search by Encouraging Transferability",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4a8a25aae3bc76b6ef2cb447ed9f3a71ec88ff34",
    "semantic_title": "improving differentiable neural architecture search by encouraging transferability",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=HtAfbHa7LAL": {
    "title": "MA-BERT: Towards Matrix Arithmetic-only BERT Inference by Eliminating Complex Non-Linear Functions",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "161f734370b15e4a6edf0e6db8850889f21be6a0",
    "semantic_title": "ma-bert: towards matrix arithmetic-only bert inference by eliminating complex non-linear functions",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=KyoVpYvWWnK": {
    "title": "Efficient Certified Training and Robustness Verification of Neural ODEs",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b07ba82ede28d57e2e84f17fee8fef3edc24e451",
    "semantic_title": "efficient certified training and robustness verification of neural odes",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=d8mr8lKIZ3n": {
    "title": "Arbitrary Virtual Try-on Network: Characteristics Representation and Trade-off between Body and Clothing",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "57f0bd3d22966dea1cd6b92f99e3328397b1d9b9",
    "semantic_title": "arbitrary virtual try-on network: characteristics representation and trade-off between body and clothing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6ruVLB727MC": {
    "title": "UL2: Unifying Language Learning Paradigms",
    "volume": "poster",
    "abstract": "Existing pre-trained models are generally geared towards a particular class of problems. To date, there seems to be still no consensus on what the right architecture and pre-training setup should be. This paper presents a unified framework for pre-training models that are universally effective across datasets and setups. We begin by disentangling architectural archetypes with pre-training objectives -- two concepts that are commonly conflated. Next, we present a generalized and unified perspective for self-supervision in NLP and show how different pre-training objectives can be cast as one another and how interpolating between different objectives can be effective. We then propose Mixture-of-Denoisers (MoD), a pre-training objective that combines diverse pre-training paradigms together. We furthermore introduce a notion of mode switching, wherein downstream fine-tuning is associated with specific pre-training schemes. We conduct extensive ablative experiments to compare multiple pre-training objectives and find that our method pushes the Pareto-frontier by outperforming T5 and/or GPT-like models across multiple diverse setups. Finally, by scaling our model up to 20B parameters, we achieve SOTA performance on 50 well-established supervised NLP tasks ranging from language generation (with automated and human evaluation), language understanding, text classification, question answering, commonsense reasoning, long text reasoning, structured knowledge grounding and information retrieval. Our model also achieve strong results at in-context learning, outperforming 175B GPT-3 on zero-shot SuperGLUE and tripling the performance of T5-XXL on one-shot summarization. Finally, we show that UL2 20B works well with chain-of-thought prompting and reasoning, making it an appealing choice for research into reasoning at a small to medium scale of 20B parameters. We release Flax-based T5X model checkpoints for the 20B model publicly",
    "checked": true,
    "id": "b21670e8061a06ab97e7d6052c9345a326e84ff8",
    "semantic_title": "ul2: unifying language learning paradigms",
    "citation_count": 327,
    "authors": []
  },
  "https://openreview.net/forum?id=SVl1w1u3InX": {
    "title": "CASR: Generating Complex Sequences with Autoregressive Self-Boost Refinement",
    "volume": "poster",
    "abstract": "There are sequence generation tasks where the best order to generate the target sequence is not left-to-right. For example, an answer to the Sudoku game, a structured code like s-expression, and even a logical natural language answer where the analysis may be generated after the decision. We define the target sequences of those tasks as complex sequences. Obviously, a complex sequence should be constructed with multiple logical steps, and has dependencies among each part of itself (e.g. decisions depend on analyses). It's a great challenge for the classic left-to-right autoregressive generation system to generate complex sequences. Current approaches improve one-pass left-to-right generation on NLG tasks by generating different heuristic intermediate sequences in multiple stages. However, for complex sequences, the heuristic rules to break down them may hurt performance, and increase additional exposure bias. To tackle these challenges, we propose a PLM-friendly autoregressive self-boost refinement framework, CASR. When training, CASR inputs the predictions generated by the model itself at the previous refinement step (instead of those produced by heuristic rules). To find an optimal design, we also discuss model architecture, parameter efficiency and initialization strategy. By evaluating CASR on Sudoku, WebQSP, MTOP and KVRET through controlled experiments and empirical studies, we find that CASR produces high-quality outputs. CASR also improves Accuracy on Sudoku (70.93% --> 97.28%) and achieves state-of-the-art performance on KVRET with Micro F1 score (67.88% --> 70.00%)",
    "checked": true,
    "id": "16bab0d8e56e6d986e2e8baffdc0bc5f5b46b4e5",
    "semantic_title": "casr: generating complex sequences with autoregressive self-boost refinement",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2QzNuaRHn4Z": {
    "title": "Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts",
    "volume": "poster",
    "abstract": "Training machine learning models robust to distribution shifts is critical for real-world applications. Some robust training algorithms (e.g., Group DRO) specialize to group shifts and require group information on all training points. Other methods (e.g., CVaR DRO) that do not need group annotations can be overly conservative, since they naively upweight high loss points which may form a contrived set that does not correspond to any meaningful group in the real world (e.g., when the high loss points are randomly mislabeled training points). In this work, we address limitations in prior approaches by assuming a more nuanced form of group shift: conditioned on the label, we assume that the true group function (indicator over group) is simple. For example, we may expect that group shifts occur along low bitrate features (e.g., image background, lighting). Thus, we aim to learn a model that maintains high accuracy on simple group functions realized by these low bitrate features, that need not spend valuable model capacity achieving high accuracy on contrived groups of examples. Based on this, we consider the two-player game formulation of DRO where the adversary's capacity is bitrate-constrained. Our resulting practical algorithm, Bitrate-Constrained DRO (\\bdro), does not require group information on training samples yet matches the performance of Group DRO on datasets that have training group annotations and that of CVaR DRO on long-tailed distributions. Our theoretical analysis reveals that in some settings \\bdro objective can provably yield statistically efficient and less conservative solutions than unconstrained CVaR DRO",
    "checked": true,
    "id": "5e4437c0ef2bcfa06102341938d63e68762527a6",
    "semantic_title": "bitrate-constrained dro: beyond worst case robustness to unknown group shifts",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=swEskiem99": {
    "title": "Feature selection and low test error in shallow low-rotation ReLU networks",
    "volume": "poster",
    "abstract": "This work establishes low test error of gradient flow (GF) and stochastic gradient descent (SGD) on two-layer ReLU networks with standard initialization scale, in three regimes where key sets of weights rotate little (either naturally due to GF and SGD, or due to an artificial constraint), and making use of margins as the core analysis technique. The first regime is near initialization, specifically until the weights have moved by $\\mathcal{O}(\\sqrt m)$, where $m$ denotes the network width, which is in sharp contrast to the $\\mathcal{O}(1)$ weight motion allowed by the Neural Tangent Kernel (NTK); here it is shown that GF and SGD only need a network width and number of samples inversely proportional to the NTK margin, and moreover that GF attains at least the NTK margin itself and in particular escapes bad KKT points of the margin objective, whereas prior work could only establish nondecreasing but arbitrarily small margins. The second regime is the Neural Collapse (NC) setting, where data lies in well-separated groups, and the sample complexity scales with the number of groups; here the contribution over prior work is an analysis of the entire GF trajectory from initialization. Lastly, if the inner layer weights are constrained to change in norm only and can not rotate, then GF with large widths achieves globally maximal margins, and its sample complexity scales with their inverse; this is in contrast to prior work, which required infinite width and a tricky dual convergence assumption",
    "checked": true,
    "id": "0512745dedebde62883f3a64e2aa331bf9cf5bd9",
    "semantic_title": "feature selection and low test error in shallow low-rotation relu networks",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=JZMR727O29": {
    "title": "Backpropagation through Combinatorial Algorithms: Identity with Projection Works",
    "volume": "poster",
    "abstract": "Embedding discrete solvers as differentiable layers has given modern deep learning architectures combinatorial expressivity and discrete reasoning capabilities. The derivative of these solvers is zero or undefined, therefore a meaningful replacement is crucial for effective gradient-based learning. Prior works rely on smoothing the solver with input perturbations, relaxing the solver to continuous problems, or interpolating the loss landscape with techniques that typically require additional solver calls, introduce extra hyper-parameters, or compromise performance. We propose a principled approach to exploit the geometry of the discrete solution space to treat the solver as a negative identity on the backward pass and further provide a theoretical justification. Our experiments demonstrate that such a straightforward hyper-parameter-free approach is able to compete with previous more complex methods on numerous experiments such as backpropagation through discrete samplers, deep graph matching, and image retrieval. Furthermore, we substitute the previously proposed problem-specific and label-dependent margin with a generic regularization procedure that prevents cost collapse and increases robustness",
    "checked": true,
    "id": "b443a9c6f4c6ead57b03acdf8dc9a7bc0e12103c",
    "semantic_title": "backpropagation through combinatorial algorithms: identity with projection works",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=kIo_C6QmMOM": {
    "title": "Coupled Multiwavelet Operator Learning for Coupled Differential Equations",
    "volume": "poster",
    "abstract": "Coupled partial differential equations (PDEs) are key tasks in modeling the complex dynamics of many physical processes. Recently, neural operators have shown the ability to solve PDEs by learning the integral kernel directly in Fourier/Wavelet space, so the difficulty of solving the coupled PDEs depends on dealing with the coupled mappings between the functions. Towards this end, we propose a \\textit{coupled multiwavelets neural operator} (CMWNO) learning scheme by decoupling the coupled integral kernels during the multiwavelet decomposition and reconstruction procedures in the Wavelet space. The proposed model achieves significantly higher accuracy compared to previous learning-based solvers in solving the coupled PDEs including Gray-Scott (GS) equations and the non-local mean field game (MFG) problem. According to our experimental results, the proposed model exhibits a $2X-4X$ improvement relative $L$2 error compared to the best results from the state-of-the-art models",
    "checked": true,
    "id": "eab89c05faa1ed6dc37875979d78424e761a147a",
    "semantic_title": "coupled multiwavelet operator learning for coupled differential equations",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=4oLK1_k71Tz": {
    "title": "Mid-Vision Feedback",
    "volume": "poster",
    "abstract": "Feedback plays a prominent role in biological vision, where perception is modulated based on agents' evolving expectations and world model. We introduce a novel mechanism which modulates perception based on high level categorical expectations: Mid-Vision Feedback (MVF). MVF associates high level contexts with linear transformations. When a context is \"expected\" its associated linear transformation is applied over feature vectors in a mid level of a network. The result is that mid-level network representations are biased towards conformance with high level expectations, improving overall accuracy and contextual consistency. Additionally, during training mid-level feature vectors are biased through introduction of a loss term which increases the distance between feature vectors associated with different contexts. MVF is agnostic as to the source of contextual expectations, and can serve as a mechanism for top down integration of symbolic systems with deep vision architectures. We show the superior performance of MVF to post-hoc filtering for incorporation of contextual knowledge, and show superior performance of configurations using predicted context (when no context is known a priori) over configurations with no context awareness",
    "checked": true,
    "id": "b15b76cbfcfa5b31c278dcbd7b4fe35e1e91b3fd",
    "semantic_title": "mid-vision feedback",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b39dQt_uffW": {
    "title": "Safe Reinforcement Learning From Pixels Using a Stochastic Latent Representation",
    "volume": "poster",
    "abstract": "We address the problem of safe reinforcement learning from pixel observations. Inherent challenges in such settings are (1) a trade-off between reward optimization and adhering to safety constraints, (2) partial observability, and (3) high-dimensional observations. We formalize the problem in a constrained, partially observable Markov decision process framework, where an agent obtains distinct reward and safety signals. To address the curse of dimensionality, we employ a novel safety critic using the stochastic latent actor-critic (SLAC) approach. The latent variable model predicts rewards and safety violations, and we use the safety critic to train safe policies. Using well-known benchmark environments, we demonstrate competitive performance over existing approaches regarding computational requirements, final reward return, and satisfying the safety constraints",
    "checked": true,
    "id": "49d371e57e8f1ff63258a7b6ccc86ccd75db6244",
    "semantic_title": "safe reinforcement learning from pixels using a stochastic latent representation",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=ja4Lpp5mqc2": {
    "title": "TrojText: Test-time Invisible Textual Trojan Insertion",
    "volume": "poster",
    "abstract": "In Natural Language Processing (NLP), intelligent neuron models can be susceptible to textual Trojan attacks. Such attacks occur when Trojan models behave normally for standard inputs but generate malicious output for inputs that contain a specific trigger. Syntactic-structure triggers, which are invisible, are becoming more popular for Trojan attacks because they are difficult to detect and defend against. However, these types of attacks require a large corpus of training data to generate poisoned samples with the necessary syntactic structures for Trojan insertion. Obtaining such data can be difficult for attackers, and the process of generating syntactic poisoned triggers and inserting Trojans can be time-consuming. This paper proposes a solution called TrojText, which aims to determine whether invisible textual Trojan attacks can be performed more efficiently and cost-effectively without training data. The proposed approach, called the Representation-Logit Trojan Insertion (RLI) algorithm, uses smaller sampled test data instead of large training data to achieve the desired attack. The paper also introduces two additional techniques, namely the accumulated gradient ranking (AGR) and Trojan Weights Pruning (TWP), to reduce the number of tuned parameters and the attack overhead. The TrojText approach was evaluated on three datasets (AG's News, SST-2, and OLID) using three NLP models (BERT, XLNet, and DeBERTa). The experiments demonstrated that the TrojText approach achieved a 98.35% classification accuracy for test sentences in the target class on the BERT model for the AG's News dataset. The source code for TrojText is available at https://github.com/UCF-ML-Research/TrojText",
    "checked": true,
    "id": "49a8ff23aa2a9d852aa8e3888d3c3d556e13d7cf",
    "semantic_title": "trojtext: test-time invisible textual trojan insertion",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=zqkfJA6R1-r": {
    "title": "Improved Training of Physics-Informed Neural Networks Using Energy-Based Priors: a Study on Electrical Impedance Tomography",
    "volume": "poster",
    "abstract": "Physics-informed neural networks (PINNs) are attracting significant attention for solving partial differential equation (PDE) based inverse problems, including electrical impedance tomography (EIT). EIT is non-linear and especially its inverse problem is highly ill-posed. Therefore, successful training of PINN is extremely sensitive to interplay between different loss terms and hyper-parameters, including the learning rate. In this work, we propose a Bayesian approach through data-driven energy-based model (EBM) as a prior, to improve the overall accuracy and quality of tomographic reconstruction. In particular, the EBM is trained over the possible solutions of the PDEs with different boundary conditions. By imparting such prior onto physics-based training, PINN convergence is expedited by more than ten times faster to the PDE's solution. Evaluation outcome shows that our proposed method is more robust for solving the EIT problem. Our code is available at: https://rooshenasgroup.github.io/eit_ebprior",
    "checked": true,
    "id": "224a29032669178b600b0e03abad6e95a8893ee9",
    "semantic_title": "improved training of physics-informed neural networks using energy-based priors: a study on electrical impedance tomography",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=wKPmPBHSnT6": {
    "title": "Ordered GNN: Ordering Message Passing to Deal with Heterophily and Over-smoothing",
    "volume": "poster",
    "abstract": "Most graph neural networks follow the message passing mechanism. However, it faces the over-smoothing problem when multiple times of message passing is applied to a graph, causing indistinguishable node representations and prevents the model to effectively learn dependencies between farther-away nodes. On the other hand, features of neighboring nodes with different labels are likely to be falsely mixed, resulting in the heterophily problem. In this work, we propose to order the messages passing into the node representation, with specific blocks of neurons targeted for message passing within specific hops. This is achieved by aligning the hierarchy of the rooted-tree of a central node with the ordered neurons in its node representation. Experimental results on an extensive set of datasets show that our model can simultaneously achieve the state-of-the-art in both homophily and heterophily settings, without any targeted design. Moreover, its performance maintains pretty well while the model becomes really deep, effectively preventing the over-smoothing problem. Finally, visualizing the gating vectors shows that our model learns to behave differently between homophily and heterophily settings, providing an explainable graph neural model",
    "checked": true,
    "id": "82bb898efad7e1db5e8aa41d55096da0fd269538",
    "semantic_title": "ordered gnn: ordering message passing to deal with heterophily and over-smoothing",
    "citation_count": 81,
    "authors": []
  },
  "https://openreview.net/forum?id=JknGeelZJpHP": {
    "title": "Sparse Distributed Memory is a Continual Learner",
    "volume": "poster",
    "abstract": "Continual learning is a problem for artificial neural networks that their biological counterparts are adept at solving. Building on work using Sparse Distributed Memory (SDM) to connect a core neural circuit with the powerful Transformer model, we create a modified Multi-Layered Perceptron (MLP) that is a strong continual learner. We find that every component of our MLP variant translated from biology is necessary for continual learning. Our solution is also free from any memory replay or task information, and introduces novel methods to train sparse networks that may be broadly applicable",
    "checked": true,
    "id": "a9c60602b9e0b268af152cca934eed40a7fb6937",
    "semantic_title": "sparse distributed memory is a continual learner",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=Xo2E217_M4n": {
    "title": "FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning",
    "volume": "poster",
    "abstract": "Federated Learning (FL) is a distributed learning paradigm that enables different parties to train a model together for high quality and strong privacy protection. In this scenario, individual participants may get compromised and perform backdoor attacks by poisoning the data (or gradients). Existing work on robust aggregation and certified FL robustness does not study how hardening benign clients can affect the global model (and the malicious clients). In this work, we theoretically analyze the connection among cross-entropy loss, attack success rate, and clean accuracy in this setting. Moreover, we propose a trigger reverse engineering based defense and show that our method can achieve robustness improvement with guarantee (i.e., reducing the attack success rate) without affecting benign accuracy. We conduct comprehensive experiments across different datasets and attack settings. Our results on nine competing SOTA defense methods show the empirical superiority of our method on both single-shot and continuous FL backdoor attacks. Code is available at https://github.com/KaiyuanZh/FLIP",
    "checked": true,
    "id": "20916aae7121c798be32771b386878183fc538df",
    "semantic_title": "flip: a provable defense framework for backdoor mitigation in federated learning",
    "citation_count": 63,
    "authors": []
  },
  "https://openreview.net/forum?id=kXwdL1cWOAi": {
    "title": "UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining",
    "volume": "poster",
    "abstract": "Pretrained multilingual large language models have typically used heuristic temperature-based sampling to balance between different languages. However previous work has not systematically evaluated the efficacy of different pretraining language distributions across model scales. In this paper, we propose a new sampling method, UniMax, that delivers more uniform coverage of head languages while mitigating overfitting on tail languages by explicitly capping the number of repeats over each language's corpus. We perform an extensive series of ablations testing a range of sampling strategies on a suite of multilingual benchmarks, while varying model scale. We find that UniMax outperforms standard temperature-based sampling, and the benefits persist as scale increases. As part of our contribution, we release: (i) an improved and refreshed mC4 multilingual corpus consisting of 29 trillion characters across 107 languages, and (ii) a suite of pretrained umT5 model checkpoints trained with UniMax sampling",
    "checked": true,
    "id": "ba184d335a9a08c52c5d25eabd7f4a8ea987918b",
    "semantic_title": "unimax: fairer and more effective language sampling for large-scale multilingual pretraining",
    "citation_count": 74,
    "authors": []
  },
  "https://openreview.net/forum?id=rqq6Dh8t4d": {
    "title": "GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks",
    "volume": "poster",
    "abstract": "Recently, Graph Neural Networks (GNNs) have significantly advanced the performance of machine learning tasks on graphs. However, this technological breakthrough makes people wonder: how does a GNN make such decisions, and can we trust its prediction with high confidence? When it comes to some critical fields, such as biomedicine, where making wrong decisions can have severe consequences, it is crucial to interpret the inner working mechanisms of GNNs before applying them. In this paper, we propose a model-agnostic model-level explanation method for different GNNs that follow the message passing scheme, GNNInterpreter, to explain the high-level decision-making process of the GNN model. More specifically, GNNInterpreter learns a probabilistic generative graph distribution that produces the most discriminative graph pattern the GNN tries to detect when making a certain prediction by optimizing a novel objective function specifically designed for the model-level explanation for GNNs. Compared to existing works, GNNInterpreter is more flexible and computationally efficient in generating explanation graphs with different types of node and edge features, without introducing another blackbox or requiring manually specified domain-specific rules. In addition, the experimental studies conducted on four different datasets demonstrate that the explanation graphs generated by GNNInterpreter match the desired graph pattern if the model is ideal; otherwise, potential model pitfalls can be revealed by the explanation",
    "checked": true,
    "id": "192067b0d238d54480d72d751cbd005e2ad2d2e4",
    "semantic_title": "gnninterpreter: a probabilistic generative model-level explanation for graph neural networks",
    "citation_count": 49,
    "authors": []
  },
  "https://openreview.net/forum?id=OPGy07PojsZ": {
    "title": "Rethinking Symbolic Regression: Morphology and Adaptability in the Context of Evolutionary Algorithms",
    "volume": "poster",
    "abstract": "Symbolic Regression (SR) is the well-studied problem of finding closed-form analytical expressions that describe the relationship between variables in a measurement dataset. In this paper, we rethink SR from two perspectives: morphology and adaptability. Morphology: Current SR algorithms typically use several man-made heuristics to influence the morphology (or structure) of the expressions in the search space. These man-made heuristics may introduce unintentional bias and data leakage, especially with the relatively few equation-recovery benchmark problems available for evaluating SR approaches. To address this, we formulate a novel minimalistic approach, based on constructing a depth-aware mathematical language model trained on terminal walks of expression trees, as a replacement to these heuristics. Adaptability: Current SR algorithms tend to select expressions based on only a single fitness function (e.g., MSE on the training set). We promote the use of an adaptability framework in evolutionary SR which uses fitness functions that alternate across generations. This leads to robust expressions that perform well on the training set and are close to the true functional form. We demonstrate this by alternating fitness functions that quantify faithfulness to values (via MSE) and empirical derivatives (via a novel theoretically justified fitness metric coined MSEDI). Proof-of-concept: We combine these ideas into a minimalistic evolutionary SR algorithm that outperforms all benchmark and state of-the-art SR algorithms in problems with unknown constants added, which we claim are more reflective of SR performance for real-world applications. Our claim is then strengthened by reproducing the superior performance on real-world regression datasets from SRBench. For researchers interested in equation-recovery problems, we also propose a set of conventions that can be used to promote fairness in comparison across SR methods and to reduce unintentional bias",
    "checked": true,
    "id": "464d9f24014f1a15746979212acd712d2b91b245",
    "semantic_title": "rethinking symbolic regression: morphology and adaptability in the context of evolutionary algorithms",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=zaq4LV55xHl": {
    "title": "On Pre-training Language Model for Antibody",
    "volume": "poster",
    "abstract": "Antibodies are vital proteins offering robust protection for the human body from pathogens. The development of general protein and antibody-specific pre-trained language models both facilitate antibody prediction tasks. However, there have been limited studies that comprehensively explore the representation capability of distinct pre-trained language models on different antibody tasks. To investigate the problem, we aim to answer several key questions in this paper, such as how pre-trained language models perform in antibody tasks with different specificity and how introducing specific biological mechanisms to the pre-training process can benefit the model. Additionally, we evaluate if the learned antibody pre-trained representations can be applied to real-world antibody problems, like drug discovery and immune process understanding. Previously, no benchmark available largely hindered the study to answer these questions. To aid in our investigation, we provide an AnTibody Understanding Evaluation (ATUE) benchmark. We comprehensively evaluate the performance of protein pre-trained language models by empirical study along with conclusions and new insights. Our ATUE and code are released at https://github.com/dqwang122/EATLM",
    "checked": true,
    "id": "a40f8e080f6b74780b9a8faa0ce02711699c5561",
    "semantic_title": "on pre-training language model for antibody",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=uR6x8Be7o_M": {
    "title": "Learning to reason over visual objects",
    "volume": "poster",
    "abstract": "A core component of human intelligence is the ability to identify abstract patterns inherent in complex, high-dimensional perceptual data, as exemplified by visual reasoning tasks such as Raven's Progressive Matrices (RPM). Motivated by the goal of designing AI systems with this capacity, recent work has focused on evaluating whether neural networks can learn to solve RPM-like problems. Previous work has generally found that strong performance on these problems requires the incorporation of inductive biases that are specific to the RPM problem format, raising the question of whether such models might be more broadly useful. Here, we investigated the extent to which a general-purpose mechanism for processing visual scenes in terms of objects might help promote abstract visual reasoning. We found that a simple model, consisting only of an object-centric encoder and a transformer reasoning module, achieved state-of-the-art results on both of two challenging RPM-like benchmarks (PGM and I-RAVEN), as well as a novel benchmark with greater visual complexity (CLEVR-Matrices). These results suggest that an inductive bias for object-centric processing may be a key component of abstract visual reasoning, obviating the need for problem-specific inductive biases",
    "checked": true,
    "id": "b816cdb27b28c1759f5060f5a1ed227fbac3efda",
    "semantic_title": "learning to reason over visual objects",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=6lUEy1J5R7p": {
    "title": "Imitating Graph-Based Planning with Goal-Conditioned Policies",
    "volume": "poster",
    "abstract": "Recently, graph-based planning algorithms have gained much attention to solve goal-conditioned reinforcement learning (RL) tasks: they provide a sequence of subgoals to reach the target-goal, and the agents learn to execute subgoal-conditioned policies. However, the sample-efficiency of such RL schemes still remains a challenge, particularly for long-horizon tasks. To address this issue, we present a simple yet effective self-imitation scheme which distills a subgoal-conditioned policy into the target-goal-conditioned policy. Our intuition here is that to reach a target-goal, an agent should pass through a subgoal, so target-goal- and subgoal- conditioned policies should be similar to each other. We also propose a novel scheme of stochastically skipping executed subgoals in a planned path, which further improves performance. Unlike prior methods that only utilize graph-based planning in an execution phase, our method transfers knowledge from a planner along with a graph into policy learning. We empirically show that our method can significantly boost the sample-efficiency of the existing goal-conditioned RL methods under various long-horizon control tasks",
    "checked": true,
    "id": "4a425aacde98c2099f721c8557a84f571af56ed7",
    "semantic_title": "imitating graph-based planning with goal-conditioned policies",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=AuEgNlEAmed": {
    "title": "A theoretical study of inductive biases in contrastive learning",
    "volume": "poster",
    "abstract": "Understanding self-supervised learning is important but challenging. Previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. However, the recent work of [Saunshi et al.] argues that the model architecture --- a component largely ignored by previous works --- also has significant influences on the downstream performance of self-supervised learning. In this work, we provide the first theoretical analysis of self-supervised learning that incorporates the effect of inductive biases originating from the model class. In particular, we focus on contrastive learning --- a popular self-supervised learning method that is widely used in the vision domain. We show that when the model has limited capacity, contrastive representations would recover certain special clustering structures that are compatible with the model architecture, but ignore many other clustering structures in the data distribution. As a result, our theory can capture the more realistic setting where contrastive representations have much lower dimensionality than the number of clusters in the data distribution. We instantiate our theory on several synthetic data distributions, and provide empirical evidence to support the theory",
    "checked": true,
    "id": "88788d73eb81dc0a1134f30a1ff815c727376681",
    "semantic_title": "a theoretical study of inductive biases in contrastive learning",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=pBBsrPzq7aF": {
    "title": "Combinatorial Pure Exploration of Causal Bandits",
    "volume": "poster",
    "abstract": "The combinatorial pure exploration of causal bandits is the following online learning task: given a causal graph with unknown causal inference distributions, in each round we choose a subset of variables to intervene or do no intervention, and observe the random outcomes of all random variables, with the goal that using as few rounds as possible, we can output an intervention that gives the best (or almost best) expected outcome on the reward variable $Y$ with probability at least $1-\\delta$, where $\\delta$ is a given confidence level. We provide the first gap-dependent and fully adaptive pure exploration algorithms on two types of causal models --- the binary generalized linear model (BGLM) and general graphs. For BGLM, our algorithm is the first to be designed specifically for this setting and achieves polynomial sample complexity, while all existing algorithms for general graphs have either sample complexity exponential to the graph size or some unreasonable assumptions. For general graphs, our algorithm provides a significant improvement on sample complexity, and it nearly matches the lower bound we prove. Our algorithms achieve such improvement by a novel integration of prior causal bandit algorithms and prior adaptive pure exploration algorithms, the former of which utilize the rich observational feedback in causal bandits but are not adaptive to reward gaps, while the latter of which have the issue in reverse",
    "checked": true,
    "id": "c023e52d78d7cf9eed549aee563b8bde4282a7b4",
    "semantic_title": "combinatorial pure exploration of causal bandits",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=C2ulri4duIs": {
    "title": "Computational Language Acquisition with Theory of Mind",
    "volume": "poster",
    "abstract": "Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in social environments, coined Theory of Mind (ToM) by Premack & Woodruff (1978). Drawing inspiration from the modern operationalized versions of ToM implemented in Rabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning agents equipped with ToM, and measure its effects on the learning process. We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures. We find that training speakers with a highly weighted ToM listener component leads to performance gains in our image referential game setting. We also find some evidence that increasing task difficulty in the training process results in more fluent and precise utterances in evaluation. This suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition",
    "checked": true,
    "id": "e7b3b692b0816821aafc0d354749bc3802cbf6ac",
    "semantic_title": "computational language acquisition with theory of mind",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=esFxSb_0pSL": {
    "title": "Pareto Invariant Risk Minimization: Towards Mitigating the Optimization Dilemma in Out-of-Distribution Generalization",
    "volume": "poster",
    "abstract": "Recently, there has been a growing surge of interest in enabling machine learning systems to generalize well to Out-of-Distribution (OOD) data. Most efforts are devoted to advancing optimization objectives that regularize models to capture the underlying invariance; however, there often are compromises in the optimization process of these OOD objectives: i) Many OOD objectives have to be relaxed as penalty terms of Empirical Risk Minimization (ERM) for the ease of optimization, while the relaxed forms can weaken the robustness of the original objective; ii) The penalty terms also require careful tuning of the penalty weights due to the intrinsic conflicts between ERM and OOD objectives. Consequently, these compromises could easily lead to suboptimal performance of either the ERM or OOD objective. To address these issues, we introduce a multi-objective optimization (MOO) perspective to understand the OOD optimization process, and propose a new optimization scheme called PAreto Invariant Risk Minimization (PAIR). PAIR improves the robustness of OOD objectives by cooperatively optimizing with other OOD objectives, thereby bridging the gaps caused by the relaxations. Then PAIR approaches a Pareto optimal solution that trades off the ERM and OOD objectives properly. Extensive experiments on challenging benchmarks, WILDS, show that PAIR alleviates the compromises and yields top OOD performances",
    "checked": true,
    "id": "9a7a51cf95e5cb796847ec6d32c0b9ed95f1eec2",
    "semantic_title": "pareto invariant risk minimization: towards mitigating the optimization dilemma in out-of-distribution generalization",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=TGJSPbRpJX-": {
    "title": "What Makes Convolutional Models Great on Long Sequence Modeling?",
    "volume": "poster",
    "abstract": "Convolutional models have been widely used in multiple domains. However, most existing models only use local convolution, making the model unable to handle long-range dependencies efficiently. Attention overcomes this problem by aggregating global information based on the pair-wise attention score but also makes the computational complexity quadratic to the sequence length. Recently, Gu et al. proposed a model called S4 inspired by the state space model. S4 can be efficiently implemented as a global convolutional model whose kernel size equals the input sequence length. With Fast Fourier Transform, S4 can model much longer sequences than Transformers and achieve significant gains over SoTA on several long-range tasks. Despite its empirical success, S4 is involved. It requires sophisticated parameterization and initialization schemes that combine the wisdom from several prior works. As a result, S4 is less intuitive and hard to use for researchers with limited prior knowledge. Here we aim to demystify S4 and extract basic principles that contribute to the success of S4 as a global convolutional model. We focus on the structure of the convolution kernel and identify two critical but intuitive principles enjoyed by S4 that are sufficient to make up an effective global convolutional model: 1) The parameterization of the convolutional kernel needs to be efficient in the sense that the number of parameters should scale sub-linearly with sequence length. 2) The kernel needs to satisfy a decaying structure that the weights for convolving with closer neighbors are larger than the more distant ones. Based on the two principles, we propose a simple yet effective convolutional model called Structured Global Convolution (SGConv). SGConv exhibits strong empirical performance over several tasks: 1) With faster speed, SGConv surpasses the previous SoTA on Long Range Arena and Speech Command datasets. 2) When plugging SGConv into standard language and vision models, it shows the potential to improve both efficiency and performance",
    "checked": true,
    "id": "240300b1da360f22bf0b82c6817eacebba6deed4",
    "semantic_title": "what makes convolutional models great on long sequence modeling?",
    "citation_count": 104,
    "authors": []
  },
  "https://openreview.net/forum?id=6t0Kwf8-jrj": {
    "title": "Editing models with task arithmetic",
    "volume": "poster",
    "abstract": "Changing how pre-trained models behave---e.g., improving their performance on a downstream task or mitigating biases learned during pre-training---is a common practice when developing machine learning systems. In this work, we propose a new paradigm for steering the behavior of neural networks, centered around task vectors. A task vector specifies a direction in the weight space of a pre-trained model, such that movement in that direction improves performance on the task. We build task vectors by subtracting the weights of a pre-trained model from the weights of the same model after fine-tuning on a task. We show that these task vectors can be modified and combined together through arithmetic operations such as negation and addition, and the behavior of the resulting model is steered accordingly. Moreover, task vectors can be added together to improve performance on multiple tasks at once. Finally, when tasks are linked by an analogy relationship of the form ``A is to B as C is to D\", combining task vectors from three of the tasks can improve performance on the fourth, even when no data from the fourth task is used for training",
    "checked": true,
    "id": "71ba5f845bd22d42003675b7cea970ca9e590bcc",
    "semantic_title": "editing models with task arithmetic",
    "citation_count": 627,
    "authors": []
  },
  "https://openreview.net/forum?id=ZPHE4fht19t": {
    "title": "Neural Systematic Binder",
    "volume": "poster",
    "abstract": "The key to high-level cognition is believed to be the ability to systematically manipulate and compose knowledge pieces. While token-like structured knowledge representations are naturally provided in text, it is elusive how to obtain them for unstructured modalities such as scene images. In this paper, we propose a neural mechanism called Neural Systematic Binder or SysBinder for constructing a novel structured representation called Block-Slot Representation. In Block-Slot Representation, object-centric representations known as slots are constructed by composing a set of independent factor representations called blocks, to facilitate systematic generalization. SysBinder obtains this structure in an unsupervised way by alternatingly applying two different binding principles: spatial binding for spatial modularity across the full scene and factor binding for factor modularity within an object. SysBinder is a simple, deterministic, and general-purpose layer that can be applied as a drop-in module in any arbitrary neural network and on any modality. In experiments, we find that SysBinder provides significantly better factor disentanglement within the slots than the conventional object-centric methods, including, for the first time, in visually complex scene images such as CLEVR-Tex. Furthermore, we demonstrate factor-level systematicity in controlled scene generation by decoding unseen factor combinations",
    "checked": true,
    "id": "78d398fb74d7f9c54ceb70343cd3f99c6a87add9",
    "semantic_title": "neural systematic binder",
    "citation_count": 39,
    "authors": []
  },
  "https://openreview.net/forum?id=PUIqjT4rzq7": {
    "title": "Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis",
    "volume": "poster",
    "abstract": "Large-scale diffusion models have achieved state-of-the-art results on text-to-image synthesis (T2I) tasks. Despite their ability to generate high-quality yet creative images, we observe that attribution-binding and compositional capabilities are still considered major challenging issues, especially when involving multiple objects. Attribute-binding requires the model to associate objects with the correct attribute descriptions, and compositional skills require the model to combine and generate multiple concepts into a single image. In this work, we improve these two aspects of T2I models to achieve more accurate image compositions. To do this, we incorporate linguistic structures with the diffusion guidance process based on the controllable properties of manipulating cross-attention layers in diffusion-based T2I models. We observe that keys and values in cross-attention layers have strong semantic meanings associated with object layouts and content. Therefore, by manipulating the cross-attention representations based on linguistic insights, we can better preserve the compositional semantics in the generated image. Built upon Stable Diffusion, a SOTA T2I model, our structured cross-attention design is efficient that requires no additional training samples. We achieve better compositional skills in qualitative and quantitative results, leading to a significant 5-8\\% advantage in head-to-head user comparison studies. Lastly, we conduct an in-depth analysis to reveal potential causes of incorrect image compositions and justify the properties of cross-attention layers in the generation process",
    "checked": true,
    "id": "25de00096c45121a06668bc501f91adec5d0aff9",
    "semantic_title": "training-free structured diffusion guidance for compositional text-to-image synthesis",
    "citation_count": 354,
    "authors": []
  },
  "https://openreview.net/forum?id=ipflrGaf7ry": {
    "title": "Can Agents Run Relay Race with Strangers? Generalization of RL to Out-of-Distribution Trajectories",
    "volume": "poster",
    "abstract": "In this paper, we evaluate and improve the generalization performance for reinforcement learning (RL) agents on the set of ``controllable'' states, where good policies exist on these states to achieve the goal. An RL agent that generally masters a task should reach its goal starting from any controllable state of the environment instead of memorizing a small set of trajectories. To practically evaluate this type of generalization, we propose relay evaluation, which starts the test agent from the middle of other independently well-trained stranger agents' trajectories. With extensive experimental evaluation, we show the prevalence of generalization failure on controllable states from stranger agents. For example, in the Humanoid environment, we observed that a well-trained Proximal Policy Optimization (PPO) agent, with only 3.9\\% failure rate during regular testing, failed on 81.6\\% of the states generated by well-trained stranger PPO agents. To improve \"relay generalization,\" we propose a novel method called Self-Trajectory Augmentation (STA), which will reset the environment to the agent's old states according to the Q function during training. After applying STA to the Soft Actor Critic's (SAC) training procedure, we reduced the failure rate of SAC under relay-evaluation by more than three times in most settings without impacting agent performance and increasing the needed number of environment interactions. Our code is available at https://github.com/lan-lc/STA",
    "checked": true,
    "id": "c7e4da026f47339697a522508893f2fa261b52ea",
    "semantic_title": "can agents run relay race with strangers? generalization of rl to out-of-distribution trajectories",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=NE2911Kq1sp": {
    "title": "CktGNN: Circuit Graph Neural Network for Electronic Design Automation",
    "volume": "poster",
    "abstract": "The electronic design automation of analog circuits has been a longstanding challenge in the integrated circuit field due to the huge design space and complex design trade-offs among circuit specifications. In the past decades, intensive research efforts have only been paid to automate the transistor sizing with a given circuit topology. By recognizing the graph nature of circuits, this paper presents a Circuit Graph Neural Network (CktGNN) that simultaneously automates the circuit topology generation and device sizing based on the encoder-dependent optimization subroutines. Particularly, CktGNN encodes circuit graphs using a two-level GNN framework (of nested GNN) where circuits are represented as combinations of subgraphs in a known subgraph basis. In this way, it significantly improves efficiency by reducing the number of subgraphs to perform message passing. Nonetheless, another critical roadblock to advancing learning-assisted circuit design automation is a lack of public benchmarks to perform canonical assessment and reproducible research. To tackle the challenge, we introduce Open Circuit Benchmark (OCB), an open-sourced dataset that contains $10$K distinct operational amplifiers with carefully-extracted circuit specifications from physical implementations. OCB also equips with communicative circuit generation and evaluation capabilities such that it can be used to generalize the applicability of CktGNN to design various analog circuits by efficiently producing corresponding datasets. Experiments on OCB show the extraordinary advantages of CktGNN through representation-based optimization frameworks over other recent powerful GNN baselines and manual design from human experts. Our work paves the way toward a learning-based open-sourced design automation flow for analog circuits",
    "checked": true,
    "id": "430a5e44fc2fc16e2376ef7197101816688f2ca7",
    "semantic_title": "cktgnn: circuit graph neural network for electronic design automation",
    "citation_count": 54,
    "authors": []
  },
  "https://openreview.net/forum?id=0pdSt3oyJa1": {
    "title": "Specformer: Spectral Graph Neural Networks Meet Transformers",
    "volume": "poster",
    "abstract": "Spectral graph neural networks (GNNs) learn graph representations via spectral-domain graph convolutions. However, most existing spectral graph filters are scalar-to-scalar functions, i.e., mapping a single eigenvalue to a single filtered value, thus ignoring the global pattern of the spectrum. Furthermore, these filters are often constructed based on some fixed-order polynomials, which have limited expressiveness and flexibility. To tackle these issues, we introduce Specformer, which effectively encodes the set of all eigenvalues and performs self-attention in the spectral domain, leading to a learnable set-to-set spectral filter. We also design a decoder with learnable bases to enable non-local graph convolution. Importantly, Specformer is equivariant to permutation. By stacking multiple Specformer layers, one can build a powerful spectral GNN. On synthetic datasets, we show that our Specformer can better recover ground-truth spectral filters than other spectral GNNs. Extensive experiments of both node-level and graph-level tasks on real-world graph datasets show that our Specformer outperforms state-of-the-art GNNs and learns meaningful spectrum patterns. Code and data are available at https://github.com/bdy9527/Specformer",
    "checked": true,
    "id": "c193011099906126fe7b6cfcb04062cf4591ccf9",
    "semantic_title": "specformer: spectral graph neural networks meet transformers",
    "citation_count": 103,
    "authors": []
  },
  "https://openreview.net/forum?id=qFVVBzXxR2V": {
    "title": "Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e7028cd7ea838ab8294ecf26d5a2c0dbb8cfa81a",
    "semantic_title": "language models are greedy reasoners: a systematic formal analysis of chain-of-thought",
    "citation_count": 366,
    "authors": []
  },
  "https://openreview.net/forum?id=5lgD4vU-l24s": {
    "title": "Recursive Time Series Data Augmentation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "7d6ef99fc8d55a2244b936706323f1f1d32f9489",
    "semantic_title": "don't overfit the history - recursive time series data augmentation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=JjCAdMUlu9v": {
    "title": "Auto-Encoding Goodness of Fit",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1df72e6e73be46d90307c8595ff9a3669f860b01",
    "semantic_title": "auto-encoding goodness of fit",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=WGApODQvwRg": {
    "title": "Understanding the Covariance Structure of Convolutional Filters",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "236a3805c01164d3319cf03fc2be083daaa65fb0",
    "semantic_title": "understanding the covariance structure of convolutional filters",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=mWRngkvIki3": {
    "title": "Masked Distillation with Receptive Tokens",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "874fcbf4b82d292bf974094136d50763dd60833d",
    "semantic_title": "masked distillation with receptive tokens",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=ctmLBs8lITa": {
    "title": "Robust Multivariate Time-Series Forecasting: Adversarial Attacks and Defense Mechanisms",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "84dc2a159c062ceedae62c4a3c682f18ead59812",
    "semantic_title": "robust multivariate time-series forecasting: adversarial attacks and defense mechanisms",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=xIWfWvKM7aQ": {
    "title": "TextShield: Beyond Successfully Detecting Adversarial Sentences in text classification",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "05d5a07d0688028e0cef5f9246e7949bb28dd01b",
    "semantic_title": "textshield: beyond successfully detecting adversarial sentences in text classification",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=14-kr46GvP-": {
    "title": "Efficient Deep Reinforcement Learning Requires Regulating Overfitting",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f04fe5f3f47f5b25e5295c29cdc8b109887f959c",
    "semantic_title": "efficient deep reinforcement learning requires regulating overfitting",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=6jfbOWzWTcE": {
    "title": "Offline Reinforcement Learning with Differentiable Function Approximation is Provably Efficient",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "839fd6f8fb5f1cc3be573e448f11f459e06abd7d",
    "semantic_title": "offline reinforcement learning with differentiable function approximation is provably efficient",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oGDKSt9JrZi": {
    "title": "Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a2b2abdb4566beee1e29f19bc6914ce67680acf3",
    "semantic_title": "proto-value networks: scaling representation learning with auxiliary tasks",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=I29Kt0RwChs": {
    "title": "Robust Algorithms on Adaptive Inputs from Bounded Adversaries",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d10e3ef7fa49e13915d0e93c0877f2f2a26cd97a",
    "semantic_title": "robust algorithms on adaptive inputs from bounded adversaries",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=7jk5gWjC18M": {
    "title": "Chasing All-Round Graph Representation Robustness: Model, Training, and Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "89eb2fd47d93dd15354c84c41df599669c68b829",
    "semantic_title": "chasing all-round graph representation robustness: model, training, and optimization",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=4gc3MGZra1d": {
    "title": "On Representing Mixed-Integer Linear Programs by Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "078fc54e3311e18d2e407e927192760e2bb67ae5",
    "semantic_title": "on representing mixed-integer linear programs by graph neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fWWFv--P0xP": {
    "title": "On the Importance and Applicability of Pre-Training for Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "393148d88541881b590c36eaf0effc4a6a823035",
    "semantic_title": "on the importance and applicability of pre-training for federated learning",
    "citation_count": 95,
    "authors": []
  },
  "https://openreview.net/forum?id=yVqC6gCNf4d": {
    "title": "Simple initialization and parametrization of sinusoidal networks via their kernel bandwidth",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "06074aeb225dcad22076bfa997e465c18a607141",
    "semantic_title": "simple initialization and parametrization of sinusoidal networks via their kernel bandwidth",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=29V3AWjVAFi": {
    "title": "The Best of Both Worlds: Accurate Global and Personalized Models through Federated Learning with Data-Free Hyper-Knowledge Distillation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ba2251da5893bb9407bb5050c279900019df160e",
    "semantic_title": "the best of both worlds: accurate global and personalized models through federated learning with data-free hyper-knowledge distillation",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=JmkjrlVE-DG": {
    "title": "Over-Training with Mixup May Hurt Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "99486d35169e1937b8ff9e5abd7227b6d1e901b9",
    "semantic_title": "over-training with mixup may hurt generalization",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=0eTTKOOOQkV": {
    "title": "HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a935ba7ce7fd44fe372c6860504fbc164f012f03",
    "semantic_title": "hiclip: contrastive language-image pretraining with hierarchy-aware attention",
    "citation_count": 49,
    "authors": []
  },
  "https://openreview.net/forum?id=p6jsTidUkPx": {
    "title": "Quantile Risk Control: A Flexible Framework for Bounding the Probability of High-Loss Predictions",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "722ee8624f376347a58d9948248227ab6d2eb3c8",
    "semantic_title": "quantile risk control: a flexible framework for bounding the probability of high-loss predictions",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=YlGsTZODyjz": {
    "title": "The Tilted Variational Autoencoder: Improving Out-of-Distribution Detection",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "20ca62aae323c8778a978300c682ac8e1d160e74",
    "semantic_title": "the tilted variational autoencoder: improving out-of-distribution detection",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=B4maZQLLW0_": {
    "title": "Stateful Active Facilitator: Coordination and Environmental Heterogeneity in Cooperative Multi-Agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "00d886e24f641bf090d745862d6d77effa500385",
    "semantic_title": "stateful active facilitator: coordination and environmental heterogeneity in cooperative multi-agent reinforcement learning",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=NDWl9qcUpvy": {
    "title": "Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2f1fee5087d47e7a8c71763c22ac784c9565278c",
    "semantic_title": "learning achievement structure for structured exploration in domains with sparse reward",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=WBXbRs63oVu": {
    "title": "PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "deff814eefe597b2fe275bc3dd205ecb1cc09c4e",
    "semantic_title": "pinto: faithful language reasoning using prompt-generated rationales",
    "citation_count": 68,
    "authors": []
  },
  "https://openreview.net/forum?id=6doXHqwMayf": {
    "title": "Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and its Superiority to Kernel Methods",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "203786a65d785c3bdd0eca1f36040293a19b879a",
    "semantic_title": "excess risk of two-layer relu neural networks in teacher-student settings and its superiority to kernel methods",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=8tYRqb05pVn": {
    "title": "Linearly Mapping from Image to Text Space",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c4cb3f7056f1216c1ddfbe4b9e55cbc07a1e43b9",
    "semantic_title": "linearly mapping from image to text space",
    "citation_count": 132,
    "authors": []
  },
  "https://openreview.net/forum?id=sAOOeI878Ns": {
    "title": "Characterizing intrinsic compositionality in transformers with Tree Projections",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5116af9e9265044d0919111f1e0e1eb283de3a1f",
    "semantic_title": "characterizing intrinsic compositionality in transformers with tree projections",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=5vM51iamNeL": {
    "title": "Augmentation Component Analysis: Modeling Similarity via the Augmentation Overlaps",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a0c935bd39f512d4eddb19edde1b6dfee637e880",
    "semantic_title": "augmentation component analysis: modeling similarity via the augmentation overlaps",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=gcD2UtCGMc2": {
    "title": "Replicable Bandits",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "59a6933e06879f8f495629572a1117881b5c7238",
    "semantic_title": "replicable bandits",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=nJ3Vx78Nf7p": {
    "title": "Neural Bregman Divergences for Distance Learning",
    "volume": "poster",
    "abstract": "Many metric learning tasks, such as triplet learning, nearest neighbor retrieval, and visualization, are treated primarily as embedding tasks where the ultimate metric is some variant of the Euclidean distance (e.g., cosine or Mahalanobis), and the algorithm must learn to embed points into the pre-chosen space. The study of non-Euclidean geometries is often not explored, which we believe is due to a lack of tools for learning non-Euclidean measures of distance. Recent work has shown that Bregman divergences can be learned from data, opening a promising approach to learning asymmetric distances. We propose a new approach to learning arbitrary Bergman divergences in a differentiable manner via input convex neural networks and show that it overcomes significant limitations of previous works. We also demonstrate that our method more faithfully learns divergences over a set of both new and previously studied tasks, including asymmetric regression, ranking, and clustering. Our tests further extend to known asymmetric, but non-Bregman tasks, where our method still performs competitively despite misspecification, showing the general utility of our approach for asymmetric learning",
    "checked": true,
    "id": "19bb4d14e3e7d322b961b4e2df6e67e88a6ecf22",
    "semantic_title": "neural bregman divergences for distance learning",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=V7CYzdruWdm": {
    "title": "Bias Propagation in Federated Learning",
    "volume": "poster",
    "abstract": "We show that participating in federated learning can be detrimental to group fairness. In fact, the bias of a few parties against under-represented groups (identified by sensitive attributes such as gender or race) can propagate through the network to all the parties in the network. We analyze and explain bias propagation in federated learning on naturally partitioned real-world datasets. Our analysis reveals that biased parties unintentionally yet stealthily encode their bias in a small number of model parameters, and throughout the training, they steadily increase the dependence of the global model on sensitive attributes. What is important to highlight is that the experienced bias in federated learning is higher than what parties would otherwise encounter in centralized training with a model trained on the union of all their data. This indicates that the bias is due to the algorithm. Our work calls for auditing group fairness in federated learning and designing learning algorithms that are robust to bias propagation",
    "checked": true,
    "id": "6ae73f371654b234372c22ea4d0df15159b6ccd0",
    "semantic_title": "bias propagation in federated learning",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=R0Xxvr_X3ZA": {
    "title": "Causal Confusion and Reward Misidentification in Preference-Based Reward Learning",
    "volume": "poster",
    "abstract": "Learning policies via preference-based reward learning is an increasingly popular method for customizing agent behavior, but has been shown anecdotally to be prone to spurious correlations and reward hacking behaviors. While much prior work focuses on causal confusion in reinforcement learning and behavioral cloning, we focus on a systematic study of causal confusion and reward misidentification when learning from preferences. In particular, we perform a series of sensitivity and ablation analyses on several benchmark domains where rewards learned from preferences achieve minimal test error but fail to generalize to out-of-distribution states---resulting in poor policy performance when optimized. We find that the presence of non-causal distractor features, noise in the stated preferences, and partial state observability can all exacerbate reward misidentification. We also identify a set of methods with which to interpret misidentified learned rewards. In general, we observe that optimizing misidentified rewards drives the policy off the reward's training distribution, resulting in high predicted (learned) rewards but low true rewards. These findings illuminate the susceptibility of preference learning to reward misidentification and causal confusion---failure to consider even one of many factors can result in unexpected, undesirable behavior",
    "checked": true,
    "id": "6be327602deb674d0e9f3b606f3e6baf733bf266",
    "semantic_title": "causal confusion and reward misidentification in preference-based reward learning",
    "citation_count": 47,
    "authors": []
  },
  "https://openreview.net/forum?id=Z63RvyAZ2Vh": {
    "title": "UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question Answering Over Knowledge Graph",
    "volume": "poster",
    "abstract": "Multi-hop Question Answering over Knowledge Graph~(KGQA) aims to find the answer entities that are multiple hops away from the topic entities mentioned in a natural language question on a large-scale Knowledge Graph (KG). To cope with the vast search space, existing work usually adopts a two-stage approach: it first retrieves a relatively small subgraph related to the question and then performs the reasoning on the subgraph to find the answer entities accurately. Although these two stages are highly related, previous work employs very different technical solutions for developing the retrieval and reasoning models, neglecting their relatedness in task essence. In this paper, we propose UniKGQA, a novel approach for multi-hop KGQA task, by unifying retrieval and reasoning in both model architecture and parameter learning. For model architecture, UniKGQA consists of a semantic matching module based on a pre-trained language model~(PLM) for question-relation semantic matching, and a matching information propagation module to propagate the matching information along the directed edges on KGs. For parameter learning, we design a shared pre-training task based on question-relation matching for both retrieval and reasoning models, and then propose retrieval- and reasoning-oriented fine-tuning strategies. Compared with previous studies, our approach is more unified, tightly relating the retrieval and reasoning stages. Extensive experiments on three benchmark datasets have demonstrated the effectiveness of our method on the multi-hop KGQA task. Our codes and data are publicly available at~\\url{https://github.com/RUCAIBox/UniKGQA}",
    "checked": true,
    "id": "2d01da2c9ece0969d6ec56d22f78caf57050fc03",
    "semantic_title": "unikgqa: unified retrieval and reasoning for solving multi-hop question answering over knowledge graph",
    "citation_count": 106,
    "authors": []
  },
  "https://openreview.net/forum?id=bRwBpKrNzF7": {
    "title": "Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games",
    "volume": "poster",
    "abstract": "Multi-Agent Reinforcement Learning (MARL)---where multiple agents learn to interact in a shared dynamic environment---permeates across a wide range of critical applications. While there has been substantial progress on understanding the global convergence of policy optimization methods in single-agent RL, designing and analysis of efficient policy optimization algorithms in the MARL setting present significant challenges and new desiderata, which unfortunately, remain highly inadequately addressed by existing theory. In this paper, we focus on the most basic setting of competitive multi-agent RL, namely two-player zero-sum Markov games, and study equilibrium finding algorithms in both the infinite-horizon discounted setting and the finite-horizon episodic setting. We propose a single-loop policy optimization method with symmetric updates from both agents, where the policy is updated via the entropy-regularized optimistic multiplicative weights update (OMWU) method and the value is updated on a slower timescale. We show that, in the full-information tabular setting, the proposed method achieves a finite-time last-iterate linear convergence to the quantal response equilibrium of the regularized problem, which translates to a sublinear convergence to the Nash equilibrium by controlling the amount of regularization. Our convergence results improve upon the best known iteration complexities, and lead to a better understanding of policy optimization in competitive Markov games",
    "checked": true,
    "id": "c2bd6bf1c2250561f954a04a7061f6d6bf9ff855",
    "semantic_title": "faster last-iterate convergence of policy optimization in zero-sum markov games",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=rB3zRN0lBYr": {
    "title": "Memorization Capacity of Neural Networks with Conditional Computation",
    "volume": "poster",
    "abstract": "Many empirical studies have demonstrated the performance benefits of conditional computation in neural networks, including reduced inference time and power consumption. We study the fundamental limits of neural conditional computation from the perspective of memorization capacity. For Rectified Linear Unit (ReLU) networks without conditional computation, it is known that memorizing a collection of $n$ input-output relationships can be accomplished via a neural network with $O(\\sqrt{n})$ neurons. Calculating the output of this neural network can be accomplished using $O(\\sqrt{n})$ elementary arithmetic operations of additions, multiplications and comparisons for each input. Using a conditional ReLU network, we show that the same task can be accomplished using only $O(\\log n)$ operations per input. This represents an almost exponential improvement as compared to networks without conditional computation. We also show that the $\\Theta(\\log n)$ rate is the best possible. Our achievability result utilizes a general methodology to synthesize a conditional network out of an unconditional network in a computationally-efficient manner, bridging the gap between unconditional and conditional architectures",
    "checked": true,
    "id": "e6f89cdc53ea40bbfc46c97623992ed80a600b56",
    "semantic_title": "memorization capacity of neural networks with conditional computation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=YfUICnZMwk7": {
    "title": "Weighted Clock Logic Point Process",
    "volume": "poster",
    "abstract": "Datasets involving multivariate event streams are prevalent in numerous applications. We present a novel framework for modeling temporal point processes called clock logic neural networks (CLNN) which learn weighted clock logic (wCL) formulas as interpretable temporal rules by which some events promote or inhibit other events. Specifically, CLNN models temporal relations between events using conditional intensity rates informed by a set of wCL formulas, which are more expressive than related prior work. Unlike conventional approaches of searching for generative rules through expensive combinatorial optimization, we design smooth activation functions for components of wCL formulas that enable a continuous relaxation of the discrete search space and efficient learning of wCL formulas using gradient-based methods. Experiments on synthetic datasets manifest our model's ability to recover the ground-truth rules and improve computational efficiency. In addition, experiments on real-world datasets show that our models perform competitively when compared with state-of-the-art models",
    "checked": true,
    "id": "ed1ed11dccc865f1448caa81ebc5a540184f1c05",
    "semantic_title": "weighted clock logic point process",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=NUl0ylt7SM": {
    "title": "Simple Emergent Action Representations from Multi-Task Policy Training",
    "volume": "poster",
    "abstract": "The low-level sensory and motor signals in deep reinforcement learning, which exist in high-dimensional spaces such as image observations or motor torques, are inherently challenging to understand or utilize directly for downstream tasks. While sensory representations have been extensively studied, the representations of motor actions are still an area of active exploration. Our work reveals that a space containing meaningful action representations emerges when a multi-task policy network takes as inputs both states and task embeddings. Moderate constraints are added to improve its representation ability. Therefore, interpolated or composed embeddings can function as a high-level interface within this space, providing instructions to the agent for executing meaningful action sequences. Empirical results demonstrate that the proposed action representations are effective for intra-action interpolation and inter-action composition with limited or no additional learning. Furthermore, our approach exhibits superior task adaptation ability compared to strong baselines in Mujoco locomotion tasks. Our work sheds light on the promising direction of learning action representations for efficient, adaptable, and composable RL, forming the basis of abstract action planning and the understanding of motor signal space. Project page: https://sites.google.com/view/emergent-action-representation/",
    "checked": true,
    "id": "a78248272e8b87e6f7650fdc29dbb77454c1a745",
    "semantic_title": "simple emergent action representations from multi-task policy training",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=JQc2VowqCzz": {
    "title": "Interaction-Based Disentanglement of Entities for Object-Centric World Models",
    "volume": "poster",
    "abstract": "Perceiving the world compositionally in terms of space and time is essential to understanding object dynamics and solving downstream tasks. Object-centric learning using generative models has improved in its ability to learn distinct representations of individual objects and predict their interactions, and how to utilize the learned representations to solve untrained, downstream tasks is a focal question. However, as models struggle to predict object interactions and track the objects accurately, especially for unseen configurations, using object-centric representations in downstream tasks is still a challenge. This paper proposes STEDIE, a new model that disentangles object representations, based on interactions, into interaction-relevant relational features and interaction-irrelevant global features without supervision. Empirical evaluation shows that the proposed model factorizes global features, unaffected by interactions from relational features that are necessary to predict outcome of interactions. We also show that STEDIE achieves better performance in planning tasks and understanding causal relationships. In both tasks, our model not only achieves better performance in terms of reconstruction ability but also utilizes the disentangled representations to solve the tasks in a structured manner",
    "checked": true,
    "id": "ac62d8e239eb90363a472681b09bac7bf4128f9a",
    "semantic_title": "interaction-based disentanglement of entities for object-centric world models",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=-ng-FXFlzgK": {
    "title": "Neural Image-based Avatars: Generalizable Radiance Fields for Human Avatar Modeling",
    "volume": "poster",
    "abstract": "We present a method that enables synthesizing novel views and novel poses of arbitrary human performers from sparse multi-view images. A key ingredient of our method is a hybrid appearance blending module that combines the advantages of the implicit body NeRF representation and image-based rendering. Existing generalizable human NeRF methods that are conditioned on the body model have shown robustness against the geometric variation of arbitrary human performers. Yet they often exhibit blurry results when generalized onto unseen identities. Meanwhile, image-based rendering shows high-quality results when sufficient observations are available, whereas it suffers artifacts in sparse-view settings. We propose Neural Image-based Avatars (NIA) that exploits the best of those two methods: to maintain robustness under new articulations and self-occlusions while directly leveraging the available (sparse) source view colors to preserve appearance details of new subject identities. Our hybrid design outperforms recent methods on both in-domain identity generalization as well as challenging cross-dataset generalization settings. Also, in terms of the pose generalization, our method outperforms even the per-subject optimized animatable NeRF methods",
    "checked": true,
    "id": "12768e64c370ec7fcb9031df24bdc2e75f559d6b",
    "semantic_title": "neural image-based avatars: generalizable radiance fields for human avatar modeling",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=38m4h8HcNRL": {
    "title": "Federated Neural Bandits",
    "volume": "poster",
    "abstract": "Recent works on neural contextual bandits have achieved compelling performances due to their ability to leverage the strong representation power of neural networks (NNs) for reward prediction. Many applications of contextual bandits involve multiple agents who collaborate without sharing raw observations, thus giving rise to the setting of federated contextual bandits}. Existing works on federated contextual bandits rely on linear or kernelized bandits, which may fall short when modeling complex real-world reward functions. So, this paper introduces the federated neural-upper confidence bound (FN-UCB) algorithm. To better exploit the federated setting, FN-UCB adopts a weighted combination of two UCBs: $\\text{UCB}^{a}$ allows every agent to additionally use the observations from the other agents to accelerate exploration (without sharing raw observations), while $\\text{UCB}^{b}$ uses an NN with aggregated parameters for reward prediction in a similar way to federated averaging for supervised learning. Notably, the weight between the two UCBs required by our theoretical analysis is amenable to an interesting interpretation, which emphasizes $\\text{UCB}^{a}$ initially for accelerated exploration and relies more on $\\text{UCB}^{b}$ later after enough observations have been collected to train the NNs for accurate reward prediction (i.e., reliable exploitation). We prove sub-linear upper bounds on both the cumulative regret and the number of communication rounds of FN-UCB, and empirically demonstrate its competitive performance",
    "checked": true,
    "id": "ad1bb40a89a889a87c5681749f2ddcbaf4292a6a",
    "semantic_title": "federated neural bandits",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=6axIMJA7ME3": {
    "title": "Compositional Task Representations for Large Language Models",
    "volume": "poster",
    "abstract": "Large language models have shown a remarkable cross-task generalization ability. Most prior work assumed that prompts effectively extract knowledge from language models to facilitate generalization to new tasks. This perspective led to numerous studies on improving prompts. In contrast, we introduce a new perspective, compositional generalization, that views each task as a composition of latent codes and generalizes to test tasks by a new composition of seen codes. To this end, we propose a novel prompt-free approach, Compositional Task Representations (CTR), that employs multi-task training to learn a discrete, compositional codebook. Empirically, our CTR substantially outperforms prompt-based methods in zero-label learning on average. According to our analysis, some of the learned CTR codes are interpretable to human and demonstrate a certain degree of controllability",
    "checked": true,
    "id": "66a8358bee061ed45ff49d08694f3a7c3abb4b38",
    "semantic_title": "compositional task representations for large language models",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=gU5sJ6ZggcX": {
    "title": "REPAIR: REnormalizing Permuted Activations for Interpolation Repair",
    "volume": "poster",
    "abstract": "In this paper we empirically investigate the conjecture from Entezari et al. (2021) which states that if permutation invariance is taken into account, then there should be no loss barrier to the linear interpolation between SGD solutions. We conduct our investigation using standard computer vision architectures trained on CIFAR-10 and ImageNet. First, we observe a general phenomenon in which interpolated deep networks suffer a collapse in the variance of their activations. We demonstrate that an appropriate rescaling of the pre-activations of the interpolated networks ameliorates this problem and significantly reduces the barrier. Second, by combining this with an algorithm for finding permutations based on maximizing correlations between the activations of matched neurons, we are able to reduce the interpolation barrier for a standard ResNet18 trained on CIFAR-10 to 1.5% absolute test error. We explore the interaction between our method and the choice of normalization layer, and demonstrate its robustness across a variety of architectures and training sets",
    "checked": true,
    "id": "3a1f0963f57baf8021c434ac14e5d4132b6735bd",
    "semantic_title": "repair: renormalizing permuted activations for interpolation repair",
    "citation_count": 107,
    "authors": []
  },
  "https://openreview.net/forum?id=HZf7UbpWHuA": {
    "title": "Diffusion-GAN: Training GANs with Diffusion",
    "volume": "poster",
    "abstract": "Generative adversarial networks (GANs) are challenging to train stably, and a promising remedy of injecting instance noise into the discriminator input has not been very effective in practice. In this paper, we propose Diffusion-GAN, a novel GAN framework that leverages a forward diffusion chain to generate Gaussian-mixture distributed instance noise. Diffusion-GAN consists of three components, including an adaptive diffusion process, a diffusion timestep-dependent discriminator, and a generator. Both the observed and generated data are diffused by the adaptive diffusion process via different noise-to-data ratios at each timestep. The timestep-dependent discriminator learns to distinguish the diffused real data from the diffused generated data at each diffusion timestep. The generator learns from the discriminator's feedback by backpropagating through the forward diffusion chain, whose length is adaptively adjusted to balance the noise and data levels. We theoretically show that the discriminator's timestep-dependent strategy gives consistent and helpful guidance to the generator, enabling it to match the true data distribution. We demonstrate the advantages of Diffusion-GAN over strong GAN baselines on various datasets, showing that it can produce more realistic images with higher stability and data efficiency than state-of-the-art GANs",
    "checked": true,
    "id": "9c3ceae3cf605f934cc5f04a44feae23b5252faa",
    "semantic_title": "diffusion-gan: training gans with diffusion",
    "citation_count": 261,
    "authors": []
  },
  "https://openreview.net/forum?id=cWmtUcsYC3V": {
    "title": "Mind the Pool: Convolutional Neural Networks Can Overfit Input Size",
    "volume": "poster",
    "abstract": "We demonstrate how convolutional neural networks can overfit the input size: The accuracy drops significantly when using certain sizes, compared with favorable ones. This issue is inherent to pooling arithmetic, with standard downsampling layers playing a major role in favoring certain input sizes and skewing the weights accordingly. We present a solution to this problem by depriving these layers from the arithmetic cues they use to overfit the input size. Through various examples, we show how our proposed spatially-balanced pooling improves the generalization of the network to arbitrary input sizes and its robustness to translational shifts",
    "checked": true,
    "id": "97074d9b00a967c0c840dc170347d92f42dc3132",
    "semantic_title": "mind the pool: convolutional neural networks can overfit input size",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=Kpdewuy7RU6": {
    "title": "Reparameterization through Spatial Gradient Scaling",
    "volume": "poster",
    "abstract": "Reparameterization aims to improve the generalization of deep neural networks by transforming a convolution operation into equivalent multi-branched structures during training. However, there exists a gap in understanding how reparameterization may change and benefit learning processes for neural networks. In this paper, we present a novel spatial gradient scaling method to redistribute learning focus among weights in convolutional neural networks. We prove that spatial gradient scaling achieves the same learning dynamics as a branched reparameterization yet without introducing structural changes into the network. We further propose an analytical approach that dynamically learns scalings for each convolutional layer based on the spatial characteristics of its input feature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100, and ImageNet show that without searching for reparameterized structures, our proposed scaling method outperforms the state-of-the-art reparameterization methods at a lower computational cost",
    "checked": true,
    "id": "9017cb3911c9dd3730e28689c2346e59d0c86e09",
    "semantic_title": "reparameterization through spatial gradient scaling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=-ENYHCE8zBp": {
    "title": "Unsupervised Learning for Combinatorial Optimization Needs Meta Learning",
    "volume": "poster",
    "abstract": "A general framework of unsupervised learning for combinatorial optimization (CO) is to train a neural network whose output gives a problem solution by directly optimizing the CO objective. Albeit with some advantages over traditional solvers, current frameworks optimize an averaged performance over the distribution of historical problem instances, which misaligns with the actual goal of CO that looks for a good solution to every future encountered instance. With this observation, we propose a new objective of unsupervised learning for CO where the goal of learning is to search for good initialization for future problem instances rather than give direct solutions. We propose a meta-learning-based training pipeline for this new objective. Our method achieves good performance. We observe that even the initial solution given by our model before fine-tuning can significantly outperform the baselines under various evaluation settings including evaluation across multiple datasets, and the case with big shifts in the problem scale. The reason we conjecture is that meta-learning-based training lets the model be loosely tied to each local optimum for a training instance while being more adaptive to the changes of optimization landscapes across instances",
    "checked": false,
    "id": "4fb5641502fc47b0a54c06a0e79fd3192aea00d6",
    "semantic_title": "unsupervised learning for combinatorial optimization needs meta-learning",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=r0BrY4BiEXO": {
    "title": "Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models",
    "volume": "poster",
    "abstract": "Privacy is a central tenet of Federated learning (FL), in which a central server trains models without centralizing user data. However, gradient updates used in FL can leak user information. While the most industrial uses of FL are for text applications (e.g. keystroke prediction), the majority of attacks on user privacy in FL have focused on simple image classifiers and threat models that assume honest execution of the FL protocol from the server. We propose a novel attack that reveals private user text by deploying malicious parameter vectors, and which succeeds even with mini-batches, multiple users, and long sequences. Unlike previous attacks on FL, the attack exploits characteristics of both the Transformer architecture and the token embedding, separately extracting tokens and positional embeddings to retrieve high-fidelity text. We argue that the threat model of malicious server states is highly relevant from a user-centric perspective, and show that in this scenario, text applications using transformer models are much more vulnerable than previously thought",
    "checked": true,
    "id": "f2cd15c1925ef54d58b3d71506d7113d7911a8c2",
    "semantic_title": "decepticons: corrupted transformers breach privacy in federated learning for language models",
    "citation_count": 65,
    "authors": []
  },
  "https://openreview.net/forum?id=zgVDqw9ZUES": {
    "title": "Adaptive Optimization in the $\\infty$-Width Limit",
    "volume": "poster",
    "abstract": "Recent works have developed detailed understanding of large neural networks' behaviors via their infinite-width limits, e.g., the neural tangent kernel (NTK) and the feature learning ($\\mu$) limits. These theories were developed for stochastic gradient descent. Yet, in practice, all large NN are trained using Adam or other adaptive gradient optimizers (AGO), which are not covered by such previous works. Here, we close this gap via the Tensor Programs framework. Specifically, for deep MLPs, we derive the NTK and $\\mu$ parametrizations as well as their infinite-width limits. We find 1) The NTK limit of AGO, in contrast to that of SGD, now depends nonlinearly on the loss derivative but nevertheless still fails to learn features; 2) this is fixed by the $\\mu$ limit of AGO (as in the case of SGD). To obtain these results, we extend the Tensor Programs language with a new instruction that allows one to express the gradient processing done by AGOs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sckjveqlCZ": {
    "title": "Broken Neural Scaling Laws",
    "volume": "poster",
    "abstract": "We present a smoothly broken power law functional form (referred to by us as a broken neural scaling law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, or upstream performance varies) for various architectures and for each of various tasks within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, AI alignment, robotics, out-of-distribution (OOD) generalization, continual learning, uncertainty estimation / calibration, out-of-distribution detection, adversarial robustness, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforcement learning (single agent and multi-agent). When compared to other functional forms for neural scaling behavior, this functional form yields extrapolations of scaling behavior that are considerably more accurate on this set. Moreover, this functional form accurately models and extrapolates scaling behavior that other functional forms are incapable of expressing such as the non-monotonic transitions present in the scaling behavior of phenomena such as double descent and the delayed, sharp inflection points present in the scaling behavior of tasks such as arithmetic. Lastly, we use this functional form to glean insights about the limit of the predictability of scaling behavior. See arXiv for longer version of this paper. Code is available at https://github.com/ethancaballero/broken_neural_scaling_laws",
    "checked": true,
    "id": "61f329722cd94291898c2c8131606a55f7a07219",
    "semantic_title": "broken neural scaling laws",
    "citation_count": 90,
    "authors": []
  },
  "https://openreview.net/forum?id=5BaqCFVh5qL": {
    "title": "Avoiding spurious correlations via logit correction",
    "volume": "poster",
    "abstract": "Empirical studies suggest that machine learning models trained with empirical risk minimization (ERM) often rely on attributes that may be spuriously correlated with the class labels. Such models typically lead to poor performance during inference for data lacking such correlations. In this work, we explicitly consider a situation where potential spurious correlations are present in the majority of training data. In contrast with existing approaches, which use the ERM model outputs to detect the samples without spurious correlations and either heuristically upweight or upsample those samples, we propose the logit correction (LC) loss, a simple yet effective improvement on the softmax cross-entropy loss, to correct the sample logit. We demonstrate that minimizing the LC loss is equivalent to maximizing the group-balanced accuracy, so the proposed LC could mitigate the negative impacts of spurious correlations. Our extensive experimental results further reveal that the proposed LC loss outperforms state-of-the-art solutions on multiple popular benchmarks by a large margin, an average 5.5% absolute improvement, without access to spurious attribute labels. LC is also competitive with oracle methods that make use of the attribute labels",
    "checked": true,
    "id": "c4ade0185969dca4b48e280b63cab54d71d7d492",
    "semantic_title": "avoiding spurious correlations via logit correction",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=wNUgn1n6esQ": {
    "title": "Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-Free RL",
    "volume": "poster",
    "abstract": "Reward-free reinforcement learning (RF-RL), a recently introduced RL paradigm, relies on random action-taking to explore the unknown environment without any reward feedback information. While the primary goal of the exploration phase in RF-RL is to reduce the uncertainty in the estimated model with minimum number of trajectories, in practice, the agent often needs to abide by certain safety constraint at the same time. It remains unclear how such safe exploration requirement would affect the corresponding sample complexity in order to achieve the desired optimality of the obtained policy in planning. In this work, we make a first attempt to answer this question. In particular, we consider the scenario where a safe baseline policy is known beforehand, and propose a unified Safe reWard-frEe ExploraTion (SWEET) framework. We then particularize the SWEET framework to the tabular and the low-rank MDP settings, and develop algorithms coined Tabular-SWEET and Low-rank-SWEET, respectively. Both algorithms leverage the concavity and continuity of the newly introduced truncated value functions, and are guaranteed to achieve zero constraint violation during exploration with high probability. Furthermore, both algorithms can provably find a near-optimal policy subject to any constraint in the planning phase. Remarkably, the sample complexities under both algorithms match or even outperform the state of the art in their constraint-free counterparts up to some constant factors, proving that safety constraint hardly increases the sample complexity for RF-RL",
    "checked": true,
    "id": "50911bce5f5aee1eb1d27ca2b17d483e9c3cf0c5",
    "semantic_title": "safe exploration incurs nearly no additional sample complexity for reward-free rl",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=Nayau9fwXU": {
    "title": "Diffusion-based Image Translation using disentangled style and content representation",
    "volume": "poster",
    "abstract": "Diffusion-based image translation guided by semantic texts or a single target image has enabled flexible style transfer which is not limited to the specific domains. Unfortunately, due to the stochastic nature of diffusion models, it is often difficult to maintain the original content of the image during the reverse diffusion. To address this, here we present a novel diffusion-based unsupervised image translation method, dubbed as DiffuseIT, using disentangled style and content representation. Specifically, inspired by the slicing Vision Transformer, we extract intermediate keys of multihead self attention layer from ViT model and used them as the content preservation loss. Then, an image guided style transfer is performed by matching the [CLS] classification token from the denoised samples and target image, whereas additional CLIP loss is used for the text-driven style transfer. To further accelerate the semantic change during the reverse diffusion, we also propose a novel semantic divergence loss and resampling strategy. Our experimental results show that the proposed method outperforms state-of-the-art baseline models in both text-guided and image-guided translation tasks",
    "checked": true,
    "id": "52472459ea81b6ebc65d16a0c80005f749542cba",
    "semantic_title": "diffusion-based image translation using disentangled style and content representation",
    "citation_count": 178,
    "authors": []
  },
  "https://openreview.net/forum?id=d7Q0vVfJ0wO": {
    "title": "Implicit Regularization for Group Sparsity",
    "volume": "poster",
    "abstract": "We study the implicit regularization of gradient descent towards structured sparsity via a novel neural reparameterization, which we call a diagonally grouped linear neural network. We show the following intriguing property of our reparameterization: gradient descent over the squared regression loss, without any explicit regularization, biases towards solutions with a group sparsity structure. In contrast to many existing works in understanding implicit regularization, we prove that our training trajectory cannot be simulated by mirror descent. We analyze the gradient dynamics of the corresponding regression problem in the general noise setting and obtain minimax-optimal error rates. Compared to existing bounds for implicit sparse regularization using diagonal linear networks, our analysis with the new reparameterization shows improved sample complexity. In the degenerate case of size-one groups, our approach gives rise to a new algorithm for sparse linear regression. Finally, we demonstrate the efficacy of our approach with several numerical experiments",
    "checked": true,
    "id": "6ed45c42f320d94ae5f209125b97ec84666bb211",
    "semantic_title": "implicit regularization for group sparsity",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=92gvk82DE-": {
    "title": "Large Language Models are Human-Level Prompt Engineers",
    "volume": "poster",
    "abstract": "By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection. In our method, we treat the instruction as the \"program,\" optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 21/24 tasks. We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts",
    "checked": true,
    "id": "4610ffb1b016acaa82a2065ffd1a3adbae1ce722",
    "semantic_title": "large language models are human-level prompt engineers",
    "citation_count": 1023,
    "authors": []
  },
  "https://openreview.net/forum?id=i-DleYh34BM": {
    "title": "Pruning Deep Neural Networks from a Sparsity Perspective",
    "volume": "poster",
    "abstract": "In recent years, deep network pruning has attracted significant attention in order to enable the rapid deployment of AI into small devices with computation and memory constraints. Pruning is often achieved by dropping redundant weights, neurons, or layers of a deep network while attempting to retain a comparable test performance. Many deep pruning algorithms have been proposed with impressive empirical success. However, existing approaches lack a quantifiable measure to estimate the compressibility of a sub-network during each pruning iteration and thus may under-prune or over-prune the model. In this work, we propose PQ Index (PQI) to measure the potential compressibility of deep neural networks and use this to develop a Sparsity-informed Adaptive Pruning (SAP) algorithm. Our extensive experiments corroborate the hypothesis that for a generic pruning procedure, PQI decreases first when a large model is being effectively regularized and then increases when its compressibility reaches a limit that appears to correspond to the beginning of underfitting. Subsequently, PQI decreases again when the model collapse and significant deterioration in the performance of the model start to occur. Additionally, our experiments demonstrate that the proposed adaptive pruning algorithm with proper choice of hyper-parameters is superior to the iterative pruning algorithms such as the lottery ticket-based pruning methods, in terms of both compression efficiency and robustness",
    "checked": true,
    "id": "4117f8b1aee5907cb8c0907f3cffbb11b27f28e0",
    "semantic_title": "pruning deep neural networks from a sparsity perspective",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=hCmjBJeGXcu": {
    "title": "Enhancing Meta Learning via Multi-Objective Soft Improvement Functions",
    "volume": "poster",
    "abstract": "Meta-learning tries to leverage information from similar learning tasks. In the commonly-used bilevel optimization formulation, the shared parameter is learned in the outer loop by minimizing the average loss over all tasks. However, the converged solution may be comprised in that it only focuses on optimizing on a small subset of tasks. To alleviate this problem, we consider meta-learning as a multi-objective optimization (MOO) problem, in which each task is an objective. However, existing MOO solvers need to access all the objectives' gradients in each iteration, and cannot scale to the huge number of tasks in typical meta-learning settings. To alleviate this problem, we propose a scalable gradient-based solver with the use of mini-batch. We provide theoretical guarantees on the Pareto optimality or Pareto stationarity of the converged solution. Empirical studies on various machine learning settings demonstrate that the proposed method is efficient, and achieves better performance than the baselines, particularly on improving the performance of the poorly-performing tasks and thus alleviating the compromising phenomenon",
    "checked": true,
    "id": "e841e0cd6b1c2677bdf6bae6e276f7fea0e1ea80",
    "semantic_title": "enhancing meta learning via multi-objective soft improvement functions",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=VM8batVBWvg": {
    "title": "Discrete Predictor-Corrector Diffusion Models for Image Synthesis",
    "volume": "poster",
    "abstract": "We introduce Discrete Predictor-Corrector diffusion models (DPC), extending predictor-corrector samplers in Gaussian diffusion models to the discrete case. Predictor-corrector samplers are a class of samplers for diffusion models, which improve on ancestral samplers by correcting the sampling distribution of intermediate diffusion states using MCMC methods. In DPC, the Langevin corrector, which does not have a direct counterpart in discrete space, is replaced with a discrete MCMC transition defined by a learned corrector kernel. The corrector kernel is trained to make the correction steps achieve asymptotic convergence, in distribution, to the correct marginal of the intermediate diffusion states. Equipped with DPC, we revisit recent transformer-based non-autoregressive generative models through the lens of discrete diffusion, and find that DPC can alleviate the compounding decoding error due to the parallel sampling of visual tokens. Our experiments show that DPC improves upon existing discrete latent space models for class-conditional image generation on ImageNet, and outperforms continuous diffusion models and GANs, according to standard metrics and user preference studies",
    "checked": true,
    "id": "30517693897bde78ee887bfc2904825f68ab65d0",
    "semantic_title": "discrete predictor-corrector diffusion models for image synthesis",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=tcbBPnfwxS": {
    "title": "OPTQ: Accurate Quantization for Generative Pre-trained Transformers",
    "volume": "poster",
    "abstract": "Generative Pre-trained Transformer models, known as GPT or OPT, set themselves apart through breakthrough performance across complex language modelling tasks, but also by their extremely high computational and storage costs. Specifically, due to their massive size, even inference for large, highly-accurate GPT models may require multiple performant GPUs, which limits the usability of such models. While there is emerging work on relieving this pressure via model compression, the applicability and performance of existing compression techniques is limited by the scale and complexity of GPT models. In this paper, we address this challenge, and propose OPTQ, a new one-shot weight quantization method based on approximate second-order information, that is both highly-accurate and highly-efficient. Specifically, OPTQ can quantize GPT models with 175 billion parameters in approximately four GPU hours, reducing the bitwidth down to 3 or 4 bits per weight, with negligible accuracy degradation relative to the uncompressed baseline. Our method more than doubles the compression gains relative to previously-proposed one-shot quantization methods, preserving accuracy, allowing us for the first time to execute an 175 billion-parameter model inside a single GPU for generative inference. Moreover, we also show that our method can still provide reasonable accuracy in the extreme quantization regime, in which weights are quantized to 2-bit or even ternary quantization levels. We show experimentally that these improvements can be leveraged for end-to-end inference speedups over FP16, of around 3.25x when using high-end GPUs (NVIDIA A100) and 4.5x when using more cost-effective ones (NVIDIA A6000). The implementation is available at https://github.com/IST-DASLab/gptq",
    "checked": true,
    "id": "363668677c459ebc0ff494655f993a93a0251009",
    "semantic_title": "optq: accurate quantization for generative pre-trained transformers",
    "citation_count": 294,
    "authors": []
  },
  "https://openreview.net/forum?id=bH-kCY6LdKg": {
    "title": "A new characterization of the edge of stability based on a sharpness measure aware of batch gradient distribution",
    "volume": "poster",
    "abstract": "For full-batch gradient descent (GD), it has been empirically shown that the sharpness, the top eigenvalue of the Hessian, increases and then hovers above $2/\\text{(learning rate)}$, and this is called ``the edge of stability'' phenomenon. However, it is unclear why the sharpness is somewhat larger than $2/\\text{(learning rate)}$ and how this can be extended to general mini-batch stochastic gradient descent (SGD). We propose a new sharpness measure (interaction-aware-sharpness) aware of the \\emph{interaction} between the batch gradient distribution and the loss landscape geometry. This leads to a more refined and general characterization of the edge of stability for SGD. Moreover, based on the analysis of a concentration measure of the batch gradient, we propose a more accurate scaling rule, Linear and Saturation Scaling Rule (LSSR), between batch size and learning rate",
    "checked": true,
    "id": "7db981dfaf7546e45947a65920ae756ea6cf239e",
    "semantic_title": "a new characterization of the edge of stability based on a sharpness measure aware of batch gradient distribution",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=RDy3IbvjMqT": {
    "title": "$\\mathrm{SE}(3)$-Equivariant Attention Networks for Shape Reconstruction in Function Space",
    "volume": "poster",
    "abstract": "We propose a method for 3D shape reconstruction from unoriented point clouds. Our method consists of a novel SE(3)-equivariant coordinate-based network (TF-ONet), that parametrizes the occupancy field of the shape and respects the inherent symmetries of the problem. In contrast to previous shape reconstruction methods that align the input to a regular grid, we operate directly on the irregular point cloud. Our architecture leverages equivariant attention layers that operate on local tokens. This mechanism enables local shape modelling, a crucial property for scalability to large scenes. Given an unoriented, sparse, noisy point cloud as input, we produce equivariant features for each point. These serve as keys and values for the subsequent equivariant cross-attention blocks that parametrize the occupancy field. By querying an arbitrary point in space, we predict its occupancy score. We show that our method outperforms previous SO(3)-equivariant methods, as well as non-equivariant methods trained on SO(3)-augmented datasets. More importantly, local modelling together with SE(3)-equivariance create an ideal setting for SE(3) scene reconstruction. We show that by training only on single, aligned objects and without any pre-segmentation, we can reconstruct novel scenes containing arbitrarily many objects in random poses without any performance loss",
    "checked": false,
    "id": "391488394770f211a7c6790a741286a1e777ed83",
    "semantic_title": "se(3)-equivariant attention networks for shape reconstruction in function space",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=m_GDIItaI3o": {
    "title": "Continual Pre-training of Language Models",
    "volume": "poster",
    "abstract": "Language models (LMs) have been instrumental for the rapid advance of natural language processing. This paper studies continual pre-training of LMs, in particular, continual domain-adaptive pre-training (or continual DAP-training). Existing research has shown that further pre-training an LM using a domain corpus to adapt the LM to the domain can improve the end-task performance in the domain. This paper proposes a novel method to continually DAP-train an LM with a sequence of unlabeled domain corpora to adapt the LM to these domains to improve their end-task performances. The key novelty of our method is a soft-masking mechanism that directly controls the update to the LM. A novel proxy is also proposed to preserve the general knowledge in the original LM. Additionally, it contrasts the representations of the previously learned domain knowledge (including the general knowledge in the pre-trained LM) and the knowledge from the current full network to achieve knowledge integration. The method not only overcomes catastrophic forgetting, but also achieves knowledge transfer to improve end-task performances. Empirical evaluation demonstrates the effectiveness of the proposed method",
    "checked": true,
    "id": "e3ec55e9e6720194a0ed5d4033d93a941c8a4f99",
    "semantic_title": "continual pre-training of language models",
    "citation_count": 167,
    "authors": []
  },
  "https://openreview.net/forum?id=PvDY71zKsvP": {
    "title": "Min-Max Multi-objective Bilevel Optimization with Applications in Robust Machine Learning",
    "volume": "poster",
    "abstract": "We consider a generic min-max multi-objective bilevel optimization problem with applications in robust machine learning such as representation learning and hyperparameter optimization. We design MORBiT, a novel single-loop gradient descent-ascent bilevel optimization algorithm, to solve the generic problem and present a novel analysis showing that MORBiT converges to the first-order stationary point at a rate of $\\widetilde{\\mathcal{O}}(n^{1/2} K^{-2/5})$ for a class of weakly convex problems with $n$ objectives upon $K$ iterations of the algorithm. Our analysis utilizes novel results to handle the non-smooth min-max multi-objective setup and to obtain a sublinear dependence in the number of objectives $n$. Experimental results on robust representation learning and robust hyperparameter optimization showcase (i) the advantages of considering the min-max multi-objective setup, and (ii) convergence properties of the proposed \\morbit",
    "checked": true,
    "id": "d6c868da77c4d9d22312541ab5af3aefda886932",
    "semantic_title": "min-max multi-objective bilevel optimization with applications in robust machine learning",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=7h5KSs2PCRi": {
    "title": "Forward Super-Resolution: How Can GANs Learn Hierarchical Generative Models for Real-World Distributions",
    "volume": "poster",
    "abstract": "Generative adversarial networks (GANs) are among the most successful models for learning high-complexity, real-world distributions. However, in theory, due to the highly non-convex, non-concave landscape of the minmax training objective, GAN remains one of the least understood deep learning models. In this work, we formally study how GANs can efficiently learn certain hierarchically generated distributions that are close to the distribution of real-life images. We prove that when a distribution has a structure that we refer to as \\emph{forward super-resolution}, then simply training generative adversarial networks using stochastic gradient descent ascent (SGDA) can learn this distribution efficiently, both in sample and time complexities. We also provide empirical evidence that our assumption ``forward super-resolution'' is very natural in practice, and the underlying learning mechanisms that we study in this paper (to allow us efficiently train GAN via GDA in theory) simulates the actual learning process of GANs on real-world problems",
    "checked": true,
    "id": "276c91fc2f41f95bfd14ab003e70dcbd0656bfc1",
    "semantic_title": "forward super-resolution: how can gans learn hierarchical generative models for real-world distributions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=9yE2xEj0BH7": {
    "title": "Spotlight: Mobile UI Understanding using Vision-Language Models with a Focus",
    "volume": "poster",
    "abstract": "Mobile UI understanding is important for enabling various interaction tasks such as UI automation and accessibility. Previous mobile UI modeling often depends on the view hierarchy information of a screen, which directly provides the structural data of the UI, with the hope to bypass challenging tasks of visual modeling from screen pixels. However, view hierarchies are not always available, and are often corrupted with missing object descriptions or misaligned structure information. As a result, despite the use of view hierarchies could offer short-term gains, it may ultimately hinder the applicability and performance of the model. In this paper, we propose Spotlight, a vision-only approach for mobile UI understanding. Specifically, we enhance a vision-language model that only takes the screenshot of the UI and a region of interest on the screen---the focus---as the input. This general architecture of Spotlight is easily scalable and capable of performing a range of UI modeling tasks. Our experiments show that our model establishes SoTA results on several representative UI tasks and outperforms previous methods that use both screenshots and view hierarchies as inputs. Furthermore, we explore multi-task learning and few-shot prompting capacities of the proposed models, demonstrating promising results in the multi-task learning direction",
    "checked": true,
    "id": "9b9fb973e5d3b413baa90648d9eb0743bd889747",
    "semantic_title": "spotlight: mobile ui understanding using vision-language models with a focus",
    "citation_count": 74,
    "authors": []
  },
  "https://openreview.net/forum?id=rimcq1oIFeR": {
    "title": "A Control-Centric Benchmark for Video Prediction",
    "volume": "poster",
    "abstract": "Video is a promising source of knowledge for embodied agents to learn models of the world's dynamics. Large deep networks have become increasingly effective at modeling complex video data in a self-supervised manner, as evaluated by metrics based on human perceptual similarity or pixel-wise comparison. However, it remains unclear whether current metrics are accurate indicators of performance on downstream tasks. We find empirically that for planning robotic manipulation, existing metrics can be unreliable at predicting execution success. To address this, we propose a benchmark for action-conditioned video prediction in the form of a control benchmark that evaluates a given model for simulated robotic manipulation through sampling-based planning. Our benchmark, Video Prediction for Visual Planning ($\\text{VP}^2$), includes simulated environments with $11$ task categories and $310$ task instance definitions, a full planning implementation, and training datasets containing scripted interaction trajectories for each task category. A central design goal of our benchmark is to expose a simple interface -- a single forward prediction call -- so it is straightforward to evaluate almost any action-conditioned video prediction model. We then leverage our benchmark to study the effects of scaling model size, quantity of training data, and model ensembling by analyzing five highly-performant video prediction models, finding that while scale can improve perceptual quality when modelling visually diverse settings, other attributes such as uncertainty awareness can also aid planning performance",
    "checked": true,
    "id": "3be14893028ab620d0fc940becd4ce758ab96a40",
    "semantic_title": "a control-centric benchmark for video prediction",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=vsMyHUq_C1c": {
    "title": "A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8371f8ca8ef8620cc72267763f5af2dd1b7c460b",
    "semantic_title": "a stable and scalable method for solving initial value pdes with neural networks",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=a65YK0cqH8g": {
    "title": "Noise Is Not the Main Factor Behind the Gap Between Sgd and Adam on Transformers, But Sign Descent Might Be",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "592e2a4c8bb3e72b1f6d671d6642907fa81b1782",
    "semantic_title": "noise is not the main factor behind the gap between sgd and adam on transformers, but sign descent might be",
    "citation_count": 92,
    "authors": []
  },
  "https://openreview.net/forum?id=li7qeBbCR1t": {
    "title": "Building Normalizing Flows with Stochastic Interpolants",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4e6244baf4236f4635e85f7dfb941a9a0a6c4a11",
    "semantic_title": "building normalizing flows with stochastic interpolants",
    "citation_count": 508,
    "authors": []
  },
  "https://openreview.net/forum?id=VE1s3e5xriA": {
    "title": "Dual Student Networks for Data-Free Model Stealing",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e562c8ee825ed4e1b3ec4037f6e9e1194d355f07",
    "semantic_title": "dual student networks for data-free model stealing",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=nWTzIsgrYNN": {
    "title": "Composite Slice Transformer: An Efficient Transformer with Composition of Multi-Scale Multi-Range Attentions",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "54983a66dc8bc15af89890bc9e1a63e056594179",
    "semantic_title": "composite slice transformer: an efficient transformer with composition of multi-scale multi-range attentions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=dhYUMMy0_Eg": {
    "title": "Equal Improvability: A New Fairness Notion Considering the Long-term Impact",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f04682dd597d4cbac4ec0d84527954b7a87158cc",
    "semantic_title": "equal improvability: a new fairness notion considering the long-term impact",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=z9SIj-IM7tn": {
    "title": "Competitive Physics Informed Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f3a1c70d8dce3377e93fa0c623ce4d435b5e59aa",
    "semantic_title": "competitive physics informed networks",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=_nGgzQjzaRy": {
    "title": "Decomposed Prompting: A Modular Approach for Solving Complex Tasks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "07955e96cbd778d0ae2a68f09d073b866dd84c2a",
    "semantic_title": "decomposed prompting: a modular approach for solving complex tasks",
    "citation_count": 528,
    "authors": []
  },
  "https://openreview.net/forum?id=9MO7bjoAfIA": {
    "title": "Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0ef6a11a0fccc6886e6f837cef43cc55c5da4de4",
    "semantic_title": "self-ensemble protection: training checkpoints are good data protectors",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=2EpjkjzdCAa": {
    "title": "Effectively Modeling Time Series with Simple Discrete State Spaces",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a7d68b1702af08ce4dbbf2cd0b083e744ae5c6be",
    "semantic_title": "effectively modeling time series with simple discrete state spaces",
    "citation_count": 56,
    "authors": []
  },
  "https://openreview.net/forum?id=Jbdc0vTOcol": {
    "title": "A Time Series is Worth 64 Words: Long-term Forecasting with Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "dad15404d372a23b4b3bf9a63b3124693df3c85e",
    "semantic_title": "a time series is worth 64 words: long-term forecasting with transformers",
    "citation_count": 1864,
    "authors": []
  },
  "https://openreview.net/forum?id=086pmarAris": {
    "title": "Fantastic Rewards and How to Tame Them: A Case Study on Reward Learning for Task-oriented Dialogue Systems",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fa49e6f77ae14a9da2371d194ace3565376428ae",
    "semantic_title": "fantastic rewards and how to tame them: a case study on reward learning for task-oriented dialogue systems",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=8jU7wy7N7mA": {
    "title": "Supervision Complexity and its Role in Knowledge Distillation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b246284c63b127414b75865a6a0725cb8d995f71",
    "semantic_title": "supervision complexity and its role in knowledge distillation",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=-htnolWDLvP": {
    "title": "Transferable Unlearnable Examples",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d0d7afcb50d92a061d4351e7ed16dce2b26b1e23",
    "semantic_title": "transferable unlearnable examples",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=3pfNb4pZBNp": {
    "title": "Random Laplacian Features for Learning with Hyperbolic Space",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b3f1594cfcb14a392feab64571691bd60f6bf308",
    "semantic_title": "random laplacian features for learning with hyperbolic space",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=SjzFVSJUt8S": {
    "title": "Replay Memory as An Empirical MDP: Combining Conservative Estimation with Experience Replay",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3b96b6306ed2fc84cb9cf8076c5084849ae62ae0",
    "semantic_title": "replay memory as an empirical mdp: combining conservative estimation with experience replay",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=vouQcZS8KfW": {
    "title": "Neural Causal Models for Counterfactual Identification and Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d356d612ac3e9d11b7a7778f03e6b1c5d4134489",
    "semantic_title": "neural causal models for counterfactual identification and estimation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vCJ9-Ri-6xU": {
    "title": "Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f154ba64b77a0deeb64220e6a4c28f007b1816e8",
    "semantic_title": "momentum stiefel optimizer, with applications to suitably-orthogonal attention, and optimal transport",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=UvmDCdSPDOW": {
    "title": "Information-Theoretic Diffusion",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b72bef3c193d58c354a12ea0672ca5654d4a4db3",
    "semantic_title": "information-theoretic diffusion",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=GPJVuyX4p_h": {
    "title": "SIMPLE: A Gradient Estimator for k-Subset Sampling",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "24f89e3d55cd639a1f0f31c43e636d2b3bb66b2d",
    "semantic_title": "simple: a gradient estimator for k-subset sampling",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=gLPkzWjdhBN": {
    "title": "Learning Iterative Neural Optimizers for Image Steganography",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "46e760a8688fbcb4a863467a0d21e43af4bf6ab8",
    "semantic_title": "learning iterative neural optimizers for image steganography",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=3aQs3MCSexD": {
    "title": "How Much Data Are Augmentations Worth? An Investigation into Scaling Laws, Invariance, and Implicit Regularization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4e2e78f75336240667687d16bf32ffdff7556f98",
    "semantic_title": "how much data are augmentations worth? an investigation into scaling laws, invariance, and implicit regularization",
    "citation_count": 47,
    "authors": []
  },
  "https://openreview.net/forum?id=qxRscesArBZ": {
    "title": "Robust Graph Dictionary Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9078452e8b927597bc0aef46c64b475ea06e2a72",
    "semantic_title": "robust graph dictionary learning",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=gpmL0D4VjN4": {
    "title": "Fundamental limits on the robustness of image classifiers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ade34f95e9350477aa7f103e9607a8f770bffe6f",
    "semantic_title": "fundamental limits on the robustness of image classifiers",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=cxCEOSF99f": {
    "title": "Understanding Influence Functions and Datamodels via Harmonic Analysis",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1e0ecc5a7589199b6fdc844207444e5accd7608e",
    "semantic_title": "understanding influence functions and datamodels via harmonic analysis",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=5tKXUZil3X": {
    "title": "TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "85d08a213e9533c515601451cd78f971e547b1ae",
    "semantic_title": "textgrad: advancing robustness evaluation in nlp by gradient-driven optimization",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=bQB6qozaBw": {
    "title": "Information Plane Analysis for Dropout Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9af80598cc32a8060fbf731e0954e3e6d3a754f8",
    "semantic_title": "information plane analysis for dropout neural networks",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=ySCL-NG_I3": {
    "title": "Learning Harmonic Molecular Representations on Riemannian Manifold",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "89a1b991a28ce671ecf36d6a4addd284bd846f0e",
    "semantic_title": "learning harmonic molecular representations on riemannian manifold",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=eSQh8rG8Oa": {
    "title": "Greedy Actor-Critic: A New Conditional Cross-Entropy Method for Policy Improvement",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cyg2YXn_BqF": {
    "title": "Efficiently Controlling Multiple Risks with Pareto Testing",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "abbd5a6a9fc908e459fe6e2fe4ea4b41a1000cea",
    "semantic_title": "efficiently controlling multiple risks with pareto testing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=loIfC8WHevK": {
    "title": "Characteristic Neural Ordinary Differential Equation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "17773066cf244e82503e7283dcf1981bfe4ef0a6",
    "semantic_title": "characteristic neural ordinary differential equations",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Loek7hfb46P": {
    "title": "Fast Sampling of Diffusion Models with Exponential Integrator",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6651ff3d8c89a3cddfeef0c5d03ac4cb121758e3",
    "semantic_title": "fast sampling of diffusion models with exponential integrator",
    "citation_count": 480,
    "authors": []
  },
  "https://openreview.net/forum?id=A9WQaxYsfx": {
    "title": "Panning for Gold in Federated Learning: Targeted Text Extraction under Arbitrarily Large-Scale Aggregation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e6c4955aa6410cfce3f7abdff22db9c2f6d96279",
    "semantic_title": "panning for gold in federated learning: targeted text extraction under arbitrarily large-scale aggregation",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=dBk3hsg-n6": {
    "title": "Artificial Neuronal Ensembles with Learned Context Dependent Gating",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7f83b7fbde102f31b48678376c43ab7365a05ec7",
    "semantic_title": "artificial neuronal ensembles with learned context dependent gating",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=rGeZuBRahju": {
    "title": "Learning Language Representations with Logical Inductive Bias",
    "volume": "poster",
    "abstract": "Transformer architectures have achieved great success in solving natural language tasks, which learn strong language representations from large-scale unlabeled texts. In this paper, we seek to go further beyond and explore a new logical inductive bias for better language representation learning. Logic reasoning is known as a formal methodology to reach answers from given knowledge and facts. Inspired by such a view, we develop a novel neural architecture named FOLNet (First-Order Logic Network), to encode this new inductive bias. We construct a set of neural logic operators as learnable Horn clauses, which are further forward-chained into a fully differentiable neural architecture (FOLNet). Interestingly, we find that the self-attention module in transformers can be composed by two of our neural logic operators, which probably explains their strong reasoning performance. Our proposed FOLNet has the same input and output interfaces as other pretrained models and thus could be pretrained/finetuned by using similar losses. It also allows FOLNet to be used in a plug-and-play manner when replacing other pretrained models. With our logical inductive bias, the same set of ``logic deduction skills'' learned through pretraining are expected to be equally capable of solving diverse downstream tasks. For this reason, FOLNet learns language representations that have much stronger transfer capabilities. Experimental results on several language understanding tasks show that our pretrained FOLNet model outperforms the existing strong transformer-based approaches",
    "checked": true,
    "id": "4d1be5f81204f968a34a08975fece5f626f79618",
    "semantic_title": "learning language representations with logical inductive bias",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Dzmd-Cc8OI": {
    "title": "How Does Semi-supervised Learning with Pseudo-labelers Work? A Case Study",
    "volume": "poster",
    "abstract": "Semi-supervised learning is a popular machine learning paradigm that utilizes a large amount of unlabeled data as well as a small amount of labeled data to facilitate learning tasks. While semi-supervised learning has achieved great success in training neural networks, its theoretical understanding remains largely open. In this paper, we aim to theoretically understand a semi-supervised learning approach based on pre-training and linear probing. In particular, the semi-supervised learning approach we consider first trains a two-layer neural network based on the unlabeled data with the help of pseudo-labelers. Then it linearly probes the pre-trained network on a small amount of labeled data. We prove that, under a certain toy data generation model and two-layer convolutional neural network, the semisupervised learning approach can achieve nearly zero test loss, while a neural network directly trained by supervised learning on the same amount of labeled data can only achieve constant test loss. Through this case study, we demonstrate a separation between semi-supervised learning and supervised learning in terms of test loss provided the same amount of labeled data",
    "checked": true,
    "id": "3ec356c38f0b2a0828e475c8d73e907691251b6f",
    "semantic_title": "how does semi-supervised learning with pseudo-labelers work? a case study",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Lnxl5pr018": {
    "title": "Empowering Graph Representation Learning with Test-Time Graph Transformation",
    "volume": "poster",
    "abstract": "As powerful tools for representation learning on graphs, graph neural networks (GNNs) have facilitated various applications from drug discovery to recommender systems. Nevertheless, the effectiveness of GNNs is immensely challenged by issues related to data quality, such as distribution shift, abnormal features and adversarial attacks. Recent efforts have been made on tackling these issues from a modeling perspective which requires additional cost of changing model architectures or re-training model parameters. In this work, we provide a data-centric view to tackle these issues and propose a graph transformation framework named GTrans which adapts and refines graph data at test time to achieve better performance. We provide theoretical analysis on the design of the framework and discuss why adapting graph data works better than adapting the model. Extensive experiments have demonstrated the effectiveness of GTrans on three distinct scenarios for eight benchmark datasets where suboptimal data is presented. Remarkably, GTrans performs the best in most cases with improvements up to 2.8%, 8.2% and 3.8% over the best baselines on three experimental settings",
    "checked": true,
    "id": "ee8333852cea80faec02a50d925f2316cf1c2e1f",
    "semantic_title": "empowering graph representation learning with test-time graph transformation",
    "citation_count": 68,
    "authors": []
  },
  "https://openreview.net/forum?id=HJFVrpCaGE": {
    "title": "Provable Robustness against Wasserstein Distribution Shifts via Input Randomization",
    "volume": "poster",
    "abstract": "Certified robustness in machine learning has primarily focused on adversarial perturbations with a fixed attack budget for each sample in the input distribution. In this work, we present provable robustness guarantees on the accuracy of a model under bounded Wasserstein shifts of the data distribution. We show that a simple procedure that randomizes the input of the model within a transformation space is provably robust to distributional shifts under that transformation. Our framework allows the datum-specific perturbation size to vary across different points in the input distribution and is general enough to include fixed-sized perturbations as well. Our certificates produce guaranteed lower bounds on the performance of the model for any shift (natural or adversarial) of the input distribution within a Wasserstein ball around the original distribution. We apply our technique to certify robustness against natural (non-adversarial) transformations of images such as color shifts, hue shifts, and changes in brightness and saturation. We obtain strong performance guarantees for the robust model under clearly visible shifts in the input images. Our experiments establish the non-vacuousness of our certificates by showing that the certified lower bound on a robust model's accuracy is higher than the empirical accuracy of an undefended model under a distribution shift. Moreover, our results also imply guaranteed lower bounds (hardness result) on the performance of models trained on so-called \"unlearnable\" datasets that have been poisoned to interfere with model training. We show that the performance of a robust model is guaranteed to remain above a certain threshold on the test distribution even when the base model is trained on the poisoned dataset",
    "checked": true,
    "id": "3055d5e50bb5ae8bda9d3e603d61d57e623366d2",
    "semantic_title": "provable robustness against wasserstein distribution shifts via input randomization",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=YtntjusJV6": {
    "title": "Interpretations of Domain Adaptations via Layer Variational Analysis",
    "volume": "poster",
    "abstract": "Transfer learning is known to perform efficiently in many applications empirically, yet limited literature reports the mechanism behind the scene. This study establishes both formal derivations and heuristic analysis to formulate the theory of transfer learning in deep learning. Our framework utilizing layer variational analysis proves that the success of transfer learning can be guaranteed with corresponding data conditions. Moreover, our theoretical calculation yields intuitive interpretations towards the knowledge transfer process. Subsequently, an alternative method for network-based transfer learning is derived. The method shows an increase in efficiency and accuracy for domain adaptation. It is particularly advantageous when new domain data is sufficiently sparse during adaptation. Numerical experiments over diverse tasks validated our theory and verified that our analytic expression achieved better performance in domain adaptation than the gradient descent method",
    "checked": true,
    "id": "b421eb4550a682d8403d3af33589fe36b63bf42a",
    "semantic_title": "interpretations of domain adaptations via layer variational analysis",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=8pvnfTAbu1f": {
    "title": "Denoising Diffusion Samplers",
    "volume": "poster",
    "abstract": "Denoising diffusion models are a popular class of generative models providing state-of-the-art results in many domains. One adds gradually noise to data using a diffusion to transform the data distribution into a Gaussian distribution. Samples from the generative model are then obtained by simulating an approximation of the time-reversal of this diffusion initialized by Gaussian samples. Practically, the intractable score terms appearing in the time-reversed process are approximated using score matching techniques. We explore here a similar idea to sample approximately from unnormalized probability density functions and estimate their normalizing constants. We consider a process where the target density diffuses towards a Gaussian. Denoising Diffusion Samplers (DDS) are obtained by approximating the corresponding time-reversal. While score matching is not applicable in this context, we can leverage many of the ideas introduced in generative modeling for Monte Carlo sampling. Existing theoretical results from denoising diffusion models also provide theoretical guarantees for DDS. We discuss the connections between DDS, optimal control and Schr\\\"odinger bridges and finally demonstrate DDS experimentally on a variety of challenging sampling tasks",
    "checked": true,
    "id": "3ee60ee899941c7056fc10e1b69e71bac0f11c97",
    "semantic_title": "denoising diffusion samplers",
    "citation_count": 108,
    "authors": []
  },
  "https://openreview.net/forum?id=_nF5imFKQI": {
    "title": "How I Learned to Stop Worrying and Love Retraining",
    "volume": "poster",
    "abstract": "Many Neural Network Pruning approaches consist of several iterative training and pruning steps, seemingly losing a significant amount of their performance after pruning and then recovering it in the subsequent retraining phase. Recent works of Renda et al. (2020) and Le & Hua (2021) demonstrate the significance of the learning rate schedule during the retraining phase and propose specific heuristics for choosing such a schedule for IMP (Han et al., 2015). We place these findings in the context of the results of Li et al. (2020) regarding the training of models within a fixed training budget and demonstrate that, consequently, the retraining phase can be massively shortened using a simple linear learning rate schedule. Improving on existing retraining approaches, we additionally propose a method to adaptively select the initial value of the linear schedule. Going a step further, we propose similarly imposing a budget on the initial dense training phase and show that the resulting simple and efficient method is capable of outperforming significantly more complex or heavily parameterized state-of-the-art approaches that attempt to sparsify the network during training. These findings not only advance our understanding of the retraining phase, but more broadly question the belief that one should aim to avoid the need for retraining and reduce the negative effects of ‘hard' pruning by incorporating the sparsification process into the standard training",
    "checked": true,
    "id": "dde57499f185730d4dfc9c5df00d6aebef5bb8a9",
    "semantic_title": "how i learned to stop worrying and love retraining",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=6u7mf9s2A9": {
    "title": "Interpretable Geometric Deep Learning via Learnable Randomness Injection",
    "volume": "poster",
    "abstract": "Point cloud data is ubiquitous in scientific fields. Recently, geometric deep learning (GDL) has been widely applied to solve prediction tasks with such data. However, GDL models are often complicated and hardly interpretable, which poses concerns to scientists who are to deploy these models in scientific analysis and experiments. This work proposes a general mechanism, learnable randomness injection (LRI), which allows building inherently interpretable models based on general GDL backbones. LRI-induced models, once trained, can detect the points in the point cloud data that carry information indicative of the prediction label. We also propose four datasets from real scientific applications that cover the domains of high-energy physics and biochemistry to evaluate the LRI mechanism. Compared with previous post-hoc interpretation methods, the points detected by LRI align much better and stabler with the ground-truth patterns that have actual scientific meanings. LRI is grounded by the information bottleneck principle, and thus LRI-induced models are also more robust to distribution shifts between training and test scenarios. Our code and datasets are available at https://github.com/Graph-COM/LRI",
    "checked": true,
    "id": "18ffe561eefe204c116d7f871a25c0500f5098e0",
    "semantic_title": "interpretable geometric deep learning via learnable randomness injection",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=fPVRcJqspu": {
    "title": "GOGGLE: Generative Modelling for Tabular Data by Learning Relational Structure",
    "volume": "poster",
    "abstract": "Deep generative models learn highly complex and non-linear representations to generate realistic synthetic data. While they have achieved notable success in computer vision and natural language processing, similar advances have been less demonstrable in the tabular domain. This is partially because generative modelling of tabular data entails a particular set of challenges, including heterogeneous relationships, limited number of samples, and difficulties in incorporating prior knowledge. Additionally, unlike their counterparts in image and sequence domain, deep generative models for tabular data almost exclusively employ fully-connected layers, which encode weak inductive biases about relationships between inputs. Real-world data generating processes can often be represented using relational structures, which encode sparse, heterogeneous relationships between variables. In this work, we learn and exploit relational structure underlying tabular data to better model variable dependence, and as a natural means to introduce regularization on relationships and include prior knowledge. Specifically, we introduce GOGGLE, an end-to-end message passing scheme that jointly learns the relational structure and corresponding functional relationships as the basis of generating synthetic samples. Using real-world datasets, we provide empirical evidence that the proposed method is effective in generating realistic synthetic data and exploiting domain knowledge for downstream tasks",
    "checked": true,
    "id": "d41c2ecc159e545ef02dac198a6be7b066d9563d",
    "semantic_title": "goggle: generative modelling for tabular data by learning relational structure",
    "citation_count": 70,
    "authors": []
  },
  "https://openreview.net/forum?id=UJTgQBc91_": {
    "title": "Progressive Prompts: Continual Learning for Language Models",
    "volume": "poster",
    "abstract": "We introduce Progressive Prompts – a simple and efficient approach for continual learning in language models. Our method allows forward transfer and resists catastrophic forgetting, without relying on data replay or a large number of task-specific parameters. Progressive Prompts learns a new soft prompt for each task and sequentially concatenates it with the previously learned prompts, while keeping the base model frozen. Experiments on standard continual learning benchmarks show that our approach outperforms state-of-the-art methods, with an improvement >20% in average test accuracy over the previous best-preforming method on T5 model. We also explore a more challenging continual learning setup with longer sequences of tasks and show that Progressive Prompts significantly outperforms prior methods",
    "checked": true,
    "id": "86478f285356b5c8d27423e6b939634d9e010fba",
    "semantic_title": "progressive prompts: continual learning for language models",
    "citation_count": 168,
    "authors": []
  },
  "https://openreview.net/forum?id=_qVhsWyWB9": {
    "title": "Deep Learning From Crowdsourced Labels: Coupled Cross-Entropy Minimization, Identifiability, and Regularization",
    "volume": "poster",
    "abstract": "Using noisy crowdsourced labels from multiple annotators, a deep learning-based end-to-end (E2E) system aims to learn the label correction mechanism and the neural classifier simultaneously. To this end, many E2E systems concatenate the neural classifier with multiple annotator-specific label confusion layers and co-train the two parts in a parameter-coupled manner. The formulated coupled cross-entropy minimization (CCEM)-type criteria are intuitive and work well in practice. Nonetheless, theoretical understanding of the CCEM criterion has been limited. The contribution of this work is twofold: First, performance guarantees of the CCEM criterion are presented. Our analysis reveals for the first time that the CCEM can indeed correctly identify the annotators' confusion characteristics and the desired ``ground-truth'' neural classifier under realistic conditions, e.g., when only incomplete annotator labeling and finite samples are available. Second, based on the insights learned from our analysis, two regularized variants of the CCEM are proposed. The regularization terms provably enhance the identifiability of the target model parameters in various more challenging cases. A series of synthetic and real data experiments are presented to showcase the effectiveness of our approach",
    "checked": true,
    "id": "f2f66f757b8df8a2f236b1500c77e2503cbec194",
    "semantic_title": "deep learning from crowdsourced labels: coupled cross-entropy minimization, identifiability, and regularization",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=yEsj8pGNl1": {
    "title": "Projective Proximal Gradient Descent for Nonconvex Nonsmooth Optimization: Fast Convergence Without Kurdyka-Lojasiewicz (KL) Property",
    "volume": "poster",
    "abstract": "Nonconvex and nonsmooth optimization problems are important and challenging for statistics and machine learning. In this paper, we propose Projected Proximal Gradient Descent (PPGD) which solves a class of nonconvex and nonsmooth optimization problems, where the nonconvexity and nonsmoothness come from a nonsmooth regularization term which is nonconvex but piecewise convex. In contrast with existing convergence analysis of accelerated PGD methods for nonconvex and nonsmooth problems based on the Kurdyka-\\L{}ojasiewicz (K\\L{}) property, we provide a new theoretical analysis showing local fast convergence of PPGD. It is proved that PPGD achieves a fast convergence rate of $O(1/k^2)$ when the iteration number $k \\ge k_0$ for a finite $k_0$ on a class of nonconvex and nonsmooth problems under mild assumptions, which is locally the Nesterov's optimal convergence rate of first-order methods on smooth and convex objective function with Lipschitz continuous gradient. Experimental results demonstrate the effectiveness of PPGD",
    "checked": true,
    "id": "d7fe70f851315a672e0e43793ef034e726345661",
    "semantic_title": "projective proximal gradient descent for nonconvex nonsmooth optimization: fast convergence without kurdyka-lojasiewicz (kl) property",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7wrq3vHcMM": {
    "title": "First Steps Toward Understanding the Extrapolation of Nonlinear Models to Unseen Domains",
    "volume": "poster",
    "abstract": "Real-world machine learning applications often involve deploying neural networks to domains that are not seen in the training time. Hence, we need to understand the extrapolation of \\textit{nonlinear} models---under what conditions on the distributions and function class, models can be guaranteed to extrapolate to new test distributions. The question is very challenging because even two-layer neural networks cannot be guaranteed to extrapolate outside the support of the training distribution without further assumptions on the domain shift. This paper makes some initial steps towards analyzing the extrapolation of nonlinear models for structured domain shift. We primarily consider settings where the \\textit{marginal} distribution of each coordinate of the data (or subset of coordinates) do not shift significantly across the training and test distributions, but the joint distribution may have a much bigger shift. We prove that the family of nonlinear models of the form $f(x)=\\sum f_i(x_i)$, where $f_i$ is an \\emph{arbitrary} function on the subset of features $x_i$, can extrapolate to unseen distributions, if the covariance of the features is well-conditioned. To the best of our knowledge, this is the first result that goes beyond linear models and the bounded density ratio assumption, even though the assumptions on the distribution shift and function class are stylized",
    "checked": true,
    "id": "50b2b7d7fb2550c0e8d012bb7152794b41701e30",
    "semantic_title": "first steps toward understanding the extrapolation of nonlinear models to unseen domains",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=-Yzz6vlX7V-": {
    "title": "Compositionality with Variation Reliably Emerges in Neural Networks",
    "volume": "poster",
    "abstract": "Human languages enable robust generalization, letting us leverage our prior experience to communicate about novel meanings. This is partly due to language being compositional, where the meaning of a whole expression is a function of its parts. Natural languages also exhibit extensive variation, encoding meaning predictably enough to enable generalization without limiting speakers to one and only one way of expressing something. Previous work looking at the languages that emerge between neural networks in a communicative task has shown languages that enable robust communication and generalization reliably emerge. Despite this those languages score poorly on existing measures of compositionality leading to claims that a language's degree of compositionality has little bearing on how well it can generalise. We argue that the languages that emerge between networks are in fact straightforwardly compositional, but with a degree of natural language-like variation that can obscure their compositionality from existing measures. We introduce 4 measures of linguistic variation and show that early in training measures of variation correlate with generalization performance, but that this effect goes away over time as the languages that emerge become regular enough to generalize robustly. Like natural languages, emergent languages appear able to support a high degree of variation while retaining the generalizability we expect from compositionality. In an effort to decrease the variability of emergent languages we show how reducing a model's capacity results in greater regularity, in line with claims about factors shaping the emergence of regularity in human language",
    "checked": true,
    "id": "ac245daef84a6753f9e90abdc775c900eb9ba9e6",
    "semantic_title": "compositionality with variation reliably emerges in neural networks",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=k8_yVW3Wqln": {
    "title": "Systematic Rectification of Language Models via Dead-end Analysis",
    "volume": "poster",
    "abstract": "With adversarial or otherwise normal prompts, existing large language models (LLM) can be pushed to generate toxic discourses. One way to reduce the risk of LLMs generating undesired discourses is to alter the training of the LLM. This can be very restrictive due to demanding computation requirements. Other methods rely on rule-based or prompt-based token elimination, which are limited as they dismiss future tokens and the overall meaning of the complete discourse. Here, we center detoxification on the probability that the finished discourse is ultimately considered toxic. That is, at each point, we advise against token selections proportional to how likely a finished text from this point will be toxic. To this end, we formally extend the dead-end theory from the recent reinforcement learning (RL) literature to also cover uncertain outcomes. Our approach, called rectification, utilizes a separate but significantly smaller model for detoxification, which can be applied to diverse LLMs as long as they share the same vocabulary. Importantly, our method does not require access to the internal representations of the LLM, but only the token probability distribution at each decoding step. We believe this is important since many LLMs today are hosted in servers and only accessible through APIs. When applied to various LLMs, including GPT-3, our approach generates notably better results compared to the base LLMs and other techniques in terms of the overall language and detoxification performance",
    "checked": true,
    "id": "da5fcb26c830663b79c9aa1c550ae62e7725fcad",
    "semantic_title": "systematic rectification of language models via dead-end analysis",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=8efJYMBrNb": {
    "title": "Multiple sequence alignment as a sequence-to-sequence learning problem",
    "volume": "poster",
    "abstract": "The sequence alignment problem is one of the most fundamental problems in bioinformatics and a plethora of methods were devised to tackle it. Here we introduce BetaAlign, a methodology for aligning sequences using an NLP approach. BetaAlign accounts for the possible variability of the evolutionary process among different datasets by using an ensemble of transformers, each trained on millions of samples generated from a different evolutionary model. Our approach leads to alignment accuracy that is similar and often better than commonly used methods, such as MAFFT, DIALIGN, ClustalW, T-Coffee, PRANK, and MUSCLE",
    "checked": true,
    "id": "a8fefdd3aa68c054747eafb928ed383e88450f76",
    "semantic_title": "multiple sequence alignment as a sequence-to-sequence learning problem",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=4FBUihxz5nm": {
    "title": "A Mixture-of-Expert Approach to RL-based Dialogue Management",
    "volume": "poster",
    "abstract": "Despite recent advancements in language models (LMs), their application to dialogue management (DM) problems and ability to carry on rich conversations remain a challenge. We use reinforcement learning (RL) to develop a dialogue agent that avoids being short-sighted (outputting generic utterances) and maximizes overall user satisfaction. Most existing RL approaches to DM train the agent at the word-level, and thus, have to deal with a combinatorially complex action space even for a medium-size vocabulary. As a result, they struggle to produce a successful and engaging dialogue even if they are warm-started with a pre-trained LM. To address this issue, we develop a RL-based DM using a novel mixture of expert language model (MoE-LM) that consists of (i) a LM capable of learning diverse semantics for conversation histories, (ii) a number of specialized LMs (or experts) capable of generating utterances corresponding to a particular attribute or personality, and (iii) a RL-based DM that performs dialogue planning with the utterances generated by the experts. Our MoE approach provides greater flexibility to generate sensible utterances with different intents and allows RL to focus on conversational-level DM. We compare it with SOTA baselines on open-domain dialogues and demonstrate its effectiveness both in terms of the diversity and sensibility of the generated utterances and the overall DM performance",
    "checked": true,
    "id": "81de450838dfe072f3b4f773cc2a4ed37064af9b",
    "semantic_title": "a mixture-of-expert approach to rl-based dialogue management",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=iBdwKIsg4m": {
    "title": "f-DM: A Multi-stage Diffusion Model via Progressive Signal Transformation",
    "volume": "poster",
    "abstract": "Diffusion models (DMs) have recently emerged as SoTA tools for generative modeling in various domains. Standard DMs can be viewed as an instantiation of hierarchical variational autoencoders (VAEs) where the latent variables are inferred from input-centered Gaussian distributions with fixed scales and variances. Unlike VAEs, this formulation constrains DMs from changing the latent spaces and learning abstract representations. In this work, we propose f-DM, a generalized family of DMs which allows progressive signal transformation. More precisely, we extend DMs to incorporate a set of (hand-designed or learned) transformations, where the transformed input is the mean of each diffusion step. We propose a generalized formulation and derive the corresponding de-noising objective with a modified sampling algorithm. As a demonstration, we apply f-DM in image generation tasks with a range of functions, including down-sampling, blurring, and learned transformations based on the encoder of pretrained VAEs. In addition, we identify the importance of adjusting the noise levels whenever the signal is sub-sampled and propose a simple rescaling recipe. f-DM can produce high-quality samples on standard image generation benchmarks like FFHQ, AFHQ, LSUN, and ImageNet with better efficiency and semantic interpretation",
    "checked": true,
    "id": "19d39b1c13795c556cfaf0eb7b89aeb187200a43",
    "semantic_title": "f-dm: a multi-stage diffusion model via progressive signal transformation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=nIMifqu2EO": {
    "title": "Backpropagation at the Infinitesimal Inference Limit of Energy-Based Models: Unifying Predictive Coding, Equilibrium Propagation, and Contrastive Hebbian Learning",
    "volume": "poster",
    "abstract": "How the brain performs credit assignment is a fundamental unsolved problem in neuroscience. Many `biologically plausible' algorithms have been proposed, which compute gradients that approximate those computed by backpropagation (BP), and which operate in ways that more closely satisfy the constraints imposed by neural circuitry. Many such algorithms utilize the framework of energy-based models (EBMs), in which all free variables in the model are optimized to minimize a global energy function. However, in the literature, these algorithms exist in isolation and no unified theory exists linking them together. Here, we provide a comprehensive theory of the conditions under which EBMs can approximate BP, which lets us unify many of the BP approximation results in the literature (namely, predictive coding, equilibrium propagation, and contrastive Hebbian learning) and demonstrate that their approximation to BP arises from a simple and general mathematical property of EBMs at free-phase equilibrium. This property can then be exploited in different ways with different energy functions, and these specific choices yield a family of BP-approximating algorithms, which both includes the known results in the literature and can be used to derive new ones",
    "checked": true,
    "id": "232e3ab355787bd61afeedc05de6ad4ae04070a6",
    "semantic_title": "backpropagation at the infinitesimal inference limit of energy-based models: unifying predictive coding, equilibrium propagation, and contrastive hebbian learning",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=ZCTvSF_uVM4": {
    "title": "A Theoretical Framework for Inference and Learning in Predictive Coding Networks",
    "volume": "poster",
    "abstract": "Predictive coding (PC) is an influential theory in computational neuroscience, which argues that the cortex forms unsupervised world models by implementing a hierarchical process of prediction error minimization. PC networks (PCNs) are trained in two phases. First, neural activities are updated to optimize the network's response to external stimuli. Second, synaptic weights are updated to consolidate this change in activity --- an algorithm called \\emph{prospective configuration}. While previous work has shown how in various limits, PCNs can be found to approximate backpropagation (BP), recent work has demonstrated that PCNs operating in this standard regime, which does not approximate BP, nevertheless obtain competitive training and generalization performance to BP-trained networks while outperforming them on various tasks. However, little is understood theoretically about the properties and dynamics of PCNs in this regime. In this paper, we provide a comprehensive theoretical analysis of the properties of PCNs trained with prospective configuration. We first derive analytical results concerning the inference equilibrium for PCNs and a previously unknown close connection relationship to target propagation (TP). Secondly, we provide a theoretical analysis of learning in PCNs as a variant of generalized expectation-maximization and use that to prove the convergence of PCNs to critical points of the BP loss function, thus showing that deep PCNs can, in theory, achieve the same generalization performance as BP, while maintaining their unique advantages",
    "checked": true,
    "id": "6f33194da2822dd84c2318d36c3f85a6ba93d73a",
    "semantic_title": "a theoretical framework for inference and learning in predictive coding networks",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=JLINxPOVTh7": {
    "title": "The Onset of Variance-Limited Behavior for Networks in the Lazy and Rich Regimes",
    "volume": "poster",
    "abstract": "For small training set sizes $P$, the generalization error of wide neural networks is well-approximated by the error of an infinite width neural network (NN), either in the kernel or mean-field/feature-learning regime. However, after a critical sample size $P^*$, we empirically find the finite-width network generalization becomes worse than that of the infinite width network. In this work, we empirically study the transition from infinite-width behavior to this \\textit{variance-limited} regime as a function of sample size $P$ and network width $N$. We find that finite-size effects can become relevant for very small dataset sizes on the order of $P^* \\sim \\sqrt{N}$ for polynomial regression with ReLU networks. We discuss the source of these effects using an argument based on the variance of the NN's final neural tangent kernel (NTK). This transition can be pushed to larger $P$ by enhancing feature learning or by ensemble averaging the networks. We find that the learning curve for regression with the final NTK is an accurate approximation of the NN learning curve. Using this, we provide a toy model which also exhibits $P^* \\sim \\sqrt{N}$ scaling and has $P$-dependent benefits from feature learning",
    "checked": true,
    "id": "4fe83e4a9aec5d057e15dc2f1aeab43b3dfea2ed",
    "semantic_title": "the onset of variance-limited behavior for networks in the lazy and rich regimes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1C6nCCaRe6p": {
    "title": "A Simple Approach for Visual Room Rearrangement: 3D Mapping and Semantic Search",
    "volume": "poster",
    "abstract": "Physically rearranging objects is an important capability for embodied agents. Visual room rearrangement evaluates an agent's ability to rearrange objects in a room to a desired goal based solely on visual input. We propose a simple yet effective method for this problem: (1) search for and map which objects need to be rearranged, and (2) rearrange each object until the task is complete. Our approach consists of an off-the-shelf semantic segmentation model, voxel-based semantic map, and semantic search policy to efficiently find objects that need to be rearranged. Our method was the winning submission to the AI2-THOR Rearrangement Challenge in the 2022 Embodied AI Workshop at CVPR 2022, and improves on current state-of-the-art end-to-end reinforcement learning-based methods that learn visual room rearrangement policies from 0.53% correct rearrangement to 16.56%, using only 2.7% as many samples from the environment",
    "checked": true,
    "id": "6f436beb9b11748f1a76c945baad014202794d74",
    "semantic_title": "a simple approach for visual room rearrangement: 3d mapping and semantic search",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=H7M_5K5qKJV": {
    "title": "Progressive Mix-Up for Few-Shot Supervised Multi-Source Domain Transfer",
    "volume": "poster",
    "abstract": "This paper targets at a new and challenging setting of knowledge transfer from multiple source domains to a single target domain, where target data is few shot or even one shot with label. Traditional domain generalization or adaptation methods cannot directly work since there is no sufficient target domain distribution serving as the transfer object. The multi-source setting further prevents the transfer task as excessive domain gap introduced from all the source domains. To tackle this problem, we newly propose a progressive mix-up (P-Mixup) mechanism to introduce an intermediate mix-up domain, pushing both the source domains and the few-shot target domain aligned to this mix-up domain. Further by enforcing the mix-up domain to progressively move towards the source domains, we achieve the domain transfer from multi-source domains to the single one-shot target domain. Our P-Mixup is different from traditional mix-up that ours is with a progressive and adaptive mix-up ratio, following the curriculum learning spirit to better align the source and target domains. Moreover, our P-Mixup combines both pixel-level and feature-level mix-up to better enrich the data diversity. Experiments on two benchmarks show that our P-Mixup significantly outperforms the state-of-the-art methods, i.e., 6.0\\% and 6.8\\% improvements on Office-Home and DomainNet",
    "checked": true,
    "id": "b2472267838a706a7c0258d0c3a185b80d61ae83",
    "semantic_title": "progressive mix-up for few-shot supervised multi-source domain transfer",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=F8VKQyDgRVj": {
    "title": "Neural Compositional Rule Learning for Knowledge Graph Reasoning",
    "volume": "poster",
    "abstract": "Learning logical rules is critical to improving reasoning in KGs. This is due to their ability to provide logical and interpretable explanations when used for predictions, as well as their ability to generalize to other tasks, domains, and data. While recent methods have been proposed to learn logical rules, the majority of these methods are either restricted by their computational complexity and can not handle the large search space of large-scale KGs, or show poor generalization when exposed to data outside the training set. In this paper, we propose an end-to-end neural model for learning compositional logical rules called NCRL. NCRL detects the best compositional structure of a rule body, and breaks it into small compositions in order to infer the rule head. By recurrently merging compositions in the rule body with a recurrent attention unit, NCRL finally predicts a single rule head. Experimental results show that NCRL learns high-quality rules, as well as being generalizable. Specifically, we show that NCRL is scalable, efficient, and yields state-of-the-art results for knowledge graph completion on large-scale KGs. Moreover, we test NCRL for systematic generalization by learning to reason on small-scale observed graphs and evaluating on larger unseen ones",
    "checked": true,
    "id": "58820d7d68e12d2a531e771a5fcb7e461c25f5c6",
    "semantic_title": "neural compositional rule learning for knowledge graph reasoning",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=XC_yGI-0j9": {
    "title": "Efficient approximation of neural population structure and correlations with probabilistic circuits",
    "volume": "poster",
    "abstract": "We present a computationally efficient framework to model a wide range of population structures with high order correlations and a large number of neurons. Our method is based on a special type of Bayesian network that has linear inference time and is founded upon the concept of contextual independence. Moreover, we use an efficient architecture learning method for network selection to model large neural populations even with a small amount of data. Our framework is both fast and accurate in approximating neural population structures. Furthermore, our approach enables us to reliably quantify higher order neural correlations. We test our method on simulated neural populations commonly used to generate higher order correlations, as well as on publicly available large-scale neural recordings from the Allen Brain Observatory. Our approach significantly outperforms other models both in terms of statistical measures and alignment with experimental evidence",
    "checked": true,
    "id": "5f6781a009d3584c5fef903d732c69d6fa6b2f05",
    "semantic_title": "efficient approximation of neural population structure and correlations with probabilistic circuits",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4cOfD2qL6T": {
    "title": "Exploring perceptual straightness in learned visual representations",
    "volume": "poster",
    "abstract": "Humans have been shown to use a ''straightened'' encoding to represent the natural visual world as it evolves in time (Henaff et al. 2019). In the context of discrete video sequences, ''straightened'' means that changes between frames follow a more linear path in representation space at progressively deeper levels of processing. While deep convolutional networks are often proposed as models of human visual processing, many do not straighten natural videos. In this paper, we explore the relationship between network architecture, differing types of robustness, biologically-inspired filtering mechanisms, and representational straightness in response to time-varying input; we identify strengths and limitations of straightness as a useful way of evaluating neural network representations. We find that (1) adversarial training leads to straighter representations in both CNN and transformer-based architectures but (2) this effect is task-dependent, not generalizing to tasks such as segmentation and frame-prediction, where straight representations are not favorable for predictions; and nor to other types of robustness. In addition, (3) straighter representations impart temporal stability to class predictions, even for out-of-distribution data. Finally, (4) biologically-inspired elements increase straightness in the early stages of a network, but do not guarantee increased straightness in downstream layers of CNNs. We show that straightness is an easily computed measure of representational robustness and stability, as well as a hallmark of human representations with benefits for computer vision models",
    "checked": true,
    "id": "ef1e0be5660333544a4525bc125171c3529c519c",
    "semantic_title": "exploring perceptual straightness in learned visual representations",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=dL35lx-mTEs": {
    "title": "Is Forgetting Less a Good Inductive Bias for Forward Transfer?",
    "volume": "poster",
    "abstract": "One of the main motivations of studying continual learning is that the problem setting allows a model to accrue knowledge from past tasks to learn new tasks more efficiently. However, recent studies suggest that the key metric that continual learning algorithms optimize, reduction in catastrophic forgetting, does not correlate well with the forward transfer of knowledge. We believe that the conclusion previous works reached is due to the way they measure forward transfer. We argue that the measure of forward transfer to a task should not be affected by the restrictions placed on the continual learner in order to preserve knowledge of previous tasks. Instead, forward transfer should be measured by how easy it is to learn a new task given a set of representations produced by continual learning on previous tasks. Under this notion of forward transfer, we evaluate different continual learning algorithms on a variety of image classification benchmarks. Our results indicate that less forgetful representations lead to a better forward transfer suggesting a strong correlation between retaining past information and learning efficiency on new tasks. Further, we found less forgetful representations to be more diverse and discriminative compared to their forgetful counterparts",
    "checked": true,
    "id": "eaab8c5159fecd44687a1639d542e4fa4b2b0003",
    "semantic_title": "is forgetting less a good inductive bias for forward transfer?",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=7J-30ilaUZM": {
    "title": "Learning Structured Representations by Embedding Class Hierarchy",
    "volume": "poster",
    "abstract": "Existing models for learning representations in supervised classification problems are permutation invariant with respect to class labels. However, structured knowledge about the classes, such as hierarchical label structures, widely exists in many real-world datasets, e.g., the ImageNet and CIFAR benchmarks. How to learn representations that can preserve such structures among the classes remains an open problem. To approach this problem, given a tree of class hierarchy, we first define a tree metric between any pair of nodes in the tree to be the length of the shortest path connecting them. We then provide a method to learn the hierarchical relationship of class labels by approximately embedding the tree metric in the Euclidean space of features. More concretely, during supervised training, we propose to use the Cophenetic Correlation Coefficient (CPCC) as a regularizer for the cross-entropy loss to correlate the tree metric of classes and the Euclidean distance in the class-conditioned representations. Our proposed regularizer is computationally lightweight and easy to implement. Empirically, we demonstrate that this approach can help to learn more interpretable representations due to the preservation of the tree metric, and leads to better in-distribution generalization as well as under sub-population shifts over six real-world datasets",
    "checked": true,
    "id": "b71600d6bb57bc9375bd9f192796034a95a6d586",
    "semantic_title": "learning structured representations by embedding class hierarchy",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=gmL46YMpu2J": {
    "title": "Promptagator: Few-shot Dense Retrieval From 8 Examples",
    "volume": "poster",
    "abstract": "Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other retrieval tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, this overlooks the fact that there are many diverse and unique retrieval problems, each targeting different search intents, queries, and search domains. In this paper, we suggest to work on Few-shot Dense Retrieval, a setting where each task comes with a short description and a few examples. To address this, we introduce Prompt-based Query Generation forRetrieval (Promptagator): for each task, we feed the few-shot examples to a large language model (LLM) and prompt it to behave as a task-specific query generator. Using this, we can synthetically generate a large number of relevant queries for any document, yielding abundant data for training task-specific retrievers --- with no reliance on traditional resources such as Natural Questions (Kwiatkowskiet al., 2019) or MS MARCO (Nguyen et al., 2016). Surprisingly, Promptagator with only 8 annotated examples enables efficient dual encoder retrievers to outperform computationally more expensive models trained on MS MARCO such as ColBERT v2 (Santhanam et al., 2022) by more than 1.2 points nDCG@10 on average on 11 retrieval sets. Further training standard-size re-rankers using the same generated data yields another 5.0 points nDCG@10 improvement. Our studies show that synthetic query generation can be far more effective than previously observed, especially when a small amount of task-specific knowledge is given",
    "checked": true,
    "id": "e86009d9f9b1cdf083a48d087552bc4153784451",
    "semantic_title": "promptagator: few-shot dense retrieval from 8 examples",
    "citation_count": 265,
    "authors": []
  },
  "https://openreview.net/forum?id=mCmerkTCG2S": {
    "title": "Brain-like representational straightening of natural movies in robust feedforward neural networks",
    "volume": "poster",
    "abstract": "Representational straightening refers to a decrease in curvature of visual feature representations of a sequence of frames taken from natural movies. Prior work established straightening in neural representations of the primate primary visual cortex (V1) and perceptual straightening in human behavior as a hallmark of biological vision in contrast to artificial feedforward neural networks which did not demonstrate this phenomenon as they were not explicitly optimized to produce temporally predictable movie representations. Here, we show robustness to noise in the input image can produce representational straightening in feedforward neural networks. Both adversarial training (AT) and base classifiers for Random Smoothing (RS) induced remarkably straightened feature codes. Demonstrating their utility within the domain of natural movies, these codes could be inverted to generate intervening movie frames by linear interpolation in the feature space even though they were not trained on these trajectories. Demonstrating their biological utility, we found that AT and RS training improved predictions of neural data in primate V1 over baseline models providing a parsimonious, bio-plausible mechanism -- noise in the sensory input stages -- for generating representations in early visual cortex. Finally, we compared the geometric properties of frame representations in these networks to better understand how they produced representations that mimicked the straightening phenomenon from biology. Overall, this work elucidating emergent properties of robust neural networks demonstrates that it is not necessary to utilize predictive objectives or train directly on natural movie statistics to achieve models supporting straightened movie representations similar to human perception that also predict V1 neural responses",
    "checked": true,
    "id": "2fff703a2cfe081b86ea3dc877a0a068da9ae503",
    "semantic_title": "brain-like representational straightening of natural movies in robust feedforward neural networks",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=BT4N_v7CLrk": {
    "title": "FunkNN: Neural Interpolation for Functional Generation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "dc444ee2a0beac5a6f0309c5119f4cc56a57dcdc",
    "semantic_title": "funknn: neural interpolation for functional generation",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=aCuFa-RRqtI": {
    "title": "Label Propagation with Weak Supervision",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3846545fe2082a15e8075fbfd960eaf56ce779d7",
    "semantic_title": "label propagation with weak supervision",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=4TyNEhI2GdN": {
    "title": "TypeT5: Seq2seq Type Inference using Static Analysis",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0b7509abcf9af50ad4e551be35f11b62ce7d2695",
    "semantic_title": "typet5: seq2seq type inference using static analysis",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=IrzkT99fDJH": {
    "title": "AGRO: Adversarial discovery of error-prone Groups for Robust Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8c87dcaba827e5c1683086c3118fd9bffa7cff5e",
    "semantic_title": "agro: adversarial discovery of error-prone groups for robust optimization",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=2b2s9vd7wYv": {
    "title": "LogicDP: Creating Labels for Graph Data via Inductive Logic Programming",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "73555a49203866198d503866d257acd0c75ecd8f",
    "semantic_title": "logicdp: creating labels for graph data via inductive logic programming",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=j3GK3_xZydY": {
    "title": "Revisiting Intrinsic Reward for Exploration in Procedurally Generated Environments",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e1a7ffaea6623d7999ba99ac66d4efbe249e5f7e",
    "semantic_title": "revisiting intrinsic reward for exploration in procedurally generated environments",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=TdBaDGCpjly": {
    "title": "Transformer-based World Models Are Happy With 100k Interactions",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f15a8105f5fb5444ef3685a893f85073af175bc4",
    "semantic_title": "transformer-based world models are happy with 100k interactions",
    "citation_count": 111,
    "authors": []
  },
  "https://openreview.net/forum?id=HVoJCRLByVk": {
    "title": "Can Neural Networks Learn Implicit Logic from Physical Reasoning?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fc80b1324187d5f7aa8466a7cb94d0d1640dfc2e",
    "semantic_title": "can neural networks learn implicit logic from physical reasoning?",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=35QyoZv8cKO": {
    "title": "ESCHER: Eschewing Importance Sampling in Games by Computing a History Value Function to Estimate Regret",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f2df422a39f2cebb4cc7f74af04ccf23bfaacc3b",
    "semantic_title": "escher: eschewing importance sampling in games by computing a history value function to estimate regret",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=fVm3nZMZs9": {
    "title": "On Achieving Optimal Adversarial Test Error",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9637c9b57eb8fff1802bbabe6431310bb64ec13f",
    "semantic_title": "on achieving optimal adversarial test error",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=FJXf1FXN8C": {
    "title": "Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4ab4a99fde6ffbfd1ca9a4313418c98d6a52c300",
    "semantic_title": "towards understanding gd with hard and conjugate pseudo-labels for test-time adaptation",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=6QkjC_cs03X": {
    "title": "A VAE for Transformers with Nonparametric Variational Information Bottleneck",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c7ccf90e0c15e28b18f7ff517a07cc82adecd708",
    "semantic_title": "a vae for transformers with nonparametric variational information bottleneck",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=Fh97BDaR6I": {
    "title": "On The Specialization of Neural Modules",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "0be71190ec12789ce2c9c1173839dddd5060667a",
    "semantic_title": "dynamics of specialization in neural modules under resource constraints",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=D7srTrGhAs": {
    "title": "HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b835345c6168d7b179516700aa4460912a8857e9",
    "semantic_title": "homodistil: homotopic task-agnostic distillation of pre-trained transformers",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=4u42KCQxCn8": {
    "title": "Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "11ba19641e12dc5f9cbe604fdeae2932f81f3056",
    "semantic_title": "using both demonstrations and language instructions to efficiently learn robotic tasks",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=NyR8OZFHw6i": {
    "title": "FIGARO: Controllable Music Generation using Learned and Expert Features",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "31454071080f0593c7e6d3cde606bdef276d8152",
    "semantic_title": "figaro: controllable music generation using learned and expert features",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=fR3wGCk-IXp": {
    "title": "Language models are multilingual chain-of-thought reasoners",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "62f0db3a5ad5c795ec18fc7a6e7b01836809df57",
    "semantic_title": "language models are multilingual chain-of-thought reasoners",
    "citation_count": 434,
    "authors": []
  },
  "https://openreview.net/forum?id=-cqvvvb-NkI": {
    "title": "Recitation-Augmented Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ed99a2572fb5f4240aa6068e3bf274832e831306",
    "semantic_title": "recitation-augmented language models",
    "citation_count": 71,
    "authors": []
  },
  "https://openreview.net/forum?id=p0JSSa1AuV": {
    "title": "KwikBucks: Correlation Clustering with Cheap-Weak and Expensive-Strong Signals",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bcd42145cf7bf312484e94b86bd0c6895cb99975",
    "semantic_title": "kwikbucks: correlation clustering with cheap-weak and expensive-strong signals",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=10uNUgI5Kl": {
    "title": "Reward Design with Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d318e0169f649656c71f02a1f84194a734fe1962",
    "semantic_title": "reward design with language models",
    "citation_count": 252,
    "authors": []
  },
  "https://openreview.net/forum?id=KdwnGErdT6": {
    "title": "Calibrating the Rigged Lottery: Making All Tickets Reliable",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b1c88b29bb53f83abe89fa74b2873e1a9d4aaccd",
    "semantic_title": "calibrating the rigged lottery: making all tickets reliable",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=FUiDMCr_W4o": {
    "title": "A Statistical Framework for Personalized Federated Learning and Estimation: Theory, Algorithms, and Privacy",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5af70db6c56ebc39d0ff58e74f6aba6fce2d67cd",
    "semantic_title": "a statistical framework for personalized federated learning and estimation: theory, algorithms, and privacy",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=w9WUQkBvpI": {
    "title": "Subsampling in Large Graphs Using Ricci Curvature",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fa05f053ef39cb3215ed5da8abf218dd35e010fd",
    "semantic_title": "subsampling in large graphs using ricci curvature",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=dNqxZgyjcYA": {
    "title": "Conservative Bayesian Model-Based Value Expansion for Offline Policy Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b70f24e1c189d3caa11792a759bc763af93125f2",
    "semantic_title": "conservative bayesian model-based value expansion for offline policy optimization",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=PYbe4MoHf32": {
    "title": "Scaling up and Stabilizing Differentiable Planning with Implicit Differentiation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "330bf00e4dab2f24c2fe30971a7f7f164370a37d",
    "semantic_title": "scaling up and stabilizing differentiable planning with implicit differentiation",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=BYWWwSY2G5s": {
    "title": "Score-based Continuous-time Discrete Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "33433e9103b00aa0c42597cbfe13a429fbf5abdf",
    "semantic_title": "score-based continuous-time discrete diffusion models",
    "citation_count": 107,
    "authors": []
  },
  "https://openreview.net/forum?id=NmZXv4467ai": {
    "title": "Decision Transformer under Random Frame Dropping",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "837118a68e143b4de61eec874c9bb85b953151c8",
    "semantic_title": "decision transformer under random frame dropping",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=bhfp5GlDtGe": {
    "title": "Adversarial Imitation Learning with Preferences",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "74e3b120e375e2fa98bbee0241f6ed3eeec75a3c",
    "semantic_title": "adversarial imitation learning with preferences",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=hNyJBk3CwR": {
    "title": "Is Model Ensemble Necessary? Model-based RL via a Single Model with Lipschitz Regularized Value Function",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "53a058a02c16d31acd2176c1104ac95e544fdcfa",
    "semantic_title": "is model ensemble necessary? model-based rl via a single model with lipschitz regularized value function",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=Q120_4COf-K": {
    "title": "Synthetic Data Generation of Many-to-Many Datasets via Random Graph Generation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ef9c719078722ad00e36d58e9017d77f8d9c62af",
    "semantic_title": "synthetic data generation of many-to-many datasets via random graph generation",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=k9CF4h3muD": {
    "title": "Learning Low Dimensional State Spaces with Overparameterized Recurrent Neural Nets",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d1193538e3ffd2eae9c9ecbeb0862b615d853a5a",
    "semantic_title": "learning low dimensional state spaces with overparameterized recurrent neural nets",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=ddad0PNUvV": {
    "title": "Images as Weight Matrices: Sequential Image Generation Through Synaptic Learning Rules",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8f30c30f92fbe1c307ee3c7a68c80a2c0dc8d619",
    "semantic_title": "images as weight matrices: sequential image generation through synaptic learning rules",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=svCcui6Drl": {
    "title": "Why (and When) does Local SGD Generalize Better than SGD?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4539dcc4672a86b8f1e0bc64b92790d33518f55d",
    "semantic_title": "why (and when) does local sgd generalize better than sgd?",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=89GT-S49mGd": {
    "title": "Function-space regularized Rényi divergences",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "01b5b907a58a798359d7fde28bb457b11c7da8b8",
    "semantic_title": "function-space regularized rényi divergences",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SRIQZTh0IK": {
    "title": "Analogy-Forming Transformers for Few-Shot 3D Parsing",
    "volume": "poster",
    "abstract": "We present Analogical Networks, a model that segments 3D object scenes with analogical reasoning: instead of mapping a scene to part segments directly, our model first retrieves related scenes from memory and their corresponding part structures, and then predicts analogous part structures in the input object 3D point cloud, via an end-to-end learnable modulation mechanism. By conditioning on more than one retrieved memories, compositions of structures are predicted, that mix and match parts across the retrieved memories. One-shot, few-shot or many-shot learning are treated uniformly in Analogical Networks, by conditioning on the appropriate set of memories, whether taken from a single, few or many memory exemplars, and inferring analogous parses. We show Analogical Networks are competitive with state-of-the-art 3D segmentation transformer in many-shot settings and outperform them and existing paradigms of meta-learning and few-shot learning in few-shot scenarios. Our model successfully parses instances of novel object categories simply by expanding its memory, without any weight updates",
    "checked": true,
    "id": "4bb44f4be38340d194d1d668de892e1e0f852166",
    "semantic_title": "analogy-forming transformers for few-shot 3d parsing",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=QWQM0ZwZdRS": {
    "title": "Fake It Until You Make It : Towards Accurate Near-Distribution Novelty Detection",
    "volume": "poster",
    "abstract": "We aim for image-based novelty detection. Despite considerable progress, existing models either fail or face dramatic drop under the so-called ``near-distribution\" setup, where the differences between normal and anomalous samples are subtle. We first demonstrate existing methods could experience up to 20\\% decrease in their AUCs in the near-distribution setting. Next, we propose to exploit a score-based generative model to produce synthetic near-distribution anomalous data. Our model is then fine-tuned to distinguish such data from the normal samples. We make quantitative as well as qualitative evaluation of this strategy, and compare the results with a variety of GAN-based models. Effectiveness of our method for both near-distribution and standard novelty detection is assessed through extensive experiments on datasets in diverse applications such as medical images, object classification, and quality control. This reveals that our method significantly improves upon existing models, and consistently decreases the gap between the near-distribution and standard novelty detection AUCs by a considerable amount",
    "checked": true,
    "id": "e7b7d5cee616906c3fc202cb4c156813372182d5",
    "semantic_title": "fake it until you make it : towards accurate near-distribution novelty detection",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=Pgtn4l6eKjv": {
    "title": "DySR: Adaptive Super-Resolution via Algorithm and System Co-design",
    "volume": "poster",
    "abstract": "Super resolution (SR) is a promising approach for improving the quality of low resolution steaming services on mobile devices. On mobile devices, the available computing and memory resources change dynamically depending on other running applications. Due to the high computation and memory demands of SR models, it is essential to adapt the model according to available resources to harvest the best possible model performance while maintaining quality of service (QoS), such as meeting a minimum framerate and avoiding interruptions. Nevertheless, there is no SR model or machine learning system that supports adaptive SR, and enabling adaptive SR model on mobile devices is challenging because adapting model can cause significant framerate drop or even service interruption. To address this challenge, we take an algorithm and system co-design approach and propose DySR that maintains QoS while maximizing the model performance. During the training stage, DySR employs an adaption-aware one-shot Neural Architecture Search to produce sub-graphs that share kernel operation weights for low model adaption overhead while striking a balance between performance and framerate. During the inference stage, an incremental model adaption method is developed for further reducing the model adaption overhead. We evaluate on a diverse set of hardware and datasets to show that DySR can generate models close to the Pareto frontier while maintaining a steady framerate throughput with a memory footprint of around 40\\% less compared to baseline methods",
    "checked": true,
    "id": "a9957da5ce2e890b2a74fcbadfee12013538c711",
    "semantic_title": "dysr: adaptive super-resolution via algorithm and system co-design",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=n7CPzMPKQl": {
    "title": "Integrating Symmetry into Differentiable Planning with Steerable Convolutions",
    "volume": "poster",
    "abstract": "To achieve this, we draw inspiration from equivariant convolution networks and model the path planning problem as a set of signals over grids. We demonstrate that value iteration can be treated as a linear equivariant operator, which is effectively a steerable convolution. Building upon Value Iteration Networks (VIN), we propose a new Symmetric Planning (SymPlan) framework that incorporates rotation and reflection symmetry using steerable convolution networks. We evaluate our approach on four tasks: 2D navigation, visual navigation, 2 degrees of freedom (2-DOF) configuration space manipulation, and 2-DOF workspace manipulation. Our experimental results show that our symmetric planning algorithms significantly improve training efficiency and generalization performance compared to non-equivariant baselines, including VINs and GPPN",
    "checked": false,
    "id": "a807a1c5048bc4f6022ff9194fc39b1b54f16c8c",
    "semantic_title": "integrating symmetry into differentiable planning",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=dcN0CaXQhT": {
    "title": "Causal Reasoning in the Presence of Latent Confounders via Neural ADMG Learning",
    "volume": "poster",
    "abstract": "Latent confounding has been a long-standing obstacle for causal reasoning from observational data. One popular approach is to model the data using acyclic directed mixed graphs (ADMGs), which describe ancestral relations between variables using directed and bidirected edges. However, existing methods using ADMGs are based on either linear functional assumptions or a discrete search that is complicated to use and lacks computational tractability for large datasets. In this work, we further extend the existing body of work and develop a novel gradient-based approach to learning an ADMG with nonlinear functional relations from observational data. We first show that the presence of latent confounding is identifiable under the assumptions of bow-free ADMGs with nonlinear additive noise models. With this insight, we propose a novel neural causal model based on autoregressive flows. This not only enables us to model complex causal relationships behind the data, but also estimate their functional relationships (hence treatment effects) simultaneously. We further validate our approach via experiments on both synthetic and real-world datasets, and demonstrate the competitive performance against relevant baselines",
    "checked": true,
    "id": "ac770ac2627c6592a95a5a8c04bdf8e3970abadf",
    "semantic_title": "causal reasoning in the presence of latent confounders via neural admg learning",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=VWqiPBB_EM": {
    "title": "$O(T^{-1})$ Convergence of Optimistic-Follow-the-Regularized-Leader in Two-Player Zero-Sum Markov Games",
    "volume": "poster",
    "abstract": "We prove that the optimistic-follow-the-regularized-leader (OFTRL) algorithm, together with smooth value updates, finds an $O(T^{−1})$ approximate Nash equilibrium in $T$ iterations for two-player zero-sum Markov games with full information. This improves the $\\tilde{O}(T^{−5/6})$ convergence rate recently shown by Zhang et al (2022). The refined analysis hinges on two essential ingredients. First, the sum of the regrets of the two players, though not necessarily non-negative as in normal-form games, is approximately non-negative in Markov games. This property allows us to bound the second-order path lengths of the learning dynamics. Second, we prove a tighter algebraic inequality regarding the weights deployed by OFTRL that shaves an extra $\\log T$ factor. This crucial improvement enables the inductive analysis that leads to the final $O(T^{−1})$ rate",
    "checked": false,
    "id": "efc026ace73425a4f990ad5a521e8653df85d072",
    "semantic_title": "o(t-1 convergence of optimistic-follow-the-regularized-leader in two-player zero-sum markov games",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xnsg4pfKb7": {
    "title": "Bispectral Neural Networks",
    "volume": "poster",
    "abstract": "We present a neural network architecture, Bispectral Neural Networks (BNNs) for learning representations that are invariant to the actions of compact commutative groups on the space over which a signal is defined. The model incorporates the ansatz of the bispectrum, an analytically defined group invariant that is complete -- that is, it preserves all signal structure while removing only the variation due to group actions. Here, we demonstrate that BNNs are able to simultaneously learn groups, their irreducible representations, and corresponding equivariant and complete-invariant maps purely from the symmetries implicit in data. Further, we demonstrate that the completeness property endows these networks with strong invariance-based adversarial robustness. This work establishes Bispectral Neural Networks as a powerful computational primitive for robust invariant representation learning",
    "checked": true,
    "id": "5b7244ead54d1f13ea3eab5342d6e27d82758bba",
    "semantic_title": "bispectral neural networks",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=pOyi9KqE56b": {
    "title": "Beyond Lipschitz: Sharp Generalization and Excess Risk Bounds for Full-Batch GD",
    "volume": "poster",
    "abstract": "We provide sharp path-dependent generalization and excess risk guarantees for the full-batch Gradient Descent (GD) algorithm on smooth losses (possibly non-Lipschitz, possibly nonconvex). At the heart of our analysis is an upper bound on the generalization error, which implies that average output stability and a bounded expected optimization error at termination lead to generalization. This result shows that a small generalization error occurs along the optimization path, and allows us to bypass Lipschitz or sub-Gaussian assumptions on the loss prevalent in previous works. For nonconvex, convex, and strongly convex losses, we show the explicit dependence of the generalization error in terms of the accumulated path-dependent optimization error, terminal optimization error, number of samples, and number of iterations. For nonconvex smooth losses, we prove that full-batch GD efficiently generalizes close to any stationary point at termination, and recovers the generalization error guarantees of stochastic algorithms with fewer assumptions. For smooth convex losses, we show that the generalization error is tighter than existing bounds for SGD (up to one order of error magnitude). Consequently the excess risk matches that of SGD for quadratically less iterations. Lastly, for strongly convex smooth losses, we show that full-batch GD achieves essentially the same excess risk rate as compared with the state of the art on SGD, but with an exponentially smaller number of iterations (logarithmic in the dataset size)",
    "checked": true,
    "id": "f3d4ce6fc9c1acb93846768f6a76c0d54fa9a9fd",
    "semantic_title": "beyond lipschitz: sharp generalization and excess risk bounds for full-batch gd",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=AatUEvC-Wjv": {
    "title": "Hyper-Decision Transformer for Efficient Online Policy Adaptation",
    "volume": "poster",
    "abstract": "Decision Transformers (DT) have demonstrated strong performances in offline reinforcement learning settings, but quickly adapting to unseen novel tasks remains challenging. To address this challenge, we propose a new framework, called Hyper-Decision Transformer (HDT), that can generalize to novel tasks from a handful of demonstrations in a data- and parameter-efficient manner. To achieve such a goal, we propose to augment the base DT with an adaptation module, whose parameters are initialized by a hyper-network. When encountering unseen tasks, the hyper-network takes a handful of demonstrations as inputs and initializes the adaptation module accordingly. This initialization enables HDT to efficiently adapt to novel tasks by only fine-tuning the adaptation module. We validate HDT's generalization capability on object manipulation tasks. We find that with a single expert demonstration and fine-tuning only 0.5% of DT parameters, HDT adapts faster to unseen tasks than fine-tuning the whole DT model. Finally, we explore a more challenging setting where expert actions are not available, and we show that HDT outperforms state-of-the-art baselines in terms of task success rates by a large margin. Demos are available on our project page: https://sites.google.com/view/hdtforiclr2023/home",
    "checked": true,
    "id": "01706dd038b959e92a93f3141bb98be8f1f048f0",
    "semantic_title": "hyper-decision transformer for efficient online policy adaptation",
    "citation_count": 43,
    "authors": []
  },
  "https://openreview.net/forum?id=U5XOGxAgccS": {
    "title": "Solving Continuous Control via Q-learning",
    "volume": "poster",
    "abstract": "While there has been substantial success for solving continuous control with actor-critic methods, simpler critic-only methods such as Q-learning find limited application in the associated high-dimensional action spaces. However, most actor-critic methods come at the cost of added complexity: heuristics for stabilisation, compute requirements and wider hyperparameter search spaces. We show that a simple modification of deep Q-learning largely alleviates these issues. By combining bang-bang action discretization with value decomposition, framing single-agent control as cooperative multi-agent reinforcement learning (MARL), this simple critic-only approach matches performance of state-of-the-art continuous actor-critic methods when learning from features or pixels. We extend classical bandit examples from cooperative MARL to provide intuition for how decoupled critics leverage state information to coordinate joint optimization, and demonstrate surprisingly strong performance across a variety of continuous control tasks",
    "checked": true,
    "id": "dd95d004827a6183146b2f497c9cbbd30803aeed",
    "semantic_title": "solving continuous control via q-learning",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=nJfylDvgzlq": {
    "title": "Make-A-Video: Text-to-Video Generation without Text-Video Data",
    "volume": "poster",
    "abstract": "We propose Make-A-Video -- an approach for directly translating the tremendous recent progress in Text-to-Image (T2I) generation to Text-to-Video (T2V). Our intuition is simple: learn what the world looks like and how it is described from paired text-image data, and learn how the world moves from unsupervised video footage. Make-A-Video has three advantages: (1) it accelerates training of the T2V model (it does not need to learn visual and multimodal representations from scratch), (2) it does not require paired text-video data, and (3) the generated videos inherit the vastness (diversity in aesthetic, fantastical depictions, etc.) of today's image generation models. We design a simple yet effective way to build on T2I models with novel and effective spatial-temporal modules. First, we decompose the full temporal U-Net and attention tensors and approximate them in space and time. Second, we design a spatial temporal pipeline to generate high resolution and frame rate videos with a video decoder, interpolation model and two super resolution models that can enable various applications besides T2V. In all aspects, spatial and temporal resolution, faithfulness to text, and quality, Make-A-Video sets the new state-of-the-art in text-to-video generation, as determined by both qualitative and quantitative measures",
    "checked": true,
    "id": "1e33716e8820b867d5a8aaebab44c2d3135ea4ac",
    "semantic_title": "make-a-video: text-to-video generation without text-video data",
    "citation_count": 1625,
    "authors": []
  },
  "https://openreview.net/forum?id=wGvzQWFyUB": {
    "title": "Personalized Reward Learning with Interaction-Grounded Learning (IGL)",
    "volume": "poster",
    "abstract": "In an era of countless content offerings, recommender systems alleviate information overload by providing users with personalized content suggestions. Due to the scarcity of explicit user feedback, modern recommender systems typically optimize for the same fixed combination of implicit feedback signals across all users. However, this approach disregards a growing body of work highlighting that (i) implicit signals can be used by users in diverse ways, signaling anything from satisfaction to active dislike, and (ii) different users communicate preferences in different ways. We propose applying the recent Interaction Grounded Learning (IGL) paradigm to address the challenge of learning representations of diverse user communication modalities. Rather than requiring a fixed, human-designed reward function, IGL is able to learn personalized reward functions for different users and then optimize directly for the latent user satisfaction. We demonstrate the success of IGL with experiments using simulations as well as with real-world production traces",
    "checked": true,
    "id": "3b4344a2d52ab2ac257b86c4a96bcf60eacaa4e0",
    "semantic_title": "personalized reward learning with interaction-grounded learning (igl)",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=4BPFwvKOvo5": {
    "title": "Towards convergence to Nash equilibria in two-team zero-sum games",
    "volume": "poster",
    "abstract": "Contemporary applications of machine learning raise important and overlooked theoretical questions regarding optimization in two-team games. Formally, two-team zero-sum games are defined as multi-player games where players are split into two competing sets of agents, each experiencing a utility identical to that of their teammates and opposite to that of the opposing team. We focus on the solution concept of Nash equilibria and prove $\\textrm{CLS}$-hardness of computing them in this class of games. To further examine the capabilities of online learning algorithms in games with full-information feedback, we propose a benchmark of a simple ---yet nontrivial--- family of such games. These games do not enjoy the properties used to prove convergence for relevant algorithms. In particular, we use a dynamical systems perspective to demonstrate that gradient descent-ascent, its optimistic variant, optimistic multiplicative weights update, and extra gradient fail to converge (even locally) to a Nash equilibrium. On a brighter note, we propose a first-order method that leverages control theory techniques and under some conditions enjoys last-iterate local convergence to a Nash equilibrium. We also believe our proposed method is of independent interest for general min-max optimization",
    "checked": true,
    "id": "4bf419ef1b7414aca02d42b4840026ced70be99e",
    "semantic_title": "towards convergence to nash equilibria in two-team zero-sum games",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=mFDU0fP3EQH": {
    "title": "Discovering Evolution Strategies via Meta-Black-Box Optimization",
    "volume": "poster",
    "abstract": "Optimizing functions without access to gradients is the remit of black-box meth- ods such as evolution strategies. While highly general, their learning dynamics are often times heuristic and inflexible — exactly the limitations that meta-learning can address. Hence, we propose to discover effective update rules for evolution strategies via meta-learning. Concretely, our approach employs a search strategy parametrized by a self-attention-based architecture, which guarantees the update rule is invariant to the ordering of the candidate solutions. We show that meta-evolving this system on a small set of representative low-dimensional analytic optimization problems is sufficient to discover new evolution strategies capable of generalizing to unseen optimization problems, population sizes and optimization horizons. Furthermore, the same learned evolution strategy can outperform established neuroevolution baselines on supervised and continuous control tasks. As additional contributions, we ablate the individual neural network components of our method; reverse engineer the learned strategy into an explicit heuristic form, which remains highly competitive; and show that it is possible to self-referentially train an evolution strategy from scratch, with the learned update rule used to drive the outer meta-learning loop",
    "checked": true,
    "id": "dae69e513a0a5c4f10c11bb56e4e3fddedff714e",
    "semantic_title": "discovering evolution strategies via meta-black-box optimization",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=p7hvOJ6Gq0i": {
    "title": "DensePure: Understanding Diffusion Models for Adversarial Robustness",
    "volume": "poster",
    "abstract": "Diffusion models have been recently employed to improve certified robustness through the process of denoising. However, the theoretical understanding of why diffusion models are able to improve the certified robustness is still lacking, preventing from further improvement. In this study, we close this gap by analyzing the fundamental properties of diffusion models and establishing the conditions under which they can enhance certified robustness. This deeper understanding allows us to propose a new method DensePure, designed to improve the certified robustness of a pretrained model (i.e. classifier). Given an (adversarial) input, DensePure consists of multiple runs of denoising via the reverse process of the diffusion model (with different random seeds) to get multiple reversed samples, which are then passed through the classifier, followed by majority voting of inferred labels to make the final prediction. This design of using multiple runs of denoising is informed by our theoretical analysis of the conditional distribution of the reversed sample. Specifically, when the data density of a clean sample is high, its conditional density under the reverse process in a diffusion model is also high; thus sampling from the latter conditional distribution can purify the adversarial example and return the corresponding clean sample with a high probability. By using the highest density point in the conditional distribution as the reversed sample, we identify the robust region of a given instance under the diffusion model's reverse process. We show that this robust region is a union of multiple convex sets, and is potentially much larger than the robust regions identified in previous works. In practice, DensePure can approximate the label of the high density region in the conditional distribution so that it can enhance certified robustness. We conduct extensive experiments to demonstrate the effectiveness of DensePure by evaluating its certified robustness given a standard model via randomized smoothing. We show that DensePure is consistently better than existing methods on ImageNet, with 7% improvement on average",
    "checked": true,
    "id": "11417522f57c13898e24d87ef22f9e45fa197cf8",
    "semantic_title": "densepure: understanding diffusion models for adversarial robustness",
    "citation_count": 39,
    "authors": []
  },
  "https://openreview.net/forum?id=jsZsEd8VEY": {
    "title": "Grounding Graph Network Simulators using Physical Sensor Observations",
    "volume": "poster",
    "abstract": "Physical simulations that accurately model reality are crucial for many engineering disciplines such as mechanical engineering and robotic motion planning. In recent years, learned Graph Network Simulators produced accurate mesh-based simulations while requiring only a fraction of the computational cost of traditional simulators. Yet, the resulting predictors are confined to learning from data generated by existing mesh-based simulators and thus cannot include real world sensory information such as point cloud data. As these predictors have to simulate complex physical systems from only an initial state, they exhibit a high error accumulation for long-term predictions. In this work, we integrate sensory information to ground Graph Network Simulators on real world observations. In particular, we predict the mesh state of deformable objects by utilizing point cloud data. The resulting model allows for accurate predictions over longer time horizons, even under uncertainties in the simulation, such as unknown material properties. Since point clouds are usually not available for every time step, especially in online settings, we employ an imputation-based model. The model can make use of such additional information only when provided, and resorts to a standard Graph Network Simulator, otherwise. We experimentally validate our approach on a suite of prediction tasks for mesh-based interactions between soft and rigid bodies. Our method results in utilization of additional point cloud information to accurately predict stable simulations where existing Graph Network Simulators fail",
    "checked": true,
    "id": "5f4636895da543ef0fdbeb04661a2d9b7f5ec2e8",
    "semantic_title": "grounding graph network simulators using physical sensor observations",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=osei3IzUia": {
    "title": "Where to Diffuse, How to Diffuse, and How to Get Back: Automated Learning for Multivariate Diffusions",
    "volume": "poster",
    "abstract": "Diffusion-based generative models (DBGMs) perturb data to a target noise distribution and reverse this process to generate samples. The choice of noising process, or inference diffusion process, affects both likelihoods and sample quality. For example, extending the inference process with auxiliary variables leads to improved sample quality. While there are many such multivariate diffusions to explore, each new one requires significant model-specific analysis, hindering rapid prototyping and evaluation. In this work, we study Multivariate Diffusion Models (MDMs). For any number of auxiliary variables, we provide a recipe for maximizing a lower-bound on the MDMs likelihood without requiring any model-specific analysis. We then demonstrate how to parameterize the diffusion for a specified target noise distribution; these two points together enable optimizing the inference diffusion process. Optimizing the diffusion expands easy experimentation from just a few well-known processes to an automatic search over all linear diffusions. To demonstrate these ideas, we introduce two new specific diffusions as well as learn a diffusion process on the MNIST, CIFAR10, and ImageNet32 datasets. We show learned MDMs match or surpass bits-per-dims (BPDs) relative to fixed choices of diffusions for a given dataset and model architecture",
    "checked": true,
    "id": "ffd9130570439d67a97cf3f6c19786db781ae231",
    "semantic_title": "where to diffuse, how to diffuse, and how to get back: automated learning for multivariate diffusions",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=eWKfMBL5to": {
    "title": "Contrastive Corpus Attribution for Explaining Representations",
    "volume": "poster",
    "abstract": "Despite the widespread use of unsupervised models, very few methods are designed to explain them. Most explanation methods explain a scalar model output. However, unsupervised models output representation vectors, the elements of which are not good candidates to explain because they lack semantic meaning. To bridge this gap, recent works defined a scalar explanation output: a dot product-based similarity in the representation space to the sample being explained (i.e., an explicand). Although this enabled explanations of unsupervised models, the interpretation of this approach can still be opaque because similarity to the explicand's representation may not be meaningful to humans. To address this, we propose contrastive corpus similarity, a novel and semantically meaningful scalar explanation output based on a reference corpus and a contrasting foil set of samples. We demonstrate that contrastive corpus similarity is compatible with many post-hoc feature attribution methods to generate COntrastive COrpus Attributions (COCOA) and quantitatively verify that features important to the corpus are identified. We showcase the utility of COCOA in two ways: (i) we draw insights by explaining augmentations of the same image in a contrastive learning setting (SimCLR); and (ii) we perform zero-shot object localization by explaining the similarity of image representations to jointly learned text representations (CLIP)",
    "checked": true,
    "id": "560f10749054035a4645b2732fb4404061e6eb9f",
    "semantic_title": "contrastive corpus attribution for explaining representations",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=PsIk0kO3hKd": {
    "title": "Spatio-temporal point processes with deep non-stationary kernels",
    "volume": "poster",
    "abstract": "Point process data are becoming ubiquitous in modern applications, such as social networks, health care, and finance. Despite the powerful expressiveness of the popular recurrent neural network (RNN) models for point process data, they may not successfully capture sophisticated non-stationary dependencies in the data due to their recurrent structures. Another popular type of deep model for point process data is based on representing the influence kernel (rather than the intensity function) by neural networks. We take the latter approach and develop a new deep non-stationary influence kernel that can model non-stationary spatio-temporal point processes. The main idea is to approximate the influence kernel with a novel and general low-rank decomposition, enabling efficient representation through deep neural networks and computational efficiency and better performance. We also take a new approach to maintain the non-negativity constraint of the conditional intensity by introducing a log-barrier penalty. We demonstrate our proposed method's good performance and computational efficiency compared with the state-of-the-art on simulated and real data",
    "checked": true,
    "id": "da8a2be8914712a04ba8562b65215c30a198ac6c",
    "semantic_title": "spatio-temporal point processes with deep non-stationary kernels",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=hDDV1lsRV8": {
    "title": "Federated Learning from Small Datasets",
    "volume": "poster",
    "abstract": "Federated learning allows multiple parties to collaboratively train a joint model without having to share any local data. It enables applications of machine learning in settings where data is inherently distributed and undisclosable, such as in the medical domain. Joint training is usually achieved by aggregating local models. When local datasets are small, locally trained models can vary greatly from a globally good model. Bad local models can arbitrarily deteriorate the aggregate model quality, causing federating learning to fail in these settings. We propose a novel approach that avoids this problem by interleaving model aggregation and permutation steps. During a permutation step we redistribute local models across clients through the server, while preserving data privacy, to allow each local model to train on a daisy chain of local datasets. This enables successful training in data-sparse domains. Combined with model aggregation, this approach enables effective learning even if the local datasets are extremely small, while retaining the privacy benefits of federated learning",
    "checked": true,
    "id": "8d20e3f4f11e757d99259e3bd1b2dfc4366d15f1",
    "semantic_title": "federated learning from small datasets",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=lGz9u1ubUXE": {
    "title": "Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences",
    "volume": "poster",
    "abstract": "Generating complex behaviors that satisfy the preferences of non-expert users is a crucial requirement for AI agents. Interactive reward learning from trajectory comparisons (a.k.a. RLHF) is one way to allow non-expert users to convey complex objectives by expressing preferences over short clips of agent behaviors. Even though this parametric method can encode complex tacit knowledge present in the underlying tasks, it implicitly assumes that the human is unable to provide richer feedback than binary preference labels, leading to intolerably high feedback complexity and poor user experience. While providing a detailed symbolic closed-form specification of the objectives might be tempting, it is not always feasible even for an expert user. However, in most cases, humans are aware of how the agent should change its behavior along meaningful axes to fulfill their underlying purpose, even if they are not able to fully specify task objectives symbolically. Using this as motivation, we introduce the notion of Relative Behavioral Attributes, which allows the users to tweak the agent behavior through symbolic concepts (e.g., increasing the softness or speed of agents' movement). We propose two practical methods that can learn to model any kind of behavioral attributes from ordered behavior clips. We demonstrate the effectiveness of our methods on four tasks with nine different behavioral attributes, showing that once the attributes are learned, end users can produce desirable agent behaviors relatively effortlessly, by providing feedback just around ten times. This is over an order of magnitude less than that required by the popular learning-from-human-preferences baselines. The supplementary video and source code are available at: https://guansuns.github.io/pages/rba",
    "checked": true,
    "id": "8e2daf1f06d2d75bff9519c86382bf50fff6ae0f",
    "semantic_title": "relative behavioral attributes: filling the gap between symbolic goal specification and reward learning from human preferences",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=GRZtigJljLY": {
    "title": "Scalable Batch-Mode Deep Bayesian Active Learning via Equivalence Class Annealing",
    "volume": "poster",
    "abstract": "Active learning has demonstrated data efficiency in many fields. Existing active learning algorithms, especially in the context of batch-mode deep Bayesian active models, rely heavily on the quality of uncertainty estimations of the model, and are often challenging to scale to large batches. In this paper, we propose Batch-BALanCe, a scalable batch-mode active learning algorithm, which combines insights from decision-theoretic active learning, combinatorial information measure, and diversity sampling. At its core, Batch-BALanCe relies on a novel decision-theoretic acquisition function that facilitates differentiation among different equivalence classes. Intuitively, each equivalence class consists of hypotheses (e.g., posterior samples of deep neural networks) with similar predictions, and Batch-BALanCe adaptively adjusts the size of the equivalence classes as learning progresses. To scale up the computation of queries to large batches, we further propose an efficient batch-mode acquisition procedure, which aims to maximize a novel combinatorial information measure defined through the acquisition function. We show that our algorithm can effectively handle realistic multi-class classification tasks, and achieves compelling performance on several benchmark datasets for active learning under both low- and large-batch regimes",
    "checked": true,
    "id": "1c1047e1021285cbdb8edb8a404c51d9d748f94b",
    "semantic_title": "scalable batch-mode deep bayesian active learning via equivalence class annealing",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=FE99-fDrWd5": {
    "title": "Semi-Parametric Inducing Point Networks and Neural Processes",
    "volume": "poster",
    "abstract": "We introduce semi-parametric inducing point networks (SPIN), a general-purpose architecture that can query the training set at inference time in a compute-efficient manner. Semi-parametric architectures are typically more compact than parametric models, but their computational complexity is often quadratic. In contrast, SPIN attains linear complexity via a cross-attention mechanism between datapoints inspired by inducing point methods. Querying large training sets can be particularly useful in meta-learning, as it unlocks additional training signal, but often exceeds the scaling limits of existing models. We use SPIN as the basis of the Inducing Point Neural Process, a probabilistic model which supports large contexts in meta-learning and achieves high accuracy where existing models fail. In our experiments, SPIN reduces memory requirements, improves accuracy across a range of meta-learning tasks, and improves state-of-the-art performance on an important practical problem, genotype imputation",
    "checked": true,
    "id": "744e68099831f743aec5e0224a79fec784a61ff1",
    "semantic_title": "semi-parametric inducing point networks and neural processes",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=m9LCdYgN8-6": {
    "title": "DAG Learning on the Permutahedron",
    "volume": "poster",
    "abstract": "We propose a continuous optimization framework for discovering a latent directed acyclic graph (DAG) from observational data. Our approach optimizes over the polytope of permutation vectors, the so-called Permutahedron, to learn a topological ordering. Edges can be optimized jointly, or learned conditional on the ordering via a non-differentiable subroutine. Compared to existing continuous optimization approaches our formulation has a number of advantages including: 1. validity: optimizes over exact DAGs as opposed to other relaxations optimizing approximate DAGs; 2. modularity: accommodates any edge-optimization procedure, edge structural parameterization, and optimization loss; 3. end-to-end: either alternately iterates between node-ordering and edge-optimization, or optimizes them jointly; We demonstrate, on real-world data problems in protein-signaling and transcriptional network discovery, that our approach lies on the Pareto frontier of two key metrics, the SID and SHD",
    "checked": true,
    "id": "354180d79bac0380188089066de79cfea36b5bfc",
    "semantic_title": "dag learning on the permutahedron",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=9krnQ-ue9M": {
    "title": "Explicitly Minimizing the Blur Error of Variational Autoencoders",
    "volume": "poster",
    "abstract": "Variational autoencoders (VAEs) are powerful generative modelling methods, however they suffer from blurry generated samples and reconstructions compared to the images they have been trained on. Significant research effort has been spent to increase the generative capabilities by creating more flexible models but often flexibility comes at the cost of higher complexity and computational cost. Several works have focused on altering the reconstruction term of the evidence lower bound (ELBO), however, often at the expense of losing the mathematical link to maximizing the likelihood of the samples under the modeled distribution. Here we propose a new formulation of the reconstruction term for the VAE that specifically penalizes the generation of blurry images while at the same time still maximizing the ELBO under the modeled distribution. We show the potential of the proposed loss on three different data sets, where it outperforms several recently proposed reconstruction losses for VAEs",
    "checked": true,
    "id": "c426a0456c4bbd3cb1d5526f7654e9341e1cf91b",
    "semantic_title": "explicitly minimizing the blur error of variational autoencoders",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=kJqXEPXMsE0": {
    "title": "3D Equivariant Diffusion for Target-Aware Molecule Generation and Affinity Prediction",
    "volume": "poster",
    "abstract": "Rich data and powerful machine learning models allow us to design drugs for a specific protein target <em>in silico</em>. Recently, the inclusion of 3D structures during targeted drug design shows superior performance to other target-free models as the atomic interaction in the 3D space is explicitly modeled. However, current 3D target-aware models either rely on the voxelized atom densities or the autoregressive sampling process, which are not equivariant to rotation or easily violate geometric constraints resulting in unrealistic structures. In this work, we develop a 3D equivariant diffusion model to solve the above challenges. To achieve target-aware molecule design, our method learns a joint generative process of both continuous atom coordinates and categorical atom types with a SE(3)-equivariant network. Moreover, we show that our model can serve as an unsupervised feature extractor to estimate the binding affinity under proper parameterization, which provides an effective way for drug screening. To evaluate our model, we propose a comprehensive framework to evaluate the quality of sampled molecules from different dimensions. Empirical studies show our model could generate molecules with more realistic 3D structures and better affinities towards the protein targets, and improve binding affinity ranking and prediction without retraining",
    "checked": true,
    "id": "59713b444d3268528416f23fe860ba63bb03fc04",
    "semantic_title": "3d equivariant diffusion for target-aware molecule generation and affinity prediction",
    "citation_count": 202,
    "authors": []
  },
  "https://openreview.net/forum?id=EBC60mxBwyw": {
    "title": "How gradient estimator variance and bias impact learning in neural networks",
    "volume": "poster",
    "abstract": "There is growing interest in understanding how real brains may approximate gradients and how gradients can be used to train neuromorphic chips. However, neither real brains nor neuromorphic chips can perfectly follow the loss gradient, so parameter updates would necessarily use gradient estimators that have some variance and/or bias. Therefore, there is a need to understand better how variance and bias in gradient estimators impact learning dependent on network and task properties. Here, we show that variance and bias can impair learning on the training data, but some degree of variance and bias in a gradient estimator can be beneficial for generalization. We find that the ideal amount of variance and bias in a gradient estimator are dependent on several properties of the network and task: the size and activity sparsity of the network, the norm of the gradient, and the curvature of the loss landscape. As such, whether considering biologically-plausible learning algorithms or algorithms for training neuromorphic chips, researchers can analyze these properties to determine whether their approximation to gradient descent will be effective for learning given their network and task properties",
    "checked": true,
    "id": "1d62dcb3a27bf9c8b46e7cefe2d5e46d2bac914d",
    "semantic_title": "how gradient estimator variance and bias impact learning in neural networks",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=Fsd-6ax4T1m": {
    "title": "Evaluating Representations with Readout Model Switching",
    "volume": "poster",
    "abstract": "Although much of the success of Deep Learning builds on learning good representations, a rigorous method to evaluate their quality is lacking. In this paper, we treat the evaluation of representations as a model selection problem and propose to use the Minimum Description Length (MDL) principle to devise an evaluation metric. Contrary to the established practice of limiting the capacity of the readout model, we design a hybrid discrete and continuous-valued model space for the readout models and employ a switching strategy to combine their predictions. The MDL score takes model complexity, as well as data efficiency into account. As a result, the most appropriate model for the specific task and representation will be chosen, making it a unified measure for comparison. The proposed metric can be efficiently computed with an online method and we present results for pre-trained vision encoders of various architectures (ResNet and ViT) and objective functions (supervised and self-supervised) on a range of downstream tasks. We compare our methods with accuracy-based approaches and show that the latter are inconsistent when multiple readout models are used. Finally, we discuss important properties revealed by our evaluations such as model scaling, preferred readout model, and data efficiency",
    "checked": true,
    "id": "d027c144ac230146d61772b6371c63a614ea9852",
    "semantic_title": "evaluating representations with readout model switching",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kPPVmUF6bM_": {
    "title": "Augmentation with Projection: Towards an Effective and Efficient Data Augmentation Paradigm for Distillation",
    "volume": "poster",
    "abstract": "Knowledge distillation is one of the primary methods of transferring knowledge from large to small models. However, it requires massive task-specific data, which may not be plausible in many real-world applications. Data augmentation methods such as representation interpolation, token replacement, or augmentation with models are applied to tackle this problem. However, these data augmentation methods either potentially cause shifts in decision boundaries (representation interpolation), are not expressive enough (token replacement), or introduce too much computational overhead (augmentation with models). To this end, we propose AugPro (Augmentation with Projection), an effective and efficient data augmentation method for distillation. Our method builds on top of representation interpolation augmentation methods to maintain the diversity of expressions and converts the augmented data to tokens to avoid shifting decision boundaries. It uses simple operations that come with little computational overhead. The results on multiple GLUE tasks show that our methods can improve distillation performance by a large margin at a low time cost",
    "checked": true,
    "id": "d829ca8ec95550b291339d8fd1d4ede8581e6896",
    "semantic_title": "augmentation with projection: towards an effective and efficient data augmentation paradigm for distillation",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=9_gsMA8MRKQ": {
    "title": "Pseudoinverse-Guided Diffusion Models for Inverse Problems",
    "volume": "poster",
    "abstract": "Diffusion models have become competitive candidates for solving various inverse problems. Models trained for specific inverse problems work well but are limited to their particular use cases, whereas methods that use problem-agnostic models are general but often perform worse empirically. To address this dilemma, we introduce Pseudoinverse-guided Diffusion Models ($\\Pi$GDM), an approach that uses problem-agnostic models to close the gap in performance. $\\Pi$GDM directly estimates conditional scores from the measurement model of the inverse problem without additional training. It can address inverse problems with noisy, non-linear, or even non-differentiable measurements, in contrast to many existing approaches that are limited to noiseless linear ones. We illustrate the empirical effectiveness of $\\Pi$GDM on several image restoration tasks, including super-resolution, inpainting and JPEG restoration. On ImageNet, $\\Pi$GDM is competitive with state-of-the-art diffusion models trained on specific tasks, and is the first to achieve this with problem-agnostic diffusion models. $\\Pi$GDM can also solve a wider set of inverse problems where the measurement processes are composed of several simpler ones",
    "checked": true,
    "id": "9c81be0c478bfc0a48eedb8769326fe289a11acc",
    "semantic_title": "pseudoinverse-guided diffusion models for inverse problems",
    "citation_count": 389,
    "authors": []
  },
  "https://openreview.net/forum?id=cVFD6qE8gnY": {
    "title": "Planning with Sequence Models through Iterative Energy Minimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "290e7e50c0c945485ab711fec7bc753d41a47491",
    "semantic_title": "planning with sequence models through iterative energy minimization",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=Rvee9CAX4fi": {
    "title": "Verifying the Union of Manifolds Hypothesis for Image Data",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "04abbf01d30993361c0e15f252046140c6fa5a76",
    "semantic_title": "verifying the union of manifolds hypothesis for image data",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=zlbci7019Z3": {
    "title": "Error Sensitivity Modulation based Experience Replay: Mitigating Abrupt Representation Drift in Continual Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5ffca4f594ea2cf774779bda12fff38b64fe38ab",
    "semantic_title": "error sensitivity modulation based experience replay: mitigating abrupt representation drift in continual learning",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=39z0zPZ0AvB": {
    "title": "Don't forget the nullspace! Nullspace occupancy as a mechanism for out of distribution failure",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "713a9d2fe1ce824a841df2ed5d0b090b5def27e9",
    "semantic_title": "don't forget the nullspace! nullspace occupancy as a mechanism for out of distribution failure",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=SM7XkJouWHm": {
    "title": "ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "519193aa26820af205e6040d4595ca30ebcebcb0",
    "semantic_title": "contranorm: a contrastive learning perspective on oversmoothing and beyond",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=HRwN7IQLUKA": {
    "title": "Accelerated Single-Call Methods for Constrained Min-Max Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8e0db841036cf9121f2b3c7ec23db79b498b6545",
    "semantic_title": "accelerated single-call methods for constrained min-max optimization",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=b3itJyarLM0": {
    "title": "Distributed Extra-gradient with Optimal Complexity and Communication Guarantees",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f58290a33ab20802d677c7b7c0cb006ff4892087",
    "semantic_title": "distributed extra-gradient with optimal complexity and communication guarantees",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=20gBzEzgtiI": {
    "title": "Performance Bounds for Model and Policy Transfer in Hidden-parameter MDPs",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "003b229489d88890674f0c6bffa41fed8df93cec",
    "semantic_title": "performance bounds for model and policy transfer in hidden-parameter mdps",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=DrtSx1z40Ib": {
    "title": "Composing Task Knowledge With Modular Successor Feature Approximators",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b3cf06fd1ab90ad218df49d69f0a033d5bc0af0f",
    "semantic_title": "composing task knowledge with modular successor feature approximators",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=LIV7-_7pYPl": {
    "title": "DexDeform: Dexterous Deformable Object Manipulation with Human Demonstrations and Differentiable Physics",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "26063b5f5efa71e1c3b726f6f8c792368ba43ce4",
    "semantic_title": "dexdeform: dexterous deformable object manipulation with human demonstrations and differentiable physics",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=QsCSLPP55Ku": {
    "title": "Effective passive membership inference attacks in federated learning against overparameterized models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "94809c93b3ce812cef198e82f7f855b2dd070cee",
    "semantic_title": "effective passive membership inference attacks in federated learning against overparameterized models",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=9EAQVEINuum": {
    "title": "Optimizing Bi-Encoder for Named Entity Recognition via Contrastive Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6e59edb734194abef65a0404e425dbd823a4f07f",
    "semantic_title": "optimizing bi-encoder for named entity recognition via contrastive learning",
    "citation_count": 56,
    "authors": []
  },
  "https://openreview.net/forum?id=p_jIy5QFB7": {
    "title": "Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for Deep Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "80dcf1b8b678cb17b3ac945c8c0838724a9ab3c9",
    "semantic_title": "taking a step back with kcal: multi-class kernel-based calibration for deep neural networks",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=TAVBJ4aHsWt": {
    "title": "SemPPL: Predicting Pseudo-Labels for Better Contrastive Representations",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2d1c3c76c666ba5af782f125d1c26ac961ee4879",
    "semantic_title": "semppl: predicting pseudo-labels for better contrastive representations",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=j1zQGmQQOX1": {
    "title": "Differentially Private Adaptive Optimization with Delayed Preconditioners",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "201146e9b26eb4a16a26808128765ba1c906ca48",
    "semantic_title": "differentially private adaptive optimization with delayed preconditioners",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=vOEXS39nOF": {
    "title": "Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "aa509ec67f311cd09d109356f7fa37a40072aabb",
    "semantic_title": "phenaki: variable length video generation from open domain textual description",
    "citation_count": 445,
    "authors": []
  },
  "https://openreview.net/forum?id=5MkYIYCbva": {
    "title": "Long Range Language Modeling via Gated State Spaces",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "eaef083b9d661f42cc0d89d9d8156218f33a91d9",
    "semantic_title": "long range language modeling via gated state spaces",
    "citation_count": 282,
    "authors": []
  },
  "https://openreview.net/forum?id=_geIwiOyUhZ": {
    "title": "Bayes-MIL: A New Probabilistic Perspective on Attention-based Multiple Instance Learning for Whole Slide Images",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "684f37d241e8f6c08dfc35e24b9f143c32e7c995",
    "semantic_title": "bayes-mil: a new probabilistic perspective on attention-based multiple instance learning for whole slide images",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=sSt9fROSZRO": {
    "title": "Investigating Multi-task Pretraining and Generalization in Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9a21003ba1334e2fa7fc48178f37e02027e91936",
    "semantic_title": "investigating multi-task pretraining and generalization in reinforcement learning",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=PDG4-Y3aboN": {
    "title": "FIT: A Metric for Model Sensitivity",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8f2c17145ccfb36761c0df28c33200ff9fbb57cf",
    "semantic_title": "fit: a metric for model sensitivity",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=b0RuGUYo8pA": {
    "title": "Transfer Learning with Deep Tabular Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "96e22af70f9ca575ebfe648677aced03c6c8803d",
    "semantic_title": "transfer learning with deep tabular models",
    "citation_count": 67,
    "authors": []
  },
  "https://openreview.net/forum?id=_eTZBs-yedr": {
    "title": "CrAM: A Compression-Aware Minimizer",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1e5c62492b2fd7d7dc428d5d6a44c694d281b395",
    "semantic_title": "cram: a compression-aware minimizer",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=JVlyfHEEm0k": {
    "title": "Understanding Train-Validation Split in Meta-Learning with Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f1ed2af14839fdb7a83983442f3f20ab4816d159",
    "semantic_title": "understanding train-validation split in meta-learning with neural networks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=h1o7Ry9Zctm": {
    "title": "Revisiting Robustness in Graph Machine Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6584f26629877392b0a34b7db448f7d9d7a4fda7",
    "semantic_title": "revisiting robustness in graph machine learning",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=77lSWa-Tm3Z": {
    "title": "Variational Information Pursuit for Interpretable Predictions",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "13fba50e2c707b30e17defd93c040e837c29921e",
    "semantic_title": "variational information pursuit for interpretable predictions",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=T5nUQDrM4u": {
    "title": "Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "397e0e0d20f00d8fbfecd2fd36b14f13e2181d0e",
    "semantic_title": "sparse upcycling: training mixture-of-experts from dense checkpoints",
    "citation_count": 145,
    "authors": []
  },
  "https://openreview.net/forum?id=5IND3TXJRb-": {
    "title": "Lossless Adaptation of Pretrained Vision Models For Robotic Manipulation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "016315a3df05cb07a6f67fa5f6a3265b55909644",
    "semantic_title": "lossless adaptation of pretrained vision models for robotic manipulation",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=SoyOsp7i_l": {
    "title": "Logical Message Passing Networks with One-hop Inference on Atomic Formulas",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e7139f6831f32bff95c1a9cfc9b10ec4f24ce36b",
    "semantic_title": "logical message passing networks with one-hop inference on atomic formulas",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=bAz2DBS35i": {
    "title": "Noise-Robust De-Duplication at Scale",
    "volume": "poster",
    "abstract": "Identifying near duplicates within large, noisy text corpora has a myriad of applications that range from de-duplicating training datasets, reducing privacy risk, and evaluating test set leakage, to identifying reproduced news articles and literature within large corpora. Across these diverse applications, the overwhelming majority of work relies on $N$-grams. Limited efforts have been made to evaluate how well $N$-gram methods perform, in part because it is unclear how one could create an unbiased evaluation dataset for a massive corpus. This study uses the unique timeliness of historical news wires to create a 27,210 document dataset, with 122,876 positive duplicate pairs, for studying noise-robust de-duplication. The time-sensitivity of news makes comprehensive hand labelling feasible - despite the massive overall size of the corpus - as duplicates occur within a narrow date range. The study then develops and evaluates a range of de-duplication methods: hashing and $N$-gram overlap (which predominate in the literature), a contrastively trained bi-encoder, and a ``re-rank'' style approach combining a bi- and cross-encoder. The neural approaches significantly outperform hashing and $N$-gram overlap. We show that the bi-encoder scales well, de-duplicating a 10 million article corpus on a single GPU card in a matter of hours. We also apply our pre-trained model to the RealNews and patent portions of C4 (Colossal Clean Crawled Corpus), illustrating that a neural approach can identify many near duplicates missed by hashing, in the presence of various types of noise. The public release of our NEWS-COPY de-duplication dataset, codebase, and the pre-trained models will facilitate further research and applications",
    "checked": true,
    "id": "7ca41cc5fc364b713aba5b573ae4ada801fd788a",
    "semantic_title": "noise-robust de-duplication at scale",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=a70lGJ-rwy": {
    "title": "Few-shot Backdoor Attacks via Neural Tangent Kernels",
    "volume": "poster",
    "abstract": "In a backdoor attack, an attacker injects corrupted examples into the training set. The goal of the attacker is to cause the final trained model to predict the attacker's desired target label when a predefined trigger is added to test inputs. Central to these attacks is the trade-off between the success rate of the attack and the number of corrupted training examples injected. We pose this attack as a novel bilevel optimization problem: construct strong poison examples that maximize the attack success rate of the trained model. We use neural tangent kernels to approximate the training dynamics of the model being attacked and automatically learn strong poison examples. We experiment on subclasses of CIFAR-10 and ImageNet with WideResNet-34 and ConvNeXt architectures on periodic and patch trigger attacks and show that NTBA-designed poisoned examples achieve, for example, an attack success rate of 90% with ten times smaller number of poison examples injected compared to the baseline. We provided an interpretation of the NTBA-designed attacks using the analysis of kernel linear regression. We further demonstrate a vulnerability in overparametrized deep neural networks, which is revealed by the shape of the neural tangent kernel",
    "checked": true,
    "id": "bc8d5957446b53f7798c209fb7ac6cfd45289bdf",
    "semantic_title": "few-shot backdoor attacks via neural tangent kernels",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=nAgdXgfmqj": {
    "title": "Hyperparameter Optimization through Neural Network Partitioning",
    "volume": "poster",
    "abstract": "Well-tuned hyperparameters are crucial for obtaining good generalization behavior in neural networks. They can enforce appropriate inductive biases, regularize the model and improve performance --- especially in the presence of limited data. In this work, we propose a simple and efficient way for optimizing hyperparameters inspired by the marginal likelihood, an optimization objective that requires no validation data. Our method partitions the training data and a neural network model into $K$ data shards and parameter partitions, respectively. Each partition is associated with and optimized only on specific data shards. Combining these partitions into subnetworks allows us to define the \"out-of-training-sample\" loss of a subnetwork, i.e., the loss on data shards unseen by the subnetwork, as the objective for hyperparameter optimization. We demonstrate that we can apply this objective to optimize a variety of different hyperparameters in a single training run while being significantly computationally cheaper than alternative methods aiming to optimize the marginal likelihood for neural networks. Lastly, we also focus on optimizing hyperparameters in federated learning, where retraining and cross-validation are particularly challenging",
    "checked": true,
    "id": "47975c425e03911ad2ac9e618bd9ae1b23e4c852",
    "semantic_title": "hyperparameter optimization through neural network partitioning",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=9ZpciCOunFb": {
    "title": "Symmetries, Flat Minima, and the Conserved Quantities of Gradient Flow",
    "volume": "poster",
    "abstract": "Empirical studies of the loss landscape of deep networks have revealed that many local minima are connected through low-loss valleys. Yet, little is known about the theoretical origin of such valleys. We present a general framework for finding continuous symmetries in the parameter space, which carve out low-loss valleys. Our framework uses equivariances of the activation functions and can be applied to different layer architectures. To generalize this framework to nonlinear neural networks, we introduce a novel set of nonlinear, data-dependent symmetries. These symmetries can transform a trained model such that it performs similarly on new samples, which allows ensemble building that improves robustness under certain adversarial attacks. We then show that conserved quantities associated with linear symmetries can be used to define coordinates along low-loss valleys. The conserved quantities help reveal that using common initialization methods, gradient flow only explores a small part of the global minimum. By relating conserved quantities to convergence rate and sharpness of the minimum, we provide insights on how initialization impacts convergence and generalizability",
    "checked": true,
    "id": "d61999e6f9ecbca226f28649f2827ac437460ee6",
    "semantic_title": "symmetries, flat minima, and the conserved quantities of gradient flow",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=ooxDOe7ZtBe": {
    "title": "Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees",
    "volume": "poster",
    "abstract": "Current abstractive summarization models either suffer from a lack of clear interpretability or provide incomplete rationales by only highlighting parts of the source document. To this end, we propose the Summarization Program (SP), an interpretable modular framework consisting of an (ordered) list of binary trees, each encoding the step-by-step generative process of an abstractive summary sentence from the source document. A Summarization Program contains one root node per summary sentence, and a distinct tree connects each summary sentence (root node) to the document sentences (leaf nodes) from which it is derived, with the connecting nodes containing intermediate generated sentences. Edges represent different modular operations involved in summarization such as sentence fusion, compression, and paraphrasing. We first propose an efficient best-first search method over neural modules, SP-Search that identifies SPs for human summaries by directly optimizing for ROUGE scores. Next, using these programs as automatic supervision, we propose seq2seq models that generate Summarization Programs, which are then executed to obtain final summaries. We demonstrate that SP-Search effectively represents the generative process behind human summaries using modules that are typically faithful to their intended behavior. We also conduct a simulation study to show that Summarization Programs improve the interpretability of summarization models by allowing humans to better simulate model reasoning. Summarization Programs constitute a promising step toward interpretable and modular abstractive summarization, a complex task previously addressed primarily through blackbox end-to-end neural systems",
    "checked": true,
    "id": "a328907b45724b61aafbad746d490f00fe0fd761",
    "semantic_title": "summarization programs: interpretable abstractive summarization with neural modular trees",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=Lr8cOOtYbfL": {
    "title": "Planning with Large Language Models for Code Generation",
    "volume": "poster",
    "abstract": "Existing large language model-based code generation pipelines typically use beam search or sampling algorithms during the decoding process. Although the programs they generate achieve high token-matching-based scores, they often fail to compile or generate incorrect outputs. The main reason is that conventional Transformer decoding algorithms may not be the best choice for code generation. In this work, we propose a novel Transformer decoding algorithm, Planning-Guided Transformer Decoding (PG-TD), that uses a planning algorithm to do lookahead search and guide the Transformer to generate better programs. Specifically, instead of simply optimizing the likelihood of the generated sequences, the Transformer makes use of a planner that generates candidate programs and tests them on public test cases. The Transformer can therefore make more informed decisions and generate tokens that will eventually lead to higher-quality programs. We also design a mechanism that shares information between the Transformer and the planner to make our algorithm computationally efficient. We empirically evaluate our framework with several large language models as backbones on public coding challenge benchmarks, showing that 1) it can generate programs that consistently achieve higher performance compared with competing baseline methods; 2) it enables controllable code generation, such as concise codes and highly-commented codes by optimizing modified objective",
    "checked": true,
    "id": "407b9e9478ba6bff43ce4b20e8b6cb2b303477d2",
    "semantic_title": "planning with large language models for code generation",
    "citation_count": 193,
    "authors": []
  },
  "https://openreview.net/forum?id=a6rCdfABJXg": {
    "title": "Equivariance-aware Architectural Optimization of Neural Networks",
    "volume": "poster",
    "abstract": "Incorporating equivariance to symmetry groups as a constraint during neural network training can improve performance and generalization for tasks exhibiting those symmetries, but such symmetries are often not perfectly nor explicitly present. This motivates algorithmically optimizing the architectural constraints imposed by equivariance. We propose the equivariance relaxation morphism, which preserves functionality while reparameterizing a group equivariant layer to operate with equivariance constraints on a subgroup, as well as the $[G]$-mixed equivariant layer, which mixes layers constrained to different groups to enable within-layer equivariance optimization. We further present evolutionary and differentiable neural architecture search (NAS) algorithms that utilize these mechanisms respectively for equivariance-aware architectural optimization. Experiments across a variety of datasets show the benefit of dynamically constrained equivariance to find effective architectures with approximate equivariance",
    "checked": true,
    "id": "7ba8d98c0b4b1b20249d87b1937f88f2220cb9cb",
    "semantic_title": "equivariance-aware architectural optimization of neural networks",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=FbRY1XVfwK": {
    "title": "Accelerating Hamiltonian Monte Carlo via Chebyshev Integration Time",
    "volume": "poster",
    "abstract": "Hamiltonian Monte Carlo (HMC) is a popular method in sampling. While there are quite a few works of studying this method on various aspects, an interesting question is how to choose its integration time to achieve acceleration. In this work, we consider accelerating the process of sampling from a distribution $\\pi(x) \\propto \\exp(-f(x))$ via HMC via time-varying integration time. When the potential $f$ is $L$-smooth and $m$-strongly convex, i.e. for sampling from a log-smooth and strongly log-concave target distribution $\\pi$, it is known that under a constant integration time, the number of iterations that ideal HMC takes to get an $\\epsilon$ Wasserstein-2 distance to the target $\\pi$ is $O( \\kappa \\log \\frac{1}{\\epsilon} )$, where $\\kappa := \\frac{L}{m}$ is the condition number. We propose a scheme of time-varying integration time based on the roots of Chebyshev polynomials. We show that in the case of quadratic potential $f$, i.e. when the target $\\pi$ is a Gaussian distribution, ideal HMC with this choice of integration time only takes $O( \\sqrt{\\kappa} \\log \\frac{1}{\\epsilon} )$ number of iterations to reach Wasserstein-2 distance less than $\\epsilon$; this improvement on the dependence on condition number is akin to acceleration in optimization. The design and analysis of HMC with the proposed integration time is built on the tools of Chebyshev polynomials. Experiments find the advantage of adopting our scheme of time-varying integration time even for sampling from distributions with smooth strongly convex potentials that are not quadratic",
    "checked": true,
    "id": "e2e4bbef1c16991788181ae527bb699197a9e981",
    "semantic_title": "accelerating hamiltonian monte carlo via chebyshev integration time",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=Q-neeWNVv1": {
    "title": "Order Matters: Agent-by-agent Policy Optimization",
    "volume": "poster",
    "abstract": "While multi-agent trust region algorithms have achieved great success empirically in solving coordination tasks, most of them, however, suffer from a non-stationarity problem since agents update their policies simultaneously. In contrast, a sequential scheme that updates policies agent-by-agent provides another perspective and shows strong performance. However, sample inefficiency and lack of monotonic improvement guarantees for each agent are still the two significant challenges for the sequential scheme. In this paper, we propose the \\textbf{A}gent-by-\\textbf{a}gent \\textbf{P}olicy \\textbf{O}ptimization (A2PO) algorithm to improve the sample efficiency and retain the guarantees of monotonic improvement for each agent during training. We justify the tightness of the monotonic improvement bound compared with other trust region algorithms. From the perspective of sequentially updating agents, we further consider the effect of agent updating order and extend the theory of non-stationarity into the sequential update scheme. To evaluate A2PO, we conduct a comprehensive empirical study on four benchmarks: StarCraftII, Multi-agent MuJoCo, Multi-agent Particle Environment, and Google Research Football full game scenarios. A2PO consistently outperforms strong baselines",
    "checked": true,
    "id": "cbb494f682944c3c21d3772683742fc519a197e4",
    "semantic_title": "order matters: agent-by-agent policy optimization",
    "citation_count": 38,
    "authors": []
  },
  "https://openreview.net/forum?id=ULnHxczCBaE": {
    "title": "On the Convergence of AdaGrad(Norm) on $\\mathbb{R}^d$: Beyond Convexity, Non-Asymptotic Rate and Acceleration",
    "volume": "poster",
    "abstract": "Existing analysis of AdaGrad and other adaptive methods for smooth convex optimization is typically for functions with bounded domain diameter. In unconstrained problems, previous works guarantee an asymptotic convergence rate without an explicit constant factor that holds true for the entire function class. Furthermore, in the stochastic setting, only a modified version of AdaGrad, different from the one commonly used in practice, in which the latest gradient is not used to update the stepsize, has been analyzed. Our paper aims at bridging these gaps and developing a deeper understanding of AdaGrad and its variants in the standard setting of smooth convex functions as well as the more general setting of quasar convex functions. First, we demonstrate new techniques to explicitly bound the convergence rate of the vanilla AdaGrad for unconstrained problems in both deterministic and stochastic settings. Second, we propose a variant of AdaGrad for which we can show the convergence of the last iterate, instead of the average iterate. Finally, we give new accelerated adaptive algorithms and their convergence guarantee in the deterministic setting with explicit dependency on the problem parameters, improving upon the asymptotic rate shown in previous works",
    "checked": false,
    "id": "ba29ac871948ddf64f85b6428530c005f7c4557b",
    "semantic_title": "on the convergence of adagrad(norm) on $\\r^{d}$: beyond convexity, non-asymptotic rate and acceleration",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=5mqFra2ZSuf": {
    "title": "SP2 : A Second Order Stochastic Polyak Method",
    "volume": "poster",
    "abstract": "Recently the SP (Stochastic Polyak step size) method has emerged as a competitive adaptive method for setting the step sizes of SGD. SP can be interpreted as a method specialized to interpolated models, since it solves the interpolation equations. SP solves these equation by using local linearizations of the model. We take a step further and develop a method for solving the interpolation equations that uses the local second-order approximation of the model. Our resulting method SP2 uses Hessian-vector products to speed-up the convergence of SP. Furthermore, and rather uniquely among second-order methods, the design of SP2 in no way relies on positive definite Hessian matrices or convexity of the objective function. We show SP2 is competitive both in experiments and in theory. We show SP2 is very competitive on matrix completion, non-convex test problems and logistic regression. We also provide a convergence theory on sums-of-quadratics",
    "checked": false,
    "id": "4c79cdf0b2a263e489d097925758a48dc8435562",
    "semantic_title": "sp2: a second order stochastic polyak method",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=r8Mu7idxyF": {
    "title": "Making Better Decision by Directly Planning in Continuous Control",
    "volume": "poster",
    "abstract": "By properly utilizing the learned environment model, model-based reinforcement learning methods can improve the sample efficiency for decision-making problems. Beyond using the learned environment model to train a policy, the success of MCTS-based methods shows that directly incorporating the learned environment model as a planner to make decisions might be more effective. However, when action space is of high dimension and continuous, directly planning according to the learned model is costly and non-trivial. Because of two challenges: (1) the infinite number of candidate actions and (2) the temporal dependency between actions in different timesteps. To address these challenges, inspired by Differential Dynamic Programming (DDP) in optimal control theory, we design a novel Policy Optimization with Model Planning (POMP) algorithm, which incorporates a carefully designed Deep Differential Dynamic Programming (D3P) planner into the model-based RL framework. In D3P planner, (1) to effectively plan in the continuous action space, we construct a locally quadratic programming problem that uses a gradient-based optimization process to replace search. (2) To take the temporal dependency of actions at different timesteps into account, we leverage the updated and latest actions of previous timesteps (i.e., step $1, \\cdots, h-1$) to update the action of the current step (i.e., step $h$), instead of updating all actions simultaneously. We theoretically prove the convergence rate for our D3P planner and analyze the effect of the feedback term. In practice, to effectively apply the neural network based D3P planner in reinforcement learning, we leverage the policy network to initialize the action sequence and keep the action update conservative in the planning process. Experiments demonstrate that POMP consistently improves sample efficiency on widely used continuous control tasks. Our code is released at https://github.com/POMP-D3P/POMP-D3P",
    "checked": true,
    "id": "ea6c9116edce14baeed7e36f72e6673d2929d6c4",
    "semantic_title": "making better decision by directly planning in continuous control",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=VuuDXDgujAc": {
    "title": "HiT-MDP: Learning the SMDP option framework on MDPs with Hidden Temporal Embeddings",
    "volume": "poster",
    "abstract": "The standard option framework is developed on the Semi-Markov Decision Process (SMDP) which is unstable to optimize and sample inefficient. To this end, we propose the Hidden Temporal MDP (HiT-MDP) and prove that the option-induced HiT-MDP is homomorphic equivalent to the option-induced SMDP. A novel transformer-based framework is introduced to learn options' embedding vectors (rather than conventional option tuples) on HiT-MDPs. We then derive a stable and sample efficient option discovering method under the maximum-entropy policy gradient framework. Extensive experiments on challenging Mujoco environments demonstrate HiT-MDP's efficiency and effectiveness: under widely used configurations, HiT-MDP achieves competitive, if not better, performance compared to the state-of-the-art baselines on all finite horizon and transfer learning environments. Moreover, HiT-MDP significantly outperforms all baselines on infinite horizon environments while exhibiting smaller variance, faster convergence, and better interpretability. Our work potentially sheds light on the theoretical ground of extending the option framework into a large-scale foundation model",
    "checked": true,
    "id": "39cb0e25acce48e6833941718b982cf5ed68887a",
    "semantic_title": "hit-mdp: learning the smdp option framework on mdps with hidden temporal embeddings",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=JLg5aHHv7j": {
    "title": "(Certified!!) Adversarial Robustness for Free!",
    "volume": "poster",
    "abstract": "In this paper we show how to achieve state-of-the-art certified adversarial robustness to 2-norm bounded perturbations by relying exclusively on off-the-shelf pretrained models. To do so, we instantiate the denoised smoothing approach of Salman et al. by combining a pretrained denoising diffusion probabilistic model and a standard high-accuracy classifier. This allows us to certify 71% accuracy on ImageNet under adversarial perturbations constrained to be within a 2-norm of 0.5, an improvement of 14 percentage points over the prior certified SoTA using any approach, or an improvement of 30 percentage points over denoised smoothing. We obtain these results using only pretrained diffusion models and image classifiers, without requiring any fine tuning or retraining of model parameters",
    "checked": true,
    "id": "05c0b2d72a943dc0be26ef9e8fedd1380f2ff9ba",
    "semantic_title": "(certified!!) adversarial robustness for free!",
    "citation_count": 163,
    "authors": []
  },
  "https://openreview.net/forum?id=QIRtAqoXwj": {
    "title": "Heterogeneous Neuronal and Synaptic Dynamics for Spike-Efficient Unsupervised Learning: Theory and Design Principles",
    "volume": "poster",
    "abstract": "This paper shows that the heterogeneity in neuronal and synaptic dynamics reduces the spiking activity of a Recurrent Spiking Neural Network (RSNN) while improving prediction performance, enabling spike-efficient (unsupervised) learning. We analytically show that the diversity in neurons' integration/relaxation dynamics improves an RSNN's ability to learn more distinct input patterns (higher memory capacity), leading to improved classification and prediction performance. We further prove that heterogeneous Spike-Timing-Dependent-Plasticity (STDP) dynamics of synapses reduce spiking activity but preserve memory capacity. The analytical results motivate Heterogeneous RSNN design using Bayesian optimization to determine heterogeneity in neurons and synapses to improve $\\mathcal{E}$, defined as the ratio of spiking activity and memory capacity. The empirical results on time series classification and prediction tasks show that optimized HRSNN increases performance and reduces spiking activity compared to a homogeneous RSNN",
    "checked": true,
    "id": "33f8433529e3f42a2892f9374a5a06936a6c835b",
    "semantic_title": "heterogeneous neuronal and synaptic dynamics for spike-efficient unsupervised learning: theory and design principles",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=sdQGxouELX": {
    "title": "MMVAE+: Enhancing the Generative Quality of Multimodal VAEs without Compromises",
    "volume": "poster",
    "abstract": "Multimodal VAEs have recently gained attention as efficient models for weakly-supervised generative learning with multiple modalities. However, all existing variants of multimodal VAEs are affected by a non-trivial trade-off between generative quality and generative coherence. In particular mixture-based models achieve good coherence only at the expense of sample diversity and a resulting lack of generative quality. We present a novel variant of the mixture-of-experts multimodal variational autoencoder that improves its generative quality, while maintaining high semantic coherence. We model shared and modality-specific information in separate latent subspaces, proposing an objective that overcomes certain dependencies on hyperparameters that arise for existing approaches with the same latent space structure. Compared to these existing approaches, we show increased robustness with respect to changes in the design of the latent space, in terms of the capacity allocated to modality-specific subspaces. We show that our model achieves both good generative coherence and high generative quality in challenging experiments, including more complex multimodal datasets than those used in previous works",
    "checked": true,
    "id": "53608de216c4628528ff1b08517099a04694df17",
    "semantic_title": "mmvae+: enhancing the generative quality of multimodal vaes without compromises",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=T2Ncx_PN2K": {
    "title": "In-Situ Text-Only Adaptation of Speech Models with Low-Overhead Speech Imputations",
    "volume": "poster",
    "abstract": "Fast and accurate adaptation of automatic speech recognition (ASR) systems using only text data in the target domain is a problem of long-standing practical relevance. Text-only adaptation was easy in traditional cascaded ASR systems with completely decoupled acoustic and language models. Recently, the RNNTransducer (RNN-T) has emerged as a default ASR model because of its high accuracy, low latency, and capability of supporting streaming input. However text-only adaptation of the RNN-T model is significantly more challenging due to its tight integration of acoustic and language models and end-to-end training. Existing recent approaches for text-only adaptation of RNN-Ts, either entail significant modification to the network or introduce high latency during decoding. We propose a new approach (TOLSTOI) that imputes speech representations internal to a baseline RNN-T, starting from text-only inputs, and performs in-situ adaptation that results in higher adaptation accuracy without any runtime overheads during decoding. Our imputation model is a function of the labeled data and trained parameters of the ASR model, and that we show, is more effective in controlling catastrophic forgetting compared to existing methods. We establish the effectiveness of TOLSTOI using three target domains and two ASR models of varying complexity. We yield up to 35% relative reduction in word error rate with text-only adaptation while forgetting the least compared to existing adaptation approaches. Our method is easy to implement and can be harnessed on existing RNN-T models without requiring ASR model training from scratch",
    "checked": true,
    "id": "418385684b218ee8eb1e4eb9caec23d476ef3c45",
    "semantic_title": "in-situ text-only adaptation of speech models with low-overhead speech imputations",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=op-ceGueqc4": {
    "title": "Scaling Laws For Deep Learning Based Image Reconstruction",
    "volume": "poster",
    "abstract": "Deep neural networks trained end-to-end to map a measurement of a (noisy) image to a clean image perform excellent for a variety of linear inverse problems. Current methods are only trained on a few hundreds or thousands of images as opposed to the millions of examples deep networks are trained on in other domains. In this work, we study whether major performance gains are expected from scaling up the training set size. We consider image denoising, accelerated magnetic resonance imaging, and super-resolution and empirically determine the reconstruction quality as a function of training set size, while simultaneously scaling the network size. For all three tasks we find that an initially steep power-law scaling slows significantly already at moderate training set sizes. Interpolating those scaling laws suggests that even training on millions of images would not significantly improve performance. To understand the expected behavior, we analytically characterize the performance of a linear estimator learned with early stopped gradient descent. The result formalizes the intuition that once the error induced by learning the signal model is small relative to the error floor, more training examples do not improve performance",
    "checked": true,
    "id": "f94aa0d4c5c1dee834d6da0365bf0acf12f18850",
    "semantic_title": "scaling laws for deep learning based image reconstruction",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=3oWo92cQyxL": {
    "title": "Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning",
    "volume": "poster",
    "abstract": "Multimodal few-shot learning is challenging due to the large domain gap between vision and language modalities. Existing methods are trying to communicate visual concepts as prompts to frozen language models, but rely on hand-engineered task induction to reduce the hypothesis space. To make the whole process learnable, we introduce a multimodal meta-learning approach. Specifically, our approach decomposes the training of the model into a set of related multimodal few-shot tasks. We define a meta-mapper network, acting as a meta-learner, to efficiently bridge frozen large-scale vision and language models and leverage their already learned capacity. By updating the learnable parameters only of the meta-mapper, it learns to accrue shared meta-knowledge among these tasks. Thus, it can rapidly adapt to newly presented samples with only a few gradient updates. Importantly, it induces the task in a completely data-driven manner, with no need for a hand-engineered task induction. We evaluate our approach on recently proposed multimodal few-shot benchmarks, measuring how rapidly the model can bind novel visual concepts to words and answer visual questions by observing only a limited set of labeled examples. The experimental results show that our meta-learning approach outperforms the baseline across multiple datasets and various training settings while being computationally more efficient",
    "checked": true,
    "id": "136d968598ab14715cec3393153355c3b535201e",
    "semantic_title": "meta learning to bridge vision and language models for multimodal few-shot learning",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=Xyme9p1rpZw": {
    "title": "SoftZoo: A Soft Robot Co-design Benchmark For Locomotion In Diverse Environments",
    "volume": "poster",
    "abstract": "While significant research progress has been made in robot learning for control, unique challenges arise when simultaneously co-optimizing morphology. Existing work has typically been tailored for particular environments or representations. In order to more fully understand inherent design and performance tradeoffs and accelerate the development of new breeds of soft robots, a comprehensive virtual platform — with well-established tasks, environments, and evaluation metrics — is needed. In this work, we introduce SoftZoo, a soft robot co-design platform for locomotion in diverse environments. SoftZoo supports an extensive, naturally-inspired material set, including the ability to simulate environments such as flat ground, desert, wetland, clay, ice, snow, shallow water, and ocean. Further, it provides a variety of tasks relevant for soft robotics, including fast locomotion, agile turning, and path following, as well as differentiable design representations for morphology and control. Combined, these elements form a feature-rich platform for analysis and development of soft robot co-design algorithms. We benchmark prevalent representations and co-design algorithms, and shed light on 1) the interplay between environment, morphology, and behavior (2) the importance of design space representations 3) the ambiguity in muscle formation and controller synthesis and 4) the value of differentiable physics. We envision that SoftZoo will serve as a standard platform and template an approach toward the development of novel representations and algorithms for co-designing soft robots' behavioral and morphological intelligence. Demos are available on our project page",
    "checked": true,
    "id": "a24d419bd3ec59f16b9103a836b419e050497b38",
    "semantic_title": "softzoo: a soft robot co-design benchmark for locomotion in diverse environments",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=dCSFiAl_VO3": {
    "title": "Improved Learning-augmented Algorithms for k-means and k-medians Clustering",
    "volume": "poster",
    "abstract": "We consider the problem of clustering in the learning-augmented setting. We are given a data set in $d$-dimensional Euclidean space, and a label for each data point given by a predictor indicating what subsets of points should be clustered together. This setting captures situations where we have access to some auxiliary information about the data set relevant for our clustering objective, for instance the labels output by a neural network. Following prior work, we assume that there are at most an $\\alpha \\in (0,c)$ for some $c<1$ fraction of false positives and false negatives in each predicted cluster, in the absence of which the labels would attain the optimal clustering cost $\\mathrm{OPT}$. For a dataset of size $m$, we propose a deterministic $k$-means algorithm that produces centers with an improved bound on the clustering cost compared to the previous randomized state-of-the-art algorithm while preserving the $O( d m \\log m)$ runtime. Furthermore, our algorithm works even when the predictions are not very accurate, i.e., our cost bound holds for $\\alpha$ up to $1/2$, an improvement from $\\alpha$ being at most $1/7$ in previous work. For the $k$-medians problem we again improve upon prior work by achieving a biquadratic improvement in the dependence of the approximation factor on the accuracy parameter $\\alpha$ to get a cost of $(1+O(\\alpha))\\mathrm{OPT}$, while requiring essentially just $O(md \\log^3 m/\\alpha)$ runtime",
    "checked": true,
    "id": "c434a00107ad954f76846f7d4628e971f28f0357",
    "semantic_title": "improved learning-augmented algorithms for k-means and k-medians clustering",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=CMPIBjmhpo": {
    "title": "Neural Implicit Shape Editing using Boundary Sensitivity",
    "volume": "poster",
    "abstract": "Neural fields are receiving increased attention as a geometric representation due to their ability to compactly store detailed and smooth shapes and easily undergo topological changes. Compared to classic geometry representations, however, neural representations do not allow the user to exert intuitive control over the shape. Motivated by this, we leverage boundary sensitivity to express how perturbations in parameters move the shape boundary. This allows us to interpret the effect of each learnable parameter and study achievable deformations. With this, we perform geometric editing: finding a parameter update that best approximates a globally prescribed deformation. Prescribing the deformation only locally allows the rest of the shape to change according to some prior, such as semantics or deformation rigidity. Our method is agnostic to the model and its training and updates the NN in-place. Furthermore, we show how boundary sensitivity helps to optimize and constrain objectives (such as surface area and volume), which are difficult to compute without first converting to another representation, such as a mesh",
    "checked": true,
    "id": "732be0b93ca8b443ecc517832f6820b32bacd05e",
    "semantic_title": "neural implicit shape editing using boundary sensitivity",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=nXOhmfFu5n": {
    "title": "Amortised Invariance Learning for Contrastive Self-Supervision",
    "volume": "poster",
    "abstract": "Contrastive self-supervised learning methods famously produce high quality transferable representations by learning invariances to different data augmentations. Invariances established during pre-training can be interpreted as strong inductive biases. However these may or may not be helpful, depending on if they match the invariance requirements of downstream tasks or not. This has led to several attempts to learn task-specific invariances during pre-training, however, these methods are highly compute intensive and tedious to train. We introduce the notion of amortized invariance learning for contrastive self supervision. In the pre-training stage, we parameterize the feature extractor by differentiable invariance hyper-parameters that control the invariances encoded by the representation. Then, for any downstream task, both linear readout and task-specific invariance requirements can be efficiently and effectively learned by gradient-descent. We evaluate the notion of amortized invariances for contrastive learning over two different modalities: vision and audio, on two widely-used contrastive learning methods in vision: SimCLR and MoCo-v2 with popular architectures like ResNets and Vision Transformers, and SimCLR with ResNet-18 for audio. We show that our amortized features provide a reliable way to learn diverse downstream tasks with different invariance requirements, while using a single feature and avoiding task-specific pre-training. This provides an exciting perspective that opens up new horizons in the field of general purpose representation learning",
    "checked": true,
    "id": "b9362fc182f3161df3cad38737e54d54ebd3d4bf",
    "semantic_title": "amortised invariance learning for contrastive self-supervision",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=n-UHRIdPju": {
    "title": "Revisiting Populations in multi-agent Communication",
    "volume": "poster",
    "abstract": "Despite evidence from cognitive sciences that larger groups of speakers tend to develop more structured languages in human communication, scaling up to populations has failed to yield significant benefits in emergent multi-agent communication. In this paper we advocate for an alternate population-level training paradigm for referential games based on the idea of \"partitioning\" the agents into sender-receiver pairs and limiting co-adaptation across pairs. We show that this results in optimizing a different objective at the population level, where agents maximize (1) their respective \"internal\" communication accuracy and (2) some measure of alignment between agents. In experiments, we find that this leads to the emergence of languages that are significantly more compositional. Moreover, when agents are trained in populations that are not fully connected (ie. not all agent pairs interact at training time), this approach reduces multi-linguality and improves zero-shot communication with new agents (ie. agents are able to communicate successfully with other agents outside their training partners)",
    "checked": true,
    "id": "d2a1876392bc86982b5d206cddc01dc1d64b5fc0",
    "semantic_title": "revisiting populations in multi-agent communication",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=-lGvSmht7a": {
    "title": "Sequential Gradient Coding For Straggler Mitigation",
    "volume": "poster",
    "abstract": "In distributed computing, slower nodes (stragglers) usually become a bottleneck. Gradient Coding (GC), introduced by Tandon et al., is an efficient technique that uses principles of error-correcting codes to distribute gradient computation in the presence of stragglers. In this paper, we consider the distributed computation of a sequence of gradients $\\{g(1),g(2),\\ldots,g(J)\\}$, where processing of each gradient $g(t)$ starts in round-$t$ and finishes by round-$(t+T)$. Here $T\\geq 0$ denotes a delay parameter. For the GC scheme, coding is only across computing nodes and this results in a solution where $T=0$. On the other hand, having $T>0$ allows for designing schemes which exploit the temporal dimension as well. In this work, we propose two schemes that demonstrate improved performance compared to GC. Our first scheme combines GC with selective repetition of previously unfinished tasks and achieves improved straggler mitigation. In our second scheme, which constitutes our main contribution, we apply GC to a subset of the tasks and repetition for the remainder of the tasks. We then multiplex these two classes of tasks across workers and rounds in an adaptive manner, based on past straggler patterns. Using theoretical analysis, we demonstrate that our second scheme achieves significant reduction in the computational load. In our experiments, we study a practical setting of concurrently training multiple neural networks over an AWS Lambda cluster involving 256 worker nodes, where our framework naturally applies. We demonstrate that the latter scheme can yield a 16\\% improvement in runtime over the baseline GC scheme, in the presence of naturally occurring, non-simulated stragglers",
    "checked": true,
    "id": "f2f308c6e8847c1fe0544bb5dac0faedc36b38e3",
    "semantic_title": "sequential gradient coding for straggler mitigation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EQfeudmWLQ": {
    "title": "TTN: A Domain-Shift Aware Batch Normalization in Test-Time Adaptation",
    "volume": "poster",
    "abstract": "This paper proposes a novel batch normalization strategy for test-time adaptation. Recent test-time adaptation methods heavily rely on the modified batch normalization, i.e., transductive batch normalization (TBN), which calculates the mean and the variance from the current test batch rather than using the running mean and variance obtained from the source data, i.e., conventional batch normalization (CBN). Adopting TBN that employs test batch statistics mitigates the performance degradation caused by the domain shift. However, re-estimating normalization statistics using test data depends on impractical assumptions that a test batch should be large enough and be drawn from i.i.d. stream, and we observed that the previous methods with TBN show critical performance drop without the assumptions. In this paper, we identify that CBN and TBN are in a trade-off relationship and present a new test-time normalization (TTN) method that interpolates the statistics by adjusting the importance between CBN and TBN according to the domain-shift sensitivity of each BN layer. Our proposed TTN improves model robustness to shifted domains across a wide range of batch sizes and in various realistic evaluation scenarios. TTN is widely applicable to other test-time adaptation methods that rely on updating model parameters via backpropagation. We demonstrate that adopting TTN further improves their performance and achieves state-of-the-art performance in various standard benchmarks",
    "checked": true,
    "id": "f175795f1a93c62f3d42cf11bb24f70895839504",
    "semantic_title": "ttn: a domain-shift aware batch normalization in test-time adaptation",
    "citation_count": 105,
    "authors": []
  },
  "https://openreview.net/forum?id=OKcJhpQiGiX": {
    "title": "Disentanglement of Correlated Factors via Hausdorff Factorized Support",
    "volume": "poster",
    "abstract": "A grand goal in deep learning research is to learn representations capable of generalizing across distribution shifts. Disentanglement is one promising direction aimed at aligning a model's representation with the underlying factors generating the data (e.g. color or background). Existing disentanglement methods, however, rely on an often unrealistic assumption: that factors are statistically independent. In reality, factors (like object color and shape) are correlated. To address this limitation, we consider the use of a relaxed disentanglement criterion -- the Hausdorff Factorized Support (HFS) criterion -- that encourages only pairwise factorized support, rather than a factorial distribution, by minimizing a Hausdorff distance. This allows for arbitrary distributions of the factors over their support, including correlations between them. We show that the use of HFS consistently facilitates disentanglement and recovery of ground-truth factors across a variety of correlation settings and benchmarks, even under severe training correlations and correlation shifts, with in parts over +60% in relative improvement over existing disentanglement methods. In addition, we find that leveraging HFS for representation learning can even facilitate transfer to downstream tasks such as classification under distribution shifts. We hope our original approach and positive empirical results inspire further progress on the open problem of robust generalization. Code available at https://github.com/facebookresearch/disentangling-correlated-factors",
    "checked": true,
    "id": "1fb3198fbaa560a7e122c13a94a9344de79586be",
    "semantic_title": "disentanglement of correlated factors via hausdorff factorized support",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=hH36JeQZDaO": {
    "title": "Generating Sequences by Learning to Self-Correct",
    "volume": "poster",
    "abstract": "Sequence generation applications require satisfying semantic constraints, such as ensuring that programs are correct, using certain keywords, or avoiding undesirable content. Language models, whether fine-tuned or prompted with few-shot demonstrations, frequently violate these constraints, and lack a mechanism to iteratively revise their outputs. Moreover, some powerful language models are of extreme scale or inaccessible, making it inefficient, if not infeasible, to update their parameters for task-specific adaptation. We present Self-Correction, an approach that decouples an imperfect base generator (an off-the-shelf language model or supervised sequence-to-sequence model) from a separate corrector that learns to iteratively correct imperfect generations. To train the corrector, we propose an online training procedure that can use either scalar or natural language feedback on intermediate imperfect generations. We show that Self-Correction improves upon the base generator in three diverse generation tasks - mathematical program synthesis, lexically-constrained generation, and toxicity control - even when the corrector is much smaller than the base generator",
    "checked": true,
    "id": "538288d24bdad73d831dfed44b706958287ed318",
    "semantic_title": "generating sequences by learning to self-correct",
    "citation_count": 263,
    "authors": []
  },
  "https://openreview.net/forum?id=3mlITJRYYbs": {
    "title": "Interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation",
    "volume": "poster",
    "abstract": "Early sensory systems in the brain rapidly adapt to fluctuating input statistics, which requires recurrent communication between neurons. Mechanistically, such recurrent communication is often indirect and mediated by local interneurons. In this work, we explore the computational benefits of mediating recurrent communication via interneurons compared with direct recurrent connections. To this end, we consider two mathematically tractable recurrent neural networks that statistically whiten their inputs --- one with direct recurrent connections and the other with interneurons that mediate recurrent communication. By analyzing the corresponding continuous synaptic dynamics and numerically simulating the networks, we show that the network with interneurons is more robust to initialization than the network with direct recurrent connections in the sense that the convergence time for the synaptic dynamics in the network with interneurons (resp. direct recurrent connections) scales logarithmically (resp. linearly) with the spectrum of their initialization. Our results suggest that interneurons are computationally useful for rapid adaptation to changing input statistics. Interestingly, the network with interneurons is an overparameterized solution of the whitening objective for the network with direct recurrent connections, so our results can be viewed as a recurrent neural network analogue of the implicit acceleration phenomenon observed in overparameterized feedforward linear networks",
    "checked": true,
    "id": "d18387c070233a65c7ebfe7951f8f8db3eabbac5",
    "semantic_title": "interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=6PIrhAx1j4i": {
    "title": "Understanding DDPM Latent Codes Through Optimal Transport",
    "volume": "poster",
    "abstract": "Diffusion models have recently outperformed alternative approaches to model the distribution of natural images. Such diffusion models allow for deterministic sampling via the probability flow ODE, giving rise to a latent space and an encoder map. While having important practical applications, such as the estimation of the likelihood, the theoretical properties of this map are not yet fully understood. In the present work, we partially address this question for the popular case of the VP-SDE (DDPM) approach. We show that, perhaps surprisingly, the DDPM encoder map coincides with the optimal transport map for common distributions; we support this claim by extensive numerical experiments using advanced tensor train solver for multidimensional Fokker-Planck equation. We provide additional theoretical evidence for the case of multivariate normal distributions",
    "checked": true,
    "id": "f638e576fddaa4f34fb7575046de83ad62269e6b",
    "semantic_title": "understanding ddpm latent codes through optimal transport",
    "citation_count": 56,
    "authors": []
  },
  "https://openreview.net/forum?id=moIlFZfj_1b": {
    "title": "Latent Neural ODEs with Sparse Bayesian Multiple Shooting",
    "volume": "poster",
    "abstract": "Training dynamic models, such as neural ODEs, on long trajectories is a hard problem that requires using various tricks, such as trajectory splitting, to make model training work in practice. These methods are often heuristics with poor theoretical justifications, and require iterative manual tuning. We propose a principled multiple shooting technique for neural ODEs that splits the trajectories into manageable short segments, which are optimized in parallel, while ensuring probabilistic control on continuity over consecutive segments. We derive variational inference for our shooting-based latent neural ODE models and propose amortized encodings of irregularly sampled trajectories with a transformer-based recognition network with temporal attention and relative positional encoding. We demonstrate efficient and stable training, and state-of-the-art performance on multiple large-scale benchmark datasets",
    "checked": true,
    "id": "e9ce0ca5f485e8ff4632693b76cdab3b64c34a84",
    "semantic_title": "latent neural odes with sparse bayesian multiple shooting",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=5cFfz6yMVPU": {
    "title": "$\\mathcal{O}$-GNN: incorporating ring priors into molecular modeling",
    "volume": "poster",
    "abstract": "Cyclic compounds that contain at least one ring play an important role in drug design. Despite the recent success of molecular modeling with graph neural networks (GNNs), few models explicitly take rings in compounds into consideration, consequently limiting the expressiveness of the models. In this work, we design a new variant of GNN, ring-enhanced GNN ($\\mathcal{O}$-GNN), that explicitly models rings in addition to atoms and bonds in compounds. In $\\mathcal{O}$-GNN, each ring is represented by a latent vector, which contributes to and is iteratively updated by atom and bond representations. Theoretical analysis shows that $\\mathcal{O}$-GNN is able to distinguish two isomorphic subgraphs lying on different rings using only one layer while conventional graph convolutional neural networks require multiple layers to distinguish, demonstrating that $\\mathcal{O}$-GNN is more expressive. Through experiments, $\\mathcal{O}$-GNN shows good performance on $\\bf{11}$ public datasets. In particular, it achieves state-of-the-art validation result on the PCQM4Mv1 benchmark (outperforming the previous KDDCup champion solution) and the drug-drug interaction prediction task on DrugBank. Furthermore, $\\mathcal{O}$-GNN outperforms strong baselines (without modeling rings) on the molecular property prediction and retrosynthesis prediction tasks",
    "checked": false,
    "id": "4cf145c765013f2369a782f9dc308b5a9c0f0f19",
    "semantic_title": "𝒪-gnn: incorporating ring priors into molecular modeling",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=CDlHZ78-Xzi": {
    "title": "MACTA: A Multi-agent Reinforcement Learning Approach for Cache Timing Attacks and Detection",
    "volume": "poster",
    "abstract": "Security vulnerabilities in computer systems raise serious concerns as computers process an unprecedented amount of private and sensitive data today. Cache timing attacks (CTA) pose an important practical threat as they can effectively breach many protection mechanisms in today's systems. However, the current detection techniques for cache timing attacks heavily rely on heuristics and expert knowledge, which can lead to brittleness and the inability to adapt to new attacks. To mitigate the CTA threat, we propose MACTA, a multi-agent reinforcement learning (MARL) approach that leverages population-based training to train both attackers and detectors. Following best practices, we develop a realistic simulated MARL environment, MA-AUTOCAT, which enables training and evaluation of cache-timing attackers and detectors. Our empirical results suggest that MACTA is an effective solution without any manual input from security experts. MACTA detectors can generalize to a heuristic attack not exposed in training with a 97.8% detection rate and reduce the attack bandwidth of adaptive attackers by 20% on average. In the meantime, MACTA attackers are qualitatively more effective than other attacks studied, and the average evasion rate of MACTA attackers against an unseen state-of-the-art detector can reach up to 99%. Furthermore, we found that agents equipped with a Transformer encoder can learn effective policies in situations when agents with multi-layer perceptron encoders do not in this environment, suggesting the potential of Transformer structures in CTA problems",
    "checked": true,
    "id": "321c8556d3c12a3eb505b578c86d9f66f97d9093",
    "semantic_title": "macta: a multi-agent reinforcement learning approach for cache timing attacks and detection",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=FVW7Mi2ph6C": {
    "title": "PAC Reinforcement Learning for Predictive State Representations",
    "volume": "poster",
    "abstract": "In this paper we study online Reinforcement Learning (RL) in partially observable dynamical systems. We focus on the Predictive State Representations (PSRs) model, which is an expressive model that captures other well-known models such as Partially Observable Markov Decision Processes (POMDP). PSR represents the states using a set of predictions of future observations and is defined entirely using observable quantities. We develop a novel model-based algorithm for PSRs that can learn a near optimal policy in sample complexity scaling polynomially with respect to all the relevant parameters of the systems. Our algorithm naturally works with function approximation to extend to systems with potentially large state and observation spaces. We show that given a realizable model class, the sample complexity of learning the near optimal policy only scales polynomially with respect to the statistical complexity of the model class, without any explicit polynomial dependence on the size of the state and observation spaces. Notably, our work is the first work that shows polynomial sample complexities to compete with the globally optimal policy in PSRs. Finally, we demonstrate how our general theorem can be directly used to derive sample complexity bounds for special models including $m$-step weakly revealing and $m$-step decodable tabular POMDPs, POMDPs with low-rank latent transition, and POMDPs with linear emission and latent transition",
    "checked": true,
    "id": "c9ffc6b13a3b9a3af9244b744b3a899a5ad1e96b",
    "semantic_title": "pac reinforcement learning for predictive state representations",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=bn0GZZdDfI1": {
    "title": "Decentralized Optimistic Hyperpolicy Mirror Descent: Provably No-Regret Learning in Markov Games",
    "volume": "poster",
    "abstract": "We study decentralized policy learning in Markov games where we control a single agent to play with nonstationary and possibly adversarial opponents. Our goal is to develop a no-regret online learning algorithm that (i) takes actions based on the local information observed by the agent and (ii) is able to find the best policy in hindsight. For such a problem, the nonstationary state transitions due to the varying opponent pose a significant challenge. In light of a recent hardness result (Liu et al., 2022), we focus on the setting where the opponent's previous policies are revealed to the agent for decision making. With such an information structure, we propose a new algorithm, Decentralized Optimistic hypeRpolicy mIrror deScent (DORIS), which achieves $\\sqrt{K}$-regret in the context of general function approximation, where $K$ is the number of episodes. Moreover, when all the agents adopt DORIS, we prove that their mixture policy constitutes an approximate coarse correlated equilibrium. In particular, DORIS maintains a hyperpolicy which is a distribution over the policy space. The hyperpolicy is updated via mirror descent, where the update direction is obtained by an optimistic variant of least-squares policy evaluation. Furthermore, to illustrate the power of our method, we apply DORIS to constrained and vector-valued MDPs, which can be formulated as zero-sum Markov games with a fictitious opponent",
    "checked": true,
    "id": "8fd7aae7826feb4733f2518cd6f8cc448be26b75",
    "semantic_title": "decentralized optimistic hyperpolicy mirror descent: provably no-regret learning in markov games",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=ZBUthI6wK9h": {
    "title": "Robust Scheduling with GFlowNets",
    "volume": "poster",
    "abstract": "Finding the best way to schedule operations in a computation graph is a classical NP-hard problem which is central to compiler optimization. However, evaluating the goodness of a schedule on the target hardware can be very time-consuming. Traditional approaches as well as previous machine learning ones typically optimize proxy metrics, which are fast to evaluate but can lead to bad schedules when tested on the target hardware. In this work, we propose a new approach to scheduling by sampling proportionally to the proxy metric using a novel GFlowNet method. We introduce a technique to control the trade-off between diversity and goodness of the proposed schedules at inference time and demonstrate empirically that the pure optimization baselines can lead to subpar performance with respect to our approach when tested on a target model. Furthermore, we show that conditioning the GFlowNet on the computation graph enables generalization to unseen scheduling problems for both synthetic and real-world compiler datasets",
    "checked": true,
    "id": "035b158f1f165930aaf7877fb54515ce29a17f9e",
    "semantic_title": "robust scheduling with gflownets",
    "citation_count": 62,
    "authors": []
  },
  "https://openreview.net/forum?id=OAsXFPBfTBh": {
    "title": "Autoregressive Conditional Neural Processes",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9d4521ed386eb5ebb657040e2ac89795642abd5b",
    "semantic_title": "autoregressive conditional neural processes",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=fe2S7736sNS": {
    "title": "$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "3ec5f0da304a606c5989de5b00e1246ee64b3e46",
    "semantic_title": "knn prompting: beyond-context learning with calibration-free nearest neighbor inference",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=zVrw4OH1Lch": {
    "title": "FIFA: Making Fairness More Generalizable in Classifiers Trained on Imbalanced Data",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1abde3cba5355070bd41c51314e9ca4b41079dcf",
    "semantic_title": "fifa: making fairness more generalizable in classifiers trained on imbalanced data",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=7Cb7Faxa1OB": {
    "title": "Understanding The Robustness of Self-supervised Learning Through Topic Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fb57a29cce4c6e4d6971ccc2f928289703566145",
    "semantic_title": "understanding the robustness of self-supervised learning through topic modeling",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=sPgP6aISLTD": {
    "title": "Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "851cfaff3dd0421a9bc2775b135fe3007910eef0",
    "semantic_title": "temporal disentanglement of representations for improved generalisation in reinforcement learning",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=oze0clVGPeX": {
    "title": "Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0ba0091c60c0346493b9ffb46ac682eee5453a53",
    "semantic_title": "exploring the limits of differentially private deep learning with group-wise clipping",
    "citation_count": 56,
    "authors": []
  },
  "https://openreview.net/forum?id=7i6OZa7oij": {
    "title": "Strong inductive biases provably prevent harmless interpolation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ee8cb5f62eaff0b766fb41d3821ee28786b46a08",
    "semantic_title": "strong inductive biases provably prevent harmless interpolation",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=b9tUk-f_aG": {
    "title": "Bridging the Gap to Real-World Object-Centric Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6174d6498562f066526c7371edf8f548918d988c",
    "semantic_title": "bridging the gap to real-world object-centric learning",
    "citation_count": 180,
    "authors": []
  },
  "https://openreview.net/forum?id=cIbjyd2Vcy": {
    "title": "Towards a Unified Theoretical Understanding of Non-contrastive Learning via Rank Differential Mechanism",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "40ff56355f530bd72010d482ae4f71260136df2d",
    "semantic_title": "towards a unified theoretical understanding of non-contrastive learning via rank differential mechanism",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=CtS2Rs_aYk": {
    "title": "Stay Moral and Explore: Learn to Behave Morally in Text-based Games",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "dfbe976f9b445140fb59fed37c46d1af78d344fc",
    "semantic_title": "stay moral and explore: learn to behave morally in text-based games",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=9kBCMNb5mc": {
    "title": "Optimistic Exploration with Learned Features Provably Solves Markov Decision Processes with Neural Dynamics",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "783a5e51e23ba9aa8ea30d96eb82764fc8c4f2fe",
    "semantic_title": "optimistic exploration with learned features provably solves markov decision processes with neural dynamics",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=hp_RwhKDJ5": {
    "title": "Learning to Induce Causal Structure",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b73266c0b61484107d1771491256adbae7d7bb58",
    "semantic_title": "learning to induce causal structure",
    "citation_count": 55,
    "authors": []
  },
  "https://openreview.net/forum?id=AHvFDPi-FA": {
    "title": "Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2cbea7615ebecea2c414d8fbad47d5d258a5c3b4",
    "semantic_title": "diffusion policies as an expressive policy class for offline reinforcement learning",
    "citation_count": 446,
    "authors": []
  },
  "https://openreview.net/forum?id=QTXKTXJKIh": {
    "title": "Achieving Near-Optimal Individual Regret & Low Communications in Multi-Agent Bandits",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "261bd37a168e69b14c6bc957d3561e5a90f4270b",
    "semantic_title": "achieving near-optimal individual regret & low communications in multi-agent bandits",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=qco4ekz2Epm": {
    "title": "Online Boundary-Free Continual Learning by Scheduled Data Prior",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3008cee71743197a6b68e8b76c6b512b61a6832d",
    "semantic_title": "online boundary-free continual learning by scheduled data prior",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=kUf4BcWXGJr": {
    "title": "HypeR: Multitask Hyper-Prompted Training Enables Large-Scale Retrieval Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6c79dc9d5ea8ef204e0543fd69a5e9eb80bbf612",
    "semantic_title": "hyper: multitask hyper-prompted training enables large-scale retrieval generalization",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=HjOo2k8lhFl": {
    "title": "Learning Rationalizable Equilibria in Multiplayer Games",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4637a1fd931b49a8119adc1c97a9d116474e5f28",
    "semantic_title": "learning rationalizable equilibria in multiplayer games",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=3dnrKbeVatv": {
    "title": "Energy-Based Test Sample Adaptation for Domain Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "af47a562da0a4d0a120a92fb7e0d48a58b09bd08",
    "semantic_title": "energy-based test sample adaptation for domain generalization",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=wCFB37bzud4": {
    "title": "Bidirectional Language Models Are Also Few-shot Learners",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b65b7f480a61d3dd31d8117b349cabc87c8ccf6c",
    "semantic_title": "bidirectional language models are also few-shot learners",
    "citation_count": 54,
    "authors": []
  },
  "https://openreview.net/forum?id=ytZIYmztET": {
    "title": "EPISODE: Episodic Gradient Clipping with Periodic Resampled Corrections for Federated Learning with Heterogeneous Data",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b827ca1a0bf9e90ff5738c93409fb2b26a5edfe0",
    "semantic_title": "episode: episodic gradient clipping with periodic resampled corrections for federated learning with heterogeneous data",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=i8L9qoeZOS": {
    "title": "A Theory of Dynamic Benchmarks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "aa9e11e4f5b6f4cc7b7e6a4aa4c21ed19528ccb2",
    "semantic_title": "a theory of dynamic benchmarks",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=HWt4BBZjVW": {
    "title": "On the Trade-Off between Actionable Explanations and the Right to be Forgotten",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e17d5e87eac867e08a780f31a2bbe89348e84547",
    "semantic_title": "on the trade-off between actionable explanations and the right to be forgotten",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=NeDc-Ak-H_": {
    "title": "Learning What and Where: Disentangling Location and Identity Tracking Without Supervision",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "173920346bde5deabdbe4c0e5950c8f5e5a4c20d",
    "semantic_title": "learning what and where: disentangling location and identity tracking without supervision",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=CN223OXgyb5": {
    "title": "BALTO: fast tensor program optimization with diversity-based active learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "464c72fe8a7873c909213a8a49ad9275ac84906d",
    "semantic_title": "balto: fast tensor program optimization with diversity-based active learning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=gwcQajoXNF": {
    "title": "Computing all Optimal Partial Transports",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "dabcb6fcd6365fe211fdd77b085c4027784d965f",
    "semantic_title": "computing all optimal partial transports",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=9OmCr1q54Z": {
    "title": "AE-FLOW: Autoencoders with Normalizing Flows for Medical Images Anomaly Detection",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "711dfa005ed3b3bd04751aec1b17c0169b342ff4",
    "semantic_title": "ae-flow: autoencoders with normalizing flows for medical images anomaly detection",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=xveTeHVlF7j": {
    "title": "A Self-Attention Ansatz for Ab-initio Quantum Chemistry",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "cc36f0c1778e9e99c84cc59be0eea15fd2119793",
    "semantic_title": "a self-attention ansatz for ab-initio quantum chemistry",
    "citation_count": 78,
    "authors": []
  },
  "https://openreview.net/forum?id=sC-PmTsiTB": {
    "title": "Probabilistically Robust Recourse: Navigating the Trade-offs between Costs and Robustness in Algorithmic Recourse",
    "volume": "poster",
    "abstract": "As machine learning models are increasingly being employed to make consequential decisions in real-world settings, it becomes critical to ensure that individuals who are adversely impacted (e.g., loan denied) by the predictions of these models are provided with a means for recourse. While several approaches have been proposed to construct recourses for affected individuals, the recourses output by these methods either achieve low costs (i.e., ease-of-implementation) or robustness to small perturbations (i.e., noisy implementations of recourses), but not both due to the inherent trade-offs between the recourse costs and robustness. Furthermore, prior approaches do not provide end users with any agency over navigating the aforementioned trade-offs. In this work, we address the above challenges by proposing the first algorithmic framework which enables users to effectively manage the recourse cost vs. robustness trade-offs. More specifically, our framework Probabilistically ROBust rEcourse (PROBE) lets users choose the probability with which a recourse could get invalidated (recourse invalidation rate) if small changes are made to the recourse i.e., the recourse is implemented somewhat noisily. To this end, we propose a novel objective function which simultaneously minimizes the gap between the achieved (resulting) and desired recourse invalidation rates, minimizes recourse costs, and also ensures that the resulting recourse achieves a positive model prediction. We develop novel theoretical results to characterize the recourse invalidation rates corresponding to any given instance w.r.t. different classes of underlying models (e.g., linear models, tree based models etc.), and leverage these results to efficiently optimize the proposed objective. Experimental evaluation with multiple real world datasets demonstrates the efficacy of the proposed framework",
    "checked": true,
    "id": "517f446ab3ff339459cab39cf12691d925d75a36",
    "semantic_title": "probabilistically robust recourse: navigating the trade-offs between costs and robustness in algorithmic recourse",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=LiXDW7CF94J": {
    "title": "How robust is unsupervised representation learning to distribution shift?",
    "volume": "poster",
    "abstract": "The robustness of machine learning algorithms to distributions shift is primarily discussed in the context of supervised learning (SL). As such, there is a lack of insight on the robustness of the representations learned from unsupervised methods, such as self-supervised learning (SSL) and auto-encoder based algorithms (AE), to distribution shift. We posit that the input-driven objectives of unsupervised algorithms lead to representations that are more robust to distribution shift than the target-driven objective of SL. We verify this by extensively evaluating the performance of SSL and AE on both synthetic and realistic distribution shift datasets. Following observations that the linear layer used for classification itself can be susceptible to spurious correlations, we evaluate the representations using a linear head trained on a small amount of out-of-distribution (OOD) data, to isolate the robustness of the learned representations from that of the linear head. We also develop \"controllable\" versions of existing realistic domain generalisation datasets with adjustable degrees of distribution shifts. This allows us to study the robustness of different learning algorithms under versatile yet realistic distribution shift conditions. Our experiments show that representations learned from unsupervised learning algorithms generalise better than SL under a wide variety of extreme as well as realistic distribution shifts",
    "checked": true,
    "id": "38cad5ae86da1c728e18cc49f77e988e927768fa",
    "semantic_title": "how robust is unsupervised representation learning to distribution shift?",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=eXkhH12DTD9": {
    "title": "Pseudo-label Training and Model Inertia in Neural Machine Translation",
    "volume": "poster",
    "abstract": "Like many other machine learning applications, neural machine translation (NMT) benefits from over-parameterized deep neural models. However, these models have been observed to be brittle: NMT model predictions are sensitive to small input changes and can show significant variation across re-training or incremental model updates. This work studies a frequently used method in NMT, pseudo-label training (PLT), which is common to the related techniques of forward-translation (or self-training) and sequence-level knowledge distillation. While the effect of PLT on quality is well-documented, we highlight a lesser-known effect: PLT can enhance a model's stability to model updates and input perturbations, a set of properties we call \\textit{model inertia}. We study inertia effects under different training settings and we identify distribution simplification as a mechanism behind the observed results",
    "checked": true,
    "id": "8627ce5fa45057477a78b1ae9dae3e3bf0a4d0a5",
    "semantic_title": "pseudo-label training and model inertia in neural machine translation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=OAw6V3ZAhSd": {
    "title": "HyperDeepONet: learning operator with complex target function space using the limited resources via hypernetwork",
    "volume": "poster",
    "abstract": "Fast and accurate predictions for complex physical dynamics are a big challenge across various applications. Real-time prediction on resource-constrained hardware is even more crucial in the real-world problems. The deep operator network (DeepONet) has recently been proposed as a framework for learning nonlinear mappings between function spaces. However, the DeepONet requires many parameters and has a high computational cost when learning operators, particularly those with complex (discontinuous or non-smooth) target functions. In this study, we propose HyperDeepONet, which uses the expressive power of the hypernetwork to enable learning of a complex operator with smaller set of parameters. The DeepONet and its variant models can be thought of as a method of injecting the input function information into the target function. From this perspective, these models can be viewed as a special case of HyperDeepONet. We analyze the complexity of DeepONet and conclude that HyperDeepONet needs relatively lower complexity to obtain the desired accuracy for operator learning. HyperDeepONet was successfully applied to various operator learning problems using low computational resources compared to other benchmarks",
    "checked": true,
    "id": "bf6750748589febbc04319f7e2471b45edbb6198",
    "semantic_title": "hyperdeeponet: learning operator with complex target function space using the limited resources via hypernetwork",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=qcJmsP3oE9": {
    "title": "Edge Guided GANs with Contrastive Learning for Semantic Image Synthesis",
    "volume": "poster",
    "abstract": "We propose a novel \\underline{e}dge guided \\underline{g}enerative \\underline{a}dversarial \\underline{n}etwork with \\underline{c}ontrastive learning (ECGAN) for the challenging semantic image synthesis task. Although considerable improvement has been achieved, the quality of synthesized images is far from satisfactory due to three largely unresolved challenges. 1) The semantic labels do not provide detailed structural information, making it difficult to synthesize local details and structures. 2) The widely adopted CNN operations such as convolution, down-sampling, and normalization usually cause spatial resolution loss and thus cannot fully preserve the original semantic information, leading to semantically inconsistent results (e.g., missing small objects). 3) Existing semantic image synthesis methods focus on modeling ``local'' semantic information from a single input semantic layout. However, they ignore ``global'' semantic information of multiple input semantic layouts, i.e., semantic cross-relations between pixels across different input layouts. To tackle 1), we propose to use edge as an intermediate representation which is further adopted to guide image generation via a proposed attention guided edge transfer module. Edge information is produced by a convolutional generator and introduces detailed structure information. To tackle 2), we design an effective module to selectively highlight class-dependent feature maps according to the original semantic layout to preserve the semantic information. To tackle 3), inspired by current methods in contrastive learning, we propose a novel contrastive learning method, which aims to enforce pixel embeddings belonging to the same semantic class to generate more similar image content than those from different classes. Doing so can capture more semantic relations by explicitly exploring the structures of labeled pixels from multiple input semantic layouts. Experiments on three challenging datasets show that our ECGAN achieves significantly better results than state-of-the-art methods",
    "checked": false,
    "id": "6a9c6bb5bd63cafabe25c79b0eccc0436469b4be",
    "semantic_title": "edge guided gans with multi-scale contrastive learning for semantic image synthesis",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=Kf7Yyf4O0u": {
    "title": "CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated Learning",
    "volume": "poster",
    "abstract": "Federated Learning (FL) is a setting for training machine learning models in distributed environments where the clients do not share their raw data but instead send model updates to a server. However, model updates can be subject to attacks and leak private information. Differential Privacy (DP) is a leading mitigation strategy which involves adding noise to clipped model updates, trading off performance for strong theoretical privacy guarantees. Previous work has shown that the threat model of DP is conservative and that the obtained guarantees may be vacuous or may overestimate information leakage in practice. In this paper, we aim to achieve a tighter measurement of the model exposure by considering a realistic threat model. We propose a novel method, CANIFE, that uses canaries - carefully crafted samples by a strong adversary to evaluate the empirical privacy of a training round. We apply this attack to vision models trained on CIFAR-10 and CelebA and to language models trained on Sent140 and Shakespeare. In particular, in realistic FL scenarios, we demonstrate that the empirical per-round epsilon obtained with CANIFE is 4 -- 5$\\times$ lower than the theoretical bound",
    "checked": true,
    "id": "37fc0cb77dfaf6cced0082f498912e19dc5666b5",
    "semantic_title": "canife: crafting canaries for empirical privacy measurement in federated learning",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=mMaInr0r0c": {
    "title": "A View From Somewhere: Human-Centric Face Representations",
    "volume": "poster",
    "abstract": "Few datasets contain self-identified demographic information, inferring demographic information risks introducing additional biases, and collecting and storing data on sensitive attributes can carry legal risks. Besides, categorical demographic labels do not necessarily capture all the relevant dimensions of human diversity. We propose to implicitly learn a set of continuous face-varying dimensions, without ever asking an annotator to explicitly categorize a person. We uncover the dimensions by learning on A View From Somewhere (AVFS) dataset of 638,180 human judgments of face similarity. We demonstrate the utility of our learned embedding space for predicting face similarity judgments, collecting continuous face attribute values, attribute classification, and comparative dataset diversity auditing. Moreover, using a novel conditional framework, we show that an annotator's demographics influences the \\emph{importance} they place on different attributes when judging similarity, underscoring the \\emph{need} for diverse annotator groups to avoid biases. Data and code are available at \\url{https://github.com/SonyAI/a_view_from_somewhere}",
    "checked": true,
    "id": "20987b31af44ef816496bee3eb1ca54549c0a6c6",
    "semantic_title": "a view from somewhere: human-centric face representations",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=U_2kuqoTcB": {
    "title": "Identifiability Results for Multimodal Contrastive Learning",
    "volume": "poster",
    "abstract": "Contrastive learning is a cornerstone underlying recent progress in multi-view and multimodal learning, e.g., in representation learning with image/caption pairs. While its effectiveness is not yet fully understood, a line of recent work reveals that contrastive learning can invert the data generating process and recover ground truth latent factors shared between views. In this work, we present new identifiability results for multimodal contrastive learning, showing that it is possible to recover shared factors in a more general setup than the multi-view setting studied previously. Specifically, we distinguish between the multi-view setting with one generative mechanism (e.g., multiple cameras of the same type) and the multimodal setting that is characterized by distinct mechanisms (e.g., cameras and microphones). Our work generalizes previous identifiability results by redefining the generative process in terms of distinct mechanisms with modality-specific latent variables. We prove that contrastive learning can block-identify latent factors shared between modalities, even when there are nontrivial dependencies between factors. We empirically verify our identifiability results with numerical simulations and corroborate our findings on a complex multimodal dataset of image/text pairs. Zooming out, our work provides a theoretical basis for multimodal representation learning and explains in which settings multimodal contrastive learning can be effective in practice",
    "checked": true,
    "id": "5be07671e7b1baeac5ce4ea7d3ee2bd0364aa701",
    "semantic_title": "identifiability results for multimodal contrastive learning",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=dZrQR7OR11": {
    "title": "Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach",
    "volume": "poster",
    "abstract": "The canonical formulation of federated learning treats it as a distributed optimization problem where the model parameters are optimized against a global loss function that decomposes across client loss functions. A recent alternative formulation instead treats federated learning as a distributed inference problem, where the goal is to infer a global posterior from partitioned client data (Al-Shedivat et al., 2021). This paper extends the inference view and describes a variational inference formulation of federated learning where the goal is to find a global variational posterior that well-approximates the true posterior. This naturally motivates an expectation propagation approach to federated learning (FedEP), where approximations to the global posterior are iteratively refined through probabilistic message-passing between the central server and the clients. We conduct an extensive empirical study across various algorithmic considerations and describe practical strategies for scaling up expectation propagation to the modern federated setting. We apply FedEP on standard federated learning benchmarks and find that it outperforms strong baselines in terms of both convergence speed and accuracy",
    "checked": true,
    "id": "aca66f06cc3f988ebfc0420b3f969466a6984fef",
    "semantic_title": "federated learning as variational inference: a scalable expectation propagation approach",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=JLR_B7n_Wqr": {
    "title": "Latent Graph Inference using Product Manifolds",
    "volume": "poster",
    "abstract": "Graph Neural Networks usually rely on the assumption that the graph topology is available to the network as well as optimal for the downstream task. Latent graph inference allows models to dynamically learn the intrinsic graph structure of problems where the connectivity patterns of data may not be directly accessible. In this work, we generalize the discrete Differentiable Graph Module (dDGM) for latent graph learning. The original dDGM architecture used the Euclidean plane to encode latent features based on which the latent graphs were generated. By incorporating Riemannian geometry into the model and generating more complex embedding spaces, we can improve the performance of the latent graph inference system. In particular, we propose a computationally tractable approach to produce product manifolds of constant curvature model spaces that can encode latent features of varying structure. The latent representations mapped onto the inferred product manifold are used to compute richer similarity measures that are leveraged by the latent graph learning model to obtain optimized latent graphs. Moreover, the curvature of the product manifold is learned during training alongside the rest of the network parameters and based on the downstream task, rather than it being a static embedding space. Our novel approach is tested on a wide range of datasets, and outperforms the original dDGM model",
    "checked": true,
    "id": "e5c6d0f131945cf0ee1a2e8e1b4e4f91e5ed4d05",
    "semantic_title": "latent graph inference using product manifolds",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=lh-HRYxuoRr": {
    "title": "This Looks Like It Rather Than That: ProtoKNN For Similarity-Based Classifiers",
    "volume": "poster",
    "abstract": "Among research on the interpretability of deep learning models, the 'this looks like that' framework with ProtoPNet has attracted significant attention. By combining the strong power of deep learning models with the interpretability of case-based inference, ProtoPNet can achieve high accuracy while keeping its reasoning process interpretable. Many methods based on ProtoPNet have emerged to take advantage of this benefit, but despite their practical usefulness, they run into difficulty when utilizing similarity-based classifiers, e.g., in domains where unknown class samples exist. This is because ProtoPNet and its variants adopt the training process specific to linear classifiers, which allows the prototypes to represent useful image features for class recognition. Due to this difficulty, the effectiveness of similarity-based classifiers (e.g., k-nearest neighbor (KNN)) on the 'this looks like that' framework have not been sufficiently examined. To alleviate this problem, we propose ProtoKNN, an extension of ProtoPNet that adopts KNN classifiers. Extensive experiments on multiple open datasets demonstrate that the proposed method can achieve competitive results with a state-of-the-art method",
    "checked": true,
    "id": "62c7996dcd38b1ac9f246a41d96821475fa0ad89",
    "semantic_title": "this looks like it rather than that: protoknn for similarity-based classifiers",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=uBKBoix9NXa": {
    "title": "Understanding weight-magnitude hyperparameters in training binary networks",
    "volume": "poster",
    "abstract": "Binary Neural Networks (BNNs) are compact and efficient by using binary weights instead of real-valued weights. Current BNNs use latent real-valued weights during training, where several training hyper-parameters are inherited from real-valued networks. The interpretation of several of these hyperparameters is based on the magnitude of the real-valued weights. For BNNs, however, the magnitude of binary weights is not meaningful, and thus it is unclear what these hyperparameters actually do. One example is weight-decay, which aims to keep the magnitude of real-valued weights small. Other examples are latent weight initialization, the learning rate, and learning rate decay, which influence the magnitude of the real-valued weights. The magnitude is interpretable for real-valued weights, but loses its meaning for binary weights. In this paper we offer a new interpretation of these magnitude-based hyperparameters based on higher-order gradient filtering during network optimization. Our analysis makes it possible to understand how magnitude-based hyperparameters influence the training of binary networks which allows for new optimization filters specifically designed for binary neural networks that are independent of their real-valued interpretation. Moreover, our improved understanding reduces the number of hyperparameters, which in turn eases the hyperparameter tuning effort which may lead to better hyperparameter values for improved accuracy. Code is available at https://github.com/jorisquist/Understanding-WM-HP-in-BNNs",
    "checked": true,
    "id": "6d0c8934f62d605d7345de39759cd2b1df393e4d",
    "semantic_title": "understanding weight-magnitude hyperparameters in training binary networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pv1GPQzRrC8": {
    "title": "Imitating Human Behaviour with Diffusion Models",
    "volume": "poster",
    "abstract": "Diffusion models have emerged as powerful generative models in the text-to-image domain. This paper studies their application as observation-to-action models for imitating human behaviour in sequential environments. Human behaviour is stochastic and multimodal, with structured correlations between action dimensions. Meanwhile, standard modelling choices in behaviour cloning are limited in their expressiveness and may introduce bias into the cloned policy. We begin by pointing out the limitations of these choices. We then propose that diffusion models are an excellent fit for imitating human behaviour, since they learn an expressive distribution over the joint action space. We introduce several innovations to make diffusion models suitable for sequential environments; designing suitable architectures, investigating the role of guidance, and developing reliable sampling strategies. Experimentally, diffusion models closely match human demonstrations in a simulated robotic control task and a modern 3D gaming environment",
    "checked": true,
    "id": "b43330013a5abcccd366d71f2f66c493c790abc6",
    "semantic_title": "imitating human behaviour with diffusion models",
    "citation_count": 238,
    "authors": []
  },
  "https://openreview.net/forum?id=6iVJOtr2zL2": {
    "title": "Contrastive Meta-Learning for Partially Observable Few-Shot Learning",
    "volume": "poster",
    "abstract": "Many contrastive and meta-learning approaches learn representations by identifying common features in multiple views. However, the formalism for these approaches generally assumes features to be shared across views to be captured coherently. We consider the problem of learning a unified representation from partial observations, where useful features may be present in only some of the views. We approach this through a probabilistic formalism enabling views to map to representations with different levels of uncertainty in different components; these views can then be integrated with one another through marginalisation over that uncertainty. Our approach, Partial Observation Experts Modelling (POEM), then enables us to meta-learn consistent representations from partial observations. We evaluate our approach on an adaptation of a comprehensive few-shot learning benchmark, Meta-Dataset, and demonstrate the benefits of POEM over other meta-learning methods at representation learning from partial observations. We further demonstrate the utility of POEM by meta-learning to represent an environment from partial views observed by an agent exploring the environment",
    "checked": true,
    "id": "21419f1f1d6d5332308786b9c5fef1dcb81d271c",
    "semantic_title": "contrastive meta-learning for partially observable few-shot learning",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=ATLEl_izD87": {
    "title": "Enhancing the Inductive Biases of Graph Neural ODE for Modeling Physical Systems",
    "volume": "poster",
    "abstract": "Neural networks with physics-based inductive biases such as Lagrangian neural networks (LNNs), and Hamiltonian neural networks (HNNs) learn the dynamics of physical systems by encoding strong inductive biases. Alternatively, Neural ODEs with appropriate inductive biases have also been shown to give similar performances. However, these models, when applied to particle-based systems, are transductive in nature and hence, do not generalize to large system sizes. In this paper, we present a graph-based neural ODE, GNODE, to learn the time evolution of dynamical systems. Further, we carefully analyze the role of different inductive biases on the performance of GNODE. We show that similar to LNN and HNN, encoding the constraints explicitly can significantly improve the training efficiency and performance of GNODE significantly. Our experiments also assess the value of additional inductive biases, such as Newton's third law, on the final performance of the model. We demonstrate that inducing these biases can enhance the performance of the model by orders of magnitude in terms of both energy violation and rollout error. Interestingly, we observe that the GNODE trained with the most effective inductive biases, namely MCGNODE, outperforms the graph versions of LNN and HNN, namely, Lagrangian graph networks (LGN) and Hamiltonian graph networks (HGN) in terms of energy violation error by ∼4 orders of magnitude for a pendulum system, and ∼2 orders of magnitude for spring systems. These results suggest that NODE-based systems can give competitive performances with energy-conserving neural networks by employing appropriate inductive biases",
    "checked": true,
    "id": "aeb80ca92243aa1862f81caa58e8505c0c68255a",
    "semantic_title": "enhancing the inductive biases of graph neural ode for modeling physical systems",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=cA77NrVEuqn": {
    "title": "Efficient Planning in a Compact Latent Action Space",
    "volume": "poster",
    "abstract": "Planning-based reinforcement learning has shown strong performance in tasks in discrete and low-dimensional continuous action spaces. However, planning usually brings significant computational overhead for decision making, so scaling such methods to high-dimensional action spaces remains challenging. To advance efficient planning for high-dimensional continuous control, we propose Trajectory Autoencoding Planner (TAP), which learns low-dimensional latent action codes with a state-conditional VQ-VAE. The decoder of the VQ-VAE thus serves as a novel dynamics model that takes latent actions and current state as input and reconstructs long-horizon trajectories. During inference time, given a starting state, TAP searches over discrete latent actions to find trajectories that have both high probability under the training distribution and high predicted cumulative reward. Empirical evaluation in the offline RL setting demonstrates low decision latency which is indifferent to the growing raw action dimensionality. For Adroit robotic hand manipulation tasks with high-dimensional continuous action space, TAP surpasses existing model-based methods by a large margin and also beats strong model-free actor-critic baselines",
    "checked": true,
    "id": "748c9aa5a31f279fa07b84238aa5ba748e9df40d",
    "semantic_title": "efficient planning in a compact latent action space",
    "citation_count": 43,
    "authors": []
  },
  "https://openreview.net/forum?id=8JsaP7j1cL0": {
    "title": "Correlative Information Maximization Based Biologically Plausible Neural Networks for Correlated Source Separation",
    "volume": "poster",
    "abstract": "The brain effortlessly extracts latent causes of stimuli, but how it does this at the network level remains unknown. Most prior attempts at this problem proposed neural networks that implement independent component analysis, which works under the limitation that latent elements are mutually independent. Here, we relax this limitation and propose a biologically plausible neural network that extracts correlated latent sources by exploiting information about their domains. To derive this network, we choose maximum correlative information transfer from inputs to outputs as the separation objective under the constraint that the outputs are restricted to their presumed sets. The online formulation of this optimization problem naturally leads to neural networks with local learning rules. Our framework incorporates infinitely many source domain choices and flexibly models complex latent structures. Choices of simplex or polytopic source domains result in networks with piecewise-linear activation functions. We provide numerical examples to demonstrate the superior correlated source separation capability for both synthetic and natural sources",
    "checked": true,
    "id": "9c091005eedd74d73839b912b5266c4f499f21be",
    "semantic_title": "correlative information maximization based biologically plausible neural networks for correlated source separation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=9Nj_gNdvqYf": {
    "title": "Leveraging Importance Weights in Subset Selection",
    "volume": "poster",
    "abstract": "We present a subset selection algorithm designed to work with arbitrary model families in a practical batch setting. In such a setting, an algorithm can sample examples one at a time but, in order to limit overhead costs, is only able to update its state (i.e. further train model weights) once a large enough batch of examples is selected. Our algorithm, IWeS, selects examples by importance sampling where the sampling probability assigned to each example is based on the entropy of models trained on previously selected batches. IWeS admits significant performance improvement compared to other subset selection algorithms for seven publicly available datasets. Additionally, it is competitive in an active learning setting, where the label information is not available at selection time. We also provide an initial theoretical analysis to support our importance weighting approach, proving generalization and sampling rate bounds",
    "checked": true,
    "id": "2ecff5518f04f768b5450cb02d30783eec9d846d",
    "semantic_title": "leveraging importance weights in subset selection",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=CROlOA9Nd8C": {
    "title": "Copy is All You Need",
    "volume": "poster",
    "abstract": "The dominant text generation models compose the output by sequentially selecting words from a fixed vocabulary. In this paper, we formulate text generation as progressively copying text segments (e.g., words or phrases) from an existing text collection. We compute the contextualized representations of meaningful text segments and index them using efficient vector search toolkits. The task of text generation is then decomposed into a series of copy-and-paste operations: at each time step, we seek suitable text spans from the text collection rather than selecting from a standalone vocabulary. Experiments on the standard language modeling benchmark (WikiText-103) show that our approach achieves better generation quality according to both automatic and human evaluations. Besides, its inference efficiency is comparable to token-level autoregressive models thanks to the reduction of decoding steps. We also show that our approach allows for effective domain adaptation by simply switching to domain-specific text collection without extra training. Finally, we observe that our approach attains additional performance gains by simply scaling up to larger text collections, again without further training.\\footnote{Our source codes are publicly available at \\url{https://github.com/gmftbyGMFTBY/Copyisallyouneed}.}",
    "checked": true,
    "id": "8b25d0065d30ed3c9e6a6cae94de53ef132d656d",
    "semantic_title": "copy is all you need",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=-CA8yFkPc7O": {
    "title": "Why adversarial training can hurt robust accuracy",
    "volume": "poster",
    "abstract": "Machine learning classifiers with high test accuracy often perform poorly under adversarial attacks. It is commonly believed that adversarial training alleviates this issue. In this paper, we demonstrate that, surprisingly, the opposite can be true for a natural class of perceptible perturbations --- even though adversarial training helps when enough data is available, it may in fact hurt robust generalization in the small sample size regime. We first prove this phenomenon for a high-dimensional linear classification setting with noiseless observations. Using intuitive insights from the proof, we could surprisingly find perturbations on standard image datasets for which this behavior persists. Specifically, it occurs for perceptible attacks that effectively reduce class information such as object occlusions or corruptions",
    "checked": true,
    "id": "1dd1795f6fa368b61c78c3afccf194bbcf25ed3a",
    "semantic_title": "why adversarial training can hurt robust accuracy",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=xjb563TH-GH": {
    "title": "Representational Dissimilarity Metric Spaces for Stochastic Neural Networks",
    "volume": "poster",
    "abstract": "Quantifying similarity between neural representations---e.g. hidden layer activation vectors---is a perennial problem in deep learning and neuroscience research. Existing methods compare deterministic responses (e.g. artificial networks that lack stochastic layers) or averaged responses (e.g., trial-averaged firing rates in biological data). However, these measures of _deterministic_ representational similarity ignore the scale and geometric structure of noise, both of which play important roles in neural computation. To rectify this, we generalize previously proposed shape metrics (Williams et al. 2021) to quantify differences in _stochastic_ representations. These new distances satisfy the triangle inequality, and thus can be used as a rigorous basis for many supervised and unsupervised analyses. Leveraging this novel framework, we find that the stochastic geometries of neurobiological representations of oriented visual gratings and naturalistic scenes respectively resemble untrained and trained deep network representations. Further, we are able to more accurately predict certain network attributes (e.g. training hyperparameters) from its position in stochastic (versus deterministic) shape space",
    "checked": true,
    "id": "6d2b13928cf9db71a0c245bbbdbdb7a07bd9247d",
    "semantic_title": "representational dissimilarity metric spaces for stochastic neural networks",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=dMMPUvNSYJr": {
    "title": "Sequential Learning of Neural Networks for Prequential MDL",
    "volume": "poster",
    "abstract": "Minimum Description Length (MDL) provides a framework and an objective for principled model evaluation. It formalizes Occam's Razor and can be applied to data from non-stationary sources. In the prequential formulation of MDL, the objective is to minimize the cumulative next-step log-loss when sequentially going through the data and using previous observations for parameter estimation. It thus closely resembles a continual- or online-learning problem. In this study, we evaluate approaches for computing prequential description lengths for image classification datasets with neural networks. Considering the computational cost, we find that online-learning with rehearsal has favorable performance compared to the previously widely used block-wise estimation. We propose forward-calibration to better align the models predictions with the empirical observations and introduce replay-streams, a minibatch incremental training technique to efficiently implement approximate random replay while avoiding large in-memory replay buffers. As a result, we present description lengths for a suite of image classification datasets that improve upon previously reported results by large margins",
    "checked": true,
    "id": "39e4e6a4672c57495cb88b9c36137f397db11612",
    "semantic_title": "sequential learning of neural networks for prequential mdl",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=lIu-ixf-Tzf": {
    "title": "Learning topology-preserving data representations",
    "volume": "poster",
    "abstract": "We propose a method for learning topology-preserving data representations (dimensionality reduction). The method aims to provide topological similarity between the data manifold and its latent representation via enforcing the similarity in topological features (clusters, loops, 2D voids, etc.) and their localization. The core of the method is the minimization of the Representation Topology Divergence (RTD) between original high-dimensional data and low-dimensional representation in latent space. RTD minimization provides closeness in topological features with strong theoretical guarantees. We develop a scheme for RTD differentiation and apply it as a loss term for the autoencoder. The proposed method \"RTD-AE\" better preserves the global structure and topology of the data manifold than state-of-the-art competitors as measured by linear correlation, triplet distance ranking accuracy, and Wasserstein distance between persistence barcodes",
    "checked": true,
    "id": "e2f69d96c20acce19ca53a4086d9ac702237cead",
    "semantic_title": "learning topology-preserving data representations",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=4C8ChYvMYBn": {
    "title": "The Curious Case of Benign Memorization",
    "volume": "poster",
    "abstract": "Despite the empirical advances of deep learning across a variety of learning tasks, our theoretical understanding of its success is still very restricted. One of the key challenges is the overparametrized nature of modern models, enabling complete overfitting of the data even if the labels are randomized, i.e. networks can completely \\textit{memorize} all given patterns. While such a memorization capacity seems worrisome, in this work we show that under training protocols that include \\textit{data augmentation}, neural networks learn to memorize entirely random labels in a benign way, i.e. they learn embeddings that lead to highly non-trivial performance under nearest neighbour probing. We demonstrate that deep models have the surprising ability to separate noise from signal by distributing the task of memorization and feature learning to different layers. As a result, only the very last layers are used for memorization, while preceding layers encode performant features which remain largely unaffected by the label noise. We explore the intricate role of the augmentations used for training and identify a memorization-generalization trade-off in terms of their diversity, marking a clear distinction to all previous works. Finally, we give a first explanation for the emergence of benign memorization by showing that \\textit{malign} memorization under data augmentation is infeasible due to the insufficient capacity of the model for the increased sample size. As a consequence, the network is forced to leverage the correlated nature of the augmentations and as a result learns meaningful features. To complete the picture, a better theory of feature learning in deep neural networks is required to fully understand the origins of this phenomenon",
    "checked": true,
    "id": "d9cf800c64398382d13e6a59b986cd9748111676",
    "semantic_title": "the curious case of benign memorization",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=Ph5cJSfD2XN": {
    "title": "Unbiased Supervised Contrastive Learning",
    "volume": "poster",
    "abstract": "Many datasets are biased, namely they contain easy-to-learn features that are highly correlated with the target class only in the dataset but not in the true underlying distribution of the data. For this reason, learning unbiased models from biased data has become a very relevant research topic in the last years. In this work, we tackle the problem of learning representations that are robust to biases. We first present a margin-based theoretical framework that allows us to clarify why recent contrastive losses (InfoNCE, SupCon, etc.) can fail when dealing with biased data. Based on that, we derive a novel formulation of the supervised contrastive loss ($\\epsilon$-SupInfoNCE), providing more accurate control of the minimal distance between positive and negative samples. Furthermore, thanks to our theoretical framework, we also propose FairKL, a new debiasing regularization loss, that works well even with extremely biased data. We validate the proposed losses on standard vision datasets including CIFAR10, CIFAR100, and ImageNet, and we assess the debiasing capability of FairKL with $\\epsilon$-SupInfoNCE, reaching state-of-the-art performance on a number of biased datasets, including real instances of biases \"in the wild\"",
    "checked": true,
    "id": "50a5411bd2121d1bdc1b775887715c920f3f7dd8",
    "semantic_title": "unbiased supervised contrastive learning",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=mE91GkXYipg": {
    "title": "Compositional Prompt Tuning with Motion Cues for Open-vocabulary Video Relation Detection",
    "volume": "poster",
    "abstract": "Prompt tuning with large-scale pretrained vision-language models empowers open-vocabulary prediction trained on limited base categories, e.g., object classification and detection. In this paper, we propose compositional prompt tuning with motion cues: an extended prompt tuning paradigm for compositional predictions of video data. In particular, we present Relation Prompt (RePro) for Open-vocabulary Video Visual Relation Detection (Open-VidVRD), where conventional prompt tuning is easily biased to certain subject-object combinations and motion patterns. To this end, RePro addresses the two technical challenges of Open-VidVRD: 1) the prompt tokens should respect the two different semantic roles of subject and object, and 2) the tuning should account for the diverse spatiotemporal motion patterns of the subject-object compositions. Our RePro achieves a new state-of-the-art performance on two VidVRD benchmarks of not only the base training object and predicate categories, but also the unseen ones. Extensive ablations also demonstrate the effectiveness of the proposed compositional and multi-mode design of prompt. Code is available at https://github.com/Dawn-LX/OpenVoc-VidVRD",
    "checked": true,
    "id": "a4ecbaf6c57e08157b268ac22bba507abb6b24d5",
    "semantic_title": "compositional prompt tuning with motion cues for open-vocabulary video relation detection",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=fSa5IjNMmmi": {
    "title": "Multi-objective optimization via equivariant deep hypervolume approximation",
    "volume": "poster",
    "abstract": "Optimizing multiple competing objectives is a common problem across science and industry. The inherent inextricable trade-off between those objectives leads one to the task of exploring their Pareto front. A meaningful quantity for the purpose of the latter is the hypervolume indicator, which is used in Bayesian Optimization (BO) and Evolutionary Algorithms (EAs). However, the computational complexity for the calculation of the hypervolume scales unfavorably with increasing number of objectives and data points, which restricts its use in those common multi-objective optimization frameworks. To overcome these restrictions, previous work has focused on approximating the hypervolume using deep learning. In this work, we propose a novel deep learning architecture to approximate the hypervolume function, which we call DeepHV. For better sample efficiency and generalization, we exploit the fact that the hypervolume is scale equivariant in each of the objectives as well as permutation invariant w.r.t. both the objectives and the samples, by using a deep neural network that is equivariant w.r.t. the combined group of scalings and permutations. We show through an ablation study that including these symmetries leads to significantly improved model accuracy. We evaluate our method against exact, and approximate hypervolume methods in terms of accuracy, computation time, and generalization. We also apply and compare our methods to state-of-the-art multi-objective BO methods and EAs on a range of synthetic and real-world benchmark test cases. The results show that our methods are promising for such multi-objective optimization tasks",
    "checked": true,
    "id": "db1ef4f77340da13e0a3b87e348938acaeba7742",
    "semantic_title": "multi-objective optimization via equivariant deep hypervolume approximation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=nG9RF9z1yy3": {
    "title": "DiffusER: Diffusion via Edit-based Reconstruction",
    "volume": "poster",
    "abstract": "In text generation, models that generate text from scratch one token at a time are currently the dominant paradigm. Despite being performant, these models lack the ability to revise existing text, which limits their usability in many practical scenarios. We look to address this, with DiffusER (Diffusion via Edit-based Reconstruction), a new edit-based generative model for text based on denoising diffusion models -- a class of models that use a Markov chain of denoising steps to incrementally generate data. DiffusER is not only a strong generative model in general, rivalling autoregressive models on several tasks spanning machine translation, summarization, and style transfer; it can also perform other varieties of generation that standard autoregressive models are not well-suited for. For instance, we demonstrate that DiffusER makes it possible for a user to condition generation on a prototype, or an incomplete sequence, and continue revising based on previous edit steps",
    "checked": true,
    "id": "0004c4e27e54f13577951416d8ed476e93f00ef9",
    "semantic_title": "diffuser: diffusion via edit-based reconstruction",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=7oPAgqxNb20": {
    "title": "DynaMS: Dyanmic Margin Selection for Efficient Deep Learning",
    "volume": "poster",
    "abstract": "The great success of deep learning is largely driven by training over-parameterized models on massive datasets. To avoid excessive computation, extracting and training only on the most informative subset is drawing increasing attention. Nevertheless, it is still an open question how to select such a subset on which the model trained generalizes on par with the full data. In this paper, we propose dynamic margin selection (DynaMS). DynaMS leverages the distance from candidate samples to the classification boundary to construct the subset, and the subset is dynamically updated during model training. We show that DynaMS converges with large probability, and for the first time show both in theory and practice that dynamically updating the subset can result in better generalization over previous works. To reduce the additional computation incurred by the selection, a light parameter sharing proxy (PSP) is designed. PSP is able to faithfully evaluate instances with respect to the current model, which is necessary for dynamic selection. Extensive analysis and experiments demonstrate the superiority of the proposed approach in data selection against many state-of-the-art counterparts on benchmark datasets",
    "checked": true,
    "id": "a30f8afa2d867fcf26c7ae504d0885a933589702",
    "semantic_title": "dynams: dyanmic margin selection for efficient deep learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=n6H86gW8u0d": {
    "title": "TANGOS: Regularizing Tabular Neural Networks through Gradient Orthogonalization and Specialization",
    "volume": "poster",
    "abstract": "Despite their success with unstructured data, deep neural networks are not yet a panacea for structured tabular data. In the tabular domain, their efficiency crucially relies on various forms of regularization to prevent overfitting and provide strong generalization performance. Existing regularization techniques include broad modelling decisions such as choice of architecture, loss functions, and optimization methods. In this work, we introduce Tabular Neural Gradient Orthogonalization and Specialization (TANGOS), a novel framework for regularization in the tabular setting built on latent unit attributions. The gradient attribution of an activation with respect to a given input feature suggests how the neuron attends to that feature, and is often employed to interpret the predictions of deep networks. In TANGOS, we take a different approach and incorporate neuron attributions directly into training to encourage orthogonalization and specialization of latent attributions in a fully-connected network. Our regularizer encourages neurons to focus on sparse, non-overlapping input features and results in a set of diverse and specialized latent units. In the tabular domain, we demonstrate that our approach can lead to improved out-of-sample generalization performance, outperforming other popular regularization methods. We provide insight into why our regularizer is effective and demonstrate that TANGOS can be applied jointly with existing methods to achieve even greater generalization performance",
    "checked": true,
    "id": "b720dc316737256f71b2e2de35bb8836e79cf2e7",
    "semantic_title": "tangos: regularizing tabular neural networks through gradient orthogonalization and specialization",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=udNhDCr2KQe": {
    "title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
    "volume": "poster",
    "abstract": "Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models. With the ability of Transformer to handle visual input, the proposed Recurrent Transformer can straightforwardly be applied to visual constraint reasoning problems while successfully addressing the symbol grounding problem. We also show how to leverage deductive knowledge of discrete constraints in the Transformer's inductive learning to achieve sample-efficient learning and semi-supervised learning for CSPs",
    "checked": true,
    "id": "6a74efe6cf4526058d1a7dd2289e1b3d4fbb418e",
    "semantic_title": "learning to solve constraint satisfaction problems with recurrent transformer",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=GrpU6dxFmMN": {
    "title": "Improving the imputation of missing data with Markov Blanket discovery",
    "volume": "poster",
    "abstract": "The process of imputation of missing data typically relies on generative and regression models. These approaches often operate on the unrealistic assumption that all of the data features are directly related with one another, and use all of the available features to impute missing values. In this paper, we propose a novel Markov Blanket discovery approach to determine the optimal feature set for a given variable by considering both observed variables and missingness of partially observed variables to account for systematic missingness. We then incorporate this method to the learning process of the state-of-the-art MissForest imputation algorithm, such that it informs MissForest which features to consider to impute missing values, depending on the variable the missing value belongs to. Experiments across different case studies and multiple imputation algorithms show that the proposed solution improves imputation accuracy, both under random and systematic missingness",
    "checked": true,
    "id": "588fac3a8154e447d2db3a594447991a49b74e48",
    "semantic_title": "improving the imputation of missing data with markov blanket discovery",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=kDSmxOspsXQ": {
    "title": "Boosting the Cycle Counting Power of Graph Neural Networks with I$^2$-GNNs",
    "volume": "poster",
    "abstract": "Message Passing Neural Networks (MPNNs) are a widely used class of Graph Neural Networks (GNNs). The limited representational power of MPNNs inspires the study of provably powerful GNN architectures. However, knowing one model is more powerful than another gives little insight about what functions they can or cannot express. It is still unclear whether these models are able to approximate specific functions such as counting certain graph substructures, which is essential for applications in biology, chemistry and social network analysis. Motivated by this, we propose to study the counting power of Subgraph MPNNs, a recent and popular class of powerful GNN models that extract rooted subgraphs for each node, assign the root node a unique identifier and encode the root node's representation within its rooted subgraph. Specifically, we prove that Subgraph MPNNs fail to count more-than-4-cycles at node level, implying that node representations cannot correctly encode the surrounding substructures like ring systems with more than four atoms. To overcome this limitation, we propose I$^2$-GNNs to extend Subgraph MPNNs by assigning different identifiers for the root node and its neighbors in each subgraph. I$^2$-GNNs' discriminative power is shown to be strictly stronger than Subgraph MPNNs and partially stronger than the 3-WL test. More importantly, I$^2$-GNNs are proven capable of counting all 3, 4, 5 and 6-cycles, covering common substructures like benzene rings in organic chemistry, while still keeping linear complexity. To the best of our knowledge, it is the first linear-time GNN model that can count 6-cycles with theoretical guarantees. We validate its counting power in cycle counting tasks and demonstrate its competitive performance in molecular prediction benchmarks",
    "checked": false,
    "id": "85aee44aecc922041ead3dc112aa7c323f2c3c05",
    "semantic_title": "boosting the cycle counting power of graph neural networks with i2-gnns",
    "citation_count": 52,
    "authors": []
  },
  "https://openreview.net/forum?id=WlbG820mRH-": {
    "title": "Fundamental Limits in Formal Verification of Message-Passing Neural Networks",
    "volume": "poster",
    "abstract": "Output reachability and adversarial robustness are among the most relevant safety properties of neural networks. We show that in the context of Message Passing Neural Networks (MPNN), a common Graph Neural Network (GNN) model, formal verification is impossible. In particular, we show that output reachability of graph-classifier MPNN, working over graphs of unbounded size, non-trivial degree and sufficiently expressive node labels, cannot be verified formally: there is no algorithm that answers correctly (with yes or no), given an MPNN, whether there exists some valid input to the MPNN such that the corresponding output satisfies a given specification. However, we also show that output reachability and adversarial robustness of node-classifier MPNN can be verified formally when a limit on the degree of input graphs is given a priori. We discuss the implications of these results, for the purpose of obtaining a complete picture of the principle possibility to formally verify GNN, depending on the expressiveness of the involved GNN models and input-output specifications",
    "checked": true,
    "id": "e71a31fee2ba7db5232ef0bb00bb2afb1c8f870a",
    "semantic_title": "fundamental limits in formal verification of message-passing neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4DU_HCijfJp": {
    "title": "Short-Term Memory Convolutions",
    "volume": "poster",
    "abstract": "The real-time processing of time series signals is a critical issue for many real-life applications. The idea of real-time processing is especially important in audio domain as the human perception of sound is sensitive to any kind of disturbance in perceived signals, especially the lag between auditory and visual modalities. The rise of deep learning (DL) models complicated the landscape of signal processing. Although they often have superior quality compared to standard DSP methods, this advantage is diminished by higher latency. In this work we propose novel method for minimization of inference time latency and memory consumption, called Short-Term Memory Convolution (STMC) and its transposed counterpart. The main advantage of STMC is the low latency comparable to long short-term memory (LSTM) networks. Furthermore, the training of STMC-based models is faster and more stable as the method is based solely on convolutional neural networks (CNNs). In this study we demonstrate an application of this solution to a U-Net model for a speech separation task and GhostNet model in acoustic scene classification (ASC) task. In case of speech separation we achieved a 5-fold reduction in inference time and a 2-fold reduction in latency without affecting the output quality. The inference time for ASC task was up to 4 times faster while preserving the original accuracy",
    "checked": true,
    "id": "84f681bba83ba75cc7962ec37297415fe8cd7674",
    "semantic_title": "short-term memory convolutions",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=PfpEtB3-csK": {
    "title": "LexMAE: Lexicon-Bottlenecked Pretraining for Large-Scale Retrieval",
    "volume": "poster",
    "abstract": "In large-scale retrieval, the lexicon-weighting paradigm, learning weighted sparse representations in vocabulary space, has shown promising results with high quality and low latency. Despite it deeply exploiting the lexicon-representing capability of pre-trained language models, a crucial gap remains between language modeling and lexicon-weighting retrieval -- the former preferring certain or low-entropy words whereas the latter favoring pivot or high-entropy words -- becoming the main barrier to lexicon-weighting performance for large-scale retrieval. To bridge this gap, we propose a brand-new pre-training framework, lexicon-bottlenecked masked autoencoder (LexMAE), to learn importance-aware lexicon representations. Essentially, we present a lexicon-bottlenecked module between a normal language modeling encoder and a weakened decoder, where a continuous bag-of-words bottleneck is constructed to learn a lexicon-importance distribution in an unsupervised fashion. The pre-trained LexMAE is readily transferred to the lexicon-weighting retrieval via fine-tuning. On the ad-hoc retrieval benchmark, MS-Marco, it achieves 42.6% MRR@10 with 45.8 QPS for the passage dataset and 44.4% MRR@100 with 134.8 QPS for the document dataset, by a CPU machine. And LexMAE shows state-of-the-art zero-shot transfer capability on BEIR benchmark with 12 datasets",
    "checked": true,
    "id": "b2fbfaefd5d02244cc9a8dbfc6643869d754f022",
    "semantic_title": "lexmae: lexicon-bottlenecked pretraining for large-scale retrieval",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=pHMpgT5xWaE": {
    "title": "A GNN-Guided Predict-and-Search Framework for Mixed-Integer Linear Programming",
    "volume": "poster",
    "abstract": "Mixed-integer linear programming (MILP) is widely employed for modeling combinatorial optimization problems. In practice, similar MILP instances with only coefficient variations are routinely solved, and machine learning (ML) algorithms are capable of capturing common patterns across these MILP instances. In this work, we combine ML with optimization and propose a novel predict-and-search framework for efficiently identifying high-quality feasible solutions. Specifically, we first utilize graph neural networks to predict the marginal probability of each variable, and then search for the best feasible solution within a properly defined ball around the predicted solution. We conduct extensive experiments on public datasets, and computational results demonstrate that our proposed framework achieves 51.1% and 9.9% performance improvements to MILP solvers SCIP and Gurobi on primal gaps, respectively",
    "checked": true,
    "id": "887d11c3fbc1a87a8bfe97bd53cfedab89496f99",
    "semantic_title": "a gnn-guided predict-and-search framework for mixed-integer linear programming",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=piIsx-G3Gux": {
    "title": "On Explaining Neural Network Robustness with Activation Path",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9d242b5c0c00fc36002161deb6a124f2c624e982",
    "semantic_title": "on explaining neural network robustness with activation path",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=O_lFCPaF48t": {
    "title": "Structure by Architecture: Structured Representations without Regularization",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "9e1f82ce5f6a31d7d0ca48d33235c7f5f6466bc0",
    "semantic_title": "structure by architecture: disentangled representations without regularization",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=1UCaQYUdE_o": {
    "title": "Understanding Neural Coding on Latent Manifolds by Sharing Features and Dividing Ensembles",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "049ee767e458d83adb939be704c0d42474c742f9",
    "semantic_title": "understanding neural coding on latent manifolds by sharing features and dividing ensembles",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=q-PbpHD3EOk": {
    "title": "Learning Fast and Slow for Online Time Series Forecasting",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4d755a5a66a8c46b722b44613788085191524e11",
    "semantic_title": "learning fast and slow for online time series forecasting",
    "citation_count": 45,
    "authors": []
  },
  "https://openreview.net/forum?id=FtOxgKe_Zg2": {
    "title": "Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b9ec37d028fae61752c33a55fb88bd27e6cb8c4d",
    "semantic_title": "guess the instruction! flipped learning makes language models stronger zero-shot learners",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=_BoPed4tYww": {
    "title": "Timing is Everything: Learning to Act Selectively with Costly Actions and Budgetary Constraints",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2bb383228065a17cbb3de273d2572e2097115612",
    "semantic_title": "timing is everything: learning to act selectively with costly actions and budgetary constraints",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=Lt8bMlhiwx2": {
    "title": "DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only Training",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a20e7e5e4338644d24145e71a9b89100af87e5d0",
    "semantic_title": "decap: decoding clip latents for zero-shot captioning via text-only training",
    "citation_count": 103,
    "authors": []
  },
  "https://openreview.net/forum?id=wZ2SVhOTzBX": {
    "title": "That Label's got Style: Handling Label Style Bias for Uncertain Image Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "86865f196771187283a232c793cb9c1015e624af",
    "semantic_title": "that label's got style: handling label style bias for uncertain image segmentation",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=sAJDi9lD06L": {
    "title": "Holistic Adversarially Robust Pruning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "47cbf414220626972ce2b609bf13514f98beef43",
    "semantic_title": "non-uniform adversarially robust pruning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=syfgJE6nFRW": {
    "title": "PASHA: Efficient HPO and NAS with Progressive Resource Allocation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bd4579d383337f2402dade25323c285f7d109ae8",
    "semantic_title": "pasha: efficient hpo and nas with progressive resource allocation",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=3VO1y5N7K1H": {
    "title": "StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c1ff3661f3edf5e0571da6d8aaf852cd6df84318",
    "semantic_title": "stabledr: stabilized doubly robust learning for recommendation on data missing not at random",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=aoDyX6vSqsd": {
    "title": "Sampling-based inference for large linear models, with application to linearised Laplace",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2c1ac6f0ee28c8c86f46f90a3a29fd75cf9f4aaf",
    "semantic_title": "sampling-based inference for large linear models, with application to linearised laplace",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=5-Df3tljit7": {
    "title": "Defending against Adversarial Audio via Diffusion Model",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f4b0306d9ddf227f3fe5167981035c4b50310389",
    "semantic_title": "defending against adversarial audio via diffusion model",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=Jifob4dSh99": {
    "title": "Theoretical Characterization of the Generalization Performance of Overfitted Meta-Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "346d43e185d6593b2d5d7c156fdaf26a335cf445",
    "semantic_title": "theoretical characterization of the generalization performance of overfitted meta-learning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=_hHYaKu0jcj": {
    "title": "Robust Explanation Constraints for Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ac9c07f716e43db03b088d3e17bc9093c271662e",
    "semantic_title": "robust explanation constraints for neural networks",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=42zs3qa2kpy": {
    "title": "Offline Reinforcement Learning via High-Fidelity Generative Behavior Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0f1402c536cc3cbbcb73b06f96289e50a34ca3cf",
    "semantic_title": "offline reinforcement learning via high-fidelity generative behavior modeling",
    "citation_count": 140,
    "authors": []
  },
  "https://openreview.net/forum?id=rB6TpjAuSRy": {
    "title": "CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "707bd332d2c21dc5eb1f02a52d4a0506199aae76",
    "semantic_title": "cogvideo: large-scale pretraining for text-to-video generation via transformers",
    "citation_count": 753,
    "authors": []
  },
  "https://openreview.net/forum?id=tXc-riXhmx": {
    "title": "Revisit Finetuning strategy for Few-Shot Learning to Transfer the Emdeddings",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "827d1a5fc6d174c83aff9bcee61852e0afbc0cab",
    "semantic_title": "revisit finetuning strategy for few-shot learning to transfer the emdeddings",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=Vf6WcUDnY7c": {
    "title": "Optimizing Spca-based Continual Learning: A Theoretical Approach",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5e293220b40d27559dc9aaa34582a088f1081671",
    "semantic_title": "optimizing spca-based continual learning: a theoretical approach",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=UYcIheNY9Pf": {
    "title": "Value Memory Graph: A Graph-Structured World Model for Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "67b950f8d31e1b5dfed49993ef4d809e3bf0cc2c",
    "semantic_title": "value memory graph: a graph-structured world model for offline reinforcement learning",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=Tuk3Pqaizx": {
    "title": "Sampling-free Inference for Ab-Initio Potential Energy Surface Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "36fa9d7494ef86b2afe775f63053d662210d1e15",
    "semantic_title": "sampling-free inference for ab-initio potential energy surface networks",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=5cAI0qXxyv": {
    "title": "$\\mathscr{N}$-WL: A New Hierarchy of Expressivity for Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "1c465203bd9cf02eaaf64b3d9b3699c276a31ec3",
    "semantic_title": "𝒩-wl: a new hierarchy of expressivity for graph neural networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=47B_ctC4pJ": {
    "title": "Learning Input-agnostic Manipulation Directions in StyleGAN with Text Guidance",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2e5dc2bbfd04bd965635218d10716b4fb996ca7c",
    "semantic_title": "learning input-agnostic manipulation directions in stylegan with text guidance",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=CW6KmU5wPh": {
    "title": "DAVA: Disentangling Adversarial Variational Autoencoder",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9d3284c33da3c60ee6c12ec88495e70b7aff33dd",
    "semantic_title": "dava: disentangling adversarial variational autoencoder",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=EIgLnNx_lC": {
    "title": "TDR-CL: Targeted Doubly Robust Collaborative Learning for Debiased Recommendations",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "84b9802042f29f4490eb36c2ac69a8ce9cdb2196",
    "semantic_title": "tdr-cl: targeted doubly robust collaborative learning for debiased recommendations",
    "citation_count": 45,
    "authors": []
  },
  "https://openreview.net/forum?id=7IG0wsTND7w": {
    "title": "Domain Generalisation via Domain Adaptation: An Adversarial Fourier Amplitude Approach",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8b2b1bd8601d61b5c5a1ea04f7f4ca674a4fe6b0",
    "semantic_title": "domain generalisation via domain adaptation: an adversarial fourier amplitude approach",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=J_Cja7cpgW": {
    "title": "Consolidator: Mergable Adapter with Group Connections for Visual Adaptation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "a17d4a542bcdd1d5ade9b64cef093fa76437f96a",
    "semantic_title": "consolidator: mergeable adapter with grouped connections for visual adaptation",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=hxUwnEGxW87": {
    "title": "Statistical Theory of Differentially Private Marginal-based Data Synthesis Algorithms",
    "volume": "poster",
    "abstract": "Marginal-based methods achieve promising performance in the synthetic data competition hosted by the National Institute of Standards and Technology (NIST). To deal with high-dimensional data, the distribution of synthetic data is represented by a probabilistic graphical model (e.g., a Bayesian network), while the raw data distribution is approximated by a collection of low-dimensional marginals. Differential privacy (DP) is guaranteed by introducing random noise to each low-dimensional marginal distribution. Despite its promising performance in practice, the statistical properties of marginal-based methods are rarely studied in the literature. In this paper, we study DP data synthesis algorithms based on Bayesian networks (BN) from a statistical perspective. We establish a rigorous accuracy guarantee for BN-based algorithms, where the errors are measured by the total variation (TV) distance or the $L^2$ distance. Related to downstream machine learning tasks, an upper bound for the utility error of the DP synthetic data is also derived. To complete the picture, we establish a lower bound for TV accuracy that holds for every $\\epsilon$-DP synthetic data generator",
    "checked": true,
    "id": "f4ca8df6c831936d466a683fbc5a7ccd306341f8",
    "semantic_title": "statistical theory of differentially private marginal-based data synthesis algorithms",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=J3Y7cgZOOS": {
    "title": "Anti-Symmetric DGN: a stable architecture for Deep Graph Networks",
    "volume": "poster",
    "abstract": "Deep Graph Networks (DGNs) currently dominate the research landscape of learning from graphs, due to their efficiency and ability to implement an adaptive message-passing scheme between the nodes. However, DGNs are typically limited in their ability to propagate and preserve long-term dependencies between nodes, i.e., they suffer from the over-squashing phenomena. As a result, we can expect them to under-perform, since different problems require to capture interactions at different (and possibly large) radii in order to be effectively solved. In this work, we present Anti-Symmetric Deep Graph Networks (A-DGNs), a framework for stable and non-dissipative DGN design, conceived through the lens of ordinary differential equations. We give theoretical proof that our method is stable and non-dissipative, leading to two key results: long-range information between nodes is preserved, and no gradient vanishing or explosion occurs in training. We empirically validate the proposed approach on several graph benchmarks, showing that A-DGN yields to improved performance and enables to learn effectively even when dozens of layers are used",
    "checked": true,
    "id": "e516225868c0247007f917213f5b23434299e5df",
    "semantic_title": "anti-symmetric dgn: a stable architecture for deep graph networks",
    "citation_count": 65,
    "authors": []
  },
  "https://openreview.net/forum?id=xPkJYRsQGM": {
    "title": "Contrastive Learning for Unsupervised Domain Adaptation of Time Series",
    "volume": "poster",
    "abstract": "Unsupervised domain adaptation (UDA) aims at learning a machine learning model using a labeled source domain that performs well on a similar yet different, unlabeled target domain. UDA is important in many applications such as medicine, where it is used to adapt risk scores across different patient cohorts. In this paper, we develop a novel framework for UDA of time series data, called CLUDA. Specifically, we propose a contrastive learning framework to learn contextual representations in multivariate time series, so that these preserve label information for the prediction task. In our framework, we further capture the variation in the contextual representations between source and target domain via a custom nearest-neighbor contrastive learning. To the best of our knowledge, ours is the first framework to learn domain-invariant, contextual representation for UDA of time series data. We evaluate our framework using a wide range of time series datasets to demonstrate its effectiveness and show that it achieves state-of-the-art performance for time series UDA",
    "checked": true,
    "id": "c8cb6aa0a02cc1a94f2065921a9346d72273e590",
    "semantic_title": "contrastive learning for unsupervised domain adaptation of time series",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=47KG_AvNqeZ": {
    "title": "Online Low Rank Matrix Completion",
    "volume": "poster",
    "abstract": "We study the problem of online low-rank matrix completion with $\\mathsf{M}$ users, $\\mathsf{N}$ items and $\\mathsf{T}$ rounds. In each round, the algorithm recommends one item per user, for which it gets a (noisy) reward sampled from a low-rank user-item preference matrix. The goal is to design a method with sub-linear regret (in $\\mathsf{T}$) and nearly optimal dependence on $\\mathsf{M}$ and $\\mathsf{N}$. The problem can be easily mapped to the standard multi-armed bandit problem where each item is an independent arm, but that leads to poor regret as the correlation between arms and users is not exploited. On the other hand, exploiting the low-rank structure of reward matrix is challenging due to non-convexity of the low-rank manifold. We first demonstrate that the low-rank structure can be exploited using a simple explore-then-commit (ETC) approach that ensures a regret of $O(\\mathsf{polylog} (\\mathsf{M}+\\mathsf{N}) \\mathsf{T}^{2/3})$. That is, roughly only $\\mathsf{polylog} (\\mathsf{M}+\\mathsf{N})$ item recommendations are required per user to get a non-trivial solution. We then improve our result for the rank-$1$ setting which in itself is quite challenging and encapsulates some of the key issues. Here, we propose OCTAL (Online Collaborative filTering using iterAtive user cLustering) that guarantees nearly optimal regret of $O(\\mathsf{polylog} (\\mathsf{M}+\\mathsf{N}) \\mathsf{T}^{1/2})$. OCTAL is based on a novel technique of clustering users that allows iterative elimination of items and leads to a nearly optimal minimax rate",
    "checked": true,
    "id": "a0afd8f249ac8dd702dc087e6f6c67087f130ab0",
    "semantic_title": "online low rank matrix completion",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=5Egggz1q575": {
    "title": "Explaining RL Decisions with Trajectories",
    "volume": "poster",
    "abstract": "Explanation is a key component for the adoption of reinforcement learning (RL) in many real-world decision-making problems. In the literature, the explanation is often provided by saliency attribution to the features of the RL agent's state. In this work, we propose a complementary approach to these explanations, particularly for offline RL, where we attribute the policy decisions of a trained RL agent to the trajectories encountered by it during training. To do so, we encode trajectories in offline training data individually as well as collectively (encoding a set of trajectories). We then attribute policy decisions to a set of trajectories in this encoded space by estimating the sensitivity of the decision with respect to that set. Further, we demonstrate the effectiveness of the proposed approach in terms of quality of attributions as well as practical scalability in diverse environments that involve both discrete and continuous state and action spaces such as grid-worlds, video games (Atari) and continuous control (MuJoCo). We also conduct a human study on a simple navigation task to observe how their understanding of the task compares with data attributed for a trained RL policy",
    "checked": true,
    "id": "c3a6432b582d2c3bbffa3c8f69276f9b42939829",
    "semantic_title": "explaining rl decisions with trajectories",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=rnRiiHw8Vy": {
    "title": "FastFill: Efficient Compatible Model Update",
    "volume": "poster",
    "abstract": "In many retrieval systems the original high dimensional data (e.g., images) is mapped to a lower dimensional feature through a learned embedding model. The task of retrieving the most similar data from a gallery set to a given query data is performed through similarity comparison on features. When the embedding model is updated, it might produce features that are not comparable/compatible with features already in the gallery computed with the old model. Subsequently, all features in the gallery need to be re-computed using the new embedding model -- a computationally expensive process called backfilling. Recently, compatible representation learning methods have been proposed to avoid back-filling. Despite their relative success, there is an inherent trade-off between new model performance and its compatibility with the old model. In this work, we introduce FastFill: a compatible model update process using feature alignment and policy based partial backfilling to promptly elevate retrieval performance. We show that previous backfilling strategies suffer from decreased performance and demonstrate the importance of both the training objective and the ordering in online partial backfilling. We propose a new training method for feature alignment between old and new embedding models using uncertainty estimation. Compared to previous works, we obtain significantly improved backfilling results on a variety of datasets: mAP on ImageNet (+4.4%), Places-365 (+2.7%), and VGG-Face2 (+1.3%). Further, we demonstrate that when updating a biased model with FastFill, the minority subgroup accuracy gap promptly vanishes with a small fraction of partial backfilling",
    "checked": true,
    "id": "628bc8e9a8408a780b61295373568f68617851ec",
    "semantic_title": "fastfill: efficient compatible model update",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=WsUMeHPo-2": {
    "title": "Learnable Graph Convolutional Attention Networks",
    "volume": "poster",
    "abstract": "Existing Graph Neural Networks (GNNs) compute the message exchange between nodes by either aggregating uniformly (convolving) the features of all the neighbor- ing nodes, or by applying a non-uniform score (attending) to the features. Recent works have shown the strengths and weaknesses of the resulting GNN architectures, respectively, GCNs and GATs. In this work, we aim at exploiting the strengths of both approaches to their full extent. To this end, we first introduce the graph convolutional attention layer (CAT), which relies on convolutions to compute the attention scores. Unfortunately, as in the case of GCNs and GATs, we show that there exists no clear winner between the three—neither theoretically nor in practice—as their performance directly depends on the nature of the data (i.e., of the graph and features). This result brings us to the main contribution of our work, the learnable graph convolutional attention network (L-CAT): a GNN architecture that automatically interpolates between GCN, GAT and CAT in each layer, by adding only two scalar parameters. Our results demonstrate that L-CAT is able to efficiently combine different GNN layers along the network, outperforming competing methods in a wide range of datasets, and resulting in a more robust model that reduces the need of cross-validating",
    "checked": true,
    "id": "a1ec107ca5e5e3ec22949aa283462947180ffd66",
    "semantic_title": "learnable graph convolutional attention networks",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=N4K5ck-BTT": {
    "title": "Scaffolding a Student to Instill Knowledge",
    "volume": "poster",
    "abstract": "We propose a novel knowledge distillation (KD) method to selectively instill teacher knowledge into a student model motivated by situations where the student's capacity is significantly smaller than that of the teachers. In vanilla KD, the teacher primarily sets a predictive target for the student to follow, and we posit that this target is overly optimistic due to the student's lack of capacity. We develop a novel scaffolding scheme where the teacher, in addition to setting a predictive target, also scaffolds the student's prediction by censoring hard-to-learn examples. Scaffolding utilizes the same information as the teacher's soft-max predictions as inputs, and in this sense, our proposal can be viewed as a natural variant of vanilla KD. We show on synthetic examples that censoring hard-examples leads to smoothening the student's loss landscape so that the student encounters fewer local minima. As a result, it has good generalization properties. Against vanilla KD, we achieve improved performance and are comparable to more intrusive techniques that leverage feature matching on benchmark datasets",
    "checked": true,
    "id": "196aee8659046d2d98ef072cdb9eb7d124024699",
    "semantic_title": "scaffolding a student to instill knowledge",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=a4COps0uokg": {
    "title": "User-Interactive Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "Offline reinforcement learning algorithms still lack trust in practice due to the risk that the learned policy performs worse than the original policy that generated the dataset or behaves in an unexpected way that is unfamiliar to the user. At the same time, offline RL algorithms are not able to tune their most important hyperparameter - the proximity of the learned policy to the original policy. We propose an algorithm that allows the user to tune this hyperparameter at runtime, thereby addressing both of the above mentioned issues simultaneously. This allows users to start with the original behavior and grant successively greater deviation, as well as stopping at any time when the policy deteriorates or the behavior is too far from the familiar one",
    "checked": true,
    "id": "41479416d858bacfaa01bfc068ceb86466d542e9",
    "semantic_title": "user-interactive offline reinforcement learning",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=EBS4C77p_5S": {
    "title": "SLTUNET: A Simple Unified Model for Sign Language Translation",
    "volume": "poster",
    "abstract": "Despite recent successes with neural models for sign language translation (SLT), translation quality still lags behind spoken languages because of the data scarcity and modality gap between sign video and text. To address both problems, we investigate strategies for cross-modality representation sharing for SLT. We propose SLTUNET, a simple unified neural model designed to support multiple SLTrelated tasks jointly, such as sign-to-gloss, gloss-to-text and sign-to-text translation. Jointly modeling different tasks endows SLTUNET with the capability to explore the cross-task relatedness that could help narrow the modality gap. In addition, this allows us to leverage the knowledge from external resources, such as abundant parallel data used for spoken-language machine translation (MT). We show in experiments that SLTUNET achieves competitive and even state-of-the-art performance on PHOENIX-2014T and CSL-Daily when augmented with MT data and equipped with a set of optimization techniques. We further use the DGS Corpus for end-to-end SLT for the first time. It covers broader domains with a significantly larger vocabulary, which is more challenging and which we consider to allow for a more realistic assessment of the current state of SLT than the former two. Still, SLTUNET obtains improved results on the DGS Corpus. Code is available at https://github.com/bzhangGo/sltunet",
    "checked": true,
    "id": "3bbc8841012fdb5971d1c86dff528edd8590f1b8",
    "semantic_title": "sltunet: a simple unified model for sign language translation",
    "citation_count": 38,
    "authors": []
  },
  "https://openreview.net/forum?id=iUYpN14qjTF": {
    "title": "Understanding the Generalization of Adam in Learning Neural Networks with Proper Regularization",
    "volume": "poster",
    "abstract": "Adaptive gradient methods such as Adam have gained increasing popularity in deep learning optimization. However, it has been observed in many deep learning applications such as image classification, Adam can converge to a different solution with a worse test error compared to (stochastic) gradient descent, even with a fine-tuned regularization. In this paper, we provide a theoretical explanation for this phenomenon: we show that in the nonconvex setting of learning over-parameterized two-layer convolutional neural networks starting from the same random initialization, for a class of data distributions (inspired from image data), Adam and gradient descent (GD) can converge to different global solutions of the training objective with provably different generalization errors, even with weight decay regularization. In contrast, we show that if the training objective is convex, and the weight decay regularization is employed, any optimization algorithms including Adam and GD will converge to the same solution if the training is successful. This suggests that the generalization gap between Adam and SGD in the presence of weight decay regularization is closely tied to the nonconvex landscape of deep learning optimization, which cannot be covered by the recent neural tangent kernel (NTK) based analysis",
    "checked": true,
    "id": "1d9cefa796b0c7340b1af35356e93b3715a39973",
    "semantic_title": "understanding the generalization of adam in learning neural networks with proper regularization",
    "citation_count": 46,
    "authors": []
  },
  "https://openreview.net/forum?id=0_TxFpAsEI": {
    "title": "A law of adversarial risk, interpolation, and label noise",
    "volume": "poster",
    "abstract": "In supervised learning, it has been shown that label noise in the data can be interpolated without penalties on test accuracy. We show that interpolating label noise induces adversarial vulnerability, and prove the first theorem showing the relationship between label noise and adversarial risk for any data distribution. Our results are almost tight if we do not make any assumptions on the inductive bias of the learning algorithm. We then investigate how different components of this problem affect this result including properties of the distribution. We also discuss non-uniform label noise distributions; and prove a new theorem showing uniform label noise induces nearly as large an adversarial risk as the worst poisoning with the same noise rate. Then, we provide theoretical and empirical evidence that uniform label noise is more harmful than typical real-world label noise. Finally, we show how inductive biases amplify the effect of label noise and argue the need for future work in this direction",
    "checked": true,
    "id": "c0c3da6e4511112f5c79c98966b7c6f2b0158c77",
    "semantic_title": "a law of adversarial risk, interpolation, and label noise",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=nchvKfvNeX0": {
    "title": "Learning ReLU networks to high uniform accuracy is intractable",
    "volume": "poster",
    "abstract": "Statistical learning theory provides bounds on the necessary number of training samples needed to reach a prescribed accuracy in a learning problem formulated over a given target class. This accuracy is typically measured in terms of a generalization error, that is, an expected value of a given loss function. However, for several applications --- for example in a security-critical context or for problems in the computational sciences --- accuracy in this sense is not sufficient. In such cases, one would like to have guarantees for high accuracy on every input value, that is, with respect to the uniform norm. In this paper we precisely quantify the number of training samples needed for any conceivable training algorithm to guarantee a given uniform accuracy on any learning problem formulated over target classes containing (or consisting of) ReLU neural networks of a prescribed architecture. We prove that, under very general assumptions, the minimal number of training samples for this task scales exponentially both in the depth and the input dimension of the network architecture",
    "checked": true,
    "id": "7b230724d2f2da51140fc603301f32b00f05ccd4",
    "semantic_title": "learning relu networks to high uniform accuracy is intractable",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=MnEjsw-vj-X": {
    "title": "Active Learning for Object Detection with Evidential Deep Learning and Hierarchical Uncertainty Aggregation",
    "volume": "poster",
    "abstract": "Despite the huge success of object detection, the training process still requires an immense amount of labeled data. Although various active learning solutions for object detection have been proposed, most existing works do not take advantage of epistemic uncertainty, which is an important metric for capturing the usefulness of the sample. Also, previous works pay little attention to the attributes of each bounding box (e.g., nearest object, box size) when computing the informativeness of an image. In this paper, we propose a new active learning strategy for object detection that overcomes the shortcomings of prior works. To make use of epistemic uncertainty, we adopt evidential deep learning (EDL) and propose a new module termed model evidence head (MEH), that makes EDL highly compatible with object detection. Based on the computed epistemic uncertainty of each bounding box, we propose hierarchical uncertainty aggregation (HUA) for obtaining the informativeness of an image. HUA realigns all bounding boxes into multiple levels based on the attributes and aggregates uncertainties in a bottom-up order, to effectively capture the context within the image. Experimental results show that our method outperforms existing state-of-the-art methods by a considerable margin",
    "checked": true,
    "id": "9ba1bc3f605e0d07a61bd44ed109096b448ac318",
    "semantic_title": "active learning for object detection with evidential deep learning and hierarchical uncertainty aggregation",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=5spDgWmpY6x": {
    "title": "How Sharpness-Aware Minimization Minimizes Sharpness?",
    "volume": "poster",
    "abstract": "Sharpness-Aware Minimization (SAM) is a highly effective regularization technique for improving the generalization of deep neural networks for various settings. However, the underlying working of SAM remains elusive because of various intriguing approximations in the theoretical characterizations. SAM intends to penalize a notion of sharpness of the model but implements a computationally efficient variant; moreover, a third notion of sharpness was used for proving generalization guarantees. The subtle differences in these notions of sharpness can indeed lead to significantly different empirical results. This paper rigorously nails down the exact sharpness notion that SAM regularizes and clarifies the underlying mechanism. We also show that the two steps of approximations in the original motivation of SAM individually lead to inaccurate local conclusions, but their combination accidentally reveals the correct effect, when full-batch gradients are applied. Furthermore, we also prove that the stochastic version of SAM in fact regularizes the third notion of sharpness mentioned above, which is most likely to be the preferred notion for practical performance. The key mechanism behind this intriguing phenomenon is the alignment between the gradient and the top eigenvector of Hessian when SAM is applied",
    "checked": true,
    "id": "8d0f6d369b2a0adb77a127f4f3085facfc7acce5",
    "semantic_title": "how sharpness-aware minimization minimizes sharpness?",
    "citation_count": 38,
    "authors": []
  },
  "https://openreview.net/forum?id=xtbog7cfsr": {
    "title": "The Implicit Bias of Minima Stability in Multivariate Shallow ReLU Networks",
    "volume": "poster",
    "abstract": "We study the type of solutions to which stochastic gradient descent converges when used to train a single hidden-layer multivariate ReLU network with the quadratic loss. Our results are based on a dynamical stability analysis. In the univariate case, it was shown that linearly stable minima correspond to network functions (predictors), whose second derivative has a bounded weighted $L^1$ norm. Notably, the bound gets smaller as the step size increases, implying that training with a large step size leads to `smoother' predictors. Here we generalize this result to the multivariate case, showing that a similar result applies to the Laplacian of the predictor. We demonstrate the tightness of our bound on the MNIST dataset, and show that it accurately captures the behavior of the solutions as a function of the step size. Additionally, we prove a depth separation result on the approximation power of ReLU networks corresponding to stable minima of the loss. Specifically, although shallow ReLU networks are universal approximators, we prove that stable shallow networks are not. Namely, there is a function that cannot be well-approximated by stable single hidden-layer ReLU networks trained with a non-vanishing step size. This is while the same function can be realized as a stable two hidden-layer ReLU network. Finally, we prove that if a function is sufficiently smooth (in a Sobolev sense) then it can be approximated arbitrarily well using shallow ReLU networks that correspond to stable solutions of gradient descent",
    "checked": true,
    "id": "f9b464154bda6ffaafa462c4e8a8253907db95b9",
    "semantic_title": "the implicit bias of minima stability in multivariate shallow relu networks",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=5KUPKjHYD-l": {
    "title": "MAST: Masked Augmentation Subspace Training for Generalizable Self-Supervised Priors",
    "volume": "poster",
    "abstract": "Recent Self-Supervised Learning (SSL) methods are able to learn feature representations that are invariant to different data augmentations, which can then be transferred to downstream tasks of interest. However, different downstream tasks require different invariances for their best performance, so the optimal choice of augmentations for SSL depends on the target task. In this paper, we aim to learn self-supervised features that generalize well across a variety of downstream tasks (e.g., object classification, detection and instance segmentation) without knowing any task information beforehand. We do so by Masked Augmentation Subspace Training (or MAST) to encode in the single feature space the priors from different data augmentations in a factorized way. Specifically, we disentangle the feature space into separate subspaces, each induced by a learnable mask that selects relevant feature dimensions to model invariance to a specific augmentation. We show the success of MAST in jointly capturing generalizable priors from different augmentations, using both unique and shared features across the subspaces. We further show that MAST benefits from uncertainty modeling to reweight ambiguous samples from strong augmentations that may cause similarity mismatch in each subspace. Experiments demonstrate that MAST consistently improves generalization on various downstream tasks, while being task-agnostic and efficient during SSL. We also provide interesting insights about how different augmentations are related and how uncertainty reflects learning difficulty",
    "checked": true,
    "id": "05e73f7da4b0a52b409459b69fcaed950b0b09f3",
    "semantic_title": "mast: masked augmentation subspace training for generalizable self-supervised priors",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=yHIIM9BgOo": {
    "title": "Graph-based Deterministic Policy Gradient for Repetitive Combinatorial Optimization Problems",
    "volume": "poster",
    "abstract": "We propose an actor-critic framework for graph-based machine learning pipelines with non-differentiable blocks, and apply it to repetitive combinatorial optimization problems (COPs) under hard constraints. Repetitive COP refers to problems to be solved repeatedly on graphs of the same or slowly changing topology but rapidly changing node or edge weights. Compared to one-shot COPs, repetitive COPs often rely on fast heuristics to solve one instance of the problem before the next one arrives, at the cost of a relatively large optimality gap. Through numerical experiments on several discrete optimization problems, we show that our approach can learn reusable node or edge representations to reduce the optimality gap of fast heuristics for independent repetitive COPs, and can optimize the long-term objectives for repetitive COPs embedded in graph-based Markov decision processes. Source code at https://github.com/XzrTGMu/twin-nphard",
    "checked": true,
    "id": "325acb7159234497a0938c019d21ed7bc7f9514f",
    "semantic_title": "graph-based deterministic policy gradient for repetitive combinatorial optimization problems",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=2mvALOAWaxY": {
    "title": "Lower Bounds on the Depth of Integral ReLU Neural Networks via Lattice Polytopes",
    "volume": "poster",
    "abstract": "We prove that the set of functions representable by ReLU neural networks with integer weights strictly increases with the network depth while allowing arbitrary width. More precisely, we show that $\\lceil\\log_2(n)\\rceil$ hidden layers are indeed necessary to compute the maximum of $n$ numbers, matching known upper bounds. Our results are based on the known duality between neural networks and Newton polytopes via tropical geometry. The integrality assumption implies that these Newton polytopes are lattice polytopes. Then, our depth lower bounds follow from a parity argument on the normalized volume of faces of such polytopes",
    "checked": true,
    "id": "f5519a5db0fd7427532a7ef26d6b32b9d20041f0",
    "semantic_title": "lower bounds on the depth of integral relu neural networks via lattice polytopes",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=JLLTtEdh1ZY": {
    "title": "Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees",
    "volume": "poster",
    "abstract": "Although deep reinforcement learning (DRL) has many success stories, the large-scale deployment of policies learned through these advanced techniques in safety-critical scenarios is hindered by their lack of formal guarantees. Variational Markov Decision Processes (VAE-MDPs) are discrete latent space models that provide a reliable framework for distilling formally verifiable controllers from any RL policy. While the related guarantees address relevant practical aspects such as the satisfaction of performance and safety properties, the VAE approach suffers from several learning flaws (posterior collapse, slow learning speed, poor dynamics estimates), primarily due to the absence of abstraction and representation guarantees to support latent optimization. We introduce the Wasserstein auto-encoded MDP (WAE-MDP), a latent space model that fixes those issues by minimizing a penalized form of the optimal transport between the behaviors of the agent executing the original policy and the distilled policy, for which the formal guarantees apply. Our approach yields bisimulation guarantees while learning the distilled policy, allowing concrete optimization of the abstraction and representation model quality. Our experiments show that, besides distilling policies up to 10 times faster, the latent model quality is indeed better in general. Moreover, we present experiments from a simple time-to-failure verification algorithm on the latent space. The fact that our approach enables such simple verification techniques highlights its applicability",
    "checked": true,
    "id": "48a56cdff6979009ab5f38596c68a810605556ab",
    "semantic_title": "wasserstein auto-encoded mdps: formal verification of efficiently distilled rl policies with many-sided guarantees",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=OTbRTIY4YS": {
    "title": "Global Explainability of GNNs via Logic Combination of Learned Concepts",
    "volume": "poster",
    "abstract": "While instance-level explanation of GNN is a well-studied problem with plenty of approaches being developed, providing a global explanation for the behaviour of a GNN is much less explored, despite its potential in interpretability and debugging. Existing solutions either simply list local explanations for a given class, or generate a synthetic prototypical graph with maximal score for a given class, completely missing any combinatorial aspect that the GNN could have learned. In this work, we propose GLGExplainer (Global Logic-based GNN Explainer), the first Global Explainer capable of generating explanations as arbitrary Boolean combinations of learned graphical concepts. GLGExplainer is a fully differentiable architecture that takes local explanations as inputs and combines them into a logic formula over graphical concepts, represented as clusters of local explanations. Contrary to existing solutions, GLGExplainer provides accurate and human-interpretable global explanations that are perfectly aligned with ground-truth explanations (on synthetic data) or match existing domain knowledge (on real-world data). Extracted formulas are faithful to the model predictions, to the point of providing insights into some occasionally incorrect rules learned by the model, making GLGExplainer a promising diagnostic tool for learned GNNs",
    "checked": true,
    "id": "5bce30f98caa5decac63ef6cf58f5580b4c17883",
    "semantic_title": "global explainability of gnns via logic combination of learned concepts",
    "citation_count": 65,
    "authors": []
  },
  "https://openreview.net/forum?id=JpRExTbl1-": {
    "title": "Gradient Gating for Deep Multi-Rate Learning on Graphs",
    "volume": "poster",
    "abstract": "We present Gradient Gating (G$^2$), a novel framework for improving the performance of Graph Neural Networks (GNNs). Our framework is based on gating the output of GNN layers with a mechanism for multi-rate flow of message passing information across nodes of the underlying graph. Local gradients are harnessed to further modulate message passing updates. Our framework flexibly allows one to use any basic GNN layer as a wrapper around which the multi-rate gradient gating mechanism is built. We rigorously prove that G$^2$ alleviates the oversmoothing problem and allows the design of deep GNNs. Empirical results are presented to demonstrate that the proposed framework achieves state-of-the-art performance on a variety of graph learning tasks, including on large-scale heterophilic graphs",
    "checked": true,
    "id": "8bae2d456875bd21d09d759850a3b92f32b0f9c5",
    "semantic_title": "gradient gating for deep multi-rate learning on graphs",
    "citation_count": 62,
    "authors": []
  },
  "https://openreview.net/forum?id=sKWlRDzPfd7": {
    "title": "MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "Open-ended learning methods that automatically generate a curriculum of increasingly challenging tasks serve as a promising avenue toward generally capable reinforcement learning agents. Existing methods adapt curricula independently over either environment parameters (in single-agent settings) or co-player policies (in multi-agent settings). However, the strengths and weaknesses of co-players can manifest themselves differently depending on environmental features. It is thus crucial to consider the dependency between the environment and co-player when shaping a curriculum in multi-agent domains. In this work, we use this insight and extend Unsupervised Environment Design (UED) to multi-agent environments. We then introduce Multi-Agent Environment Design Strategist for Open-Ended Learning (MAESTRO), the first multi-agent UED approach for two-player zero-sum settings. MAESTRO efficiently produces adversarial, joint curricula over both environments and co-players and attains minimax-regret guarantees at Nash equilibrium. Our experiments show that MAESTRO outperforms a number of strong baselines on competitive two-player games, spanning discrete and continuous control settings",
    "checked": true,
    "id": "84a0c5ee814b88d8f422e928c004658a981bd373",
    "semantic_title": "maestro: open-ended environment design for multi-agent reinforcement learning",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=gu-SC0dpkvw": {
    "title": "Almost Linear Constant-Factor Sketching for $\\ell_1$ and Logistic Regression",
    "volume": "poster",
    "abstract": "We improve upon previous oblivious sketching and turnstile streaming results for $\\ell_1$ and logistic regression, giving a much smaller sketching dimension achieving $O(1)$-approximation and yielding an efficient optimization problem in the sketch space. Namely, we achieve for any constant $c>0$ a sketching dimension of $\\tilde{O}(d^{1+c})$ for $\\ell_1$ regression and $\\tilde{O}(\\mu d^{1+c})$ for logistic regression, where $\\mu$ is a standard measure that captures the complexity of compressing the data. For $\\ell_1$-regression our sketching dimension is near-linear and improves previous work which either required $\\Omega(\\log d)$-approximation with this sketching dimension, or required a larger $\\operatorname{poly}(d)$ number of rows. Similarly, for logistic regression previous work had worse $\\operatorname{poly}(\\mu d)$ factors in its sketching dimension. We also give a tradeoff that yields a $1+\\varepsilon$ approximation in input sparsity time by increasing the total size to $(d\\log(n)/\\varepsilon)^{O(1/\\varepsilon)}$ for $\\ell_1$ and to $(\\mu d\\log(n)/\\varepsilon)^{O(1/\\varepsilon)}$ for logistic regression. Finally, we show that our sketch can be extended to approximate a regularized version of logistic regression where the data-dependent regularizer corresponds to the variance of the individual logistic losses",
    "checked": false,
    "id": "fa8c80bb3c44d5f4e8f6b8936f7bf9dbcc635eb8",
    "semantic_title": "almost linear constant-factor sketching for 𝓁1 and logistic regression",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=7tJyBmu9iCj": {
    "title": "Neural-based classification rule learning for sequential data",
    "volume": "poster",
    "abstract": "Discovering interpretable patterns for classification of sequential data is of key importance for a variety of fields, ranging from genomics to fraud detection or more generally interpretable decision-making. In this paper, we propose a novel differentiable fully interpretable method to discover both local and global patterns (i.e. catching a relative or absolute temporal dependency) for rule-based binary classification. It consists of a convolutional binary neural network with an interpretable neural filter and a training strategy based on dynamically-enforced sparsity. We demonstrate the validity and usefulness of the approach on synthetic datasets and on an open-source peptides dataset. Key to this end-to-end differentiable method is that the expressive patterns used in the rules are learned alongside the rules themselves",
    "checked": true,
    "id": "95b0634c6ff3fc372c36e380232d881f6af757f1",
    "semantic_title": "neural-based classification rule learning for sequential data",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=ORp91sAbzI": {
    "title": "Leveraging Unlabeled Data to Track Memorization",
    "volume": "poster",
    "abstract": "Deep neural networks may easily memorize noisy labels present in real-world data, which degrades their ability to generalize. It is therefore important to track and evaluate the robustness of models against noisy label memorization. We propose a metric, called $\\textit{susceptibility}$, to gauge such memorization for neural networks. Susceptibility is simple and easy to compute during training. Moreover, it does not require access to ground-truth labels and it only uses unlabeled data. We empirically show the effectiveness of our metric in tracking memorization on various architectures and datasets and provide theoretical insights into the design of the susceptibility metric. Finally, we show through extensive experiments on datasets with synthetic and real-world label noise that one can utilize susceptibility and the overall training accuracy to distinguish models that maintain a low memorization on the training set and generalize well to unseen clean data",
    "checked": true,
    "id": "e8bcdd6bb6e3692e760ae73e0d44458dd549d5ed",
    "semantic_title": "leveraging unlabeled data to track memorization",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=SmufNDN90G": {
    "title": "Policy-Based Self-Competition for Planning Problems",
    "volume": "poster",
    "abstract": "AlphaZero-type algorithms may stop improving on single-player tasks in case the value network guiding the tree search is unable to approximate the outcome of an episode sufficiently well. One technique to address this problem is transforming the single-player task through self-competition. The main idea is to compute a scalar baseline from the agent's historical performances and to reshape an episode's reward into a binary output, indicating whether the baseline has been exceeded or not. However, this baseline only carries limited information for the agent about strategies how to improve. We leverage the idea of self-competition and directly incorporate a historical policy into the planning process instead of its scalar performance. Based on the recently introduced Gumbel AlphaZero (GAZ), we propose our algorithm GAZ ‘Play-to-Plan' (GAZ PTP), in which the agent learns to find strong trajectories by planning against possible strategies of its past self. We show the effectiveness of our approach in two well-known combinatorial optimization problems, the Traveling Salesman Problem and the Job-Shop Scheduling Problem. With only half of the simulation budget for search, GAZ PTP consistently outperforms all selected single-player variants of GAZ",
    "checked": true,
    "id": "0d8742c18f5c0a509a52a76228c8a0d86a472d7d",
    "semantic_title": "policy-based self-competition for planning problems",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=KkazG4lgKL": {
    "title": "Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization with Modern Hopfield Energy",
    "volume": "poster",
    "abstract": "Out-of-Distribution (OOD) detection is essential for safety-critical applications of deep neural networks. OOD detection is challenging since DNN models may produce very high logits value even for OOD samples. Hence, it is of great difficulty to discriminate OOD data by directly adopting Softmax on output logits as the confidence score. Differently, we detect the OOD sample with Hopfield energy in a store-then-compare paradigm. In more detail, penultimate layer outputs on the training set are considered as the representations of in-distribution (ID) data. Thus they can be transformed into stored patterns that serve as anchors to measure the discrepancy of unseen data for OOD detection. Starting from the energy function defined in Modern Hopfield Network for the discrepancy score calculation, we derive a simplified version SHE with theoretical analysis. In SHE, we utilize only one stored pattern to present each class, and these patterns can be obtained by simply averaging the penultimate layer outputs of training samples within this class. SHE has the advantages of hyperparameterfree and high computational efficiency. The evaluations of nine widely-used OOD datasets show the promising performance of such a simple yet effective approach and its superiority over State-of-the-Art models. Code is available at https://github.com/zjs975584714/SHE ood detection",
    "checked": true,
    "id": "cfd5982c81538f128bd7aa755929c8c0f4ee2bbe",
    "semantic_title": "out-of-distribution detection based on in-distribution data patterns memorization with modern hopfield energy",
    "citation_count": 76,
    "authors": []
  },
  "https://openreview.net/forum?id=Ki4ocDm364": {
    "title": "Scaling Pareto-Efficient Decision Making via Offline Multi-Objective RL",
    "volume": "poster",
    "abstract": "The goal of multi-objective reinforcement learning (MORL) is to learn policies that simultaneously optimize multiple competing objectives. In practice, an agent's preferences over the objectives may not be known apriori, and hence, we require policies that can generalize to arbitrary preferences at test time. In this work, we propose a new data-driven setup for offline MORL, where we wish to learn a preference-agnostic policy agent using only a finite dataset of offline demonstrations of other agents and their preferences. The key contributions of this work are two-fold. First, we introduce D4MORL, (D)atasets for MORL that are specifically designed for offline settings. It contains 1.8 million annotated demonstrations obtained by rolling out reference policies that optimize for randomly sampled preferences on 6 MuJoCo environments with 2-3 objectives each. Second, we propose Pareto-Efficient Decision Agents (PEDA), a family of offline MORL algorithms that builds and extends Decision Transformers via a novel preference-and-return-conditioned policy. Empirically, we show that PEDA closely approximates the behavioral policy on the D4MORL benchmark and provides an excellent approximation of the Pareto-front with appropriate conditioning, as measured by the hypervolume and sparsity metrics",
    "checked": true,
    "id": "cecc6b1f862bccf2bcc8071ca838161cd26eafe2",
    "semantic_title": "scaling pareto-efficient decision making via offline multi-objective rl",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=8KYeilT3Ow": {
    "title": "NAGphormer: A Tokenized Graph Transformer for Node Classification in Large Graphs",
    "volume": "poster",
    "abstract": "The graph Transformer emerges as a new architecture and has shown superior performance on various graph mining tasks. In this work, we observe that existing graph Transformers treat nodes as independent tokens and construct a single long sequence composed of all node tokens so as to train the Transformer model, causing it hard to scale to large graphs due to the quadratic complexity on the number of nodes for the self-attention computation. To this end, we propose a Neighborhood Aggregation Graph Transformer (NAGphormer) that treats each node as a sequence containing a series of tokens constructed by our proposed Hop2Token module. For each node, Hop2Token aggregates the neighborhood features from different hops into different representations and thereby produces a sequence of token vectors as one input. In this way, NAGphormer could be trained in a mini-batch manner and thus could scale to large graphs. Moreover, we mathematically show that as compared to a category of advanced Graph Neural Networks (GNNs), the decoupled Graph Convolutional Network, NAGphormer could learn more informative node representations from the multi-hop neighborhoods. Extensive experiments on benchmark datasets from small to large are conducted to demonstrate that NAGphormer consistently outperforms existing graph Transformers and mainstream GNNs. Code is available at https://github.com/JHL-HUST/NAGphormer",
    "checked": true,
    "id": "295526bc7ee119423af707e649cb55ab98854a47",
    "semantic_title": "nagphormer: a tokenized graph transformer for node classification in large graphs",
    "citation_count": 139,
    "authors": []
  },
  "https://openreview.net/forum?id=iYC5hOMqUg": {
    "title": "Bayesian Oracle for bounding information gain in neural encoding models",
    "volume": "poster",
    "abstract": "In recent years, deep learning models have set new standards in predicting neural population responses. Most of these models currently focus on predicting the mean response of each neuron for a given input. However, neural variability around this mean is not just noise and plays a central role in several theories on neural computation. To capture this variability, we need models that predict full response distributions for a given stimulus. However, to measure the quality of such models, commonly used correlation-based metrics are not sufficient as they mainly care about the mean of the response distribution. An interpretable alternative evaluation metric for likelihood-based models is \\textit{Information Gain} (IG) which evaluates the likelihood of a model relative to a lower and upper bound. However, while a lower bound is usually easy to obtain, constructing an upper bound turns out to be challenging for neural recordings with relatively low numbers of repeated trials, high (shared) variability, and sparse responses. In this work, we generalize the jack-knife oracle estimator for the mean---commonly used for correlation metrics---to a flexible Bayesian oracle estimator for IG based on posterior predictive distributions. We describe and address the challenges that arise when estimating the lower and upper bounds from small datasets. We then show that our upper bound estimate is data-efficient and robust even in the case of sparse responses and low signal-to-noise ratio. We further provide the derivation of the upper bound estimator for a variety of common distributions including the state-of-the-art zero-inflated mixture models, and relate IG to common mean-based metrics. Finally, we use our approach to evaluate such a mixture model resulting in $90\\%$ IG performance",
    "checked": true,
    "id": "0c3f07b121372d32a3ddacf93f850c7cb091918e",
    "semantic_title": "bayesian oracle for bounding information gain in neural encoding models",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=oztkQizr3kk": {
    "title": "$\\Lambda$-DARTS: Mitigating Performance Collapse by Harmonizing Operation Selection among Cells",
    "volume": "poster",
    "abstract": "Differentiable neural architecture search (DARTS) is a popular method for neural architecture search (NAS), which performs cell-search and utilizes continuous relaxation to improve the search efficiency via gradient-based optimization. The main shortcoming of DARTS is performance collapse, where the discovered architecture suffers from a pattern of declining quality during search. Performance collapse has become an important topic of research, with many methods trying to solve the issue through either regularization or fundamental changes to DARTS. However, the weight-sharing framework used for cell-search in DARTS and the convergence of architecture parameters has not been analyzed yet. In this paper, we provide a thorough and novel theoretical and empirical analysis on DARTS and its point of convergence. We show that DARTS suffers from a specific structural flaw due to its weight-sharing framework that limits the convergence of DARTS to saturation points of the softmax function. This point of convergence gives an unfair advantage to layers closer to the output in choosing the optimal architecture, causing performance collapse. We then propose two new regularization terms that aim to prevent performance collapse by harmonizing operation selection via aligning gradients of layers. Experimental results on six different search spaces and three different datasets show that our method ($\\Lambda$-DARTS) does indeed prevent performance collapse, providing justification for our theoretical analysis and the proposed remedy",
    "checked": false,
    "id": "426d452eb45ac5eca6ccc58b62bc78db3ec09ae8",
    "semantic_title": "λ-darts: mitigating performance collapse by harmonizing operation selection among cells",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=nYWqxUwFc3x": {
    "title": "Learning Vortex Dynamics for Fluid Inference and Prediction",
    "volume": "poster",
    "abstract": "We propose a novel differentiable vortex particle (DVP) method to infer and predict fluid dynamics from a single video. Lying at its core is a particle-based latent space to encapsulate the hidden, Lagrangian vortical evolution underpinning the observable, Eulerian flow phenomena. Our differentiable vortex particles are coupled with a learnable, vortex-to-velocity dynamics mapping to effectively capture the complex flow features in a physically-constrained, low-dimensional space. This representation facilitates the learning of a fluid simulator tailored to the input video that can deliver robust, long-term future predictions. The value of our method is twofold: first, our learned simulator enables the inference of hidden physics quantities (e.g., velocity field) purely from visual observation; secondly, it also supports future prediction, constructing the input video's sequel along with its future dynamics evolution. We compare our method with a range of existing methods on both synthetic and real-world videos, demonstrating improved reconstruction quality, visual plausibility, and physical integrity",
    "checked": true,
    "id": "f7e7f83b0287ab3cf2f6151a8a37f903f3ca4e7f",
    "semantic_title": "learning vortex dynamics for fluid inference and prediction",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=53FyUAdP7d": {
    "title": "Discovering Generalizable Multi-agent Coordination Skills from Multi-task Offline Data",
    "volume": "poster",
    "abstract": "Cooperative multi-agent reinforcement learning (MARL) faces the challenge of adapting to multiple tasks with varying agents and targets. Previous multi-task MARL approaches require costly interactions to simultaneously learn or fine-tune policies in different tasks. However, the situation that an agent should generalize to multiple tasks with only offline data from limited tasks is more in line with the needs of real-world applications. Since offline multi-task data contains a variety of behaviors, an effective data-driven approach is to extract informative latent variables that can represent universal skills for realizing coordination across tasks. In this paper, we propose a novel Offline MARL algorithm to Discover coordInation Skills (ODIS) from multi-task data. ODIS first extracts task-invariant coordination skills from offline multi-task data and learns to delineate different agent behaviors with the discovered coordination skills. Then we train a coordination policy to choose optimal coordination skills with the centralized training and decentralized execution paradigm. We further demonstrate that the discovered coordination skills can assign effective coordinative behaviors, thus significantly enhancing generalization to unseen tasks. Empirical results in cooperative MARL benchmarks, including the StarCraft multi-agent challenge, show that ODIS obtains superior performance in a wide range of tasks only with offline data from limited sources",
    "checked": true,
    "id": "cc95b268a5f0ac69af25194dc0c7b052ec8d2303",
    "semantic_title": "discovering generalizable multi-agent coordination skills from multi-task offline data",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=bLmSMXbqXr": {
    "title": "Quality-Similar Diversity via Population Based Reinforcement Learning",
    "volume": "poster",
    "abstract": "Diversity is a growing research topic in Reinforcement Learning (RL). Previous research on diversity has mainly focused on promoting diversity to encourage exploration and thereby improve quality (the cumulative reward), maximizing diversity subject to quality constraints, or jointly maximizing quality and diversity, known as the quality-diversity problem. In this work, we present the quality-similar diversity problem that features diversity among policies of similar qualities. In contrast to task-agnostic diversity, we focus on task-specific diversity defined by a set of user-specified Behavior Descriptors (BDs). A BD is a scalar function of a trajectory (e.g., the fire action rate for an Atari game), which delivers the type of diversity the user prefers. To derive the gradient of the user-specified diversity with respect to a policy, which is not trivially available, we introduce a set of BD estimators and connect it with the classical policy gradient theorem. Based on the diversity gradient, we develop a population-based RL algorithm to adaptively and efficiently optimize the population diversity at multiple quality levels throughout training. Extensive results on MuJoCo and Atari demonstrate that our algorithm significantly outperforms previous methods in terms of generating user-specified diverse policies across different quality levels",
    "checked": true,
    "id": "98abf6219d648a18292686670668aef7177dc64a",
    "semantic_title": "quality-similar diversity via population based reinforcement learning",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=M0_sUuEyHs": {
    "title": "Better Teacher Better Student: Dynamic Prior Knowledge for Knowledge Distillation",
    "volume": "poster",
    "abstract": "Knowledge distillation (KD) has shown very promising capabilities in transferring learning representations from large models (teachers) to small models (students). However, as the capacity gap between students and teachers becomes larger, existing KD methods fail to achieve better results. Our work shows that the 'prior knowledge' is vital to KD, especially when applying large teachers. Particularly, we propose the dynamic prior knowledge (DPK), which integrates part of teacher's features as the prior knowledge before the feature distillation. This means that our method also takes the teacher's feature as `input', not just `target'. Besides, we dynamically adjust the ratio of the prior knowledge during the training phase according to the feature gap, thus guiding the student in an appropriate difficulty. To evaluate the proposed method, we conduct extensive experiments on two image classification benchmarks (i.e. CIFAR100 and ImageNet) and an object detection benchmark (\\i.e. MS COCO). The results demonstrate the superiority of our method in performance under varying settings. Besides, our DPK makes the performance of the student model positively correlated with that of the teacher model, which means that we can further boost the accuracy of students by applying larger teachers. More importantly, DPK provides a fast solution in teacher model selection for any given model. Our codes will be publicly available for reproducibility",
    "checked": true,
    "id": "4e677fd99355643c67cedde98f1ffcf258c71fbe",
    "semantic_title": "better teacher better student: dynamic prior knowledge for knowledge distillation",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=rOFKmzNTbC": {
    "title": "Tensor-Based Sketching Method for the Low-Rank Approximation of Data Streams",
    "volume": "poster",
    "abstract": "Low-rank approximation in data streams is a fundamental and significant task in computing science, machine learning and statistics. Multiple streaming algorithms have emerged over years and most of them are inspired by randomized algorithms, more specifically, sketching methods. However, many algorithms are not able to leverage information of data streams and consequently suffer from low accuracy. Existing data-driven methods improve accuracy but the training cost is expensive in practice. In this paper, from a subspace perspective, we propose a tensor-based sketching method for low-rank approximation of data streams. The proposed algorithm fully exploits the structure of data streams and obtains quasi-optimal sketching matrices by performing tensor decomposition on training data. A series of experiments are carried out and show that the proposed tensor-based method can be more accurate and much faster than the previous work",
    "checked": true,
    "id": "d66c944e6ebb64bca459e12684ecad7df52b3cfd",
    "semantic_title": "tensor-based sketching method for the low-rank approximation of data streams",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=cEygmQNOeI": {
    "title": "Language Models are Realistic Tabular Data Generators",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "394bd431e522b86581086bcb5cd9be161cf1cdf4",
    "semantic_title": "language models are realistic tabular data generators",
    "citation_count": 293,
    "authors": []
  },
  "https://openreview.net/forum?id=y4uc4NtTWaq": {
    "title": "Data augmentation alone can improve adversarial training",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "68be99a37c23486fcdd016fdf7833bb9092146ae",
    "semantic_title": "data augmentation alone can improve adversarial training",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=UG8bQcD3Emv": {
    "title": "CUTS: Neural Causal Discovery from Irregular Time-Series Data",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ce3a8101612d9adf68236a43e165ca08649c9611",
    "semantic_title": "cuts: neural causal discovery from irregular time-series data",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=OOWLRfAI_V_": {
    "title": "Quantized Compressed Sensing with Score-Based Generative Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8ead85160abac1795e6926abb1a3d4c40f143a14",
    "semantic_title": "quantized compressed sensing with score-based generative models",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=qihMOPw4Sf_": {
    "title": "Valid P-Value for Deep Learning-driven Salient Region",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "127db6eee606e5efc2dc26d76e952f610db0dfaf",
    "semantic_title": "valid p-value for deep learning-driven salient region",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=yf1icZHC-l9": {
    "title": "Complexity-Based Prompting for Multi-step Reasoning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c88cafa3e980765a64febe369ceb7c2aa7261d2a",
    "semantic_title": "complexity-based prompting for multi-step reasoning",
    "citation_count": 487,
    "authors": []
  },
  "https://openreview.net/forum?id=mXPoBtnpMnuy": {
    "title": "Unsupervised 3D Object Learning through Neuron Activity aware Plasticity",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "62c6c28691a93e1504279d752e3230538254917a",
    "semantic_title": "unsupervised 3d object learning through neuron activity aware plasticity",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=8IN-qLkl215": {
    "title": "Visually-Augmented Language Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6d02cc3e66330fc170a5bde44be7b358149b9c0a",
    "semantic_title": "visually-augmented language modeling",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=XrgjF5-M3xi": {
    "title": "Incremental Learning of Structured Memory via Closed-Loop Transcription",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "918ea9b6a17fc4e25087232b753e37a382c98445",
    "semantic_title": "incremental learning of structured memory via closed-loop transcription",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=lMO7TC7cuuh": {
    "title": "When Data Geometry Meets Deep Function: Generalizing Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "08f8fdb2ac880bb8cc4f4e529f36772e2067dbbd",
    "semantic_title": "when data geometry meets deep function: generalizing offline reinforcement learning",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=sVzBN-DlJRi": {
    "title": "Budgeted Training for Vision Transformer",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a40f5b9acd81fad048a97562336b46d04cde4023",
    "semantic_title": "budgeted training for vision transformer",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=4rXMRuoJlai": {
    "title": "Mind's Eye: Grounded Language Model Reasoning through Simulation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2cb97b2bb6ab2eb17add9ffe69d5cbeaca2b29c8",
    "semantic_title": "mind's eye: grounded language model reasoning through simulation",
    "citation_count": 87,
    "authors": []
  },
  "https://openreview.net/forum?id=azCKuYyS74": {
    "title": "What Do Self-Supervised Vision Transformers Learn?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5e0f2264b872288afa8c069cda381379897e13e4",
    "semantic_title": "what do self-supervised vision transformers learn?",
    "citation_count": 94,
    "authors": []
  },
  "https://openreview.net/forum?id=fB4V-2QvCEm": {
    "title": "Population-size-Aware Policy Optimization for Mean-Field Games",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a19c67d9d1d416731930dff76d8c79ff5b8247c9",
    "semantic_title": "population-size-aware policy optimization for mean-field games",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=qs2YCziX2o-": {
    "title": "On The Relative Error of Random Fourier Features for Preserving Kernel Distance",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c012b0bbb159d94516946d3d6010ed1a87ea16c2",
    "semantic_title": "on the relative error of random fourier features for preserving kernel distance",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=sE7-XhLxHA": {
    "title": "DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "972706306f85b1bfb40c7d35c796ad5174eb0c9c",
    "semantic_title": "debertav3: improving deberta using electra-style pre-training with gradient-disentangled embedding sharing",
    "citation_count": 1355,
    "authors": []
  },
  "https://openreview.net/forum?id=Z_tmYu060Kr": {
    "title": "Squeeze Training for Adversarial Robustness",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7e9e38a9101fd6e9ee3cd44f72d9be6842b7a42d",
    "semantic_title": "squeeze training for adversarial robustness",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=MofT9KEF0kw": {
    "title": "Pushing the Accuracy-Group Robustness Frontier with Introspective Self-play",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b1ab0635586fc7677f9a54590e56dcb0717db664",
    "semantic_title": "pushing the accuracy-group robustness frontier with introspective self-play",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=n-hKHMzBgy": {
    "title": "Max-Margin Works while Large Margin Fails: Generalization without Uniform Convergence",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2b18d87e71d06f6c7028aec77283aa243e1ccffe",
    "semantic_title": "max-margin works while large margin fails: generalization without uniform convergence",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=oGVu9spZaJJ": {
    "title": "Asymptotic Instance-Optimal Algorithms for Interactive Decision Making",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ead669b7bdf90ff20dcf42a0c09c283813c0df68",
    "semantic_title": "asymptotic instance-optimal algorithms for interactive decision making",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=SNwH0dDGl7_": {
    "title": "Near-Optimal Deployment Efficiency in Reward-Free Reinforcement Learning with Linear Function Approximation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "88298748d970690e09fe6043d68125b93ccce89d",
    "semantic_title": "near-optimal deployment efficiency in reward-free reinforcement learning with linear function approximation",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=k5PEHHY4spM": {
    "title": "An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "eb26dd5126ea375a37c608d9e07cf04b77848f1b",
    "semantic_title": "an equal-size hard em algorithm for diverse dialogue generation",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=04K3PMtMckp": {
    "title": "The hidden uniform cluster prior in self-supervised learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8be831a07abe8c5475c2bd91cc41bf4c1c2be771",
    "semantic_title": "the hidden uniform cluster prior in self-supervised learning",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=sXfWoK4KvSW": {
    "title": "Long-Tailed Partial Label Learning via Dynamic Rebalancing",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "030d8c57cd6da1ff77cff3e2c5bd91905e351117",
    "semantic_title": "long-tailed partial label learning via dynamic rebalancing",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=QrnDe_9ZFd8": {
    "title": "Task Ambiguity in Humans and Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c3f687be2ee470d41106010be3a66e14df85e91f",
    "semantic_title": "task ambiguity in humans and language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=z92lBy1ehjI": {
    "title": "Winning Both the Accuracy of Floating Point Activation and the Simplicity of Integer Arithmetic",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3c1d8d3846a7ed76d870451c03b1a6f366ea2d7d",
    "semantic_title": "winning both the accuracy of floating point activation and the simplicity of integer arithmetic",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=Peot1SFDX0": {
    "title": "Preference Transformer: Modeling Human Preferences using Transformers for RL",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c6478decdfff11ccbd085967c2f83aea11927a46",
    "semantic_title": "preference transformer: modeling human preferences using transformers for rl",
    "citation_count": 82,
    "authors": []
  },
  "https://openreview.net/forum?id=znLlSgN-4S0": {
    "title": "More Centralized Training, Still Decentralized Execution: Multi-Agent Conditional Policy Factorization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bc789d637841e01efe283ab2a5d798b0141dec6e",
    "semantic_title": "more centralized training, still decentralized execution: multi-agent conditional policy factorization",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=2YQrqe4RNv": {
    "title": "Edgeformers: Graph-Empowered Transformers for Representation Learning on Textual-Edge Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1c3ddc72d39d99da8c73669155e9109c6b4e1ef4",
    "semantic_title": "edgeformers: graph-empowered transformers for representation learning on textual-edge networks",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=lEkl0jdSb7B": {
    "title": "Any-scale Balanced Samplers for Discrete Space",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "09c2aa9f94e10f05551382347ea3e17950c8755e",
    "semantic_title": "any-scale balanced samplers for discrete space",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=4MbGnp4iPQ": {
    "title": "Equivariant Shape-Conditioned Generation of 3D Molecules for Ligand-Based Drug Design",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7a78ce6533d26135b087c7c85f79749f09c0d2d0",
    "semantic_title": "equivariant shape-conditioned generation of 3d molecules for ligand-based drug design",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=rVM8wD2G7Dy": {
    "title": "Imbalanced Semi-supervised Learning with Bias Adaptive Classifier",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "cad82941268526b364b8b16d374aacf4573bc4eb",
    "semantic_title": "imbalanced semi-supervised learning with bias adaptive classifier",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=rJcLocAJpA6": {
    "title": "On Compositional Uncertainty Quantification for Seq2seq Graph Parsing",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "995c3f5b6776d58e5dd9abfe62f0435751dc9e48",
    "semantic_title": "on compositional uncertainty quantification for seq2seq graph parsing",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=GPTjnA57h_3": {
    "title": "Free Lunch for Domain Adversarial Training: Environment Label Smoothing",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b7ae62f4c2c3696ffe587f40685839baff9f2b8b",
    "semantic_title": "free lunch for domain adversarial training: environment label smoothing",
    "citation_count": 45,
    "authors": []
  },
  "https://openreview.net/forum?id=JxpBP1JM15-": {
    "title": "Scaling Forward Gradient With Local Losses",
    "volume": "poster",
    "abstract": "Forward gradient learning computes a noisy directional gradient and is a biologically plausible alternative to backprop for learning deep neural networks. The standard forward gradient algorithm suffers from the curse of dimensionality in the number of parameters. In this paper, we propose to scale forward gradient by adding a large number of local greedy loss functions. We consider block-wise, patch-wise, and channel group-wise local losses, and show that activity perturbation reduces variance compared to weight perturbation. Inspired by MLPMixer, we also propose a new architecture, LocalMixer, that is more suitable for local learning. We find local learning can work well with both supervised classification and self-supervised contrastive learning. Empirically, it can match backprop on MNIST and CIFAR-10 and significantly outperform backprop-free algorithms on ImageNet",
    "checked": true,
    "id": "7a31b37b4844653e084ff096f1ec5861b95389a9",
    "semantic_title": "scaling forward gradient with local losses",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=ugA1HX69sf": {
    "title": "Understanding Embodied Reference with Touch-Line Transformer",
    "volume": "poster",
    "abstract": "We study embodied reference understanding, the task of locating referents using embodied gestural signals and language references. Human studies have revealed that, contrary to popular belief, objects referred to or pointed to do not lie on the elbow-wrist line, but rather on the so-called virtual touch line. Nevertheless, contemporary human pose representations lack the virtual touch line. To tackle this problem, we devise the touch-line Transformer: It takes as input tokenized visual and textual features and simultaneously predicts the referent's bounding box and a touch-line vector. Leveraging this touch-line prior, we further devise a geometric consistency loss that promotes co-linearity between referents and touch lines. Using the touch line as gestural information dramatically improves model performances: Experiments on the YouRefIt dataset demonstrate that our method yields a +25.0% accuracy improvement under the 0.75 IoU criterion, hence closing 63.6% of the performance difference between models and humans. Furthermore, we computationally validate prior human studies by demonstrating that computational models more accurately locate referents when employing the virtual touch line than when using the elbow-wrist line",
    "checked": true,
    "id": "43b529f03d32d0e4a2830ac6c3bc066cee733bf8",
    "semantic_title": "understanding embodied reference with touch-line transformer",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=wzlWiO_WY4": {
    "title": "Calibration Matters: Tackling Maximization Bias in Large-scale Advertising Recommendation Systems",
    "volume": "poster",
    "abstract": "Calibration is defined as the ratio of the average predicted click rate to the true click rate. The optimization of calibration is essential to many online advertising recommendation systems because it directly affects the downstream bids in ads auctions and the amount of money charged to advertisers. Despite its importance, calibration often suffers from a problem called \"maximization bias\". Maximization bias refers to the phenomenon that the maximum of predicted values overestimates the true maximum. The problem is introduced because the calibration is computed on the set selected by the prediction model itself. It persists even if unbiased predictions are achieved on every datapoint and worsens when covariate shifts exist between the training and test sets. To mitigate this problem, we quantify maximization bias and propose a variance-adjusting debiasing (VAD) meta-algorithm in this paper. The algorithm is efficient, robust, and practical as it is able to mitigate maximization bias problem under covariate shifts, without incurring additional online serving costs or compromising the ranking performance. We demonstrate the effectiveness of the proposed algorithm using a state-of-the-art recommendation neural network model on a large-scale real-world dataset",
    "checked": true,
    "id": "c64404668fb09f8843ad08d493f30f325f1ef0b4",
    "semantic_title": "calibration matters: tackling maximization bias in large-scale advertising recommendation systems",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=cJWxqmmDL2b": {
    "title": "Memorization-Dilation: Modeling Neural Collapse Under Noise",
    "volume": "poster",
    "abstract": "The notion of neural collapse refers to several emergent phenomena that have been empirically observed across various canonical classification problems. During the terminal phase of training a deep neural network, the feature embedding of all examples of the same class tend to collapse to a single representation, and the features of different classes tend to separate as much as possible. Neural collapse is often studied through a simplified model, called the layer-peeled model, in which the network is assumed to have ``infinite expressivity'' and can map each data point to any arbitrary representation. In this work we study a more realistic variant of the layer-peeled model, which takes the positivity of the features into account. Furthermore, we extend this model to also incorporate the limited expressivity of the network. Empirical evidence suggests that the memorization of noisy data points leads to a degradation (dilation) of the neural collapse. Using a model of the memorization-dilation (M-D) phenomenon, we show one mechanism by which different losses lead to different performances of the trained network on noisy data. Our proofs reveal why label smoothing, a modification of cross-entropy empirically observed to produce a regularization effect, leads to improved generalization in classification tasks",
    "checked": true,
    "id": "ef5dd59b4e1effa613e9c5b686f9e08970a0ba21",
    "semantic_title": "memorization-dilation: modeling neural collapse under noise",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=qV_M_rhYajc": {
    "title": "Spacetime Representation Learning",
    "volume": "poster",
    "abstract": "Much of the data we encounter in the real world can be represented as directed graphs. In this work, we introduce a general family of representations for directed graphs through connected time-oriented Lorentz manifolds, called \"spacetimes\" in general relativity. Spacetimes intrinsically contain a causal structure that indicates whether or not there exists a causal or even chronological order between points of the manifold, called events. This chronological order allows us to naturally represent directed edges via imposing the correct ordering when the nodes are embedded as events in the spacetime. Previous work in machine learning only considers embeddings lying on the simplest Lorentz manifold or does not exploit the connection between Lorentzian pre-length spaces and directed graphs. We introduce a well-defined approach to map data onto a general family of spacetimes. We empirically evaluate our framework in the tasks of hierarchy extraction of undirected graphs, directed link prediction and representation of directed graphs",
    "checked": true,
    "id": "a7f25b6658ddc35c6edfd5a89e5d10c107e46644",
    "semantic_title": "spacetime representation learning",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=lid14UkLPd4": {
    "title": "Learning to Extrapolate: A Transductive Approach",
    "volume": "poster",
    "abstract": "Machine learning systems, especially with overparameterized deep neural networks, can generalize to novel test instances drawn from the same distribution as the training data. However, they fare poorly when evaluated on out-of-support test points. In this work, we tackle the problem of developing machine learning systems that retain the power of overparameterized function approximators while enabling extrapolation to out-of-support test points when possible. This is accomplished by noting that under certain conditions, a \"transductive\" reparameterization can convert an out-of-support extrapolation problem into a problem of within-support combinatorial generalization. We propose a simple strategy based on bilinear embeddings to enable this type of combinatorial generalization, thereby addressing the out-of-support extrapolation problem under certain conditions. We instantiate a simple, practical algorithm applicable to various supervised learning and imitation learning tasks",
    "checked": true,
    "id": "0bd3eb18d34eba3a0f0f0468e36e231892c9065d",
    "semantic_title": "learning to extrapolate: a transductive approach",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=FlCg47MNvBA": {
    "title": "Label-free Concept Bottleneck Models",
    "volume": "poster",
    "abstract": "Concept bottleneck models (CBM) are a popular way of creating more interpretable neural networks by having hidden layer neurons correspond to human-understandable concepts. However, existing CBMs and their variants have two crucial limitations: first, they need to collect labeled data for each of the predefined concepts, which is time consuming and labor intensive; second, the accuracy of a CBM is often significantly lower than that of a standard neural network, especially on more complex datasets. This poor performance creates a barrier for adopting CBMs in practical real world applications. Motivated by these challenges, we propose Label-free CBM which is a novel framework to transform any neural network into an interpretable CBM without labeled concept data, while retaining a high accuracy. Our Label-free CBM has many advantages, it is: scalable - we present the first CBM scaled to ImageNet, efficient - creating a CBM takes only a few hours even for very large datasets, and automated - training it for a new dataset requires minimal human effort. Our code is available at https://github.com/Trustworthy-ML-Lab/Label-free-CBM",
    "checked": true,
    "id": "1d603b03bb083a2c3e2e3b6f116cf196d637e6b6",
    "semantic_title": "label-free concept bottleneck models",
    "citation_count": 212,
    "authors": []
  },
  "https://openreview.net/forum?id=XGagtiJ8XC": {
    "title": "Multi-level Protein Structure Pre-training via Prompt Learning",
    "volume": "poster",
    "abstract": "A protein can focus on different structure levels to implement its functions. Each structure has its own merit and driving forces in describing some specific characteristics, and they cannot replace each other. Most existing function prediction methods take the tertiary structure as input, unintentionally ignoring the other levels of protein structures. Considering protein sequences can determine multi-level structures, in this paper, we aim to realize the comprehensive potential of protein sequences for function prediction. Specifically, we propose a new prompt-guided multi-task pre-training and fine-tuning framework, and the resulting protein model is called PromptProtein. Through the prompt-guided multi-task pre-training, we learn multiple prompt signals to steer the model to focus on different structure levels. We also design a prompt fine-tuning module to provide downstream tasks the on-demand flexibility of utilizing respective levels of structure information. Extensive experiments on function prediction and protein engineering show that PromptProtein outperforms state-of-the-art methods by large margins",
    "checked": true,
    "id": "785628876bccf1b72d6e78c0972289f4026ccfda",
    "semantic_title": "multi-level protein structure pre-training via prompt learning",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=-Aw0rrrPUF": {
    "title": "GLM-130B: An Open Bilingual Pre-trained Model",
    "volume": "poster",
    "abstract": "We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model as good as GPT-3 (davinci) and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we face numerous unexpected technical and engineering challenges, particularly on loss spikes and divergence. In this paper, we introduce the pre-training process of GLM-130B including its design choices, training strategies for both efficiency and stability, and engineering efforts. The resultant GLM-130B model offers significant outperformance over GPT-3 175B on a wide range of popular English benchmarks while the performance advantage is not observed in OPT-175B and BLOOM-176B. It also consistently and significantly outperforms ERNIE TITAN 3.0 260B—the largest Chinese language model—across related benchmarks. Finally, we leverage a unique scaling property of GLM-130B to reach INT4 quantization with almost no performance loss, making it the first among 100B-scale models and more importantly, allowing its effective inference on 4×RTX 3090 (24G) or 8×RTX 2080 Ti (11G) GPUs, the most ever affordable GPUs required for using 100B-scale models. The GLM-130B model weights are publicly accessible and its code, training logs, related toolkit, and lessons learned are open-sourced at https://github.com/THUDM/GLM-130B/",
    "checked": true,
    "id": "1d26c947406173145a4665dd7ab255e03494ea28",
    "semantic_title": "glm-130b: an open bilingual pre-trained model",
    "citation_count": 1145,
    "authors": []
  },
  "https://openreview.net/forum?id=Ha2MnQM9Ph": {
    "title": "Causal Estimation for Text Data with (Apparent) Overlap Violations",
    "volume": "poster",
    "abstract": "Consider the problem of estimating the causal effect of some attribute of a text document; for example: what effect does writing a polite vs. rude email have on response time? To estimate a causal effect from observational data, we need to adjust for confounding aspects of the text that affect both the treatment and outcome---e.g., the topic or writing level of the text. These confounding aspects are unknown a priori, so it seems natural to adjust for the entirety of the text (e.g., using a transformer). However, causal identification and estimation procedures rely on the assumption of overlap: for all levels of the adjustment variables, there is randomness leftover so that every unit could have (not) received treatment. Since the treatment here is itself an attribute of the text, it is perfectly determined, and overlap is apparently violated. The purpose of this paper is to show how to handle causal identification and obtain robust causal estimation in the presence of apparent overlap violations. In brief, the idea is to use supervised representation learning to produce a data representation that preserves confounding information while eliminating information that is only predictive of the treatment. This representation then suffices for adjustment and satisfies overlap. Adapting results on non-parametric estimation, we show that this procedure shows robustness with respect to conditional outcome misestimation and yields a low-bias estimator that admits valid uncertainty quantification under weak conditions. Empirical results show reductions in bias and strong improvements in uncertainty quantification relative to the natural (transformer-based) baseline",
    "checked": true,
    "id": "5cd83a86584065c82837cd9e73fc844fb2b2e18e",
    "semantic_title": "causal estimation for text data with (apparent) overlap violations",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=JdTnc9gjVfJ": {
    "title": "MoDem: Accelerating Visual Model-Based Reinforcement Learning with Demonstrations",
    "volume": "poster",
    "abstract": "Poor sample efficiency continues to be the primary challenge for deployment of deep Reinforcement Learning (RL) algorithms for real-world applications, and in particular for visuo-motor control. Model-based RL has the potential to be highly sample efficient by concurrently learning a world model and using synthetic rollouts for planning and policy improvement. However, in practice, sample-efficient learning with model-based RL is bottlenecked by the exploration challenge. In this work, we find that leveraging just a handful of demonstrations can dramatically improve the sample-efficiency of model-based RL. Simply appending demonstrations to the interaction dataset, however, does not suffice. We identify key ingredients for leveraging demonstrations in model learning -- policy pretraining, targeted exploration, and oversampling of demonstration data -- which forms the three phases of our model-based RL framework. We empirically study three complex visuo-motor control domains and find that our method is 160%-250% more successful in completing sparse reward tasks compared to prior approaches in the low data regime (100k interaction steps, 5 demonstrations). Code and videos are available at https://nicklashansen.github.io/modemrl",
    "checked": true,
    "id": "b2004f4f19bc6ccae8e4afc554f39142870100f5",
    "semantic_title": "modem: accelerating visual model-based reinforcement learning with demonstrations",
    "citation_count": 54,
    "authors": []
  },
  "https://openreview.net/forum?id=zS9sRyaPFlJ": {
    "title": "PD-MORL: Preference-Driven Multi-Objective Reinforcement Learning Algorithm",
    "volume": "poster",
    "abstract": "Multi-objective reinforcement learning (MORL) approaches have emerged to tackle many real-world problems with multiple conflicting objectives by maximizing a joint objective function weighted by a preference vector. These approaches find fixed customized policies corresponding to preference vectors specified during training. However, the design constraints and objectives typically change dynamically in real-life scenarios. Furthermore, storing a policy for each potential preference is not scalable. Hence, obtaining a set of Pareto front solutions for the entire preference space in a given domain with a single training is critical. To this end, we propose a novel MORL algorithm that trains a single universal network to cover the entire preference space scalable to continuous robotic tasks. The proposed approach, Preference-Driven MORL (PD-MORL), utilizes the preferences as guidance to update the network parameters. It also employs a novel parallelization approach to increase sample efficiency. We show that PD-MORL achieves up to 25% larger hypervolume for challenging continuous control tasks and uses an order of magnitude fewer trainable parameters compared to prior approaches",
    "checked": true,
    "id": "dd619a923937874a7dc569b618504c6efb713a6a",
    "semantic_title": "pd-morl: preference-driven multi-objective reinforcement learning algorithm",
    "citation_count": 43,
    "authors": []
  },
  "https://openreview.net/forum?id=s130rTE3U_X": {
    "title": "Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning",
    "volume": "poster",
    "abstract": "While the empirical success of self-supervised learning (SSL) heavily relies on the usage of deep nonlinear models, existing theoretical works on SSL understanding still focus on linear ones. In this paper, we study the role of nonlinearity in the training dynamics of contrastive learning (CL) on one and two-layer nonlinear networks with homogeneous activation $h(x) = h'(x)x$. We have two major theoretical discoveries. First, the presence of nonlinearity can lead to many local optima even in 1-layer setting, each corresponding to certain patterns from the data distribution, while with linear activation, only one major pattern can be learned. This suggests that models with lots of parameters can be regarded as a \\emph{brute-force} way to find these local optima induced by nonlinearity. Second, in the 2-layer case, linear activation is proven not capable of learning specialized weights into diverse patterns, demonstrating the importance of nonlinearity. In addition, for 2-layer setting, we also discover \\emph{global modulation}: those local patterns discriminative from the perspective of global-level patterns are prioritized to learn, further characterizing the learning process. Simulation verifies our theoretical findings",
    "checked": true,
    "id": "f5db3b0a99e9ab7777b2fecf8b5d237715a3464d",
    "semantic_title": "understanding the role of nonlinearity in training dynamics of contrastive learning",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=s7oOe6cNRT8": {
    "title": "M-L2O: Towards Generalizable Learning-to-Optimize by Test-Time Fast Self-Adaptation",
    "volume": "poster",
    "abstract": "Learning to Optimize (L2O) has drawn increasing attention as it often remarkably accelerates the optimization procedure of complex tasks by \"overfitting\" specific task type, leading to enhanced performance compared to analytical optimizers. Generally, L2O develops a parameterized optimization method (i.e., \"optimizer\") by learning from solving sample problems. This data-driven procedure yields L2O that can efficiently solve problems similar to those seen in training, that is, drawn from the same \"task distribution\". However, such learned optimizers often struggle when new test problems come with a substantially deviation from the training task distribution. This paper investigates a potential solution to this open challenge, by meta-training an L2O optimizer that can perform fast test-time self-adaptation to a out-of-distribution task, in only a few steps. We theoretically characterize the generalization of L2O, and further show that our proposed framework (termed as M-L2O) provably facilitates rapid task adaptation by locating well-adapted initial points for the optimizer weight. Empirical observations on several classic tasks like LASSO and Quadratic, demonstrate that M-L2O converges significantly faster than vanilla L2O with only $5$ steps of adaptation, echoing our theoretical results. Codes are available in https://github.com/VITA-Group/M-L2O",
    "checked": true,
    "id": "c2773a1dfd8878593eac4d3de6d6aba7d5860ec6",
    "semantic_title": "m-l2o: towards generalizable learning-to-optimize by test-time fast self-adaptation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=wsZsjOSytRA": {
    "title": "3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical Transformer for Medical Image Segmentation",
    "volume": "poster",
    "abstract": "The recent 3D medical ViTs (e.g., SwinUNETR) achieve the state-of-the-art performances on several 3D volumetric data benchmarks, including 3D medical image segmentation. Hierarchical transformers (e.g., Swin Transformers) reintroduced several ConvNet priors and further enhanced the practical viability of adapting volumetric segmentation in 3D medical datasets. The effectiveness of hybrid approaches is largely credited to the large receptive field for non-local self-attention and the large number of model parameters. We hypothesize that volumetric ConvNets can simulate the large receptive field behavior of these learning approaches with fewer model parameters using depth-wise convolution. In this work, we propose a lightweight volumetric ConvNet, termed 3D UX-Net, which adapts the hierarchical transformer using ConvNet modules for robust volumetric segmentation. Specifically, we revisit volumetric depth-wise convolutions with large kernel (LK) size (e.g. starting from $7\\times7\\times7$) to enable the larger global receptive fields, inspired by Swin Transformer. We further substitute the multi-layer perceptron (MLP) in Swin Transformer blocks with pointwise depth convolutions and enhance model performances with fewer normalization and activation layers, thus reducing the number of model parameters. 3D UX-Net competes favorably with current SOTA transformers (e.g. SwinUNETR) using three challenging public datasets on volumetric brain and abdominal imaging: 1) MICCAI Challenge 2021 FLARE, 2) MICCAI Challenge 2021 FeTA, and 3) MICCAI Challenge 2022 AMOS. 3D UX-Net consistently outperforms SwinUNETR with improvement from 0.929 to 0.938 Dice (FLARE2021) and 0.867 to 0.874 Dice (Feta2021). We further evaluate the transfer learning capability of 3D UX-Net with AMOS2022 and demonstrates another improvement of $2.27\\%$ Dice (from 0.880 to 0.900). The source code with our proposed model are available at https://github.com/MASILab/3DUX-Net",
    "checked": true,
    "id": "831ab0f9e9f94bd41f1966d45fdd87640871ec43",
    "semantic_title": "3d ux-net: a large kernel volumetric convnet modernizing hierarchical transformer for medical image segmentation",
    "citation_count": 163,
    "authors": []
  },
  "https://openreview.net/forum?id=NpsVSN6o4ul": {
    "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small",
    "volume": "poster",
    "abstract": "Research in mechanistic interpretability seeks to explain behaviors of ML models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task that requires logical reasoning: indirect object identification (IOI). Our explanation encompasses 28 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches including causal interventions and projections. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior \"in the wild\" in a language model. We evaluate the reliability of our explanation using three quantitative criteria - faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks",
    "checked": true,
    "id": "6edd112383ad494f5f2eba72b6f4ffae122ce61f",
    "semantic_title": "interpretability in the wild: a circuit for indirect object identification in gpt-2 small",
    "citation_count": 675,
    "authors": []
  },
  "https://openreview.net/forum?id=dnjZSPGmY5O": {
    "title": "Equivariant Descriptor Fields: SE(3)-Equivariant Energy-Based Models for End-to-End Visual Robotic Manipulation Learning",
    "volume": "poster",
    "abstract": "End-to-end learning for visual robotic manipulation is known to suffer from sample inefficiency, requiring large numbers of demonstrations. The spatial roto-translation equivariance, or the SE(3)-equivariance can be exploited to improve the sample efficiency for learning robotic manipulation. In this paper, we present SE(3)-equivariant models for visual robotic manipulation from point clouds that can be trained fully end-to-end. By utilizing the representation theory of the Lie group, we construct novel SE(3)-equivariant energy-based models that allow highly sample efficient end-to-end learning. We show that our models can learn from scratch without prior knowledge and yet are highly sample efficient (5~10 demonstrations are enough). Furthermore, we show that our models can generalize to tasks with (i) previously unseen target object poses, (ii) previously unseen target object instances of the category, and (iii) previously unseen visual distractors. We experiment with 6-DoF robotic manipulation tasks to validate our models' sample efficiency and generalizability. Codes are available at: https://github.com/tomato1mule/edf",
    "checked": true,
    "id": "9837ab8e799c51ff84c389c1b434cecae2d9b25b",
    "semantic_title": "equivariant descriptor fields: se(3)-equivariant energy-based models for end-to-end visual robotic manipulation learning",
    "citation_count": 63,
    "authors": []
  },
  "https://openreview.net/forum?id=BR_ZhvcYbGJ": {
    "title": "Explaining Temporal Graph Models through an Explorer-Navigator Framework",
    "volume": "poster",
    "abstract": "While GNN explanation has recently received significant attention, existing works are consistently designed for static graphs. Due to the prevalence of temporal graphs, many temporal graph models have been proposed, but explaining their predictions remains to be explored. To bridge the gap, in this paper, we propose T-GNNExplainer for temporal graph model explanation. Specifically, we regard a temporal graph constituted by a sequence of temporal events. Given a target event, our task is to find a subset of previously occurred events that lead to the model's prediction for it. To handle this combinatorial optimization problem, T-GNNExplainer includes an explorer to find the event subsets with Monte Carlo Tree Search (MCTS) and a navigator that learns the correlations between events and helps reduce the search space. In particular, the navigator is trained in advance and then integrated with the explorer to speed up searching and achieve better results. To the best of our knowledge, T-GNNExplainer is the first explainer tailored for temporal graph models. We conduct extensive experiments to evaluate the performance of T-GNNExplainer. Experimental results on both real-world and synthetic datasets demonstrate that T-GNNExplainer can achieve superior performance with up to about 50% improvement in Area under Fidelity-Sparsity Curve",
    "checked": true,
    "id": "7d6aa3d0a9113501e658ff939dda4b01e0f6a785",
    "semantic_title": "explaining temporal graph models through an explorer-navigator framework",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=l9vM_PaUKz": {
    "title": "Soft Neighbors are Positive Supporters in Contrastive Visual Representation Learning",
    "volume": "poster",
    "abstract": "Contrastive learning methods train visual encoders by comparing views (e.g., often created via a group of data augmentations on the same instance) from one instance to others. Typically, the views created from one instance are set as positive, while views from other instances are negative. This binary instance discrimination is studied extensively to improve feature representations in self-supervised learning. In this paper, we rethink the instance discrimination framework and find the binary instance labeling insufficient to measure correlations between different samples. For an intuitive example, given a random image instance, there may exist other images in a mini-batch whose content meanings are the same (i.e., belonging to the same category) or partially related (i.e., belonging to a similar category). How to treat the images that correlate similarly to the current image instance leaves an unexplored problem. We thus propose to support the current image by exploring other correlated instances (i.e., soft neighbors). We first carefully cultivate a candidate neighbor set, which will be further utilized to explore the highly-correlated instances. A cross-attention module is then introduced to predict the correlation score (denoted as positiveness) of other correlated instances with respect to the current one. The positiveness score quantitatively measures the positive support from each correlated instance, and is encoded into the objective for pretext training. To this end, our proposed method benefits in discriminating uncorrelated instances while absorbing correlated instances for SSL. We evaluate our soft neighbor contrastive learning method (SNCLR) on standard visual recognition benchmarks, including image classification, object detection, and instance segmentation. The state-of-the-art recognition performance shows that SNCLR is effective in improving feature representations from both ViT and CNN encoders",
    "checked": true,
    "id": "d21a932262c2824114a3ce767bc144bf10530d3f",
    "semantic_title": "soft neighbors are positive supporters in contrastive visual representation learning",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=aBH_DydEvoH": {
    "title": "Offline RL for Natural Language Generation with Implicit Language Q Learning",
    "volume": "poster",
    "abstract": "Large language models distill broad knowledge from text corpora. However, they can be inconsistent when it comes to completing user specified tasks. This issue can be addressed by finetuning such models via supervised learning on curated datasets, or via reinforcement learning. In this work, we propose a novel offline RL method, implicit language Q-learning (ILQL), designed for use on language models, that combines both the flexible utility maximization framework of RL algorithms with the ability of supervised learning to leverage previously collected data, as well as its simplicity and stability. Our method employs a combination of value conservatism alongside an implicit dataset support constraint in learning value functions, which are then used to guide language model generations towards maximizing user-specified utility functions. In addition to empirically validating ILQL, we present a detailed empirical analysis of situations where offline RL can be useful in natural language generation settings, demonstrating how it can be a more effective utility optimizer than prior approaches for end-to-end dialogue, and how it can effectively optimize high variance reward functions based on subjective judgement, such as whether to label a comment as toxic or not",
    "checked": true,
    "id": "a5cea6716378949a2b73f0401237d29791a6ee6c",
    "semantic_title": "offline rl for natural language generation with implicit language q learning",
    "citation_count": 126,
    "authors": []
  },
  "https://openreview.net/forum?id=H-T3F0dMbyj": {
    "title": "CLIPSep: Learning Text-queried Sound Separation with Noisy Unlabeled Videos",
    "volume": "poster",
    "abstract": "Recent years have seen progress beyond domain-specific sound separation for speech or music towards universal sound separation for arbitrary sounds. Prior work on universal sound separation has investigated separating a target sound out of an audio mixture given a text query. Such text-queried sound separation systems provide a natural and scalable interface for specifying arbitrary target sounds. However, supervised text-queried sound separation systems require costly labeled audio-text pairs for training. Moreover, the audio provided in existing datasets is often recorded in a controlled environment, causing a considerable generalization gap to noisy audio in the wild. In this work, we aim to approach text-queried universal sound separation by using only unlabeled data. We propose to leverage the visual modality as a bridge to learn the desired audio-textual correspondence. The proposed CLIPSep model first encodes the input query into a query vector using the contrastive language-image pretraining (CLIP) model, and the query vector is then used to condition an audio separation model to separate out the target sound. While the model is trained on image-audio pairs extracted from unlabeled videos, at test time we can instead query the model with text inputs in a zero-shot setting, thanks to the joint language-image embedding learned by the CLIP model. Further, videos in the wild often contain off-screen sounds and background noise that may hinder the model from learning the desired audio-textual correspondence. To address this problem, we further propose an approach called noise invariant training for training a query-based sound separation model on noisy data. Experimental results show that the proposed models successfully learn text-queried universal sound separation using only noisy unlabeled videos, even achieving competitive performance against a supervised model in some settings",
    "checked": true,
    "id": "2c2d85aa20477676741895af5ccc16e129ebe7bc",
    "semantic_title": "clipsep: learning text-queried sound separation with noisy unlabeled videos",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=z57WK5lGeHd": {
    "title": "On the Soft-Subnetwork for Few-Shot Class Incremental Learning",
    "volume": "poster",
    "abstract": "Inspired by Regularized Lottery Ticket Hypothesis, which states that competitive smooth (non-binary) subnetworks exist within a dense network, we propose a few-shot class-incremental learning method referred to as Soft-SubNetworks (SoftNet). Our objective is to learn a sequence of sessions incrementally, where each session only includes a few training instances per class while preserving the knowledge of the previously learned ones. SoftNet jointly learns the model weights and adaptive non-binary soft masks at a base training session in which each mask consists of the major and minor subnetwork; the former aims to minimize catastrophic forgetting during training, and the latter aims to avoid overfitting to a few samples in each new training session. We provide comprehensive empirical validations demonstrating that our SoftNet effectively tackles the few-shot incremental learning problem by surpassing the performance of state-of-the-art baselines over benchmark datasets",
    "checked": true,
    "id": "105c4ac44493c4189c53d39d4838000bc8805535",
    "semantic_title": "on the soft-subnetwork for few-shot class incremental learning",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=6Wl7-M2BC-": {
    "title": "An Adaptive Policy to Employ Sharpness-Aware Minimization",
    "volume": "poster",
    "abstract": "Sharpness-aware minimization (SAM), which searches for flat minima by min-max optimization, has been shown to be useful in improving model generalization. However, since each SAM update requires computing two gradients, its computational cost and training time are both doubled compared to standard empirical risk minimization (ERM). Recent state-of-the-arts reduce the fraction of SAM updates and thus accelerate SAM by switching between SAM and ERM updates randomly or periodically. In this paper, we design an adaptive policy to employ SAM based on the loss landscape geometry. Two efficient algorithms, AE-SAM and AE-LookSAM, are proposed. We theoretically show that AE-SAM has the same convergence rate as SAM. Experimental results on various datasets and architectures demonstrate the efficiency and effectiveness of the adaptive policy",
    "checked": true,
    "id": "8adf430deefe6af08b894d28399eb027c2e8e69e",
    "semantic_title": "an adaptive policy to employ sharpness-aware minimization",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=jBEXnEMdNOL": {
    "title": "Fairness and Accuracy under Domain Generalization",
    "volume": "poster",
    "abstract": "As machine learning (ML) algorithms are increasingly used in high-stakes applications, concerns have arisen that they may be biased against certain social groups. Although many approaches have been proposed to make ML models fair, they typically rely on the assumption that data distributions in training and deployment are identical. Unfortunately, this is commonly violated in practice and a model that is fair during training may lead to an unexpected outcome during its deployment. Although the problem of designing robust ML models under dataset shifts has been widely studied, most existing works focus only on the transfer of accuracy. In this paper, we study the transfer of both fairness and accuracy under domain generalization where the data at test time may be sampled from never-before-seen domains. We first develop theoretical bounds on the unfairness and expected loss at deployment, and then derive sufficient conditions under which fairness and accuracy can be perfectly transferred via invariant representation learning. Guided by this, we design a learning algorithm such that fair ML models learned with training data still have high fairness and accuracy when deployment environments change. Experiments on real-world data validate the proposed algorithm",
    "checked": true,
    "id": "8b4a80daed8331c051e7daf1ae8bc3c9ee3829fb",
    "semantic_title": "fairness and accuracy under domain generalization",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=SaRj2ka1XZ3": {
    "title": "Language Models Can Teach Themselves to Program Better",
    "volume": "poster",
    "abstract": "Recent Language Models (LMs) achieve breakthrough performance in code generation when trained on human-authored problems, even solving some competitive-programming problems. Self-play has proven useful in games such as Go, and thus it is natural to ask whether LMs can generate their own instructive programming problems to improve their performance. We show that it is possible for an LM to synthesize programming problems and solutions, which are filtered for correctness by a Python interpreter. The LM's performance is then seen to improve when it is fine-tuned on its own synthetic problems and verified solutions; thus the model \"improves itself\" using the Python interpreter. Problems are specified formally as programming puzzles [Schuster et al. , 2021], a code-based problem format where solutions can easily be verified for correctness by execution. In experiments on publicly-available LMs, test accuracy more than doubles. This work demonstrates the potential for code LMs, with an interpreter, to generate instructive problems and improve their own performance",
    "checked": true,
    "id": "ff9a0d405e3afd88552e35a0255ddf9e10c28e36",
    "semantic_title": "language models can teach themselves to program better",
    "citation_count": 90,
    "authors": []
  },
  "https://openreview.net/forum?id=yIxtevizEA": {
    "title": "Latent Bottlenecked Attentive Neural Processes",
    "volume": "poster",
    "abstract": "Neural Processes (NPs) are popular methods in meta-learning that can estimate predictive uncertainty on target datapoints by conditioning on a context dataset. Previous state-of-the-art method Transformer Neural Processes (TNPs) achieve strong performance but require quadratic computation with respect to the number of context datapoints, significantly limiting its scalability. Conversely, existing sub-quadratic NP variants perform significantly worse than that of TNPs. Tackling this issue, we propose Latent Bottlenecked Attentive Neural Processes (LBANPs), a new computationally efficient sub-quadratic NP variant, that has a querying computational complexity independent of the number of context datapoints. The model encodes the context dataset into a constant number of latent vectors on which self-attention is performed. When making predictions, the model retrieves higher-order information from the context dataset via multiple cross-attention mechanisms on the latent vectors. We empirically show that LBANPs achieve results competitive with the state-of-the-art on meta-regression, image completion, and contextual multi-armed bandits. We demonstrate that LBANPs can trade-off the computational cost and performance according to the number of latent vectors. Finally, we show LBANPs can scale beyond existing attention-based NP variants to larger dataset settings",
    "checked": true,
    "id": "ff52d3e0abc6874fb752a6258a87dfbac392c86e",
    "semantic_title": "latent bottlenecked attentive neural processes",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=8oJHwb3Sgp": {
    "title": "Represent to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency",
    "volume": "poster",
    "abstract": "Reinforcement learning in partially observed Markov decision processes (POMDPs) faces two challenges. (i) It often takes the full history to predict the future, which induces a sample complexity that scales exponentially with the horizon. (ii) The observation and state spaces are often continuous, which induces a sample complexity that scales exponentially with the extrinsic dimension. Addressing such challenges requires learning a minimal but sufficient representation of the observation and state histories by exploiting the structure of the POMDP. To this end, we propose a reinforcement learning algorithm named Represent to Control (RTC), which learns the representation at two levels while optimizing the policy.~(i) For each step, RTC learns to represent the state with a low-dimensional feature, which factorizes the transition kernel. (ii) Across multiple steps, RTC learns to represent the full history with a low-dimensional embedding, which assembles the per-step feature. We integrate (i) and (ii) in a unified framework that allows a variety of estimators (including maximum likelihood estimators and generative adversarial networks). For a class of POMDPs with a low-rank structure in the transition kernel, RTC attains an $O(1/\\epsilon^2)$ sample complexity that scales polynomially with the horizon and the intrinsic dimension (that is, the rank). Here $\\epsilon$ is the optimality gap. To our best knowledge, RTC is the first sample-efficient algorithm that bridges representation learning and policy optimization in POMDPs with infinite observation and state spaces",
    "checked": true,
    "id": "8051cab7646361d9f9afe79979fae001ef7097d2",
    "semantic_title": "represent to control partially observed systems: representation learning with provable sample efficiency",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5gDz_yTcst": {
    "title": "Towards Better Selective Classification",
    "volume": "poster",
    "abstract": "We tackle the problem of Selective Classification where the objective is to achieve the best performance on a predetermined ratio (coverage) of the dataset. Recent state-of-the-art selective methods come with architectural changes either via introducing a separate selection head or an extra abstention logit. In this paper, we challenge the aforementioned methods. The results suggest that the superior performance of state-of-the-art methods is owed to training a more generalizable classifier rather than their proposed selection mechanisms. We argue that the best performing selection mechanism should instead be rooted in the classifier itself. Our proposed selection strategy uses the classification scores and achieves better results by a significant margin, consistently, across all coverages and all datasets, without any added compute cost. Furthermore, inspired by semi-supervised learning, we propose an entropy-based regularizer that improves the performance of selective classification methods. Our proposed selection mechanism with the proposed entropy-based regularizer achieves new state-of-the-art results",
    "checked": true,
    "id": "23fd30a95dccb8627a5935708a5e76722cde8b05",
    "semantic_title": "towards better selective classification",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=-G1kjTFsSs": {
    "title": "Learning Kernelized Contextual Bandits in a Distributed and Asynchronous Environment",
    "volume": "poster",
    "abstract": "Despite the recent advances in communication-efficient distributed bandit learning, most existing solutions are restricted to parametric models, e.g., linear bandits and generalized linear bandits (GLB). In comparison, kernel bandits, which search for non-parametric functions in a reproducing kernel Hilbert space (RKHS), offer higher modeling capacity. But the only existing work in distributed kernel bandits adopts a synchronous communication protocol, which greatly limits its practical use (e.g., every synchronization step requires all clients to participate and wait for data exchange). In this paper, in order to improve the robustness against delays and unavailability of clients that are common in practice, we propose the first asynchronous solution based on approximated kernel regression for distributed kernel bandit learning. A set of effective treatments are developed to ensure approximation quality and communication efficiency. Rigorous theoretical analysis about the regret and communication cost is provided; and extensive empirical evaluations demonstrate the effectiveness of our solution",
    "checked": true,
    "id": "c31d28f0cafe664624c3b8f0f772441b41171c4e",
    "semantic_title": "learning kernelized contextual bandits in a distributed and asynchronous environment",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=G_HSyfLk0m": {
    "title": "Graph Signal Sampling for Inductive One-Bit Matrix Completion: a Closed-form Solution",
    "volume": "poster",
    "abstract": "Inductive one-bit matrix completion is motivated by modern applications such as recommender systems, where new users would appear at test stage with the ratings consisting of only ones and no zeros. We propose a unified graph signal sampling framework which enjoys the benefits of graph signal analysis and processing. The key idea is to transform each user's ratings on the items to a function (signal) on the vertices of an item-item graph, then learn structural graph properties to recover the function from its values on certain vertices --- the problem of graph signal sampling. We propose a class of regularization functionals that takes into account discrete random label noise in the graph vertex domain, then develop the GS-IMC approach which biases the reconstruction towards functions that vary little between adjacent vertices for noise reduction. Theoretical result shows that accurate reconstructions can be achieved under mild conditions. For the online setting, we develop a Bayesian extension, i.e., BGS-IMC which considers continuous random Gaussian noise in the graph Fourier domain and builds upon a prediction-correction update algorithm to obtain the unbiased and minimum-variance reconstruction. Both GS-IMC and BGS-IMC have closed-form solutions and thus are highly scalable in large data. Experiments show that our methods achieve state-of-the-art performance on public benchmarks",
    "checked": true,
    "id": "9d5a25d072e4689be4d5ed879d940b21bc6b2398",
    "semantic_title": "graph signal sampling for inductive one-bit matrix completion: a closed-form solution",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=cHf1DcCwcH3": {
    "title": "LipsFormer: Introducing Lipschitz Continuity to Vision Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d3a6e9790ef423497e855bdacbbc357e962ddd71",
    "semantic_title": "lipsformer: introducing lipschitz continuity to vision transformers",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=5NTt8GFjUHkr": {
    "title": "Automatic Chain of Thought Prompting in Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "90350aa626bed47b02d0c162462e5b0ca82be6b2",
    "semantic_title": "automatic chain of thought prompting in large language models",
    "citation_count": 726,
    "authors": []
  },
  "https://openreview.net/forum?id=fzberKYWKsI": {
    "title": "An efficient encoder-decoder architecture with top-down attention for speech separation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "965c80b37c51ef0f380e0a3af5650b7ffef78f00",
    "semantic_title": "an efficient encoder-decoder architecture with top-down attention for speech separation",
    "citation_count": 62,
    "authors": []
  },
  "https://openreview.net/forum?id=VzwfoFyYDga": {
    "title": "Machine Unlearning of Federated Clusters",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "742c39b9fd2db956a94211030a90d8060ab881be",
    "semantic_title": "machine unlearning of federated clusters",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=7D5EECbOaf9": {
    "title": "Moderate Coreset: A Universal Method of Data Selection for Real-world Data-efficient Deep Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8f683dbe9ac52a4faef2464b99eabbbba1ab211d",
    "semantic_title": "moderate coreset: a universal method of data selection for real-world data-efficient deep learning",
    "citation_count": 110,
    "authors": []
  },
  "https://openreview.net/forum?id=R1U5G2spbLd": {
    "title": "Federated Nearest Neighbor Machine Translation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3e9b1229a20663579334fff95146daee1b348e3e",
    "semantic_title": "federated nearest neighbor machine translation",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=mQpmZVzXK1h": {
    "title": "Latent Variable Representation for Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5fee006a53b0c6e2879c3bfce3b46e370ea0398e",
    "semantic_title": "latent variable representation for reinforcement learning",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=2r6YMqz4Mml": {
    "title": "ROCO: A General Framework for Evaluating Robustness of Combinatorial Optimization Solvers on Graphs",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2e2c56325c3caac544285f46187c33439b211962",
    "semantic_title": "roco: a general framework for evaluating robustness of combinatorial optimization solvers on graphs",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=O-G91-4cMdv": {
    "title": "Words are all you need? Language as an approximation for human similarity judgments",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3366e1fac06f0fbb346d7b96995338a079331aa0",
    "semantic_title": "words are all you need? language as an approximation for human similarity judgments",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=PDrUPTXJI_A": {
    "title": "FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a4c99a1f69909443b3ca895cdd3dc78070c03377",
    "semantic_title": "freematch: self-adaptive thresholding for semi-supervised learning",
    "citation_count": 323,
    "authors": []
  },
  "https://openreview.net/forum?id=sOXU-PEJSgQ": {
    "title": "Confidence Estimation Using Unlabeled Data",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "422408227a26b3c0f5935bd43b26c36b9bd7b0c9",
    "semantic_title": "confidence estimation using unlabeled data",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=FBMLeaXpZN": {
    "title": "Spectral Decomposition Representation for Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "42929aa6ebf8cdc0e7d7662751dc228de07800bb",
    "semantic_title": "spectral decomposition representation for reinforcement learning",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=fYzLpCsGZVf": {
    "title": "On Accelerated Perceptrons and Beyond",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "debf64b879e07c8eee101c39d2980db7a8140503",
    "semantic_title": "on accelerated perceptrons and beyond",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=ymt1zQXBDiF": {
    "title": "SoftMatch: Addressing the Quantity-Quality Tradeoff in Semi-supervised Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "100da279ee981960884a12dfc5a0697c24ed315a",
    "semantic_title": "softmatch: addressing the quantity-quality trade-off in semi-supervised learning",
    "citation_count": 178,
    "authors": []
  },
  "https://openreview.net/forum?id=dCOL0inGl3e": {
    "title": "Certifiably Robust Policy Learning against Adversarial Multi-Agent Communication",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4678c9f7ce7d91bc1770e64856b4ab9e050af2e2",
    "semantic_title": "certifiably robust policy learning against adversarial multi-agent communication",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=LE5LxBgjB4V": {
    "title": "Disentangling the Mechanisms Behind Implicit Regularization in SGD",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d91d57242ecc2e400f819c502e3367127fa16368",
    "semantic_title": "disentangling the mechanisms behind implicit regularization in sgd",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=TTLLGx3eet": {
    "title": "Sequential Attention for Feature Selection",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2d86e852f12b40af4074551a9fac47bc817f7da3",
    "semantic_title": "sequential attention for feature selection",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=jpsw-KuOi7r": {
    "title": "Improved Sample Complexity for Reward-free Reinforcement Learning under Low-rank MDPs",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "439c9ca1fdfcc0d794fee946eba10463fcd85a95",
    "semantic_title": "improved sample complexity for reward-free reinforcement learning under low-rank mdps",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=XSEBx0iSjFQ": {
    "title": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ec1ac8df419a241c3cc6bfd209a38b494af792ee",
    "semantic_title": "re-imagen: retrieval-augmented text-to-image generator",
    "citation_count": 200,
    "authors": []
  },
  "https://openreview.net/forum?id=Qd0p0bl-A9t": {
    "title": "Provably Efficient Lifelong Reinforcement Learning with Linear Representation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c18432b02714830ad78aab976431006f929151a6",
    "semantic_title": "provably efficient lifelong reinforcement learning with linear representation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=9Jaz4APHtWD": {
    "title": "Link Prediction with Non-Contrastive Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b0e870b0ac63b97f1328ff3eeda14edd99dde109",
    "semantic_title": "link prediction with non-contrastive learning",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=cw8FeirkIfU": {
    "title": "Distributed Differential Privacy in Multi-Armed Bandits",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "63625a2a1250d6be300413ea584d052afb9d9d81",
    "semantic_title": "distributed differential privacy in multi-armed bandits",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=jClGv3Qjhb": {
    "title": "A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "91166a75f0e32b782a57028f1501aba6335ac550",
    "semantic_title": "a theoretical understanding of shallow vision transformers: learning, generalization, and sample complexity",
    "citation_count": 68,
    "authors": []
  },
  "https://openreview.net/forum?id=AjC0KBjiMu": {
    "title": "Contrastive Learning Can Find An Optimal Basis For Approximately View-Invariant Functions",
    "volume": "poster",
    "abstract": "Contrastive learning is a powerful framework for learning self-supervised representations that generalize well to downstream supervised tasks. We show that multiple existing contrastive learning methods can be reinterpeted as learning kernel functions that approximate a fixed *positive-pair kernel*. We then prove that a simple representation obtained by combining this kernel with PCA provably minimizes the worst-case approximation error of linear predictors, under a straightforward assumption that positive pairs have similar labels. Our analysis is based on a decomposition of the target function in terms of the eigenfunctions of a positive-pair Markov chain, and a surprising equivalence between these eigenfunctions and the output of Kernel PCA. We give generalization bounds for downstream linear prediction using our kernel PCA representation, and show empirically on a set of synthetic tasks that applying kernel PCA to contrastive learning models can indeed approximately recover the Markov chain eigenfunctions, although the accuracy depends on the kernel parameterization as well as on the augmentation strength",
    "checked": true,
    "id": "15e7f019669d22039ac0c9c9b4dad5193b341443",
    "semantic_title": "contrastive learning can find an optimal basis for approximately view-invariant functions",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=DlpCotqdTy": {
    "title": "Provably Auditing Ordinary Least Squares in Low Dimensions",
    "volume": "poster",
    "abstract": "Auditing the stability of a machine learning model to small changes in the training procedure is critical for engendering trust in practical applications. For example, a model should not be overly sensitive to removing a small fraction of its training data. However, algorithmically validating this property seems computationally challenging, even for the simplest of models: Ordinary Least Squares (OLS) linear regression. Concretely, recent work defines the stability of a regression as the minimum number of samples that need to be removed so that rerunning the analysis overturns the conclusion (Broderick et al., 2020), specifically meaning that the sign of a particular coefficient of the OLS regressor changes. But the only known approach for estimating this metric, besides the obvious exponential-time algorithm, is a greedy heuristic that may produce severe overestimates and therefore cannot certify stability. We show that stability can be efficiently certified in the low-dimensional regime: when the number of covariates is a constant but the number of samples is large, there are polynomial-time algorithms for estimating (a fractional version of) stability, with provable approximation guarantees. Applying our algorithms to the Boston Housing dataset, we exhibit regression analyses where our estimator outperforms the greedy heuristic, and can successfully certify stability even in the regime where a constant fraction of the samples are dropped",
    "checked": true,
    "id": "b2434a9a214c4b1eea48961c1afb0ced8faefcc5",
    "semantic_title": "provably auditing ordinary least squares in low dimensions",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=Qamz7Q_Ta1k": {
    "title": "Direct Embedding of Temporal Network Edges via Time-Decayed Line Graphs",
    "volume": "poster",
    "abstract": "Temporal networks model a variety of important phenomena involving timed interactions between entities. Existing methods for machine learning on temporal networks generally exhibit at least one of two limitations. First, many methods assume time to be discretized, so if the time data is continuous, the user must determine the discretization and discard precise time information. Second, edge representations can only be calculated indirectly from the nodes, which may be suboptimal for tasks like edge classification. We present a simple method that avoids both shortcomings: construct the line graph of the network, which includes a node for each interaction, and weigh the edges of this graph based on the difference in time between interactions. From this derived graph, edge representations for the original network can be computed with efficient classical methods. The simplicity of this approach facilitates explicit theoretical analysis: we can constructively show the effectiveness of our method's representations for a natural synthetic model of temporal networks. Empirical results on real-world networks demonstrate our method's efficacy and efficiency on both link classification and prediction",
    "checked": true,
    "id": "0e3e1496a7db8907d8236bc1e6841181cc0443e9",
    "semantic_title": "direct embedding of temporal network edges via time-decayed line graphs",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=WL8FlAugqQ": {
    "title": "Neural DAG Scheduling via One-Shot Priority Sampling",
    "volume": "poster",
    "abstract": "We consider the problem of scheduling operations/nodes, the dependency among which is characterized by a Directed Acyclic Graph (DAG). Due to its NP-hard nature, heuristic algorithms were traditionally used to acquire reasonably good solutions, and more recent works have proposed Machine Learning (ML) heuristics that can generalize to unseen graphs and outperform the non-ML heuristics. However, it is computationally costly to generate solutions using existing ML schedulers since they adopt the episodic reinforcement learning framework that necessitates multi-round neural network processing. We propose a novel ML scheduler that uses a one-shot neural network encoder to sample node priorities which are converted by list scheduling to the final schedules. Since the one-shot encoder can efficiently sample the priorities in parallel, our algorithm runs significantly faster than existing ML baselines and has comparable run time with the fast traditional heuristics. We empirically show that our algorithm generates better schedules than both non-neural and neural baselines across various real-world and synthetic scheduling tasks",
    "checked": true,
    "id": "0e816678a221eb4d6a43cc877fae0587c91a0bab",
    "semantic_title": "neural dag scheduling via one-shot priority sampling",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=QZfdDpTX1uM": {
    "title": "Meta Temporal Point Processes",
    "volume": "poster",
    "abstract": "A temporal point process (TPP) is a stochastic process where its realization is a sequence of discrete events in time. Recent work in TPPs model the process using a neural network in a supervised learning framework, where a training set is a collection of all the sequences. In this work, we propose to train TPPs in a meta learning framework, where each sequence is treated as a different task, via a novel framing of TPPs as neural processes (NPs). We introduce context sets to model TPPs as an instantiation of NPs. Motivated by attentive NP, we also introduce local history matching to help learn more informative features. We demonstrate the potential of the proposed method on popular public benchmark datasets and tasks, and compare with state-of-the-art TPP methods",
    "checked": true,
    "id": "decac76160a3ff2a56fed12f4f320adcc4e5c5c4",
    "semantic_title": "meta temporal point processes",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=flap0Bo6TK_": {
    "title": "Graph Neural Network-Inspired Kernels for Gaussian Processes in Semi-Supervised Learning",
    "volume": "poster",
    "abstract": "Gaussian processes (GPs) are an attractive class of machine learning models because of their simplicity and flexibility as building blocks of more complex Bayesian models. Meanwhile, graph neural networks (GNNs) emerged recently as a promising class of models for graph-structured data in semi-supervised learning and beyond. Their competitive performance is often attributed to a proper capturing of the graph inductive bias. In this work, we introduce this inductive bias into GPs to improve their predictive performance for graph-structured data. We show that a prominent example of GNNs, the graph convolutional network, is equivalent to some GP when its layers are infinitely wide; and we analyze the kernel universality and the limiting behavior in depth. We further present a programmable procedure to compose covariance kernels inspired by this equivalence and derive example kernels corresponding to several interesting members of the GNN family. We also propose a computationally efficient approximation of the covariance matrix for scalable posterior inference with large-scale data. We demonstrate that these graph-based kernels lead to competitive classification and regression performance, as well as advantages in computation time, compared with the respective GNNs",
    "checked": true,
    "id": "6a7e86550dfe2652e63ae65bf9eed9ce54a3128d",
    "semantic_title": "graph neural network-inspired kernels for gaussian processes in semi-supervised learning",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=9IaN4FkVSR1": {
    "title": "Deconstructing Distributions: A Pointwise Framework of Learning",
    "volume": "poster",
    "abstract": "In machine learning, we traditionally evaluate the performance of a single model, averaged over a collection of test inputs. In this work, we propose a new approach: we measure the performance of a collection of models when evaluated at *single input point*. Specifically, we study a point's *profile*: the relationship between models' average performance on the test distribution and their pointwise performance on this individual point. We find that profiles can yield new insights into the structure of both models and data---in and out-of-distribution. For example, we empirically show that real data distributions consist of points with qualitatively different profiles. On one hand, there are ``compatible'' points with strong correlation between the pointwise and average performance. On the other hand, there are points with weak and even *negative* correlation: cases where improving overall model accuracy actually *hurts* performance on these inputs. As an application, we use profiles to construct a dataset we call CIFAR-10-NEG: a subset of CINIC-10 such that for standard models, accuracy on CIFAR-10-NEG is *negatively correlated* with CIFAR-10 accuracy. Illustrating for the first time an OOD dataset that completely inverts ``accuracy-on-the-line'' (Miller et al., 2021)",
    "checked": true,
    "id": "04ff95e0edc3759fc5d18a1b929b3ccf79b032b2",
    "semantic_title": "deconstructing distributions: a pointwise framework of learning",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=Idusfje4-Wq": {
    "title": "Diffusion Models for Causal Discovery via Topological Ordering",
    "volume": "poster",
    "abstract": "Discovering causal relations from observational data becomes possible with additional assumptions such as considering the functional relations to be constrained as nonlinear with additive noise (ANM). Even with strong assumptions, causal discovery involves an expensive search problem over the space of directed acyclic graphs (DAGs). \\emph{Topological ordering} approaches reduce the optimisation space of causal discovery by searching over a permutation rather than graph space. For ANMs, the \\emph{Hessian} of the data log-likelihood can be used for finding leaf nodes in a causal graph, allowing its topological ordering. However, existing computational methods for obtaining the Hessian still do not scale as the number of variables and the number of samples are increased. Therefore, inspired by recent innovations in diffusion probabilistic models (DPMs), we propose \\emph{DiffAN}, a topological ordering algorithm that leverages DPMs for learning a Hessian function. We introduce theory for updating the learned Hessian without re-training the neural network, and we show that computing with a subset of samples gives an accurate approximation of the ordering, which allows scaling to datasets with more samples and variables. We show empirically that our method scales exceptionally well to datasets with up to $500$ nodes and up to $10^5$ samples while still performing on par over small datasets with state-of-the-art causal discovery methods. Implementation is available at \\url{https://github.com/vios-s/DiffAN}",
    "checked": true,
    "id": "1ffd02a5ef1ecd0321df2c3265234eee8bc3d151",
    "semantic_title": "diffusion models for causal discovery via topological ordering",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=eb_cpjZZ3GH": {
    "title": "Scalable and Equivariant Spherical CNNs by Discrete-Continuous (DISCO) Convolutions",
    "volume": "poster",
    "abstract": "No existing spherical convolutional neural network (CNN) framework is both computationally scalable and rotationally equivariant. Continuous approaches capture rotational equivariance but are often prohibitively computationally demanding. Discrete approaches offer more favorable computational performance but at the cost of equivariance. We develop a hybrid discrete-continuous (DISCO) group convolution that is simultaneously equivariant and computationally scalable to high-resolution. While our framework can be applied to any compact group, we specialize to the sphere. Our DISCO spherical convolutions exhibit $\\text{SO}(3)$ rotational equivariance, where $\\text{SO}(n)$ is the special orthogonal group representing rotations in $n$-dimensions. When restricting rotations of the convolution to the quotient space $\\text{SO}(3)/\\text{SO}(2)$ for further computational enhancements, we recover a form of asymptotic $\\text{SO}(3)$ rotational equivariance. Through a sparse tensor implementation we achieve linear scaling in number of pixels on the sphere for both computational cost and memory usage. For 4k spherical images we realize a saving of $10^9$ in computational cost and $10^4$ in memory usage when compared to the most efficient alternative equivariant spherical convolution. We apply the DISCO spherical CNN framework to a number of benchmark dense-prediction problems on the sphere, such as semantic segmentation and depth estimation, on all of which we achieve the state-of-the-art performance",
    "checked": true,
    "id": "75680b206517d09136e4ecd4577e72bf3d919345",
    "semantic_title": "scalable and equivariant spherical cnns by discrete-continuous (disco) convolutions",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=Hu4r-dedqR0": {
    "title": "Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic",
    "volume": "poster",
    "abstract": "Natural language inference (NLI) aims to determine the logical relationship between two sentences, such as Entailment, Contradiction, and Neutral. In recent years, deep learning models have become a prevailing approach to NLI, but they lack interpretability and explainability. In this work, we address the explainability of NLI by weakly supervised logical reasoning, and propose an Explainable Phrasal Reasoning (EPR) approach. Our model first detects phrases as the semantic unit and aligns corresponding phrases in the two sentences. Then, the model predicts the NLI label for the aligned phrases, and induces the sentence label by fuzzy logic formulas. Our EPR is almost everywhere differentiable and thus the system can be trained end to end. In this way, we are able to provide explicit explanations of phrasal logical relationships in a weakly supervised manner. We further show that such reasoning results help textual explanation generation",
    "checked": true,
    "id": "dc7c33da4d804fcd02becc00a8c7039ea1c14d4f",
    "semantic_title": "weakly supervised explainable phrasal reasoning with neural fuzzy logic",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=462z-gLgSht": {
    "title": "DCI-ES: An Extended Disentanglement Framework with Connections to Identifiability",
    "volume": "poster",
    "abstract": "In representation learning, a common approach is to seek representations which disentangle the underlying factors of variation. Eastwood & Williams (2018) proposed three metrics for quantifying the quality of such disentangled representations: disentanglement (D), completeness (C) and informativeness (I). In this work, we first connect this DCI framework to two common notions of linear and nonlinear identifiability, thereby establishing a formal link between disentanglement and the closely-related field of independent component analysis. We then propose an extended DCI-ES framework with two new measures of representation quality—explicitness (E) and size (S)—and point out how D and C can be computed for black-box predictors. Our main idea is that the functional capacity required to use a representation is an important but thus-far neglected aspect of representation quality, which we quantify using explicitness or ease-of-use (E). We illustrate the relevance of our extensions on the MPI3D and Cars3D datasets",
    "checked": true,
    "id": "461630c5126fb457b2396ed5238fff0977e94b5a",
    "semantic_title": "dci-es: an extended disentanglement framework with connections to identifiability",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=ElC6LYO4MfD": {
    "title": "Faster federated optimization under second-order similarity",
    "volume": "poster",
    "abstract": "Federated learning (FL) is a subfield of machine learning where multiple clients try to collaboratively learn a model over a network under communication constraints. We consider finite-sum federated optimization under a second-order function similarity condition and strong convexity, and propose two new algorithms: SVRP and Catalyzed SVRP. This second-order similarity condition has grown popular recently, and is satisfied in many applications including distributed statistical learning and differentially private empirical risk minimization. The first algorithm, SVRP, combines approximate stochastic proximal point evaluations, client sampling, and variance reduction. We show that SVRP is communication efficient and achieves superior performance to many existing algorithms when function similarity is high enough. Our second algorithm, Catalyzed SVRP, is a Catalyst-accelerated variant of SVRP that achieves even better performance and uniformly improves upon existing algorithms for federated optimization under second-order similarity and strong convexity. In the course of analyzing these algorithms, we provide a new analysis of the Stochastic Proximal Point Method (SPPM) that might be of independent interest. Our analysis of SPPM is simple, allows for approximate proximal point evaluations, does not require any smoothness assumptions, and shows a clear benefit in communication complexity over ordinary distributed stochastic gradient descent",
    "checked": true,
    "id": "58a7d51c3dd42f567fddb64c725876112bdb78d9",
    "semantic_title": "faster federated optimization under second-order similarity",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=EUrxG8IBCrC": {
    "title": "Mutual Partial Label Learning with Competitive Label Noise",
    "volume": "poster",
    "abstract": "Partial label learning (PLL) is an important weakly supervised learning problem, where each training instance is associated with a set of candidate labels that include both the true label and additional noisy labels. Most existing PLL methods assume the candidate noisy labels are randomly chosen, which hardly holds in real-world learning scenarios. In this paper, we consider a more realistic PLL scenario with competitive label noise that is more difficult to distinguish from the true label than the random label noise. We propose a novel Mutual Learning based PLL approach named ML-PLL to address this challenging problem. ML-PLL learns a prediction network based classifier and a class-prototype based classifier cooperatively through interactive mutual learning and label correction. Moreover, we use a transformation network to model the association relationships between the true label and candidate labels, and learn it together with the prediction network to match the observed candidate labels in the training data and enhance label correction. Extensive experiments are conducted on several benchmark PLL datasets, and the proposed ML-PLL approach demonstrates state-of-the-art performance for partial label learning",
    "checked": true,
    "id": "edfa307182bbfb5b4dd34645eada01f540af66c4",
    "semantic_title": "mutual partial label learning with competitive label noise",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=jpq0qHggw3t": {
    "title": "Partial Label Unsupervised Domain Adaptation with Class-Prototype Alignment",
    "volume": "poster",
    "abstract": "Partial label learning (PLL) tackles the problem where each instance is associated with a set of candidate labels, only one of which is the ground-truth label. Most existing PLL approaches assume that both the training and test sets share an identical data distribution. However, this assumption does not hold in many real-world scenarios where the training and test data come from different distributions. In this paper, we formalize this learning scenario as a new problem called partial label unsupervised domain adaptation (PLUDA). To address this challenging PLUDA problem, we propose a novel Prototype Alignment based PLUDA method named PAPLUDA, which dynamically refines the pseudo-labels of instances from both the source and target domains by consulting the outputs of a teacher-student model in a moving-average manner, and bridges the cross-domain discrepancy through inter-domain class-prototype alignment. In addition, a teacher-student model based contrastive regularization is deployed to enhance prediction stability and hence improve the class-prototypes in both domains for PLUDA. Comprehensive experimental results demonstrate that PAPLUDA achieves state-of-the-art performance on the widely used benchmark datasets",
    "checked": true,
    "id": "fe9e90e23484cd7d0a6e34e0391a2206d37d999f",
    "semantic_title": "partial label unsupervised domain adaptation with class-prototype alignment",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=9HiGqC9C-KA": {
    "title": "simpleKT: A Simple But Tough-to-Beat Baseline for Knowledge Tracing",
    "volume": "poster",
    "abstract": "Knowledge tracing (KT) is the problem of predicting students' future performance based on their historical interactions with intelligent tutoring systems. Recently, many works present lots of special methods for applying deep neural networks to KT from different perspectives like model architecture, adversarial augmentation and etc., which make the overall algorithm and system become more and more complex. Furthermore, due to the lack of standardized evaluation protocol \\citep{liu2022pykt}, there is no widely agreed KT baselines and published experimental comparisons become inconsistent and self-contradictory, i.e., the reported AUC scores of DKT on ASSISTments2009 range from 0.721 to 0.821 \\citep{minn2018deep,yeung2018addressing}. Therefore, in this paper, we provide a strong but simple baseline method to deal with the KT task named \\textsc{simpleKT}. Inspired by the Rasch model in psychometrics, we explicitly model question-specific variations to capture the individual differences among questions covering the same set of knowledge components that are a generalization of terms of concepts or skills needed for learners to accomplish steps in a task or a problem. Furthermore, instead of using sophisticated representations to capture student forgetting behaviors, we use the ordinary dot-product attention function to extract the time-aware information embedded in the student learning interactions. Extensive experiments show that such a simple baseline is able to always rank top 3 in terms of AUC scores and achieve 57 wins, 3 ties and 16 loss against 12 DLKT baseline methods on 7 public datasets of different domains. We believe this work serves as a strong baseline for future KT research. Code is available at \\url{https://github.com/pykt-team/pykt-toolkit}\\footnote{We merged our model to the \\textsc{pyKT} benchmark at \\url{https://pykt.org/}.}",
    "checked": true,
    "id": "e6ed6f3fb7537f525f405553240f6d598fbca0ae",
    "semantic_title": "simplekt: a simple but tough-to-beat baseline for knowledge tracing",
    "citation_count": 58,
    "authors": []
  },
  "https://openreview.net/forum?id=CL-sVR9pvF": {
    "title": "Weighted Ensemble Self-Supervised Learning",
    "volume": "poster",
    "abstract": "Ensembling has proven to be a powerful technique for boosting model performance, uncertainty estimation, and robustness in supervised learning. Advances in self-supervised learning (SSL) enable leveraging large unlabeled corpora for state-of-the-art few-shot and supervised learning performance. In this paper, we explore how ensemble methods can improve recent SSL techniques by developing a framework that permits data-dependent weighted cross-entropy losses. We refrain from ensembling the representation backbone; this choice yields an efficient ensemble method that incurs a small training cost and requires no architectural changes or computational overhead to downstream evaluation. The effectiveness of our method is demonstrated with two state-of-the-art SSL methods, DINO (Caron et al., 2021) and MSN (Assran et al., 2022). Our method outperforms both in multiple evaluation metrics on ImageNet-1K, particularly in the few-shot setting. We explore several weighting schemes and find that those which increase the diversity of ensemble heads lead to better downstream evaluation results. Thorough experiments yield improved prior art baselines which our method still surpasses; e.g., our overall improvement with MSN ViT-B/16 is 3.9 p.p. for 1-shot learning",
    "checked": true,
    "id": "db4de65a7415bb23af4ec40cbc78bce2208b2aa0",
    "semantic_title": "weighted ensemble self-supervised learning",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=zzqBoIFOQ1": {
    "title": "Guiding Safe Exploration with Weakest Preconditions",
    "volume": "poster",
    "abstract": "In reinforcement learning for safety-critical settings, it is often desirable for the agent to obey safety constraints at all points in time, including during training. We present a novel neurosymbolic approach called SPICE to solve this safe exploration problem. SPICE uses an online shielding layer based on symbolic weakest preconditions to achieve a more precise safety analysis than existing tools without unduly impacting the training process. We evaluate the approach on a suite of continuous control benchmarks and show that it can achieve comparable performance to existing safe learning techniques while incurring fewer safety violations. Additionally, we present theoretical results showing that SPICE converges to the optimal safe policy under reasonable assumptions",
    "checked": true,
    "id": "f552ea23e70adaa0b160dd02efb2c46d5224a3b0",
    "semantic_title": "guiding safe exploration with weakest preconditions",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=cYijsVZhb5": {
    "title": "Is a Caption Worth a Thousand Images? A Study on Representation Learning",
    "volume": "poster",
    "abstract": "The development of CLIP [Radford et al., 2021] has sparked a debate on whether adding language supervision can yield vision models with more transferable representations than traditional image-only methods. Our work studies this question through a carefully controlled comparison of two approaches, in terms of their ability to learn representations that generalize to downstream classification tasks. We find that when the pre-training data meets certain criteria---it is sufficiently large and contains descriptive captions with low variability----image-only methods do not match CLIP's performance even when they are trained with more image data. However, contrary to what one might expect, there are practical settings in which these criteria are not met, wherein added supervision through captions is actually detrimental. Motivated by our findings, we devise simple data and algorithmic interventions to improve the transfer performance of CLIP-style models",
    "checked": true,
    "id": "8ae769c817612c0c09615d96af4d6de351207041",
    "semantic_title": "is a caption worth a thousand images? a study on representation learning",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=XSRSWxyJIC": {
    "title": "Parameter-Efficient Fine-Tuning Design Spaces",
    "volume": "poster",
    "abstract": "Parameter-efficient fine-tuning aims to achieve comparable performances of fine-tuning with much fewer trainable parameters. Recently, various tuning strategies (e.g., Adapters, Prefix Tuning, BitFit, and LoRA) have been proposed. However, their designs are hand-crafted separately, and it remains unclear whether certain design patterns exist for parameter-efficient fine-tuning. Thus, we present a parameter-efficient fine-tuning design paradigm and discover design patterns that are applicable to different experimental settings. Instead of focusing on designing another individual tuning strategy, we introduce parameter-efficient fine-tuning design spaces that parameterize tuning structures and tuning strategies. Specifically, any design space is characterized by four components: layer grouping, trainable parameter allocation, tunable groups, and strategy assignment. Our comprehensive empirical study leads to the discovery of design patterns: (i) grouping layers in a spindle pattern, (ii) uniformly allocating the number of trainable parameters to layers, (ii) tuning all the groups, and (iv) tuning different groups with proper strategies. Our discovered design patterns result in new parameter-efficient fine-tuning methods. Experiments show that these methods consistently outperform investigated parameter-efficient fine-tuning strategies across different backbone models and different tasks in natural language processing",
    "checked": true,
    "id": "220ddeb4dc43bc922289fec8b1b60d7226068b20",
    "semantic_title": "parameter-efficient fine-tuning design spaces",
    "citation_count": 71,
    "authors": []
  },
  "https://openreview.net/forum?id=_01dDd3f78": {
    "title": "Concept Gradient: Concept-based Interpretation Without Linear Assumption",
    "volume": "poster",
    "abstract": "Concept-based interpretations of black-box models are often more intuitive for humans to understand. The most widely adopted approach for concept-based, gradient interpretation is Concept Activation Vector (CAV). CAV relies on learning a linear relation between some latent representation of a given model and concepts. The premise of meaningful concepts lying in a linear subspace of model layers is usually implicitly assumed but does not hold true in general. In this work we proposed Concept Gradient (CG), which extends concept-based, gradient interpretation methods to non-linear concept functions. We showed that for a general (potentially non-linear) concept, we can mathematically measure how a small change of concept affects the model's prediction, which is an extension of gradient-based interpretation to the concept space. We demonstrated empirically that CG outperforms CAV in attributing concept importance on real world datasets and performed case study on a medical dataset. The code is available at github.com/jybai/concept-gradients",
    "checked": true,
    "id": "ab5e6f8e01ce666fef96fd790fdb30e4e94d18ad",
    "semantic_title": "concept gradient: concept-based interpretation without linear assumption",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=1w_Amtk67X": {
    "title": "Constraining Representations Yields Models That Know What They Don't Know",
    "volume": "poster",
    "abstract": "A well-known failure mode of neural networks is that they may confidently return erroneous predictions. Such unsafe behaviour is particularly frequent when the use case slightly differs from the training context, and/or in the presence of an adversary. This work presents a novel direction to address these issues in a broad, general manner: imposing class-aware constraints on a model's internal activation patterns. Specifically, we assign to each class a unique, fixed, randomly-generated binary vector - hereafter called class code - and train the model so that its cross-depths activation patterns predict the appropriate class code according to the input sample's class. The resulting predictors are dubbed total activation classifiers (TAC), and TACs may either be trained from scratch, or used with negligible cost as a thin add-on on top of a frozen, pre-trained neural network. The distance between a TAC's activation pattern and the closest valid code acts as an additional confidence score, besides the default unTAC'ed prediction head's. In the add-on case, the original neural network's inference head is completely unaffected (so its accuracy remains the same) but we now have the option to use TAC's own confidence and prediction when determining which course of action to take in an hypothetical production workflow. In particular, we show that TAC strictly improves the value derived from models allowed to reject/defer. We provide further empirical evidence that TAC works well on multiple types of architectures and data modalities and that it is at least as good as state-of-the-art alternative confidence scores derived from existing models",
    "checked": true,
    "id": "d43f83260f6855eea99c446dd2e1e1e6abcd7fae",
    "semantic_title": "constraining representations yields models that know what they don't know",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n70oyIlS4g": {
    "title": "An Extensible Multi-modal Multi-task Object Dataset with Materials",
    "volume": "poster",
    "abstract": "We present EMMa, an Extensible, Multimodal dataset of Amazon product listings that contains rich Material annotations. It contains more than 2.8 million objects, each with image(s), listing text, mass, price, product ratings, and position in Amazon's product-category taxonomy. We also design a comprehensive taxonomy of 182 physical materials (e.g., Plastic → Thermoplastic → Acrylic). Objects areannotated with one or more materials from this taxonomy. With the numerous attributes available for each object, we develop a Smart Labeling framework to quickly add new binary labels to all objects with very little manual labeling effort, making the dataset extensible. Each object attribute in our dataset can be included in either the model inputs or outputs, leading to combinatorial possibilities in task configurations. For example, we can train a model to predict the object category from the listing text, or the mass and price from the product listing image. EMMa offers a new benchmark for multi-task learning in computer vision and NLP, and allows practitioners to efficiently add new tasks and object attributes at scale",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zWy7dqOcel": {
    "title": "Sampling with Mollified Interaction Energy Descent",
    "volume": "poster",
    "abstract": "Sampling from a target measure whose density is only known up to a normalization constant is a fundamental problem in computational statistics and machine learning. In this paper, we present a new optimization-based method for sampling called mollified interaction energy descent (MIED). MIED minimizes a new class of energies on probability measures called mollified interaction energies (MIEs). These energies rely on mollifier functions---smooth approximations of the Dirac delta originated from PDE theory. We show that as the mollifier approaches the Dirac delta, the MIE converges to the chi-square divergence with respect to the target measure and the gradient flow of the MIE agrees with that of the chi-square divergence. Optimizing this energy with proper discretization yields a practical first-order particle-based algorithm for sampling in both unconstrained and constrained domains. We show experimentally that for unconstrained sampling problems our algorithm performs on par with existing particle-based algorithms like SVGD, while for constrained sampling problems our method readily incorporates constrained optimization techniques to handle more flexible constraints with strong performance compared to alternatives",
    "checked": true,
    "id": "19ee642ac5e18428c3c3081d8c814aea161f8417",
    "semantic_title": "sampling with mollified interaction energy descent",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=nhKHA59gXz": {
    "title": "Self-Stabilization: The Implicit Bias of Gradient Descent at the Edge of Stability",
    "volume": "poster",
    "abstract": "Traditional analyses of gradient descent show that when the largest eigenvalue of the Hessian, also known as the sharpness $S(\\theta)$, is bounded by $2/\\eta$, training is \"stable\" and the training loss decreases monotonically. Recent works, however, have observed that this assumption does not hold when training modern neural networks with full batch or large batch gradient descent. Most recently, Cohen at al. (2021) detailed two important phenomena. The first, dubbed \\emph{progressive sharpening}, is that the sharpness steadily increases throughout training until it reaches the instability cutoff $2/\\eta$. The second, dubbed \\emph{edge of stability}, is that the sharpness hovers at $2/\\eta$ for the remainder of training while the loss continues decreasing, albeit non-monotonically. We demonstrate that, far from being chaotic, the dynamics of gradient descent at the edge of stability can be captured by a cubic Taylor expansion: as the iterates diverge in direction of the top eigenvector of the Hessian due to instability, the cubic term in the local Taylor expansion of the loss function causes the curvature to decrease until stability is restored. This property, which we call \\emph{self-stabilization}, is a general property of gradient descent and explains its behavior at the edge of stability. A key consequence of self-stabilization is that gradient descent at the edge of stability implicitly follows \\emph{projected} gradient descent (PGD) under the constraint $S(\\theta) \\le 2/\\eta$. Our analysis provides precise predictions for the loss, sharpness, and deviation from the PGD trajectory throughout training, which we verify both empirically in a number of standard settings and theoretically under mild conditions. Our analysis uncovers the mechanism for gradient descent's implicit bias towards stability",
    "checked": true,
    "id": "f21a88af78583bd7959b121b800eed5c1f7b7b99",
    "semantic_title": "self-stabilization: the implicit bias of gradient descent at the edge of stability",
    "citation_count": 98,
    "authors": []
  },
  "https://openreview.net/forum?id=_X12NmQKvX": {
    "title": "TILP: Differentiable Learning of Temporal Logical Rules on Knowledge Graphs",
    "volume": "poster",
    "abstract": "Compared with static knowledge graphs, temporal knowledge graphs (tKG), which can capture the evolution and change of information over time, are more realistic and general. However, due to the complexity that the notion of time introduces to the learning of the rules, an accurate graph reasoning, e.g., predicting new links between entities, is still a difficult problem. In this paper, we propose TILP, a differentiable framework for temporal logical rules learning. By designing a constrained random walk mechanism and the introduction of temporal operators, we ensure the efficiency of our model. We present temporal features modeling in tKG, e.g., recurrence, temporal order, interval between pair of relations, and duration, and incorporate it into our learning process. We compare TILP with state-of-the-art methods on two benchmark datasets. We show that our proposed framework can improve upon the performance of baseline methods while providing interpretable results. In particular, we consider various scenarios in which training samples are limited, data is biased, and the time range between training and inference are different. In all these cases, TILP works much better than the state-of-the-art methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MIMwy4kh9lf": {
    "title": "Open-Vocabulary Object Detection upon Frozen Vision and Language Models",
    "volume": "poster",
    "abstract": "We present F-VLM, a simple open-vocabulary object detection method built uponFrozenVision andLanguageModels. F-VLM simplifies the current multi-stage training pipeline by eliminating the need for knowledge distillation or detection-tailored pretraining. Surprisingly, we observe that a frozen VLM: 1) retains the locality-sensitive features necessary for detection, and 2) is a strong region classifier. We finetune only the detector head and combine the detector and VLM outputs for each region at inference time. F-VLM shows compelling scaling behavior and achieves +6.5 mask AP improvement over the previous state of theart on novel categories of LVIS open-vocabulary detection benchmark. In addition, we demonstrate very competitive results on COCO open-vocabulary detection benchmark and cross-dataset transfer detection, in addition to significant training speed-up and compute savings. Code will be released",
    "checked": true,
    "id": "dcc523d8804c584e3cbb79e0cded20e40608d4cc",
    "semantic_title": "open-vocabulary object detection upon frozen vision and language models",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=_wSHsgrVali": {
    "title": "Revisiting the Assumption of Latent Separability for Backdoor Defenses",
    "volume": "poster",
    "abstract": "Recent studies revealed that deep learning is susceptible to backdoor poisoning attacks. An adversary can embed a hidden backdoor into a model to manipulate its predictions by only modifying a few training data, without controlling the training process. Currently, a tangible signature has been widely observed across a diverse set of backdoor poisoning attacks --- models trained on a poisoned dataset tend to learn separable latent representations for poison and clean samples. This latent separation is so pervasive that a family of backdoor defenses directly take it as a default assumption (dubbed latent separability assumption), based on which to identify poison samples via cluster analysis in the latent space. An intriguing question consequently follows: is the latent separation unavoidable for backdoor poisoning attacks? This question is central to understanding whether the assumption of latent separability provides a reliable foundation for defending against backdoor poisoning attacks. In this paper, we design adaptive backdoor poisoning attacks to present counter-examples against this assumption. Our methods include two key components: (1) a set of trigger-planted samples correctly labeled to their semantic classes (other than the target class) that can regularize backdoor learning; (2) asymmetric trigger planting strategies that help to boost attack success rate (ASR) as well as to diversify latent representations of poison samples. Extensive experiments on benchmark datasets verify the effectiveness of our adaptive attacks in bypassing existing latent separation based backdoor defenses. Moreover, our attacks still maintain a high attack success rate with negligible clean accuracy drop. Our studies call for defense designers to take caution when leveraging latent separation as an assumption in their defenses. Our codes are available at https://github.com/Unispac/Circumventing-Backdoor-Defenses",
    "checked": true,
    "id": "c973cd07dc3cd3d768dabb122dce346fb8b44199",
    "semantic_title": "revisiting the assumption of latent separability for backdoor defenses",
    "citation_count": 113,
    "authors": []
  },
  "https://openreview.net/forum?id=PINRbk7h01": {
    "title": "Restricted Strong Convexity of Deep Learning Models with Smooth Activations",
    "volume": "poster",
    "abstract": "We consider the problem of optimization of deep learning models with smooth activation functions. While there exist influential results on the problem from the ``near initialization'' perspective, we shed considerable new light on the problem. In particular, we make two key technical contributions for such models with $L$ layers, $m$ width, and $\\sigma_0^2$ initialization variance. First, for suitable $\\sigma_0^2$, we establish a $O(\\frac{\\text{poly}(L)}{\\sqrt{m}})$ upper bound on the spectral norm of the Hessian of such models, considerably sharpening prior results. Second, we introduce a new analysis of optimization based on Restricted Strong Convexity (RSC) which holds as long as the squared norm of the average gradient of predictors is $\\Omega(\\frac{\\text{poly}(L)}{\\sqrt{m}})$ for the square loss. We also present results for more general losses. The RSC based analysis does not need the ``near initialization\" perspective and guarantees geometric convergence for gradient descent (GD). To the best of our knowledge, ours is the first result on establishing geometric convergence of GD based on RSC for deep learning models, thus becoming an alternative sufficient condition for convergence that does not depend on the widely-used Neural Tangent Kernel (NTK). We share preliminary experimental results supporting our theoretical advances",
    "checked": true,
    "id": "f2a93f567b1d606c4ac7ce72ca8958efaba47b72",
    "semantic_title": "restricted strong convexity of deep learning models with smooth activations",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=kUmdmHxK5N": {
    "title": "Koopman Neural Operator Forecaster for Time-series with Temporal Distributional Shifts",
    "volume": "poster",
    "abstract": "Temporal distributional shifts, with underlying dynamics changing over time, frequently occur in real-world time series and pose a fundamental challenge for deep neural networks (DNNs). In this paper, we propose a novel deep sequence model based on the Koopman theory for time series forecasting: Koopman Neural Forecaster (KNF) that leverages DNNs to learn the linear Koopman space and the coefficients of chosen measurement functions. KNF imposes appropriate inductive biases for improved robustness against distributional shifts, employing both a global operator to learn shared characteristics and a local operator to capture changing dynamics, as well as a specially-designed feedback loop to continuously update the learnt operators over time for rapidly varying behaviors. We demonstrate that KNF achieves superior performance compared to the alternatives, on multiple time series datasets that are shown to suffer from distribution shifts",
    "checked": true,
    "id": "c920e78a562bdf0f44bcea25c65fccc04a51da34",
    "semantic_title": "koopman neural operator forecaster for time-series with temporal distributional shifts",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=C1ns08q9jZ": {
    "title": "MetaGL: Evaluation-Free Selection of Graph Learning Models via Meta-Learning",
    "volume": "poster",
    "abstract": "Given a graph learning task, such as link prediction, on a new graph, how can we select the best method as well as its hyperparameters (collectively called a model) without having to train or evaluate any model on the new graph? Model selection for graph learning has been largely ad hoc. A typical approach has been to apply popular methods to new datasets, but this is often suboptimal. On the other hand, systematically comparing models on the new graph quickly becomes too costly, or even impractical. In this work, we develop the first meta-learning approach for evaluation-free graph learning model selection, called MetaGL, which utilizes the prior performances of existing methods on various benchmark graph datasets to automatically select an effective model for the new graph, without any model training or evaluations. To quantify similarities across a wide variety of graphs, we introduce specialized meta-graph features that capture the structural characteristics of a graph. Then we design G-M network, which represents the relations among graphs and models, and develop a graph-based meta-learner operating on this G-M network, which estimates the relevance of each model to different graphs. Extensive experiments show that using MetaGL to select a model for the new graph greatly outperforms several existing meta-learning techniques tailed for graph learning model selection (up to 47% better), while being extremely fast at test time (∼1 sec)",
    "checked": true,
    "id": "3f80a0ec819a6b781ba2babbb9459029d8fc3356",
    "semantic_title": "metagl: evaluation-free selection of graph learning models via meta-learning",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=oX3tGygjW1q": {
    "title": "Minimum Description Length Control",
    "volume": "poster",
    "abstract": "We propose a novel framework for multitask reinforcement learning based on the minimum description length (MDL) principle. In this approach, which we term MDL-control (MDL-C), the agent learns the common structure among the tasks with which it is faced and then distills it into a simpler representation which facilitates faster convergence and generalization to new tasks. In doing so, MDL-C naturally balances adaptation to each task with epistemic uncertainty about the task distribution. We motivate MDL-C via formal connections between the MDL principle and Bayesian inference, derive theoretical performance guarantees, and demonstrate MDL-C's empirical effectiveness on both discrete and high-dimensional continuous control tasks",
    "checked": true,
    "id": "41bba26e8b607d1c0be9fb494c545c233d51a887",
    "semantic_title": "minimum description length control",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=hxEIgUXLFF": {
    "title": "PerFedMask: Personalized Federated Learning with Optimized Masking Vectors",
    "volume": "poster",
    "abstract": "Recently, various personalized federated learning (FL) algorithms have been proposed to tackle data heterogeneity. To mitigate device heterogeneity, a common approach is to use masking. In this paper, we first show that using random masking can lead to a bias in the obtained solution of the learning model. To this end, we propose a personalized FL algorithm with optimized masking vectors called PerFedMask. In particular, PerFedMask facilitates each device to obtain its optimized masking vector based on its computational capability before training. Fine-tuning is performed after training. PerFedMask is a generalization of a recently proposed personalized FL algorithm, FedBABU (Oh et al., 2022). PerFedMask can be combined with other FL algorithms including HeteroFL (Diao et al., 2021) and Split-Mix FL (Hong et al., 2022). Results based on CIFAR-10 and CIFAR-100 datasets show that the proposed PerFedMask algorithm provides a higher test accuracy after fine-tuning and lower average number of trainable parameters when compared with six existing state-of-the-art FL algorithms in the literature. The codes are available at https://github.com/MehdiSet/PerFedMask",
    "checked": true,
    "id": "b2848f5cb964f821ae0516f64f64f9733c07a90e",
    "semantic_title": "perfedmask: personalized federated learning with optimized masking vectors",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=3VFQfAG3vwi": {
    "title": "Variational Latent Branching Model for Off-Policy Evaluation",
    "volume": "poster",
    "abstract": "Model-based methods have recently shown great potential for off-policy evaluation (OPE); offline trajectories induced by behavioral policies are fitted to transitions of Markov decision processes (MDPs), which are used to rollout simulated trajectories and estimate the performance of policies. Model-based OPE methods face two key challenges. First, as offline trajectories are usually fixed, they tend to cover limited state and action space. Second, the performance of model-based methods can be sensitive to the initialization of their parameters. In this work, we propose the variational latent branching model (VLBM) to learn the transition function of MDPs by formulating the environmental dynamics as a compact latent space, from which the next states and rewards are then sampled. Specifically, VLBM leverages and extends the variational inference framework with the recurrent state alignment (RSA), which is designed to capture as much information underlying the limited training data, by smoothing out the information flow between the variational (encoding) and generative (decoding) part of VLBM. Moreover, we also introduce the branching architecture to improve the model's robustness against randomly initialized model weights. The effectiveness of the VLBM is evaluated on the deep OPE (DOPE) benchmark, from which the training trajectories are designed to result in varied coverage of the state-action space. We show that the VLBM outperforms existing state-of-the-art OPE methods in general",
    "checked": true,
    "id": "dde3d9d731e3bd88ff94c0488fe17dbabe89e3c5",
    "semantic_title": "variational latent branching model for off-policy evaluation",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=oLIZ2jGTiv": {
    "title": "Tuning Frequency Bias in Neural Network Training with Nonuniform Data",
    "volume": "poster",
    "abstract": "Small generalization errors of over-parameterized neural networks (NNs) can be partially explained by the frequency biasing phenomenon, where gradient-based algorithms minimize the low-frequency misfit before reducing the high-frequency residuals. Using the Neural Tangent Kernel (NTK), one can provide a theoretically rigorous analysis for training where data are drawn from constant or piecewise-constant probability densities. Since most training data sets are not drawn from such distributions, we use the NTK model and a data-dependent quadrature rule to theoretically quantify the frequency biasing of NN training given fully nonuniform data. By replacing the loss function with a carefully selected Sobolev norm, we can further amplify, dampen, counterbalance, or reverse the intrinsic frequency biasing in NN training",
    "checked": true,
    "id": "469cef50b5a1b9dbaaba4f4d167028a3e19450b4",
    "semantic_title": "tuning frequency bias in neural network training with nonuniform data",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=6SRDbbvU8s": {
    "title": "Learning Multimodal Data Augmentation in Feature Space",
    "volume": "poster",
    "abstract": "The ability to jointly learn from multiple modalities, such as text, audio, and visual data, is a defining feature of intelligent systems. While there have been promising advances in designing neural networks to harness multimodal data, the enormous success of data augmentation currently remains limited to single-modality tasks like image classification. Indeed, it is particularly difficult to augment each modality while preserving the overall semantic structure of the data; for example, a caption may no longer be a good description of an image after standard augmentations have been applied, such as translation. Moreover, it is challenging to specify reasonable transformations that are not tailored to a particular modality. In this paper, we introduce LeMDA, Learning Multimodal Data Augmentation, an easy-to-use method that automatically learns to jointly augment multimodal data in feature space, with no constraints on the identities of the modalities or the relationship between modalities. We show that LeMDA can (1) profoundly improve the performance of multimodal deep learning architectures, (2) apply to combinations of modalities that have not been previously considered, and (3) achieve state-of-the-art results on a wide range of applications comprised of image, text, and tabular data",
    "checked": true,
    "id": "7a63b216572f21a3d7e05007a1b27329d9e0ef46",
    "semantic_title": "learning multimodal data augmentation in feature space",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=iTtGCMDEzS_": {
    "title": "BigVGAN: A Universal Neural Vocoder with Large-Scale Training",
    "volume": "poster",
    "abstract": "Despite recent progress in generative adversarial network (GAN)-based vocoders, where the model generates raw waveform conditioned on acoustic features, it is challenging to synthesize high-fidelity audio for numerous speakers across various recording environments. In this work, we present BigVGAN, a universal vocoder that generalizes well for various out-of-distribution scenarios without fine-tuning. We introduce periodic activation function and anti-aliased representation into the GAN generator, which brings the desired inductive bias for audio synthesis and significantly improves audio quality. In addition, we train our GAN vocoder at the largest scale up to 112M parameters, which is unprecedented in the literature. We identify and address the failure modes in large-scale GAN training for audio, while maintaining high-fidelity output without over-regularization. Our BigVGAN, trained only on clean speech (LibriTTS), achieves the state-of-the-art performance for various zero-shot (out-of-distribution) conditions, including unseen speakers, languages, recording environments, singing voices, music, and instrumental audio. We release our code and model at: https://github.com/NVIDIA/BigVGAN",
    "checked": true,
    "id": "04f5553934c458305a501d63323f1b841fd5d102",
    "semantic_title": "bigvgan: a universal neural vocoder with large-scale training",
    "citation_count": 321,
    "authors": []
  },
  "https://openreview.net/forum?id=zZhX4eYNeeh": {
    "title": "Achieving Sub-linear Regret in Infinite Horizon Average Reward Constrained MDP with Linear Function Approximation",
    "volume": "poster",
    "abstract": "We study the infinite horizon average reward constrained Markov Decision Process (CMDP). In contrast to existing works on model-based, finite state space, we consider the model-free linear CMDP setup. We first propose a computationally inefficient algorithm and show that $\\tilde{\\mathcal{O}}(\\sqrt{d^3T})$ regret and constraint violation can be achieved, in which $T$ is the number of interactions, and $d$ is the dimension of the feature mapping. We also propose an efficient variant based on the primal-dual adaptation of the LSVI-UCB algorithm and show that $\\tilde{\\mathcal{O}}((dT)^{3/4})$ regret and constraint violation can be achieved. This improves the known regret bound of $\\tilde{\\mathcal{O}}(T^{5/6})$ for the finite state-space model-free constrained RL which was obtained under a stronger assumption compared to ours. We also develop an efficient policy-based algorithm via novel adaptation of the MDP-EXP2 algorithm to our primal-dual set up with $\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret and even zero constraint violation bound under a stronger set of assumptions",
    "checked": true,
    "id": "e8d7b5f1d32a221234b309c96af0ee9d0313ac89",
    "semantic_title": "achieving sub-linear regret in infinite horizon average reward constrained mdp with linear function approximation",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=B-z41MBL_tH": {
    "title": "Causal Imitation Learning via Inverse Reinforcement Learning",
    "volume": "poster",
    "abstract": "One of the most common ways children learn when unfamiliar with the environment is by mimicking adults. Imitation learning concerns an imitator learning to behave in an unknown environment from an expert's demonstration; reward signals remain latent to the imitator. This paper studies imitation learning through causal lenses and extends the analysis and tools developed for behavior cloning (Zhang, Kumor, Bareinboim, 2020) to inverse reinforcement learning. First, we propose novel graphical conditions that allow the imitator to learn a policy performing as well as the expert's behavior policy, even when the imitator and the expert's state-action space disagree, and unobserved confounders (UCs) are present. When provided with parametric knowledge about the unknown reward function, such a policy may outperform the expert's. Also, our method is easily extensible and allows one to leverage existing IRL algorithms even when UCs are present, including the multiplicative-weights algorithm (MWAL) (Syed & Schapire, 2008) and the generative adversarial imitation learning (GAIL) (Ho & Ermon, 2016). Finally, we validate our framework by simulations using real-world and synthetic data",
    "checked": true,
    "id": "381ba148f67e9f96e8cd190f84d49a51469a7231",
    "semantic_title": "causal imitation learning via inverse reinforcement learning",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=o58JtGDs6y": {
    "title": "The Surprising Computational Power of Nondeterministic Stack RNNs",
    "volume": "poster",
    "abstract": "Traditional recurrent neural networks (RNNs) have a fixed, finite number of memory cells. In theory (assuming bounded range and precision), this limits their formal language recognition power to regular languages, and in practice, RNNs have been shown to be unable to learn many context-free languages (CFLs). In order to expand the class of languages RNNs recognize, prior work has augmented RNNs with a nondeterministic stack data structure, putting them on par with pushdown automata and increasing their language recognition power to CFLs. Nondeterminism is needed for recognizing all CFLs (not just deterministic CFLs), but in this paper, we show that nondeterminism and the neural controller interact to produce two more unexpected abilities. First, the nondeterministic stack RNN can recognize not only CFLs, but also many non-context-free languages. Second, it can recognize languages with much larger alphabet sizes than one might expect given the size of its stack alphabet. Finally, to increase the information capacity in the stack and allow it to solve more complicated tasks with large alphabet sizes, we propose a new version of the nondeterministic stack that simulates stacks of vectors rather than discrete symbols. We demonstrate perplexity improvements with this new model on the Penn Treebank language modeling benchmark",
    "checked": true,
    "id": "f3ff2da07cc9873a838687c17704be4e1fc6743b",
    "semantic_title": "the surprising computational power of nondeterministic stack rnns",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=EnrY5TOrbQ": {
    "title": "Agnostic Learning of General ReLU Activation Using Gradient Descent",
    "volume": "poster",
    "abstract": "We provide a convergence analysis of gradient descent for the problem of agnostically learning a single ReLU function under Gaussian distributions. Unlike prior work that studies the setting of zero bias, we consider the more challenging scenario when the bias of the ReLU function is non-zero. Our main result establishes that starting from random initialization, in a polynomial number of iterations gradient descent outputs, with high probability, a ReLU function that achieves an error that is within a constant factor of the optimal i.e., it is guaranteed to achieve an error of $O(OPT)$, where $OPT$ is the error of the best ReLU function. This is a significant improvement over existing guarantees for gradient descent, which only guarantee error of $O(\\sqrt{d \\cdot OPT})$ even in the zero-bias case (Frei et al., 2020). We also provide finite sample guarantees, and obtain similar guarantees for a broader class of marginal distributions beyond Gaussians",
    "checked": true,
    "id": "119ae580262ff700ad4f4f3255dc7744acfd443a",
    "semantic_title": "agnostic learning of general relu activation using gradient descent",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=aCQt_BrkSjC": {
    "title": "Learning Hyper Label Model for Programmatic Weak Supervision",
    "volume": "poster",
    "abstract": "To reduce the human annotation efforts, the programmatic weak supervision (PWS) paradigm abstracts weak supervision sources as labeling functions (LFs) and involves a label model to aggregate the output of multiple LFs to produce training labels. Most existing label models require a parameter learning step for each dataset. In this work, we present a hyper label model that (once learned) infers the ground-truth labels for each dataset in a single forward pass without dataset-specific parameter learning. The hyper label model approximates an optimal analytical (yet computationally intractable) solution of the ground-truth labels. We train the model on synthetic data generated in the way that ensures the model approximates the analytical optimal solution, and build the model upon Graph Neural Network (GNN) to ensure the model prediction being invariant (or equivariant) to the permutation of LFs (or data points). On 14 real-world datasets, our hyper label model outperforms the best existing methods in both accuracy (by 1.4 points on average) and efficiency (by six times on average). Our code is available at https://github.com/wurenzhi/hyper_label_model",
    "checked": true,
    "id": "a93dbfcad6262462206596b8e189264e8273a05b",
    "semantic_title": "learning hyper label model for programmatic weak supervision",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=U9yFP90jU0": {
    "title": "FedFA: Federated Feature Augmentation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2c6e48a8c892731e5a5a227642a87078de872bd1",
    "semantic_title": "fedfa: federated feature augmentation",
    "citation_count": 39,
    "authors": []
  },
  "https://openreview.net/forum?id=PXVGer7hmJ": {
    "title": "Offline Congestion Games: How Feedback Type Affects Data Coverage Requirement",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "086d5bf9b7acc9acd8a61e66bbcd6c3de1a67c0b",
    "semantic_title": "offline congestion games: how feedback type affects data coverage requirement",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=2L9gzS80tA4": {
    "title": "Does Learning from Decentralized Non-IID Unlabeled Data Benefit from Self Supervision?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7552dc5354b6cec2887fce47500177113c297d53",
    "semantic_title": "does learning from decentralized non-iid unlabeled data benefit from self supervision?",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=dQNL7Zsta3": {
    "title": "Malign Overfitting: Interpolation and Invariance are Fundamentally at Odds",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "efe92a066a2db0de106033b8af3843d1c9546f46",
    "semantic_title": "malign overfitting: interpolation and invariance are fundamentally at odds",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=aRTKuscKByJ": {
    "title": "Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2272b37bae59c30ca218abfeecdb0a61270c48f1",
    "semantic_title": "exploring and exploiting decision boundary dynamics for adversarial robustness",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=OIe3kpwl40D": {
    "title": "SMART: Sentences as Basic Units for Text Evaluation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a00c394527eb98885cfcb773c4471adb6abc4393",
    "semantic_title": "smart: sentences as basic units for text evaluation",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=SZdfz5k7cd1": {
    "title": "Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f4aa05137e87d6c6e959604936baf504bac8e3c3",
    "semantic_title": "tier balancing: towards dynamic fairness over underlying causal factors",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=xYWqSjBcGMl": {
    "title": "Anamnesic Neural Differential Equations with Orthogonal Polynomial Projections",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "be30fc0627babcc50974c940847e8ba6f796e632",
    "semantic_title": "anamnesic neural differential equations with orthogonal polynomial projections",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=y81ppNf_vg": {
    "title": "AutoTransfer: AutoML with Knowledge Transfer - An Application to Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c44f1323caaacc07863757cc5b7e0ae025ec40eb",
    "semantic_title": "autotransfer: automl with knowledge transfer - an application to graph neural networks",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=C0q9oBc3n4": {
    "title": "Temporal Dependencies in Feature Importance for Time Series Prediction",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "077c4f979ac6a369318c59ff8c5df8d6f681d8b5",
    "semantic_title": "temporal dependencies in feature importance for time series predictions",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=Tvms8xrZHyR": {
    "title": "Characterizing the spectrum of the NTK via a power series expansion",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f2fbf53e17e5dc0a0d3dc9a400d1dd37ab8c4d36",
    "semantic_title": "characterizing the spectrum of the ntk via a power series expansion",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=tJbbQfw-5wv": {
    "title": "A critical look at the evaluation of GNNs under heterophily: Are we really making progress?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6ef892cd47300c56a72ff67bc7b87b43b3654e16",
    "semantic_title": "a critical look at the evaluation of gnns under heterophily: are we really making progress?",
    "citation_count": 262,
    "authors": []
  },
  "https://openreview.net/forum?id=vw-5EgYbJZr": {
    "title": "A Non-monotonic Self-terminating Language Model",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "04fbe8d6e9d07d97e0ad1c2b26b3ff68f6e91284",
    "semantic_title": "a non-monotonic self-terminating language model",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Qc_OopMEBnC": {
    "title": "Learning to Segment from Noisy Annotations: A Spatial Correction Approach",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fc48cf6c250eaeff04a580ffddb28026acf3ee64",
    "semantic_title": "learning to segment from noisy annotations: a spatial correction approach",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=7bJizxLKrR": {
    "title": "Measuring Forgetting of Memorized Training Examples",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6c46b7b401be5ada79f00b36cb8e5b41286ae2aa",
    "semantic_title": "measuring forgetting of memorized training examples",
    "citation_count": 122,
    "authors": []
  },
  "https://openreview.net/forum?id=QAV2CcLEDh": {
    "title": "MaskViT: Masked Visual Pre-Training for Video Prediction",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a86fe34e17cfc4847a39ab54a2f3adda534eb43d",
    "semantic_title": "maskvit: masked visual pre-training for video prediction",
    "citation_count": 128,
    "authors": []
  },
  "https://openreview.net/forum?id=HehQobsr0S": {
    "title": "Text Summarization with Oracle Expectation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3d9cb63bf82f3b6e5c9e444e9b89eb0bd00c9b9f",
    "semantic_title": "text summarization with oracle expectation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=_4n3k3d1ob": {
    "title": "Continuous-time identification of dynamic state-space models by deep subspace encoding",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9a52c83a06b6796b3d1783e4abdbe683bcc908d4",
    "semantic_title": "continuous-time identification of dynamic state-space models by deep subspace encoding",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=klK17OQ3KB": {
    "title": "How to Train your HIPPO: State Space Models with Generalized Orthogonal Basis Projections",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a30ac45ac5b7bd2148d3fb80ee7f3c29724e3170",
    "semantic_title": "how to train your hippo: state space models with generalized orthogonal basis projections",
    "citation_count": 119,
    "authors": []
  },
  "https://openreview.net/forum?id=TkQ1sxd9P4": {
    "title": "Interpretable Debiasing of Vectorized Language Representations with Iterative Orthogonalization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "21c87d4662e5a552133cc58420d31b8ae2ad8c38",
    "semantic_title": "interpretable debiasing of vectorized language representations with iterative orthogonalization",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=jwdqNwyREyh": {
    "title": "Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2e27b1355389e897ccd38cd8f086eeec3b29d391",
    "semantic_title": "layer grafted pre-training: bridging contrastive learning and masked image modeling for label-efficient representations",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=ETKGuby0hcs": {
    "title": "Discovering Latent Knowledge in Language Models Without Supervision",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "89c3bd70ad33c4f8832f00ab98872b77861ee0ec",
    "semantic_title": "discovering latent knowledge in language models without supervision",
    "citation_count": 465,
    "authors": []
  },
  "https://openreview.net/forum?id=H0gdPxSwkPb": {
    "title": "Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e84ed70a8e00a2feec0e8462bf72af0a30cff2a9",
    "semantic_title": "diffusion adversarial representation learning for self-supervised vessel segmentation",
    "citation_count": 71,
    "authors": []
  },
  "https://openreview.net/forum?id=gmSZ-GPNY6": {
    "title": "Noise Injection Node Regularization for Robust Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c5283314492adacea2de8a056f5529c506d0fef4",
    "semantic_title": "noise injection node regularization for robust learning",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=jpR98ZdIm2q": {
    "title": "Efficient Edge Inference by Selective Query",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a39d7b3a3cb29b23fa98bcced73a031a9e389c5f",
    "semantic_title": "efficient edge inference by selective query",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=JtC6yOHRoJJ": {
    "title": "Human-level Atari 200x faster",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b3e59caf23dd121048779b2edcdff0dd2872cd43",
    "semantic_title": "human-level atari 200x faster",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=mkJm5Uy4HrQ": {
    "title": "Incompatibility Clustering as a Defense Against Backdoor Poisoning Attacks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8c8968245228abdb78b7adb5ff930c1e8d632dcf",
    "semantic_title": "incompatibility clustering as a defense against backdoor poisoning attacks",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=DpE5UYUQzZH": {
    "title": "A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d95bb741913c93c7b5fd745668d8538bbbf7b584",
    "semantic_title": "a unified approach to reinforcement learning, quantal response equilibria, and two-player zero-sum games",
    "citation_count": 61,
    "authors": []
  },
  "https://openreview.net/forum?id=ovZE0KsbM3S": {
    "title": "Pitfalls of Gaussians as a noise distribution in NCE",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fe3656e5fbfa0ee451d95d958d41e066aa555863",
    "semantic_title": "pitfalls of gaussians as a noise distribution in nce",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=ZrEbzL9eQ3W": {
    "title": "Scaling Laws for a Multi-Agent Reinforcement Learning Model",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b39d803f9e5f816744f10425fb9419828d03c301",
    "semantic_title": "scaling laws for a multi-agent reinforcement learning model",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=HQ67mj5rJdR": {
    "title": "Perfectly Secure Steganography Using Minimum Entropy Coupling",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "789df3835224ca1feaa6e5bca69500c86c849d96",
    "semantic_title": "perfectly secure steganography using minimum entropy coupling",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=jPVAFXHlbL": {
    "title": "Calibrating Transformers via Sparse Gaussian Processes",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a63987a9d947793efaa7807a26320ad4607ea63e",
    "semantic_title": "calibrating transformers via sparse gaussian processes",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=z37tDDHHgi": {
    "title": "Red PANDA: Disambiguating Image Anomaly Detection by Removing Nuisance Factors",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "44f72136edd3d30482e4afd734ec6622e03a9143",
    "semantic_title": "red panda: disambiguating image anomaly detection by removing nuisance factors",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=xE-LtsE-xx": {
    "title": "Is Attention All That NeRF Needs?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b3bee2d9bec8f4b28eaaab963cc63eec6b0ee744",
    "semantic_title": "is attention all that nerf needs?",
    "citation_count": 124,
    "authors": []
  },
  "https://openreview.net/forum?id=oJZ8bPtCar": {
    "title": "Stochastic No-regret Learning for General Games with Variance Reduction",
    "volume": "poster",
    "abstract": "We show that a stochastic version of optimistic mirror descent (OMD), a variant of mirror descent with recency bias, converges fast in general games. More specifically, with our algorithm, the individual regret of each player vanishes at a speed of $O(1/T^{3/4})$ and the sum of all players' regret vanishes at a speed of $O(1/T)$, which is an improvement upon the $O(1/\\sqrt{T})$ convergence rate of prior stochastic algorithms, where $T$ is the number of interaction rounds. Due to the advantage of stochastic methods in the computational cost, we significantly improve the time complexity over the deterministic algorithms to approximate coarse correlated equilibrium. To achieve lower time complexity, we equip the stochastic version of OMD in \\cite{alacaoglu2021stochastic} with a novel low-variance Monte-Carlo estimator. Our algorithm extends previous works \\cite{alacaoglu2021stochastic,carmon2019variance} from two-player zero-sum games to general games",
    "checked": true,
    "id": "38ef22db4c64d3d91370268ec923b2b1d002eb16",
    "semantic_title": "stochastic no-regret learning for general games with variance reduction",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=bsZULlDGXe": {
    "title": "The Dark Side of AutoML: Towards Architectural Backdoor Search",
    "volume": "poster",
    "abstract": "This paper asks the intriguing question: is it possible to exploit neural architecture search (NAS) as a new attack vector to launch previously improbable attacks? Specifically, we present EVAS, a new attack that leverages NAS to find neural architectures with inherent backdoors and exploits such vulnerability using input-aware triggers. Compared with existing attacks, EVAS demonstrates many interesting properties: (i) it does not require polluting training data or perturbing model parameters; (ii) it is agnostic to downstream fine-tuning or even re-training from scratch; (iii) it naturally evades defenses that rely on inspecting model parameters or training data. With extensive evaluation on benchmark datasets, we show that EVAS features high evasiveness, transferability, and robustness, thereby expanding the adversary's design spectrum. We further characterize the mechanisms underlying EVAS, which are possibly explainable by architecture-level ``shortcuts'' that recognize trigger patterns. This work showcases that NAS can be exploited in a harmful way to find architectures with inherent backdoor vulnerability. The code is available at https://github.com/ain-soph/nas_backdoor",
    "checked": true,
    "id": "b30e33bfcfc185620e625017bc206d5b174a94e3",
    "semantic_title": "the dark side of automl: towards architectural backdoor search",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=9F_xlC7sk9": {
    "title": "Generalization and Estimation Error Bounds for Model-based Neural Networks",
    "volume": "poster",
    "abstract": "Model-based neural networks provide unparalleled performance for various tasks, such as sparse coding and compressed sensing problems. Due to the strong connection with the sensing model, these networks are interpretable and inherit prior structure of the problem. In practice, model-based neural networks exhibit higher generalization capability compared to ReLU neural networks. However, this phenomenon was not addressed theoretically. Here, we leverage complexity measures including the global and local Rademacher complexities, in order to provide upper bounds on the generalization and estimation errors of model-based networks. We show that the generalization abilities of model-based networks for sparse recovery outperform those of regular ReLU networks, and derive practical design rules that allow to construct model-based networks with guaranteed high generalization. We demonstrate through a series of experiments that our theoretical insights shed light on a few behaviours experienced in practice, including the fact that ISTA and ADMM networks exhibit higher generalization abilities (especially for small number of training samples), compared to ReLU networks",
    "checked": true,
    "id": "a3d4518b215945bc9259aec633d642d9b23d27d0",
    "semantic_title": "generalization and estimation error bounds for model-based neural networks",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=E8mzu3JbdR": {
    "title": "ChordMixer: A Scalable Neural Attention Model for Sequences with Different Length",
    "volume": "poster",
    "abstract": "Sequential data naturally have different lengths in many domains, with some very long sequences. As an important modeling tool, neural attention should capture long-range interaction in such sequences. However, most existing neural attention models admit only short sequences, or they have to employ chunking or padding to enforce a constant input length. Here we propose a simple neural network building block called ChordMixer which can model the attention for long sequences with variable lengths. Each ChordMixer block consists of a position-wise rotation layer without learnable parameters and an element-wise MLP layer. Repeatedly applying such blocks forms an effective network backbone that mixes the input signals towards the learning targets. We have tested ChordMixer on the synthetic adding problem, long document classification, and DNA sequence-based taxonomy classification. The experiment results show that our method substantially outperforms other neural attention models",
    "checked": false,
    "id": "2fc384087f55111a196c96d88029aab324aa543e",
    "semantic_title": "chordmixer: a scalable neural attention model for sequences with different lengths",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=SZynfVLGd5": {
    "title": "Boosting Adversarial Transferability using Dynamic Cues",
    "volume": "poster",
    "abstract": "The transferability of adversarial perturbations between image models has been extensively studied. In this case, an attack is generated from a known surrogate \\eg, the ImageNet trained model, and transferred to change the decision of an unknown (black-box) model trained on an image dataset. However, attacks generated from image models do not capture the dynamic nature of a moving object or a changing scene due to a lack of temporal cues within image models. This leads to reduced transferability of adversarial attacks from representation-enriched \\emph{image} models such as Supervised Vision Transformers (ViTs), Self-supervised ViTs (\\eg, DINO), and Vision-language models (\\eg, CLIP) to black-box \\emph{video} models. In this work, we induce dynamic cues within the image models without sacrificing their original performance on images. To this end, we optimize \\emph{temporal prompts} through frozen image models to capture motion dynamics. Our temporal prompts are the result of a learnable transformation that allows optimizing for temporal gradients during an adversarial attack to fool the motion dynamics. Specifically, we introduce spatial (image) and temporal (video) cues within the same source model through task-specific prompts. Attacking such prompts maximizes the adversarial transferability from image-to-video and image-to-image models using the attacks designed for image models. As an example, an iterative attack launched from image model Deit-B with temporal prompts reduces generalization (top1 \\% accuracy) of a video model by 35\\% on Kinetics-400. Our approach also improves adversarial transferability to image models by 9\\% on ImageNet w.r.t the current state-of-the-art approach. Our attack results indicate that the attacker does not need specialized architectures, \\eg, divided space-time attention, 3D convolutions, or multi-view convolution networks for different data modalities. Image models are effective surrogates to optimize an adversarial attack to fool black-box models in a changing environment over time. Code is available at \\url{https://bit.ly/3Xd9gRQ}",
    "checked": true,
    "id": "d3465e44404e718d0f73f4ac07e8ce623723facb",
    "semantic_title": "boosting adversarial transferability using dynamic cues",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=lLp-C5nTdJG": {
    "title": "Static Prediction of Runtime Errors by Learning to Execute Programs with External Resource Descriptions",
    "volume": "poster",
    "abstract": "The execution behavior of a program often depends on external resources, such as program inputs or file contents, and so the program cannot be run in isolation. Nevertheless, software developers benefit from fast iteration loops where automated tools identify errors as early as possible, even before programs can be compiled and run. This presents an interesting machine learning challenge: can we predict runtime errors in a \"static\" setting, where program execution is not possible? Here, we introduce a competitive programming dataset and task for predicting runtime errors, which we show is difficult for generic models like Transformers. We approach this task by developing an interpreter-inspired architecture with an inductive bias towards mimicking program executions, which models exception handling and \"learns to execute\" descriptions of external resources. Surprisingly, we show that the model can also predict the locations of errors, despite being trained only on labels indicating error presence or absence and kind. In total, we present a practical and difficult-yet-approachable challenge problem related to learning program execution behavior and we demonstrate promising new capabilities of interpreter-inspired machine learning models for code",
    "checked": true,
    "id": "c125b0be73c8493ebc27beb572f6c1b21d6b4ae4",
    "semantic_title": "static prediction of runtime errors by learning to execute programs with external resource descriptions",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=q9VherQJd8_": {
    "title": "Matching receptor to odorant with protein language and graph neural networks",
    "volume": "poster",
    "abstract": "Odor perception in mammals is triggered by interactions between volatile organic compounds and a subset of hundreds of proteins called olfactory receptors (ORs). Molecules activate these receptors in a complex combinatorial coding allowing mammals to discriminate a vast number of chemical stimuli. Recently, ORs have gained attention as new therapeutic targets following the discovery of their involvement in other physiological processes and diseases. To date, predicting molecule-induced activation for ORs is highly challenging since $43\\%$ of ORs have no identified active compound. In this work, we combine [CLS] token from protBERT with a molecular graph and propose a tailored GNN architecture incorporating inductive biases from the protein-molecule binding. We abstract the biological process of protein-molecule activation as the injection of a molecule into a protein-specific environment. On a newly gathered dataset of $46$ $700$ OR-molecule pairs, this model outperforms state-of-the-art models on drug-target interaction prediction as well as standard GNN baselines. Moreover, by incorporating non-bonded interactions the model is able to work with mixtures of compounds. Finally, our predictions reveal a similar activation pattern for molecules within a given odor family, which is in agreement with the theory of combinatorial coding in olfaction",
    "checked": true,
    "id": "0ed021f02c902d93d31bb3365c396389ef5c2fa9",
    "semantic_title": "matching receptor to odorant with protein language and graph neural networks",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=6xXtM8bFFJ": {
    "title": "SGDA with shuffling: faster convergence for nonconvex-PŁ minimax optimization",
    "volume": "poster",
    "abstract": "Stochastic gradient descent-ascent (SGDA) is one of the main workhorses for solving finite-sum minimax optimization problems. Most practical implementations of SGDA randomly reshuffle components and sequentially use them (i.e., without-replacement sampling); however, there are few theoretical results on this approach for minimax algorithms, especially outside the easier-to-analyze (strongly-)monotone setups. To narrow this gap, we study the convergence bounds of SGDA with random reshuffling (SGDA-RR) for smooth nonconvex-nonconcave objectives with Polyak-{\\L}ojasiewicz (P{\\L}) geometry. We analyze both simultaneous and alternating SGDA-RR for nonconvex-P{\\L} and primal-P{\\L}-P{\\L} objectives, and obtain convergence rates faster than with-replacement SGDA. Our rates extend to mini-batch SGDA-RR, recovering known rates for full-batch gradient descent-ascent (GDA). Lastly, we present a comprehensive lower bound for GDA with an arbitrary step-size ratio, which matches the full-batch upper bound for the primal-P{\\L}-P{\\L} case",
    "checked": true,
    "id": "b5792a753a628797fc8ba1db13799a5cb3099cbd",
    "semantic_title": "sgda with shuffling: faster convergence for nonconvex-pł minimax optimization",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=H0HGljkxQFN": {
    "title": "MOAT: Alternating Mobile Convolution and Attention Brings Strong Vision Models",
    "volume": "poster",
    "abstract": "This paper presents MOAT, a family of neural networks that build on top of MObile convolution (i.e., inverted residual blocks) and ATtention. Unlike the current works that stack separate mobile convolution and transformer blocks, we effectively merge them into a MOAT block. Starting with a standard Transformer block, we replace its multi-layer perceptron with a mobile convolution block, and further reorder it before the self-attention operation. The mobile convolution block not only enhances the network representation capacity, but also produces better downsampled features. Our conceptually simple MOAT networks are surprisingly effective, achieving 89.1% / 81.5% top-1 accuracy on ImageNet-1K / ImageNet-1K-V2 with ImageNet-22K pretraining. Additionally, MOAT can be seamlessly applied to downstream tasks that require large resolution inputs by simply converting the global attention to window attention. Thanks to the mobile convolution that effectively exchanges local information between pixels (and thus cross-windows), MOAT does not need the extra window-shifting mechanism. As a result, on COCO object detection, MOAT achieves 59.2% AP$^{\\text{box}}$ with 227M model parameters (single-scale inference, and hard NMS), and on ADE20K semantic segmentation, MOAT attains 57.6% mIoU with 496M model parameters (single-scale inference). Finally, the tiny-MOAT family, obtained by simply reducing the channel sizes, also surprisingly outperforms several mobile-specific transformer-based models on ImageNet. The tiny-MOAT family is also benchmarked on downstream tasks, serving as a baseline for the community. We hope our simple yet effective MOAT will inspire more seamless integration of convolution and self-attention. Code is publicly available",
    "checked": true,
    "id": "a8a2a8229f99c291bf71ec92b801a073854c52e2",
    "semantic_title": "moat: alternating mobile convolution and attention brings strong vision models",
    "citation_count": 71,
    "authors": []
  },
  "https://openreview.net/forum?id=bAMTaeqluh4": {
    "title": "Part-Based Models Improve Adversarial Robustness",
    "volume": "poster",
    "abstract": "We show that combining human prior knowledge with end-to-end learning can improve the robustness of deep neural networks by introducing a part-based model for object classification. We believe that the richer form of annotation helps guide neural networks to learn more robust features without requiring more samples or larger models. Our model combines a part segmentation model with a tiny classifier and is trained end-to-end to simultaneously segment objects into parts and then classify the segmented object. Empirically, our part-based models achieve both higher accuracy and higher adversarial robustness than a ResNet-50 baseline on all three datasets. For instance, the clean accuracy of our part models is up to 15 percentage points higher than the baseline's, given the same level of robustness. Our experiments indicate that these models also reduce texture bias and yield better robustness against common corruptions and spurious correlations. The code is publicly available at https://github.com/chawins/adv-part-model",
    "checked": true,
    "id": "5860267c5b1761fa5ff8dbcde980edff4c3b2f2a",
    "semantic_title": "part-based models improve adversarial robustness",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=CgCmwcfgEdH": {
    "title": "PGrad: Learning Principal Gradients For Domain Generalization",
    "volume": "poster",
    "abstract": "Machine learning models fail to perform when facing out-of-distribution (OOD) domains, a challenging task known as domain generalization (DG). In this work, we develop a novel DG training strategy, we call PGrad, to learn a robust gradient direction, improving models' generalization ability on unseen domains. The proposed gradient aggregates the principal directions of a sampled roll-out optimization trajectory that measures the training dynamics across all training domains. PGrad gradient design forces the DG training to ignore domain-dependent noise signals and updates all training domains with a robust direction covering main components of parameter dynamics. We further improve PGrad via bijection-based computational refinement and directional plus length-based calibrations. Our theoretical proof connects PGrad to the spectral analysis of Hessian in training neural networks. Experiments on DomainBed and WILDS benchmarks demonstrate that our approach effectively enables robust DG optimization and leads to smoothly decreased loss curves. Empirically, PGrad achieves competitive results across seven datasets, demonstrating its efficacy across both synthetic and real-world distributional shifts",
    "checked": true,
    "id": "03fa1a26d628a1a6f66fab9a55a24bc76b7b0a78",
    "semantic_title": "pgrad: learning principal gradients for domain generalization",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=ndYXTEL6cZz": {
    "title": "Extremely Simple Activation Shaping for Out-of-Distribution Detection",
    "volume": "poster",
    "abstract": "The separation between training and deployment of machine learning models implies that not all scenarios encountered in deployment can be anticipated during training, and therefore relying solely on advancements in training has its limits. Out-of-distribution (OOD) detection is an important area that stress-tests a model's ability to handle unseen situations: Do models know when they don't know? Existing OOD detection methods either incur extra training steps, additional data or make nontrivial modifications to the trained network. In contrast, in this work, we propose an extremely simple, post-hoc, on-the-fly activation shaping method, ASH, where a large portion (e.g. 90%) of a sample's activation at a late layer is removed, and the rest (e.g. 10%) simplified or lightly adjusted. The shaping is applied at inference time, and does not require any statistics calculated from training data. Experiments show that such a simple treatment enhances in-distribution and out- of-distribution sample distinction so as to allow state-of-the-art OOD detection on ImageNet, and does not noticeably deteriorate the in-distribution accuracy. Video, animation and code can be found at: https://andrijazz.github.io/ash",
    "checked": true,
    "id": "cf49af82a5f1ba5f2beba9f290e684b7b51b64e6",
    "semantic_title": "extremely simple activation shaping for out-of-distribution detection",
    "citation_count": 185,
    "authors": []
  },
  "https://openreview.net/forum?id=kQxry8Z6Fd9": {
    "title": "Statistical Guarantees for Consensus Clustering",
    "volume": "poster",
    "abstract": "Consider the problem of clustering $n$ objects. One can apply multiple algorithms to produce $N$ potentially different clustersings of the same objects, that is, partitions of the $n$ objects into $K$ groups. Even a single randomized algorithm can output different clusterings. This often happens when one samples from the posterior of a Bayesian model, or runs multiple MCMC chains from random initializations. A natural task is then to form a consensus among these different clusterings. The challenge in an unsupervised setting is that the optimal matching between clusters of different inputs is unknown. We model this problem as finding a barycenter (also known as Fr\\'{e}chet mean) relative to the misclassification rate. We show that by lifting the problem to the space of association matrices, one can derive aggregation algorithms that circumvent the knowledge of the optimal matchings. We analyze the statistical performance of aggregation algorithms under a stochastic label perturbation model, and show that a $K$-means type algorithm followed by a local refinement step can achieve near optimal performance, with a rate that decays exponentially fast in $N$. Numerical experiments show the effectiveness of the proposed methods",
    "checked": true,
    "id": "0153bcf9f2a410a4e9fa1dd8b524059e36cb159e",
    "semantic_title": "statistical guarantees for consensus clustering",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=w2P7fMy_RH": {
    "title": "Expressive Monotonic Neural Networks",
    "volume": "poster",
    "abstract": "The monotonic dependence of the outputs of a neural network on some of its inputs is a crucial inductive bias in many scenarios where domain knowledge dictates such behavior. This is especially important for interpretability and fairness considerations. In a broader context, scenarios in which monotonicity is important can be found in finance, medicine, physics, and other disciplines. It is thus desirable to build neural network architectures that implement this inductive bias provably. In this work, we propose a weight-constrained architecture with a single residual connection to achieve exact monotonic dependence in any subset of the inputs. The weight constraint scheme directly controls the Lipschitz constant of the neural network and thus provides the additional benefit of robustness. Compared to currently existing techniques used for monotonicity, our method is simpler in implementation and in theory foundations, has negligible computational overhead, is guaranteed to produce monotonic dependence, and is highly expressive. We show how the algorithm is used to train powerful, robust, and interpretable discriminators that achieve competitive performance compared to current state-of-the-art methods across various benchmarks, from social applications to the classification of the decays of subatomic particles produced at the CERN Large Hadron Collider",
    "checked": true,
    "id": "0e93a3ca8e1d86d9b61bc3324b07686bf5772389",
    "semantic_title": "expressive monotonic neural networks",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=K9RHxPpjn2": {
    "title": "Active Image Indexing",
    "volume": "poster",
    "abstract": "Image copy detection and retrieval from large databases leverage two components. First, a neural network maps an image to a vector representation, that is relatively robust to various transformations of the image. Second, an efficient but approximate similarity search algorithm trades scalability (size and speed) against quality of the search, thereby introducing a source of error. This paper improves the robustness of image copy detection with active indexing, that optimizes the interplay of these two components. We reduce the quantization loss of a given image representation by making imperceptible changes to the image before its release. The loss is back-propagated through the deep neural network back to the image, under perceptual constraints. These modifications make the image more retrievable. Our experiments show that the retrieval and copy detection of activated images is significantly improved. For instance, activation improves by $+40\\%$ the Recall1@1 on various image transformations, and for several popular indexing structures based on product quantization and locality sensitivity hashing",
    "checked": true,
    "id": "84958b642b15a640b7f9d8dde771a03d85a980da",
    "semantic_title": "active image indexing",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=NEtep2C7yD": {
    "title": "Learning Simultaneous Navigation and Construction in Grid Worlds",
    "volume": "poster",
    "abstract": "We propose to study a new learning task, mobile construction, to enable an agent to build designed structures in 1/2/3D grid worlds while navigating in the same evolving environments. Unlike existing robot learning tasks such as visual navigation and object manipulation, this task is challenging because of the interdependence between accurate localization and strategic construction planning. In pursuit of generic and adaptive solutions to this partially observable Markov decision process (POMDP) based on deep reinforcement learning (RL), we design a Deep Recurrent Q-Network (DRQN) with explicit recurrent position estimation in this dynamic grid world. Our extensive experiments show that pre-training this position estimation module before Q-learning can significantly improve the construction performance measured by the intersection-over-union score, achieving the best results in our benchmark of various baselines including model-free and model-based RL, a handcrafted SLAM-based policy, and human players. Our code is available at: https://ai4ce.github.io/SNAC/",
    "checked": true,
    "id": "ae19c39923e1d7977c2c542fe262361b4182557c",
    "semantic_title": "learning simultaneous navigation and construction in grid worlds",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ZcnzsHC10Y": {
    "title": "Learning to CROSS exchange to solve min-max vehicle routing problems",
    "volume": "poster",
    "abstract": "CROSS exchange (CE), a meta-heuristic that solves various vehicle routing problems (VRPs), improves the solutions of VRPs by swapping the sub-tours of the vehicles. Inspired by CE, we propose Neuro CE (NCE), a fundamental operator of \\textit{learned} meta-heuristic, to solve various min-max VRPs while overcoming the limitations of CE, i.e., the expensive $\\mathcal{O}(n^4)$ search cost. NCE employs graph neural network to predict the cost-decrements (i.e., results of CE searches) and utilizes the predicted cost-decrements to guide the selection of sub-tours for swapping, while reducing the search cost to $\\mathcal{O}(n^2)$. As the learning objective of NCE is to predict the cost-decrement, the training can be simply done in a supervised fashion, whose training samples can be easily collected. Despite the simplicity of NCE, numerical results show that the NCE trained with min-max flexible multi-depot VRP (min-max FMDVRP) outperforms the meta-heuristic baselines. More importantly, it significantly outperforms the neural baselines when solving distinctive special cases of min-max FMDVRP (e.g., min-max MDVRP, min-max mTSP, min-max CVRP) without additional training",
    "checked": true,
    "id": "178cb57e1e046e32ba3c93763b84907b51e0532f",
    "semantic_title": "learning to cross exchange to solve min-max vehicle routing problems",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=iUdSB2kK9GY": {
    "title": "PandA: Unsupervised Learning of Parts and Appearances in the Feature Maps of GANs",
    "volume": "poster",
    "abstract": "Recent advances in the understanding of Generative Adversarial Networks (GANs) have led to remarkable progress in visual editing and synthesis tasks, capitalizing on the rich semantics that are embedded in the latent spaces of pre-trained GANs. However, existing methods are often tailored to specific GAN architectures and are limited to either discovering global semantic directions that do not facilitate localized control, or require some form of supervision through manually provided regions or segmentation masks. In this light, we present an architecture-agnostic approach that jointly discovers factors representing spatial parts and their appearances in an entirely unsupervised fashion. These factors are obtained by applying a semi-nonnegative tensor factorization on the feature maps, which in turn enables context-aware local image editing with pixel-level control. In addition, we show that the discovered appearance factors correspond to saliency maps that localize concepts of interest, without using any labels. Experiments on a wide range of GAN architectures and datasets show that, in comparison to the state of the art, our method is far more efficient in terms of training time and, most importantly, provides much more accurate localized control. Our code is available at: https://github.com/james-oldfield/PandA",
    "checked": true,
    "id": "f5cbde920a432a20b99417778aa128d40481217c",
    "semantic_title": "panda: unsupervised learning of parts and appearances in the feature maps of gans",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=PEuxUXIMLlA": {
    "title": "Compositional Law Parsing with Latent Random Functions",
    "volume": "poster",
    "abstract": "Human cognition has compositionality. We understand a scene by decomposing the scene into different concepts (e.g., shape and position of an object) and learning the respective laws of these concepts, which may be either natural (e.g., laws of motion) or man-made (e.g., laws of a game). The automatic parsing of these laws indicates the model's ability to understand the scene, which makes law parsing play a central role in many visual tasks. This paper proposes a deep latent variable model for Compositional LAw Parsing (CLAP), which achieves the human-like compositionality ability through an encoding-decoding architecture to represent concepts in the scene as latent variables. CLAP employs concept-specific latent random functions instantiated with Neural Processes to capture the law of concepts. Our experimental results demonstrate that CLAP outperforms the baseline methods in multiple visual tasks such as intuitive physics, abstract visual reasoning, and scene representation. The law manipulation experiments illustrate CLAP's interpretability by modifying specific latent random functions on samples. For example, CLAP learns the laws of position-changing and appearance constancy from the moving balls in a scene, making it possible to exchange laws between samples or compose existing laws into novel laws",
    "checked": true,
    "id": "a6ba31c87f4f346965300c2c0015f7e7cbedf434",
    "semantic_title": "compositional law parsing with latent random functions",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=NVZvalzCLg": {
    "title": "LilNetX: Lightweight Networks with EXtreme Model Compression and Structured Sparsification",
    "volume": "poster",
    "abstract": "We introduce LilNetX, an end-to-end trainable technique for neural networks that enables learning models with specified accuracy-rate-computation trade-off. Prior works approach these problems one at a time and often require post-processing or multistage training which become less practical and do not scale very well for large datasets or architectures. Our method constructs a joint training objective that penalizes the self information of network parameters in a latent representation space to encourage small model size while also introducing priors to increase structured sparsity in the parameter space to reduce computation. When compared with existing state-of-the-art model compression methods, we achieve up to 50% smaller model size and 98% model sparsity on ResNet-20 on the CIFAR-10 dataset as well as 37% smaller model size and 71% structured sparsity on ResNet-50 trained on ImageNet while retaining the same accuracy as those methods. We show that the resulting sparsity can improve the inference time of the models by almost 1.8 times the dense ResNet-50 baseline model. Code is available at https://github.com/Sharath-girish/LilNetX",
    "checked": true,
    "id": "f7bd7fec504ef63839bdb43594111cffa06853f1",
    "semantic_title": "lilnetx: lightweight networks with extreme model compression and structured sparsification",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=7mgUec-7GMv": {
    "title": "Mitigating Dataset Bias by Using Per-Sample Gradient",
    "volume": "poster",
    "abstract": "The performance of deep neural networks is strongly influenced by the training dataset setup. In particular, when attributes with a strong correlation with the target attribute are present, the trained model can provide unintended prejudgments and show significant inference errors (i.e., the dataset bias problem). Various methods have been proposed to mitigate dataset bias, and their emphasis is on weakly correlated samples, called bias-conflicting samples. These methods are based on explicit bias labels provided by humans. However, such methods require human costs. Recently, several studies have sought to reduce human intervention by utilizing the output space values of neural networks, such as feature space, logits, loss, or accuracy. However, these output space values may be insufficient for the model to understand the bias attributes well. In this study, we propose a debiasing algorithm leveraging gradient called Per-sample Gradient-based Debiasing (PGD). PGD is comprised of three steps: (1) training a model on uniform batch sampling, (2) setting the importance of each sample in proportion to the norm of the sample gradient, and (3) training the model using importance-batch sampling, whose probability is obtained in step (2). Compared with existing baselines for various datasets, the proposed method showed state-of-the-art accuracy for the classification task. Furthermore, we describe theoretical understandings of how PGD can mitigate dataset bias",
    "checked": true,
    "id": "35cd12a6fe30e8fc532c37396f581bc8dc0c2a09",
    "semantic_title": "mitigating dataset bias by using per-sample gradient",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=fhcu4FBLciL": {
    "title": "Efficient Model Updates for Approximate Unlearning of Graph-Structured Data",
    "volume": "poster",
    "abstract": "With the adoption of recent laws ensuring the ``right to be forgotten'', the problem of machine unlearning has become of significant importance. This is particularly the case for graph-structured data, and learning tools specialized for such data, including graph neural networks (GNNs). This work introduces the first known approach for \\emph{approximate graph unlearning} with provable theoretical guarantees. The challenges in addressing the problem are two-fold. First, there exist multiple different types of unlearning requests that need to be considered, including node feature, edge and node unlearning. Second, to establish provable performance guarantees, one needs to carefully evaluate the process of feature mixing during propagation. We focus on analyzing Simple Graph Convolutions (SGC) and their generalized PageRank (GPR) extensions, thereby laying the theoretical foundations for unlearning GNNs. Empirical evaluations of six benchmark datasets demonstrate excellent performance/complexity/privacy trade-offs of our approach compared to complete retraining and general methods that do not leverage graph information. For example, unlearning $200$ out of $1208$ training nodes of the Cora dataset only leads to a $0.1\\%$ loss in test accuracy, but offers a $4$-fold speed-up compared to complete retraining with a $(\\epsilon,\\delta)=(1,10^{-4})$ ``privacy cost''. We also exhibit a $12\\%$ increase in test accuracy for the same dataset when compared to unlearning methods that do not leverage graph information, with comparable time complexity and the same privacy guarantee",
    "checked": true,
    "id": "5e04e20d9c550fc1cef1f1f86b30aadf0492fbac",
    "semantic_title": "efficient model updates for approximate unlearning of graph-structured data",
    "citation_count": 49,
    "authors": []
  },
  "https://openreview.net/forum?id=CYK7RfcOzQ4": {
    "title": "AudioGen: Textually Guided Audio Generation",
    "volume": "poster",
    "abstract": "In this work, we tackle the problem of generating audio samples conditioned on descriptive text captions. We propose AudioGen, an auto-regressive generative model, operating on a learnt discrete audio representation, that generates audio samples conditioned on text inputs. The task of text-to-audio generation poses multiple challenges. Due to the way audio travels through a medium, differentiating ``objects'' can be a difficult task (e.g., separating multiple people simultaneously speaking). This is further complicated by real-world recording conditions (e.g., background noise, reverberation, etc.). Scarce text annotations impose another constraint, limiting the ability to scale models. Finally, modeling high fidelity audio requires one to operate over extremely long sequences. To alleviate the aforementioned challenges we propose an augmentation technique that mixes different audio samples, driving the model to internally learn to separate multiple sources. We curated 10 datasets containing different types of audio and text annotations to handle the scarcity of text-audio data points. For faster inference, we explore the use of multi-stream modeling, allowing the use of shorter sequences while maintaining a similar bitrate and perceptual quality. Finally, we apply classifier-free guidance to improve adherence to text. Comparing to the evaluated baselines, AudioGen outperforms over both objective and subjective metrics. We further conduct an ablation study to gauge the effects of pre-trained text and audio components",
    "checked": true,
    "id": "ebb85974e06c4879b451fdfcb4f472a09471935b",
    "semantic_title": "audiogen: textually guided audio generation",
    "citation_count": 356,
    "authors": []
  },
  "https://openreview.net/forum?id=2WklawyeI08": {
    "title": "Hebbian and Gradient-based Plasticity Enables Robust Memory and Rapid Learning in RNNs",
    "volume": "poster",
    "abstract": "Rapidly learning from ongoing experiences and remembering past events with a flexible memory system are two core capacities of biological intelligence. While the underlying neural mechanisms are not fully understood, various evidence supports that synaptic plasticity plays a critical role in memory formation and fast learning. Inspired by these results, we equip Recurrent Neural Networks (RNNs) with plasticity rules to enable them to adapt their parameters according to ongoing experiences. In addition to the traditional local Hebbian plasticity, we propose a global, gradient-based plasticity rule, which allows the model to evolve towards its self-determined target. Our models show promising results on sequential and associative memory tasks, illustrating their ability to robustly form and retain memories. In the meantime, these models can cope with many challenging few-shot learning problems. Comparing different plasticity rules under the same framework shows that Hebbian plasticity is well-suited for several memory and associative learning tasks; however, it is outperformed by gradient-based plasticity on few-shot regression tasks which require the model to infer the underlying mapping",
    "checked": true,
    "id": "989830e67b55120b098afe12958b8c53d1b49f5b",
    "semantic_title": "hebbian and gradient-based plasticity enables robust memory and rapid learning in rnns",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=U9HW6vyNClg": {
    "title": "Towards Minimax Optimal Reward-free Reinforcement Learning in Linear MDPs",
    "volume": "poster",
    "abstract": "We study reward-free reinforcement learning with linear function approximation for episodic Markov decision processes (MDPs). In this setting, an agent first interacts with the environment without accessing the reward function in the exploration phase. In the subsequent planning phase, it is given a reward function and asked to output an $\\epsilon$-optimal policy. We propose a novel algorithm LSVI-RFE under the linear MDP setting, where the transition probability and reward functions are linear in a feature mapping. We prove an $\\widetilde{O}(H^{4} d^{2}/\\epsilon^2)$ sample complexity upper bound for LSVI-RFE, where $H$ is the episode length and $d$ is the feature dimension. We also establish a sample complexity lower bound of $\\Omega(H^{3} d^{2}/\\epsilon^2)$. To the best of our knowledge, LSVI-RFE is the first computationally efficient algorithm that achieves the minimax optimal sample complexity in linear MDP settings up to an $H$ and logarithmic factors. Our LSVI-RFE algorithm is based on a novel variance-aware exploration mechanism to avoid overly-conservative exploration in prior works. Our sharp bound relies on the decoupling of UCB bonuses during two phases, and a Bernstein-type self-normalized bound, which remove the extra dependency of sample complexity on $H$ and $d$, respectively",
    "checked": true,
    "id": "96ecf468d53457e492080cd61be6345409a69999",
    "semantic_title": "towards minimax optimal reward-free reinforcement learning in linear mdps",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=-nm-rHXi5ga": {
    "title": "On the Data-Efficiency with Contrastive Image Transformation in Reinforcement Learning",
    "volume": "poster",
    "abstract": "Data-efficiency has always been an essential issue in pixel-based reinforcement learning (RL). As the agent not only learns decision-making but also meaningful representations from images. The line of reinforcement learning with data augmentation shows significant improvements in sample-efficiency. However, it is challenging to guarantee the optimality invariant transformation, that is, the augmented data are readily recognized as a completely different state by the agent. In the end, we propose a contrastive invariant transformation (CoIT), a simple yet promising learnable data augmentation combined with standard model-free algorithms to improve sample-efficiency. Concretely, the differentiable CoIT leverages original samples with augmented samples and hastens the state encoder for a contrastive invariant embedding. We evaluate our approach on DeepMind Control Suite and Atari100K. Empirical results verify advances using CoIT, enabling it to outperform the new state-of-the-art on various tasks. Source code is available at https://github.com/mooricAnna/CoIT",
    "checked": true,
    "id": "4c1567b83c5e3e420103fde5757277a8f19476b2",
    "semantic_title": "on the data-efficiency with contrastive image transformation in reinforcement learning",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=zoz7Ze4STUL": {
    "title": "Energy-based Out-of-Distribution Detection for Graph Neural Networks",
    "volume": "poster",
    "abstract": "Representation learning on semi-structured data, e.g., graphs, has become a central problem in deep learning community as relational structures are pervasive in real situations and induce data inter-dependence that hinders trivial adaptation of existing approaches in other domains where the inputs are assumed to be i.i.d. sampled. However, current models in this regime mostly focus on improving testing performance of in-distribution data and largely ignores the potential risk w.r.t. out-of-distribution (OOD) testing samples that may cause negative outcome if the model is overconfident in prediction on them. In this paper, we identify a provably effective OOD discriminator based on an energy function directly extracted from a graph neural network trained with standard supervised classification loss. This paves a way for a simple and efficient OOD detection model for GNN-based semi-supervised learning on graphs, which we call GNN-Safe. It also has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for in-distribution and OOD samples, which, more critically, can be further strengthened by a non-learning-based structured propagation scheme. Extensive experiments over five real-world datasets validate the practical efficacy of the proposed model for detecting various OOD instances that are inter-connected in a graph with up to 17.0% improvement on average AUROC over competitive peer models and without sacrificing in-distribution testing accuracy",
    "checked": true,
    "id": "0dcf24bb23ce5bc17aab8138903af5f049a4db91",
    "semantic_title": "energy-based out-of-distribution detection for graph neural networks",
    "citation_count": 82,
    "authors": []
  },
  "https://openreview.net/forum?id=O8Vc52xFSUR": {
    "title": "Quasi-optimal Reinforcement Learning with Continuous Actions",
    "volume": "poster",
    "abstract": "Many real-world applications of reinforcement learning (RL) require making decisions in continuous action environments. In particular, determining the optimal dose level plays a vital role in developing medical treatment regimes. One challenge in adapting existing RL algorithms to medical applications, however, is that the popular infinite support stochastic policies, e.g., Gaussian policy, may assign riskily high dosages and harm patients seriously. Hence, it is important to induce a policy class whose support only contains near-optimal actions, and shrink the action-searching area for effectiveness and reliability. To achieve this, we develop a novel quasi-optimal learning algorithm, which can be easily optimized in off-policy settings with guaranteed convergence under general function approximations. Theoretically, we analyze the consistency, sample complexity, adaptability, and convergence of the proposed algorithm. We evaluate our algorithm with comprehensive simulated experiments and a dose suggestion real application to Ohio Type 1 diabetes dataset",
    "checked": true,
    "id": "8fe1f7d407423813e6cfd1e880703e2a2d6aa6de",
    "semantic_title": "quasi-optimal reinforcement learning with continuous actions",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=-EHqoysUYLx": {
    "title": "Generalization Bounds for Federated Learning: Fast Rates, Unparticipating Clients and Unbounded Losses",
    "volume": "poster",
    "abstract": "In {federated learning}, the underlying data distributions may be different across clients. This paper provides a theoretical analysis of generalization error of {federated learning}, which captures both heterogeneity and relatedness of the distributions. In particular, we assume that the heterogeneous distributions are sampled from a meta-distribution. In this two-level distribution framework, we characterize the generalization error not only for clients participating in the training but also for unparticipating clients. We first show that the generalization error for unparticipating clients can be bounded by participating generalization error and participating gap caused by clients' sampling. We further establish fast learning bounds of order $\\mathcal{O}(\\frac{1}{mn} + \\frac{1}{m})$ for unparticipating clients, where $m$ is the number of clients and $n$ is the sample size at each client. To our knowledge, the obtained fast bounds are state-of-the-art in the two-level distribution framework. Moreover, previous theoretical results mostly require the loss function to be bounded. We derive convergence bounds of order $\\mathcal{O}(\\frac{1}{\\sqrt{mn}} + \\frac{1}{\\sqrt{m}})$ under unbounded assumptions, including sub-exponential and sub-Weibull losses",
    "checked": true,
    "id": "b0dc28621dde6bb7a3f7372e9592c47117a4289e",
    "semantic_title": "generalization bounds for federated learning: fast rates, unparticipating clients and unbounded losses",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=bXNl-myZkJl": {
    "title": "More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity",
    "volume": "poster",
    "abstract": "Transformers have quickly shined in the computer vision world since the emergence of Vision Transformers (ViTs). The dominant role of convolutional neural networks (CNNs) seems to be challenged by increasingly effective transformer-based models. Very recently, a couple of advanced convolutional models strike back with large kernels motivated by the local-window attention mechanism, showing appealing performance and efficiency. While one of them, i.e. RepLKNet, impressively manages to scale the kernel size to 31x31 with improved performance, the performance starts to saturate as the kernel size continues growing, compared to the scaling trend of advanced ViTs such as Swin Transformer. In this paper, we explore the possibility of training extreme convolutions larger than 31x31 and test whether the performance gap can be eliminated by strategically enlarging convolutions. This study ends up with a recipe for applying extremely large kernels from the perspective of sparsity, which can smoothly scale up kernels to 61x61 with better performance. Built on this recipe, we propose Sparse Large Kernel Network (SLaK), a pure CNN architecture equipped with sparse factorized 51x51 kernels that can perform on par with or better than state-of-the-art hierarchical Transformers and modern ConvNet architectures like ConvNeXt and RepLKNet, on ImageNet classification as well as a wide range of downstream tasks including semantic segmentation on ADE20K, object detection on PASCAL VOC 2007, and object detection/segmentation on MS COCO. Codes are available at https://github.com/VITA-Group/SLaK",
    "checked": true,
    "id": "d1869155960e4b1b882b39171dbecd25a7eda3cd",
    "semantic_title": "more convnets in the 2020s: scaling up kernels beyond 51x51 using sparsity",
    "citation_count": 216,
    "authors": []
  },
  "https://openreview.net/forum?id=wlMDF1jQF86": {
    "title": "Which Layer is Learning Faster? A Systematic Exploration of Layer-wise Convergence Rate for Deep Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ca195fc6d5879060135a5cf6ff571b243f0c6156",
    "semantic_title": "which layer is learning faster? a systematic exploration of layer-wise convergence rate for deep neural networks",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=CJd-BtnwtXq": {
    "title": "A Non-Asymptotic Analysis of Oversmoothing in Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8ad64183b0d49ba90bdb09803c777524b8fe545b",
    "semantic_title": "a non-asymptotic analysis of oversmoothing in graph neural networks",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=sCrnllCtjoE": {
    "title": "Scaleformer: Iterative Multi-scale Refining Transformers for Time Series Forecasting",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "016e99ccef0afb7011f3ea3b1b932611c8fb957b",
    "semantic_title": "scaleformer: iterative multi-scale refining transformers for time series forecasting",
    "citation_count": 75,
    "authors": []
  },
  "https://openreview.net/forum?id=g4OTKRKfS7R": {
    "title": "Liquid Structural State-Space Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b40f0b0465cdf4b487fb2ef85d4e2672c4b623cc",
    "semantic_title": "liquid structural state-space models",
    "citation_count": 128,
    "authors": []
  },
  "https://openreview.net/forum?id=RiTjKoscnNd": {
    "title": "Equivariant Hypergraph Diffusion Neural Operators",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "73bac2bf125f6d21d2eec79aa2fc31bcddbb1b7d",
    "semantic_title": "equivariant hypergraph diffusion neural operators",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=sPCKNl5qDps": {
    "title": "Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ccf5ce2110f723e8d147392206e7d33677cb8320",
    "semantic_title": "ollivier-ricci curvature for hypergraphs: a unified framework",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=wq0luyH3m4": {
    "title": "Hard-Meta-Dataset++: Towards Understanding Few-Shot Performance on Difficult Tasks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4cd935cd2f7f26b31f6bdc3b062d071b5d7f9cdb",
    "semantic_title": "hard-meta-dataset++: towards understanding few-shot performance on difficult tasks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=gJW8hSGBys8": {
    "title": "Compositional Semantic Parsing with Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fd19acf53899a33c0c84c21533ddf7f88b079485",
    "semantic_title": "compositional semantic parsing with large language models",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=zClyiZ5V6sL": {
    "title": "TiAda: A Time-scale Adaptive Algorithm for Nonconvex Minimax Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "96f7e2a757759d61eb7e81c5ee0e1f48fb8a271a",
    "semantic_title": "tiada: a time-scale adaptive algorithm for nonconvex minimax optimization",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=shzu8d6_YAR": {
    "title": "FaiREE: fair classification with finite-sample and distribution-free guarantee",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bc6b759cc95fbfeba3ca8c7bb42be4feee36b864",
    "semantic_title": "fairee: fair classification with finite-sample and distribution-free guarantee",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=1_jtWjhSSkr": {
    "title": "Exponential Generalization Bounds with Near-Optimal Rates for $L_q$-Stable Algorithms",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "edc76bbaaee213b86263fd108aacc50e085a57cb",
    "semantic_title": "exponential generalization bounds with near-optimal rates for $l_q$-stable algorithms",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=EMvG1Jdhw_8": {
    "title": "Disentangling Learning Representations with Density Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "913349ed72e00869ae55cace91e0a6398d7379c3",
    "semantic_title": "disentangling learning representations with density estimation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=GVSf7Z7DbYL": {
    "title": "Teacher Guided Training: An Efficient Framework for Knowledge Transfer",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "13df9e045024fcbc5ed0e33829ca8e02986bcbcb",
    "semantic_title": "teacher guided training: an efficient framework for knowledge transfer",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=GULFHQfgw0g": {
    "title": "Neural Agents Struggle to Take Turns in Bidirectional Emergent Communication",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2f8c78b54a1a64d5ab7e634e49f1a58163dc45b5",
    "semantic_title": "neural agents struggle to take turns in bidirectional emergent communication",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=98p5x51L5af": {
    "title": "Prompting GPT-3 To Be Reliable",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c8d594f09413b1555970f43e68847c211235d60f",
    "semantic_title": "prompting gpt-3 to be reliable",
    "citation_count": 317,
    "authors": []
  },
  "https://openreview.net/forum?id=ReDQ1OUQR0X": {
    "title": "Human alignment of neural network representations",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7ed0b9e3c058a0f9db07d8dc63043a16bb05f08c",
    "semantic_title": "human alignment of neural network representations",
    "citation_count": 70,
    "authors": []
  },
  "https://openreview.net/forum?id=j3cUWIMsFBN": {
    "title": "Unbiased Stochastic Proximal Solver for Graph Neural Networks with Equilibrium States",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4a040e3946b66a319b203a7b9240008dd405dced",
    "semantic_title": "unbiased stochastic proximal solver for graph neural networks with equilibrium states",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=UaAD-Nu86WX": {
    "title": "DiGress: Discrete Denoising diffusion for graph generation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c65c4b68ac153176354a4c33c37f0ba1d86772c0",
    "semantic_title": "digress: discrete denoising diffusion for graph generation",
    "citation_count": 436,
    "authors": []
  },
  "https://openreview.net/forum?id=gVOXZproe-e": {
    "title": "How to prepare your task head for finetuning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "75852ed23746bb8fceebeef8c5ae2d228b83dd24",
    "semantic_title": "how to prepare your task head for finetuning",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=jQj-_rLVXsj": {
    "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "69144d537f90f214d5b07a7c79121d16afd7da16",
    "semantic_title": "diffuseq: sequence to sequence text generation with diffusion models",
    "citation_count": 390,
    "authors": []
  },
  "https://openreview.net/forum?id=-Y34L45JR6z": {
    "title": "Policy Expansion for Bridging Offline-to-Online Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7f270c9b098727675c9d8b893e362b561d61f27e",
    "semantic_title": "policy expansion for bridging offline-to-online reinforcement learning",
    "citation_count": 80,
    "authors": []
  },
  "https://openreview.net/forum?id=6qcYDVlVLnK": {
    "title": "Mitigating Memorization of Noisy Labels via Regularization between Representations",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "34ddedc56636cffd6582570049747bd5dfa0ae5b",
    "semantic_title": "mitigating memorization of noisy labels via regularization between representations",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=dqnNW2omZL6": {
    "title": "Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f6c7ac7e5eb42fb0524657b1954a33f795ca54a8",
    "semantic_title": "graph neural networks are inherently good generalizers: insights by bridging gnns and mlps",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=Zob4P9bRNcK": {
    "title": "Learning Cut Selection for Mixed-Integer Linear Programming via Hierarchical Sequence Model",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "54e3065e2cfdc9d30d1a190dafb1c80335e88662",
    "semantic_title": "learning cut selection for mixed-integer linear programming via hierarchical sequence model",
    "citation_count": 49,
    "authors": []
  },
  "https://openreview.net/forum?id=ZxdkjTgK_Dl": {
    "title": "BSTT: A Bayesian Spatial-Temporal Transformer for Sleep Staging",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3dabb1da0107f7b8b2974daa570e406763838e99",
    "semantic_title": "bstt: a bayesian spatial-temporal transformer for sleep staging",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=6qZC7pfenQm": {
    "title": "Improving Deep Policy Gradients with Value Function Search",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b01df6b25ef53a764874e6437d898a851d8f1627",
    "semantic_title": "improving deep policy gradients with value function search",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=txlWziuCE5W": {
    "title": "MEDICAL IMAGE UNDERSTANDING WITH PRETRAINED VISION LANGUAGE MODELS: A COMPREHENSIVE STUDY",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5d8fd04c436367b18b35e28332ee8e452a477f3f",
    "semantic_title": "medical image understanding with pretrained vision language models: a comprehensive study",
    "citation_count": 76,
    "authors": []
  },
  "https://openreview.net/forum?id=-t4D61w4zvQ": {
    "title": "Temporal Coherent Test Time Optimization for Robust Video Classification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "b28083b620deb716b24797daf662d1950bcfec94",
    "semantic_title": "temporal coherent test-time optimization for robust video classification",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=rdfgqiwz7lZ": {
    "title": "A Learning Based Hypothesis Test for Harmful Covariate Shift",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "68b6406545fdacffbc8dabde5a80188b54772e5a",
    "semantic_title": "a learning based hypothesis test for harmful covariate shift",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=NPrsUQgMjKK": {
    "title": "Deep Transformers without Shortcuts: Modifying Self-attention for Faithful Signal Propagation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b8c236dc5963dac36b0d8e419beb5876e3a18f96",
    "semantic_title": "deep transformers without shortcuts: modifying self-attention for faithful signal propagation",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=ZKDUlVMqG_O": {
    "title": "Self-Supervised Geometric Correspondence for Category-Level 6D Object Pose Estimation in the Wild",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c1e4f984549320771f31a8f05e53acc067b9fce5",
    "semantic_title": "self-supervised geometric correspondence for category-level 6d object pose estimation in the wild",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=JHklpEZqduQ": {
    "title": "Non-parametric Outlier Synthesis",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "682ff0690c87a31c6bc148e53f56b5b494621d66",
    "semantic_title": "non-parametric outlier synthesis",
    "citation_count": 127,
    "authors": []
  },
  "https://openreview.net/forum?id=r90KYcuB7JS": {
    "title": "Approximation and non-parametric estimation of functions over high-dimensional spheres via deep ReLU networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5a0cc4b2b51bd264008d081ca4810abb2fa50f64",
    "semantic_title": "approximation and non-parametric estimation of functions over high-dimensional spheres via deep relu networks",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=sVU54nyaA9K": {
    "title": "Learning Adversarial Linear Mixture Markov Decision Processes with Bandit Feedback and Unknown Transition",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2a00e9c1393be7dc62519c0994c7ebb67c1a194f",
    "semantic_title": "learning adversarial linear mixture markov decision processes with bandit feedback and unknown transition",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=4yqxDCbzS98": {
    "title": "Weakly Supervised Knowledge Transfer with Probabilistic Logical Reasoning for Object Detection",
    "volume": "poster",
    "abstract": "Training object detection models usually requires instance-level annotations, such as the positions and labels of all objects present in each image. Such supervision is unfortunately not always available and, more often, only image-level information is provided, also known as weak supervision. Recent works have addressed this limitation by leveraging knowledge from a richly annotated domain. However, the scope of weak supervision supported by these approaches has been very restrictive, preventing them to use all available information. In this work, we propose ProbKT, a framework based on probabilistic logical reasoning to train object detection models with arbitrary types of weak supervision. We empirically show on different datasets that using all available information is beneficial as our ProbKT leads to significant improvement on target domain and better generalisation compared to existing baselines. We also showcase the ability of our approach to handle complex logic statements as supervision signal",
    "checked": true,
    "id": "96165b189c0099bd73bdf9147021712c98e507f2",
    "semantic_title": "weakly supervised knowledge transfer with probabilistic logical reasoning for object detection",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=rLguqxYvYHB": {
    "title": "A Neural Mean Embedding Approach for Back-door and Front-door Adjustment",
    "volume": "poster",
    "abstract": "We consider the estimation of average and counterfactual treatment effects, under two settings: back-door adjustment and front-door adjustment. The goal in both cases is to recover the treatment effect without having an access to a hidden confounder. This objective is attained by first estimating the conditional mean of the desired outcome variable given relevant covariates (the ``first stage\" regression), and then taking the (conditional) expectation of this function as a ``second stage\" procedure. We propose to compute these conditional expectations directly using a regression function to the learned input features of the first stage, thus avoiding the need for sampling or density estimation. All functions and features (and in particular, the output features in the second stage) are neural networks learned adaptively from data, with the sole requirement that the final layer of the first stage should be linear. The proposed method is shown to converge to the true causal parameter, and outperforms the recent state-of-the-art methods on challenging causal benchmarks, including settings involving high-dimensional image data",
    "checked": true,
    "id": "eba6df900c6d2d0fa776aff332571b17b73c2b6b",
    "semantic_title": "a neural mean embedding approach for back-door and front-door adjustment",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=UVAmFAtC5ye": {
    "title": "TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation",
    "volume": "poster",
    "abstract": "Direct speech-to-speech translation (S2ST) with discrete units leverages recent progress in speech representation learning. Specifically, a sequence of discrete representations derived in a self-supervised manner are predicted from the model and passed to a vocoder for speech reconstruction, while still facing the following challenges: 1) Acoustic multimodality: the discrete units derived from speech with same content could be indeterministic due to the acoustic property (e.g., rhythm, pitch, and energy), which causes deterioration of translation accuracy; 2) high latency: current S2ST systems utilize autoregressive models which predict each unit conditioned on the sequence previously generated, failing to take full advantage of parallelism. In this work, we propose TranSpeech, a speech-to-speech translation model with bilateral perturbation. To alleviate the acoustic multimodal problem, we propose bilateral perturbation (BiP), which consists of the style normalization and information enhancement stages, to learn only the linguistic information from speech samples and generate more deterministic representations. With reduced multimodality, we step forward and become the first to establish a non-autoregressive S2ST technique, which repeatedly masks and predicts unit choices and produces high-accuracy results in just a few cycles. Experimental results on three language pairs demonstrate that BiP yields an improvement of 2.9 BLEU on average compared with a baseline textless S2ST model. Moreover, our parallel decoding shows a significant reduction of inference latency, enabling speedup up to 21.4x than autoregressive technique. Audio samples are available at https://TranSpeech.github.io",
    "checked": true,
    "id": "6b86667bae101cc045f39d3d77a1eaf21a43c12c",
    "semantic_title": "transpeech: speech-to-speech translation with bilateral perturbation",
    "citation_count": 47,
    "authors": []
  },
  "https://openreview.net/forum?id=aBIpZvMdS56": {
    "title": "Over-parameterized Model Optimization with Polyak-{\\L}ojasiewicz Condition",
    "volume": "poster",
    "abstract": "This work pursues the optimization of over-parameterized deep models for superior training efficiency and test performance. We first theoretically emphasize the importance of two properties of over-parameterized models, i.e., the convergence gap and the generalization gap. Subsequent analyses unveil that these two gaps can be upper-bounded by the ratio of the Lipschitz constant and the Polyak-{\\L}ojasiewicz (PL) constant, a crucial term abbreviated as the \\emph{condition number}. Such discoveries have led to a structured pruning method with a novel pruning criterion. That is, we devise a gating network that dynamically detects and masks out those poorly-behaved nodes of a deep model during the training session. To this end, this gating network is learned via minimizing the \\emph{condition number} of the target model, and this process can be implemented as an extra regularization loss term. Experimental studies demonstrate that the proposed method outperforms the baselines in terms of both training efficiency and test performance, exhibiting the potential of generalizing to a variety of deep network architectures and tasks",
    "checked": false,
    "id": "a545b5d6076bd6690c062c27cc04412117940d61",
    "semantic_title": "fast convergence of random reshuffling under over-parameterization and the polyak-łojasiewicz condition",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=BPwIgvf5iQ": {
    "title": "Jointly Learning Visual and Auditory Speech Representations from Raw Data",
    "volume": "poster",
    "abstract": "We present RAVEn, a self-supervised multi-modal approach to jointly learn visual and auditory speech representations. Our pre-training objective involves encoding masked inputs, and then predicting contextualised targets generated by slowly-evolving momentum encoders. Driven by the inherent differences between video and audio, our design is asymmetric w.r.t. the two modalities' pretext tasks: Whereas the auditory stream predicts both the visual and auditory targets, the visual one predicts only the auditory targets. We observe strong results in low- and high-resource labelled data settings when fine-tuning the visual and auditory encoders resulting from a single pre-training stage, in which the encoders are jointly trained. Notably, RAVEn surpasses all self-supervised methods on visual speech recognition (VSR) on LRS3, and combining RAVEn with self-training using only 30 hours of labelled data even outperforms a recent semi-supervised method trained on 90,000 hours of non-public data. At the same time, we achieve state-of-the-art results in the LRS3 low-resource setting for auditory speech recognition (as well as for VSR). Our findings point to the viability of learning powerful speech representations entirely from raw video and audio, i.e., without relying on handcrafted features. Code and models are available at https://github.com/ahaliassos/raven",
    "checked": true,
    "id": "cb517aba70a65b68e5f4d599ff2d094e0ad51051",
    "semantic_title": "jointly learning visual and auditory speech representations from raw data",
    "citation_count": 56,
    "authors": []
  },
  "https://openreview.net/forum?id=H4Ncs5jhTCu": {
    "title": "Diminishing Return of Value Expansion Methods in Model-Based Reinforcement Learning",
    "volume": "poster",
    "abstract": "Model-based reinforcement learning is one approach to increase sample efficiency. However, the accuracy of the dynamics model and the resulting compounding error over modelled trajectories are commonly regarded as key limitations. A natural question to ask is: How much more sample efficiency can be gained by improving the learned dynamics models? Our paper empirically answers this question for the class of model-based value expansion methods in continuous control problems. Value expansion methods should benefit from increased model accuracy by enabling longer rollout horizons and better value function approximations. Our empirical study, which leverages oracle dynamics models to avoid compounding model errors, shows that (1) longer horizons increase sample efficiency, but the gain in improvement decreases with each additional expansion step, and (2) the increased model accuracy only marginally increases the sample efficiency compared to learned models with identical horizons. Therefore, longer horizons and increased model accuracy yield diminishing returns in terms of sample efficiency. These improvements in sample efficiency are particularly disappointing when compared to model-free value expansion methods. Even though they introduce no computational overhead, we find their performance to be on-par with model-based value expansion methods. Therefore, we conclude that the limitation of model-based value expansion methods is not the model accuracy of the learned models. While higher model accuracy is beneficial, our experiments show that even a perfect model will not provide an un-rivaled sample efficiency but that the bottleneck lies elsewhere",
    "checked": true,
    "id": "1484cc1fc1d7ed1b9e77b230aaee01f4b29e9327",
    "semantic_title": "diminishing return of value expansion methods in model-based reinforcement learning",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=GNjzMAgawq": {
    "title": "CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language Alignment",
    "volume": "poster",
    "abstract": "Pre-trained image-text models, like CLIP, have demonstrated the strong power of vision-language representation learned from a large scale of web-collected image-text data. In light of the well-learned visual features, there are works that transfer image representation to the video domain and achieve good results. However, adapting image-text pre-trained models to video-text pre-training (i.e., post-pretraining) has not demonstrated a significant advantage yet. In this paper, we tackle this challenge by raising and addressing two questions: 1) what are the factors hindering post-pretraining CLIP from improving performance on video-text tasks, and 2) how to mitigate the impact of these factors. Through a series of comparative experiments and analyses, we find that the data scale and domain gap between language sources have large impacts. By these observations, we propose an Omnisource Cross-modal Learning method equipped with a Video Proxy mechanism on the basis of CLIP, namely CLIP-ViP. Extensive results show that our approach improves the performance of CLIP on video-text retrieval by a large margin. Our model achieves state-of-the-art results on a variety of datasets, including MSR-VTT, DiDeMo, LSMDC, and ActivityNet. We release our code and pre-trained CLIP-ViP models at \\url{https://github.com/microsoft/XPretrain/tree/main/CLIP-ViP}",
    "checked": true,
    "id": "9e095237a496f20c286eafb9dd966f775f5fbac5",
    "semantic_title": "clip-vip: adapting pre-trained image-text model to video-language alignment",
    "citation_count": 82,
    "authors": []
  },
  "https://openreview.net/forum?id=r0otLtOwYW": {
    "title": "Equivariant Energy-Guided SDE for Inverse Molecular Design",
    "volume": "poster",
    "abstract": "Inverse molecular design is critical in material science and drug discovery, where the generated molecules should satisfy certain desirable properties. In this paper, we propose equivariant energy-guided stochastic differential equations (EEGSDE), a flexible framework for controllable 3D molecule generation under the guidance of an energy function in diffusion models. Formally, we show that EEGSDE naturally exploits the geometric symmetry in 3D molecular conformation, as long as the energy function is invariant to orthogonal transformations. Empirically, under the guidance of designed energy functions, EEGSDE significantly improves the baseline on QM9, in inverse molecular design targeted to quantum properties and molecular structures. Furthermore, EEGSDE is able to generate molecules with multiple target properties by combining the corresponding energy functions linearly",
    "checked": true,
    "id": "154fa935150bb2c9e4fd7f6fc7820007c6390990",
    "semantic_title": "equivariant energy-guided sde for inverse molecular design",
    "citation_count": 71,
    "authors": []
  },
  "https://openreview.net/forum?id=KB1sc5pNKFv": {
    "title": "On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement Learning",
    "volume": "poster",
    "abstract": "Reinforcement Learning (RL) algorithms can solve challenging control problems directly from image observations, but they often require millions of environment interactions to do so. Recently, model-based RL algorithms have greatly improved sample-efficiency by concurrently learning an internal model of the world, and supplementing real environment interactions with imagined rollouts for policy improvement. However, learning an effective model of the world from scratch is challenging, and in stark contrast to humans that rely heavily on world understanding and visual cues for learning new skills. In this work, we investigate whether internal models learned by modern model-based RL algorithms can be leveraged to solve new, distinctly different tasks faster. We propose Model-Based Cross-Task Transfer (XTRA), a framework for sample-efficient online RL with scalable pretraining and finetuning of learned world models. By offline multi-task pretraining and online cross-task finetuning, we achieve substantial improvements over a baseline trained from scratch; we improve mean performance of model-based algorithm EfficientZero by 23%, and by as much as 71% in some instances. Project page: https://nicklashansen.github.io/xtra",
    "checked": true,
    "id": "48f5b8bf81a860b46e69e5482f8ae7ecf8909a0d",
    "semantic_title": "on the feasibility of cross-task transfer with model-based reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IVESH65r0Ar": {
    "title": "A Simple Yet Powerful Deep Active Learning With Snapshots Ensembles",
    "volume": "poster",
    "abstract": "Given an unlabeled pool of data and the experts who can label them, active learning aims to build an agent that can effectively acquire data to be queried to the experts, maximizing the gain in performance when trained with them. While there are several principles for active learning, a prevailing approach is to estimate uncertainties of predictions for unlabeled samples and use them to define acquisition functions. Active learning with the uncertainty principle works well for deep learning, especially for large-scale image classification tasks with deep neural networks. Still, it is often overlooked how the uncertainty of predictions is estimated, despite the common findings on the difficulty of accurately estimating uncertainties of deep neural networks. In this paper, we highlight the effectiveness of snapshot ensembles for deep active learning. Compared to the previous approaches based on Monte-Carlo dropout or deep ensembles, we show that a simple acquisition strategy based on uncertainties estimated from parameter snapshots gathered from a single optimization path significantly improves the quality of the acquired samples. Based on this observation, we further propose an efficient active learning algorithm that maintains a single learning trajectory throughout the entire active learning episodes, unlike the existing algorithms training models from scratch for every active learning episode. Through the extensive empirical comparison, we demonstrate the effectiveness of snapshot ensembles for deep active learning",
    "checked": true,
    "id": "ca9c118eb5a129c33ac818acbe847adbc2c3f114",
    "semantic_title": "a simple yet powerful deep active learning with snapshots ensembles",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=bcYZwYo-0t": {
    "title": "Decoupled Training for Long-Tailed Classification With Stochastic Representations",
    "volume": "poster",
    "abstract": "Decoupling representation learning and classifier learning has been shown to be effective in classification with long-tailed data. There are two main ingredients in constructing a decoupled learning scheme; 1) how to train the feature extractor for representation learning so that it provides generalizable representations and 2) how to re-train the classifier that constructs proper decision boundaries by handling class imbalances in long-tailed data. In this work, we first apply Stochastic Weight Averaging (SWA), an optimization technique for improving the generalization of deep neural networks, to obtain better generalizing feature extractors for long-tailed classification. We then propose a novel classifier re-training algorithm based on stochastic representation obtained from the SWA-Gaussian, a Gaussian perturbed SWA, and a self-distillation strategy that can harness the diverse stochastic representations based on uncertainty estimates to build more robust classifiers. Extensive experiments on CIFAR10/100-LT, ImageNet-LT, and iNaturalist-2018 benchmarks show that our proposed method improves upon previous methods both in terms of prediction accuracy and uncertainty estimation",
    "checked": true,
    "id": "12c14868a38fd7f4cefe4007474e3139f9065586",
    "semantic_title": "decoupled training for long-tailed classification with stochastic representations",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=2XLRBjY46O6": {
    "title": "ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View Semantic Consistency",
    "volume": "poster",
    "abstract": "Recently, great success has been made in learning visual representations from text supervision, facilitating the emergence of text-supervised semantic segmentation. However, existing works focus on pixel grouping and cross-modal semantic alignment, while ignoring the correspondence among multiple augmented views of the same image. To overcome such limitation, we propose multi-View Consistent learning (ViewCo) for text-supervised semantic segmentation. Specifically, we first propose text-to-views consistency modeling to learn correspondence for multiple views of the same input image. Additionally, we propose cross-view segmentation consistency modeling to address the ambiguity issue of text supervision by contrasting the segment features of Siamese visual encoders. The text-to-views consistency benefits dense assignment of the visual features by encouraging different crops to align with the same text, while the cross-view segmentation consistency modeling provides additional self-supervision, overcoming the limitation of ambiguous text supervision for segmentation masks. Trained with large-scale image-text data, our model can directly segment objects of arbitrary categories in a zero-shot manner. Extensive experiments show that ViewCo outperforms state-of-the-art methods on average by up to 2.9%, 1.6%, and 2.4% mIoU on PASCAL VOC2012, PASCAL Context, and COCO, respectively",
    "checked": true,
    "id": "bd4d6f8c0935d4bb7a4ec5f426bac7bbb0f50fd4",
    "semantic_title": "viewco: discovering text-supervised segmentation masks via multi-view semantic consistency",
    "citation_count": 52,
    "authors": []
  },
  "https://openreview.net/forum?id=vINj_Hv9szL": {
    "title": "Benchmarking Constraint Inference in Inverse Reinforcement Learning",
    "volume": "poster",
    "abstract": "When deploying Reinforcement Learning (RL) agents into a physical system, we must ensure that these agents are well aware of the underlying constraints. In many real-world problems, however, the constraints are often hard to specify mathematically and unknown to the RL agents. To tackle these issues, Inverse Constrained Reinforcement Learning (ICRL) empirically estimates constraints from expert demonstrations. As an emerging research topic, ICRL does not have common benchmarks, and previous works tested algorithms under hand-crafted environments with manually-generated expert demonstrations. In this paper, we construct an ICRL benchmark in the context of RL application domains, including robot control, and autonomous driving. For each environment, we design relevant constraints and train expert agents to generate demonstration data. Besides, unlike existing baselines that learn a deterministic constraint, we propose a variational ICRL method to model a posterior distribution of candidate constraints. We conduct extensive experiments on these algorithms under our benchmark and show how they can facilitate studying important research challenges for ICRL. The benchmark, including the instructions for reproducing ICRL algorithms, is available at https://github.com/Guiliang/ICRL-benchmarks-public",
    "checked": true,
    "id": "ba8293be338f4bed4a6e44e7ce78510d74c1e048",
    "semantic_title": "benchmarking constraint inference in inverse reinforcement learning",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=jHc8dCx6DDr": {
    "title": "Memory Gym: Partially Observable Challenges to Memory-Based Agents",
    "volume": "poster",
    "abstract": "Memory Gym is a novel benchmark for challenging Deep Reinforcement Learning agents to memorize events across long sequences, be robust to noise, and generalize. It consists of the partially observable 2D and discrete control environments Mortar Mayhem, Mystery Path, and Searing Spotlights. These environments are believed to be unsolvable by memory-less agents because they feature strong dependencies on memory and frequent agent-memory interactions. Empirical results based on Proximal Policy Optimization (PPO) and Gated Recurrent Unit (GRU) underline the strong memory dependency of the contributed environments. The hardness of these environments can be smoothly scaled, while different levels of difficulty (some of them unsolved yet) emerge for Mortar Mayhem and Mystery Path. Surprisingly, Searing Spotlights poses a tremendous challenge to GRU-PPO, which remains an open puzzle. Even though the randomly moving spotlights reveal parts of the environment's ground truth, environmental ablations hint that these pose a severe perturbation to agents that leverage recurrent model architectures as their memory. Source Code: https://github.com/MarcoMeter/drl-memory-gym/",
    "checked": true,
    "id": "35078cd14bb18c974b7f87f1c643708fdbe67a30",
    "semantic_title": "memory gym: partially observable challenges to memory-based agents",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kjkdzBW3b8p": {
    "title": "Discovering Policies with DOMiNO: Diversity Optimization Maintaining Near Optimality",
    "volume": "poster",
    "abstract": "In this work we propose a Reinforcement Learning (RL) agent that can discover complex behaviours in a rich environment with a simple reward function. We define diversity in terms of state-action occupancy measures, since policies with different occupancy measures visit different states on average. More importantly, defining diversity in this way allows us to derive an intrinsic reward function for maximizing the diversity directly. Our agent, DOMiNO, stands for Diversity Optimization Maintaining Near Optimally. It is based on maximizing a reward function with two components: the extrinsic reward and the diversity intrinsic reward, which are combined with Lagrange multipliers to balance the quality-diversity trade-off. Any RL algorithm can be used to maximize this reward and no other changes are needed. We demonstrate that given a simple reward functions in various control domains, like height (stand) and forward velocity (walk), DOMiNO discovers diverse and meaningful behaviours. We also perform extensive analysis of our approach, compare it with other multi-objective baselines, demonstrate that we can control both the quality and the diversity of the set via interpretable hyperparameters, and show that the set is robust to perturbations of the environment",
    "checked": true,
    "id": "ee626478aafe6496c86512660820933538059ef2",
    "semantic_title": "discovering policies with domino: diversity optimization maintaining near optimality",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=Mg5CLXZgvLJ": {
    "title": "SpeedyZero: Mastering Atari with Limited Data and Time",
    "volume": "poster",
    "abstract": "Many recent breakthroughs of deep reinforcement learning (RL) are mainly built upon large-scale distributed training of model-free methods using millions to billions of samples. On the other hand, state-of-the-art model-based RL methods can achieve human-level sample efficiency but often take a much longer over all training time than model-free methods. However, high sample efficiency and fast training time are both important to many real-world applications. We develop SpeedyZero, a distributed RL system built upon a state-of-the-art model-based RL method, EfficientZero, with a dedicated system design for fast distributed computation. We also develop two novel algorithmic techniques, Priority Refresh and Clipped LARS, to stabilize training with massive parallelization and large batch size. SpeedyZero maintains on-par sample efficiency compared with EfficientZero while achieving a 14.5X speedup in wall-clock time, leading to human-level performances on the Atari benchmark within 35 minutes using only 300k samples. In addition, we also present an in-depth analysis on the fundamental challenges in further scaling our system to bring insights to the community",
    "checked": true,
    "id": "2fc10a75e4fdf87123a7f471cc2b6830acb35163",
    "semantic_title": "speedyzero: mastering atari with limited data and time",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=p8coElqiSDw": {
    "title": "Neural Architecture Design and Robustness: A Dataset",
    "volume": "poster",
    "abstract": "Deep learning models have proven to be successful in a wide range of machine learning tasks. Yet, they are often highly sensitive to perturbations on the input data which can lead to incorrect decisions with high confidence, hampering their deployment for practical use-cases. Thus, finding architectures that are (more) robust against perturbations has received much attention in recent years. Just like the search for well-performing architectures in terms of clean accuracy, this usually involves a tedious trial-and-error process with one additional challenge: the evaluation of a network's robustness is significantly more expensive than its evaluation for clean accuracy. Thus, the aim of this paper is to facilitate better streamlined research on architectural design choices with respect to their impact on robustness as well as, for example, the evaluation of surrogate measures for robustness. We therefore borrow one of the most commonly considered search spaces for neural architecture search for image classification, NAS-Bench-201, which contains a manageable size of 6466 non-isomorphic network designs. We evaluate all these networks on a range of common adversarial attacks and corruption types and introduce a database on neural architecture design and robustness evaluations. We further present three exemplary use cases of this dataset, in which we (i) benchmark robustness measurements based on Jacobian and Hessian matrices for their robustness predictability, (ii) perform neural architecture search on robust accuracies, and (iii) provide an initial analysis of how architectural design choices affect robustness. We find that carefully crafting the topology of a network can have substantial impact on its robustness, where networks with the same parameter count range in mean adversarial robust accuracy from 20%-41%. Code and data is available at http://robustness.vision/",
    "checked": true,
    "id": "c5772e031f2b7110dac99acae3425ea56b952856",
    "semantic_title": "neural architecture design and robustness: a dataset",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=QB1dMPEXau5": {
    "title": "Does Deep Learning Learn to Abstract? A Systematic Probing Framework",
    "volume": "poster",
    "abstract": "Abstraction is a desirable capability for deep learning models, which means to induce abstract concepts from concrete instances and flexibly apply them beyond the learning context. At the same time, there is a lack of clear understanding about both the presence and further characteristics of this capability in deep learning models. In this paper, we introduce a systematic probing framework to explore the abstraction capability of deep learning models from a transferability perspective. A set of controlled experiments are conducted based on this framework, providing strong evidence that two probed pre-trained language models (PLMs), T5 and GPT2, have the abstraction capability. We also conduct in-depth analysis, thus shedding further light: (1) the whole training phase exhibits a \"memorize-then-abstract\" two-stage process; (2) the learned abstract concepts are gathered in a few middle-layer attention heads, rather than being evenly distributed throughout the model; (3) the probed abstraction capabilities exhibit robustness against concept mutations, and are more robust to low-level/source-side mutations than high-level/target-side ones; (4) generic pre-training is critical to the emergence of abstraction capability, and PLMs exhibit better abstraction with larger model sizes and data scales",
    "checked": true,
    "id": "2ae807688d5bae0a7331992793be066b93d7655f",
    "semantic_title": "does deep learning learn to abstract? a systematic probing framework",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=0f-0I6RFAch": {
    "title": "Improving Out-of-distribution Generalization with Indirection Representations",
    "volume": "poster",
    "abstract": "We propose a generic module named Indirection Layer (InLay), which leverages indirection and data internal relationships to effectively construct symbolic indirect representations to improve out-of-distribution generalization capabilities of various neural architectures. InLay receives data input in the form of a sequence of objects, treats it as a complete weighted graph whose vertices are the objects and edge weights are scalars representing relationships between vertices. The input is first mapped via indirection to a symbolic graph with data-independent and trainable vertices. This symbolic graph is then propagated, resulting in new vertex features whose indirection will be used for prediction steps afterward. Theoretically, we show that the distances between indirection representations are bounded by the distances between corresponding graphs, implying that unseen samples with very different surface statistics can still be close in the representation space to the seen samples if they share similar internal relationships. We demonstrate that InLay is consistently effective in improving out-of-distribution generalization throughout a comprehensive suite of experiments, including IQ problems, distorted image classification, and few-shot domain adaptation NLP classification. We also conduct ablation studies to verify different design choices of InLay",
    "checked": true,
    "id": "c1f1d55ee54b6ea0b6052180e1aa88c2efd62481",
    "semantic_title": "improving out-of-distribution generalization with indirection representations",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=F0KTk2plQzO": {
    "title": "Accelerating Guided Diffusion Sampling with Splitting Numerical Methods",
    "volume": "poster",
    "abstract": "Guided diffusion is a technique for conditioning the output of a diffusion model at sampling time without retraining the network for each specific task. However, one drawback of diffusion models, whether they are guided or unguided, is their slow sampling process. Recent techniques can accelerate unguided sampling by applying high-order numerical methods to the sampling process when viewed as differential equations. On the contrary, we discover that the same techniques do not work for guided sampling, and little has been explored about its acceleration. This paper explores the culprit of this problem and provides a solution based on operator splitting methods, motivated by our key finding that classical high-order numerical methods are unsuitable for the conditional function. Our proposed method can re-utilize the high-order methods for guided sampling and can generate images with the same quality as a 250-step DDIM baseline using 32-58% less sampling time on ImageNet256. We also demonstrate usage on a wide variety of conditional generation tasks, such as text-to-image generation, colorization, inpainting, and super-resolution",
    "checked": true,
    "id": "a2410521a94d5281ff63ff2c510840a0f9c03ccf",
    "semantic_title": "accelerating guided diffusion sampling with splitting numerical methods",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=Dk7QQp8jHEo": {
    "title": "Batch Multivalid Conformal Prediction",
    "volume": "poster",
    "abstract": "We develop fast distribution-free conformal prediction algorithms for obtaining multivalid coverage on exchangeable data in the batch setting. Multivalid coverage guarantees are stronger than marginal coverage guarantees in two ways: (1) They hold even conditional on group membership---that is, the target coverage level $1-\\alpha$ holds conditionally on membership in each of an arbitrary (potentially intersecting) group in a finite collection $\\mathcal{G}$ of regions in the feature space. (2) They hold even conditional on the value of the threshold used to produce the prediction set on a given example. In fact multivalid coverage guarantees hold even when conditioning on group membership and threshold value simultaneously. We give two algorithms: both take as input an arbitrary non-conformity score and an arbitrary collection of possibly intersecting groups $\\mathcal{G}$, and then can equip arbitrary black-box predictors with prediction sets. Our first algorithm is a direct extension of quantile regression, needs to solve only a single convex minimization problem, and produces an estimator which has group-conditional guarantees for each group in $\\mathcal{G}$. Our second algorithm is iterative, and gives the full guarantees of multivalid conformal prediction: prediction sets that are valid conditionally both on group membership and non-conformity threshold. We evaluate the performance of both of our algorithms in an extensive set of experiments",
    "checked": true,
    "id": "cbf016f8da4a5c30531af2d3f584de03e8dfd0bf",
    "semantic_title": "batch multivalid conformal prediction",
    "citation_count": 56,
    "authors": []
  },
  "https://openreview.net/forum?id=sb-IkS8DQw2": {
    "title": "Accurate Bayesian Meta-Learning by Accurate Task Posterior Inference",
    "volume": "poster",
    "abstract": "Bayesian meta-learning (BML) enables fitting expressive generative models to small datasets by incorporating inductive priors learned from a set of related tasks. The Neural Process (NP) is a prominent deep neural network-based BML architecture, which has shown remarkable results in recent years. In its standard formulation, the NP encodes epistemic uncertainty in an amortized, factorized, Gaussian variational (VI) approximation to the BML task posterior (TP), using reparametrized gradients. Prior work studies a range of architectural modifications to boost performance, such as attentive computation paths or improved context aggregation schemes, while the influence of the VI scheme remains under-explored. We aim to bridge this gap by introducing GMM-NP, a novel BML model, which builds on recent work that enables highly accurate, full-covariance Gaussian mixture (GMM) TP approximations by combining VI with natural gradients and trust regions. We show that GMM-NP yields tighter evidence lower bounds, which increases the efficiency of marginal likelihood optimization, leading to improved epistemic uncertainty estimation and accuracy. GMM-NP does not require complex architectural modifications, resulting in a powerful, yet conceptually simple BML model, which outperforms the state of the art on a range of challenging experiments, highlighting its applicability to settings where data is scarce",
    "checked": true,
    "id": "af035e972f79d4e011971b27c80d5eed5e741764",
    "semantic_title": "accurate bayesian meta-learning by accurate task posterior inference",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=wtcud6HroZr": {
    "title": "Learning to Decompose Visual Features with Latent Textual Prompts",
    "volume": "poster",
    "abstract": "Recent advances in pre-training vision-language models like CLIP have shown great potential in learning transferable visual representations. Nonetheless, for downstream inference, CLIP-like models suffer from either 1) degraded accuracy and robustness in the case of inaccurate text descriptions during retrieval-based inference (the challenge for zero-shot protocol); or 2) breaking the well-established vision-language alignment (the challenge for linear probing). To address them, we propose Decomposed Feature Prompting (DeFo). DeFo leverages a flexible number of learnable embeddings as textual input while maintaining the vision-language dual-model architecture, which enables the model to learn decomposed visual features with the help of feature-level textual prompts. We further use an additional linear layer to perform classification, allowing a scalable size of language inputs. Our empirical study shows DeFo's significance in improving the vision-language models. For example, DeFo obtains 73.2% test accuracy on ImageNet with a ResNet-50 backbone without tuning any pretrained weights of both the vision and language encoder, outperforming zero-shot CLIP by a large margin of 15.0%, and outperforming state-of-the-art vision-language prompt tuning method by 7.6%",
    "checked": true,
    "id": "25c110fa479e1e1b21de703ad310ca75f4132102",
    "semantic_title": "learning to decompose visual features with latent textual prompts",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=XrMWUuEevr": {
    "title": "Context-enriched molecule representations improve few-shot drug discovery",
    "volume": "poster",
    "abstract": "A central task in computational drug discovery is to construct models from known active molecules to find further promising molecules for subsequent screening. However, typically only very few active molecules are known. Therefore, few-shot learning methods have the potential to improve the effectiveness of this critical phase of the drug discovery process. We introduce a new method for few-shot drug discovery. Its main idea is to enrich a molecule representation by knowledge about known context or reference molecules. Our novel concept for molecule representation enrichment is to associate molecules from both the support set and the query set with a large set of reference (context) molecules through a modern Hopfield network. Intuitively, this enrichment step is analogous to a human expert who would associate a given molecule with familiar molecules whose properties are known. The enrichment step reinforces and amplifies the covariance structure of the data, while simultaneously removing spurious correlations arising from the decoration of molecules. Our approach is compared with other few-shot methods for drug discovery on the FS-Mol benchmark dataset. On FS-Mol, our approach outperforms all compared methods and therefore sets a new state-of-the art for few-shot learning in drug discovery. An ablation study shows that the enrichment step of our method is the key to improve the predictive quality. In a domain shift experiment, we further demonstrate the robustness of our method",
    "checked": true,
    "id": "fe2274ab4ea7cf20214fe2f1b89168f966094a4e",
    "semantic_title": "context-enriched molecule representations improve few-shot drug discovery",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=EzLtB4M1SbM": {
    "title": "Test-Time Adaptation via Self-Training with Nearest Neighbor Information",
    "volume": "poster",
    "abstract": "Test-time adaptation (TTA) aims to adapt a trained classifier using online unlabeled test data only, without any information related to the training procedure. Most existing TTA methods adapt the trained classifier using the classifier's prediction on the test data as pseudo-label. However, under test-time domain shift, accuracy of the pseudo labels cannot be guaranteed, and thus the TTA methods often encounter performance degradation at the adapted classifier. To overcome this limitation, we propose a novel test-time adaptation method, called Test-time Adaptation via Self-Training with nearest neighbor information (TAST), which is composed of the following procedures: (1) adds trainable adaptation modules on top of the trained feature extractor; (2) newly defines a pseudo-label distribution for the test data by using the nearest neighbor information; (3) trains these modules only a few times during test time to match the nearest neighbor-based pseudo label distribution and a prototype-based class distribution for the test data; and (4) predicts the label of test data using the average predicted class distribution from these modules. The pseudo-label generation is based on the basic intuition that a test data and its nearest neighbor in the embedding space are likely to share the same label under the domain shift. By utilizing multiple randomly initialized adaptation modules, TAST extracts useful information for the classification of the test data under the domain shift, using the nearest neighbor information. TAST showed better performance than the state-of-the-art TTA methods on two standard benchmark tasks, domain generalization, namely VLCS, PACS, OfficeHome, and TerraIncognita, and image corruption, particularly CIFAR-10/100C",
    "checked": true,
    "id": "ec1a1e378d5b106303a4b17128119353dbd2336a",
    "semantic_title": "test-time adaptation via self-training with nearest neighbor information",
    "citation_count": 73,
    "authors": []
  },
  "https://openreview.net/forum?id=yTbNYYcopd": {
    "title": "Accurate Neural Training with 4-bit Matrix Multiplications at Standard Formats",
    "volume": "poster",
    "abstract": "Quantization of the weights and activations is one of the main methods to reduce the computational footprint of Deep Neural Networks (DNNs) training. Current methods enable 4-bit quantization of the forward phase. However, this constitutes only a third of the training process. Reducing the computational footprint of the entire training process requires the quantization of the neural gradients, i.e., the loss gradients with respect to the outputs of intermediate neural layers. Previous works separately showed that accurate 4-bit quantization of the neural gradients needs to (1) be unbiased and (2) have a log scale. However, no previous work aimed to combine both ideas, as we do in this work. Specifically, we examine the importance of having unbiased quantization in quantized neural network training, where to maintain it, and how to combine it with logarithmic quantization. Based on this, we suggest a $\\textit{logarithmic unbiased quantization}$ (LUQ) method to quantize all both the forward and backward phase to 4-bit, achieving state-of-the-art results in 4-bit training without overhead. For example, in ResNet50 on ImageNet, we achieved a degradation of 1.1 %. We further improve this to degradation of only 0.32 % after three epochs of high precision fine-tunining, combined with a variance reduction method---where both these methods add overhead comparable to previously suggested methods. A reference implementation is supplied in the supplementary material",
    "checked": true,
    "id": "693d1b61112ef52f096f2586f7fe4080bae83c99",
    "semantic_title": "accurate neural training with 4-bit matrix multiplications at standard formats",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=lUpjsrKItz4": {
    "title": "Unsupervised Manifold Alignment with Joint Multidimensional Scaling",
    "volume": "poster",
    "abstract": "We introduce Joint Multidimensional Scaling, a novel approach for unsupervised manifold alignment, which maps datasets from two different domains, without any known correspondences between data instances across the datasets, to a common low-dimensional Euclidean space. Our approach integrates Multidimensional Scaling (MDS) and Wasserstein Procrustes analysis into a joint optimization problem to simultaneously generate isometric embeddings of data and learn correspondences between instances from two different datasets, while only requiring intra-dataset pairwise dissimilarities as input. This unique characteristic makes our approach applicable to datasets without access to the input features, such as solving the inexact graph matching problem. We propose an alternating optimization scheme to solve the problem that can fully benefit from the optimization techniques for MDS and Wasserstein Procrustes. We demonstrate the effectiveness of our approach in several applications, including joint visualization of two datasets, unsupervised heterogeneous domain adaptation, graph matching, and protein structure alignment. The implementation of our work is available at https://github.com/BorgwardtLab/JointMDS",
    "checked": true,
    "id": "92ed667cdf735cb32fe6037a27584443c4a4dd3a",
    "semantic_title": "unsupervised manifold alignment with joint multidimensional scaling",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=uu1GBD9SlLe": {
    "title": "Simple and Scalable Nearest Neighbor Machine Translation",
    "volume": "poster",
    "abstract": "$k$NN-MT is a straightforward yet powerful approach for fast domain adaptation, which directly plugs the pre-trained neural machine translation (NMT) models with domain-specific token-level $k$-nearest-neighbor ($k$NN) retrieval to achieve domain adaptation without retraining. Despite being conceptually attractive, $k$NN-MT is burdened with massive storage requirements and high computational complexity since it conducts nearest neighbor searches over the entire reference corpus. In this paper, we propose a simple and scalable nearest neighbor machine translation framework to drastically promote the decoding and storage efficiency of $k$NN-based models while maintaining the translation performance. To this end, we dynamically construct a extremely small datastore for each input via sentence-level retrieval to avoid searching the entire datastore in vanilla $k$NN-MT, based on which we further introduce a distance-aware adapter to adaptively incorporate the $k$NN retrieval results into the pre-trained NMT models. Experiments on machine translation in two general settings, static domain adaptation, and online learning, demonstrate that our proposed approach not only achieves almost 90% speed as the NMT model without performance degradation, but also significantly reduces the storage requirements of $k$NN-MT",
    "checked": true,
    "id": "161956dc055a680cfe1a0bbdc22fabd9822cadc8",
    "semantic_title": "simple and scalable nearest neighbor machine translation",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=v8JIQdiN9Sh": {
    "title": "On the Effectiveness of Out-of-Distribution Data in Self-Supervised Long-Tail Learning",
    "volume": "poster",
    "abstract": "Though Self-supervised learning (SSL) has been widely studied as a promising technique for representation learning, it doesn't generalize well on long-tailed datasets due to the majority classes dominating the feature space. Recent work shows that the long-tailed learning performance could be boosted by sampling extra in-domain (ID) data for self-supervised training, however, large-scale ID data which can rebalance the minority classes are expensive to collect. In this paper, we propose an alternative but easy-to-use and effective solution, \\textbf{C}ontrastive with \\textbf{O}ut-of-distribution (OOD) data for \\textbf{L}ong-\\textbf{T}ail learning (COLT), which can effectively exploit OOD data to dynamically re-balance the feature space. We empirically identify the counter-intuitive usefulness of OOD samples in SSL long-tailed learning and principally design a novel SSL method. Concretely, we first localize the `\\emph{head}' and `\\emph{tail}' samples by assigning a tailness score to each OOD sample based on its neighborhoods in the feature space. Then, we propose an online OOD sampling strategy to dynamically re-balance the feature space. Finally, we enforce the model to be capable of distinguishing ID and OOD samples by a distribution-level supervised contrastive loss. Extensive experiments are conducted on various datasets and several state-of-the-art SSL frameworks to verify the effectiveness of the proposed method. The results show that our method significantly improves the performance of SSL on long-tailed datasets by a large margin, and even outperforms previous work which uses external ID data. Our code is available at \\url{https://github.com/JianhongBai/COLT}",
    "checked": true,
    "id": "48790c048f0b982e290e932eb320e0e1f544b641",
    "semantic_title": "on the effectiveness of out-of-distribution data in self-supervised long-tail learning",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=ZIkHSXzd9O7": {
    "title": "Dynamic Update-to-Data Ratio: Minimizing World Model Overfitting",
    "volume": "poster",
    "abstract": "Early stopping based on the validation set performance is a popular approach to find the right balance between under- and overfitting in the context of supervised learning. However, in reinforcement learning, even for supervised sub-problems such as world model learning, early stopping is not applicable as the dataset is continually evolving. As a solution, we propose a new general method that dynamically adjusts the update to data (UTD) ratio during training based on under- and overfitting detection on a small subset of the continuously collected experience not used for training. We apply our method to DreamerV2, a state-of-the-art model-based reinforcement learning algorithm, and evaluate it on the DeepMind Control Suite and the Atari 100k benchmark. The results demonstrate that one can better balance under- and overestimation by adjusting the UTD ratio with our approach compared to the default setting in DreamerV2 and that it is competitive with an extensive hyperparameter search which is not feasible for many applications. Our method eliminates the need to set the UTD hyperparameter by hand and even leads to a higher robustness with regard to other learning-related hyperparameters further reducing the amount of necessary tuning",
    "checked": true,
    "id": "60442e29e359186c6b3009ba16cb1627fe9a6672",
    "semantic_title": "dynamic update-to-data ratio: minimizing world model overfitting",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=6K2RM6wVqKu": {
    "title": "Uni-Mol: A Universal 3D Molecular Representation Learning Framework",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "11f42721f56f36a64638677ccde7784040829656",
    "semantic_title": "uni-mol: a universal 3d molecular representation learning framework",
    "citation_count": 372,
    "authors": []
  },
  "https://openreview.net/forum?id=YgC62m4CY3r": {
    "title": "Learning with Auxiliary Activation for Memory-Efficient Training",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "33c61fcec57f5b412439e5a882b1a2a1e8a1de5a",
    "semantic_title": "learning with auxiliary activation for memory-efficient training",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=sIoED-yPK9l": {
    "title": "Massively Scaling Heteroscedastic Classifiers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "dc13f0e91cc31bab2092e2a4017fb9841c5e42df",
    "semantic_title": "massively scaling heteroscedastic classifiers",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=2nocgE1m0A": {
    "title": "KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Low-Resource NLP",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e852c5ed7f4f1a4375f0f3bce1b4e445c7684e7e",
    "semantic_title": "knowda: all-in-one knowledge mixture model for data augmentation in low-resource nlp",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=9ImtNIZ7bYx": {
    "title": "Finding the Global Semantic Representation in GAN through Fréchet Mean",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "9534ee7d40043ead143246503cd9d9e175b4fc25",
    "semantic_title": "finding the global semantic representation in gan through frechet mean",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=i2_TvOFmEml": {
    "title": "MultiViz: Towards Visualizing and Understanding Multimodal Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d0d9158f9a2096a01430799e23b90ebc8c1176b2",
    "semantic_title": "multiviz: towards visualizing and understanding multimodal models",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=sKHqgFOaFXI": {
    "title": "How Informative is the Approximation Error from Tensor Decomposition for Neural Network Compression?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "32fbe8a97c77ee90e4cdfe9e78b13dc4c7f9c923",
    "semantic_title": "how informative is the approximation error from tensor decomposition for neural network compression?",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=OjDkC57x5sz": {
    "title": "Blurring Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0250e08e4edef6e05c175f1ffd689d9f2965bb43",
    "semantic_title": "blurring diffusion models",
    "citation_count": 88,
    "authors": []
  },
  "https://openreview.net/forum?id=3Bh6sRPKS3J": {
    "title": "Hyperbolic Self-paced Learning for Self-supervised Skeleton-based Action Representations",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f0a1ed3aad34420e799b32b5e420b71b8f753c56",
    "semantic_title": "hyperbolic self-paced learning for self-supervised skeleton-based action representations",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=Yt-yM-JbYFO": {
    "title": "Efficient Offline Policy Optimization with a Learned Model",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4823d4dcf5a293f50be4f237b6621514b407f272",
    "semantic_title": "efficient offline policy optimization with a learned model",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=fxC7kJYwA_a": {
    "title": "New Insights for the Stability-Plasticity Dilemma in Online Continual Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9ae53b9875a6d26c26d156b04705d61d85ed083f",
    "semantic_title": "new insights for the stability-plasticity dilemma in online continual learning",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=dRjWsd3gwsm": {
    "title": "MixPro: Data Augmentation with MaskMix and Progressive Attention Labeling for Vision Transformer",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bc99c855d52ba3d432c428fb4096b3a22c04f8bf",
    "semantic_title": "mixpro: data augmentation with maskmix and progressive attention labeling for vision transformer",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=Ojpb1y8jflw": {
    "title": "StyleMorph: Disentangled 3D-Aware Image Synthesis with a 3D Morphable StyleGAN",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7a0f785f1d1e252caeff3efbce7576d94579ec7d",
    "semantic_title": "stylemorph: disentangled 3d-aware image synthesis with a 3d morphable stylegan",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Dvs-a3aymPe": {
    "title": "Searching Lottery Tickets in Graph Neural Networks: A Dual Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f87ab24bca90dc062b7ba73dc355a41625c0652a",
    "semantic_title": "searching lottery tickets in graph neural networks: a dual perspective",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=KLrGlNoxzb4": {
    "title": "Video Scene Graph Generation from Single-Frame Weak Supervision",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4717da5971b2b6785a56f00337425f8f28f98621",
    "semantic_title": "video scene graph generation from single-frame weak supervision",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=nI2HmVA0hvt": {
    "title": "Unsupervised visualization of image datasets using contrastive learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b7458825ffec74d76e6739389ca515e4c2022d43",
    "semantic_title": "unsupervised visualization of image datasets using contrastive learning",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=s1KljJpAukm": {
    "title": "PowerQuant: Automorphism Search for Non-Uniform Quantization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "078ef926a9cdcea3f33abcd057d02d1194a8a97f",
    "semantic_title": "powerquant: automorphism search for non-uniform quantization",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=Bd7GueaTxUz": {
    "title": "BAYES RISK CTC: CONTROLLABLE CTC ALIGNMENT IN SEQUENCE-TO-SEQUENCE TASKS",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f66e606c3924efab07b5729b11ffed75771a9f7e",
    "semantic_title": "bayes risk ctc: controllable ctc alignment in sequence-to-sequence tasks",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=0jxPyVWmiiF": {
    "title": "A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein in Graph Data",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bc2db6f6483118408c620f02c800e2f006fc165d",
    "semantic_title": "a convergent single-loop algorithm for relaxation of gromov-wasserstein in graph data",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=zOHQGKO3WGY": {
    "title": "Semi-supervised learning with a principled likelihood from a generative model of data curation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "058bb31e2ebaf5fec47b6c341b911387ecd16a38",
    "semantic_title": "semi-supervised learning with a principled likelihood from a generative model of data curation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=sO1QiAftQFv": {
    "title": "E3Bind: An End-to-End Equivariant Network for Protein-Ligand Docking",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9946caf3a8a381f880fe6452c960429ebe8b1440",
    "semantic_title": "e3bind: an end-to-end equivariant network for protein-ligand docking",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=Q-WfHzmiG9m": {
    "title": "Re-weighting Based Group Fairness Regularization via Classwise Robust Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "eb776076b4653f45a399e0afef781919d94b0578",
    "semantic_title": "re-weighting based group fairness regularization via classwise robust optimization",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=uagC-X9XMi8": {
    "title": "Are More Layers Beneficial to Graph Transformers?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ef8e70f781780b2d129287adf4db536e4a2f068b",
    "semantic_title": "are more layers beneficial to graph transformers?",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=_QLsH8gatwx": {
    "title": "Simplicial Hopfield networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ca04700240c273a4ca237607ef5a1cbf9163fa16",
    "semantic_title": "simplicial hopfield networks",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=2nLeOOfAjK": {
    "title": "Versatile Neural Processes for Learning Implicit Neural Representations",
    "volume": "poster",
    "abstract": "Representing a signal as a continuous function parameterized by neural network (a.k.a. Implicit Neural Representations, INRs) has attracted increasing attention in recent years. Neural Processes (NPs), which model the distributions over functions conditioned on partial observations (context set), provide a practical solution for fast inference of continuous functions. However, existing NP architectures suffer from inferior modeling capability for complex signals. In this paper, we propose an efficient NP framework dubbed Versatile Neural Processes (VNP), which largely increases the capability of approximating functions. Specifically, we introduce a bottleneck encoder that produces fewer and informative context tokens, relieving the high computational cost while providing high modeling capability. At the decoder side, we hierarchically learn multiple global latent variables that jointly model the global structure and the uncertainty of a function, enabling our model to capture the distribution of complex signals. We demonstrate the effectiveness of the proposed VNP on a variety of tasks involving 1D, 2D and 3D signals. Particularly, our method shows promise in learning accurate INRs w.r.t. a 3D scene without further finetuning",
    "checked": true,
    "id": "29761d4b33ad1443c008f4950ae96c3ea26152b0",
    "semantic_title": "versatile neural processes for learning implicit neural representations",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=ymFhZxw70uz": {
    "title": "Classically Approximating Variational Quantum Machine Learning with Random Fourier Features",
    "volume": "poster",
    "abstract": "Many applications of quantum computing in the near term rely on variational quantum circuits (VQCs). They have been showcased as a promising model for reaching a quantum advantage in machine learning with current noisy intermediate scale quantum computers (NISQ). It is often believed that the power of VQCs relies on their exponentially large feature space, and extensive works have explored the expressiveness and trainability of VQCs in that regard. In our work, we propose a classical sampling method that can closely approximate most VQCs with Hamiltonian encoding, given only the description of their architecture. It uses the seminal proposal of Random Fourier Features (RFF) and the fact that VQCs can be seen as large Fourier series. We show theoretically and experimentally that models built from exponentially large quantum feature space can be classically reproduced by sampling a few frequencies to build an equivalent low dimensional kernel. Precisely, we show that the number of required samples grows favourably with the size of the quantum spectrum. This tool therefore questions the hope for quantum advantage from VQCs in many cases, but conversely helps to narrow the conditions for their potential success. We expect VQCs with various and complex encoding Hamiltonians, or with large input dimension, to become more robust to classical approximations",
    "checked": true,
    "id": "0d4a5161b6ac6d19f473d67e63050a15b5eb70f7",
    "semantic_title": "classically approximating variational quantum machine learning with random fourier features",
    "citation_count": 50,
    "authors": []
  },
  "https://openreview.net/forum?id=LGkmUauBUL": {
    "title": "Distributional Meta-Gradient Reinforcement Learning",
    "volume": "poster",
    "abstract": "Meta-gradient reinforcement learning (RL) algorithms have substantially boosted the performance of RL agents by learning an adaptive return. All the existing algorithms adhere to the same reward learning principle, where the adaptive return is simply formulated in the form of expected cumulative rewards, upon which the policy and critic update rules are specified under well-adopted distance metrics. In this paper, we present a novel algorithm that builds on the success of meta-gradient RL algorithms and effectively improves such algorithms by following a simple recipe, i.e., going beyond the expected return to formulate and learn the return in a more expressive form, value distributions. To this end, we first formulate a distributional return that could effectively capture bootstrapping and discounting behaviors over distributions, to form an informative distributional return target in value update. Then we derive an efficient meta update rule to learn the adaptive distributional return with meta-gradients. For empirical evaluation, we first present an illustrative example on a toy two-color grid-world domain, which validates the benefit of learning distributional return over expectation; then we conduct extensive comparisons on a large-scale RL benchmark Atari 2600, where we confirm that our proposed method with distributional return works seamlessly well with the actor-critic framework and leads to state-of-the-art median human normalized score among meta-gradient RL literature",
    "checked": true,
    "id": "914fe22dcbbb82c973aff31370c8f0d762661838",
    "semantic_title": "distributional meta-gradient reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=lRdhvzMpVYV": {
    "title": "A Differential Geometric View and Explainability of GNN on Evolving Graphs",
    "volume": "poster",
    "abstract": "Graphs are ubiquitous in social networks and biochemistry, where Graph Neural Networks (GNN) are the state-of-the-art models for prediction. Graphs can be evolving and it is vital to formally model and understand how a trained GNN responds to graph evolution. We propose a smooth parameterization of the GNN predicted distributions using axiomatic attribution, where the distributions are on a low dimensional manifold within a high-dimensional embedding space. We exploit the differential geometric viewpoint to model distributional evolution as smooth curves on the manifold. We reparameterize families of curves on the manifold and design a convex optimization problem to find a unique curve that concisely approximates the distributional evolution for human interpretation. Extensive experiments on node classification, link prediction, and graph classification tasks with evolving graphs demonstrate the better sparsity, faithfulness, and intuitiveness of the proposed method over the state-of-the-art methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7L2mgi0TNEP": {
    "title": "$\\rm A^2Q$: Aggregation-Aware Quantization for Graph Neural Networks",
    "volume": "poster",
    "abstract": "As graph data size increases, the vast latency and memory consumption during inference pose a significant challenge to the real-world deployment of Graph Neural Networks (GNNs). While quantization is a powerful approach to reducing GNNs complexity, most previous works on GNNs quantization fail to exploit the unique characteristics of GNNs, suffering from severe accuracy degradation. Through an in-depth analysis of the topology of GNNs, we observe that the topology of the graph leads to significant differences between nodes, and most of the nodes in a graph appear to have a small aggregation value. Motivated by this, in this paper, we propose the Aggregation-Aware mixed-precision Quantization ($\\rm A^2Q$) for GNNs, where an appropriate bitwidth is automatically learned and assigned to each node in the graph. To mitigate the vanishing gradient problem caused by sparse connections between nodes, we propose a Local Gradient method to serve the quantization error of the node features as the supervision during training. We also develop a Nearest Neighbor Strategy to deal with the generalization on unseen graphs. Extensive experiments on eight public node-level and graph-level datasets demonstrate the generality and robustness of our proposed method. Compared to the FP32 models, our method can achieve up to $18.8\\times$ (i.e., 1.70bits) compression ratio with negligible accuracy degradation. Moreover, compared to the state-of-the-art quantization method, our method can achieve up to $11.4\\%$ and $9.5\\%$ accuracy improvements on the node-level and graph-level tasks, respectively, and up to $2\\times$ speedup on a dedicated hardware accelerator",
    "checked": false,
    "id": "a608961f5060c81dd88e31c71921c69d66541d49",
    "semantic_title": "a2q: aggregation-aware quantization for graph neural networks",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=pfuqQQCB34": {
    "title": "Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker Assumptions and Communication Compression as a Cherry on the Top",
    "volume": "poster",
    "abstract": "Byzantine-robustness has been gaining a lot of attention due to the growth of the interest in collaborative and federated learning. However, many fruitful directions, such as the usage of variance reduction for achieving robustness and communication compression for reducing communication costs, remain weakly explored in the field. This work addresses this gap and proposes Byz-VR-MARINA -- a new Byzantine-tolerant method with variance reduction and compression. A key message of our paper is that variance reduction is key to fighting Byzantine workers more effectively. At the same time, communication compression is a bonus that makes the process more communication efficient. We derive theoretical convergence guarantees for Byz-VR-MARINA outperforming previous state-of-the-art for general non-convex and Polyak-Lojasiewicz loss functions. Unlike the concurrent Byzantine-robust methods with variance reduction and/or compression, our complexity results are tight and do not rely on restrictive assumptions such as boundedness of the gradients or limited compression. Moreover, we provide the first analysis of a Byzantine-tolerant method supporting non-uniform sampling of stochastic gradients. Numerical experiments corroborate our theoretical findings",
    "checked": true,
    "id": "f60e6bac323949e3239537d9d83224a98d3705d5",
    "semantic_title": "variance reduction is an antidote to byzantines: better rates, weaker assumptions and communication compression as a cherry on the top",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=Nk2pDtuhTq": {
    "title": "Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning",
    "volume": "poster",
    "abstract": "Prompt tuning, in which a base pretrained model is adapted to each task via conditioning on learned prompt vectors, has emerged as a promising approach for efficiently adapting large language models to multiple downstream tasks. However, existing methods typically learn soft prompt vectors from scratch, and it has not been clear how to exploit the rich cross-task knowledge with prompt vectors in a multitask learning setting. We propose multitask prompt tuning (MPT), which first learns a single transferable prompt by distilling knowledge from multiple task-specific source prompts. We then learn multiplicative low rank updates to this shared prompt to efficiently adapt it to each downstream target task. Extensive experiments on 23 NLP datasets demonstrate that our proposed approach outperforms the state-of-the-art methods, including the full finetuning baseline in some cases, despite only tuning $0.035\\%$ as many task-specific parameters",
    "checked": true,
    "id": "8b32aa33601514976d88fabcb060a5cd38d34006",
    "semantic_title": "multitask prompt tuning enables parameter-efficient transfer learning",
    "citation_count": 135,
    "authors": []
  },
  "https://openreview.net/forum?id=cRxYWKiTan": {
    "title": "Better Generative Replay for Continual Federated Learning",
    "volume": "poster",
    "abstract": "Federated Learning (FL) aims to develop a centralized server that learns from distributed clients via communications without accessing the clients' local data. However, existing works mainly focus on federated learning in a single task sce- nario with static data. In this paper, we introduce the continual federated learning (CFL) problem, where clients incrementally learn new tasks and history data can- not be stored due to certain reasons, such as limited storage and data retention policy 1. Generative replay (GR) based methods are effective for continual learning without storing history data. However, we fail when trying to intuitively adapt GR models for this setting. By analyzing the behaviors of clients during training, we find the unstable training process caused by distributed training on non-IID data leads to a notable performance degradation. To address this problem, we propose our FedCIL model with two simple but effective solutions: 1. model consolidation and 2. consistency enforcement. Experimental results on multiple benchmark datasets demonstrate that our method significantly outperforms baselines. Code is available at: https://github.com/daiqing98/FedCIL",
    "checked": true,
    "id": "27c286bbc692805d68bd168f992498d157e49e0b",
    "semantic_title": "better generative replay for continual federated learning",
    "citation_count": 64,
    "authors": []
  },
  "https://openreview.net/forum?id=4PJUBT9f2Ol": {
    "title": "Generative Modelling with Inverse Heat Dissipation",
    "volume": "poster",
    "abstract": "While diffusion models have shown great success in image generation, their noise-inverting generative process does not explicitly consider the structure of images, such as their inherent multi-scale nature. Inspired by diffusion models and the empirical success of coarse-to-fine modelling, we propose a new diffusion-like model that generates images through stochastically reversing the heat equation, a PDE that locally erases fine-scale information when run over the 2D plane of the image. We interpret the solution of the forward heat equation with constant additive noise as a variational approximation in the diffusion latent variable model. Our new model shows emergent qualitative properties not seen in standard diffusion models, such as disentanglement of overall colour and shape in images. Spectral analysis on natural images highlights connections to diffusion models and reveals an implicit coarse-to-fine inductive bias in them",
    "checked": true,
    "id": "9933e54773afff557fd8f498ebca7da8327f4224",
    "semantic_title": "generative modelling with inverse heat dissipation",
    "citation_count": 134,
    "authors": []
  },
  "https://openreview.net/forum?id=Ubc74gTVo3": {
    "title": "Self-supervision through Random Segments with Autoregressive Coding (RandSAC)",
    "volume": "poster",
    "abstract": "Inspired by the success of self-supervised autoregressive representation learning in natural language (GPT and its variants), and advances in recent visual architecture design with Vision Transformers (ViTs), in this paper, we explore the effects various design choices have on the success of applying such training strategies for visual feature learning. Specifically, we introduce a novel strategy that we call Random Segments with Autoregressive Coding (RandSAC). In RandSAC, we group patch representations (image tokens) into hierarchically arranged segments; within each segment, tokens are predicted in parallel, similar to BERT, while across segment predictions are sequential, similar to GPT. We illustrate that randomized serialization of the segments significantly improves the performance and results in distribution over spatially-long (across-segments) and -short (within-segment) predictions which are effective for feature learning. We illustrate the pertinence of these design choices and explore alternatives on a number of datasets (e.g., CIFAR10, ImageNet). While our pre-training strategy works with vanilla Transformer, we also propose a conceptually simple, but highly effective, addition to the decoder that allows learnable skip-connections to encoder feature layers, which further improves the performance",
    "checked": true,
    "id": "52266a1017644f468285b01598270e7474ca9f84",
    "semantic_title": "self-supervision through random segments with autoregressive coding (randsac)",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=4oYUGeGBPm": {
    "title": "Transformer-Patcher: One Mistake Worth One Neuron",
    "volume": "poster",
    "abstract": "Large Transformer-based Pretrained Language Models (PLMs) dominate almost all Natural Language Processing (NLP) tasks. Nevertheless, they still make mistakes from time to time. For a model deployed in an industrial environment, fixing these mistakes quickly and robustly is vital to improve user experiences. Previous works formalize such problems as Model Editing (ME) and mostly focus on fixing one mistake. However, the one-mistake-fixing scenario is not an accurate abstraction of the real-world challenge. In the deployment of AI services, there are ever-emerging mistakes, and the same mistake may recur if not corrected in time. Thus a preferable solution is to rectify the mistakes as soon as they appear nonstop. Therefore, we extend the existing ME into the Sequential Model Editing (SME) to help develop more practical editing methods. Our study shows that current ME methods either fail to make a sequence of edits or to remember previous edits. We then introduce Transformer-Patcher, a novel model editor that can shift the behavior of transformer-based models by simply adding and training a few neurons in the last Feed-Forward Network layer. Experimental results on both classification and generation tasks show that Transformer-Patcher can successively correct up to thousands of errors (Reliability) and generalize to their equivalent inputs (Generality) while retaining the model's accuracy on irrelevant inputs (Locality). Our method outperforms previous fine-tuning and HyperNetwork-based methods and achieves state-of-the-art performance for Sequential Model Editing (SME)",
    "checked": true,
    "id": "a9be51698e7c2247853b7b6f1f70fc4d6d7ef605",
    "semantic_title": "transformer-patcher: one mistake worth one neuron",
    "citation_count": 193,
    "authors": []
  },
  "https://openreview.net/forum?id=8E5Yazboyh": {
    "title": "Sharper Bounds for Uniformly Stable Algorithms with Stationary Mixing Process",
    "volume": "poster",
    "abstract": "Generalization analysis of learning algorithms often builds on a critical assumption that training examples are independently and identically distributed, which is often violated in practical problems such as time series prediction. In this paper, we use algorithmic stability to study the generalization performance of learning algorithms with $\\psi$-mixing data, where the dependency between observations weakens over time. We show uniformly stable algorithms guarantee high-probability generalization bounds of the order $O(1/\\sqrt{n})$ (within a logarithmic factor), where $n$ is the sample size. We apply our general result to specific algorithms including regularization schemes, stochastic gradient descent and localized iterative regularization, and develop excess population risk bounds for learning with $\\psi$-mixing data. Our analysis builds on a novel moment bound for weakly-dependent random variables on a $\\varphi$-mixing sequence and a novel error decomposition of generalization error",
    "checked": true,
    "id": "edd21525d02b5f3bd9464f069f8ab0e99244cf77",
    "semantic_title": "sharper bounds for uniformly stable algorithms with stationary mixing process",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=UrEwJebCxk": {
    "title": "Benign Overfitting in Classification: Provably Counter Label Noise with Larger Models",
    "volume": "poster",
    "abstract": "Studies on benign overfitting provide insights for the success of overparameterized deep learning models. In this work, we examine whether overfitting is truly benign in real-world classification tasks. We start with the observation that a ResNet model overfits benignly on Cifar10 but not benignly on ImageNet. To understand why benign overfitting fails in the ImageNet experiment, we theoretically analyze benign overfitting under a more restrictive setup where the number of parameters is not significantly larger than the number of data points. Under this mild overparameterization setup, our analysis identifies a phase change: unlike in the previous heavy overparameterization settings, benign overfitting can now fail in the presence of label noise. Our analysis explains our empirical observations, and is validated by a set of control experiments with ResNets. Our work highlights the importance of understanding implicit bias in underfitting regimes as a future direction",
    "checked": true,
    "id": "098669d74f7a84b711718dccef7070052f22ca65",
    "semantic_title": "benign overfitting in classification: provably counter label noise with larger models",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=0uRm1YmFTu": {
    "title": "Predictive Inference with Feature Conformal Prediction",
    "volume": "poster",
    "abstract": "Conformal prediction is a distribution-free technique for establishing valid prediction intervals. Although conventionally people conduct conformal prediction in the output space, this is not the only possibility. In this paper, we propose feature conformal prediction, which extends the scope of conformal prediction to semantic feature spaces by leveraging the inductive bias of deep representation learning. From a theoretical perspective, we demonstrate that feature conformal prediction provably outperforms regular conformal prediction under mild assumptions. Our approach could be combined with not only vanilla conformal prediction, but also other adaptive conformal prediction methods. Apart from experiments on existing predictive inference benchmarks, we also demonstrate the state-of-the-art performance of the proposed methods on \\textit{large-scale} tasks such as ImageNet classification and Cityscapes image segmentation",
    "checked": true,
    "id": "e4b5ea8c1c0bdd1a34b7f136fc296a523896aa98",
    "semantic_title": "predictive inference with feature conformal prediction",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=ivwZO-HnzG_": {
    "title": "Recon: Reducing Conflicting Gradients From the Root For Multi-Task Learning",
    "volume": "poster",
    "abstract": "A fundamental challenge for multi-task learning is that different tasks may conflict with each other when they are solved jointly, and a cause of this phenomenon is conflicting gradients during optimization. Recent works attempt to mitigate the influence of conflicting gradients by directly altering the gradients based on some criteria. However, our empirical study shows that ``gradient surgery'' cannot effectively reduce the occurrence of conflicting gradients. In this paper, we take a different approach to reduce conflicting gradients from the root. In essence, we investigate the task gradients w.r.t. each shared network layer, select the layers with high conflict scores, and turn them to task-specific layers. Our experiments show that such a simple approach can greatly reduce the occurrence of conflicting gradients in the remaining shared layers and achieve better performance, with only a slight increase in model parameters in many cases. Our approach can be easily applied to improve various state-of-the-art methods including gradient manipulation methods and branched architecture search methods. Given a network architecture (e.g., ResNet18), it only needs to search for the conflict layers once, and the network can be modified to be used with different methods on the same or even different datasets to gain performance improvement. The source code is available at https://github.com/moukamisama/Recon",
    "checked": true,
    "id": "c339e9353a80db8a4411babd4b9eeb43be0502a8",
    "semantic_title": "recon: reducing conflicting gradients from the root for multi-task learning",
    "citation_count": 47,
    "authors": []
  },
  "https://openreview.net/forum?id=g2oB_k-18b": {
    "title": "Measure the Predictive Heterogeneity",
    "volume": "poster",
    "abstract": "As an intrinsic and fundamental property of big data, data heterogeneity exists in a variety of real-world applications, such as in agriculture, sociology, health care, etc. For machine learning algorithms, the ignorance of data heterogeneity will significantly hurt the generalization performance and the algorithmic fairness, since the prediction mechanisms among different sub-populations are likely to differ. In this work, we focus on the data heterogeneity that affects the prediction of machine learning models, and first formalize the Predictive Heterogeneity, which takes into account the model capacity and computational constraints. We prove that it can be reliably estimated from finite data with PAC bounds even in high dimensions. Additionally, we propose the Information Maximization (IM) algorithm, a bi-level optimization algorithm, to explore the predictive heterogeneity of data. Empirically, the explored predictive heterogeneity provides insights for sub-population divisions in agriculture, sociology, and object recognition, and leveraging such heterogeneity benefits the out-of-distribution generalization performance",
    "checked": true,
    "id": "d48e7c0382635599b43676092c2b5b94466e3786",
    "semantic_title": "measure the predictive heterogeneity",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=o8xdgmwCP8l": {
    "title": "Time to augment self-supervised visual representation learning",
    "volume": "poster",
    "abstract": "Biological vision systems are unparalleled in their ability to learn visual representations without supervision. In machine learning, self-supervised learning (SSL) has led to major advances in forming object representations in an unsupervised fashion. Such systems learn representations invariant to augmentation operations over images, like cropping or flipping. In contrast, biological vision systems exploit the temporal structure of the visual experience during natural interactions with objects. This gives access to \"augmentations\" not commonly used in SSL, like watching the same object from multiple viewpoints or against different backgrounds. Here, we systematically investigate and compare the potential benefits of such time-based augmentations during natural interactions for learning object categories. Our results show that incorporating time-based augmentations achieves large performance gains over state-of-the-art image augmentations. Specifically, our analyses reveal that: 1) 3-D object manipulations drastically improve the learning of object categories; 2) viewing objects against changing backgrounds is important for learning to discard background-related information from the latent representation. Overall, we conclude that time-based augmentations during natural interactions with objects can substantially improve self-supervised learning, narrowing the gap between artificial and biological vision systems",
    "checked": true,
    "id": "7f42442bd5395acadfadd6155c45ff94670832ca",
    "semantic_title": "time to augment self-supervised visual representation learning",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=-vKlt84fHs": {
    "title": "Towards Lightweight, Model-Agnostic and Diversity-Aware Active Anomaly Detection",
    "volume": "poster",
    "abstract": "Active Anomaly Discovery (AAD) is flourishing in the anomaly detection research area, which aims to incorporate analysts' feedback into unsupervised anomaly detectors. However, existing AAD approaches usually prioritize the samples with the highest anomaly scores for user labeling, which hinders the exploration of anomalies that were initially ranked lower. Besides, most existing AAD approaches are specially tailored for a certain unsupervised detector, making it difficult to extend to other detection models. To tackle these problems, we propose a lightweight, model-agnostic and diversity-aware AAD method, named LMADA. In LMADA, we design a diversity-aware sample selector powered by Determinantal Point Process (DPP). It considers the diversity of samples in addition to their anomaly scores for feedback querying. Furthermore, we propose a model-agnostic tuner. It approximates diverse unsupervised detectors with a unified proxy model, based on which the feedback information is incorporated by a lightweight non-linear representation adjuster. Through extensive experiments on 8 public datasets, LMADA achieved 74% F1-Score improvement on average, outperforming other comparative AAD approaches. Besides, LMADA can also achieve significant performance boosting under any unsupervised detectors",
    "checked": true,
    "id": "fec536a3aeb844aabcca6facd2cb66478e3f641e",
    "semantic_title": "towards lightweight, model-agnostic and diversity-aware active anomaly detection",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=AwWaBXLIJE": {
    "title": "Q-Pensieve: Boosting Sample Efficiency of Multi-Objective RL Through Memory Sharing of Q-Snapshots",
    "volume": "poster",
    "abstract": "Many real-world continuous control problems are in the dilemma of weighing the pros and cons, multi-objective reinforcement learning (MORL) serves as a generic framework of learning control policies for different preferences over objectives. However, the existing MORL methods either rely on multiple passes of explicit search for finding the Pareto front and therefore are not sample-efficient, or utilizes a shared policy network for coarse knowledge sharing among policies. To boost the sample efficiency of MORL, we propose $Q$-Pensieve, a policy improvement scheme that stores a collection of $Q$-snapshots to jointly determine the policy update direction and thereby enables data sharing at the policy level. We show that $Q$-Pensieve can be naturally integrated with soft policy iteration with convergence guarantee. To substantiate this concept, we propose the technique of $Q$ replay buffer, which stores the learned $Q$-networks from the past iterations, and arrive at a practical actor-critic implementation. Through extensive experiments and an ablation study, we demonstrate that with much fewer samples, the proposed algorithm can outperform the benchmark MORL methods on a variety of MORL benchmark tasks",
    "checked": true,
    "id": "a21490dc90f57362878f27d836ddc15649565407",
    "semantic_title": "q-pensieve: boosting sample efficiency of multi-objective rl through memory sharing of q-snapshots",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tkwP32nsEq": {
    "title": "Variance-Aware Sparse Linear Bandits",
    "volume": "poster",
    "abstract": "It is well-known that for sparse linear bandits, when ignoring the dependency on sparsity which is much smaller than the ambient dimension, the worst-case minimax regret is $\\widetilde{\\Theta}\\left(\\sqrt{dT}\\right)$ where $d$ is the ambient dimension and $T$ is the number of rounds. On the other hand, in the benign setting where there is no noise and the action set is the unit sphere, one can use divide-and-conquer to achieve $\\widetilde{\\mathcal O}(1)$ regret, which is (nearly) independent of $d$ and $T$. In this paper, we present the first variance-aware regret guarantee for sparse linear bandits: $\\widetilde{\\mathcal O}\\left(\\sqrt{d\\sum_{t=1}^T \\sigma_t^2} + 1\\right)$, where $\\sigma_t^2$ is the variance of the noise at the $t$-th round. This bound naturally interpolates the regret bounds for the worst-case constant-variance regime (i.e., $\\sigma_t \\equiv \\Omega(1)$) and the benign deterministic regimes (i.e., $\\sigma_t \\equiv 0$). To achieve this variance-aware regret guarantee, we develop a general framework that converts any variance-aware linear bandit algorithm to a variance-aware algorithm for sparse linear bandits in a \"black-box\" manner. Specifically, we take two recent algorithms as black boxes to illustrate that the claimed bounds indeed hold, where the first algorithm can handle unknown-variance cases and the second one is more efficient",
    "checked": true,
    "id": "a60627db07969cf74dcd436a1faa4fe30a80f2c6",
    "semantic_title": "variance-aware sparse linear bandits",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=zQWqV2tzDv": {
    "title": "CircNet: Meshing 3D Point Clouds with Circumcenter Detection",
    "volume": "poster",
    "abstract": "Reconstructing 3D point clouds into triangle meshes is a key problem in computational geometry and surface reconstruction. Point cloud triangulation solves this problem by providing edge information to the input points. Since no vertex interpolation is involved, it is beneficial to preserve sharp details on the surface. Taking advantage of learning-based techniques in triangulation, existing methods enumerate the complete combinations of candidate triangles, which is both complex and inefficient. In this paper, we leverage the duality between a triangle and its circumcenter, and introduce a deep neural network that detects the circumcenters to achieve point cloud triangulation. Specifically, we introduce multiple anchor priors to divide the neighborhood space of each point. The neural network then learns to predict the presences and locations of circumcenters under the guidance of those anchors. We extract the triangles dual to the detected circumcenters to form a primitive mesh, from which an edge-manifold mesh is produced via simple post-processing. Unlike existing learning-based triangulation methods, the proposed method bypasses an exhaustive enumeration of triangle combinations and local surface parameterization. We validate the efficiency, generalization, and robustness of our method on prominent datasets of both watertight and open surfaces. The code and trained models are provided at \\url{https://github.com/Ruitao-L/CircNet}",
    "checked": true,
    "id": "1743b5626ca1ec49baf79a9914e76894351cfe54",
    "semantic_title": "circnet: meshing 3d point clouds with circumcenter detection",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=dfDv0WU853R": {
    "title": "In-sample Actor Critic for Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "Offline reinforcement learning suffers from out-of-distribution issue and extrapolation error. Most methods penalize the out-of-distribution state-action pairs or regularize the trained policy towards the behavior policy but cannot guarantee to get rid of extrapolation error. We propose In-sample Actor Critic (IAC) which utilizes sampling-importance resampling to execute in-sample policy evaluation. IAC only uses the target Q-values of the actions in the dataset to evaluate the trained policy, thus avoiding extrapolation error. The proposed method performs unbiased policy evaluation and has a lower variance than importance sampling in many cases. Empirical results show that IAC obtains competitive performance compared to the state-of-the-art methods on Gym-MuJoCo locomotion domains and much more challenging AntMaze domains",
    "checked": true,
    "id": "00941d55a15602be3db4826c2117b3475adc79bc",
    "semantic_title": "in-sample actor critic for offline reinforcement learning",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=CGBCTp2M6lA": {
    "title": "Leveraging Future Relationship Reasoning for Vehicle Trajectory Prediction",
    "volume": "poster",
    "abstract": "Understanding the interaction between multiple agents is crucial for realistic vehicle trajectory prediction. Existing methods have attempted to infer the interaction from the observed past trajectories of agents using pooling, attention, or graph-based methods, which rely on a deterministic approach. However, these methods can fail under complex road structures, as they cannot predict various interactions that may occur in the future. In this paper, we propose a novel approach that uses lane information to predict a stochastic future relationship among agents. To obtain a coarse future motion of agents, our method first predicts the probability of lane-level waypoint occupancy of vehicles. We then utilize the temporal probability of passing adjacent lanes for each agent pair, assuming that agents passing adjacent lanes will highly interact. We also model the interaction using a probabilistic distribution, which allows for multiple possible future interactions. The distribution is learned from the posterior distribution of interaction obtained from ground truth future trajectories. We validate our method on popular trajectory prediction datasets: nuScenes and Argoverse. The results show that the proposed method brings remarkable performance gain in prediction accuracy, and achieves state-of-the-art performance in long-term prediction benchmark dataset",
    "checked": true,
    "id": "e13bd05a7de4d578fce4f905de678443009861d4",
    "semantic_title": "leveraging future relationship reasoning for vehicle trajectory prediction",
    "citation_count": 68,
    "authors": []
  },
  "https://openreview.net/forum?id=P44WPn1_aJV": {
    "title": "LMSeg: Language-guided Multi-dataset Segmentation",
    "volume": "poster",
    "abstract": "It's a meaningful and attractive topic to build a general and inclusive segmentation model that can recognize more categories in various scenarios. A straightforward way is to combine the existing fragmented segmentation datasets and train a multi-dataset network. However, there are two major issues with multi-dataset segmentation: (i) the inconsistent taxonomy demands manual reconciliation to construct a unified taxonomy; (ii) the inflexible one-hot common taxonomy causes time-consuming model retraining and defective supervision of unlabeled categories. In this paper, we investigate the multi-dataset segmentation and propose a scalable Language-guided Multi-dataset Segmentation framework, dubbed LMSeg, which supports both semantic and panoptic segmentation. Specifically, we introduce a pretrained text encoder to map the category names to a text embedding space as a unified taxonomy, instead of using inflexible one-hot label. The model dynamically aligns the segment queries with the category embeddings. Instead of relabeling each dataset with the unified taxonomy, a category-guided decoding module is designed to dynamically guide predictions to each dataset's taxonomy. Furthermore, we adopt a dataset-aware augmentation strategy that assigns each dataset a specific image augmentation pipeline, which can suit the proper- ties of images from different datasets. Extensive experiments demonstrate that our method achieves significant improvements on four segmentation datasets and three panoptic datasets, while the ablation study evaluates the effectiveness of each component",
    "checked": true,
    "id": "9a6ce0b13dbc307ee4ea4d6170a6baace88ae6ed",
    "semantic_title": "lmseg: language-guided multi-dataset segmentation",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=G1H4NSATlr": {
    "title": "RoPAWS: Robust Semi-supervised Representation Learning from Uncurated Data",
    "volume": "poster",
    "abstract": "Semi-supervised learning aims to train a model using limited labels. State-of-the-art semi-supervised methods for image classification such as PAWS rely on self-supervised representations learned with large-scale unlabeled but curated data. However, PAWS is often less effective when using real-world unlabeled data that is uncurated, e.g., contains out-of-class data. We propose RoPAWS, a robust extension of PAWS that can work with real-world unlabeled data. We first reinterpret PAWS as a generative classifier that models densities using kernel density estimation. From this probabilistic perspective, we calibrate its prediction based on the densities of labeled and unlabeled data, which leads to a simple closed-form solution from the Bayes' rule. We demonstrate that RoPAWS significantly improves PAWS for uncurated Semi-iNat by +5.3% and curated ImageNet by +0.4%",
    "checked": true,
    "id": "76f4416826b3393cf8f28ffd1a3191706d2b4286",
    "semantic_title": "ropaws: robust semi-supervised representation learning from uncurated data",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=DWn1TEb2fK": {
    "title": "Treeformer: Dense Gradient Trees for Efficient Attention Computation",
    "volume": "poster",
    "abstract": "Standard inference and training with transformer based architectures scale quadratically with input sequence length. This is prohibitively large for a variety of applications especially in web-page translation, query-answering etc. Consequently, several approaches have been developed recently to speedup attention computation by enforcing different attention structures such as sparsity, low-rank, approximating attention using kernels. In this work, we view attention computation as that of nearest neighbor retrieval, and use decision tree based hierarchical navigation to reduce the retrieval cost per query token from linear in sequence length to nearly logarithmic. Based on such hierarchical navigation, we design Treeformer which can use one of two efficient attention layers -- TF-Attention and TC-Attention. TF-Attention computes the attention in a fine-grained style, while TC-Attention is a coarse attention layer which also ensures that the gradients are \"dense\". To optimize such challenging discrete layers, we propose a two-level bootstrapped training method. Using extensive experiments on standard NLP benchmarks, especially for long-sequences, we demonstrate that our Treeformer architecture can be almost as accurate as baseline Transformer while using 30x lesser FLOPs in the attention layer. Compared to Linformer, the accuracy can be as much as 12% higher while using similar FLOPs in the attention layer",
    "checked": true,
    "id": "29587ba6dca7e713c3abf6f2d1045e4a5bf10586",
    "semantic_title": "treeformer: dense gradient trees for efficient attention computation",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=kJWcI39kXY": {
    "title": "ODAM: Gradient-based Instance-Specific Visual Explanations for Object Detection",
    "volume": "poster",
    "abstract": "We propose the Gradient-weighted Object Detector Activation Mapping (Grad-ODAM), a visualized explanation technique for interpreting the predictions of object detectors. Utilizing the gradients of detector targets flowing into the intermediate feature maps, Grad-ODAM produces heat maps that show the influence of regions on the detector's decision. Compared to previous classification activation mapping works, Grad-ODAM generates instance-specific explanations rather than class-specific ones. We show that Grad-ODAM is applicable to both one-stage detectors such as FCOS and two-stage detectors such as Faster R-CNN, and produces higher-quality visual explanations than the state-of-the-art both effectively and efficiently. We next propose a training scheme, ODAM-Train, to improve the explanation ability on object discrimination of the detector through encouraging consistency between explanations for detections on the same object, and distinct explanations for detections on different objects. Based on the heat maps produced by Grad-ODAM with ODAM-Train, we propose ODAM-NMS, which considers the information of the model's explanation for each prediction to distinguish the duplicate detected objects. We present a detailed analysis of the visualized explanations of detectors and carry out extensive experiments to validate the effectiveness of the proposed ODAM",
    "checked": true,
    "id": "f79a0f9f60dd1ff4cb631dc8aa5b825948e31ede",
    "semantic_title": "odam: gradient-based instance-specific visual explanations for object detection",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=xZD10GhCvM": {
    "title": "Toward Adversarial Training on Contextualized Language Representation",
    "volume": "poster",
    "abstract": "Beyond the success story of adversarial training (AT) in the recent text domain on top of pre-trained language models (PLMs), our empirical study showcases the inconsistent gains from AT on some tasks, e.g. commonsense reasoning, named entity recognition. This paper investigates AT from the perspective of the contextualized language representation outputted by PLM encoders. We find the current AT attacks lean to generate sub-optimal adversarial examples that can fool the decoder part but have a minor effect on the encoder. However, we find it necessary to effectively deviate the latter one to allow AT to gain. Based on the observation, we propose simple yet effective \\textit{Contextualized representation-Adversarial Training} (CreAT), in which the attack is explicitly optimized to deviate the contextualized representation of the encoder. It allows a global optimization of adversarial examples that can fool the entire model. We also find CreAT gives rise to a better direction to optimize the adversarial examples, to let them less sensitive to hyperparameters. Compared to AT, CreAT produces consistent performance gains on a wider range of tasks and is proven to be more effective for language pre-training where only the encoder part is kept for downstream tasks. We achieve the new state-of-the-art performances on a series of challenging benchmarks, e.g. AdvGLUE (59.1 $ \\rightarrow $ 61.1), HellaSWAG (93.0 $ \\rightarrow $ 94.9), ANLI (68.1 $ \\rightarrow $ 69.3)",
    "checked": true,
    "id": "443210c6e57f4a4f18ff2a357fb1f5dee3bd1a6e",
    "semantic_title": "toward adversarial training on contextualized language representation",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=sbS10BCtc7": {
    "title": "Gromov-Wasserstein Autoencoders",
    "volume": "poster",
    "abstract": "Variational Autoencoder (VAE)-based generative models offer flexible representation learning by incorporating meta-priors, general premises considered beneficial for downstream tasks. However, the incorporated meta-priors often involve ad-hoc model deviations from the original likelihood architecture, causing undesirable changes in their training. In this paper, we propose a novel representation learning method, Gromov-Wasserstein Autoencoders (GWAE), which directly matches the latent and data distributions using the variational autoencoding scheme. Instead of likelihood-based objectives, GWAE models minimize the Gromov-Wasserstein (GW) metric between the trainable prior and given data distributions. The GW metric measures the distance structure-oriented discrepancy between distributions even with different dimensionalities, which provides a direct measure between the latent and data spaces. By restricting the prior family, we can introduce meta-priors into the latent space without changing their objective. The empirical comparisons with VAE-based models show that GWAE models work in two prominent meta-priors, disentanglement and clustering, with their GW objective unchanged",
    "checked": true,
    "id": "1e73910c342a1ee470c15377ef270525a7a87e01",
    "semantic_title": "gromov-wasserstein autoencoders",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=ltWade-cpK": {
    "title": "Optimal Activation Functions for the Random Features Regression Model",
    "volume": "poster",
    "abstract": "The asymptotic mean squared test error and sensitivity of the Random Features Regression model (RFR) have been recently studied. We build on this work and identify in closed-form the family of Activation Functions (AFs) that minimize a combination of the test error and sensitivity of the RFR under different notions of functional parsimony. We find scenarios under which the optimal AFs are linear, saturated linear functions, or expressible in terms of Hermite polynomials. Finally, we show how using optimal AFs impacts well established properties of the RFR model, such as its double descent curve, and the dependency of its optimal regularization parameter on the observation noise level",
    "checked": true,
    "id": "19c275fbfe480c3f473152eaceac1f150c264542",
    "semantic_title": "optimal activation functions for the random features regression model",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=_-FN9mJsgg": {
    "title": "Improving Object-centric Learning with Query Optimization",
    "volume": "poster",
    "abstract": "The ability to decompose complex natural scenes into meaningful object-centric abstractions lies at the core of human perception and reasoning. In the recent culmination of unsupervised object-centric learning, the Slot-Attention module has played an important role with its simple yet effective design and fostered many powerful variants. These methods, however, have been exceedingly difficult to train without supervision and are ambiguous in the notion of object, especially for complex natural scenes. In this paper, we propose to address these issues by investigating the potential of learnable queries as initializations for Slot-Attention learning, uniting it with efforts from existing attempts on improving Slot-Attention learning with bi-level optimization. With simple code adjustments on Slot-Attention, our model, Bi-level Optimized Query Slot Attention, achieves state-of-the-art results on 3 challenging synthetic and 7 complex real-world datasets in unsupervised image segmentation and reconstruction, outperforming previous baselines by a large margin. We provide thorough ablative studies to validate the necessity and effectiveness of our design. Additionally, our model exhibits great potential for concept binding and zero-shot learning. Our work is made publicly available at https://bo-qsa.github.io",
    "checked": true,
    "id": "48c064a5b65eb00fd54df20ee0087a2975d0a3e3",
    "semantic_title": "improving object-centric learning with query optimization",
    "citation_count": 56,
    "authors": []
  },
  "https://openreview.net/forum?id=zH9GcZ3ZGXu": {
    "title": "Feature Reconstruction From Outputs Can Mitigate Simplicity Bias in Neural Networks",
    "volume": "poster",
    "abstract": "Deep Neural Networks are known to be brittle to even minor distribution shifts compared to the training distribution. While one line of work has demonstrated that \\emph{Simplicity Bias} (SB) of DNNs -- bias towards learning only the simplest features -- is a key reason for this brittleness, another recent line of work has surprisingly found that diverse/ complex features are indeed learned by the backbone, and their brittleness is due to the linear classification head relying primarily on the simplest features. To bridge the gap between these two lines of work, we first hypothesize and verify that while SB may not altogether preclude learning complex features, it amplifies simpler features over complex ones. Namely, simple features are replicated several times in the learned representations while complex features might not be replicated. This phenomenon, we term \\emph{Feature Replication Hypothesis}, coupled with the \\emph{Implicit Bias} of SGD to converge to maximum margin solutions in the feature space, leads the models to rely mostly on the simple features for classification. To mitigate this bias, we propose \\emph{Feature Reconstruction Regularizer (FRR)} to ensure that the learned features can be reconstructed back from the logits. The use of \\emph{FRR} in linear layer training (\\emph{FRR-L}) encourages the use of more diverse features for classification. We further propose to finetune the full network by freezing the weights of the linear layer trained using \\emph{FRR-L}, to refine the learned features, making them more suitable for classification. Using this simple solution, we demonstrate up to 15\\% gains in OOD accuracy on the recently introduced semi-synthetic datasets with extreme distribution shifts. Moreover, we demonstrate noteworthy gains over existing SOTA methods on the standard OOD benchmark DomainBed as well",
    "checked": true,
    "id": "9bdb9d9add99fc2697cda911283679580e92d9a5",
    "semantic_title": "feature reconstruction from outputs can mitigate simplicity bias in neural networks",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=xQAjSr64PTc": {
    "title": "EUCLID: Towards Efficient Unsupervised Reinforcement Learning with Multi-choice Dynamics Model",
    "volume": "poster",
    "abstract": "Unsupervised reinforcement learning (URL) poses a promising paradigm to learn useful behaviors in a task-agnostic environment without the guidance of extrinsic rewards to facilitate the fast adaptation of various downstream tasks. Previous works focused on the pre-training in a model-free manner while lacking the study of transition dynamics modeling that leaves a large space for the improvement of sample efficiency in downstream tasks. To this end, we propose an Efficient Unsupervised Reinforcement Learning Framework with Multi-choice Dynamics model (EUCLID), which introduces a novel model-fused paradigm to jointly pre-train the dynamics model and unsupervised exploration policy in the pre-training phase, thus better leveraging the environmental samples and improving the downstream task sampling efficiency. However, constructing a generalizable model which captures the local dynamics under different behaviors remains a challenging problem. We introduce the multi-choice dynamics model that covers different local dynamics under different behaviors concurrently, which uses different heads to learn the state transition under different behaviors during unsupervised pre-training and selects the most appropriate head for prediction in the downstream task. Experimental results in the manipulation and locomotion domains demonstrate that EUCLID achieves state-of-the-art performance with high sample efficiency, basically solving the state-based URLB benchmark and reaching a mean normalized score of 104.0±1.2% in downstream tasks with 100k fine-tuning steps, which is equivalent to DDPG's performance at 2M interactive steps with 20× more data. More visualization videos are released on our homepage",
    "checked": true,
    "id": "8cb359a03b499319c05eb7d36726341579dbe56f",
    "semantic_title": "euclid: towards efficient unsupervised reinforcement learning with multi-choice dynamics model",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=lj1Eb1OPeNw": {
    "title": "Maximizing Spatio-Temporal Entropy of Deep 3D CNNs for Efficient Video Recognition",
    "volume": "poster",
    "abstract": "3D convolution neural networks (CNNs) have been the prevailing option for video recognition. To capture the temporal information, 3D convolutions are computed along the sequences, leading to cubically growing and expensive computations. To reduce the computational cost, previous methods resort to manually designed 3D/2D CNN structures with approximations or automatic search, which sacrifice the modeling ability or make training time-consuming. In this work, we propose to automatically design efficient 3D CNN architectures via a novel training-free neural architecture search approach tailored for 3D CNNs considering the model complexity. To measure the expressiveness of 3D CNNs efficiently, we formulate a 3D CNN as an information system and derive an analytic entropy score, based on the Maximum Entropy Principle. Specifically, we propose a spatio-temporal entropy score (STEntr-Score) with a refinement factor to handle the discrepancy of visual information in spatial and temporal dimensions, through dynamically leveraging the correlation between the feature map size and kernel size depth-wisely. Highly efficient and expressive 3D CNN architectures, i.e., entropy-based 3D CNNs (E3D family), can then be efficiently searched by maximizing the STEntr-Score under a given computational budget, via an evolutionary algorithm without training the network parameters. Extensive experiments on Something-Something V1&V2 and Kinetics400 demonstrate that the E3D family achieves state-of-the-art performance with higher computational efficiency",
    "checked": true,
    "id": "3b57267ad5b0c3f21fc2a6e5cf2da25c45bd81b0",
    "semantic_title": "maximizing spatio-temporal entropy of deep 3d cnns for efficient video recognition",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=7d-g8KozkiE": {
    "title": "Cycle to Clique (Cy2C) Graph Neural Network: A Sight to See beyond Neighborhood Aggregation",
    "volume": "poster",
    "abstract": "Graph neural networks have been successfully adapted for learning vector representations of graphs through various neighborhood aggregation schemes. Previous researches suggest, however, that they possess limitations in incorporating key non-Euclidean topological properties of graphs. This paper mathematically identifies the caliber of graph neural networks in classifying isomorphism classes of graphs with continuous node attributes up to their local topological properties. In light of these observations, we construct the Cycle to Clique graph neural network, a novel yet simple algorithm which topologically enriches the input data of conventional graph neural networks while preserving their architectural components. This method theoretically outperforms conventional graph neural networks in classifying isomorphism classes of graphs while ensuring comparable time complexity in representing random graphs. Empirical results further support that the novel algorithm produces comparable or enhanced results in classifying benchmark graph data sets compared to contemporary variants of graph neural networks",
    "checked": true,
    "id": "fba9a9ac43d65216be740969b12213b7ba170f40",
    "semantic_title": "cycle to clique (cy2c) graph neural network: a sight to see beyond neighborhood aggregation",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=b0UksKFcTOL": {
    "title": "Latent State Marginalization as a Low-cost Approach for Improving Exploration",
    "volume": "poster",
    "abstract": "While the maximum entropy (MaxEnt) reinforcement learning (RL) framework -- often touted for its exploration and robustness capabilities -- is usually motivated from a probabilistic perspective, the use of deep probabilistic models have not gained much traction in practice due to their inherent complexity. In this work, we propose the adoption of latent variable policies within the MaxEnt framework, which we can provably approximate any policy distribution, and additionally, naturally emerges under the use of world models with a latent belief state. We discuss why latent variable policies are difficult to train, how naive approaches can fail, and subsequently introduce a series of improvements centered around low-cost marginalization of the latent state, allowing us to make full use of the latent state at minimal additional cost. We instantiate our method under the actor-critic framework, marginalizing both the actor and critic. The resulting algorithm, referred to as Stochastic Marginal Actor-Critic (SMAC), is simple yet effective. We experimentally validate our method on continuous control tasks, showing that effective marginalization can lead to better exploration and more robust training. Our implementation is open sourced at https://github.com/zdhNarsil/Stochastic-Marginal-Actor-Critic",
    "checked": true,
    "id": "227f04217a212a5e1f7a8e38831431e4b1ab325f",
    "semantic_title": "latent state marginalization as a low-cost approach for improving exploration",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=inU2quhGdNU": {
    "title": "Generalizing and Decoupling Neural Collapse via Hyperspherical Uniformity Gap",
    "volume": "poster",
    "abstract": "The neural collapse (NC) phenomenon describes an underlying geometric symmetry for deep neural networks, where both deeply learned features and classifiers converge to a simplex equiangular tight frame. It has been shown that both cross-entropy loss and mean square error can provably lead to NC. We remove NC's key assumption on the feature dimension and the number of classes, and then present a generalized neural collapse (GNC) hypothesis that effectively subsumes the original NC. Inspired by how NC characterizes the training target of neural networks, we decouple GNC into two objectives: minimal intra-class variability and maximal inter-class separability. We then use hyperspherical uniformity (which characterizes the degree of uniformity on the unit hypersphere) as a unified framework to quantify these two objectives. Finally, we propose a general objective -- hyperspherical uniformity gap (HUG), which is defined by the difference between inter-class and intra-class hyperspherical uniformity. HUG not only provably converges to GNC, but also decouples GNC into two separate objectives. Unlike cross-entropy loss that couples intra-class compactness and inter-class separability, HUG enjoys more flexibility and serves as a good alternative loss function. Empirical results show that HUG works well in terms of generalization and robustness",
    "checked": true,
    "id": "402fb091fccc9921f938bfa81de0b978896a674e",
    "semantic_title": "generalizing and decoupling neural collapse via hyperspherical uniformity gap",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=QzbKH8nNq_V": {
    "title": "MaskFusion: Feature Augmentation for Click-Through Rate Prediction via Input-adaptive Mask Fusion",
    "volume": "poster",
    "abstract": "Click-through rate (CTR) prediction plays important role in the advertisement, recommendation, and retrieval applications. Given the feature set, how to fully utilize the information from the feature set is an active topic in deep CTR model designs. There are several existing deep CTR works focusing on feature interactions, feature attentions, and so on. They attempt to capture high-order feature interactions to enhance the generalization ability of deep CTR models. However, these works either suffer from poor high-order feature interaction modeling using DNN or ignore the balance between generalization and memorization during the recommendation. To mitigate these problems, we propose an adaptive feature fusion framework called MaskFusion, to additionally capture the explicit interactions between the input feature and the existing deep part structure of deep CTR models dynamically, besides the common feature interactions proposed in existing works. MaskFusion is an instance-aware feature augmentation method, which makes deep CTR models more personalized by assigning each feature with an instance-adaptive mask and fusing each feature with each hidden state vector in the deep part structure. MaskFusion can also be integrated into any existing deep CTR models flexibly. MaskFusion achieves state-of-the-art (SOTA) performance on all seven benchmarks deep CTR models with three public datasets",
    "checked": true,
    "id": "0238cf8b0ca75d175a4489e3704888b3892d7076",
    "semantic_title": "maskfusion: feature augmentation for click-through rate prediction via input-adaptive mask fusion",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=8U4joMeLRF": {
    "title": "Rethinking Self-Supervised Visual Representation Learning in Pre-training for 3D Human Pose and Shape Estimation",
    "volume": "poster",
    "abstract": "Recently, a few self-supervised representation learning (SSL) methods have outperformed the ImageNet classification pre-training for vision tasks such as object detection. However, its effects on 3D human body pose and shape estimation (3DHPSE) are open to question, whose target is fixed to a unique class, the human, and has an inherent task gap with SSL. We empirically study and analyze the effects of SSL and further compare it with other pre-training alternatives for 3DHPSE. The alternatives are 2D annotation-based pre-training and synthetic data pre-training, which share the motivation of SSL that aims to reduce the labeling cost. They have been widely utilized as a source of weak-supervision or fine-tuning, but have not been remarked as a pre-training source. SSL methods underperform the conventional ImageNet classification pre-training on multiple 3DHPSE benchmarks by 7.7% on average. In contrast, despite a much less amount of pre-training data, the 2D annotation-based pre-training improves accuracy on all benchmarks and shows faster convergence during fine-tuning. Our observations challenge the naive application of the current SSL pre-training to 3DHPSE and relight the value of other data types in the pre-training aspect",
    "checked": true,
    "id": "f784b35fc06aa0fc7677dca79fe106f73bbf670b",
    "semantic_title": "rethinking self-supervised visual representation learning in pre-training for 3d human pose and shape estimation",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=UiaUEICawgw": {
    "title": "Learned Index with Dynamic $\\epsilon$",
    "volume": "poster",
    "abstract": "Index structure is a fundamental component in database and facilitates broad data retrieval applications. Recent learned index methods show superior performance by learning hidden yet useful data distribution with the help of machine learning, and provide a guarantee that the prediction error is no more than a pre-defined $\\epsilon$. However, existing learned index methods adopt a fixed $\\epsilon$ for all the learned segments, neglecting the diverse characteristics of different data localities. In this paper, we propose a mathematically-grounded learned index framework with dynamic $\\epsilon$, which is efficient and pluggable to existing learned index methods. We theoretically analyze prediction error bounds that link $\\epsilon$ with data characteristics for an illustrative learned index method. Under the guidance of the derived bounds, we learn how to vary $\\epsilon$ and improve the index performance with a better space-time trade-off. Experiments with real-world datasets and several state-of-the-art methods demonstrate the efficiency, effectiveness and usability of the proposed framework",
    "checked": true,
    "id": "d45f32665a1c436a0e67581f10b3e779e7a66843",
    "semantic_title": "learned index with dynamic $\\epsilon$",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OxNQXyZK-K8": {
    "title": "Boosting Multiagent Reinforcement Learning via Permutation Invariant and Permutation Equivariant Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "393fa16f4076c460603b546fc9b86ad07f468ae7",
    "semantic_title": "boosting multiagent reinforcement learning via permutation invariant and permutation equivariant networks",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=v8Mi8KU6056": {
    "title": "wav2tok: Deep Sequence Tokenizer for Audio Retrieval",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "aa6bf20a03c311e96ea6ba1f47808b4a3b30d019",
    "semantic_title": "wav2tok: deep sequence tokenizer for audio retrieval",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=o3yygm3lnzS": {
    "title": "PV3D: A 3D Generative Model for Portrait Video Generation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5552e4acb67c845075836749691c3ef29bdecb89",
    "semantic_title": "pv3d: a 3d generative model for portrait video generation",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=51GXyzOKOp": {
    "title": "Characterizing the Influence of Graph Elements",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "78a8e8986ea2234a24df34b62e4cca095325aea3",
    "semantic_title": "characterizing the influence of graph elements",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=jh1nCir1R3d": {
    "title": "SWIFT: Rapid Decentralized Federated Learning via Wait-Free Model Communication",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "08c9200e6bc8e2cfe380fafa577e06d96b952e9f",
    "semantic_title": "swift: rapid decentralized federated learning via wait-free model communication",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=CUOaVn6mYEj": {
    "title": "Hierarchical Sliced Wasserstein Distance",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d6a7261a98f5029abce173dbe41af6afe52367aa",
    "semantic_title": "hierarchical sliced wasserstein distance",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=nUsP9lFADUF": {
    "title": "Prototypical Calibration for Few-shot Learning of Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6a483cd1cbecd66150c9bbcd01606723950281bc",
    "semantic_title": "prototypical calibration for few-shot learning of language models",
    "citation_count": 58,
    "authors": []
  },
  "https://openreview.net/forum?id=NO0ThzteQdI": {
    "title": "NERDS: A General Framework to Train Camera Denoisers from Raw-RGB Noisy Image Pairs",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "79297b48a09987dce09cfde683c931a54f06a428",
    "semantic_title": "nerds: a general framework to train camera denoisers from raw-rgb noisy image pairs",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=9X-hgLDLYkQ": {
    "title": "Learning Hierarchical Protein Representations via Complete 3D Graph Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6b29d0e8c69db690d25843e3f81bf34a9a558596",
    "semantic_title": "learning hierarchical protein representations via complete 3d graph networks",
    "citation_count": 66,
    "authors": []
  },
  "https://openreview.net/forum?id=1UbNwQC89a": {
    "title": "RGI: robust GAN-inversion for mask-free image inpainting and unsupervised pixel-wise anomaly detection",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f70801100c8d523bed156895120d53286d7aa49e",
    "semantic_title": "rgi: robust gan-inversion for mask-free image inpainting and unsupervised pixel-wise anomaly detection",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=QwKvL6wC8Yi": {
    "title": "Coverage-centric Coreset Selection for High Pruning Rates",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7619ed35ac30712fefd8f3e7f5d921f209f1268c",
    "semantic_title": "coverage-centric coreset selection for high pruning rates",
    "citation_count": 74,
    "authors": []
  },
  "https://openreview.net/forum?id=OM7doLjQbOQ": {
    "title": "ILA-DA: Improving Transferability of Intermediate Level Attack with Data Augmentation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a7a5bb518faf8db79a8ccae290b2a2f5256b26f2",
    "semantic_title": "ila-da: improving transferability of intermediate level attack with data augmentation",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=x0BPR9iXc1": {
    "title": "Contrastive Alignment of Vision to Language Through Parameter-Efficient Transfer Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7733cf84e5447339dd57ca96133e14e36c29e0e7",
    "semantic_title": "contrastive alignment of vision to language through parameter-efficient transfer learning",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=iP77_axu0h3": {
    "title": "BEEF: Bi-Compatible Class-Incremental Learning via Energy-Based Expansion and Fusion",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "816fdfd060bf85d84f5c98f1ad04bc55e1e1c4c6",
    "semantic_title": "beef: bi-compatible class-incremental learning via energy-based expansion and fusion",
    "citation_count": 73,
    "authors": []
  },
  "https://openreview.net/forum?id=gUZWOE42l6Q": {
    "title": "Out-of-distribution Representation Learning for Time Series Classification",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "95d1e89b4ed74c1d2924aacf1b0ae21ffd2a1cff",
    "semantic_title": "out-of-distribution representation learning for time series classification",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=VGI9dSmTgPF": {
    "title": "Schema Inference for Interpretable Image Classification",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "eed4caa4d1dc631cf6317903b410408abeef21f0",
    "semantic_title": "schema inference for interpretable image classification",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=XFSCKELP3bp": {
    "title": "Your Contrastive Learning Is Secretly Doing Stochastic Neighbor Embedding",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "740b343fac0e9bc5b1906c99c1071b67f4c163e1",
    "semantic_title": "your contrastive learning is secretly doing stochastic neighbor embedding",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=OhUAblg27z": {
    "title": "Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e672d0103fa44f73f15758d51d6a7046352ffd5e",
    "semantic_title": "harnessing mixed offline reinforcement learning datasets via trajectory weighting",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=1PL1NIMMrw": {
    "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5f19ae1135a9500940978104ec15a5b8751bc7d2",
    "semantic_title": "self-consistency improves chain of thought reasoning in language models",
    "citation_count": 4588,
    "authors": []
  },
  "https://openreview.net/forum?id=pgU3k7QXuz0": {
    "title": "Spiking Convolutional Neural Networks for Text Classification",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "305bd0dc722e204800bb61aa02d5952ee48555a6",
    "semantic_title": "gated convolutional neural networks for text classification",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=E3ip6qBLF7": {
    "title": "Distributionally Robust Recourse Action",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "928d22cc193ccae8e1bf345c1f2ce253a261a077",
    "semantic_title": "distributionally robust recourse action",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=HgQR0mXQ1_a": {
    "title": "Write and Paint: Generative Vision-Language Models are Unified Modal Learners",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ef57279f080e6e305c5cd216fd8f22ade2c903da",
    "semantic_title": "write and paint: generative vision-language models are unified modal learners",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=zJXg_Wmob03": {
    "title": "Progressive Voronoi Diagram Subdivision Enables Accurate Data-free Class-Incremental Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9323c9c8a89ff0b04fdc778fc058f1eaa6b8cca6",
    "semantic_title": "progressive voronoi diagram subdivision enables accurate data-free class-incremental learning",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=XIzO8zr-WbM": {
    "title": "Data Valuation Without Training of a Model",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e7ca53c22f02257ae3cfce00c27fe386b5c2a107",
    "semantic_title": "data valuation without training of a model",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=YDJRFWBMNby": {
    "title": "HotProtein: A Novel Framework for Protein Thermostability Prediction and Editing",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e36dfa8078c211ca9420f86b0dff2480150d5374",
    "semantic_title": "hotprotein: a novel framework for protein thermostability prediction and editing",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=HnSceSzlfrY": {
    "title": "RPM: Generalizable Multi-Agent Policies for Multi-Agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "05c522667f9dee976764f805a2e509f7c05ca80e",
    "semantic_title": "rpm: generalizable behaviors for multi-agent reinforcement learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=hQ4K9Bf4G2B": {
    "title": "Behavior Prior Representation learning for Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "adb0ae3a3c581c3dda0f2f3eb6af316cc602d699",
    "semantic_title": "behavior prior representation learning for offline reinforcement learning",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=o0LFPcoFKnr": {
    "title": "SCALE-UP: An Efficient Black-box Input-level Backdoor Detection via Analyzing Scaled Prediction Consistency",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6c780dfe8ff9c5a0d51893b5eaf41591299b3b8b",
    "semantic_title": "scale-up: an efficient black-box input-level backdoor detection via analyzing scaled prediction consistency",
    "citation_count": 118,
    "authors": []
  },
  "https://openreview.net/forum?id=tQG-o3SeipT": {
    "title": "On the Perils of Cascading Robust Classifiers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "dc15ef5398d7506ccf9c7f526f6cab8816e207d5",
    "semantic_title": "on the perils of cascading robust classifiers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4D4TSJE6-K": {
    "title": "Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7107d06366b48b3593c8128ed2ca67e0b413628c",
    "semantic_title": "learning math reasoning from self-sampled correct and partially-correct solutions",
    "citation_count": 47,
    "authors": []
  },
  "https://openreview.net/forum?id=3yJ-hcJBqe": {
    "title": "Adaptive Robust Evidential Optimization For Open Set Detection from Imbalanced Data",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "709b003b429b8f1a5470fb49838692961b40550e",
    "semantic_title": "adaptive robust evidential optimization for open set detection from imbalanced data",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=5HLoTvVGDe": {
    "title": "Dual Diffusion Implicit Bridges for Image-to-Image Translation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d1ca82960da359427557189f95e1c4037ddab5fc",
    "semantic_title": "dual diffusion implicit bridges for image-to-image translation",
    "citation_count": 228,
    "authors": []
  },
  "https://openreview.net/forum?id=boik01yhssB": {
    "title": "Average Sensitivity of Decision Tree Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "231367ab96468de02b77885784d0ca39d138aa07",
    "semantic_title": "average sensitivity of decision tree learning",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=WmIwYTd0YTF": {
    "title": "Stable Target Field for Reduced Variance Score Estimation in Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6a0f59e40e902519b698b4d678e7d61d5c0701d5",
    "semantic_title": "stable target field for reduced variance score estimation in diffusion models",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=m3twGT2bAug": {
    "title": "Continuous pseudo-labeling from the start",
    "volume": "poster",
    "abstract": "Self-training (ST), or pseudo-labeling has sparked significant interest in the automatic speech recognition (ASR) community recently because of its success in harnessing unlabeled data. Unlike prior semi-supervised learning approaches that relied on iteratively regenerating pseudo-labels (PLs) from a trained model and using them to train a new model, recent state-of-the-art methods perform `continuous training' where PLs are generated using a very recent version of the model being trained. Nevertheless, these approaches still rely on bootstrapping the ST using an initial supervised learning phase where the model is trained on labeled data alone. We believe this has the potential for over-fitting to the labeled dataset in low resource settings and that ST from the start of training should reduce over-fitting. In this paper we show how we can do this by dynamically controlling the evolution of PLs during the training process in ASR. To the best of our knowledge, this is the first study that shows the feasibility of generating PLs from the very start of the training. We are able to achieve this using two techniques that avoid instabilities which lead to degenerate models that do not generalize. Firstly, we control the evolution of PLs through a curriculum that uses the online changes in PLs to control the membership of the cache of PLs and improve generalization. Secondly, we find that by sampling transcriptions from the predictive distribution, rather than only using the best transcription, we can stabilize training further. With these techniques, our ST models match prior works without an external language model",
    "checked": true,
    "id": "1f8160b7e91b570e60e9cba2631cf0472cbc764c",
    "semantic_title": "continuous pseudo-labeling from the start",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=X9yCkmT5Qrl": {
    "title": "GNNDelete: A General Strategy for Unlearning in Graph Neural Networks",
    "volume": "poster",
    "abstract": "Graph unlearning, which involves deleting graph elements such as nodes, node labels, and relationships from a trained graph neural network (GNN) model, is crucial for real-world applications where data elements may become irrelevant, inaccurate, or privacy-sensitive. However, existing methods for graph unlearning either deteriorate model weights shared across all nodes or fail to effectively delete edges due to their strong dependence on local graph neighborhoods. To address these limitations, we introduce GNNDelete, a novel model-agnostic layer-wise operator that optimizes two critical properties, namely, Deleted Edge Consistency and Neighborhood Influence, for graph unlearning. Deleted Edge Consistency ensures that the influence of deleted elements is removed from both model weights and neighboring representations, while Neighborhood Influence guarantees that the remaining model knowledge is preserved after deletion. GNNDelete updates representations to delete nodes and edges from the model while retaining the rest of the learned knowledge. We conduct experiments on seven real-world graphs, showing that GNNDelete outperforms existing approaches by up to 38.8% (AUC) on edge, node, and node feature deletion tasks, and 32.2% on distinguishing deleted edges from non-deleted ones. Additionally, GNNDelete is efficient, taking 12.3x less time and 9.3x less space than retraining GNN from scratch on WordNet18",
    "checked": true,
    "id": "a0cfbac01e36ad24cdaa76ca62124a62d5c04c43",
    "semantic_title": "gnndelete: a general strategy for unlearning in graph neural networks",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=uHaWaNhCvZD": {
    "title": "Meta-Learning in Games",
    "volume": "poster",
    "abstract": "In the literature on game-theoretic equilibrium finding, focus has mainly been on solving a single game in isolation. In practice, however, strategic interactions—ranging from routing problems to online advertising auctions—evolve dynamically, thereby leading to many similar games to be solved. To address this gap, we introduce meta-learning for equilibrium finding and learning to play games. We establish the first meta-learning guarantees for a variety of fundamental and well-studied games, including two-player zero-sum games, general-sum games, Stackelberg games, and multiple extensions thereof. In particular, we obtain rates of convergence to different game-theoretic equilibria that depend on natural notions of similarity between the sequence of games encountered, while at the same time recovering the known single-game guarantees when the sequence of games is arbitrary. Along the way, we prove a number of new results in the single-game regime through a simple and unified framework, which may be of independent interest. Finally, we evaluate our meta-learning algorithms on endgames faced by the poker agent Libratus against top human professionals. The experiments show that games with varying stack sizes can be solved significantly faster using our meta-learning techniques than by solving them separately, often by an order of magnitude",
    "checked": true,
    "id": "bf68472d74f56fa3205e331360157974eeeb5e7f",
    "semantic_title": "meta-learning in games",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=kKF8_K-mBbS": {
    "title": "DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking",
    "volume": "poster",
    "abstract": "Predicting the binding structure of a small molecule ligand to a protein---a task known as molecular docking---is critical to drug design. Recent deep learning methods that treat docking as a regression problem have decreased runtime compared to traditional search-based methods but have yet to offer substantial improvements in accuracy. We instead frame molecular docking as a generative modeling problem and develop DiffDock, a diffusion generative model over the non-Euclidean manifold of ligand poses. To do so, we map this manifold to the product space of the degrees of freedom (translational, rotational, and torsional) involved in docking and develop an efficient diffusion process on this space. Empirically, DiffDock obtains a 38% top-1 success rate (RMSD<2A) on PDBBind, significantly outperforming the previous state-of-the-art of traditional docking (23%) and deep learning (20%) methods. Moreover, while previous methods are not able to dock on computationally folded structures (maximum accuracy 10.4%), DiffDock maintains significantly higher precision (21.7%). Finally, DiffDock has fast inference times and provides confidence estimates with high selective accuracy",
    "checked": true,
    "id": "e99604e2da48483b633247c13dd4ad5f46196562",
    "semantic_title": "diffdock: diffusion steps, twists, and turns for molecular docking",
    "citation_count": 509,
    "authors": []
  },
  "https://openreview.net/forum?id=yLzLfM-Esnu": {
    "title": "Constructive TT-representation of the tensors given as index interaction functions with applications",
    "volume": "poster",
    "abstract": "This paper presents a method to build explicit tensor-train (TT) representations. We show that a wide class of tensors can be explicitly represented with sparse TT-cores, obtaining, in many cases, optimal TT-ranks. Numerical experiments show that our method outperforms the existing ones in several practical applications, including game theory problems. Theoretical estimations of the number of operations show that in some problems, such as permanent calculation, our methods are close to the known optimal asymptotics, which are obtained by a completely different type of methods",
    "checked": true,
    "id": "705ca2b71f88854cde6b870da7f0a50f5b5d19ce",
    "semantic_title": "constructive tt-representation of the tensors given as index interaction functions with applications",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=78xgBm6ckZr": {
    "title": "Sparse tree-based Initialization for Neural Networks",
    "volume": "poster",
    "abstract": "Dedicated neural network (NN) architectures have been designed to handle specific data types (such as CNN for images or RNN for text), which ranks them among state-of-the-art methods for dealing with these data. Unfortunately, no architecture has been found for dealing with tabular data yet, for which tree ensemble methods (tree boosting, random forests) usually show the best predictive performances. In this work, we propose a new sparse initialization technique for (potentially deep) multilayer perceptrons (MLP): we first train a tree-based procedure to detect feature interactions and use the resulting information to initialize the network, which is subsequently trained via standard gradient descent (GD) strategies. Numerical experiments on several tabular data sets showthe benefits of this new, simple and easy-to-use method, both in terms of generalization capacity and computation time, compared to default MLP initialization and even to existing complex deep learning solutions. In fact, this wise MLP initialization raises the performances of the resulting NN methods to that of gradient boosting on tabular data. Besides, such initializations are able to preserve the sparsity of weights introduced in the first layers of the network throughout the training, which emphasizes that the first layers act as a sparse feature extractor (like convolutional layers in CNN)",
    "checked": true,
    "id": "d7755a396f1fb2fc6fee4cfcb901daff1cd3741f",
    "semantic_title": "sparse tree-based initialization for neural networks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=AdPJb9cud_Y": {
    "title": "VoGE: A Differentiable Volume Renderer using Gaussian Ellipsoids for Analysis-by-Synthesis",
    "volume": "poster",
    "abstract": "Differentiable rendering allows the application of computer graphics on vision tasks, e.g. object pose and shape fitting, via analysis-by-synthesis, where gradients at occluded regions are important when inverting the rendering process.To obtain those gradients, state-of-the-art (SoTA) differentiable renderers use rasterization to collect a set of nearest components for each pixel and aggregate them based on the viewing distance. In this paper, we propose VoGE, which uses ray tracing to capture nearest components with their volume density distributions on the rays and aggregates via integral of the volume densities based on Gaussian ellipsoids, which brings more efficient and stable gradients. To efficiently render via VoGE, we propose an approximate close-form solution for the volume density aggregation and a coarse-to-fine rendering strategy. Finally, we provide a CUDA implementation of VoGE, which gives a competitive rendering speed in comparison to PyTorch3D. Quantitative and qualitative experiment results show VoGE outperforms SoTA counterparts when applied to various vision tasks, e.g., object pose estimation, shape/texture fitting, and occlusion reasoning. The VoGE code is available at: https://github.com/Angtian/VoGE",
    "checked": true,
    "id": "31e79b62a9483dcdf2575603469e6ff888e7f234",
    "semantic_title": "voge: a differentiable volume renderer using gaussian ellipsoids for analysis-by-synthesis",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=TJ2nxciYCk-": {
    "title": "The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers",
    "volume": "poster",
    "abstract": "This paper studies a curious phenomenon that machine learning model with Transformer architectures have sparse activation maps. By activation map we refer to the intermediate output of the multi-layer perceptrons (MLPs) after a ReLU activation function, and by \"sparse\" we mean that on average very few entries (e.g., 3.0% for T5-Base and 6.3% for ViT-B16) are nonzero for each input to MLP. Moreover, larger Transformers with more layers and wider MLP hidden dimensions are sparser as measured by the percentage of nonzero entries. Through extensive experiments we demonstrate that the emergence of sparsity is a prevalent phenomenon that occurs for both natural language processing and vision tasks, on both training and evaluation data, for Transformers of various configurations, at layers of all depth levels. We discuss how sparsity immediately implies a way to significantly reduce the FLOP count and improve efficiency for Transformers. Moreover, we demonstrate perhaps surprisingly that enforcing an even sparser activation via Top-k thresholding with a small k brings a collection of desired properties, namely less sensitivity to noisy training data, more robustness to input corruptions, and better calibration for their prediction confidence",
    "checked": true,
    "id": "e0271cb75087ccfd4a8c3351e0f5189a6de04c03",
    "semantic_title": "the lazy neuron phenomenon: on emergence of activation sparsity in transformers",
    "citation_count": 110,
    "authors": []
  },
  "https://openreview.net/forum?id=3YjQfCLdrzz": {
    "title": "FoSR: First-order spectral rewiring for addressing oversquashing in GNNs",
    "volume": "poster",
    "abstract": "Graph neural networks (GNNs) are able to leverage the structure of graph data by passing messages along the edges of the graph. While this allows GNNs to learn features depending on the graph structure, for certain graph topologies it leads to inefficient information propagation and a problem known as oversquashing. This has recently been linked with the curvature and spectral gap of the graph. On the other hand, adding edges to the message-passing graph can lead to increasingly similar node representations and a problem known as oversmoothing. We propose a computationally efficient algorithm that prevents oversquashing by systematically adding edges to the graph based on spectral expansion. We combine this with a relational architecture, which lets the GNN preserve the original graph structure and provably prevents oversmoothing. We find experimentally that our algorithm outperforms existing graph rewiring methods in several graph classification tasks",
    "checked": true,
    "id": "b3a464038b8aad8a7d9475bf8bcc495f1378b0ae",
    "semantic_title": "fosr: first-order spectral rewiring for addressing oversquashing in gnns",
    "citation_count": 81,
    "authors": []
  },
  "https://openreview.net/forum?id=3OaBBATwsvP": {
    "title": "Generative Modeling Helps Weak Supervision (and Vice Versa)",
    "volume": "poster",
    "abstract": "Many promising applications of supervised machine learning face hurdles in the acquisition of labeled data in sufficient quantity and quality, creating an expensive bottleneck. To overcome such limitations, techniques that do not depend on ground truth labels have been studied, including weak supervision and generative modeling. While these techniques would seem to be usable in concert, improving one another, how to build an interface between them is not well-understood. In this work, we propose a model fusing programmatic weak supervision and generative adversarial networks and provide theoretical justification motivating this fusion. The proposed approach captures discrete latent variables in the data alongside the weak supervision derived label estimate. Alignment of the two allows for better modeling of sample-dependent accuracies of the weak supervision sources, improving the estimate of unobserved labels. It is the first approach to enable data augmentation through weakly supervised synthetic images and pseudolabels. Additionally, its learned latent variables can be inspected qualitatively. The model outperforms baseline weak supervision label models on a number of multiclass image classification datasets, improves the quality of generated images, and further improves end-model performance through data augmentation with synthetic samples",
    "checked": true,
    "id": "c5eee006cbcc87f7a633b2a89a0a8e8031661dbc",
    "semantic_title": "generative modeling helps weak supervision (and vice versa)",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=8JCg5xJCTPR": {
    "title": "Provable Memorization Capacity of Transformers",
    "volume": "poster",
    "abstract": "Quantifying memorization capacity is essential for understanding the expressiveness and generalizability of deep learning model architectures. However, the memorization capacity of the Transformer architecture has yet to be explored. In this work, we present the first study of the memorization capacity of the Transformer architecture. We prove that Transformers are capable of memorizing $N$ sequence-to-sequence mappings of length $n$ with $d$-dimensional input tokens using $\\tilde{O}(d + n + \\sqrt{nN})$ parameters. Our theory supports memorization both with and without permutation equivariance, utilizing positional encodings in the latter case. Building on our theory, we also analyze the memorization capacity of Transformers in the sequence classification and language modeling tasks. To verify these theoretical findings, we conduct experiments analyzing the memorization capacity of Transformers in the natural language domain",
    "checked": true,
    "id": "cde0857f0f37937671c9d6dc282b8b0b8af61f7e",
    "semantic_title": "provable memorization capacity of transformers",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=A7v2DqLjZdq": {
    "title": "Bridge the Inference Gaps of Neural Processes via Expectation Maximization",
    "volume": "poster",
    "abstract": "The neural process (NP) is a family of computationally efficient models for learning distributions over functions. However, it suffers from under-fitting and shows suboptimal performance in practice. Researchers have primarily focused on incorporating diverse structural inductive biases, e.g. attention or convolution, in modeling. The topic of inference suboptimality and an analysis of the NP from the optimization objective perspective has hardly been studied in earlier work. To fix this issue, we propose a surrogate objective of the target log-likelihood of the meta dataset within the expectation maximization framework. The resulting model, referred to as the Self-normalized Importance weighted Neural Process (SI-NP), can learn a more accurate functional prior and has an improvement guarantee concerning the target log-likelihood. Experimental results show the competitive performance of SI-NP over other NPs objectives and illustrate that structural inductive biases, such as attention modules, can also augment our method to achieve SOTA performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZhuXksSJYWn": {
    "title": "Masked Vision and Language Modeling for Multi-modal Representation Learning",
    "volume": "poster",
    "abstract": "In this paper, we study how to use masked signal modeling in vision and language (V+L) representation learning. Instead of developing masked language modeling (MLM) and masked image modeling (MIM) independently, we propose to build joint masked vision and language modeling, where the masked signal of one modality is reconstructed with the help from another modality. This is motivated by the nature of image-text paired data that both of the image and the text convey almost the same information but in different formats. The masked signal reconstruction of one modality conditioned on another modality can also implicitly learn cross-modal alignment between language tokens and image patches. Our experiments on various V+L tasks show that the proposed method, along with common V+L alignment losses, not only achieves state-of-the-art performance by using a large amount of data but also outperforms the other competitors by a significant margin in the regimes of limited training data",
    "checked": true,
    "id": "620369d6ed3ed68c3e4374d6ddf282e0b036d2f8",
    "semantic_title": "masked vision and language modeling for multi-modal representation learning",
    "citation_count": 80,
    "authors": []
  },
  "https://openreview.net/forum?id=8WTAh0tj2jC": {
    "title": "Agent-based Graph Neural Networks",
    "volume": "poster",
    "abstract": "We present a novel graph neural network we call AgentNet, which is designed specifically for graph-level tasks. AgentNet is inspired by sublinear algorithms, featuring a computational complexity that is independent of the graph size. The architecture of AgentNet differs fundamentally from the architectures of traditional graph neural networks. In AgentNet, some trained \\textit{neural agents} intelligently walk the graph, and then collectively decide on the output. We provide an extensive theoretical analysis of AgentNet: We show that the agents can learn to systematically explore their neighborhood and that AgentNet can distinguish some structures that are even indistinguishable by 2-WL. Moreover, AgentNet is able to separate any two graphs which are sufficiently different in terms of subgraphs. We confirm these theoretical results with synthetic experiments on hard-to-distinguish graphs and real-world graph classification tasks. In both cases, we compare favorably not only to standard GNNs but also to computationally more expensive GNN extensions",
    "checked": true,
    "id": "ce7e583841e6be721d8ef32ebf94956c7db2f209",
    "semantic_title": "agent-based graph neural networks",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=6JMXLWX68Kj": {
    "title": "On the Performance of Temporal Difference Learning With Neural Networks",
    "volume": "poster",
    "abstract": "Neural Temporal Difference (TD) Learning is an approximate temporal difference method for policy evaluation that uses a neural network for function approximation. Analysis of Neural TD Learning has proven to be challenging. In this paper we provide a convergence analysis of Neural TD Learning with a projection onto $B(\\theta_0, \\omega)$, a ball of fixed radius $\\omega$ around the initial point $\\theta_0$. We show an approximation bound of $O(\\epsilon + 1/\\sqrt{m})$ where $\\epsilon$ is the approximation quality of the best neural network in $B(\\theta_0, \\omega)$ and $m$ is the width of all hidden layers in the network",
    "checked": true,
    "id": "2cceba22a8231f19034896cf320a83a6db9e844d",
    "semantic_title": "on the performance of temporal difference learning with neural networks",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=b0JxQC7JLWh": {
    "title": "Certified Defences Against Adversarial Patch Attacks on Semantic Segmentation",
    "volume": "poster",
    "abstract": "Adversarial patch attacks are an emerging security threat for real world deep learning applications. We present Demasked Smoothing, the first approach (up to our knowledge) to certify the robustness of semantic segmentation models against this threat model. Previous work on certifiably defending against patch attacks has mostly focused on image classification task and often required changes in the model architecture and additional training which is undesirable and computationally expensive. In Demasked Smoothing, any segmentation model can be applied without particular training, fine-tuning, or restriction of the architecture. Using different masking strategies, Demasked Smoothing can be applied both for certified detection and certified recovery. In extensive experiments we show that Demasked Smoothing can on average certify 63% of the pixel predictions for a 1% patch in the detection task and 46% against a 0.5% patch for the recovery task on the ADE20K dataset",
    "checked": true,
    "id": "9cf8990a8b089059452cf59cc561d23b02611282",
    "semantic_title": "certified defences against adversarial patch attacks on semantic segmentation",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=81VJDmOE2ol": {
    "title": "Markup-to-Image Diffusion Models with Scheduled Sampling",
    "volume": "poster",
    "abstract": "Building on recent advances in image generation, we present a fully data-driven approach to rendering markup into images. The approach is based on diffusion models, which parameterize the distribution of data using a sequence of denoising operations on top of a Gaussian noise distribution. We view the diffusion denoising process a sequential decision making process, and show that it exhibits compounding errors similar to exposure bias issues in imitation learning problems. To mitigate these issues, we adapt the scheduled sampling algorithm to diffusion training. We conduct experiments on four markup datasets: formulas (LaTeX), table layouts (HTML), sheet music (LilyPond), and molecular images (SMILES). These experiments each verify the effectiveness of diffusion and the use of scheduled sampling to fix generation issues. These results also show that the markup-to-image task presents a useful controlled compositional setting for diagnosing and analyzing generative image models",
    "checked": true,
    "id": "b69391b7b4cbef5a9a749744d7f676942c214706",
    "semantic_title": "markup-to-image diffusion models with scheduled sampling",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=Yo06F8kfMa1": {
    "title": "How Much Space Has Been Explored? Measuring the Chemical Space Covered by Databases and Machine-Generated Molecules",
    "volume": "poster",
    "abstract": "Forming a molecular candidate set that contains a wide range of potentially effective compounds is crucial to the success of drug discovery. While most databases and machine-learning-based generation models aim to optimize particular chemical properties, there is limited literature on how to properly measure the coverage of the chemical space by those candidates included or generated. This problem is challenging due to the lack of formal criteria to select good measures of the chemical space. In this paper, we propose a novel evaluation framework for measures of the chemical space based on two analyses: an axiomatic analysis with three intuitive axioms that a good measure should obey, and an empirical analysis on the correlation between a measure and a proxy gold standard. Using this framework, we are able to identify #Circles, a new measure of chemical space coverage, which is superior to existing measures both analytically and empirically. We further evaluate how well the existing databases and generation models cover the chemical space in terms of #Circles. The results suggest that many generation models fail to explore a larger space over existing databases, which leads to new opportunities for improving generation models by encouraging exploration",
    "checked": true,
    "id": "71b4adf2c937c54e1e1ac57e3ecfea94c05b8a1c",
    "semantic_title": "how much space has been explored? measuring the chemical space covered by databases and machine-generated molecules",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=DBMttEEoLbw": {
    "title": "Understanding new tasks through the lens of training data via exponential tilting",
    "volume": "poster",
    "abstract": "Deploying machine learning models on new tasks is a major challenge due to differences in distributions of the train (source) data and the new (target) data. However, the training data likely captures some of the properties of the new task. We consider the problem of reweighing the training samples to gain insights into the distribution of the target task. Specifically, we formulate a distribution shift model based on the exponential tilt assumption and learn train data importance weights minimizing the KL divergence between labeled train and unlabeled target datasets. The learned train data weights can then be used for downstream tasks such as target performance evaluation, fine-tuning, and model selection. We demonstrate the efficacy of our method on Waterbirds and Breeds benchmarks",
    "checked": true,
    "id": "22ce16a6c15adfe9cedb91493083bf0ebb08faaa",
    "semantic_title": "understanding new tasks through the lens of training data via exponential tilting",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=0qSOodKmJaN": {
    "title": "Calibrating Sequence likelihood Improves Conditional Language Generation",
    "volume": "poster",
    "abstract": "Conditional language models are predominantly trained with maximum likelihood estimation (MLE), giving probability mass to sparsely observed target sequences. While MLE trained models assign high probability to plausible sequences given the context, the model probabilities often do not accurately rank-order generated sequences by quality. This has been empirically observed in beam search decoding as output quality degrading with large beam sizes, and decoding strategies benefiting from heuristics such as length normalization and repetition-blocking. In this work, we introduce sequence likelihood calibration (SLiC) where the likelihood of model generated sequences are calibrated to better align with reference sequences in the model's latent space. With SLiC, decoding heuristics become unnecessary and decoding candidates' quality significantly improves regardless of the decoding method. Furthermore, SLiC shows no sign of diminishing returns with model scale, and presents alternative ways to improve quality with limited training and inference budgets. With SLiC, we exceed or match SOTA results on a wide range of generation tasks spanning abstractive summarization, question generation, abstractive question answering and data-to-text generation, even with modest-sized models",
    "checked": true,
    "id": "891edceb78a274b0c2494d8176bc4d6f6e3f9cbc",
    "semantic_title": "calibrating sequence likelihood improves conditional language generation",
    "citation_count": 143,
    "authors": []
  },
  "https://openreview.net/forum?id=vdv6CmGksr0": {
    "title": "Learning differentiable solvers for systems with hard constraints",
    "volume": "poster",
    "abstract": "We introduce a practical method to enforce partial differential equation (PDE) constraints for functions defined by neural networks (NNs), with a high degree of accuracy and up to a desired tolerance. We develop a differentiable PDE-constrained layer that can be incorporated into any NN architecture. Our method leverages differentiable optimization and the implicit function theorem to effectively enforce physical constraints. Inspired by dictionary learning, our model learns a family of functions, each of which defines a mapping from PDE parameters to PDE solutions. At inference time, the model finds an optimal linear combination of the functions in the learned family by solving a PDE-constrained optimization problem. Our method provides continuous solutions over the domain of interest that accurately satisfy desired physical constraints. Our results show that incorporating hard constraints directly into the NN architecture achieves much lower test error when compared to training on an unconstrained objective",
    "checked": true,
    "id": "89c45395053922e34ffd056b2f4dd7a99ea1c73f",
    "semantic_title": "learning differentiable solvers for systems with hard constraints",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=6P9Y25Pljl6": {
    "title": "FedDAR: Federated Domain-Aware Representation Learning",
    "volume": "poster",
    "abstract": "Cross-silo Federated learning (FL) has become a promising tool in machine learning applications for healthcare. It allows hospitals/institutions to train models with sufficient data while the data is kept private. To make sure the FL model is robust when facing heterogeneous data among FL clients, most efforts focus on personalizing models for clients. However, the latent relationships between clients' data are ignored. In this work, we focus on a special non-iid FL problem, called Domain-mixed FL, where each client's data distribution is assumed to be a mixture of several predefined domains. Recognizing the diversity of domains and the similarity within domains, we propose a novel method, FedDAR, which learns a domain shared representation and domain-wise personalized prediction heads in a decoupled manner. For simplified linear regression settings, we have theoretically proved that FedDAR enjoys a linear convergence rate. For general settings, we have performed intensive empirical studies on both synthetic and real-world medical datasets which demonstrate its superiority over prior FL methods. Our code is available at https://github.com/zlz0414/FedDAR",
    "checked": true,
    "id": "25f74e75e5dd41875eb2404b550b99bb91866ee7",
    "semantic_title": "feddar: federated domain-aware representation learning",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=TFbwV6I0VLg": {
    "title": "SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models",
    "volume": "poster",
    "abstract": "Understanding dynamics from visual observations is a challenging problem that requires disentangling individual objects from the scene and learning their interactions. While recent object-centric models can successfully decompose a scene into objects, modeling their dynamics effectively still remains a challenge. We address this problem by introducing SlotFormer -- a Transformer-based autoregressive model operating on learned object-centric representations. Given a video clip, our approach reasons over object features to model spatio-temporal relationships and predicts accurate future object states. In this paper, we successfully apply SlotFormer to perform video prediction on datasets with complex object interactions. Moreover, the unsupervised SlotFormer's dynamics model can be used to improve the performance on supervised downstream tasks, such as Visual Question Answering (VQA), and goal-conditioned planning. Compared to past works on dynamics modeling, our method achieves significantly better long-term synthesis of object dynamics, while retaining high quality visual generation. Besides, SlotFormer enables VQA models to reason about the future without object-level labels, even outperforming counterparts that use ground-truth annotations. Finally, we show its ability to serve as a world model for model-based planning, which is competitive with methods designed specifically for such tasks",
    "checked": true,
    "id": "cb5e13ad829a67f5fc25c113a7d39bebb940f3f8",
    "semantic_title": "slotformer: unsupervised visual dynamics simulation with object-centric models",
    "citation_count": 106,
    "authors": []
  },
  "https://openreview.net/forum?id=MQcmfgRxf7a": {
    "title": "Simplifying Model-based RL: Learning Representations, Latent-space Models, and Policies with One Objective",
    "volume": "poster",
    "abstract": "While reinforcement learning (RL) methods that learn an internal model of the environment have the potential to be more sample efficient than their model-free counterparts, learning to model raw observations from high dimensional sensors can be challenging. Prior work has addressed this challenge by learning low-dimensional representation of observations through auxiliary objectives, such as reconstruction or value prediction. However, the alignment between these auxiliary objectives and the RL objective is often unclear. In this work, we propose a single objective which jointly optimizes a latent-space model and policy to achieve high returns while remaining self-consistent. This objective is a lower bound on expected returns. Unlike prior bounds for model-based RL on policy exploration or model guarantees, our bound is directly on the overall RL objective. We demonstrate that the resulting algorithm matches or improves the sample-efficiency of the best prior model-based and model-free RL methods. While sample efficient methods typically are computationally demanding, our method attains the performance of SAC in about 50\\% less wall-clock time",
    "checked": true,
    "id": "0d9786c223866337b80e126f3a145c5a8a378473",
    "semantic_title": "simplifying model-based rl: learning representations, latent-space models, and policies with one objective",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=o7koEEMA1bR": {
    "title": "Deep Generative Symbolic Regression",
    "volume": "poster",
    "abstract": "Symbolic regression (SR) aims to discover concise closed-form mathematical equations from data, a task fundamental to scientific discovery. However, the problem is highly challenging because closed-form equations lie in a complex combinatorial search space. Existing methods, ranging from heuristic search to reinforcement learning, fail to scale with the number of input variables. We make the observation that closed-form equations often have structural characteristics and invariances (e.g. the commutative law) that could be further exploited to build more effective symbolic regression solutions. Motivated by this observation, our key contribution is to leverage pre-trained deep generative models to capture the intrinsic regularities of equations, thereby providing a solid foundation for subsequent optimization steps. We show that our novel formalism unifies several prominent approaches of symbolic regression and offers a new perspective to justify and improve on the previous ad hoc designs, such as the usage of cross-entropy loss during pre-training. Specifically, we propose an instantiation of our framework, Deep Generative Symbolic Regression (DGSR). In our experiments, we show that DGSR achieves a higher recovery rate of true equations in the setting of a larger number of input variables, and it is more computationally efficient at inference time than state-of-the-art RL symbolic regression solutions",
    "checked": true,
    "id": "cda10f395932f2d16ce925d3d91dc4368416a656",
    "semantic_title": "deep generative symbolic regression",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=p66AzKi6Xim": {
    "title": "What Can we Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers?",
    "volume": "poster",
    "abstract": "When deployed for risk-sensitive tasks, deep neural networks must include an uncertainty estimation mechanism. Here we examine the relationship between deep architectures and their respective training regimes, with their corresponding selective prediction and uncertainty estimation performance. We consider some of the most popular estimation performance metrics previously proposed including AUROC, ECE, AURC as well as coverage for selective accuracy constraint. We present a novel and comprehensive study of selective prediction and the uncertainty estimation performance of 523 existing pretrained deep ImageNet classifiers that are available in popular repositories. We identify numerous and previously unknown factors that affect uncertainty estimation and examine the relationships between the different metrics. We find that distillation-based training regimes consistently yield better uncertainty estimations than other training schemes such as vanilla training, pretraining on a larger dataset and adversarial training. Moreover, we find a subset of ViT models that outperform any other models in terms of uncertainty estimation performance. For example, we discovered an unprecedented 99% top-1 selective accuracy on ImageNet at 47% coverage (and 95% top-1 accuracy at 80%) for a ViT model, whereas a competing EfficientNet-V2-XL cannot obtain these accuracy constraints at any level of coverage. Our companion paper, also published in ICLR 2023 (A framework for benchmarking class-out-of-distribution detection and its application to ImageNet), examines the performance of these classifiers in a class-out-of-distribution setting",
    "checked": false,
    "id": "f4d36f70fe8b0bb497c37ccb2531c0b540cc9e9b",
    "semantic_title": "what can we learn from the selective prediction and uncertainty estimation performance of 523 imagenet classifiers",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=2SV2dlfBuE3": {
    "title": "Predictor-corrector algorithms for stochastic optimization under gradual distribution shift",
    "volume": "poster",
    "abstract": "Time-varying stochastic optimization problems frequently arise in machine learning practice (e.g., gradual domain shift, object tracking, strategic classification). Often, the underlying process that drives the distribution shift is continuous in nature. We exploit this underlying continuity by developing predictor-corrector algorithms for time-varying stochastic optimization that anticipates changes in the underlying data generating process through a predictor-corrector term in the update rule. The key challenge is the estimation of the predictor-corrector term; a naive approach based on sample-average approximation may lead to non-convergence. We develop a general moving-average based method to estimate the predictor-corrector term and provide error bounds for the iterates, both in presence of pure and noisy access to the queries from the relevant derivatives of the loss function. Furthermore, we show (theoretically and empirically in several examples) that our method outperforms non-predictor corrector methods that do not anticipate changes in the data generating process",
    "checked": true,
    "id": "7b831ed967fe9633f77b59df55b4894c330c5218",
    "semantic_title": "predictor-corrector algorithms for stochastic optimization under gradual distribution shift",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=CIoSZ_HKHS7": {
    "title": "AIM: Adapting Image Models for Efficient Video Action Recognition",
    "volume": "poster",
    "abstract": "Recent vision transformer based video models mostly follow the ``image pre-training then finetuning\" paradigm and have achieved great success on multiple video benchmarks. However, fully finetuning such a video model could be computationally expensive and unnecessary, given the pre-trained image transformer models have demonstrated exceptional transferability. In this work, we propose a novel method to Adapt pre-trained Image Models (AIM) for efficient video understanding. By freezing the pre-trained image model and adding a few lightweight Adapters, we introduce spatial adaptation, temporal adaptation and joint adaptation to gradually equip an image model with spatiotemporal reasoning capability. We show that our proposed AIM can achieve competitive or even better performance than prior arts with substantially fewer tunable parameters on four video action recognition benchmarks. Thanks to its simplicity, our method is also generally applicable to different image pre-trained models, which has the potential to leverage more powerful image foundation models in the future. The project webpage is https://adapt-image-models.github.io/",
    "checked": true,
    "id": "fac388b8c24044dea06cc8c7b03dd1d99c8439a0",
    "semantic_title": "aim: adapting image models for efficient video action recognition",
    "citation_count": 185,
    "authors": []
  },
  "https://openreview.net/forum?id=sciA_xgYofB": {
    "title": "Impossibly Good Experts and How to Follow Them",
    "volume": "poster",
    "abstract": "We consider the sequential decision making problem of learning from an expert that has access to more information than the learner. For many problems this extra information will enable the expert to achieve greater long term reward than any policy without this privileged information access. We call these experts ``Impossibly Good'' because no learning algorithm will be able to reproduce their behavior. However, in these settings it is reasonable to attempt to recover the best policy possible given the agent's restricted access to information. We provide a set of necessary criteria on the expert that will allow a learner to recover the optimal policy in the reduced information space from the expert's advice alone. We also provide a new approach called Elf Distillation (Explorer Learning from Follower) that can be used in cases where these criteria are not met and environmental rewards must be taken into account. We show that this algorithm performs better than a variety of strong baselines on a challenging suite of Minigrid and Vizdoom environments",
    "checked": true,
    "id": "f8331e032902a289bdd5f7c68c499edabc9ea9a0",
    "semantic_title": "impossibly good experts and how to follow them",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=3KUfbI9_DQE": {
    "title": "Distributionally Robust Post-hoc Classifiers under Prior Shifts",
    "volume": "poster",
    "abstract": "The generalization ability of machine learning models degrades significantly when the test distribution shifts away from the training distribution. We investigate the problem of training models that are robust to shifts caused by changes in the distribution of class-priors or group-priors. The presence of skewed training priors can often lead to the models overfitting to spurious features. Unlike existing methods, which optimize for either the worst or the average performance over classes or groups, our work is motivated by the need for finer control over the robustness properties of the model. We present an extremely lightweight post-hoc approach that performs scaling adjustments to predictions from a pre-trained model, with the goal of minimizing a distributionally robust loss around a chosen target distribution. These adjustments are computed by solving a constrained optimization problem on a validation set and applied to the model during test time. Our constrained optimization objective is inspired from a natural notion of robustness to controlled distribution shifts. Our method comes with provable guarantees and empirically makes a strong case for distributional robust post-hoc classifiers. An empirical implementation is available at https://github.com/weijiaheng/Drops",
    "checked": true,
    "id": "e31b40fcb240a3b6d41890c6e30d8bd8556cdcf8",
    "semantic_title": "distributionally robust post-hoc classifiers under prior shifts",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=HnlCZATopvr": {
    "title": "Transformer Meets Boundary Value Inverse Problems",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b8bbba4bcb5f60c9174d786ce8a722a4b349cb69",
    "semantic_title": "transformer meets boundary value inverse problems",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=3YFDsSRSxB-": {
    "title": "Unicom: Universal and Compact Representation Learning for Image Retrieval",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4274922ab64d4d994fe1ecc5d58e0b6c6c53d35b",
    "semantic_title": "unicom: universal and compact representation learning for image retrieval",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=ik91mY-2GN": {
    "title": "Diffusion Probabilistic Fields",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6e44135a35a5af90756ac22a496a412355150cb9",
    "semantic_title": "diffusion probabilistic fields",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=6w1k-IixnL8": {
    "title": "Beyond calibration: estimating the grouping loss of modern neural networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6439d4e28820ebd37c704ef2f951bd983d988b84",
    "semantic_title": "beyond calibration: estimating the grouping loss of modern neural networks",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=yyBis80iUuU": {
    "title": "Hybrid RL: Using both offline and online data can make RL efficient",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2d33f309f7e92c75434a2bb16f70d6ec65ab7d2a",
    "semantic_title": "hybrid rl: using both offline and online data can make rl efficient",
    "citation_count": 120,
    "authors": []
  },
  "https://openreview.net/forum?id=p0yrSRbN5Bu": {
    "title": "Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3d7d385d9ee75a286e8da27f7d3cf9f12651c899",
    "semantic_title": "model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=RlPmWBiyp6w": {
    "title": "GAIN: On the Generalization of Instructional Action Understanding",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "620d54c32923db997d9312b1d631393a740d2842",
    "semantic_title": "gain: on the generalization of instructional action understanding",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=lcSfirnflpW": {
    "title": "ManyDG: Many-domain Generalization for Healthcare Applications",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "02d161ae84ef3e6a832ccefb9544288d21c89aea",
    "semantic_title": "manydg: many-domain generalization for healthcare applications",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=XHc5zRPxqV9": {
    "title": "DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0751b6de6c07c52a324450e32ae6581d403603da",
    "semantic_title": "decaf: joint decoding of answers and logical forms for question answering over knowledge bases",
    "citation_count": 102,
    "authors": []
  },
  "https://openreview.net/forum?id=elDEe8LYW7-": {
    "title": "NANSY++: Unified Voice Synthesis with Neural Analysis and Synthesis",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3d6880b1ae95335d2e6bae38c62614a44a299c04",
    "semantic_title": "nansy++: unified voice synthesis with neural analysis and synthesis",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=8XqDnrmZQNF": {
    "title": "Causality Compensated Attention for Contextual Biased Visual Recognition",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "beb756f8135145cf9362ec8a6c5431301aebb4a8",
    "semantic_title": "causality compensated attention for contextual biased visual recognition",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=TjEzIsyEsQ6": {
    "title": "Multi-Objective Reinforcement Learning: Convexity, Stationarity and Pareto Optimality",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "460c3bcb289b0771accead06c9bfc10f9bbc7795",
    "semantic_title": "multi-objective reinforcement learning: convexity, stationarity and pareto optimality",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=J4mJjotSauh": {
    "title": "Fooling SHAP with Stealthily Biased Sampling",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "70dbf6a274a72e64c0f3f37a1cfa7aa9143b4236",
    "semantic_title": "fooling shap with stealthily biased sampling",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=vPXp7K_Yhre": {
    "title": "Asynchronous Gradient Play in Zero-Sum Multi-agent Games",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d3ef760e824e685586deb2a71edb606e8e0f91c8",
    "semantic_title": "asynchronous gradient play in zero-sum multi-agent games",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=HtoA0oT30jC": {
    "title": "Novel View Synthesis with Diffusion Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "23a1b0fdb857fbbe328ffe254df33ff615acc5ea",
    "semantic_title": "novel view synthesis with diffusion models",
    "citation_count": 297,
    "authors": []
  },
  "https://openreview.net/forum?id=C_PRLz8bEJx": {
    "title": "DM-NeRF: 3D Scene Geometry Decomposition and Manipulation from 2D Images",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b068a02d484f21cec04f5f0dd62dd72deea3b0d1",
    "semantic_title": "dm-nerf: 3d scene geometry decomposition and manipulation from 2d images",
    "citation_count": 73,
    "authors": []
  },
  "https://openreview.net/forum?id=eWtMdr6yCmL": {
    "title": "Trading Information between Latents in Hierarchical Variational Autoencoders",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "858ba8166ae64b04eebc014ab3c365692c2e5a78",
    "semantic_title": "trading information between latents in hierarchical variational autoencoders",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=0paCJSFW7j": {
    "title": "ISAAC Newton: Input-based Approximate Curvature for Newton's Method",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a2ff4dc9e34635679aec4ec59367332df37d97b9",
    "semantic_title": "isaac newton: input-based approximate curvature for newton's method",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=r0xte-t40I": {
    "title": "Learning Human-Compatible Representations for Case-Based Decision Support",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f1a6d2c02c250125ad669e4f63dd44e60915de4f",
    "semantic_title": "learning human-compatible representations for case-based decision support",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=S-h1oFv-mq": {
    "title": "Long-Tailed Learning Requires Feature Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fe0630f73c9995913bf182b71305ffdf9c363637",
    "semantic_title": "long-tailed learning requires feature learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=aEFaE0W5pAd": {
    "title": "How to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ef81bbfae3c77c177e3a5fd007c8b66a2ee7322b",
    "semantic_title": "how to exploit hyperspherical embeddings for out-of-distribution detection?",
    "citation_count": 121,
    "authors": []
  },
  "https://openreview.net/forum?id=yyLvxYBJV1B": {
    "title": "AnyDA: Anytime Domain Adaptation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "60274156ef9cf5d96f0facb718483a300df83e9d",
    "semantic_title": "anyda: anytime domain adaptation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=raU07GpP0P": {
    "title": "Improving Deep Regression with Ordinal Entropy",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "29882eb4f73055cae5cb703beefff64b032471e6",
    "semantic_title": "improving deep regression with ordinal entropy",
    "citation_count": 52,
    "authors": []
  },
  "https://openreview.net/forum?id=8JqINxA-2a": {
    "title": "Unified Discrete Diffusion for Simultaneous Vision-Language Generation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0b59a2680806fe518429957a7a19a9b0e4f24e3e",
    "semantic_title": "unified discrete diffusion for simultaneous vision-language generation",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=QCrw0u9LQ7": {
    "title": "Iterative Patch Selection for High-Resolution Image Recognition",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ed4435743b661f8bbbadba78124c70dd6165c306",
    "semantic_title": "iterative patch selection for high-resolution image recognition",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=LSz-gQyd0zE": {
    "title": "Fuzzy Alignments in Directed Acyclic Graph for Non-Autoregressive Machine Translation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e47d5a56ffbe7615a910f5bfcb77237fed30cc5c",
    "semantic_title": "fuzzy alignments in directed acyclic graph for non-autoregressive machine translation",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=uhLAcrAZ9cJ": {
    "title": "Efficient Federated Domain Translation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5b144ec82ea5760cc578483aca70b3d9ef9afff4",
    "semantic_title": "efficient federated domain translation",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=4dZeBJ83oxk": {
    "title": "3D Segmenter: 3D Transformer based Semantic Segmentation via 2D Panoramic Distillation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e372ff3153fe0c8d7783416f09565c6f2f29cf94",
    "semantic_title": "3d segmenter: 3d transformer based semantic segmentation via 2d panoramic distillation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=okwxL_c4x84": {
    "title": "Clifford Neural Layers for PDE Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "84959e211a767f902cbf1695ec54a5b50148020f",
    "semantic_title": "clifford neural layers for pde modeling",
    "citation_count": 99,
    "authors": []
  },
  "https://openreview.net/forum?id=W-nZDQyuy8D": {
    "title": "GOOD: Exploring geometric cues for detecting objects in an open world",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "959c50155d0b32ef4d472cb6e5aefa9f83b03fe6",
    "semantic_title": "good: exploring geometric cues for detecting objects in an open world",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=OgbtSLESnI": {
    "title": "TabCaps: A Capsule Neural Network for Tabular Data Classification with BoW Routing",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ba3a5e59d290d192265c22efd6f2f10ce681e12d",
    "semantic_title": "tabcaps: a capsule neural network for tabular data classification with bow routing",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=-CoNloheTs": {
    "title": "An Exact Poly-Time Membership-Queries Algorithm for Extracting a Three-Layer ReLU Network",
    "volume": "poster",
    "abstract": "We consider the natural problem of learning a ReLU network from queries, which was recently remotivated by model extraction attacks. In this work, we present a polynomial-time algorithm that can learn a depth-two ReLU network from queries under mild general position assumptions. We also present a polynomial-time algorithm that, under mild general position assumptions, can learn a rich class of depth-three ReLU networks from queries. For instance, it can learn most networks where the number of first layer neurons is smaller than the dimension and the number of second layer neurons. These two results substantially improve state-of-the-art: Until our work, polynomial-time algorithms were only shown to learn from queries depth-two networks under the assumption that either the underlying distribution is Gaussian (Chen et al. (2021)) or that the weights matrix rows are linearly independent (Milli et al. (2019)). For depth three or more, there were no known poly-time results",
    "checked": false,
    "id": "5b6a6a46caac1316f268a1e6643c10b16fdaef0f",
    "semantic_title": "an exact poly-time membership-queries algorithm for extraction a three-layer relu network",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=EXnIyMVTL8s": {
    "title": "Towards Understanding and Mitigating Dimensional Collapse in Heterogeneous Federated Learning",
    "volume": "poster",
    "abstract": "Federated learning aims to train models collaboratively across different clients without sharing data for privacy considerations. However, one major challenge for this learning paradigm is the data heterogeneity problem, which refers to the discrepancies between the local data distributions among various clients. To tackle this problem, we first study how data heterogeneity affects the representations of the globally aggregated models. Interestingly, we find that heterogeneous data results in the global model suffering from severe dimensional collapse, in which representations tend to reside in a lower-dimensional space instead of the ambient space. Moreover, we observe a similar phenomenon on models locally trained on each client and deduce that the dimensional collapse on the global model is inherited from local models. In addition, we theoretically analyze the gradient flow dynamics to shed light on how data heterogeneity result in dimensional collapse for local models. To remedy this problem caused by the data heterogeneity, we propose FedDecorr, a novel method that can effectively mitigate dimensional collapse in federated learning. Specifically, FedDecorr applies a regularization term during local training that encourages different dimensions of representations to be uncorrelated. FedDecorr, which is implementation-friendly and computationally-efficient, yields consistent improvements over baselines on standard benchmark datasets. Code: https://github.com/bytedance/FedDecorr",
    "checked": true,
    "id": "d08e0c551116c325071c6fb55c33f3f958bbccb0",
    "semantic_title": "towards understanding and mitigating dimensional collapse in heterogeneous federated learning",
    "citation_count": 69,
    "authors": []
  },
  "https://openreview.net/forum?id=xI1ZTtVOtlz": {
    "title": "Evidential Uncertainty and Diversity Guided Active Learning for Scene Graph Generation",
    "volume": "poster",
    "abstract": "Scene Graph Generation (SGG) has already shown its great potential in various downstream tasks, but it comes at the price of a prohibitively expensive annotation process. To reduce the annotation cost, we propose using Active Learning (AL) for sampling the most informative data. However, directly porting current AL methods to the SGG task poses the following challenges: 1) unreliable uncertainty estimates, and 2) data bias problems. To deal with these challenges, we propose EDAL (\\textbf{E}vidential Uncertainty and \\textbf{D}iversity Guided Deep \\textbf{A}ctive \\textbf{L}earning), a novel AL framework tailored for the SGG task. For challenge 1), we start with Evidential Deep Learning (EDL) coupled with a global relationship mining approach to estimate uncertainty, which can effectively overcome the perturbations of open-set relationships and background-relationships to obtain reliable uncertainty estimates. To address challenge 2), we seek the diversity-based method and design the Context Blocking Module (CBM) and Image Blocking Module (IBM) to alleviate context-level bias and image-level bias, respectively. Experiments show that our AL framework can approach the performance of a fully supervised SGG model with only about $10\\%$ annotation cost. Furthermore, our ablation studies indicate that introducing AL into the SGG will face many challenges not observed in other vision tasks that are successfully overcome by our new modules",
    "checked": true,
    "id": "ccb3742687c6458f9c7aa608c62502b44ac22721",
    "semantic_title": "evidential uncertainty and diversity guided active learning for scene graph generation",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=socffUzSIlx": {
    "title": "Anisotropic Message Passing: Graph Neural Networks with Directional and Long-Range Interactions",
    "volume": "poster",
    "abstract": "Graph neural networks have shown great potential for the description of a variety of chemical systems. However, standard message passing does not explicitly account for long-range and directional interactions, for instance due to electrostatics. In this work, an anisotropic state based on Cartesian multipoles is proposed as an addition to the existing hidden features. With the anisotropic state, message passing can be modified to explicitly account for directional interactions. Compared to existing models, this modification results in relatively little additional computational cost. Most importantly, the proposed formalism offers as a distinct advantage the seamless integration of (1) anisotropic long-range interactions, (2) interactions with surrounding fields and particles that are not part of the graph, and (3) the fast multipole method. As an exemplary use case, the application to quantum mechanics/molecular mechanics (QM/MM) systems is demonstrated",
    "checked": true,
    "id": "899620f76f3a5f0d235a93d8d74caa2a4f26edfb",
    "semantic_title": "anisotropic message passing: graph neural networks with directional and long-range interactions",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=_8mS2NE-HXN": {
    "title": "SYNC: SAFETY-AWARE NEURAL CONTROL FOR STABILIZING STOCHASTIC DELAY-DIFFERENTIAL EQUATIONS",
    "volume": "poster",
    "abstract": "Stabilization of the systems described by \\textit{stochastic delay}-differential equations (SDDEs) under preset conditions is a challenging task in the control community. Here, to achieve this task, we leverage neural networks to learn control policies using the information of the controlled systems in some prescribed regions. Specifically, two learned control policies, i.e., the neural deterministic controller (NDC) and the neural stochastic controller (NSC), work effectively in the learning procedures that rely on, respectively, the well-known LaSalle-type theorem and the newly-established theorem for guaranteeing the stochastic stability in SDDEs. We theoretically investigate the performance of the proposed controllers in terms of convergence time and energy cost. More practically and significantly, we improve our learned control policies through considering the situation where the controlled trajectories only evolve in some specific safety set. {\\color{black} The practical validity of such control policies restricted in safety set is attributed to the theory that we further develop for safety and stability guarantees in SDDEs using the stochastic control barrier function and the spatial discretization}. We call this control as SYNC (\\textbf{S}afet\\textbf{Y}-aware \\textbf{N}eural \\textbf{C}ontrol). The efficacy of all the articulated control policies, including the SYNC, is demonstrated systematically by using representative control problems",
    "checked": true,
    "id": "33f9b3acdfb95cf13e598400ca489415820e1e8b",
    "semantic_title": "sync: safety-aware neural control for stabilizing stochastic delay-differential equations",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=1J-ZTr7aypY": {
    "title": "Differentiable Mathematical Programming for Object-Centric Representation Learning",
    "volume": "poster",
    "abstract": "We propose topology-aware feature partitioning into $k$ disjoint partitions for given scene features as a method for object-centric representation learning. To this end, we propose to use minimum $s$-$t$ graph cuts as a partitioning method which is represented as a linear program. The method is topologically aware since it explicitly encodes neighborhood relationships in the image graph. To solve the graph cuts our solution relies on an efficient, scalable, and differentiable quadratic programming approximation. Optimizations specific to cut problems allow us to solve the quadratic programs and compute their gradients significantly more efficiently compared with the general quadratic programming approach. Our results show that our approach is scalable and outperforms existing methods on object discovery tasks with textured scenes and objects",
    "checked": true,
    "id": "c157a09658c6e71e4e3d10939d8160af463a31a0",
    "semantic_title": "differentiable mathematical programming for object-centric representation learning",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=p8hMBcPtvju": {
    "title": "Scalable Subset Sampling with Neural Conditional Poisson Networks",
    "volume": "poster",
    "abstract": "A number of problems in learning can be formulated in terms of the basic primitive of sampling $k$ elements out of a universe of $n$ elements. This subset sampling operation cannot directly be included in differentiable models and approximations are essential. Current approaches take an \\emph{order sampling} approach to sampling subsets and depend on differentiable approximations of the Top-$k$ operator for selecting the largest $k$ elements from a set. We present a simple alternative method for sampling subsets based on \\emph{conditional Poisson sampling}. Unlike order sampling approaches, the parallel complexity of the proposed method is independent of the subset size which makes the method scalable to large subset sizes. We adapt the procedure to make it efficient and amenable to discrete gradient approximations for use in differentiable models. Furthermore, the method also allows the subset size parameter $k$ to be differentiable. We demonstrate our approach on model explanation, image sub-sampling and stochastic $k$-nearest neighbor tasks outperforming existing methods in accuracy, efficiency and scalability",
    "checked": true,
    "id": "10d05e55fbfdb79787cccd8abed439673d459abd",
    "semantic_title": "scalable subset sampling with neural conditional poisson networks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=FRLswckPXQ5": {
    "title": "Improved Convergence of Differential Private SGD with Gradient Clipping",
    "volume": "poster",
    "abstract": "Differential private stochastic gradient descent (DP-SGD) with gradient clipping (DP-SGD-GC) is an effective optimization algorithm that can train machine learning models with a privacy guarantee. Despite the popularity of DP-SGD-GC, its convergence in unbounded domain without the Lipschitz continuous assumption is less-understood; existing analysis of DP-SGD-GC either impose additional assumptions or end up with an utility bound that involves an non-vanishing bias term. In this work, for smooth and unconstrained problems, we improve the current analysis and show that DP-SGD-GC can achieve a vanishing utility bound without any bias term. Furthermore, when the noise generated from subsampled gradients is light-tailed, we prove that DP-SGD-GC can achieve nearly the same utility bound as DP-SGD applies to the Lipschitz continuous objectives. As a by-product, we propose a new clipping technique, called value clipping, to mitigate the computational overhead caused by the classic gradient clipping. Experiments on standard benchmark datasets are conducted to support our analysis",
    "checked": true,
    "id": "79126e73eaeb5056e2e8b443b991a29a755eee29",
    "semantic_title": "improved convergence of differential private sgd with gradient clipping",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=2vmGv5wPDBZ": {
    "title": "Learning to Estimate Single-View Volumetric Flow Motions without 3D Supervision",
    "volume": "poster",
    "abstract": "We address the challenging problem of jointly inferring the 3D flow and volumetric densities moving in a fluid from a monocular input video with a deep neural network. Despite the complexity of this task, we show that it is possible to train the corresponding networks without requiring any 3D ground truth for training. In the absence of ground truth data we can train our model with observations from real-world capture setups instead of relying on synthetic reconstructions. We make this unsupervised training approach possible by first generating an initial prototype volume which is then moved and transported over time without the need for volumetric supervision. Our approach relies purely on image-based losses, an adversarial discriminator network, and regularization. Our method can estimate long-term sequences in a stable manner, while achieving closely matching targets for inputs such as rising smoke plumes",
    "checked": true,
    "id": "83d03f25d2e7e4139662943bda92f8907e7f8554",
    "semantic_title": "learning to estimate single-view volumetric flow motions without 3d supervision",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=n0Pb9T5kmb": {
    "title": "ArCL: Enhancing Contrastive Learning with Augmentation-Robust Representations",
    "volume": "poster",
    "abstract": "Self-Supervised Learning (SSL) is a paradigm that leverages unlabeled data for model training. Empirical studies show that SSL can achieve promising performance in distribution shift scenarios, where the downstream and training distributions differ. However, the theoretical understanding of its transferability remains limited. In this paper, we develop a theoretical framework to analyze the transferability of self-supervised contrastive learning, by investigating the impact of data augmentation on it. Our results reveal that the downstream performance of contrastive learning depends largely on the choice of data augmentation. Moreover, we show that contrastive learning fails to learn domain-invariant features, which limits its transferability. Based on these theoretical insights, we propose a novel method called Augmentation-robust Contrastive Learning (ArCL), which guarantees to learn domain-invariant features and can be easily integrated with existing contrastive learning algorithms. We conduct experiments on several datasets and show that ArCL significantly improves the transferability of contrastive learning",
    "checked": true,
    "id": "03955eca48b8e20b1860114df640f801785fb731",
    "semantic_title": "arcl: enhancing contrastive learning with augmentation-robust representations",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=ejHUr4nfHhD": {
    "title": "Temperature Schedules for self-supervised contrastive methods on long-tail data",
    "volume": "poster",
    "abstract": "Most approaches for self-supervised learning (SSL) are optimised on curated balanced datasets, e.g. ImageNet, despite the fact that natural data usually exhibits long-tail distributions. In this paper, we analyse the behaviour of one of the most popular variants of SSL, i.e. contrastive methods, on imbalanced data. In particular, we investigate the role of the temperature parameter $\\tau$ in the contrastive loss, by analysing the loss through the lens of average distance maximisation, and find that a large $\\tau$ emphasises group-wise discrimination, whereas a small $\\tau$ leads to a higher degree of instance discrimination. While $\\tau$ has thus far been treated exclusively as a constant hyperparameter, in this work, we propose to employ a dynamic $\\tau$ and show that a simple cosine schedule can yield significant improvements in the learnt representations. Such a schedule results in a constant `task switching' between an emphasis on instance discrimination and group-wise discrimination and thereby ensures that the model learns both group-wise features, as well as instance-specific details. Since frequent classes benefit from the former, while infrequent classes require the latter, we find this method to consistently improve separation between the classes in long-tail data without any additional computational cost",
    "checked": true,
    "id": "fd4f02958c6454d67a0caa0e9166f4eccd2df57b",
    "semantic_title": "temperature schedules for self-supervised contrastive methods on long-tail data",
    "citation_count": 53,
    "authors": []
  },
  "https://openreview.net/forum?id=OoOIW-3uadi": {
    "title": "Deep Learning on Implicit Neural Representations of Shapes",
    "volume": "poster",
    "abstract": "Implicit Neural Representations (INRs) have emerged in the last few years as a powerful tool to encode continuously a variety of different signals like images, videos, audio and 3D shapes. When applied to 3D shapes, INRs allow to overcome the fragmentation and shortcomings of the popular discrete representations used so far. Yet, considering that INRs consist in neural networks, it is not clear whether and how it may be possible to feed them into deep learning pipelines aimed at solving a downstream task. In this paper, we put forward this research problem and propose inr2vec, a framework that can compute a compact latent representation for an input INR in a single inference pass. We verify that inr2vec can embed effectively the 3D shapes represented by the input INRs and show how the produced embeddings can be fed into deep learning pipelines to solve several tasks by processing exclusively INRs",
    "checked": true,
    "id": "7d03af1ccf5404e23bee02903b41850e88cc8590",
    "semantic_title": "deep learning on implicit neural representations of shapes",
    "citation_count": 54,
    "authors": []
  },
  "https://openreview.net/forum?id=9MbhFHqrti9": {
    "title": "ImaginaryNet: Learning Object Detectors without Real Images and Annotations",
    "volume": "poster",
    "abstract": "Without the demand of training in reality, humans are able of detecting a new category of object simply based on the language description on its visual characteristics. Empowering deep learning with this ability undoubtedly enables the neural network to handle complex vision tasks, e.g., object detection, without collecting and annotating real images. To this end, this paper introduces a novel challenging learning paradigm Imaginary-Supervised Object Detection (ISOD), where neither real images nor manual annotations are allowed for training object detectors. To resolve this challenge, we propose ImaginaryNet, a framework to synthesize images by combining pretrained language model and text-to-image synthesis model. Given a class label, the language model is used to generate a full description of a scene with a target object, and the text-to-image model is deployed to generate a photo-realistic image. With the synthesized images and class labels, weakly supervised object detection can then be leveraged to accomplish ISOD. By gradually introducing real images and manual annotations, ImaginaryNet can collaborate with other supervision settings to further boost detection performance. Experiments show that ImaginaryNet can (i) obtain about 75% performance in ISOD compared with the weakly supervised counterpart of the same backbone trained on real data, (ii) significantly improve the baseline while achieving state-of-the-art or comparable performance by incorporating ImaginaryNet with other supervision settings. Our code will be publicly available at https://github.com/kodenii/ImaginaryNet",
    "checked": true,
    "id": "ec22c5a091191ad78ab4ae6b57fd9e0bfd1f26af",
    "semantic_title": "imaginarynet: learning object detectors without real images and annotations",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=UT-_SVOyD1H": {
    "title": "Contextual bandits with concave rewards, and an application to fair ranking",
    "volume": "poster",
    "abstract": "We consider Contextual Bandits with Concave Rewards (CBCR), a multi-objective bandit problem where the desired trade-off between the rewards is defined by a known concave objective function, and the reward vector depends on an observed stochastic context. We present the first algorithm with provably vanishing regret for CBCR without restrictions on the policy space, whereas prior works were restricted to finite policy spaces or tabular representations. Our solution is based on a geometric interpretation of CBCR algorithms as optimization algorithms over the convex set of expected rewards spanned by all stochastic policies. Building on Frank-Wolfe analyses in constrained convex optimization, we derive a novel reduction from the CBCR regret to the regret of a \\emph{scalar-reward} bandit problem. We illustrate how to apply the reduction off-the-shelf to obtain algorithms for CBCR with both linear and general reward functions, in the case of non-combinatorial actions. Motivated by fairness in recommendation, we describe a special case of CBCR with rankings and fairness-aware objectives, leading to the first algorithm with regret guarantees for contextual combinatorial bandits with fairness of exposure",
    "checked": true,
    "id": "89e6f8ce0079de9931493494d27bb9d3e36bd522",
    "semantic_title": "contextual bandits with concave rewards, and an application to fair ranking",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=3VKiaagxw1S": {
    "title": "Gradient Boosting Performs Gaussian Process Inference",
    "volume": "poster",
    "abstract": "This paper shows that gradient boosting based on symmetric decision trees can be equivalently reformulated as a kernel method that converges to the solution of a certain Kernel Ridge Regression problem. Thus, we obtain the convergence to a Gaussian Process' posterior mean, which, in turn, allows us to easily transform gradient boosting into a sampler from the posterior to provide better knowledge uncertainty estimates through Monte-Carlo estimation of the posterior variance. We show that the proposed sampler allows for better knowledge uncertainty estimates leading to improved out-of-domain detection",
    "checked": true,
    "id": "0136cc23c0f6e6c1f2647f1190a9978b3b7396b5",
    "semantic_title": "gradient boosting performs gaussian process inference",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=TrwE8l9aJzs": {
    "title": "Learning Zero-Shot Cooperation with Humans, Assuming Humans Are Biased",
    "volume": "poster",
    "abstract": "There is a recent trend of applying multi-agent reinforcement learning (MARL) to train an agent that can cooperate with humans in a zero-shot fashion without using any human data. The typical workflow is to first repeatedly run self-play (SP) to build a policy pool and then train the final adaptive policy against this pool. A crucial limitation of this framework is that every policy in the pool is optimized w.r.t. the environment reward function, which implicitly assumes that the testing partners of the adaptive policy will be precisely optimizing the same reward function as well. However, human objectives are often substantially biased according to their own preferences, which can differ greatly from the environment reward. We propose a more general framework, Hidden-Utility Self-Play (HSP), which explicitly models human biases as hidden reward functions in the self-play objective. By approximating the reward space as linear functions, HSP adopts an effective technique to generate an augmented policy pool with biased policies. We evaluate HSP on the Overcooked benchmark. Empirical results show that our HSP method produces higher rewards than baselines when cooperating with learned human models, manually scripted policies, and real humans. The HSP policy is also rated as the most assistive policy based on human feedback",
    "checked": true,
    "id": "c093f1f59f6197d6186e78872ba9ae863d89f4e1",
    "semantic_title": "learning zero-shot cooperation with humans, assuming humans are biased",
    "citation_count": 46,
    "authors": []
  },
  "https://openreview.net/forum?id=ZW5aK4yCRqU": {
    "title": "Modelling Long Range Dependencies in $N$D: From Task-Specific to a General Purpose CNN",
    "volume": "poster",
    "abstract": "Performant Convolutional Neural Network (CNN) architectures must be tailored to specific tasks in order to consider the length, resolution, and dimensionality of the input data. In this work, we tackle the need for problem-specific CNN architectures. We present the Continuous Convolutional Neural Network (CCNN): a single CNN able to process data of arbitrary resolution, dimensionality and length without any structural changes. Its key component are its continuous convolutional kernels which model long-range dependencies at every layer, and thus remove the need of current CNN architectures for task-dependent downsampling and depths. We showcase the generality of our method by using the same architecture for tasks on sequential ($1{\\rm D}$), visual ($2{\\rm D}$) and point-cloud ($3{\\rm D}$) data. Our CCNN matches and often outperforms the current state-of-the-art across all tasks considered",
    "checked": false,
    "id": "edd23cff90be3f27e50e74d7b24cd0ca92370bbd",
    "semantic_title": "modelling long range dependencies in n-d: from task-specific to a general purpose cnn",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=Pia70sP2Oi1": {
    "title": "Planckian Jitter: countering the color-crippling effects of color jitter on self-supervised training",
    "volume": "poster",
    "abstract": "Several recent works on self-supervised learning are trained by mapping different augmentations of the same image to the same feature representation. The data augmentations used are of crucial importance to the quality of learned feature representations. In this paper, we analyze how the color jitter traditionally used in data augmentation negatively impacts the quality of the color features in learned feature representations. To address this problem, we propose a more realistic, physics-based color data augmentation - which we call Planckian Jitter - that creates realistic variations in chromaticity and produces a model robust to illumination changes that can be commonly observed in real life, while maintaining the ability to discriminate image content based on color information. Experiments confirm that such a representation is complementary to the representations learned with the currently-used color jitter augmentation and that a simple concatenation leads to significant performance gains on a wide range of downstream datasets. In addition, we present a color sensitivity analysis that documents the impact of different training methods on model neurons and shows that the performance of the learned features is robust with respect to illuminant variations. Official code available at: https://github.com/TheZino/PlanckianJitter",
    "checked": true,
    "id": "0e4fb0b0efb34f4e76f2c25c38d6619c411641e4",
    "semantic_title": "planckian jitter: countering the color-crippling effects of color jitter on self-supervised training",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=iLMgk2IGNyv": {
    "title": "GAMR: A Guided Attention Model for (visual) Reasoning",
    "volume": "poster",
    "abstract": "Humans continue to outperform modern AI systems in their ability to flexibly parse and understand complex visual scenes. Here, we present a novel module for visual reasoning, the Guided Attention Model for (visual) Reasoning ($\\textit{GAMR}$), which instantiates an active vision theory -- positing that the brain solves complex visual reasoning problems dynamically -- via sequences of attention shifts to select and route task-relevant visual information into memory. Experiments on an array of visual reasoning tasks and datasets demonstrate GAMR's ability to learn visual routines in a robust and sample-efficient manner. In addition, GAMR is shown to be capable of zero-shot generalization on completely novel reasoning tasks. Overall, our work provides computational support for cognitive theories that postulate the need for a critical interplay between attention and memory to dynamically maintain and manipulate task-relevant visual information to solve complex visual reasoning tasks",
    "checked": true,
    "id": "d5bd67e5d438ee81f0f098ccbaf91246f6409c10",
    "semantic_title": "gamr: a guided attention model for (visual) reasoning",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=IpGgfpMucHj": {
    "title": "Voint Cloud: Multi-View Point Cloud Representation for 3D Understanding",
    "volume": "poster",
    "abstract": "Multi-view projection methods have demonstrated promising performance on 3D understanding tasks like 3D classification and segmentation. However, it remains unclear how to combine such multi-view methods with the widely available 3D point clouds. Previous methods use unlearned heuristics to combine features at the point level. To this end, we introduce the concept of the multi-view point cloud (Voint cloud), representing each 3D point as a set of features extracted from several view-points. This novel 3D Voint cloud representation combines the compactness of 3D point cloud representation with the natural view-awareness of multi-view representation. Naturally, we can equip this new representation with convolutional and pooling operations. We deploy a Voint neural network (VointNet) to learn representations in the Voint space. Our novel representation achieves state-of-the-art performance on 3D classification, shape retrieval, and robust 3D part segmentation on standard benchmarks ( ScanObjectNN, ShapeNet Core55, and ShapeNet Parts). Further analysis shows that VointNet improves the robustness to occlusion compared to other methods",
    "checked": true,
    "id": "e91bed2d7193ec4f28e8abca9d034bc8f659379e",
    "semantic_title": "voint cloud: multi-view point cloud representation for 3d understanding",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=-jP_rDkyfpI": {
    "title": "Approximate Nearest Neighbor Search through Modern Error-Correcting Codes",
    "volume": "poster",
    "abstract": "A locality-sensitive hash (or LSH) is a function that can efficiently map dataset points into a latent space while preserving pairwise distances. Such LSH functions have been used in approximate nearest-neighbor search (ANNS) in the following classic way, which we call classic hash clustering (CHC): first, the dataset points are hashed into a low-dimensional binary space using the LSH function; then, the points are clustered by these hash values. Upon receiving a query, its nearest neighbors are sought within its hash-cluster and nearby hash-clusters (i.e., multi-probe). However, CHC mandates a low-dimensional latent space for the LSH function, which distorts distances from the (high-dimensional) original real space; this results in inferior recall. This is often mitigated through using multiple hash tables at additional storage and memory costs. In this paper, we introduce a better way of using LSH functions for ANNS. Our method, called the Polar Code Nearest-Neighbor (PCNN) algorithm, uses modern error-correcting codes (specifically polar codes) to maintain a manageable number of clusters inside a high-dimensional latent space. Allowing the LSH function to embed into this high-dimensional latent space results in higher recall, as the embedding faithfully captures distances in the original space. The crux of PCNN is using polar codes for probing: we present a multi-probe scheme for PCNN which uses efficient list-decoding methods for polar codes, with time complexity independent of the dataset size. Fixing the choice of LSH, experiment results demonstrate significant performance gains of PCNN over CHC; in particular, PCNN with a single table outperforms CHC with multiple tables, obviating the need for large memory and storage",
    "checked": true,
    "id": "f2f10c9742cf93d508aec74b83c5d2e8a9a4fdbc",
    "semantic_title": "approximate nearest neighbor search through modern error-correcting codes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q8vgHfPdoQP": {
    "title": "When to Make and Break Commitments?",
    "volume": "poster",
    "abstract": "In many scenarios, decision-makers must commit to long-term actions until their resolution before receiving the payoff of said actions, and usually, staying committed to such actions incurs continual costs. For instance, in healthcare, a newly-discovered treatment cannot be marketed to patients until a clinical trial is conducted, which both requires time and is also costly. Of course in such scenarios, not all commitments eventually pay off. For instance, a clinical trial might end up failing to show efficacy. Given the time pressure created by the continual cost of keeping a commitment, we aim to answer: When should a decision-maker break a commitment that is likely to fail—either to make an alternative commitment or to make no further commitments at all? First, we formulate this question as a new type of optimal stopping/switching problem called the optimal commitment problem (OCP). Then, we theoretically analyze OCP, and based on the insights we gain, propose a practical algorithm for solving it. Finally, we empirically evaluate the performance of our algorithm in running clinical trials with subpopulation selection",
    "checked": true,
    "id": "0f21f1bde0908da68280511159d092d7f068c155",
    "semantic_title": "when to make and break commitments?",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=QUK1ExlbbA": {
    "title": "DENSE RGB SLAM WITH NEURAL IMPLICIT MAPS",
    "volume": "poster",
    "abstract": "There is an emerging trend of using neural implicit functions for map representation in Simultaneous Localization and Mapping (SLAM). Some pioneer works have achieved encouraging results on RGB-D SLAM. In this paper, we present a dense RGB SLAM method with neural implicit map representation. To reach this challenging goal without depth input, we introduce a hierarchical feature volume to facilitate the implicit map decoder. This design effectively fuses shape cues across different scales to facilitate map reconstruction. Our method simultaneously solves the camera motion and the neural implicit map by matching the rendered and input video frames. To facilitate optimization, we further propose a photometric warping loss in the spirit of multi-view stereo to better constrain the camera pose and scene geometry. We evaluate our method on commonly used benchmarks and compare it with modern RGB and RGB-D SLAM systems. Our method achieves favorable results than previous methods and even surpasses some recent RGB-D SLAM methods.The code is at poptree.github.io/DIM-SLAM/",
    "checked": true,
    "id": "f3168e3b02757b533503f1c0858e63ccfbee1c84",
    "semantic_title": "dense rgb slam with neural implicit maps",
    "citation_count": 54,
    "authors": []
  },
  "https://openreview.net/forum?id=-iADdfa4GKH": {
    "title": "Monocular Scene Reconstruction with 3D SDF Transformers",
    "volume": "poster",
    "abstract": "Monocular scene reconstruction from posed images is challenging due to the complexity of a large environment. Recent volumetric methods learn to directly predict the TSDF volume and have demonstrated promising results in this task. However, most methods focus on how to extract and fuse the 2D features to a 3D feature volume, but none of them improve the way how the 3D volume is aggregated. In this work, we propose an SDF transformer network, which replaces the role of 3D CNN for better 3D feature aggregation. To reduce the explosive computation complexity of the 3D multi-head attention, we propose a sparse window attention module, where the attention is only calculated between the non-empty voxels within a local window. Then a top-down-bottom-up 3D attention network is built for 3D feature aggregation, where a dilate-attention structure is proposed to prevent geometry degeneration, and two global modules are employed to equip with global receptive fields. The experiments on multiple datasets show that this 3D transformer network generates a more accurate and complete reconstruction, which outperforms previous methods by a large margin. Remarkably, the mesh accuracy is improved by 41.8%, and the mesh completeness is improved by 25.3% on the ScanNet dataset. The code of our method will be made public",
    "checked": true,
    "id": "fa80130a2d977028105b7c6eb49c04c36d8642c8",
    "semantic_title": "monocular scene reconstruction with 3d sdf transformers",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=qU6NIcpaSi-": {
    "title": "Learning Heterogeneous Interaction Strengths by Trajectory Prediction with Graph Neural Network",
    "volume": "poster",
    "abstract": "Dynamical systems with interacting agents are universal in nature, commonly modeled by a graph of relationships between their constituents. Recently, various works have been presented to tackle the problem of inferring those relationships from the system trajectories via deep neural networks, but most of the studies assume binary or discrete types of interactions for simplicity. In the real world, the interaction kernels often involve continuous interaction strengths, which cannot be accurately approximated by discrete relations. In this work, we propose the relational attentive inference network (RAIN) to infer continuously weighted interaction graphs without any ground-truth interaction strengths. Our model employs a novel pairwise attention (PA) mechanism to refine the trajectory representations and a graph transformer to extract heterogeneous interaction weights for each pair of agents. We show that our RAIN model with the PA mechanism accurately infers continuous interaction strengths for simulated physical systems in an unsupervised manner. Further, RAIN with PA successfully predicts trajectories from motion capture data with an interpretable interaction graph, demonstrating the virtue of modeling unknown dynamics with continuous weights",
    "checked": true,
    "id": "4f27abca5ea9644dd572c0f9879fecac0e60e998",
    "semantic_title": "learning heterogeneous interaction strengths by trajectory prediction with graph neural network",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=B8a1FcY0vi": {
    "title": "From $t$-SNE to UMAP with contrastive learning",
    "volume": "poster",
    "abstract": "Neighbor embedding methods $t$-SNE and UMAP are the de facto standard for visualizing high-dimensional datasets. Motivated from entirely different viewpoints, their loss functions appear to be unrelated. In practice, they yield strongly differing embeddings and can suggest conflicting interpretations of the same data. The fundamental reasons for this and, more generally, the exact relationship between $t$-SNE and UMAP have remained unclear. In this work, we uncover their conceptual connection via a new insight into contrastive learning methods. Noise-contrastive estimation can be used to optimize $t$-SNE, while UMAP relies on negative sampling, another contrastive method. We find the precise relationship between these two contrastive methods, and provide a mathematical characterization of the distortion introduced by negative sampling. Visually, this distortion results in UMAP generating more compact embeddings with tighter clusters compared to $t$-SNE. We exploit this new conceptual connection to propose and implement a generalization of negative sampling, allowing us to interpolate between (and even extrapolate beyond) $t$-SNE and UMAP and their respective embeddings. Moving along this spectrum of embeddings leads to a trade-off between discrete / local and continuous / global structures, mitigating the risk of over-interpreting ostensible features of any single embedding. We provide a PyTorch implementation",
    "checked": true,
    "id": "8ca5aa0dee4cfdfda8cf02df4ae6d298b1dc308f",
    "semantic_title": "from $t$-sne to umap with contrastive learning",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=5fvXH49wk2": {
    "title": "D4AM: A General Denoising Framework for Downstream Acoustic Models",
    "volume": "poster",
    "abstract": "The performance of acoustic models degrades notably in noisy environments. Speech enhancement (SE) can be used as a front-end strategy to aid automatic speech recognition (ASR) systems. However, existing training objectives of SE methods are not fully effective at integrating speech-text and noise-clean paired data for training toward unseen ASR systems. In this study, we propose a general denoising framework, D4AM, for various downstream acoustic models. Our framework fine-tunes the SE model with the backward gradient according to a specific acoustic model and the corresponding classification objective. In addition, our method aims to consider the regression objective as an auxiliary loss to make the SE model generalize to other unseen acoustic models. To jointly train an SE unit with regression and classification objectives, D4AM uses an adjustment scheme to directly estimate suitable weighting coefficients rather than undergoing a grid search process with additional training costs. The adjustment scheme consists of two parts: gradient calibration and regression objective weighting. The experimental results show that D4AM can consistently and effectively provide improvements to various unseen acoustic models and outperforms other combination setups. Specifically, when evaluated on the Google ASR API with real noisy data completely unseen during SE training, D4AM achieves a relative WER reduction of 24.65% compared with the direct feeding of noisy input. To our knowledge, this is the first work that deploys an effective combination scheme of regression (denoising) and classification (ASR) objectives to derive a general pre-processor applicable to various unseen ASR systems. Our code is available at https://github.com/ChangLee0903/D4AM",
    "checked": true,
    "id": "289e78fd432cd3c00ebab014fa7d23c4fab40418",
    "semantic_title": "d4am: a general denoising framework for downstream acoustic models",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=lq62uWRJjiY": {
    "title": "Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning",
    "volume": "poster",
    "abstract": "Fine-tuning large pre-trained language models on downstream tasks has become an important paradigm in NLP. However, common practice fine-tunes all of the parameters in a pre-trained model, which becomes prohibitive when a large number of downstream tasks are present. Therefore, many fine-tuning methods are proposed to learn incremental updates of pre-trained weights in a parameter efficient way, e.g., low-rank increments. These methods often evenly distribute the budget of incremental updates across all pre-trained weight matrices, and overlook the varying importance of different weight parameters. As a consequence, the fine-tuning performance is suboptimal. To bridge this gap, we propose AdaLoRA, which adaptively allocates the parameter budget among weight matrices according to their importance score. In particular, AdaLoRA parameterizes the incremental updates in the form of singular value decomposition. Such a novel approach allows us to effectively prune the singular values of unimportant updates, which is essentially to reduce their parameter budget but circumvent intensive exact SVD computations. We conduct extensive experiments with several pre-trained models on natural language processing, question answering, and natural language generation to validate the effectiveness of AdaLoRA. Results demonstrate that AdaLoRA manifests notable improvement over baselines, especially in the low budget settings. Our code is publicly available at https://github.com/QingruZhang/AdaLoRA",
    "checked": true,
    "id": "5ef82a8c8aa50f99285f2143b57ca4e82da1af80",
    "semantic_title": "adaptive budget allocation for parameter-efficient fine-tuning",
    "citation_count": 515,
    "authors": []
  },
  "https://openreview.net/forum?id=6ZajpxqTlQ": {
    "title": "Generalize Learned Heuristics to Solve Large-scale Vehicle Routing Problems in Real-time",
    "volume": "poster",
    "abstract": "Large-scale Vehicle Routing Problems (VRPs) are widely used in logistics, transportation, supply chain, and robotic systems. Recently, data-driven VRP heuristics are proposed to generate real-time VRP solutions with up to 100 nodes. Despite this progress, current heuristics for large-scale VRPs still face three major challenges: 1) Difficulty in generalizing the heuristics learned on small-scale VRPs to large-scale VRPs without retraining; 2) Challenge in generating real-time solutions for large-scale VRPs; 3) Difficulty in embedding global constraints into learned heuristics. We contribute in the three directions: We propose a Two-stage Divide Method (TAM) to generate sub-route sequence rather than node sequence for generalizing the heuristics learned on small-scale VRPs to solve large-scale VRPs in real-time. A two-step reinforcement learning method with new reward and padding techniques is proposed to train our TAM. A global mask function is proposed to keep the global constraints satisfied when dividing a large-scale VRP into several small-scale Traveling Salesman Problems (TSPs). As result, we can solve the small-scale TSPs in parallel quickly. The experiments on synthetic and real-world large-scale VRPs show our method could generalize the learned heuristics trained on datasets of VRP 100 to solve VRPs with over 5000 nodes in real-time while keeping the solution quality better than data-driven heuristics and competitive with traditional heuristics",
    "checked": true,
    "id": "bdd83f76787abb6f8bc1865291a7d33d3e9a6788",
    "semantic_title": "generalize learned heuristics to solve large-scale vehicle routing problems in real-time",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=XDJwuEYHhme": {
    "title": "Towards the Generalization of Contrastive Self-Supervised Learning",
    "volume": "poster",
    "abstract": "Recently, self-supervised learning has attracted great attention, since it only requires unlabeled data for model training. Contrastive learning is one popular method for self-supervised learning and has achieved promising empirical performance. However, the theoretical understanding of its generalization ability is still limited. To this end, we define a kind of $(\\sigma,\\delta)$-measure to mathematically quantify the data augmentation, and then provide an upper bound of the downstream classification error rate based on the measure. It reveals that the generalization ability of contrastive self-supervised learning is related to three key factors: alignment of positive samples, divergence of class centers, and concentration of augmented data. The first two factors are properties of learned representations, while the third one is determined by pre-defined data augmentation. We further investigate two canonical contrastive losses, InfoNCE and cross-correlation, to show how they provably achieve the first two factors. Moreover, we conduct experiments to study the third factor, and observe a strong correlation between downstream performance and the concentration of augmented data",
    "checked": true,
    "id": "3ed2b5a9c8e42f3bf93dfd40426e4df205420ac7",
    "semantic_title": "towards the generalization of contrastive self-supervised learning",
    "citation_count": 126,
    "authors": []
  },
  "https://openreview.net/forum?id=QUaDoIdgo0": {
    "title": "CO3: Cooperative Unsupervised 3D Representation Learning for Autonomous Driving",
    "volume": "poster",
    "abstract": "Unsupervised contrastive learning for indoor-scene point clouds has achieved great successes. However, unsupervised representation learning on outdoor-scene point clouds remains challenging because previous methods need to reconstruct the whole scene and capture partial views for the contrastive objective. This is infeasible in outdoor scenes with moving objects, obstacles, and sensors. In this paper, we propose CO3, namely {Co}operative {Co}ntrastive Learning and {Co}ntextual Shape Prediction, to learn 3D representation for outdoor-scene point clouds in an unsupervised manner. CO3 has several merits compared to existing methods. (1) It utilizes LiDAR point clouds from vehicle-side and infrastructure-side to build views that differ enough but meanwhile maintain common semantic information for contrastive learning, which are more appropriate than views built by previous methods. (2) Alongside the contrastive objective, we propose contextual shape prediction to bring more task-relevant information for unsupervised 3D point cloud representation learning and we also provide a theoretical analysis for this pre-training goal. (3) As compared to previous methods, representation learned by CO3 is able to be transferred to different outdoor scene dataset collected by different type of LiDAR sensors. (4) CO3 improves current state-of-the-art methods on Once, KITTI and NuScenes datasets by up to 2.58 mAP in 3D object detection task and 3.54 mIoU in LiDAR semantic segmentation task. Codes and models will be released",
    "checked": true,
    "id": "c5700d02e952352af702eb3c68ac1af75b932c42",
    "semantic_title": "co3: cooperative unsupervised 3d representation learning for autonomous driving",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=SbR9mpTuBn": {
    "title": "Bag of Tricks for Unsupervised Text-to-Speech",
    "volume": "poster",
    "abstract": "Unsupervised text-to-speech (TTS) aims to train TTS models for a specific language without any paired speech-text training data in that language. Existing methods either use speech and corresponding pseudo text generated by an unsupervised automatic speech recognition (ASR) model as training data, or employ the back-translation technique. Though effective, they suffer from low robustness to low-quality data and heavy dependence on the lexicon of a language that is sometimes unavailable, leading to difficulty in convergence, especially in low-resource language scenarios. In this work, we introduce a bag of tricks to enable effective unsupervised TTS. Specifically, 1) we carefully design a voice conversion model to normalize the variable and noisy information in the low-quality speech data while preserving the pronunciation information; 2) we employ the non-autoregressive TTS model to overcome the robustness issue; and 3) we explore several tricks applied in back-translation, including curriculum learning, length augmentation and auxiliary supervised loss to stabilize the back-translation and improve its effectiveness. Through experiments, it has been demonstrated that our method achieves better intelligibility and audio quality than all previous methods, and that these tricks are very essential to the performance gain",
    "checked": true,
    "id": "d491df0a4f65152701e968dfe13f9bc8640303ac",
    "semantic_title": "bag of tricks for unsupervised text-to-speech",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=bZjxxYURKT": {
    "title": "FedSpeed: Larger Local Interval, Less Communication Round, and Higher Generalization Accuracy",
    "volume": "poster",
    "abstract": "Federated learning (FL) is an emerging distributed machine learning framework which jointly trains a global model via a large number of local devices with data privacy protections. Its performance suffers from the non-vanishing biases introduced by the local inconsistent optimal and the rugged client-drifts by the local over-fitting. In this paper, we propose a novel and practical method, FedSpeed, to alleviate the negative impacts posed by these problems. Concretely, FedSpeed applies the prox-correction term on the current local updates to efficiently reduce the biases introduced by the prox-term, a necessary regularizer to maintain the strong local consistency. Furthermore, FedSpeed merges the vanilla stochastic gradient with a perturbation computed from an extra gradient ascent step in the neighborhood, thereby alleviating the issue of local over-fitting. Our theoretical analysis indicates that the convergence rate is related to both the communication rounds $T$ and local intervals $K$ with a tighter upper bound $\\mathcal{O}(\\frac{1}{T})$ if $K=\\mathcal{O}(T)$. Moreover, we conduct extensive experiments on the real-world dataset to demonstrate the efficiency of our proposed FedSpeed, which converges significantly faster and achieves the state-of-the-art (SOTA) performance on the general FL experimental settings than several baselines including FedAvg, FedProx, FedCM, FedAdam, SCAFFOLD, FedDyn, FedADMM, etc",
    "checked": true,
    "id": "f0844a620d2a326b383c9be9ce442eb5c9faef23",
    "semantic_title": "fedspeed: larger local interval, less communication round, and higher generalization accuracy",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=w-x7U26GM7j": {
    "title": "Advancing Radiograph Representation Learning with Masked Record Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "81620597ffafb4368cf0fe4fab7b7cd4506e09cd",
    "semantic_title": "advancing radiograph representation learning with masked record modeling",
    "citation_count": 70,
    "authors": []
  },
  "https://openreview.net/forum?id=FIrQfNSOoTr": {
    "title": "Instance-wise Batch Label Restoration via Gradients in Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5e00b303299f0c0bd72e2c67e09395358202219e",
    "semantic_title": "instance-wise batch label restoration via gradients in federated learning",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=B92TMCG_7rp": {
    "title": "Re-parameterizing Your Optimizers rather than Architectures",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b65de6b99535e9c3b07fd672b363d4496306eafb",
    "semantic_title": "re-parameterizing your optimizers rather than architectures",
    "citation_count": 59,
    "authors": []
  },
  "https://openreview.net/forum?id=VbCMhg7MRmj": {
    "title": "Protein Representation Learning via Knowledge Enhanced Primary Structure Reasoning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "aca61344ef23077bd3d756601328df347a9bbe2c",
    "semantic_title": "protein representation learning via knowledge enhanced primary structure reasoning",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=MTTPLcwvqTt": {
    "title": "The Provable Benefit of Unsupervised Data Sharing for Offline Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "47cd9b32f18c806eb1fb88469b8526364fe77627",
    "semantic_title": "the provable benefit of unsupervised data sharing for offline reinforcement learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=-bVsNeR56KS": {
    "title": "Modeling Sequential Sentence Relation to Improve Cross-lingual Dense Retrieval",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c3d091c4ab12cc2d1503d40aeb25374e477f16ae",
    "semantic_title": "modeling sequential sentence relation to improve cross-lingual dense retrieval",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=pf8RIZTMU58": {
    "title": "DepthFL : Depthwise Federated Learning for Heterogeneous Clients",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "03f52748440203a25738e0ca093ee35c93111ee4",
    "semantic_title": "depthfl : depthwise federated learning for heterogeneous clients",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=1fZd4owfJP6": {
    "title": "Masked Image Modeling with Denoising Contrast",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "32e606846f5396162294055fafd3632757e35ba2",
    "semantic_title": "masked image modeling with denoising contrast",
    "citation_count": 62,
    "authors": []
  },
  "https://openreview.net/forum?id=NnOZT_CR26Z": {
    "title": "GoBigger: A Scalable Platform for Cooperative-Competitive Multi-Agent Interactive Simulation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8f5f7ae022a075dda077f8a774b836fca9d09bfe",
    "semantic_title": "gobigger: a scalable platform for cooperative-competitive multi-agent interactive simulation",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=ZAKkiVxiAM9": {
    "title": "Masked Unsupervised Self-training for Label-free Image Classification",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "98473b4f5bf852e09fe8acb906e74989bc573ed9",
    "semantic_title": "masked unsupervised self-training for label-free image classification",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=YfwMIDhPccD": {
    "title": "GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f7865a3f3c5795829e49d7285e1696a18d5f08c8",
    "semantic_title": "geneface: generalized and high-fidelity audio-driven 3d talking face synthesis",
    "citation_count": 154,
    "authors": []
  },
  "https://openreview.net/forum?id=3mRwyG5one": {
    "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9dc481ec44178e797466bbad968071917842156b",
    "semantic_title": "dino: detr with improved denoising anchor boxes for end-to-end object detection",
    "citation_count": 1751,
    "authors": []
  },
  "https://openreview.net/forum?id=dSYoPjM5J_W": {
    "title": "Revisiting Graph Adversarial Attack and Defense From a Data Distribution Perspective",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "823cc9972c5b5cd93a30593af2a01ffb5916a7aa",
    "semantic_title": "revisiting graph adversarial attack and defense from a data distribution perspective",
    "citation_count": 39,
    "authors": []
  },
  "https://openreview.net/forum?id=S31oTB72m0G": {
    "title": "Provable Sim-to-real Transfer in Continuous Domain with Partial Observations",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "cbb5c5edf310da22134c7ec93237285f9b34a991",
    "semantic_title": "provable sim-to-real transfer in continuous domain with partial observations",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=_9k5kTgyHT": {
    "title": "Globally Optimal Training of Neural Networks with Threshold Activation Functions",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1d1088efd299f1d174e8c304ca8cdcf270414570",
    "semantic_title": "globally optimal training of neural networks with threshold activation functions",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=Rq13idF0F73": {
    "title": "Molecule Generation For Target Protein Binding with Structural Motifs",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3d8e9601710eab43a89c0c49a9aaea44e6209b8e",
    "semantic_title": "molecule generation for target protein binding with structural motifs",
    "citation_count": 59,
    "authors": []
  },
  "https://openreview.net/forum?id=7GEvPKxjtt": {
    "title": "Towards Robustness Certification Against Universal Perturbations",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d60709222aa772732b9ea644bdb364971c0dea13",
    "semantic_title": "towards robustness certification against universal perturbations",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=M9u_ctqFUlg": {
    "title": "Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1e438b41bdf9283fbbb7d1306753d06f258ddc2f",
    "semantic_title": "deep generative modeling on limited data with regularization by nontransferable pre-trained models",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=h8T5dZWTZ-Z": {
    "title": "Basic Binary Convolution Unit for Binarized Image Restoration Network",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a3d9fd2c384e98fb6074a9064562a4e4dd941ed8",
    "semantic_title": "basic binary convolution unit for binarized image restoration network",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=Hnk1WRMAYqg": {
    "title": "Multimodal Federated Learning via Contrastive Representation Ensemble",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "eb07d132c5f3b0686e68c64bb554cf306a967bed",
    "semantic_title": "multimodal federated learning via contrastive representation ensemble",
    "citation_count": 105,
    "authors": []
  },
  "https://openreview.net/forum?id=_Mic8V96Voy": {
    "title": "Eva: Practical Second-order Optimization with Kronecker-vectorized Approximation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b504620e0313c8fd0968fcdc66811182d1b34df2",
    "semantic_title": "eva: practical second-order optimization with kronecker-vectorized approximation",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=TKIFuQHHECj": {
    "title": "Can CNNs Be More Robust Than Transformers?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fd4c076e0229ccd1a992cb89285d14fd4adcb7ad",
    "semantic_title": "can cnns be more robust than transformers?",
    "citation_count": 49,
    "authors": []
  },
  "https://openreview.net/forum?id=-RwZOVybbj": {
    "title": "Risk-Aware Reinforcement Learning with Coherent Risk Measures and Non-linear Function Approximation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c14fb18468f81cac6be8eca67611c0735a0d35dd",
    "semantic_title": "risk-aware reinforcement learning with coherent risk measures and non-linear function approximation",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=kkpL4zUXtiw": {
    "title": "Bi-level Physics-Informed Neural Networks for PDE Constrained Optimization using Broyden's Hypergradients",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6336baa441be4274e1ccf46bf4da14093ee06ffc",
    "semantic_title": "bi-level physics-informed neural networks for pde constrained optimization using broyden's hypergradients",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=tFvr-kYWs_Y": {
    "title": "On the Saturation Effect of Kernel Ridge Regression",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=to3qCB3tOh9": {
    "title": "Protein Representation Learning by Geometric Structure Pretraining",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c080266260e7b5c709350519f0534f362e521b95",
    "semantic_title": "protein representation learning by geometric structure pretraining",
    "citation_count": 250,
    "authors": []
  },
  "https://openreview.net/forum?id=8wbnpOJY-f": {
    "title": "Trainable Weight Averaging: Efficient Training by Optimizing Historical Solutions",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "035113896965c71a2ae46d770055d0fa2db448a9",
    "semantic_title": "trainable weight averaging: efficient training by optimizing historical solutions",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=UClBPxIZqnY": {
    "title": "Deep Declarative Dynamic Time Warping for End-to-End Learning of Alignment Paths",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2e462eff8fc41b8b7a0d3fa327ca433b2948101a",
    "semantic_title": "deep declarative dynamic time warping for end-to-end learning of alignment paths",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=3itjR9QxFw": {
    "title": "Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b64537bdf7a103aa01972ba06ea24a9c08f7cd74",
    "semantic_title": "analog bits: generating discrete data using diffusion models with self-conditioning",
    "citation_count": 349,
    "authors": []
  },
  "https://openreview.net/forum?id=p7EagBsMAEO": {
    "title": "Understanding Edge-of-Stability Training Dynamics with a Minimalist Example",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a1e8ac85fc10fb3f4e591143242fc2955c098b91",
    "semantic_title": "understanding edge-of-stability training dynamics with a minimalist example",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PzBGIu-llo7": {
    "title": "Learning Proximal Operators to Discover Multiple Optima",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b518ff4bf3de8093641f325831c342e1feff5f77",
    "semantic_title": "learning proximal operators to discover multiple optima",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=gfWNItGOES6": {
    "title": "Guiding continuous operator learning through Physics-based boundary constraints",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "7054a6587aab6639b45e5d69b2719b804b6b603d",
    "semantic_title": "guiding continuous operator learning through physics-based boundary constraints",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=mX56bKDybu5": {
    "title": "Neural Radiance Field Codebooks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d132389fea640b963c23bd49c6a828812085db71",
    "semantic_title": "neural radiance field codebooks",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=qBvBycTqVJ": {
    "title": "Generalized Precision Matrix for Scalable Estimation of Nonparametric Markov Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2249035ff915951db6a7d4718cd6bf28ec3c3e93",
    "semantic_title": "generalized precision matrix for scalable estimation of nonparametric markov networks",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=9aokcgBVIj1": {
    "title": "FiT: Parameter Efficient Few-shot Transfer Learning for Personalized and Federated Image Classification",
    "volume": "poster",
    "abstract": "Modern deep learning systems are increasingly deployed in situations such as personalization and federated learning where it is necessary to support i) learning on small amounts of data, and ii) communication efficient distributed training protocols. In this work, we develop FiLM Transfer (FiT) which fulfills these requirements in the image classification setting by combining ideas from transfer learning (fixed pretrained backbones and fine-tuned FiLM adapter layers) and meta-learning (automatically configured Naive Bayes classifiers and episodic training) to yield parameter efficient models with superior classification accuracy at low-shot. The resulting parameter efficiency is key for enabling few-shot learning, inexpensive model updates for personalization, and communication efficient federated learning. We experiment with FiT on a wide range of downstream datasets and show that it achieves better classification accuracy than the leading Big Transfer (BiT) algorithm at low-shot and achieves state-of-the art accuracy on the challenging VTAB-1k benchmark, with fewer than 1% of the updateable parameters. Finally, we demonstrate the parameter efficiency and superior accuracy of FiT in distributed low-shot applications including model personalization and federated learning where model update size is an important performance metric",
    "checked": true,
    "id": "5945baeb4c52ad091e7e2a2c351424073154250a",
    "semantic_title": "fit: parameter efficient few-shot transfer learning for personalized and federated image classification",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=1-MBdJssZ-S": {
    "title": "Discrete Contrastive Diffusion for Cross-Modal Music and Image Generation",
    "volume": "poster",
    "abstract": "Diffusion probabilistic models (DPMs) have become a popular approach to conditional generation, due to their promising results and support for cross-modal synthesis. A key desideratum in conditional synthesis is to achieve high correspondence between the conditioning input and generated output. Most existing methods learn such relationships implicitly, by incorporating the prior into the variational lower bound. In this work, we take a different route---we explicitly enhance input-output connections by maximizing their mutual information. To this end, we introduce a Conditional Discrete Contrastive Diffusion (CDCD) loss and design two contrastive diffusion mechanisms to effectively incorporate it into the denoising process, combining the diffusion training and contrastive learning for the first time by connecting it with the conventional variational objectives. We demonstrate the efficacy of our approach in evaluations with diverse multimodal conditional synthesis tasks: dance-to-music generation, text-to-image synthesis, as well as class-conditioned image synthesis. On each, we enhance the input-output correspondence and achieve higher or competitive general synthesis quality. Furthermore, the proposed approach improves the convergence of diffusion models, reducing the number of required diffusion steps by more than 35% on two benchmarks, significantly increasing the inference speed",
    "checked": true,
    "id": "f2ad100d01a586ef798633e3801eb85bd43f45cd",
    "semantic_title": "discrete contrastive diffusion for cross-modal music and image generation",
    "citation_count": 52,
    "authors": []
  },
  "https://openreview.net/forum?id=6TxBxqNME1Y": {
    "title": "Diffusion Probabilistic Modeling of Protein Backbones in 3D for the motif-scaffolding problem",
    "volume": "poster",
    "abstract": "Construction of a scaffold structure that supports a desired motif, conferring protein function, shows promise for the design of vaccines and enzymes. But a general solution to this motif-scaffolding problem remains open. Current machine-learning techniques for scaffold design are either limited to unrealistically small scaffolds (up to length 20) or struggle to produce multiple diverse scaffolds. We propose to learn a distribution over diverse and longer protein backbone structures via an E(3)-equivariant graph neural network. We develop SMCDiff to efficiently sample scaffolds from this distribution conditioned on a given motif; our algorithm is the first to theoretically guarantee conditional samples from a diffusion model in the large-compute limit. We evaluate our designed backbones by how well they align with AlphaFold2-predicted structures. We show that our method can (1) sample scaffolds up to 80 residues and (2) achieve structurally diverse scaffolds for a fixed motif",
    "checked": true,
    "id": "a4754e9045a4dfd8aba54df0cb847ddc0eb6965a",
    "semantic_title": "diffusion probabilistic modeling of protein backbones in 3d for the motif-scaffolding problem",
    "citation_count": 263,
    "authors": []
  },
  "https://openreview.net/forum?id=kfOtMqYJlUU": {
    "title": "NeRF-SOS: Any-View Self-supervised Object Segmentation on Complex Scenes",
    "volume": "poster",
    "abstract": "Neural volumetric representations have shown the potential that Multi-layer Perceptrons (MLPs) can be optimized with multi-view calibrated images to represent scene geometry and appearance without explicit 3D supervision. Object segmentation can enrich many downstream applications based on the learned radiance field. However, introducing hand-crafted segmentation to define regions of interest in a complex real-world scene is non-trivial and expensive as it acquires per view annotation. This paper carries out the exploration of self-supervised learning for object segmentation using NeRF for complex real-world scenes. Our framework, called NeRF with Self-supervised Object Segmentation (NeRF-SOS), couples object segmentation and neural radiance field to segment objects in any view within a scene. By proposing a novel collaborative contrastive loss in both appearance and geometry levels, NeRF-SOS encourages NeRF models to distill compact geometry-aware segmentation clusters from their density fields and the self-supervised pre-trained 2D visual features. The self-supervised object segmentation framework can be applied to various NeRF models that both lead to photo-realistic rendering results and convincing segmentation maps for both indoor and outdoor scenarios. Extensive results on the LLFF, BlendedMVS, CO3Dv2, and Tank & Temples datasets validate the effectiveness of NeRF-SOS. It consistently surpasses other 2D-based self-supervised baselines and predicts finer object masks than existing supervised counterparts",
    "checked": true,
    "id": "a1b3b3415d2e62f3728cd26d9a480d27f13254ea",
    "semantic_title": "nerf-sos: any-view self-supervised object segmentation on complex scenes",
    "citation_count": 72,
    "authors": []
  },
  "https://openreview.net/forum?id=fjh7UGQgOB": {
    "title": "Rethinking Graph Lottery Tickets: Graph Sparsity Matters",
    "volume": "poster",
    "abstract": "Lottery Ticket Hypothesis (LTH) claims the existence of a winning ticket (i.e., a properly pruned sub-network together with original weight initialization) that can achieve competitive performance to the original dense network. A recent work, called UGS, extended LTH to prune graph neural networks (GNNs) for effectively accelerating GNN inference. UGS simultaneously prunes the graph adjacency matrix and the model weights using the same masking mechanism, but since the roles of the graph adjacency matrix and the weight matrices are very different, we find that their sparsifications lead to different performance characteristics. Specifically, we find that the performance of a sparsified GNN degrades significantly when the graph sparsity goes beyond a certain extent. Therefore, we propose two techniques to improve GNN performance when the graph sparsity is high. First, UGS prunes the adjacency matrix using a loss formulation which, however, does not properly involve all elements of the adjacency matrix; in contrast, we add a new auxiliary loss head to better guide the edge pruning by involving the entire adjacency matrix. Second, by regarding unfavorable graph sparsification as adversarial data perturbations, we formulate the pruning process as a min-max optimization problem to gain the robustness of lottery tickets when the graph sparsity is high. We further investigate the question: Can the ``retrainable'' winning ticket of a GNN be also effective for graph transferring learning? We call it the transferable graph lottery ticket (GLT) hypothesis. Extensive experiments were conducted which demonstrate the superiority of our proposed sparsification method over UGS, and which empirically verified our transferable GLT hypothesis",
    "checked": true,
    "id": "8cb97eb1acb9db3e683ab531bdf7b81e68a0cd46",
    "semantic_title": "rethinking graph lottery tickets: graph sparsity matters",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=TVY6GoURrw": {
    "title": "Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses",
    "volume": "poster",
    "abstract": "This paper studies federated learning (FL)—especially cross-silo FL—with data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) has data from different people (e.g. patients) and must maintain the privacy of each person's data (e.g. medical record), even if the server or other silos act as adversarial eavesdroppers. This requirement motivates the study of Inter-Silo Record-Level Differential Privacy (ISRL-DP), which requires silo $i$'s communications to satisfy record/item-level differential privacy (DP). ISRL-DP ensures that the data of each person (e.g. patient) in silo $i$ (e.g. hospital $i$) cannot be leaked. ISRL-DP is different from well-studied privacy notions. Central and user-level DP assume that people trust the server/other silos. On the other end of the spectrum, local DP assumes that people do not trust anyone at all (even their own silo). Sitting between central and local DP, ISRL-DP makes the realistic assumption (in cross-silo FL) that people trust their own silo, but not the server or other silos. In this work, we provide tight (up to logarithms) upper and lower bounds for ISRL-DP FL with convex/strongly convex loss functions and homogeneous (i.i.d.) silo data. Remarkably, we show that similar bounds are attainable for smooth losses with arbitrary heterogeneous silo data distributions, via an accelerated ISRL-DP algorithm. We also provide tight upper and lower bounds for ISRL-DP federated empirical risk minimization, and use acceleration to attain the optimal bounds in fewer rounds of communication than the state-of-the-art. Finally, with a secure \"shuffler\" to anonymize silo messages (but without a trusted server), our algorithm attains the optimal central DP rates under more practical trust assumptions. Numerical experiments show favorable privacy-accuracy tradeoffs for our algorithm in classification and regression tasks",
    "checked": true,
    "id": "d089c7e30153a0bd866606dd199e6a74a81764fe",
    "semantic_title": "private federated learning without a trusted server: optimal algorithms for convex losses",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=cddbeL1HWaD": {
    "title": "Cheap Talk Discovery and Utilization in Multi-Agent Reinforcement Learning",
    "volume": "poster",
    "abstract": "By enabling agents to communicate, recent cooperative multi-agent reinforcement learning (MARL) methods have demonstrated better task performance and more coordinated behavior. Most existing approaches facilitate inter-agent communication by allowing agents to send messages to each other through free communication channels, i.e., \\emph{cheap talk channels}. Current methods require these channels to be constantly accessible and known to the agents a priori. In this work, we lift these requirements such that the agents must discover the cheap talk channels and learn how to use them. Hence, the problem has two main parts: \\emph{cheap talk discovery} (CTD) and \\emph{cheap talk utilization} (CTU). We introduce a novel conceptual framework for both parts and develop a new algorithm based on mutual information maximization that outperforms existing algorithms in CTD/CTU settings. We also release a novel benchmark suite to stimulate future research in CTD/CTU",
    "checked": true,
    "id": "7a796060552abafec70f9d3cf58ff581db945bf5",
    "semantic_title": "cheap talk discovery and utilization in multi-agent reinforcement learning",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=Oc2vlWU0jFY": {
    "title": "Reversible Column Networks",
    "volume": "poster",
    "abstract": "We propose a new neural network design paradigm Reversible Column Network (RevCol). The main body of RevCol is composed of multiple copies of subnetworks, named columns respectively, between which multi-level reversible connections are employed. Such architectural scheme attributes RevCol very different behavior from conventional networks: during forward propagation, features in RevCol are learned to be gradually disentangled when passing through each column, whose total information is maintained rather than compressed or discarded as other network does. Our experiments suggest that CNN-style RevCol models can achieve very competitive performances on multiple computer vision tasks such as image classification, object detection and semantic segmentation, especially with large parameter budget and large dataset. For example, after ImageNet-22K pre-training, RevCol-XL obtains 88.2% ImageNet-1K accuracy. Given more pre-training data, our largest model RevCol-H reaches 90.0% on ImageNet-1K, 63.8% AP$_{box}$ on COCO detection minival set, 61.0% mIoU on ADE20k segmentation. To our knowledge, it is the best COCO detection and ADE20k segmentation result among pure (static) CNN models. Moreover, as a general macro architecture fashion, RevCol can also be introduced into transformers or other neural networks, which is demonstrated to improve the performances in both computer vision and NLP tasks. We release code and models at https://github.com/megvii-research/RevCol",
    "checked": true,
    "id": "007323e9a19faa7be415eb2122dd331b11a54989",
    "semantic_title": "reversible column networks",
    "citation_count": 64,
    "authors": []
  },
  "https://openreview.net/forum?id=KE_wJD2RK4": {
    "title": "Modeling Multimodal Aleatoric Uncertainty in Segmentation with Mixture of Stochastic Experts",
    "volume": "poster",
    "abstract": "Equipping predicted segmentation with calibrated uncertainty is essential for safety-critical applications. In this work, we focus on capturing the data-inherent uncertainty (aka aleatoric uncertainty) in segmentation, typically when ambiguities exist in input images. Due to the high-dimensional output space and potential multiple modes in segmenting ambiguous images, it remains challenging to predict well-calibrated uncertainty for segmentation. To tackle this problem, we propose a novel mixture of stochastic experts (MoSE) model, where each expert network estimates a distinct mode of the aleatoric uncertainty and a gating network predicts the probabilities of an input image being segmented in those modes. This yields an efficient two-level uncertainty representation. To learn the model, we develop a Wasserstein-like loss that directly minimizes the distribution distance between the MoSE and ground truth annotations. The loss can easily integrate traditional segmentation quality measures and be efficiently optimized via constraint relaxation. We validate our method on the LIDC-IDRI dataset and a modified multimodal Cityscapes dataset. Results demonstrate that our method achieves the state-of-the-art or competitive performance on all metrics",
    "checked": false,
    "id": "ea6caec5d86fa91df065c1a7e145e8958d8133e3",
    "semantic_title": "modeling multimodal aleatoric uncertainty in segmentation with mixture of stochastic expert",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=jbIYfq4Tr-": {
    "title": "On the Robustness of Safe Reinforcement Learning under Observational Perturbations",
    "volume": "poster",
    "abstract": "Safe reinforcement learning (RL) trains a policy to maximize the task reward while satisfying safety constraints. While prior works focus on the performance optimality, we find that the optimal solutions of many safe RL problems are not robust and safe against carefully designed observational perturbations. We formally analyze the unique properties of designing effective observational adversarial attackers in the safe RL setting. We show that baseline adversarial attack techniques for standard RL tasks are not always effective for safe RL and propose two new approaches - one maximizes the cost and the other maximizes the reward. One interesting and counter-intuitive finding is that the maximum reward attack is strong, as it can both induce unsafe behaviors and make the attack stealthy by maintaining the reward. We further propose a robust training framework for safe RL and evaluate it via comprehensive experiments. This paper provides a pioneer work to investigate the safety and robustness of RL under observational attacks for future safe RL studies. Code is available at: \\url{https://github.com/liuzuxin/safe-rl-robustness}",
    "checked": true,
    "id": "274f0cee47c8a5bbc38c32de6787adee6a08f69e",
    "semantic_title": "on the robustness of safe reinforcement learning under observational perturbations",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=TPiwkItUSu": {
    "title": "Behind the Scenes of Gradient Descent: A Trajectory Analysis via Basis Function Decomposition",
    "volume": "poster",
    "abstract": "This work analyzes the solution trajectory of gradient-based algorithms via a novel basis function decomposition. We show that, although solution trajectories of gradient-based algorithms may vary depending on the learning task, they behave almost monotonically when projected onto an appropriate orthonormal function basis. Such projection gives rise to a basis function decomposition of the solution trajectory. Theoretically, we use our proposed basis function decomposition to establish the convergence of gradient descent (GD) on several representative learning tasks. In particular, we improve the convergence of GD on symmetric matrix factorization and provide a completely new convergence result for the orthogonal symmetric tensor decomposition. Empirically, we illustrate the promise of our proposed framework on realistic deep neural networks (DNNs) across different architectures, gradient-based solvers, and datasets. Our key finding is that gradient-based algorithms monotonically learn the coefficients of a particular orthonormal function basis of DNNs defined as the eigenvectors of the conjugate kernel after training",
    "checked": true,
    "id": "53255b2d1494e0bbf6fdbf942e2357a267b69c75",
    "semantic_title": "behind the scenes of gradient descent: a trajectory analysis via basis function decomposition",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=MjsDeTcDEy": {
    "title": "What Is Missing in IRM Training and Evaluation? Challenges and Solutions",
    "volume": "poster",
    "abstract": "Invariant risk minimization (IRM) has received increasing attention as a way to acquire environment-agnostic data representations and predictions, and also a principled solution for preventing spurious correlations from being learned and improving models' out-of-distribution generalization. Yet, recent works have found that the optimality of the originally-proposed IRM optimization (IRMV1) may be compromised in practice or could be impossible to achieve in some scenarios. Therefore, a series of advanced IRM algorithms have been developed that show practical improvement over IRMV1. In this work, we revisit these recent IRM advancements and identify and resolve three practical limitations in IRM training and evaluation. First, we find that the effect of batch size during training has been chronically overlooked in previous studies, leaving room for further improvement. We propose small-batch training and highlight the improvements over a set of large-batch optimization techniques. Second, we find that improper selection of evaluation environments could give a false sense of invariance for IRM. To alleviate this effect, we leverage diversified test-time environments to precisely characterize the invariance of IRM when applied in practice. Third, we revisit Ahuja et al. (2020)'s proposal to convert IRM into an ensemble game and identify a limitation when a single invariant predictor is desired instead of an ensemble of individual predictors. We propose a new IRM variant to address this limitation based on a novel viewpoint of ensemble IRM games as consensus-constrained bi-level optimization. Lastly, we conduct extensive experiments (covering 7 existing IRM variants and 7 datasets) to justify the practical significance of revisiting IRM training and evaluation in a principled manner",
    "checked": true,
    "id": "2b6aa2226b8333b89a03c3f83e2d015a772f92a4",
    "semantic_title": "what is missing in irm training and evaluation? challenges and solutions",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=1tHAZRqftM": {
    "title": "Multi-task Self-supervised Graph Neural Networks Enable Stronger Task Generalization",
    "volume": "poster",
    "abstract": "Self-supervised learning (SSL) for graph neural networks (GNNs) has attracted increasing attention from the graph machine learning community in recent years, owing to its capability to learn performant node embeddings without costly label information. One weakness of conventional SSL frameworks for GNNs is that they learn through a single philosophy, such as mutual information maximization or generative reconstruction. When applied to various downstream tasks, these frameworks rarely perform equally well for every task, because one philosophy may not span the extensive knowledge required for all tasks. To enhance the task generalization across tasks, as an important first step forward in exploring fundamental graph models, we introduce PARETOGNN, a multi-task SSL framework for node representation learning over graphs. Specifically, PARETOGNN is self-supervised by manifold pretext tasks observing multiple philosophies. To reconcile different philosophies, we explore a multiple-gradient descent algorithm, such that PARETOGNN actively learns from every pretext task while minimizing potential conflicts. We conduct comprehensive experiments over four downstream tasks (i.e., node classification, node clustering, link prediction, and partition prediction), and our proposal achieves the best overall performance across tasks on 11 widely adopted benchmark datasets. Besides, we observe that learning from multiple philosophies enhances not only the task generalization but also the single task performances, demonstrating that PARETOGNN achieves better task generalization via the disjoint yet complementary knowledge learned from different philosophies. Our code is publicly available at https://github.com/jumxglhf/ParetoGNN",
    "checked": true,
    "id": "f631fef661e6c6c1ccbbd2085b5a0cb273ed0f9f",
    "semantic_title": "multi-task self-supervised graph neural networks enable stronger task generalization",
    "citation_count": 39,
    "authors": []
  },
  "https://openreview.net/forum?id=V_06QV-kZX": {
    "title": "Analyzing Tree Architectures in Ensembles via Neural Tangent Kernel",
    "volume": "poster",
    "abstract": "A soft tree is an actively studied variant of a decision tree that updates splitting rules using the gradient method. Although soft trees can take various architectures, their impact is not theoretically well known. In this paper, we formulate and analyze the Neural Tangent Kernel (NTK) induced by soft tree ensembles for arbitrary tree architectures. This kernel leads to the remarkable finding that only the number of leaves at each depth is relevant for the tree architecture in ensemble learning with an infinite number of trees. In other words, if the number of leaves at each depth is fixed, the training behavior in function space and the generalization performance are exactly the same across different tree architectures, even if they are not isomorphic. We also show that the NTK of asymmetric trees like decision lists does not degenerate when they get infinitely deep. This is in contrast to the perfect binary trees, whose NTK is known to degenerate and leads to worse generalization performance for deeper trees",
    "checked": true,
    "id": "c0ecf92a4f055cc8a0e6e72d316a48fd188fe56f",
    "semantic_title": "analyzing tree architectures in ensembles via neural tangent kernel",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=7sn6Vxp92xV": {
    "title": "Exploring The Role of Mean Teachers in Self-supervised Masked Auto-Encoders",
    "volume": "poster",
    "abstract": "Masked image modeling (MIM) has become a popular strategy for self-supervised learning (SSL) of visual representations with Vision Transformers. A representative MIM model, the masked auto-encoder (MAE), randomly masks a subset of image patches and reconstructs the masked patches given the unmasked patches. Concurrently, many recent works in self-supervised learning utilize the student/teacher paradigm which provides the student with an additional target based on the output of a teacher composed of an exponential moving average (EMA) of previous students. Although common, relatively little is known about the dynamics of the interaction between the student and teacher. Through analysis on a simple linear model, we find that the teacher conditionally removes previous gradient directions based on feature similarities which effectively acts as a conditional momentum regularizer. From this analysis, we present a simple SSL method, the Reconstruction-Consistent Masked Auto-Encoder (RC-MAE) by adding an EMA teacher to MAE. We find that RC-MAE converges faster and requires less memory usage than state-of-the-art self-distillation methods during pre-training, which may provide a way to enhance the practicality of prohibitively expensive self-supervised learning of Vision Transformer models. Additionally, we show that RC-MAE achieves more robustness and better performance compared to MAE on downstream tasks such as ImageNet-1K classification, object detection, and instance segmentation",
    "checked": true,
    "id": "651281af4c8651ab634ac9f043227a9ed04364f1",
    "semantic_title": "exploring the role of mean teachers in self-supervised masked auto-encoders",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BrJATVZDWEH": {
    "title": "Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks",
    "volume": "poster",
    "abstract": "The field of Natural Language Processing (NLP) has experienced a dramatic leap in capabilities with the recent introduction of huge Language Models (LMs). Despite this success, natural language problems that involve several compounded steps are still practically unlearnable, even by the largest LMs. This complies with experimental failures for end-to-end learning of composite problems that were demonstrated in a variety of domains. An effective mitigation is to introduce intermediate supervision for solving sub-tasks of the compounded problem. Recently, several works have demonstrated high gains by taking a straightforward approach for incorporating intermediate supervision in compounded natural language problems: the sequence-to-sequence LM is fed with an augmented input, in which the decomposed tasks' labels are simply concatenated to the original input. In this paper, we prove a positive learning result that motivates these recent efforts. We show that when concatenating intermediate supervision to the input and training a sequence-to-sequence model on this modified input, unlearnable composite problems can become learnable. We show that this is true for any family of tasks which on the one hand, are unlearnable, and on the other hand, can be decomposed into a polynomial number of simple sub-tasks, each of which depends only on $O(1)$ previous sub-task results. Beyond motivating contemporary empirical efforts for incorporating intermediate supervision in sequence-to-sequence language models, our positive theoretical result is the first of its kind in the landscape of results on the benefits of intermediate supervision for neural-network learning: Until now, all theoretical results on the subject are negative, i.e., show cases where learning is impossible without intermediate supervision, while our result is positive, showing that learning is facilitated in the presence of intermediate supervision",
    "checked": true,
    "id": "932b6353204e56f20917edadda2fa636ace21090",
    "semantic_title": "sub-task decomposition enables learning in sequence to sequence tasks",
    "citation_count": 40,
    "authors": []
  },
  "https://openreview.net/forum?id=yHLvIlE9RGN": {
    "title": "Evaluating Long-Term Memory in 3D Mazes",
    "volume": "poster",
    "abstract": "Intelligent agents need to remember salient information to reason in partially-observed environments. For example, agents with a first-person view should remember the positions of relevant objects even if they go out of view. Similarly, to effectively navigate through rooms agents need to remember the floor plan of how rooms are connected. However, most benchmark tasks in reinforcement learning do not test long-term memory in agents, slowing down progress in this important research direction. In this paper, we introduce the Memory Maze, a 3D domain of randomized mazes specifically designed for evaluating long-term memory in agents. Unlike existing benchmarks, Memory Maze measures long-term memory separate from confounding agent abilities and requires the agent to localize itself by integrating information over time. With Memory Maze, we propose an online reinforcement learning benchmark, a diverse offline dataset, and an offline probing evaluation. Recording a human player establishes a strong baseline and verifies the need to build up and retain memories, which is reflected in their gradually increasing rewards within each episode. We find that current algorithms benefit from training with truncated backpropagation through time and succeed on small mazes, but fall short of human performance on the large mazes, leaving room for future algorithmic designs to be evaluated on the Memory Maze",
    "checked": true,
    "id": "5f164c00d9dcdc5da72b9f71a802eabc4d2e8e68",
    "semantic_title": "evaluating long-term memory in 3d mazes",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=CPIy9TWFYBG": {
    "title": "Proactive Multi-Camera Collaboration for 3D Human Pose Estimation",
    "volume": "poster",
    "abstract": "This paper presents a multi-agent reinforcement learning (MARL) scheme for proactive Multi-Camera Collaboration in 3D Human Pose Estimation in dynamic human crowds. Traditional fixed-viewpoint multi-camera solutions for human motion capture (MoCap) are limited in capture space and susceptible to dynamic occlusions. Active camera approaches proactively control camera poses to find optimal viewpoints for 3D reconstruction. However, current methods still face challenges with credit assignment and environment dynamics. To address these issues, our proposed method introduces a novel Collaborative Triangulation Contribution Reward (CTCR) that improves convergence and alleviates multi-agent credit assignment issues resulting from using 3D reconstruction accuracy as the shared reward. Additionally, we jointly train our model with multiple world dynamics learning tasks to better capture environment dynamics and encourage anticipatory behaviors for occlusion avoidance. We evaluate our proposed method in four photo-realistic UE4 environments to ensure validity and generalizability. Empirical results show that our method outperforms fixed and active baselines in various scenarios with different numbers of cameras and humans",
    "checked": true,
    "id": "93c6151db4a62b3f69468c23fa97652ddbb1166c",
    "semantic_title": "proactive multi-camera collaboration for 3d human pose estimation",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=Sy-o2N0hF4f": {
    "title": "Become a Proficient Player with Limited Data through Watching Pure Videos",
    "volume": "poster",
    "abstract": "Recently, RL has shown its strong ability for visually complex tasks. However, it suffers from the low sample efficiency and poor generalization ability, which prevent RL from being useful in real-world scenarios. Inspired by the huge success of unsupervised pre-training methods on language and vision domains, we propose to improve the sample efficiency via a novel pre-training method for model-based RL. Instead of using pre-recorded agent trajectories that come with their own actions, we consider the setting where the pre-training data are action-free videos, which are more common and available in the real world. We introduce a two-phase training pipeline as follows: for the pre-training phase, we implicitly extract the hidden action embedding from videos and pre-train the visual representation and the environment dynamics network through a novel \\Changes{forward-inverse} cycle consistency \\Changes{(FICC)} objective based on vector quantization; for down-stream tasks, we finetune with small amount of task data based on the learned models. Our framework can significantly improve the sample efficiency on Atari Games with data of only one hour of game playing. We achieve 118.4\\% mean human performance and 36.0\\% median performance with only 50k environment steps, which is 85.6\\% and 65.1\\% better than the scratch EfficientZero model. We believe such pre-training approach can provide an option for solving real-world RL problems. The code is available at \\url{https://github.com/YeWR/FICC.git}",
    "checked": true,
    "id": "d3381404950dc163f91787f0f4bbbd81c445246d",
    "semantic_title": "become a proficient player with limited data through watching pure videos",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=lQVpasnQS62": {
    "title": "Human MotionFormer: Transferring Human Motions with Vision Transformers",
    "volume": "poster",
    "abstract": "Human motion transfer aims to transfer motions from a target dynamic person to a source static one for motion synthesis. An accurate matching between the source person and the target motion in both large and subtle motion changes is vital for improving the transferred motion quality. In this paper, we propose Human MotionFormer, a hierarchical ViT framework that leverages global and local perceptions to capture large and subtle motion matching, respectively. It consists of two ViT encoders to extract input features (i.e., a target motion image and a source human image) and a ViT decoder with several cascaded blocks for feature matching and motion transfer. In each block, we set the target motion feature as Query and the source person as Key and Value, calculating the cross-attention maps to conduct a global feature matching. Further, we introduce a convolutional layer to improve the local perception after the global cross-attention computations. This matching process is implemented in both warping and generation branches to guide the motion transfer. During training, we propose a mutual learning loss to enable the co-supervision between warping and generation branches for better motion representations. Experiments show that our Human MotionFormer sets the new state-of-the-art performance both qualitatively and quantitatively. Project page: https://github.com/KumapowerLIU/Human-MotionFormer",
    "checked": true,
    "id": "3ca7ec57add7669c67e7c48f2555b23b87a9be98",
    "semantic_title": "human motionformer: transferring human motions with vision transformers",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=YPChvOgRXRA": {
    "title": "Backstepping Temporal Difference Learning",
    "volume": "poster",
    "abstract": "Off-policy learning ability is an important feature of reinforcement learning (RL) for practical applications. However, even one of the most elementary RL algorithms, temporal-difference (TD) learning, is known to suffer form divergence issue when the off-policy scheme is used together with linear function approximation. To overcome the divergent behavior, several off-policy TD learning algorithms have been developed until now. In this work, we provide a unified view of such algorithms from a purely control-theoretic perspective. Our method relies on the backstepping technique, which is widely used in nonlinear control theory",
    "checked": true,
    "id": "28efd129dc5f4bf511f485ee380f1066d237ea1e",
    "semantic_title": "backstepping temporal difference learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=dYHYXZ3uGdQ": {
    "title": "A General Rank Preserving Framework for Asymmetric Image Retrieval",
    "volume": "poster",
    "abstract": "Asymmetric image retrieval aims to deploy compatible models on platforms of different resources to achieve a balance between computational efficiency and retrieval accuracy. The most critical issue is how to align the output features of different models. Despite the great progress, existing approaches apply strong constraints so that features or neighbor structures are strictly aligned across different models. However, such a one-to-one constraint is too strict to be well preserved for the query models with low capacity. Considering that the primary concern of the users is the rank of the returned images, we propose a generic rank preserving framework, which achieves feature compatibility and the order consistency between query and gallery models simultaneously. Specifically, we propose two alternatives to instantiate the framework. One realizes straightforward rank order preservation by directly preserving the consistency of the sorting results. To make sorting process differentiable, the Heaviside step function in sorting is approximated by the sigmoid function. The other aims to preserve a learnable monotonic mapping relationship between the returned similarity scores of query and gallery models. The mapped similarity scores of gallery model are considered as pseudo-supervision to guide the query model training. Extensive experiments on various large-scale datasets demonstrate the superiority of our two proposed methods",
    "checked": true,
    "id": "b424d2b043695305adf2b480aca568214396e508",
    "semantic_title": "a general rank preserving framework for asymmetric image retrieval",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=qNLe3iq2El": {
    "title": "Mega: Moving Average Equipped Gated Attention",
    "volume": "poster",
    "abstract": "The design choices in the Transformer attention mechanism, including weak inductive bias and quadratic computational complexity, have limited its application for modeling long sequences. In this paper, we introduce Mega, a simple, theoretically grounded, single-head gated attention mechanism equipped with (exponential) moving average to incorporate inductive bias of position-aware local dependencies into the position-agnostic attention mechanism. We further propose a variant of Mega that offers linear time and space complexity yet yields only minimal quality loss, by efficiently splitting the whole sequence into multiple chunks with fixed length. Extensive experiments on a wide range of sequence modeling benchmarks, including the Long Range Arena, neural machine translation, auto-regressive language modeling, and image and speech classification, show that Mega achieves significant improvements over other sequence models, including variants of Transformers and recent state space models",
    "checked": true,
    "id": "70e91e16eb321067d9402710e14a40cf28311f73",
    "semantic_title": "mega: moving average equipped gated attention",
    "citation_count": 198,
    "authors": []
  },
  "https://openreview.net/forum?id=6zrOr_Rdhjs": {
    "title": "Parallel Deep Neural Networks Have Zero Duality Gap",
    "volume": "poster",
    "abstract": "Training deep neural networks is a challenging non-convex optimization problem. Recent work has proven that the strong duality holds (which means zero duality gap) for regularized finite-width two-layer ReLU networks and consequently provided an equivalent convex training problem. However, extending this result to deeper networks remains to be an open problem. In this paper, we prove that the duality gap for deeper linear networks with vector outputs is non-zero. In contrast, we show that the zero duality gap can be obtained by stacking standard deep networks in parallel, which we call a parallel architecture, and modifying the regularization. Therefore, we prove the strong duality and existence of equivalent convex problems that enable globally optimal training of deep networks. As a by-product of our analysis, we demonstrate that the weight decay regularization on the network parameters explicitly encourages low-rank solutions via closed-form expressions. In addition, we show that strong duality holds for three-layer standard ReLU networks given rank-1 data matrices",
    "checked": true,
    "id": "20b59491ba014b0cfa0cc3e12882fca39f926411",
    "semantic_title": "parallel deep neural networks have zero duality gap",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=c5tbxWXU9-y": {
    "title": "Information-Theoretic Analysis of Unsupervised Domain Adaptation",
    "volume": "poster",
    "abstract": "This paper uses information-theoretic tools to analyze the generalization error in unsupervised domain adaptation (UDA). We present novel upper bounds for two notions of generalization errors. The first notion measures the gap between the population risk in the target domain and that in the source domain, and the second measures the gap between the population risk in the target domain and the empirical risk in the source domain. While our bounds for the first kind of error are in line with the traditional analysis and give similar insights, our bounds on the second kind of error are algorithm-dependent, which also provide insights into algorithm designs. Specifically, we present two simple techniques for improving generalization in UDA and validate them experimentally",
    "checked": true,
    "id": "6b47d9e8a4c553b8e39cafc6e7130608be9badd8",
    "semantic_title": "information-theoretic analysis of unsupervised domain adaptation",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=PbkBDQ5_UbV": {
    "title": "Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes",
    "volume": "poster",
    "abstract": "We study offline reinforcement learning (RL) in partially observable Markov decision processes. In particular, we aim to learn an optimal policy from a dataset collected by a behavior policy which possibly depends on the latent state. Such a dataset is confounded in the sense that the latent state simultaneously affects the action and the observation, which is prohibitive for existing offline RL algorithms. To this end, we propose the \\underline{P}roxy variable \\underline{P}essimistic \\underline{P}olicy \\underline{O}ptimization (\\texttt{P3O}) algorithm, which addresses the confounding bias and the distributional shift between the optimal and behavior policies in the context of general function approximation. At the core of \\texttt{P3O} is a coupled sequence of pessimistic confidence regions constructed via proximal causal inference, which is formulated as minimax estimation. Under a partial coverage assumption on the confounded dataset, we prove that \\texttt{P3O} achieves a $n^{-1/2}$-suboptimality, where $n$ is the number of trajectories in the dataset. To our best knowledge, \\texttt{P3O} is the first provably efficient offline RL algorithm for POMDPs with a confounded dataset",
    "checked": true,
    "id": "5de965bcb5dacaed52f36c64a193a309e56e6a4b",
    "semantic_title": "pessimism in the face of confounders: provably efficient offline reinforcement learning in partially observable markov decision processes",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=P4bXCawRi5J": {
    "title": "Understanding Zero-shot Adversarial Robustness for Large-Scale Models",
    "volume": "poster",
    "abstract": "Pretrained large-scale vision-language models like CLIP have exhibited strong generalization over unseen tasks. Yet imperceptible adversarial perturbations can significantly reduce CLIP's performance on new tasks. In this work, we identify and explore the problem of adapting large-scale models for zero-shot adversarial robustness. We first identify two key factors during model adaption--training losses and adaptation methods--that affect the model's zero-shot adversarial robustness. We then propose a text-guided contrastive adversarial training loss, which aligns the text embeddings and the adversarial visual features with contrastive learning on a small set of training data. We apply this training loss to two adaption methods, model finetuning and visual prompt tuning. We find that visual prompt tuning is more effective in the absence of texts, while finetuning wins in the existence of text guidance. Overall, our approach significantly improves the zero-shot adversarial robustness over CLIP, seeing an average improvement of 31 points over ImageNet and 15 zero-shot datasets. We hope this work can shed light on understanding the zero-shot adversarial robustness of large-scale models",
    "checked": true,
    "id": "16596dd03fa40ba278f9533ea9986982dcc81fb6",
    "semantic_title": "understanding zero-shot adversarial robustness for large-scale models",
    "citation_count": 91,
    "authors": []
  },
  "https://openreview.net/forum?id=YV8tP7bW6Kt": {
    "title": "Can We Faithfully Represent Absence States to Compute Shapley Values on a DNN?",
    "volume": "poster",
    "abstract": "Masking some input variables of a deep neural network (DNN) and computing output changes on the masked input sample represent a typical way to compute attributions of input variables in the sample. People usually mask an input variable using its baseline value. However, there is no theory to examine whether baseline value faithfully represents the absence of an input variable, i.e., removing all signals from the input variable. Fortunately, recent studies (Ren et al., 2023a; Deng et al., 2022a) show that the inference score of a DNN can be strictly disentangled into a set of causal patterns (or concepts) encoded by the DNN. Therefore, we propose to use causal patterns to examine the faithfulness of baseline values. More crucially, it is proven that causal patterns can be explained as the elementary rationale of the Shapley value. Furthermore, we propose a method to learn optimal baseline values, and experimental results have demonstrated its effectiveness",
    "checked": true,
    "id": "0cc11371294b5af0573c971c3b11460a08fa50a2",
    "semantic_title": "can we faithfully represent absence states to compute shapley values on a dnn?",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=FCnohuR6AnM": {
    "title": "Dataless Knowledge Fusion by Merging Weights of Language Models",
    "volume": "poster",
    "abstract": "Fine-tuning pre-trained language models has become the prevalent paradigm for building downstream NLP models. Oftentimes fine-tuned models are readily available but their training data is not, due to data privacy or intellectual property concerns. This creates a barrier to fusing knowledge across individual models to yield a better single model. In this paper, we study the problem of merging individual models built on different training data sets to obtain a single model that performs well both across all data set domains and can generalize on out-of-domain data. We propose a data-less knowledge fusion method that merges models in their parameter space, guided by weights that minimize prediction differences between the merged model and the individual models. Over a battery of evaluation settings, we show that the proposed method significantly outperforms baselines such as Fisher-weighted averaging or model ensembling. Further, we find that our method is a promising alternative to multi-task learning that can preserve or sometimes improve over the individual models without access to the training data. Finally, model merging is more efficient than training a multi-task model, thus making it applicable to a wider set of scenarios",
    "checked": true,
    "id": "3ff08b5ca57e786d8af7b204ef94c9972bd9a61e",
    "semantic_title": "dataless knowledge fusion by merging weights of language models",
    "citation_count": 291,
    "authors": []
  },
  "https://openreview.net/forum?id=PQOlkgsBsik": {
    "title": "Universal Vision-Language Dense Retrieval: Learning A Unified Representation Space for Multi-Modal Retrieval",
    "volume": "poster",
    "abstract": "This paper presents Universal Vision-Language Dense Retrieval (UniVL-DR), which builds a unified model for multi-modal retrieval. UniVL-DR encodes queries and multi-modality resources in an embedding space for searching candidates from different modalities. To learn a unified embedding space for multi-modal retrieval, UniVL-DR proposes two techniques: 1) Universal embedding optimization strategy, which contrastively optimizes the embedding space using the modality-balanced hard negatives; 2) Image verbalization method, which bridges the modality gap between images and texts in the raw data space. UniVL-DR achieves the state-of-the-art on the multi-modal open-domain question answering benchmark, WebQA, and outperforms all retrieval models on the two subtasks, text-text retrieval and text-image retrieval. It demonstrates that universal multi-modal search is feasible to replace the divide-and-conquer pipeline with a united model and also benefits single/cross modality tasks. All source codes of this work are available at https://github.com/OpenMatch/UniVL-DR",
    "checked": true,
    "id": "5bba7776f70edb9408a6fb38c0cfb1f2140d1f04",
    "semantic_title": "universal vision-language dense retrieval: learning a unified representation space for multi-modal retrieval",
    "citation_count": 43,
    "authors": []
  },
  "https://openreview.net/forum?id=5O2uzDusEN5": {
    "title": "DFlow: Learning to Synthesize Better Optical Flow Datasets via a Differentiable Pipeline",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "17ea8e59067745248683961a8de5d972b1f6a5d5",
    "semantic_title": "dflow: learning to synthesize better optical flow datasets via a differentiable pipeline",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=k1FHgri5y3-": {
    "title": "Sparse Random Networks for Communication-Efficient Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ffe13079f6e1d475e5e358ac5a1dbdd93c409015",
    "semantic_title": "sparse random networks for communication-efficient federated learning",
    "citation_count": 57,
    "authors": []
  },
  "https://openreview.net/forum?id=vVJZtlZB9D": {
    "title": "A General Framework For Proving The Equivariant Strong Lottery Ticket Hypothesis",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a7a3d734ecdcb3dec57fa66f708427147c65e692",
    "semantic_title": "a general framework for proving the equivariant strong lottery ticket hypothesis",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=4LMIZY7gt7h": {
    "title": "Robust Fair Clustering: A Novel Fairness Attack and Defense Framework",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6545eebb1162c70751119e173f8d51f5c112fcc1",
    "semantic_title": "robust fair clustering: a novel fairness attack and defense framework",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=UMERaIHMwB3": {
    "title": "Learning to Jointly Share and Prune Weights for Grounding Based Vision and Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "26a576dc6151ddac5fe30f1e652b37a8a854fd8f",
    "semantic_title": "learning to jointly share and prune weights for grounding based vision and language models",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=3DIpIf3wQMC": {
    "title": "Spatial Attention Kinetic Networks with E(n)-Equivariance",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c8697f4e9fb55bee80761be0f0b649e1cc63a0d3",
    "semantic_title": "spatial attention kinetic networks with e(n)-equivariance",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=OysfLgrk8mk": {
    "title": "Graph Domain Adaptation via Theory-Grounded Spectral Regularization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5a073c23190fe31d5555e5f600ca0c09d1ca6e96",
    "semantic_title": "graph domain adaptation via theory-grounded spectral regularization",
    "citation_count": 60,
    "authors": []
  },
  "https://openreview.net/forum?id=5aT4ganOd98": {
    "title": "CLARE: Conservative Model-Based Reward Learning for Offline Inverse Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "47ce36618ea2426b076e62fe4d5bedf86de708c1",
    "semantic_title": "clare: conservative model-based reward learning for offline inverse reinforcement learning",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=_hb4vM3jspB": {
    "title": "Data-Free One-Shot Federated Learning Under Very High Statistical Heterogeneity",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c9f8fd88b20d0618682869af5461152b7fa4d074",
    "semantic_title": "data-free one-shot federated learning under very high statistical heterogeneity",
    "citation_count": 59,
    "authors": []
  },
  "https://openreview.net/forum?id=8duT3mi_5n": {
    "title": "GReTo: Remedying dynamic graph topology-task discordance via target homophily",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "62c37b88f7660735242894dd9c8cfce1f8b62c5f",
    "semantic_title": "greto: remedying dynamic graph topology-task discordance via target homophily",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=0WVNuEnqVu": {
    "title": "Deep Reinforcement Learning for Cost-Effective Medical Diagnosis",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "00f742790f41f52b1bf5ab49d802293ecf3c211e",
    "semantic_title": "deep reinforcement learning for cost-effective medical diagnosis",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=chDrutUTs0K": {
    "title": "POPGym: Benchmarking Partially Observable Reinforcement Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c77112b5b2aff937ca071b349e47176b684c45b2",
    "semantic_title": "popgym: benchmarking partially observable reinforcement learning",
    "citation_count": 46,
    "authors": []
  },
  "https://openreview.net/forum?id=pOnhudsvzR": {
    "title": "Everybody Needs Good Neighbours: An Unsupervised Locality-based Method for Bias Mitigation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f65459842018463de592db3acaf3ca65a4774a4c",
    "semantic_title": "everybody needs good neighbours: an unsupervised locality-based method for bias mitigation",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=6OphWWAE3cS": {
    "title": "Particle-based Variational Inference with Preconditioned Functional Gradient Flow",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "63e4f8c60914d283871c08a781892b3b466d77d9",
    "semantic_title": "particle-based variational inference with preconditioned functional gradient flow",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=dPs6BGO2QT0": {
    "title": "Learning Locality and Isotropy in Dialogue Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "85b3d72e46d0ea77df7477430bef0f5b74f0d9c7",
    "semantic_title": "learning locality and isotropy in dialogue modeling",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=eKllxpLOOm": {
    "title": "Combating Exacerbated Heterogeneity for Robust Models in Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "25ffa7c814856551843025632f092239152aa43e",
    "semantic_title": "combating exacerbated heterogeneity for robust models in federated learning",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=vqSyt8D3ny": {
    "title": "Towards Robust Object Detection Invariant to Real-World Domain Shifts",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "928ca39340784fafca5411d5d45a322463a1aea6",
    "semantic_title": "towards robust object detection invariant to real-world domain shifts",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=yYEb8v65X8": {
    "title": "Light Sampling Field and BRDF Representation for Physically-based Neural Rendering",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "13bef1381dc0d1cda6e44624a00ac8691c83b8ba",
    "semantic_title": "light sampling field and brdf representation for physically-based neural rendering",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=X5SUR7g2vVw": {
    "title": "Policy Pre-training for Autonomous Driving via Self-supervised Geometric Modeling",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "aa5645b4896acb72aa4893d174af765d962aa708",
    "semantic_title": "policy pre-training for autonomous driving via self-supervised geometric modeling",
    "citation_count": 32,
    "authors": []
  },
  "https://openreview.net/forum?id=ju_Uqw384Oq": {
    "title": "TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "47696145b3f88c4cc3f3c22035286b5d7ebce09d",
    "semantic_title": "timesnet: temporal 2d-variation modeling for general time series analysis",
    "citation_count": 1096,
    "authors": []
  },
  "https://openreview.net/forum?id=gfPUokHsW-": {
    "title": "Learning without Prejudices: Continual Unbiased Learning via Benign and Malignant Forgetting",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "07e45677b989b4f97be107b8681bdf8994e9451d",
    "semantic_title": "learning without prejudices: continual unbiased learning via benign and malignant forgetting",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=tLScKVhcCR": {
    "title": "FINDE: Neural Differential Equations for Finding and Preserving Invariant Quantities",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b170b752042eee58985968080dc7c9a86374587b",
    "semantic_title": "finde: neural differential equations for finding and preserving invariant quantities",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=3ZPESALKXO": {
    "title": "Approximate Vanishing Ideal Computations at Scale",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "497c8444a3a9838ee344e688556351330647fd5a",
    "semantic_title": "approximate vanishing ideal computations at scale",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=qY1hlv7gwg": {
    "title": "Selective Annotation Makes Language Models Better Few-Shot Learners",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "86d0d3855f94105e25d81cab9f3d269c6062a9c4",
    "semantic_title": "selective annotation makes language models better few-shot learners",
    "citation_count": 279,
    "authors": []
  },
  "https://openreview.net/forum?id=PQ2zoIZqvm": {
    "title": "Switch-NeRF: Learning Scene Decomposition with Mixture of Experts for Large-scale Neural Radiance Fields",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "38db51e2f76d490d911ce8e8573c611f59c06376",
    "semantic_title": "switch-nerf: learning scene decomposition with mixture of experts for large-scale neural radiance fields",
    "citation_count": 99,
    "authors": []
  },
  "https://openreview.net/forum?id=CRNwGauQpb6": {
    "title": "NORM: Knowledge Distillation via N-to-One Representation Matching",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "71c2cf9a7348f435eb68633594f66892a5c999b8",
    "semantic_title": "norm: knowledge distillation via n-to-one representation matching",
    "citation_count": 74,
    "authors": []
  },
  "https://openreview.net/forum?id=ObtGcyKmwna": {
    "title": "Critic Sequential Monte Carlo",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0412360a27a92f621c889f4ee2701c5e805e0d6e",
    "semantic_title": "critic sequential monte carlo",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=8Oun8ZUVe8N": {
    "title": "Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image Transformers Help 3D Representation Learning?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "22471140ae31b15dd55241e4be0c8bb851961ddc",
    "semantic_title": "autoencoders as cross-modal teachers: can pretrained 2d image transformers help 3d representation learning?",
    "citation_count": 119,
    "authors": []
  },
  "https://openreview.net/forum?id=0Q9H_Pgx132": {
    "title": "Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0816489cd650186d32b3fd29da511d979cb667ef",
    "semantic_title": "deep learning meets nonparametric regression: are weight-decayed dnns locally adaptive?",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=VV0hSE8AxCw": {
    "title": "Sparse Token Transformer with Attention Back Tracking",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8b16dc5b4c0728147eef1647a6ab7f786333b76c",
    "semantic_title": "sparse token transformer with attention back tracking",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=ALDM5SN2r7M": {
    "title": "Robust Active Distillation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "175a2ed466f02c8fcef66b7ead61578700173e7c",
    "semantic_title": "robust active distillation",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=Zuc_MHtUma4": {
    "title": "Kernel Neural Optimal Transport",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "778da412ef4b6fee1b588bb30c8a645111e4fab9",
    "semantic_title": "kernel neural optimal transport",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=-qg8MQNrxZw": {
    "title": "SeaFormer: Squeeze-enhanced Axial Transformer for Mobile Semantic Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "14c0212a0831c7f66835e0495ffb461ca3517817",
    "semantic_title": "seaformer: squeeze-enhanced axial transformer for mobile semantic segmentation",
    "citation_count": 98,
    "authors": []
  },
  "https://openreview.net/forum?id=4UldFtZ_CVF": {
    "title": "Joint Edge-Model Sparse Learning is Provably Efficient for Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "377e5e0e5f4253442ad1e476c076a3928b031811",
    "semantic_title": "joint edge-model sparse learning is provably efficient for graph neural networks",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=TXPN6MtdSE4": {
    "title": "Learning Sparse and Low-Rank Priors for Image Recovery via Iterative Reweighted Least Squares Minimization",
    "volume": "poster",
    "abstract": "In this work we introduce a novel optimization algorithm for image recovery under learned sparse and low-rank constraints, which are parameterized with weighted extensions of the $\\ell_p^p$-vector and $\\mathcal{S}_p^p$ Schatten-matrix quasi-norms for $0\\!<p\\!\\le1$, respectively. Our proposed algorithm generalizes the Iteratively Reweighted Least Squares (IRLS) method, used for signal recovery under $\\ell_1$ and nuclear-norm constrained minimization. Further, we interpret our overall minimization approach as a recurrent network that we then employ to deal with inverse low-level computer vision problems. Thanks to the convergence guarantees that our IRLS strategy offers, we are able to train the derived reconstruction networks using a memory-efficient implicit back-propagation scheme, which does not pose any restrictions on their effective depth. To assess our networks' performance, we compare them against other existing reconstruction methods on several inverse problems, namely image deblurring, super-resolution, demosaicking and sparse recovery. Our reconstruction results are shown to be very competitive and in many cases outperform those of existing unrolled networks, whose number of parameters is orders of magnitude higher than that of our learned models",
    "checked": true,
    "id": "a03d8ef2c833dae678f3db750d423fa4f9cdbe2a",
    "semantic_title": "learning sparse and low-rank priors for image recovery via iterative reweighted least squares minimization",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=jXQ0ipgMdU": {
    "title": "Spherical Sliced-Wasserstein",
    "volume": "poster",
    "abstract": "Many variants of the Wasserstein distance have been introduced to reduce its original computational burden. In particular the Sliced-Wasserstein distance (SW), which leverages one-dimensional projections for which a closed-form solution of the Wasserstein distance is available, has received a lot of interest. Yet, it is restricted to data living in Euclidean spaces, while the Wasserstein distance has been studied and used recently on manifolds. We focus more specifically on the sphere, for which we define a novel SW discrepancy, which we call spherical Sliced-Wasserstein, making a first step towards defining SW discrepancies on manifolds. Our construction is notably based on closed-form solutions of the Wasserstein distance on the circle, together with a new spherical Radon transform. Along with efficient algorithms and the corresponding implementations, we illustrate its properties in several machine learning use cases where spherical representations of data are at stake: sampling on the sphere, density estimation on real eath data or hyperspherical auto-encoders",
    "checked": true,
    "id": "115807b57a3da1047b70818160a34ac08dd18e2f",
    "semantic_title": "spherical sliced-wasserstein",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=m6ahb1mpwwX": {
    "title": "InPL: Pseudo-labeling the Inliers First for Imbalanced Semi-supervised Learning",
    "volume": "poster",
    "abstract": "Recent state-of-the-art methods in imbalanced semi-supervised learning (SSL) rely on confidence-based pseudo-labeling with consistency regularization. To obtain high-quality pseudo-labels, a high confidence threshold is typically adopted. However, it has been shown that softmax-based confidence scores in deep networks can be arbitrarily high for samples far from the training data, and thus, the pseudo-labels for even high-confidence unlabeled samples may still be unreliable. In this work, we present a new perspective of pseudo-labeling for imbalanced SSL. Without relying on model confidence, we propose to measure whether an unlabeled sample is likely to be \"in-distribution''; i.e., close to the current training data. To decide whether an unlabeled sample is \"in-distribution'' or \"out-of-distribution'', we adopt the energy score from out-of-distribution detection literature. As training progresses and more unlabeled samples become in-distribution and contribute to training, the combined labeled and pseudo-labeled data can better approximate the true class distribution to improve the model. Experiments demonstrate that our energy-based pseudo-labeling method, InPL, albeit conceptually simple, significantly outperforms confidence-based methods on imbalanced SSL benchmarks. For example, it produces a 4-6% absolute accuracy improvement on CIFAR10-LT when the imbalance ratio is higher than 50. When combined with state-of-the-art long-tailed SSL methods, further improvements are attained. In particular, in one of the most challenging scenarios, InPL achieves a 6.9% accuracy improvement over the best competitor",
    "checked": true,
    "id": "533dea0d2d76ade54d31a6c189e832ac192ea666",
    "semantic_title": "inpl: pseudo-labeling the inliers first for imbalanced semi-supervised learning",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=-CefY2EOupj": {
    "title": "Maximizing Communication Efficiency for Large-scale Training via 0/1 Adam",
    "volume": "poster",
    "abstract": "1-bit gradient compression and local steps are two representative techniques that enable drastic communication reduction in distributed SGD. Their benefits, however, remain an open question on Adam-based large model pre-training (e.g. BERT and GPT). In this paper, we demonstrate the non-linearity in Adam causes slow convergence even when 1-bit compression or local steps are individually applied. To alleviate this limitation, we propose \\textbf{0/1 Adam} that linearizes each Adam step via approximating its optimizer states using their stale estimates and linear correlation. \\textbf{0/1 Adam} performs an Adam-like step to preserve the adaptivity, while its linearity allows utilizing 1-bit compression and local steps simultaneously for wall-clock time speed up. We provide convergence guarantee for \\textbf{0/1 Adam} on smooth non-convex objectives. On various large-scale benchmarks such as BERT-Base, BERT-Large, GPT-2 pre-training and ImageNet, we demonstrate on up to 128 GPUs that \\textbf{0/1 Adam} is able to reduce up to 87\\% of data volume, 54\\% of communication rounds, and achieve up to 2$\\times$ higher training throughput and end-to-end training time reduction compared to the state-of-the-art baseline 1-bit Adam; while enjoying the same statistical convergence speed and end task model accuracy on GLUE dataset and ImageNet validation set",
    "checked": true,
    "id": "98850975e574e08695a9f32b4c8747dc7f8bcc17",
    "semantic_title": "maximizing communication efficiency for large-scale training via 0/1 adam",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=WVRb98rwbv9": {
    "title": "Truthful Self-Play",
    "volume": "poster",
    "abstract": "We present a general framework for evolutionary learning to emergent unbiased state representation without any supervision. Evolutionary frameworks such as self-play converge to bad local optima in case of multi-agent reinforcement learning in non-cooperative partially observable environments with communication due to information asymmetry. Our proposed framework is a simple modification of self-play inspired by mechanism design, also known as {\\em reverse game theory}, to elicit truthful signals and make the agents cooperative. The key idea is to add imaginary rewards using the peer prediction method, i.e., a mechanism for evaluating the validity of information exchanged between agents in a decentralized environment. Numerical experiments with predator prey, traffic junction and StarCraft tasks demonstrate that the state-of-the-art performance of our framework",
    "checked": true,
    "id": "938d660945bea4ef41d5379fd7b1624ad8a6f4a3",
    "semantic_title": "truthful self-play",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TuHkVOjSAR": {
    "title": "Strategic Classification with Graph Neural Networks",
    "volume": "poster",
    "abstract": "Strategic classification studies learning in settings where users can modify their features to obtain favorable predictions. Most current works focus on simple classifiers that trigger independent user responses. Here we examine the implications of learning with more elaborate models that break the independence assumption. Motivated by the idea that applications of strategic classification are often social in nature, we focus on graph neural networks, which make use of social relations between users to improve predictions. Using a graph for learning introduces inter-user dependencies in prediction; our key point is that strategic users can exploit these to promote their goals. As we show through analysis and simulation, this can work either against the system---or for it. Based on this, we propose a differentiable framework for strategically-robust learning of graph-based classifiers. Experiments on several real networked datasets demonstrate the utility of our approach",
    "checked": true,
    "id": "cc435dddfb8042b518444502507bbc1e62c1a3ff",
    "semantic_title": "strategic classification with graph neural networks",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=PolHquob8M7": {
    "title": "Continual Transformers: Redundancy-Free Attention for Online Inference",
    "volume": "poster",
    "abstract": "Transformers in their common form are inherently limited to operate on whole token sequences rather than on one token at a time. Consequently, their use during online inference on time-series data entails considerable redundancy due to the overlap in successive token sequences. In this work, we propose novel formulations of the Scaled Dot-Product Attention, which enable Transformers to perform efficient online token-by-token inference on a continual input stream. Importantly, our modifications are purely to the order of computations, while the outputs and learned weights are identical to those of the original Transformer Encoder. We validate our Continual Transformer Encoder with experiments on the THUMOS14, TVSeries and GTZAN datasets with remarkable results: Our Continual one- and two-block architectures reduce the floating point operations per prediction by up to 63x and 2.6x, respectively, while retaining predictive performance",
    "checked": true,
    "id": "d10864946d1733444f0472acf1294f15b350e65e",
    "semantic_title": "continual transformers: redundancy-free attention for online inference",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=f2wN4v_2__W": {
    "title": "Learning Symbolic Models for Graph-structured Physical Mechanism",
    "volume": "poster",
    "abstract": "Graph-structured physical mechanisms are ubiquitous in real-world scenarios, thus revealing underneath formulas is of great importance for scientific discovery. However, classical symbolic regression methods fail on this task since they can only handle input-output pairs that are not graph-structured. In this paper, we propose a new approach that generalizes symbolic regression to graph-structured physical mechanisms. The essence of our method is to model the formula skeleton with a message-passing flow, which helps transform the discovery of the skeleton into the search for the message-passing flow. Such a transformation guarantees that we are able to search a message-passing flow, which is efficient and Pareto-optimal in terms of both accuracy and simplicity. Subsequently, the underneath formulas can be identified by interpreting component functions of the searched message-passing flow, reusing classical symbolic regression methods. We conduct extensive experiments on datasets from different physical domains, including mechanics, electricity, and thermology, and on real-world datasets of pedestrian dynamics without ground-truth formulas. The experimental results not only verify the rationale of our design but also demonstrate that the proposed method can automatically learn precise and interpretable formulas for graph-structured physical mechanisms",
    "checked": true,
    "id": "7f7deb561b23936c47f984d3cfac5ecad182412a",
    "semantic_title": "learning symbolic models for graph-structured physical mechanism",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=0v4VkCSkHNm": {
    "title": "Priors, Hierarchy, and Information Asymmetry for Skill Transfer in Reinforcement Learning",
    "volume": "poster",
    "abstract": "The ability to discover behaviours from past experience and transfer them to new tasks is a hallmark of intelligent agents acting sample-efficiently in the real world. Equipping embodied reinforcement learners with the same ability may be crucial for their successful deployment in robotics. While hierarchical and KL-regularized reinforcement learning individually hold promise here, arguably a hybrid approach could combine their respective benefits. Key to these fields is the use of information asymmetry across architectural modules to bias which skills are learnt. While asymmetry choice has a large influence on transferability, existing methods base their choice primarily on intuition in a domain-independent, potentially sub-optimal, manner. In this paper, we theoretically and empirically show the crucial expressivity-transferability trade-off of skills across sequential tasks, controlled by information asymmetry. Given this insight, we introduce Attentive Priors for Expressive and Transferable Skills (APES), a hierarchical KL-regularized method, heavily benefiting from both priors and hierarchy. Unlike existing approaches, APES automates the choice of asymmetry by learning it in a data-driven, domain-dependent, way based on our expressivity-transferability theorems. Experiments over complex transfer domains of varying levels of extrapolation and sparsity, such as robot block stacking, demonstrate the criticality of the correct asymmetric choice, with APES drastically outperforming previous methods",
    "checked": true,
    "id": "546bff6c12ea395690292f204a7e019a8b3b87a0",
    "semantic_title": "priors, hierarchy, and information asymmetry for skill transfer in reinforcement learning",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=kIAx30hYi_p": {
    "title": "Self-Supervised Set Representation Learning for Unsupervised Meta-Learning",
    "volume": "poster",
    "abstract": "Unsupervised meta-learning (UML) essentially shares the spirit of self-supervised learning (SSL) in that their goal aims at learning models without any human supervision so that the models can be adapted to downstream tasks. Further, the learning objective of self-supervised learning, which pulls positive pairs closer and repels negative pairs, also resembles metric-based meta-learning. Metric-based meta-learning is one of the most successful meta-learning methods, which learns to minimize the distance between representations from the same class. One notable aspect of metric-based meta-learning, however, is that it is widely interpreted as a set-level problem since the inference of discriminative class prototypes (or set representations) from few examples is crucial for the performance of downstream tasks. Motivated by this, we propose Set-SimCLR, a novel self-supervised set representation learning framework for targeting UML problem. Specifically, our Set-SimCLR learns a set encoder on top of instance representations to maximize the agreement between two sets of augmented samples, which are generated by applying stochastic augmentations to a given image. We theoretically analyze how our proposed set representation learning can potentially improve the generalization performance at the meta-test. We also empirically validate its effectiveness on various benchmark datasets, showing that Set-SimCLR largely outperforms both UML and instance-level self-supervised learning baselines",
    "checked": true,
    "id": "dfacf2f1c11049895598d0c33a6576177d3b17fc",
    "semantic_title": "self-supervised set representation learning for unsupervised meta-learning",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=itZ6ggvMnzS": {
    "title": "Causal Representation Learning for Instantaneous and Temporal Effects in Interactive Systems",
    "volume": "poster",
    "abstract": "Causal representation learning is the task of identifying the underlying causal variables and their relations from high-dimensional observations, such as images. Recent work has shown that one can reconstruct the causal variables from temporal sequences of observations under the assumption that there are no instantaneous causal relations between them. In practical applications, however, our measurement or frame rate might be slower than many of the causal effects. This effectively creates ``instantaneous'' effects and invalidates previous identifiability results. To address this issue, we propose iCITRIS, a causal representation learning method that allows for instantaneous effects in intervened temporal sequences when intervention targets can be observed, e.g., as actions of an agent. iCITRIS identifies the potentially multidimensional causal variables from temporal observations, while simultaneously using a differentiable causal discovery method to learn their causal graph. In experiments on three datasets of interactive systems, iCITRIS accurately identifies the causal variables and their causal graph",
    "checked": true,
    "id": "c76ddc26e14d43382ec52ab574150b353817a6a5",
    "semantic_title": "causal representation learning for instantaneous and temporal effects in interactive systems",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=OnM3R47KIiU": {
    "title": "Visual Imitation Learning with Patch Rewards",
    "volume": "poster",
    "abstract": "Visual imitation learning enables reinforcement learning agents to learn to behave from expert visual demonstrations such as videos or image sequences, without explicit, well-defined rewards. Previous reseaches either adopt supervised learning techniques or induce simple and coarse scalar rewards from pixels, neglecting the dense information contained in the image demonstrations. In this work, we propose to measure the expertise of various local regions of image samples, or called patches, and recover multi-dimensional patch rewards accordingly. Patch reward is a more precise rewarding characterization that serves as fine-grained expertise measurement and visual explainability tool. Specifically, we present Adversarial Imitation Learning with Patch Rewards (PatchAIL), which employs a patch-based discriminator to measure the expertise of different local parts from given images and provide patch rewards. The patch-based knowledge is also used to regularize the aggregated reward and stabilize the training. We evaluate our method on the standard pixel-based benchmark DeepMind Control Suite. The experiment results have demonstrated that PatchAIL outperforms baseline methods and provides valuable interpretations for visual demonstrations",
    "checked": true,
    "id": "017844bd5429a27c46b434903dc0e60ebf215f90",
    "semantic_title": "visual imitation learning with patch rewards",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=ktrw68Cmu9c": {
    "title": "CodeT: Code Generation with Generated Tests",
    "volume": "poster",
    "abstract": "The task of generating code solutions for a given programming problem can benefit from the use of pre-trained language models such as Codex, which can produce multiple diverse samples. However, a major challenge for this task is to select the most appropriate solution from the multiple samples generated by the pre-trained language models. A natural way to evaluate the quality and correctness of a code solution is to run it against a set of test cases, but the manual creation of such test cases is often costly and time-consuming. In this paper, we propose a novel method, CodeT, that leverages the same pre-trained language models to automatically generate test cases for the code samples, thus reducing the human effort and increasing the coverage of the test scenarios. CodeT then executes the code samples using the generated test cases, and performs a dual execution agreement, which considers both the consistency of the outputs against the generated test cases and the agreement of the outputs with other code samples. We conduct comprehensive experiments on four benchmarks, HumanEval, MBPP, APPS and CodeContests, using five different pre-trained language models with varying sizes and capabilities. Our results show that CodeT can significantly improve the performance of code solution selection over previous methods, achieving remarkable and consistent gains across different models and benchmarks. For instance, CodeT improves the pass@1 metric on HumanEval to 65.8%, which represents an absolute improvement of 18.8% over the code-davinci-002 model, and an absolute improvement of more than 20% over the previous state-of-the-art results",
    "checked": true,
    "id": "876eb375cb7b365475040046df669c039ad54202",
    "semantic_title": "codet: code generation with generated tests",
    "citation_count": 385,
    "authors": []
  },
  "https://openreview.net/forum?id=JHW30A4DXtO": {
    "title": "Learning to Generate Columns with Application to Vertex Coloring",
    "volume": "poster",
    "abstract": "We present a new column generation approach based on Machine Learning (ML) for solving combinatorial optimization problems. The aim of our method is to generate high-quality columns that belong to an optimal integer solution, in contrast to the traditional approach that aims at solving linear programming relaxations. To achieve this aim, we design novel features to characterize a column, and develop an effective ML model to predict whether a column belongs to an optimal integer solution. We then use the ML model as a filter to select high-quality columns generated from a sampling method and use the selected columns to construct an integer solution. Our method is computationally fast compared to the traditional methods that generate columns by repeatedly solving a pricing problem. We demonstrate the efficacy of our method on the vertex coloring problem, by empirically showing that the columns selected by our ML model are significantly better, in terms of the integer solution that can be constructed from them, than those selected randomly or based only on their reduced cost. Further, we show that the columns generated by our method can be used as a warm start to boost the performance of a column generation-based heuristic",
    "checked": true,
    "id": "4e84a56f1a2055cfe262649d5a39255494356af0",
    "semantic_title": "learning to generate columns with application to vertex coloring",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=XUxad2Gj40n": {
    "title": "EVC: Towards Real-Time Neural Image Compression with Mask Decay",
    "volume": "poster",
    "abstract": "Neural image compression has surpassed state-of-the-art traditional codecs (H.266/VVC) for rate-distortion (RD) performance, but suffers from large complexity and separate models for different rate-distortion trade-offs. In this paper, we propose an Efficient single-model Variable-bit-rate Codec (EVC), which is able to run at 30 FPS with 768x512 input images and still outperforms VVC for the RD performance. By further reducing both encoder and decoder complexities, our small model even achieves 30 FPS with 1920x1080 input images. To bridge the performance gap between our different capacities models, we meticulously design the mask decay, which transforms the large model's parameters into the small model automatically. And a novel sparsity regularization loss is proposed to mitigate shortcomings of $L_p$ regularization. Our algorithm significantly narrows the performance gap by 50% and 30% for our medium and small models, respectively. At last, we advocate the scalable encoder for neural image compression. The encoding complexity is dynamic to meet different latency requirements. We propose decaying the large encoder multiple times to reduce the residual representation progressively. Both mask decay and residual representation learning greatly improve the RD performance of our scalable encoder. Our code is at https://github.com/microsoft/DCVC",
    "checked": true,
    "id": "04251d3850f2703ef6ea5c8b332d988155acd6e2",
    "semantic_title": "evc: towards real-time neural image compression with mask decay",
    "citation_count": 80,
    "authors": []
  },
  "https://openreview.net/forum?id=ICYasJBlZNs": {
    "title": "Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information",
    "volume": "poster",
    "abstract": "Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations (perturbations that this cell did not factually receive), leveraging information representing biological knowledge in the form of gene regulatory networks (GRNs) to aid individualized cellular response predictions. Aiming at a data-adaptive GRN, we also developed an adjacency matrix updating technique for graph convolutional networks and used it to refine GRNs during pre-training, which generated more insights on gene relations and enhanced model performance. Additionally, we propose a robust estimator within our framework for the asymptotically efficient estimation of marginal perturbation effect, which is yet to be carried out in previous works. With extensive experiments, we exhibited the advantage of our approach over state-of-the-art deep learning models for individual response prediction",
    "checked": true,
    "id": "4588ed2b6771693f49090af31eedc1e60a68d633",
    "semantic_title": "predicting cellular responses with variational causal inference and refined relational information",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=HmPOzJQhbwg": {
    "title": "ResAct: Reinforcing Long-term Engagement in Sequential Recommendation with Residual Actor",
    "volume": "poster",
    "abstract": "Long-term engagement is preferred over immediate engagement in sequential recommendation as it directly affects product operational metrics such as daily active users (DAUs) and dwell time. Meanwhile, reinforcement learning (RL) is widely regarded as a promising framework for optimizing long-term engagement in sequential recommendation. However, due to expensive online interactions, it is very difficult for RL algorithms to perform state-action value estimation, exploration and feature extraction when optimizing long-term engagement. In this paper, we propose ResAct which seeks a policy that is close to, but better than, the online-serving policy. In this way, we can collect sufficient data near the learned policy so that state-action values can be properly estimated, and there is no need to perform online exploration. ResAct optimizes the policy by first reconstructing the online behaviors and then improving it via a Residual Actor. To extract long-term information, ResAct utilizes two information-theoretical regularizers to confirm the expressiveness and conciseness of features. We conduct experiments on a benchmark dataset and a large-scale industrial dataset which consists of tens of millions of recommendation requests. Experimental results show that our method significantly outperforms the state-of-the-art baselines in various long-term engagement optimization tasks",
    "checked": true,
    "id": "aa211fe8b25eaf2d38ac4c69599f12ce61c584ec",
    "semantic_title": "resact: reinforcing long-term engagement in sequential recommendation with residual actor",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=4wZiAXD29TQ": {
    "title": "Dataset Pruning: Reducing Training Data by Examining Generalization Influence",
    "volume": "poster",
    "abstract": "The great success of deep learning heavily relies on increasingly larger training data, which comes at a price of huge computational and infrastructural costs. This poses crucial questions that, do all training data contribute to model's performance? How much does each individual training sample or a sub-training-set affect the model's generalization, and how to construct the smallest subset from the entire training data as a proxy training set without significantly sacrificing the model's performance? To answer these, we propose dataset pruning, an optimization-based sample selection method that can (1) examine the influence of removing a particular set of training samples on model's generalization ability with theoretical guarantee, and (2) construct the smallest subset of training data that yields strictly constrained generalization gap. The empirically observed generalization gap of dataset pruning is substantially consistent with our theoretical expectations. Furthermore, the proposed method prunes 40% training examples on the CIFAR-10 dataset, halves the convergence time with only 1.3% test accuracy decrease, which is superior to previous score-based sample selection methods",
    "checked": true,
    "id": "b2a030a5fff73e0ccba312a5d3a7fb177bb61072",
    "semantic_title": "dataset pruning: reducing training data by examining generalization influence",
    "citation_count": 130,
    "authors": []
  },
  "https://openreview.net/forum?id=HE_75XY5Ljh": {
    "title": "StrucTexTv2: Masked Visual-Textual Prediction for Document Image Pre-training",
    "volume": "poster",
    "abstract": "In this paper, we present StrucTexTv2, an effective document image pre-training framework, by performing masked visual-textual prediction. It consists of two self-supervised pre-training tasks: masked image modeling and masked language modeling, based on text region-level image masking. The proposed method randomly masks some image regions according to the bounding box coordinates of text words. The objectives of our pre-training tasks are reconstructing the pixels of masked image regions and the corresponding masked tokens simultaneously. Hence the pre-trained encoder can capture more textual semantics in comparison to the masked image modeling that usually predicts the masked image patches. Compared to the masked multi-modal modeling methods for document image understanding that rely on both the image and text modalities, StrucTexTv2 models image-only input and potentially deals with more application scenarios free from OCR pre-processing. Extensive experiments on mainstream benchmarks of document image understanding demonstrate the effectiveness of StrucTexTv2. It achieves competitive or even new state-of-the-art performance in various downstream tasks such as image classification, layout analysis, table structure recognition, document OCR, and information extraction under the end-to-end scenario",
    "checked": true,
    "id": "7ed32e4a8e7ee87b2c441acd2b88ad012159eccf",
    "semantic_title": "structextv2: masked visual-textual prediction for document image pre-training",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=z289SIQOQna": {
    "title": "Plateau in Monotonic Linear Interpolation --- A \"Biased\" View of Loss Landscape for Deep Networks",
    "volume": "poster",
    "abstract": "Monotonic linear interpolation (MLI) --- on the line connecting a random initialization with the minimizer it converges to, the loss and accuracy are monotonic --- is a phenomenon that is commonly observed in the training of neural networks. Such a phenomenon may seem to suggest that optimization of neural networks is easy. In this paper, we show that the MLI property is not necessarily related to the hardness of optimization problems, and empirical observations on MLI for deep neural networks depend heavily on the biases. In particular, we show that interpolating both weights and biases linearly leads to very different influences on the final output, and when different classes have different last-layer biases on a deep network, there will be a long plateau in both the loss and accuracy interpolation (which existing theory of MLI cannot explain). We also show how the last-layer biases for different classes can be different even on a perfectly balanced dataset using a simple model. Empirically we demonstrate that similar intuitions hold on practical networks and realistic datasets",
    "checked": false,
    "id": "92f1b57b897479120c6eb74713c3de50f95c2b24",
    "semantic_title": "plateau in monotonic linear interpolation - a \"biased\" view of loss landscape for deep networks",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=qUKsCztWlKq": {
    "title": "The KFIoU Loss for Rotated Object Detection",
    "volume": "poster",
    "abstract": "Differing from the well-developed horizontal object detection area whereby the computing-friendly IoU based loss is readily adopted and well fits with the detection metrics, rotation detectors often involve a more complicated loss based on SkewIoU which is unfriendly to gradient-based training. In this paper, we propose an effective approximate SkewIoU loss based on Gaussian modeling and Gaussian product, which mainly consists of two items. The first term is a scale-insensitive center point loss, which is used to quickly narrow the distance between the center points of the two bounding boxes. In the distance-independent second term, the product of the Gaussian distributions is adopted to inherently mimic the mechanism of SkewIoU by its definition, and show its alignment with the SkewIoU loss at trend-level within a certain distance (i.e. within 9 pixels). This is in contrast to recent Gaussian modeling based rotation detectors e.g. GWD loss and KLD loss that involve a human-specified distribution distance metric which require additional hyperparameter tuning that vary across datasets and detectors. The resulting new loss called KFIoU loss is easier to implement and works better compared with exact SkewIoU loss, thanks to its full differentiability and ability to handle the non-overlapping cases. We further extend our technique to the 3-D case which also suffers from the same issues as 2-D. Extensive results on various datasets with different base detectors show the effectiveness of our approach",
    "checked": true,
    "id": "698e7311b84cb5fdfb28994f388d7448cfd008f9",
    "semantic_title": "the kfiou loss for rotated object detection",
    "citation_count": 193,
    "authors": []
  },
  "https://openreview.net/forum?id=xmcYx_reUn6": {
    "title": "BrainBERT: Self-supervised representation learning for intracranial recordings",
    "volume": "poster",
    "abstract": "We create a reusable Transformer, BrainBERT, for intracranial recordings bringing modern representation learning approaches to neuroscience. Much like in NLP and speech recognition, this Transformer enables classifying complex concepts, i.e., decoding neural data, with higher accuracy and with much less data by being pretrained in an unsupervised manner on a large corpus of unannotated neural recordings. Our approach generalizes to new subjects with electrodes in new positions and to unrelated tasks showing that the representations robustly disentangle the neural signal. Just like in NLP where one can study language by investigating what a language model learns, this approach opens the door to investigating the brain by what a model of the brain learns. As a first step along this path, we demonstrate a new analysis of the intrinsic dimensionality of the computations in different areas of the brain. To construct these representations, we combine a technique for producing super-resolution spectrograms of neural data with an approach designed for generating contextual representations of audio by masking. In the future, far more concepts will be decodable from neural recordings by using representation learning, potentially unlocking the brain like language models unlocked language",
    "checked": true,
    "id": "bbb943fdb5e4f4f2d1642e13cb86865f711bcb2d",
    "semantic_title": "brainbert: self-supervised representation learning for intracranial recordings",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=XWkWK2UagFR": {
    "title": "General Neural Gauge Fields",
    "volume": "poster",
    "abstract": "The recent advance of neural fields, such as neural radiance fields, has significantly pushed the boundary of scene representation learning. Aiming to boost the computation efﬁciency and rendering quality of 3D scenes, a popular line of research maps the 3D coordinate system to another measuring system, e.g., 2D manifolds and hash tables, for modeling neural fields. The conversion of coordinate systems can be typically dubbed as \\emph{gauge transformation}, which is usually a pre-defined mapping function, e.g., orthogonal projection or spatial hash function. This begs a question: can we directly learn a desired gauge transformation along with the neural field in an end-to-end manner? In this work, we extend this problem to a general paradigm with a taxonomy of discrete and continuous cases, and develop an end-to-end learning framework to jointly optimize the gauge transformation and neural fields. To counter the problem that the learning of gauge transformations can collapse easily, we derive a general regularization mechanism from the principle of information conservation during the gauge transformation. To circumvent the high computation cost in gauge learning with regularization, we directly derive an information-invariant gauge transformation which allows to preserve scene information inherently and yield superior performance",
    "checked": true,
    "id": "8bb623ccc055f9806b5a81f7090fe67abbb4ff2d",
    "semantic_title": "general neural gauge fields",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=fB0hRu9GZUS": {
    "title": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
    "volume": "poster",
    "abstract": "Knowledge-intensive tasks, such as open-domain question answering (QA), require access to a large amount of world or domain knowledge. A common approach for knowledge-intensive tasks is to employ a retrieve-then-read pipeline that first retrieves a handful of relevant contextual documents from an external corpus such as Wikipedia and then predicts an answer conditioned on the retrieved documents. In this paper, we present a novel perspective for solving knowledge-intensive tasks by replacing document retrievers with large language model generators. We call our method generate-then-read (GenRead), which first prompts a large language model to generate contextual documents based on a given question, and then reads the generated documents to produce the final answer. Furthermore, we propose a novel clustering-based prompting method that selects distinct prompts, in order to generate diverse documents that cover different perspectives, leading to better recall over acceptable answers. We conduct extensive experiments on three different knowledge-intensive tasks, including open-domain QA, fact checking, and dialogue system. Notably, GenRead achieves 71.6 and 54.4 exact match scores on TriviaQA and WebQ, significantly outperforming the state-of-the-art retrieve-then-read pipeline DPR-FiD by +4.0 and +3.9, without retrieving any documents from any external knowledge source. Lastly, we demonstrate the model performance can be further improved by combining retrieval and generation. Our code and generated documents can be found at https://github.com/wyu97/GenRead",
    "checked": true,
    "id": "b2542a738b75ee9b7ce1a13d8b78f9095d212412",
    "semantic_title": "generate rather than retrieve: large language models are strong context generators",
    "citation_count": 366,
    "authors": []
  },
  "https://openreview.net/forum?id=vk-j5pQY3Gv": {
    "title": "Discovering Informative and Robust Positives for Video Domain Adaptation",
    "volume": "poster",
    "abstract": "Unsupervised domain adaptation for video recognition is challenging where the domain shift includes both spatial variations and temporal dynamics. Previous works have focused on exploring contrastive learning for cross-domain alignment. However, limited variations in intra-domain positives, false cross-domain positives, and false negatives hinder contrastive learning from fulfilling intra-domain discrimination and cross-domain closeness. This paper presents a non-contrastive learning framework without relying on negative samples for unsupervised video domain adaptation. To address the limited variations in intra-domain positives, we set unlabeled target videos as anchors and explored to mine \"informative intra-domain positives\" in the form of spatial/temporal augmentations and target nearest neighbors (NNs). To tackle the false cross-domain positives led by noisy pseudo-labels, we reversely set source videos as anchors and sample the synthesized target videos as \"robust cross-domain positives\" from an estimated target distribution, which are naturally more robust to the pseudo-label noise. Our approach is demonstrated to be superior to state-of-the-art methods through extensive experiments on several cross-domain action recognition benchmarks",
    "checked": true,
    "id": "256d7fb66db5a835f8ba32f10f56899b7f318c17",
    "semantic_title": "discovering informative and robust positives for video domain adaptation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=ashPce_W8F-": {
    "title": "Understanding Why Generalized Reweighting Does Not Improve Over ERM",
    "volume": "poster",
    "abstract": "Empirical risk minimization (ERM) is known to be non-robust in practice to distributional shift where the training and the test distributions are different. A suite of approaches, such as importance weighting, and variants of distributionally robust optimization (DRO), have been proposed to solve this problem. But a line of recent work has empirically shown that these approaches do not significantly improve over ERM in real applications with distribution shift. The goal of this work is to obtain a comprehensive theoretical understanding of this intriguing phenomenon. We first posit the class of Generalized Reweighting (GRW) algorithms, as a broad category of approaches that iteratively update model parameters based on iterative reweighting of the training samples. We show that when overparameterized models are trained under GRW, the resulting models are close to that obtained by ERM. We also show that adding small regularization which does not greatly affect the empirical training accuracy does not help. Together, our results show that a broad category of what we term GRW approaches are not able to achieve distributionally robust generalization. Our work thus has the following sobering takeaway: to make progress towards distributionally robust generalization, we either have to develop non-GRW approaches, or perhaps devise novel classification/regression loss functions that are adapted to GRW approaches",
    "checked": true,
    "id": "0399be055f69e07a360dd4537c6f6304ff8c6ddc",
    "semantic_title": "understanding why generalized reweighting does not improve over erm",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=hY6M0JHl3uL": {
    "title": "Linear Connectivity Reveals Generalization Strategies",
    "volume": "poster",
    "abstract": "In the mode connectivity literature, it is widely accepted that there are common circumstances in which two neural networks, trained similarly on the same data, will maintain loss when interpolated in the weight space. In particular, transfer learning is presumed to ensure the necessary conditions for linear mode connectivity across training runs. In contrast to existing results from image classification, we find that among text classifiers (trained on MNLI, QQP, and CoLA), some pairs of finetuned models have large barriers of increasing loss on the linear paths between them. On each task, we find distinct clusters of models which are linearly connected on the test loss surface, but are disconnected from models outside the cluster---models that occupy separate basins on the surface. By measuring performance on specially-crafted diagnostic datasets, we find that these clusters correspond to different generalization strategies. For example, on MNLI, one cluster behaves like a bag of words model under domain shift, while another cluster uses syntactic heuristics. Our work demonstrates how the geometry of the loss surface can guide models towards different heuristic functions in standard finetuning settings",
    "checked": true,
    "id": "4ebac708d34577c73dbdb392a6531e82d4d5145c",
    "semantic_title": "linear connectivity reveals generalization strategies",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=9DZKk85Z4zA": {
    "title": "Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models",
    "volume": "poster",
    "abstract": "Learning energy-based models (EBMs) is known to be difficult especially on discrete data where gradient-based learning strategies cannot be applied directly. Although ratio matching is a sound method to learn discrete EBMs, it suffers from expensive computation and excessive memory requirements, thereby resulting in difficulties in learning EBMs on high-dimensional data. Motivated by these limitations, in this study, we propose ratio matching with gradient-guided importance sampling (RMwGGIS). Particularly, we use the gradient of the energy function w.r.t. the discrete data space to approximately construct the provably optimal proposal distribution, which is subsequently used by importance sampling to efficiently estimate the original ratio matching objective. We perform experiments on density modeling over synthetic discrete data, graph generation, and training Ising models to evaluate our proposed method. The experimental results demonstrate that our method can significantly alleviate the limitations of ratio matching, perform more effectively in practice, and scale to high-dimensional problems. Our implementation is available at https://github.com/divelab/RMwGGIS",
    "checked": true,
    "id": "40471ac761012724498954fd014ed68191e239d9",
    "semantic_title": "gradient-guided importance sampling for learning binary energy-based models",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=gmwDKo-4cY": {
    "title": "Composing Ensembles of Pre-trained Models via Iterative Consensus",
    "volume": "poster",
    "abstract": "Large pre-trained models exhibit distinct and complementary capabilities dependent on the data they are trained on. Language models such as GPT-3 are capable of textual reasoning but cannot understand visual information, while vision models such as DALL-E can generate photorealistic photos but fail to understand complex language descriptions. In this work, we propose a unified framework for composing ensembles of different pre-trained models -- combining the strengths of each individual model to solve various multimodal problems in a zero-shot manner. We use pre-trained models as \"generators\" or \"scorers\" and compose them via closed-loop iterative consensus optimization. The generator constructs proposals and the scorers iteratively provide feedback to refine the generated result. Such closed-loop communication enables models to correct errors caused by other models, significantly boosting performance on downstream tasks, e.g. improving accuracy on grade school math problems by 7.5%, without requiring any model finetuning. We demonstrate that consensus achieved by an ensemble of scorers outperforms the feedback of a single scorer, by leveraging the strengths of each expert model. Results show that the proposed method can be used as a general purpose framework for a wide range of zero-shot multimodal tasks, such as image generation, video question answering, mathematical reasoning, and robotic manipulation",
    "checked": true,
    "id": "f3a13abf23afecf534c955954d70c3b0fc41d334",
    "semantic_title": "composing ensembles of pre-trained models via iterative consensus",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=vTb1JI0Gps_": {
    "title": "Automated Data Augmentations for Graph Classification",
    "volume": "poster",
    "abstract": "Data augmentations are effective in improving the invariance of learning machines. We argue that the core challenge of data augmentations lies in designing data transformations that preserve labels. This is relatively straightforward for images, but much more challenging for graphs. In this work, we propose GraphAug, a novel automated data augmentation method aiming at computing label-invariant augmentations for graph classification. Instead of using uniform transformations as in existing studies, GraphAug uses an automated augmentation model to avoid compromising critical label-related information of the graph, thereby producing label-invariant augmentations at most times. To ensure label-invariance, we develop a training method based on reinforcement learning to maximize an estimated label-invariance probability. Experiments show that GraphAug outperforms previous graph augmentation methods on various graph classification tasks",
    "checked": true,
    "id": "e8b693712629de41c86898eefcefd79fd4c39ec3",
    "semantic_title": "automated data augmentations for graph classification",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=v3y68gz-WEz": {
    "title": "Riemannian Metric Learning via Optimal Transport",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "0e001e0dc8e4e2b91c39ab10e01897266338f6c3",
    "semantic_title": "riemannian metric learning via optimal transport",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=8HRvyxc606": {
    "title": "Reliability of CKA as a Similarity Measure in Deep Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "dfb149bfbfb81de225dbad69aac41ffa617141e8",
    "semantic_title": "reliability of cka as a similarity measure in deep learning",
    "citation_count": 44,
    "authors": []
  },
  "https://openreview.net/forum?id=9vcXCMp9VEp": {
    "title": "Fair Attribute Completion on Graph with Missing Attributes",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4bee03667291e316e9427afa2b515abdff11cbc6",
    "semantic_title": "fair attribute completion on graph with missing attributes",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=_ruvo2KCL2x": {
    "title": "Deep Ranking Ensembles for Hyperparameter Optimization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fa06d4b3938cafd2220436aa62ede8fa3c83dd57",
    "semantic_title": "deep ranking ensembles for hyperparameter optimization",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=kUI41mY8bHl": {
    "title": "Robustness to corruption in pre-trained Bayesian neural networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ef92ca5d1826b8abfc71dfb7752721de8b061ccc",
    "semantic_title": "robustness to corruption in pre-trained bayesian neural networks",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=resApVNcqSB": {
    "title": "Weakly-supervised HOI Detection via Prior-guided Bi-level Representation Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "449f44544704a470e1e274ecaf80268cfa97344c",
    "semantic_title": "weakly-supervised hoi detection via prior-guided bi-level representation learning",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=KXRSh0sdVTP": {
    "title": "Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1aed7b21007519b7482ac4a005d5f2e0c7a1d047",
    "semantic_title": "meta-learning adaptive deep kernel gaussian processes for molecular property prediction",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=FYZCHEtt6H0": {
    "title": "ERL-Re$^2$: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "ef9e1910dafebf2a26a2c800a1d5099abd17ed68",
    "semantic_title": "erl-re2: efficient evolutionary reinforcement learning with shared state representation and individual policy representation",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=WZH7099tgfM": {
    "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5437e8adab596d7294124c0e798708e050e25321",
    "semantic_title": "least-to-most prompting enables complex reasoning in large language models",
    "citation_count": 1286,
    "authors": []
  },
  "https://openreview.net/forum?id=hZftxQGJ4Re": {
    "title": "Deep Ensembles for Graphs with Higher-order Dependencies",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "991a6c1aeb3cfc83ea34ff0a22b8592f720f9292",
    "semantic_title": "deep ensembles for graphs with higher-order dependencies",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=PaEUQiY40Dk": {
    "title": "Towards Understanding Why Mask Reconstruction Pretraining Helps in Downstream Tasks",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "9d4c2fc60b5c60c3639974aebdbf9743f27df785",
    "semantic_title": "towards understanding why mask-reconstruction pretraining helps in downstream tasks",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=20GtJ6hIaPA": {
    "title": "Self-Supervised Category-Level Articulated Object Pose Estimation with Part-Level SE(3) Equivariance",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "82d5216eab8dbcce6f00dc5d1e96baa767720909",
    "semantic_title": "self-supervised category-level articulated object pose estimation with part-level se(3) equivariance",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=6orC5MvgPBK": {
    "title": "Thalamus: a brain-inspired algorithm for biologically-plausible continual learning and disentangled representations",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9b32dfe3685dcfb00d782346560e999b90a0b4f6",
    "semantic_title": "thalamus: a brain-inspired algorithm for biologically-plausible continual learning and disentangled representations",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=8aeSJNbmbQq": {
    "title": "Deep Variational Implicit Processes",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c5402c096c591e2341af70891573c09af5d9a9b9",
    "semantic_title": "deep variational implicit processes",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=zDjtZZBZtqK": {
    "title": "Denoising Masked Autoencoders Help Robust Classification",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f7227e206e11923e5d29a84ecc7dbd623a168f25",
    "semantic_title": "denoising masked autoencoders help robust classification",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=ULsuEVQbV-9": {
    "title": "Estimating individual treatment effects under unobserved confounding using binary instruments",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8f9fd02c3312ce4e61534b08637593b764d813be",
    "semantic_title": "estimating individual treatment effects under unobserved confounding using binary instruments",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=a2-aoqmeYM4": {
    "title": "Approximate Bayesian Inference with Stein Functional Variational Gradient Descent",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "823d3b95ea09881754f459173aad585629e7f9b8",
    "semantic_title": "approximate bayesian inference with stein functional variational gradient descent",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=s-c96mSU0u5": {
    "title": "SCoMoE: Efficient Mixtures of Experts with Structured Communication",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d73247905abdea4edc7ff23f8152e6c1bcee8ce1",
    "semantic_title": "scomoe: efficient mixtures of experts with structured communication",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=5OygDd-4Eeh": {
    "title": "An Additive Instance-Wise Approach to Multi-class Model Interpretation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "aa1203d276db502440702ebe51eacfc0abeecdd5",
    "semantic_title": "an additive instance-wise approach to multi-class model interpretation",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=ILQVw4cA5F9": {
    "title": "LDMIC: Learning-based Distributed Multi-view Image Coding",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8ea993cf56ffb5166462ac7dafe4c6c0c7940bd4",
    "semantic_title": "ldmic: learning-based distributed multi-view image coding",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=HaHCoGcpV9": {
    "title": "Sound Randomized Smoothing in Floating-Point Arithmetic",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "799e1de31dd35e86a229f7a79dbc88ba4ca8ff57",
    "semantic_title": "sound randomized smoothing in floating-point arithmetics",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=hLbeJ6jObDD": {
    "title": "Collaborative Pure Exploration in Kernel Bandit",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1f59205ce5f0116a462d5bec66c803174ccf381d",
    "semantic_title": "collaborative pure exploration in kernel bandit",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=Yn0xg-kHNW-": {
    "title": "Provably Efficient Risk-Sensitive Reinforcement Learning: Iterated CVaR and Worst Path",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b36278ebc9e69c74acd1c031fd51ca1c969eb42d",
    "semantic_title": "provably efficient risk-sensitive reinforcement learning: iterated cvar and worst path",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3aBuJEza5sq": {
    "title": "Test-Time Robust Personalization for Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8b2ee805275ec92d032e0e5848b3196727b6c431",
    "semantic_title": "test-time robust personalization for federated learning",
    "citation_count": 50,
    "authors": []
  },
  "https://openreview.net/forum?id=BGF9IeDfmlH": {
    "title": "Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f400b801becf89b1db03ef8bcedb845d20a9dcda",
    "semantic_title": "learning to linearize deep neural networks for secure and efficient private inference",
    "citation_count": 31,
    "authors": []
  },
  "https://openreview.net/forum?id=TDf-XFAwc79": {
    "title": "Meta Knowledge Condensation for Federated Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "156b05966132836a1fb3c9b6ca4df6ae78189544",
    "semantic_title": "meta knowledge condensation for federated learning",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=9-umxtNPx5E": {
    "title": "Masked Frequency Modeling for Self-Supervised Visual Pre-Training",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2a7aee4ff519a7c0938bd397b6610707002836b3",
    "semantic_title": "masked frequency modeling for self-supervised visual pre-training",
    "citation_count": 83,
    "authors": []
  },
  "https://openreview.net/forum?id=DHyHRBwJUTN": {
    "title": "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3e565c544a8639cc9c7568833e484d7610f5e5d4",
    "semantic_title": "dynamic prompt learning via policy gradient for semi-structured mathematical reasoning",
    "citation_count": 342,
    "authors": []
  },
  "https://openreview.net/forum?id=mjHlitXvReu": {
    "title": "Learning Object-Language Alignments for Open-Vocabulary Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b2eb28dd5e2340a5e9de8ae82feaca7b6a265b4e",
    "semantic_title": "learning object-language alignments for open-vocabulary object detection",
    "citation_count": 103,
    "authors": []
  },
  "https://openreview.net/forum?id=iN3Lh-Vy2TH": {
    "title": "Phase transition for detecting a small community in a large network",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "029fe6904528abbc8881010de9a254befe23f890",
    "semantic_title": "phase transition for detecting a small community in a large network",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=b4t9_XASt6G": {
    "title": "On the Word Boundaries of Emergent Languages Based on Harris's Articulation Scheme",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "09b8f21c6b087c9daeb4685e881dd60fa35db877",
    "semantic_title": "on the word boundaries of emergent languages based on harris's articulation scheme",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=CIFOsnhZvON": {
    "title": "TempCLR: Temporal Alignment Representation with Contrastive Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d9f7c0d30ec978ed3f4be439e4eb00e7b8128ddc",
    "semantic_title": "tempclr: temporal alignment representation with contrastive learning",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=My57qBufZWs": {
    "title": "Bort: Towards Explainable Neural Networks with Bounded Orthogonal Constraint",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a6ce3dbf45e5a0f33273abcd2b70d70787ee1eac",
    "semantic_title": "bort: towards explainable neural networks with bounded orthogonal constraint",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=bPiHuNUNv_R": {
    "title": "The Power of Regularization in Solving Extensive-Form Games",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "a26d02cf56413be1736b5172e301b44203b7108d",
    "semantic_title": "the power of regularization in solving extensive-form games",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=P8YIphWNEGO": {
    "title": "MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP Initialization",
    "volume": "poster",
    "abstract": "Training graph neural networks (GNNs) on large graphs is complex and extremely time consuming. This is attributed to overheads caused by sparse matrix multiplication, which are sidestepped when training multi-layer perceptrons (MLPs) with only node features. MLPs, by ignoring graph context, are simple and faster for graph data, however they usually sacrifice prediction accuracy, limiting their applications for graph data. We observe that for most message passing-based GNNs, we can trivially derive an analog MLP (we call this a PeerMLP) with an equivalent weight space, by setting the trainable parameters with the same shapes, making us curious about how do GNNs using weights from a fully trained PeerMLP perform? Surprisingly, we find that GNNs initialized with such weights significantly outperform their PeerMLPs, motivating us to use PeerMLP training as a precursor, initialization step to GNN training. To this end, we propose an embarrassingly simple, yet hugely effective initialization method for GNN training acceleration, called \\mlpinit. Our extensive experiments on multiple large-scale graph datasets with diverse GNN architectures validate that MLPInit can accelerate the training of GNNs (up to 33× speedup on OGB-Products) and often improve prediction performance (e.g., up to $7.97\\%$ improvement for GraphSAGE across $7$ datasets for node classification, and up to $17.81\\%$ improvement across $4$ datasets for link prediction on metric Hits@10). The code is available at https://github.com/snap-research/MLPInit-for-GNNs",
    "checked": true,
    "id": "6178a6b71ce5846104970819321d58a4e1e6759d",
    "semantic_title": "mlpinit: embarrassingly simple gnn training acceleration with mlp initialization",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=8T4qmZbTkW7": {
    "title": "Progressively Compressed Auto-Encoder for Self-supervised Representation Learning",
    "volume": "poster",
    "abstract": "As a typical self-supervised learning strategy, Masked Image Modeling (MIM) is driven by recovering all masked patches from visible ones. However, patches from the same image are highly correlated and it is redundant to reconstruct all the masked patches. We find that this redundancy is neglected by existing MIM based methods and causes non-negligible overheads in computation that do not necessarily benefit self-supervised representation. In this paper, we present a novel approach named PCAE, short for Progressively Compressed AutoEncoder, to address the redundant reconstruction issue by progressively compacting tokens and only retaining necessary information for forward propagation and reconstruction. In particular, we identify those redundant tokens in an image via a simple yet effective similarity metric between each token with the mean of the token sequence. Those redundant tokens that other ones can probably represent are progressively dropped accordingly during the forward propagation, and importantly, we only focus on reconstructing these retained tokens. As a result, we are able to achieve a better trade-off between performance and efficiency for pre-training. Besides, benefitting from the flexible strategy, PCAE can be also directly employed for downstream fine-tuning tasks and enable scalable deployment. Experiments show that PCAE achieves comparable performance to MAE with only 1/8 GPU days. The code is available at https://github.com/caddyless/PCAE/",
    "checked": true,
    "id": "4d8fa3ac5f995441f2427a5f245e7d7e4f1b2a52",
    "semantic_title": "progressively compressed auto-encoder for self-supervised representation learning",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=gx2yJS-ENqI": {
    "title": "S-NeRF: Neural Radiance Fields for Street Views",
    "volume": "poster",
    "abstract": "Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and scenes, given the object-centric camera views with large overlaps. However, we conjugate that this paradigm does not fit the nature of the street views that are collected by many self-driving cars from the large-scale unbounded scenes. Also, the onboard cameras perceive scenes without much overlapping. Thus, existing NeRFs often produce blurs, \"floaters\" and other artifacts on street-view synthesis. In this paper, we propose a new street-view NeRF (S-NeRF) that considers novel view synthesis of both the large-scale background scenes and the foreground moving vehicles jointly. Specifically, we improve the scene parameterization function and the camera poses for learning better neural representations from street views. We also use the the noisy and sparse LiDAR points to boost the training and learn a robust geometry and reprojection based confidence to address the depth outliers. Moreover, we extend our S-NeRF for reconstructing moving vehicles that is impracticable for conventional NeRFs. Thorough experiments on the large-scale driving datasets (e.g., nuScenes and Waymo) demonstrate that our method beats the state-of-the-art rivals by reducing 7～40% of the mean-squared error in the street-view synthesis and a 45% PSNR gain for the moving vehicles rendering",
    "checked": true,
    "id": "380578ed28081a70b877be7e8a3c4d3a9997b041",
    "semantic_title": "s-nerf: neural radiance fields for street views",
    "citation_count": 118,
    "authors": []
  },
  "https://openreview.net/forum?id=wC98X1qpDBA": {
    "title": "Cycle-consistent Masked AutoEncoder for Unsupervised Domain Generalization",
    "volume": "poster",
    "abstract": "Self-supervised learning methods undergo undesirable performance drops when there exists a significant domain gap between training and testing scenarios. Therefore, unsupervised domain generalization (UDG) is proposed to tackle the problem, which requires the model to be trained on several different domains without supervision and generalize well on unseen test domains. Existing methods either rely on a cross-domain and semantically consistent image pair in contrastive methods or the reconstruction pair in generative methods, while the precious image pairs are not available without semantic labels. In this paper, we propose a cycle cross-domain reconstruction task for unsupervised domain generalization in the absence of paired images. The cycle cross-domain reconstruction task converts a masked image from one domain to another domain and then reconstructs the original image from the converted images. To preserve the divergent domain knowledge of decoders in the cycle reconstruction task, we propose a novel domain-contrastive loss to regularize the domain information in reconstructed images encoded with the desirable domain style. Qualitative results on extensive datasets illustrate our method improves the state-of-the-art unsupervised domain generalization methods by average $\\textbf{+5.59\\%}, \\textbf{+4.52\\%}, \\textbf{+4.22\\%}, \\textbf{+7.02\\%}$ on $1\\%, 5\\%, 10\\%, 100\\%$ PACS, and $\\textbf{+5.08\\%}, \\textbf{+6.49\\%}, \\textbf{+1.79\\%}, \\textbf{+0.53\\%}$ on $1\\%, 5\\%, 10\\%, 100\\%$ DomainNet, respectively",
    "checked": true,
    "id": "76f15b72b2b58c608e17bb4c75041d2b29b033f7",
    "semantic_title": "cycle-consistent masked autoencoder for unsupervised domain generalization",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=yAYHho4fATa": {
    "title": "CFlowNets: Continuous Control with Generative Flow Networks",
    "volume": "poster",
    "abstract": "Generative flow networks (GFlowNets), as an emerging technique, can be used as an alternative to reinforcement learning for exploratory control tasks. GFlowNets aims to sample actions with a probability proportional to the reward, similar to sampling different candidates in an active learning fashion. However, existing GFlowNets cannot adapt to continuous control tasks because GFlowNets need to form a DAG and compute the flow matching loss by traversing the inflows and outflows of each node in the trajectory. In this paper, we propose generative continuous flow networks (CFlowNets) that can be applied to continuous control tasks. First, we present the theoretical formulation of CFlowNets. Then, a training framework for CFlowNets is proposed, including the action selection process, the flow approximation algorithm, and the continuous flow matching loss function. Afterward, we theoretically prove the error bound of the flow approximation. The error decreases rapidly as the number of flow samples increases. Finally, experimental results on continuous control tasks demonstrate the performance advantages of CFlowNets compared to many reinforcement learning methods, especially regarding exploration ability",
    "checked": true,
    "id": "43737655c34a6f2a1446d1574e7830560c34bd2f",
    "semantic_title": "cflownets: continuous control with generative flow networks",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=OXP9Ns0gnIq": {
    "title": "Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models",
    "volume": "poster",
    "abstract": "Deep generative models such as GANs, normalizing flows, and diffusion models are powerful regularizers for inverse problems. They exhibit great potential for helping reduce ill-posedness and attain high-quality results. However, the latent tensors of such deep generative models can fall out of the desired high-dimensional standard Gaussian distribution during inversion, particularly in the presence of data noise and inaccurate forward models, leading to low-fidelity solutions. To address this issue, we propose to reparameterize and Gaussianize the latent tensors using novel differentiable data-dependent layers wherein custom operators are defined by solving optimization problems. These proposed layers constrain inverse problems to obtain high-fidelity in-distribution solutions. We validate our technique on three inversion tasks: compressive-sensing MRI, image deblurring, and eikonal tomography (a nonlinear PDE-constrained inverse problem) using two representative deep generative models: StyleGAN2 and Glow. Our approach achieves state-of-the-art performance in terms of accuracy and consistency",
    "checked": true,
    "id": "2da2131ae4a652a71760ec01a6630c74b7948ecd",
    "semantic_title": "differentiable gaussianization layers for inverse problems regularized by deep generative models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=ZccFLU-Yk65": {
    "title": "DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection",
    "volume": "poster",
    "abstract": "Many point-based 3D detectors adopt point-feature sampling strategies to drop some points for efficient inference. These strategies are typically based on fixed and handcrafted rules, making it difficult to handle complicated scenes. Different from them, we propose a Dynamic Ball Query (DBQ) network to adaptively select a subset of input points according to the input features, and assign the feature transform with a suitable receptive field for each selected point. It can be embedded into some state-of-the-art 3D detectors and trained in an end-to-end manner, which significantly reduces the computational cost. Extensive experiments demonstrate that our method can reduce latency by 30%-100% on KITTI, Waymo, and ONCE datasets. Specifically, the inference speed of our detector can reach 162 FPS on KITTI scene, and 30 FPS on Waymo and ONCE scenes without performance degradation. Due to skipping the redundant points, some evaluation metrics show significant improvements",
    "checked": true,
    "id": "286deda04928c92caf8001ef067003ce622f30d0",
    "semantic_title": "dbq-ssd: dynamic ball query for efficient 3d object detection",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=01KmhBsEPFO": {
    "title": "Exploring Low-Rank Property in Multiple Instance Learning for Whole Slide Image Classification",
    "volume": "poster",
    "abstract": "The classification of gigapixel-sized whole slide images (WSIs) with slide-level labels can be formulated as a multiple-instance-learning (MIL) problem. State-of-the-art models often consist of two decoupled parts: local feature embedding with a pre-trained model followed by a global feature aggregation network for classification. We leverage the properties of the apparent similarity in high-resolution WSIs, which essentially exhibit \\textit{low-rank} structures in the data manifold, to develop a novel MIL with a boost in both feature embedding and feature aggregation. We extend the contrastive learning with a pathology-specific Low-Rank Constraint (LRC) for feature embedding to pull together samples (i.e., patches) belonging to the same pathological tissue in the low-rank subspace and simultaneously push apart those from different latent subspaces. At the feature aggregation stage, we introduce an iterative low-rank attention MIL (ILRA-MIL) model to aggregate features with low-rank learnable latent vectors to model global interactions among all instances. We highlight the importance of instance correlation modeling but refrain from directly using the transformer encoder considering the $O(n^2)$ complexity. ILRA-MIL with LRC pre-trained features achieves strong empirical results across various benchmarks, including (i) 96.49\\% AUC on the CAMELYON16 for binary metastasis classification, (ii) 97.63\\% AUC on the TCGA-NSCLC for lung cancer subtyping, and (iii) 0.6562 kappa on the large-scale PANDA dataset for prostate cancer classification. The code is available at https://github.com/jinxixiang/low_rank_wsi",
    "checked": true,
    "id": "76e918d42bee0ef68575b097c9b1b79ba9ce1a4b",
    "semantic_title": "exploring low-rank property in multiple instance learning for whole slide image classification",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=F91SROvVJ_6": {
    "title": "Causal Balancing for Domain Generalization",
    "volume": "poster",
    "abstract": "While machine learning models rapidly advance the state-of-the-art on various real-world tasks, out-of-domain (OOD) generalization remains a challenging problem given the vulnerability of these models to spurious correlations. We propose a balanced mini-batch sampling strategy to transform a biased data distribution into a spurious-free balanced distribution, based on the invariance of the underlying causal mechanisms for the data generation process. We argue that the Bayes optimal classifiers trained on such balanced distribution are minimax optimal across a diverse enough environment space. We also provide an identifiability guarantee of the latent variable model of the proposed data generation process, when utilizing enough train environments. Experiments are conducted on DomainBed, demonstrating empirically that our method obtains the best performance across 20 baselines reported on the benchmark",
    "checked": true,
    "id": "892e308ebecd85c88282b45f21fe3f4027e360c8",
    "semantic_title": "causal balancing for domain generalization",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=rzrqh85f4Sc": {
    "title": "Towards Addressing Label Skews in One-Shot Federated Learning",
    "volume": "poster",
    "abstract": "Federated learning (FL) has been a popular research area, where multiple clients collaboratively train a model without sharing their local raw data. Among existing FL solutions, one-shot FL is a promising and challenging direction, where the clients conduct FL training with a single communication round. However, while label skew is a common real-world scenario where some clients may have few or no data of some classes, existing one-shot FL approaches that conduct voting on the local models are not able to produce effective global models. Due to the limited number of classes in each party, the local models misclassify the data from unseen classes into seen classes, which leads to very ineffective global models from voting. To address the label skew issue in one-shot FL, we propose a novel approach named FedOV which generates diverse outliers and introduces them as an additional unknown class in local training to improve the voting performance. Specifically, based on open-set recognition, we propose novel outlier generation approaches by corrupting the original features and further develop adversarial learning to enhance the outliers. Our extensive experiments show that FedOV can significantly improve the test accuracy compared to state-of-the-art approaches in various label skew settings",
    "checked": true,
    "id": "1e447e092f2704b6a53d9c9511dba4d199511e0e",
    "semantic_title": "towards addressing label skews in one-shot federated learning",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=-jTaz3CMk72": {
    "title": "Breaking Correlation Shift via Conditional Invariant Regularizer",
    "volume": "poster",
    "abstract": "Recently, generalization on out-of-distribution (OOD) data with correlation shift has attracted great attentions. The correlation shift is caused by the spurious attributes that correlate to the class label, as the correlation between them may vary in training and test data. For such a problem, we show that given the class label, the models that are conditionally independent of spurious attributes are OOD generalizable. Based on this, a metric Conditional Spurious Variation (CSV) which controls the OOD generalization error, is proposed to measure such conditional independence. To improve the OOD generalization, we regularize the training process with the proposed CSV. Under mild assumptions, our training objective can be formulated as a nonconvex-concave mini-max problem. An algorithm with a provable convergence rate is proposed to solve the problem. Extensive empirical results verify our algorithm's efficacy in improving OOD generalization",
    "checked": true,
    "id": "132505e9c068b50f10665055f357c2fa0e9b6b6e",
    "semantic_title": "breaking correlation shift via conditional invariant regularizer",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=h21yJhdzbwz": {
    "title": "Towards One-shot Neural Combinatorial Solvers: Theoretical and Empirical Notes on the Cardinality-Constrained Case",
    "volume": "poster",
    "abstract": "One-shot non-autoregressive neural networks, different from RL-based ones, have been actively adopted for solving combinatorial optimization (CO) problems, which can be trained by the objective score in a self-supervised manner. Such methods have shown their superiority in efficiency (e.g. by parallelization) and potential for tackling predictive CO problems for decision-making under uncertainty. While the discrete constraints often become a bottleneck for gradient-based neural solvers, as currently handled in three typical ways: 1) adding a soft penalty in the objective, where a bounded violation of the constraints cannot be guaranteed, being critical to many constraint-sensitive scenarios; 2) perturbing the input to generate an approximate gradient in a black-box manner, though the constraints are exactly obeyed while the approximate gradients can hurt the performance on the objective score; 3) a compromise by developing soft algorithms whereby the output of neural networks obeys a relaxed constraint, and there can still occur an arbitrary degree of constraint-violation. Towards the ultimate goal of establishing a general framework for neural CO solver with the ability to control an arbitrary-small degree of constraint violation, in this paper, we focus on a more achievable and common setting: the cardinality constraints, which in fact can be readily encoded by a differentiable optimal transport (OT) layer. Based on this observation, we propose OT-based cardinality constraint encoding for end-to-end CO problem learning with two variants: Sinkhorn and Gumbel-Sinkhorn, whereby their violation of the constraints can be exactly characterized and bounded by our theoretical results. On synthetic and real-world CO problem instances, our methods surpass the state-of-the-art CO network and are comparable to (if not superior to) the commercial solver Gurobi. In particular, we further showcase a case study of applying our approach to the predictive portfolio optimization task on real-world asset price data, improving the Sharpe ratio from 1.1 to 2.0 of a strong LSTM+Gurobi baseline under the classic predict-then-optimize paradigm",
    "checked": true,
    "id": "91b9cac12c0914f3f295a5b3f74c97ee10178b3e",
    "semantic_title": "towards one-shot neural combinatorial solvers: theoretical and empirical notes on the cardinality-constrained case",
    "citation_count": 18,
    "authors": []
  },
  "https://openreview.net/forum?id=VWm4o4l3V9e": {
    "title": "Block and Subword-Scaling Floating-Point (BSFP) : An Efficient Non-Uniform Quantization For Low Precision Inference",
    "volume": "poster",
    "abstract": "In this paper, we propose Block and Subword-Scaling Floating-Point (BSFP), a non-uniform quantization scheme for the skewed and non-uniform distribution of weight vectors in neural networks. By quantizing each weight vector as the superposition of multiple subword vectors (in two's complement) with scaling factors (in Low-bit Floating-Point, LBFP), BSFP can effectively fit the distribution of weight vectors while maintaining high computation efficiency. Furthermore, we present a grid search-based MSE-optimal quantization flow and a scaled serial processing engine to complete the quantization pipeline and the infrastructure. The experimental results on the ImageNet classification task show that our proposed method outperforms state-of-the-art Microsoft Floating Point (MSFP) by up to 20.56% top-1 accuracy at the same weight precision and reduces up to 10.3% model size. Furthermore, BSFP outperforms MSFP by up to 2.0$\\times$ computing throughput and up to 5.3$\\times$ energy efficiency under the same silicon area budget",
    "checked": true,
    "id": "77814b65e9b5cdd7eeceab5435b0dca10dcf549c",
    "semantic_title": "block and subword-scaling floating-point (bsfp) : an efficient non-uniform quantization for low precision inference",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=0qmwFNJyxCL": {
    "title": "Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning",
    "volume": "poster",
    "abstract": "Recent works have shown that self-supervised learning can achieve remarkable robustness when integrated with adversarial training (AT). However, the robustness gap between supervised AT (sup-AT) and self-supervised AT (self-AT) remains significant. Motivated by this observation, we revisit existing self-AT methods and discover an inherent dilemma that affects self-AT robustness: either strong or weak data augmentations are harmful to self-AT, and a medium strength is insufficient to bridge the gap. To resolve this dilemma, we propose a simple remedy named DYNACL (Dynamic Adversarial Contrastive Learning). In particular, we propose an augmentation schedule that gradually anneals from a strong augmentation to a weak one to benefit from both extreme cases. Besides, we adopt a fast post-processing stage for adapting it to downstream tasks. Through extensive experiments, we show that DYNACL can improve state-of-the-art self-AT robustness by 8.84% under Auto-Attack on the CIFAR-10 dataset, and can even outperform vanilla supervised adversarial training for the first time. Our code is available at \\url{https://github.com/PKU-ML/DYNACL}",
    "checked": true,
    "id": "28fb89e76c096d9083e0258b8386c6baa517f372",
    "semantic_title": "rethinking the effect of data augmentation in adversarial contrastive learning",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=cxvEGLCHpgl": {
    "title": "Semi-supervised Community Detection via Structural Similarity Metrics",
    "volume": "poster",
    "abstract": "Motivated by the interests of social network analysis and network-based recommendation systems, we consider a semi-supervised community detection problem, where the goal is to estimate the community label of a new node by leveraging on the network structure and partially observed community labels of existing nodes. We model the network with a degree-corrected stochastic block model, which allows for severe degree heterogeneity and potentially non-assortative communities. We propose a fast algorithm that computes a `structural similarity metric' between the new node and each of the $K$ communities, aggregating information in labeled and unlabeled data. The estimated label of the new node is equal to the value of $k$ that maximizes this similarity metric. Our method is computationally fast and compares favorably with existing semi-supervised algorithms on numerical performance. In theory, we derive explicit bounds for the misclassification error and show the efficiency of our method by comparing it with an ideal classifier. To our best knowledge, our results provide the first semi-supervised community detection algorithm with theoretical guarantees",
    "checked": true,
    "id": "5c2ca7525a2a2589b83cbf5361bfff42639323ed",
    "semantic_title": "semi-supervised community detection via structural similarity metrics",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0vqjc50HfcC": {
    "title": "DDM$^2$: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models",
    "volume": "poster",
    "abstract": "Magnetic resonance imaging (MRI) is a common and life-saving medical imaging technique. However, acquiring high signal-to-noise ratio MRI scans requires long scan times, resulting in increased costs and patient discomfort, and decreased throughput. Thus, there is great interest in denoising MRI scans, especially for the subtype of diffusion MRI scans that are severely SNR-limited. While most prior MRI denoising methods are supervised in nature, acquiring supervised training datasets for the multitude of anatomies, MRI scanners, and scan parameters proves impractical. Here, we propose Denoising Diffusion Models for Denoising Diffusion MRI (DDM^2), a self-supervised denoising method for MRI denoising using diffusion denoising generative models. Our three-stage framework integrates statistic-based denoising theory into diffusion models and performs denoising through conditional generation. During inference, we represent input noisy measurements as a sample from an intermediate posterior distribution within the diffusion Markov chain. We conduct experiments on 4 real-world in-vivo diffusion MRI datasets and show that our DDM^2 demonstrates superior denoising performances ascertained with clinically-relevant visual qualitative and quantitative metrics",
    "checked": false,
    "id": "0949978a51943a8547632b273496375616a9931b",
    "semantic_title": "ddm2: self-supervised diffusion mri denoising with generative diffusion models",
    "citation_count": 61,
    "authors": []
  },
  "https://openreview.net/forum?id=rdjeCNUS6TG": {
    "title": "Multivariate Time-series Imputation with Disentangled Temporal Representations",
    "volume": "poster",
    "abstract": "Multivariate time series often faces the problem of missing value. Many time series imputation methods have been developed in the literature. However, these methods all rely on an entangled representation to model dynamics of time series, which may fail to fully exploit the multiple factors (e.g., periodic patterns) contained in the time series. Moreover, the entangled representation usually has no semantic meaning, and thus they often lack interpretability. In addition, many recent models are proposed to deal with the whole time series to capture cross-channel correlations and identify temporal dynamics, but they are not scalable to large-scale datasets. Different from existing approaches, we propose TIDER, a novel matrix factorization-based method with disentangled temporal representations that account for multiple factors, namely trend, seasonality, and local bias, to model complex dynamics. The learned disentanglement makes the imputation process more reliable and offers explainability for imputation results. Moreover, TIDER is scalable to large datasets. Empirical results show that our method not only outperforms existing approaches by notable margins on three real-world datasets, but also scales well to large datasets on which existing deep learning based methods struggle. Disentanglement validation experiments further demonstrate the robustness of our model in obtaining accurate and explainable disentangled components",
    "checked": true,
    "id": "e4722f21ff4819713362dc217fd8d64a918a8d8a",
    "semantic_title": "multivariate time-series imputation with disentangled temporal representations",
    "citation_count": 34,
    "authors": []
  },
  "https://openreview.net/forum?id=FvevdI0aA_h": {
    "title": "Unified Detoxifying and Debiasing in Language Generation via Inference-time Adaptive Optimization",
    "volume": "poster",
    "abstract": "Recently pre-trained language models (PLMs) have prospered in various natural language generation (NLG) tasks due to their ability to generate fairly fluent text. Nevertheless, these models are observed to capture and reproduce harmful contents in training corpora, typically toxic language and social biases, raising severe moral issues. Prior works on ethical NLG tackle detoxifying and debiasing separately, which is problematic since we find debiased models still exhibit toxicity while detoxified ones even exacerbate biases. To address such a challenge, we propose the first unified framework of detoxifying and debiasing called UDDIA, which jointly formalizes these two problems as rectifying the output space. We theoretically interpret our framework as learning a text distribution mixing weighted attributes. Besides, UDDIA conducts adaptive optimization of only a few parameters during decoding based on a parameter-efficient tuning schema without any training data. This leads to minimal generation quality loss and improved rectification performance with acceptable computational cost. Experimental results demonstrate that compared to several strong baselines, UDDIA achieves debiasing and detoxifying simultaneously and better balances efficiency and effectiveness, taking a further step towards practical ethical NLG",
    "checked": true,
    "id": "473e55ded26b201b834ae73966474299528ec48d",
    "semantic_title": "unified detoxifying and debiasing in language generation via inference-time adaptive optimization",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=KfptQCEKVW4": {
    "title": "Automating Nearest Neighbor Search Configuration with Constrained Optimization",
    "volume": "poster",
    "abstract": "The approximate nearest neighbor (ANN) search problem is fundamental to efficiently serving many real-world machine learning applications. A number of techniques have been developed for ANN search that are efficient, accurate, and scalable. However, such techniques typically have a number of parameters that affect the speed-recall tradeoff, and exhibit poor performance when such parameters aren't properly set. Tuning these parameters has traditionally been a manual process, demanding in-depth knowledge of the underlying search algorithm. This is becoming an increasingly unrealistic demand as ANN search grows in popularity. To tackle this obstacle to ANN adoption, this work proposes a constrained optimization-based approach to tuning quantization-based ANN algorithms. Our technique takes just a desired search cost or recall as input, and then generates tunings that, empirically, are very close to the speed-recall Pareto frontier and give leading performance on standard benchmarks",
    "checked": true,
    "id": "6823730022f217b88a4ecb33dcfaab6091d3d302",
    "semantic_title": "automating nearest neighbor search configuration with constrained optimization",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=HDxgaKk956l": {
    "title": "Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders",
    "volume": "poster",
    "abstract": "Employing a forward diffusion chain to gradually map the data to a noise distribution, diffusion-based generative models learn how to generate the data by inferring a reverse diffusion chain. However, this approach is slow and costly because it needs many forward and reverse steps. We propose a faster and cheaper approach that adds noise not until the data become pure random noise, but until they reach a hidden noisy data distribution that we can confidently learn. Then, we use fewer reverse steps to generate data by starting from this hidden distribution that is made similar to the noisy data. We reveal that the proposed model can be cast as an adversarial auto-encoder empowered by both the diffusion process and a learnable implicit prior. Experimental results show even with a significantly smaller number of reverse diffusion steps, the proposed truncated diffusion probabilistic models can provide consistent improvements over the non-truncated ones in terms of performance in both unconditional and text-guided image generations",
    "checked": false,
    "id": "55b717812e5d1c4eb80b621732c357399357f9bf",
    "semantic_title": "truncated diffusion probabilistic models",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=-5EWhW_4qWP": {
    "title": "NTK-SAP: Improving neural network pruning by aligning training dynamics",
    "volume": "poster",
    "abstract": "Pruning neural networks before training has received increasing interest due to its potential to reduce training time and memory. One popular method is to prune the connections based on a certain metric, but it is not entirely clear what metric is the best choice. Recent advances in neural tangent kernel (NTK) theory suggest that the training dynamics of large enough neural networks is closely related to the spectrum of the NTK. Motivated by this finding, we propose to prune the connections that have the least influence on the spectrum of the NTK. This method can help maintain the NTK spectrum, which may help align the training dynamics to that of its dense counterpart. However, one possible issue is that the fixed-weight-NTK corresponding to a given initial point can be very different from the NTK corresponding to later iterates during the training phase. We further propose to sample multiple realizations of random weights to estimate the NTK spectrum. Note that our approach is weight-agnostic, which is different from most existing methods that are weight-dependent. In addition, we use random inputs to compute the fixed-weight-NTK, making our method data-agnostic as well. We name our foresight pruning algorithm Neural Tangent Kernel Spectrum-Aware Pruning (NTK-SAP). Empirically, our method achieves better performance than all baselines on multiple datasets",
    "checked": true,
    "id": "b6da4e11e24da4e863bbc1c5c7bd6080d0906b98",
    "semantic_title": "ntk-sap: improving neural network pruning by aligning training dynamics",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=cbpRzMy-UZH": {
    "title": "Effective Self-supervised Pre-training on Low-compute Networks without Distillation",
    "volume": "poster",
    "abstract": "Despite the impressive progress of self-supervised learning (SSL), its applicability to low-compute networks has received limited attention. Reported performance has trailed behind standard supervised pre-training by a large margin, barring self-supervised learning from making an impact on models that are deployed on device. Most prior works attribute this poor performance to the capacity bottleneck of the low-compute networks and opt to bypass the problem through the use of knowledge distillation (KD). In this work, we revisit SSL for efficient neural networks, taking a closer at what are the detrimental factors causing the practical limitations, and whether they are intrinsic to the self-supervised low-compute setting. We find that, contrary to accepted knowledge, there is no intrinsic architectural bottleneck, we diagnose that the performance bottleneck is related to the model complexity vs regularization strength trade-off. In particular, we start by empirically observing that the use of local views can have a dramatic impact on the effectiveness of the SSL methods. This hints at view sampling being one of the performance bottlenecks for SSL on low-capacity networks. We hypothesize that the view sampling strategy for large neural networks, which requires matching views in very diverse spatial scales and contexts, is too demanding for low-capacity architectures. We systematize the design of the view sampling mechanism, leading to a new training methodology that consistently improves the performance across different SSL methods (e.g. MoCo-v2, SwAV or DINO), different low-size networks (convolution-based networks, e.g. MobileNetV2, ResNet18, ResNet34 and vision transformer, e.g. ViT-Ti), and different tasks (linear probe, object detection, instance segmentation and semi-supervised learning). Our best models establish new state-of-the-art for SSL methods on low-compute networks despite not using a KD loss term. Code is publicly available at github.com/saic-fi/SSLight",
    "checked": true,
    "id": "8b1be014b073b25c28e955918634cedb15744def",
    "semantic_title": "effective self-supervised pre-training on low-compute networks without distillation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=L2MUOUp0beo": {
    "title": "CoRTX: Contrastive Framework for Real-time Explanation",
    "volume": "poster",
    "abstract": "Recent advancements in explainable machine learning provide effective and faithful solutions for interpreting model behaviors. However, many explanation methods encounter efficiency issues, which largely limit their deployments in practical scenarios. Real-time explainer (RTX) frameworks have thus been proposed to accelerate the model explanation process by learning an one-feed-forward explainer. Existing RTX frameworks typically build the explainer under the supervised learning paradigm, which requires large amounts of explanation labels as the ground truth. Considering that accurate explanation labels are usually hard to obtain, due to constrained computational resources and limited human efforts, effective explainer training is still challenging in practice. In this work, we propose a COntrastive Real-Time eXplanation (CoRTX) framework to learn the explanation-oriented representation and relieve the intensive dependence of explainer training on explanation labels. Specifically, we design a synthetic strategy to select positive and negative instances for explanation representation learning. Theoretical analysis show that our selection strategy can benefit the contrastive learning process on explanation tasks. Experimental results on three real-world datasets further demonstrate the efficiency and efficacy of our proposed CoRTX framework",
    "checked": true,
    "id": "4c4140cd59969f65f6bfc4a8632a8bfae7889097",
    "semantic_title": "cortx: contrastive framework for real-time explanation",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=7ynoX1ojPMt": {
    "title": "OTOv2: Automatic, Generic, User-Friendly",
    "volume": "poster",
    "abstract": "The existing model compression methods via structured pruning typically require complicated multi-stage procedures. Each individual stage necessitates numerous engineering efforts and domain-knowledge from the end-users which prevent their wider applications onto broader scenarios. We propose the second generation of Only-Train-Once (OTOv2), which first automatically trains and compresses a general DNN only once from scratch to produce a more compact model with competitive performance without fine-tuning. OTOv2 is automatic and pluggable into various deep learning applications, and requires almost minimal engineering efforts from the users. Methodologically, OTOv2 proposes two major improvements: (i) Autonomy: automatically exploits the dependency of general DNNs, partitions the trainable variables into Zero-Invariant Groups (ZIGs), and constructs the compressed model; and (ii) Dual Half-Space Projected Gradient (DHSPG): a novel optimizer to more reliably solve structured-sparsity problems. Numerically, we demonstrate the generality and autonomy of OTOv2 on a variety of model architectures such as VGG, ResNet, CARN, ConvNeXt, DenseNet and StackedUnets, the majority of which cannot be handled by other methods without extensive handcrafting efforts. Together with benchmark datasets including CIFAR10/100, DIV2K, Fashion-MNIST, SVNH and ImageNet, its effectiveness is validated by performing competitively or even better than the state-of-the-arts. The source code is available at https://github.com/tianyic/only_train_once",
    "checked": true,
    "id": "e3faac97f35bd02ffa534a672bb25c1ac0d57330",
    "semantic_title": "otov2: automatic, generic, user-friendly",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=fiB2RjmgwQ6": {
    "title": "Filter-Recovery Network for Multi-Speaker Audio-Visual Speech Separation",
    "volume": "poster",
    "abstract": "In this paper, we systematically study the audio-visual speech separation task in a multi-speaker scenario. Given the facial information of each speaker, the goal of this task is to separate the corresponding speech from the mixed speech. The existing works are designed for speech separation in a controlled setting with a fixed number of speakers (mostly 2 or 3 speakers), which seems to be impractical for real applications. As a result, we try to utilize a single model to separate the voices with a variable number of speakers. Based on the observation, there are two prominent issues for multi-speaker separation: 1) There are some noisy voice pieces belonging to other speakers in the separation results; 2) Part of the target speech is missing after separation. Accordingly, we propose \\textbf{BFRNet}, including a {\\bf B}asic audio-visual speech separator and a Filter-Recovery Network (\\textbf{FRNet}). FRNet can refine the coarse audio separated by basic audio-visual speech separator. To have fair comparisons, we build a comprehensive benchmark for multi-speaker audio-visual speech separation to verify the performance of various methods. Experimental results show that our method is able to achieve the state-of-the-art performance. Furthermore, we also find that FRNet can boost the performance of other off-the-shelf speech separators, which exhibits its ability of generalization",
    "checked": true,
    "id": "2886e2d77338207404d726d60848f0371b52ed39",
    "semantic_title": "filter-recovery network for multi-speaker audio-visual speech separation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=sbWVtxq8-zE": {
    "title": "Can discrete information extraction prompts generalize across language models?",
    "volume": "poster",
    "abstract": "We study whether automatically-induced prompts that effectively extract information from a language model can also be used, out-of-the-box, to probe other language models for the same information. After confirming that discrete prompts induced with the AutoPrompt algorithm outperform manual and semi-manual prompts on the slot-filling task, we demonstrate a drop in performance for AutoPrompt prompts learned on a model and tested on another. We introduce a way to induce prompts by mixing language models at training time that results in prompts that generalize well across models. We conduct an extensive analysis of the induced prompts, finding that the more general prompts include a larger proportion of existing English words and have a less order-dependent and more uniform distribution of information across their component tokens. Our work provides preliminary evidence that it's possible to generate discrete prompts that can be induced once and used with a number of different models, and gives insights on the properties characterizing such prompts",
    "checked": true,
    "id": "9590e4624029518792c62750ad6c02417fc7d60e",
    "semantic_title": "can discrete information extraction prompts generalize across language models?",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=bzaPGEllsjE": {
    "title": "A view of mini-batch SGD via generating functions: conditions of convergence, phase transitions, benefit from negative momenta",
    "volume": "poster",
    "abstract": "Mini-batch SGD with momentum is a fundamental algorithm for learning large predictive models. In this paper we develop a new analytic framework to analyze noise-averaged properties of mini-batch SGD for linear models at constant learning rates, momenta and sizes of batches. Our key idea is to consider the dynamics of the second moments of model parameters for a special family of \"Spectrally Expressible\" approximations. This allows to obtain an explicit expression for the generating function of the sequence of loss values. By analyzing this generating function, we find, in particular, that 1) the SGD dynamics exhibits several convergent and divergent regimes depending on the spectral distributions of the problem; 2) the convergent regimes admit explicit stability conditions, and explicit loss asymptotics in the case of power-law spectral distributions; 3) the optimal convergence rate can be achieved at negative momenta. We verify our theoretical predictions by extensive experiments with MNIST and synthetic problems, and find a good quantitative agreement",
    "checked": true,
    "id": "7f4b73d667077ef8e7438f3bb0d7f9c9aa79fe4b",
    "semantic_title": "a view of mini-batch sgd via generating functions: conditions of convergence, phase transitions, benefit from negative momenta",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=PFbzoWZyZRX": {
    "title": "Bridging the Gap between ANNs and SNNs by Calibrating Offset Spikes",
    "volume": "poster",
    "abstract": "Spiking Neural Networks (SNNs) have attracted great attention due to their distinctive characteristics of low power consumption and temporal information processing. ANN-SNN conversion, as the most commonly used training method for applying SNNs, can ensure that converted SNNs achieve comparable performance to ANNs on large-scale datasets. However, the performance degrades severely under low quantities of time-steps, which hampers the practical applications of SNNs to neuromorphic chips. In this paper, instead of evaluating different conversion errors and then eliminating these errors, we define an offset spike to measure the degree of deviation between actual and desired SNN firing rates. We perform a detailed analysis of offset spike and note that the firing of one additional (or one less) spike is the main cause of conversion errors. Based on this, we propose an optimization strategy based on shifting the initial membrane potential and we theoretically prove the corresponding optimal shifting distance for calibrating the spike. In addition, we also note that our method has a unique iterative property that enables further reduction of conversion errors. The experimental results show that our proposed method achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet datasets. For example, we reach a top-1 accuracy of 67.12% on ImageNet when using 6 time-steps. To the best of our knowledge, this is the first time an ANN-SNN conversion has been shown to simultaneously achieve high accuracy and ultralow latency on complex datasets. Code is available at https://github.com/hzc1208/ANN2SNN_COS",
    "checked": true,
    "id": "5556d6e4c24f1793459407eb1ee623d9549281c9",
    "semantic_title": "bridging the gap between anns and snns by calibrating offset spikes",
    "citation_count": 46,
    "authors": []
  },
  "https://openreview.net/forum?id=bHW9njOSON": {
    "title": "ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure",
    "volume": "poster",
    "abstract": "Studies have shown that modern neural networks tend to be poorly calibrated due to over-confident predictions. Traditionally, post-processing methods have been used to calibrate the model after training. In recent years, various trainable calibration measures have been proposed to incorporate them directly into the training process. However, these methods all incorporate internal hyperparameters, and the performance of these calibration objectives relies on tuning these hyperparameters, incurring more computational costs as the size of neural networks and datasets become larger. As such, we present Expected Squared Difference (ESD), a tuning-free (i.e., hyperparameter-free) trainable calibration objective loss, where we view the calibration error from the perspective of the squared difference between the two expectations. With extensive experiments on several architectures (CNNs, Transformers) and datasets, we demonstrate that (1) incorporating ESD into the training improves model calibration in various batch size settings without the need for internal hyperparameter tuning, (2) ESD yields the best-calibrated results compared with previous approaches, and (3) ESD drastically improves the computational costs required for calibration during training due to the absence of internal hyperparameter. The code is publicly accessible at https://github.com/hee-suk-yoon/ESD",
    "checked": true,
    "id": "2386670cbe053ec29f116ee23c79c8ac38c39a30",
    "semantic_title": "esd: expected squared difference as a tuning-free trainable calibration measure",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=AP0iZoaRaS": {
    "title": "Interactive Portrait Harmonization",
    "volume": "poster",
    "abstract": "Current image harmonization methods consider the entire background as the guidance for harmonization. However, this may limit the capability for user to choose any specific object/person in the background to guide the harmonization. To enable flexible interaction between user and harmonization, we introduce interactive harmonization, a new setting where the harmonization is performed with respect to a selected region in the reference image instead of the entire background. A new flexible framework that allows users to pick certain regions of the background image and use it to guide the harmonization is proposed. Inspired by professional portrait harmonization users, we also introduce a new luminance matching loss to optimally match the color/luminance conditions between the composite foreground and select reference region. This framework provides more control to the image harmonization pipeline achieving visually pleasing portrait edits. Furthermore, we also introduce a new dataset carefully curated for validating portrait harmonization. Extensive experiments on both synthetic and real-world datasets show that the proposed approach is efficient and robust compared to previous harmonization baselines, especially for portraits",
    "checked": true,
    "id": "c423c8ef2d8101676a4c2ba403ad5970c0364f09",
    "semantic_title": "interactive portrait harmonization",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=kj6oK_Hj40": {
    "title": "Self-Distillation for Further Pre-training of Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3b34df9e3b9b41930f46adfd22331d62a830cdd7",
    "semantic_title": "self-distillation for further pre-training of transformers",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=PldynS56bN": {
    "title": "Contextual Convolutional Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ea6aa161623268ea12bfc7d14df4711ca2feabd1",
    "semantic_title": "contextual convolutional networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KemSBwOYJC": {
    "title": "Statistical Inference for Fisher Market Equilibrium",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "31190a8c8da534ebefc1534bf09887d7f6d15b2d",
    "semantic_title": "statistical inference for fisher market equilibrium",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=tPrRs6YB2P": {
    "title": "Scenario-based Question Answering with Interacting Contextual Properties",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "23f4cfc5695e13ebe32606475421d77a3999d2cb",
    "semantic_title": "scenario-based question answering with interacting contextual properties",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rSUCajhLsQ": {
    "title": "Easy Differentially Private Linear Regression",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ce33f5fcffda564ed06fba1e4378c5610ea91d6e",
    "semantic_title": "easy differentially private linear regression",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=8pOVAeo8ie": {
    "title": "LPT: Long-tailed Prompt Tuning for Image Classification",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e9bebbe12a1124dee2214e3f6bd7973540d8af63",
    "semantic_title": "lpt: long-tailed prompt tuning for image classification",
    "citation_count": 79,
    "authors": []
  },
  "https://openreview.net/forum?id=NkJOhtNKX91": {
    "title": "DamoFD: Digging into Backbone Design on Face Detection",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4e867c4856692358beff44692bd17a5054bfc402",
    "semantic_title": "damofd: digging into backbone design on face detection",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=W918Ora75q": {
    "title": "Towards Smooth Video Composition",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "60a318955f7f35bbf90cce6da209909d545e2188",
    "semantic_title": "towards smooth video composition",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=06mk-epSwZ": {
    "title": "DiffMimic: Efficient Motion Mimicking with Differentiable Physics",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9c6f0ca7ff6555f308fdb6235bf0dd11ec091929",
    "semantic_title": "diffmimic: efficient motion mimicking with differentiable physics",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=li4GQCQWkv": {
    "title": "Towards Inferential Reproducibility of Machine Learning Research",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "82d81a7888bd02b4f67fecb358e033b7b23a174e",
    "semantic_title": "towards inferential reproducibility of machine learning research",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Fg3mYW8owg": {
    "title": "Knowledge Distillation based Degradation Estimation for Blind Super-Resolution",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "98b04d8f06f9fadd2abce51049a14525abb3b707",
    "semantic_title": "knowledge distillation based degradation estimation for blind super-resolution",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=PLUXnnxUdr4": {
    "title": "Graph Contrastive Learning for Skeleton-based Action Recognition",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "fd8f64c1d06ce0a13427690d226c0bdf13ce8a6b",
    "semantic_title": "graph contrastive learning for skeleton-based action recognition",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=s4WVupnJjmX": {
    "title": "Explicit Box Detection Unifies End-to-End Multi-Person Pose Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "54d67bd651eb76cef1224f9f9d7c167ae9266c7d",
    "semantic_title": "explicit box detection unifies end-to-end multi-person pose estimation",
    "citation_count": 63,
    "authors": []
  },
  "https://openreview.net/forum?id=frE4fUwz_h": {
    "title": "Spikformer: When Spiking Neural Network Meets Transformer",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ffd91f85d6d19e75309ececfd190afa6bb562284",
    "semantic_title": "spikformer: when spiking neural network meets transformer",
    "citation_count": 308,
    "authors": []
  },
  "https://openreview.net/forum?id=NRHajbzg8y0P": {
    "title": "Multimodal Analogical Reasoning over Knowledge Graphs",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8c43cbe3dff3f556bf09462a7bdbbb8a292af7f9",
    "semantic_title": "multimodal analogical reasoning over knowledge graphs",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=N92hjSf5NNh": {
    "title": "MECTA: Memory-Economic Continual Test-Time Model Adaptation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9ce101efac1e7950e41493eb6068043a913b4b74",
    "semantic_title": "mecta: memory-economic continual test-time model adaptation",
    "citation_count": 46,
    "authors": []
  },
  "https://openreview.net/forum?id=R_OL5mLhsv": {
    "title": "Interpretability with full complexity by constraining feature information",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "718d22c746ded92caf5d79638a1b5ac6405ca200",
    "semantic_title": "interpretability with full complexity by constraining feature information",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=3zSn48RUO8M": {
    "title": "What shapes the loss landscape of self supervised learning?",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": "197790926475674f5997a7f70d06c6265617282e",
    "semantic_title": "what shapes the loss landscape of self-supervised learning?",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=-z9hdsyUwVQ": {
    "title": "Linear Convergence of Natural Policy Gradient Methods with Log-Linear Policies",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "f7e93c8adec97784ec0e18d4fd56d982a8922e0d",
    "semantic_title": "linear convergence of natural policy gradient methods with log-linear policies",
    "citation_count": 35,
    "authors": []
  },
  "https://openreview.net/forum?id=UP_GHHPw7rP": {
    "title": "Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bb4c13c86048a48ec3f398d7d613ff8e56e1c8ae",
    "semantic_title": "nearly minimax optimal offline reinforcement learning with linear function approximation: single-agent mdp and markov game",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=3KWnuT-R1bh": {
    "title": "Conditional Positional Encodings for Vision Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "63812f583caac3ac32bbfb64f66ba69e57c1e90a",
    "semantic_title": "conditional positional encodings for vision transformers",
    "citation_count": 661,
    "authors": []
  },
  "https://openreview.net/forum?id=b_CQDy9vrD1": {
    "title": "ManiSkill2: A Unified Benchmark for Generalizable Manipulation Skills",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "634127f09be5119f4d29a175866f11b14b3821e0",
    "semantic_title": "maniskill2: a unified benchmark for generalizable manipulation skills",
    "citation_count": 233,
    "authors": []
  },
  "https://openreview.net/forum?id=L8iZdgeKmI6": {
    "title": "Deja Vu: Continual Model Generalization for Unseen Domains",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1432133bf51be0bcd42676ca916143e321e101f0",
    "semantic_title": "deja vu: continual model generalization for unseen domains",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=65XDF_nwI61": {
    "title": "A Graph Neural Network Approach to Automated Model Building in Cryo-EM Maps",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e07dc03cefbf1c052f0c4dabf920218d775d76ce",
    "semantic_title": "a graph neural network approach to automated model building in cryo-em maps",
    "citation_count": 28,
    "authors": []
  },
  "https://openreview.net/forum?id=S3D9NLzjnQ5": {
    "title": "Distilling Cognitive Backdoor Patterns within an Image",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ec025c1a5f8cf8c1b0d6744e0a3ad50bec13f90a",
    "semantic_title": "distilling cognitive backdoor patterns within an image",
    "citation_count": 27,
    "authors": []
  },
  "https://openreview.net/forum?id=QjQibO3scV_": {
    "title": "Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching",
    "volume": "poster",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vZTp1oPV3PC": {
    "title": "One Transformer Can Understand Both 2D & 3D Molecular Data",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "bf8d98979f1dfd1df492be21d760d5c0e7f22359",
    "semantic_title": "one transformer can understand both 2d & 3d molecular data",
    "citation_count": 107,
    "authors": []
  },
  "https://openreview.net/forum?id=WumysvcMvV6": {
    "title": "Mind the Gap: Offline Policy Optimization for Imperfect Rewards",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "b2950bce85a14904d1e30018fa4c8d21ba0651a8",
    "semantic_title": "mind the gap: offline policy optimization for imperfect rewards",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=S8-A2FXnIh": {
    "title": "Learning to Compose Soft Prompts for Compositional Zero-Shot Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ffd8486787d4f838dbe5601f0cfe67fccf83fefc",
    "semantic_title": "learning to compose soft prompts for compositional zero-shot learning",
    "citation_count": 77,
    "authors": []
  },
  "https://openreview.net/forum?id=IDJx97BC38": {
    "title": "SQA3D: Situated Question Answering in 3D Scenes",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c1a4fb211cf995b1af1247a152fcc145594ec13b",
    "semantic_title": "sqa3d: situated question answering in 3d scenes",
    "citation_count": 199,
    "authors": []
  },
  "https://openreview.net/forum?id=NJENsJ37sQ": {
    "title": "Empowering Networks With Scale and Rotation Equivariance Using A Similarity Convolution",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "db5136128f21e5c7c6a13dce365a769fb984b6c9",
    "semantic_title": "empowering networks with scale and rotation equivariance using a similarity convolution",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=wcNtbEtcGIC": {
    "title": "Robust and Controllable Object-Centric Learning through Energy-based Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "81f5859549221ecf9f42262b8c13e68d68b0a9a1",
    "semantic_title": "robust and controllable object-centric learning through energy-based models",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=ylMq8MBnAp": {
    "title": "Topology-aware Robust Optimization for Out-of-Distribution Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "eba7eb5d82c08ad1ba700afa08153168993de963",
    "semantic_title": "topology-aware robust optimization for out-of-distribution generalization",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=mfIX4QpsARJ": {
    "title": "EAGLE: Large-scale Learning of Turbulent Fluid Dynamics with Mesh Transformers",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "318e4159296cc0b5ad1d6a29e4b0e0411faeffb9",
    "semantic_title": "eagle: large-scale learning of turbulent fluid dynamics with mesh transformers",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=XqcQhVUr2h0": {
    "title": "Limitless Stability for Graph Convolutional Networks",
    "volume": "poster",
    "abstract": "This work establishes rigorous, novel and widely applicable stability guarantees and transferability bounds for general graph convolutional networks -- without reference to any underlying limit object or statistical distribution. Crucially, utilized graph-shift operators are not necessarily assumed to be normal, allowing for the treatment of networks on both directed- and undirected graphs within the developed framework. In the undirected setting, stability to node-level perturbations is related to an 'adequate spectral covering' property of the filters in each layer. Stability to edge-level perturbations is discussed and related to properties of the utilized filters such as their Lipschitz constants. Results on stability to vertex-set non-preserving perturbations are obtained by utilizing recently developed mathematical-physics based tools. As an exemplifying application of the developed theory, it is showcased that general graph convolutional networks utilizing the un-normalized graph Laplacian as graph-shift-operator can be rendered stable to collapsing strong edges in the underlying graph if filters are mandated to be constant at infinity. These theoretical results are supported by corresponding numerical investigations showcasing the response of filters and networks to such perturbations",
    "checked": true,
    "id": "714933b995e2905a31e0b5ae3f3a6cdb4c43855b",
    "semantic_title": "limitless stability for graph convolutional networks",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=Q_Jexl8-qDi": {
    "title": "De Novo Molecular Generation via Connection-aware Motif Mining",
    "volume": "poster",
    "abstract": "De novo molecular generation is an essential task for science discovery. Recently, fragment-based deep generative models have attracted much research attention due to their flexibility in generating novel molecules based on existing molecule fragments. However, the motif vocabulary, i.e., the collection of frequent fragments, is usually built upon heuristic rules, which brings difficulties to capturing common substructures from large amounts of molecules. In this work, we propose MiCaM to generate molecules based on mined connection-aware motifs. Specifically, it leverages a data-driven algorithm to automatically discover motifs from a molecule library by iteratively merging subgraphs based on their frequency. The obtained motif vocabulary consists of not only molecular motifs (i.e., the frequent fragments), but also their connection information, indicating how the motifs are connected with each other. Based on the mined connection-aware motifs, MiCaM builds a connection-aware generator, which simultaneously picks up motifs and determines how they are connected. We test our method on distribution-learning benchmarks (i.e., generating novel molecules to resemble the distribution of a given training set) and goal-directed benchmarks (i.e., generating molecules with target properties), and achieve significant improvements over previous fragment-based baselines. Furthermore, we demonstrate that our method can effectively mine domain-specific motifs for different tasks",
    "checked": true,
    "id": "26ed17bb45e9fcad97482f0a112f4067785fd301",
    "semantic_title": "de novo molecular generation via connection-aware motif mining",
    "citation_count": 36,
    "authors": []
  },
  "https://openreview.net/forum?id=SNgLnzFQeiD": {
    "title": "Revisiting the Entropy Semiring for Neural Speech Recognition",
    "volume": "poster",
    "abstract": "In streaming settings, speech recognition models have to map sub-sequences of speech to text before the full audio stream becomes available. However, since alignment information between speech and text is rarely available during training, models need to learn it in a completely self-supervised way. In practice, the exponential number of possible alignments makes this extremely challenging, with models often learning peaky or sub-optimal alignments. Prima facie, the exponential nature of the alignment space makes it difficult to even quantify the uncertainty of a model's alignment distribution. Fortunately, it has been known for decades that the entropy of a probabilistic finite state transducer can be computed in time linear to the size of the transducer via a dynamic programming reduction based on semirings. In this work, we revisit the entropy semiring for neural speech recognition models, and show how alignment entropy can be used to supervise models through regularization or distillation. We also contribute an open-source implementation of CTC and RNN-T in the semiring framework that includes numerically stable and highly parallel variants of the entropy semiring. Empirically, we observe that the addition of alignment distillation improves the accuracy and latency of an already well-optimized teacher-student distillation model, achieving state-of-the-art performance on the Librispeech dataset in the streaming scenario",
    "checked": true,
    "id": "04684ad525cf51eaee8d3bbba818850733c34303",
    "semantic_title": "revisiting the entropy semiring for neural speech recognition",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=yQdBtFfleh6": {
    "title": "Rethinking skip connection model as a learnable Markov chain",
    "volume": "poster",
    "abstract": "Over the past few years afterward the birth of ResNet, skip connection has become the defacto standard for the design of modern architectures due to its widespread adoption, easy optimization, and proven performance. Prior work has explained the effectiveness of the skip connection mechanism from different perspectives. In this work, we deep dive into the model's behaviors with skip connections which can be formulated as a learnable Markov chain. An efficient Markov chain is preferred as it always maps the input data to the target domain in a better way. However, while a model is explained as a Markov chain, it is not guaranteed to be optimized following an efficient Markov chain by existing SGD-based optimizers prone to getting trapped in local optimal points. In order to move towards a more efficient Markov chain, we propose a simple routine of penal connection to make any residual-like model become a learnable Markov chain. Aside from that, the penal connection can also be viewed as a particular model regularization and can be easily implemented with one line of code in the most popular deep learning frameworks. The encouraging experimental results in multi-modal translation and image recognition empirically confirm our conjecture of the learnable Markov chain view and demonstrate the superiority of the proposed penal connection",
    "checked": true,
    "id": "431e308dba5aa880c037c6bf31d9ab917f546181",
    "semantic_title": "rethinking skip connection model as a learnable markov chain",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=lZOUQQvwI3q": {
    "title": "Measuring axiomatic soundness of counterfactual image models",
    "volume": "poster",
    "abstract": "We present a general framework for evaluating image counterfactuals. The power and flexibility of deep generative models make them valuable tools for learning mechanisms in structural causal models. However, their flexibility makes counterfactual identifiability impossible in the general case. Motivated by these issues, we revisit Pearl's axiomatic definition of counterfactuals to determine the necessary constraints of any counterfactual inference model: composition, reversibility, and effectiveness. We frame counterfactuals as functions of an input variable, its parents, and counterfactual parents and use the axiomatic constraints to restrict the set of functions that could represent the counterfactual, thus deriving distance metrics between the approximate and ideal functions. We demonstrate how these metrics can be used to compare and choose between different approximate counterfactual inference models and to provide insight into a model's shortcomings and trade-offs",
    "checked": true,
    "id": "582efef4fba2ded7d66b0b68dbfbc71654f414a3",
    "semantic_title": "measuring axiomatic soundness of counterfactual image models",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=KKBMz-EL4tD": {
    "title": "Alternating Differentiation for Optimization Layers",
    "volume": "poster",
    "abstract": "The idea of embedding optimization problems into deep neural networks as optimization layers to encode constraints and inductive priors has taken hold in recent years. Most existing methods focus on implicitly differentiating Karush–Kuhn–Tucker (KKT) conditions in a way that requires expensive computations on the Jacobian matrix, which can be slow and memory-intensive. In this paper, we developed a new framework, named Alternating Differentiation (Alt-Diff), that differentiates optimization problems (here, specifically in the form of convex optimization problems with polyhedral constraints) in a fast and recursive way. Alt-Diff decouples the differentiation procedure into a primal update and a dual update in an alternating way. Accordingly, Alt-Diff substantially decreases the dimensions of the Jacobian matrix especially for optimization with large-scale constraints and thus increases the computational speed of implicit differentiation. We show that the gradients obtained by Alt-Diff are consistent with those obtained by differentiating KKT conditions. In addition, we propose to truncate Alt-Diff to further accelerate the computational speed. Under some standard assumptions, we show that the truncation error of gradients is upper bounded by the same order of variables' estimation error. Therefore, Alt-Diff can be truncated to further increase computational speed without sacrificing much accuracy. A series of comprehensive experiments validate the superiority of Alt-Diff",
    "checked": true,
    "id": "6b573633ad1250ce284d369fa331e8dec041ce1a",
    "semantic_title": "alternating differentiation for optimization layers",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=hdghx6wbGuD": {
    "title": "Out-of-distribution Detection with Implicit Outlier Transformation",
    "volume": "poster",
    "abstract": "Outlier exposure (OE) is powerful in out-of-distribution (OOD) detection, enhancing detection capability via model fine-tuning with surrogate OOD data. However, surrogate data typically deviate from test OOD data. Thus, the performance of OE when facing unseen OOD data, can be weaken. To address this issue, we propose a novel OE-based approach that makes the model perform well for unseen OOD situations, even for unseen OOD cases. It leads to a min-max learning scheme---searching to synthesize OOD data that leads to worst judgments and learning from such OOD data for the uniform performance in OOD detection. In our realization, these worst OOD data are synthesized by transforming original surrogate ones, where the associated transform functions are learned implicitly based on our novel insight that model perturbation leads to data transformation. Our methodology offers an efficient way of synthesizing OOD data, which can further benefit the detection model, besides the surrogate OOD data. We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts",
    "checked": true,
    "id": "a64a192b01c57e18dafd1a8e826056cd3e97cedd",
    "semantic_title": "out-of-distribution detection with implicit outlier transformation",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=cMAjKYftNwx": {
    "title": "Extracting Robust Models with Uncertain Examples",
    "volume": "poster",
    "abstract": "Model extraction attacks are proven to be a severe privacy threat to Machine Learning as a Service (MLaaS). A variety of techniques have been designed to steal a remote machine learning model with high accuracy and fidelity. However, how to extract a robust model with similar resilience against adversarial attacks is never investigated. This paper presents the first study toward this goal. We first analyze those existing extraction solutions either fail to maintain the model accuracy or model robustness or lead to the robust overfitting issue. Then we propose Boundary Entropy Searching Thief (BEST), a novel model extraction attack to achieve both accuracy and robustness extraction under restricted attack budgets. BEST generates a new kind of uncertain examples for querying and reconstructing the victim model. These samples have uniform confidence scores across different classes, which can perfectly balance the trade-off between model accuracy and robustness. Extensive experiments demonstrate that BEST outperforms existing attack methods over different datasets and model architectures under limited data. It can also effectively invalidate state-of-the-art extraction defenses",
    "checked": true,
    "id": "7fd631dd3783704f8a58ffbd13cf41d307169982",
    "semantic_title": "extracting robust models with uncertain examples",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=Pza24zf9FpS": {
    "title": "Neural Groundplans: Persistent Neural Scene Representations from a Single Image",
    "volume": "poster",
    "abstract": "We present a method to map 2D image observations of a scene to a persistent 3D scene representation, enabling novel view synthesis and disentangled representation of the movable and immovable components of the scene. Motivated by the bird's-eye-view (BEV) representation commonly used in vision and robotics, we propose conditional neural groundplans, ground-aligned 2D feature grids, as persistent and memory-efficient scene representations. Our method is trained self-supervised from unlabeled multi-view observations using differentiable rendering, and learns to complete geometry and appearance of occluded regions. In addition, we show that we can leverage multi-view videos at training time to learn to separately reconstruct static and movable components of the scene from a single image at test time. The ability to separately reconstruct movable objects enables a variety of downstream tasks using simple heuristics, such as extraction of object-centric 3D representations, novel view synthesis, instance-level segmentation, 3D bounding box prediction, and scene editing. This highlights the value of neural groundplans as a backbone for efficient 3D scene understanding models",
    "checked": true,
    "id": "091ccbcc52b77df62c1610831fbb3c196c65db76",
    "semantic_title": "neural groundplans: persistent neural scene representations from a single image",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=g1GnnCI1OrC": {
    "title": "E-CRF: Embedded Conditional Random Field for Boundary-caused Class Weights Confusion in Semantic Segmentation",
    "volume": "poster",
    "abstract": "Modern semantic segmentation methods devote much effect to adjusting image feature representations to improve the segmentation performance in various ways, such as architecture design, attention mechnism, etc. However, almost all those methods neglect the particularity of class weights (in the classification layer) in segmentation models. In this paper, we notice that the class weights of categories that tend to share many adjacent boundary pixels lack discrimination, thereby limiting the performance. We call this issue Boundary-caused Class Weights Confusion (BCWC). We try to focus on this problem and propose a novel method named Embedded Conditional Random Field (E-CRF) to alleviate it. E-CRF innovatively fuses the CRF into the CNN network as an organic whole for more effective end-to-end optimization. The reasons are two folds. It utilizes CRF to guide the message passing between pixels in high-level features to purify the feature representation of boundary pixels, with the help of inner pixels belonging to the same object. More importantly, it enables optimizing class weights from both scale and direction during backpropagation. We make detailed theoretical analysis to prove it. Besides, superpixel is integrated into E-CRF and served as an auxiliary to exploit the local object prior for more reliable message passing. Finally, our proposed method yields impressive results on ADE20K, Cityscapes, and Pascal Context datasets",
    "checked": true,
    "id": "7ed7a1f2cf825db11c01ad2850789edb8c02deb6",
    "semantic_title": "e-crf: embedded conditional random field for boundary-caused class weights confusion in semantic segmentation",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=9x3CO0ZU9LR": {
    "title": "Sample Complexity of Nonparametric Off-Policy Evaluation on Low-Dimensional Manifolds using Deep Networks",
    "volume": "poster",
    "abstract": "We consider the off-policy evaluation problem of reinforcement learning using deep convolutional neural networks. We analyze the deep fitted Q-evaluation method for estimating the expected cumulative reward of a target policy, when the data are generated from an unknown behavior policy. We show that, by choosing network size appropriately, one can leverage any low-dimensional manifold structure in the Markov decision process and obtain a sample-efficient estimator without suffering from the curse of high data ambient dimensionality. Specifically, we establish a sharp error bound for fitted Q-evaluation, which depends on the intrinsic dimension of the state-action space, the smoothness of Bellman operator, and a function class-restricted $\\chi^2$-divergence. It is noteworthy that the restricted $\\chi^2$-divergence measures the behavior and target policies' {\\it mismatch in the function space}, which can be small even if the two policies are not close to each other in their tabular forms. We also develop a novel approximation result for convolutional neural networks in Q-function estimation. Numerical experiments are provided to support our theoretical analysis",
    "checked": true,
    "id": "b8e4c552553d8e244ffad6238e01f461c85a6cf5",
    "semantic_title": "sample complexity of nonparametric off-policy evaluation on low-dimensional manifolds using deep networks",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=3nM5uhPlfv6": {
    "title": "Stochastic Differentially Private and Fair Learning",
    "volume": "poster",
    "abstract": "Machine learning models are increasingly used in high-stakes decision-making systems. In such applications, a major concern is that these models sometimes discriminate against certain demographic groups such as individuals with certain race, gender, or age. Another major concern in these applications is the violation of the privacy of users. While fair learning algorithms have been developed to mitigate discrimination issues, these algorithms can still leak sensitive information, such as individuals' health or financial records. Utilizing the notion of differential privacy (DP), prior works aimed at developing learning algorithms that are both private and fair. However, existing algorithms for DP fair learning are either not guaranteed to converge or require full batch of data in each iteration of the algorithm to converge. In this paper, we provide the first stochastic differentially private algorithm for fair learning that is guaranteed to converge. Here, the term \"stochastic\" refers to the fact that our proposed algorithm converges even when minibatches of data are used at each iteration (i.e. stochastic optimization). Our framework is flexible enough to permit different fairness notions, including demographic parity and equalized odds. In addition, our algorithm can be applied to non-binary classification tasks with multiple (non-binary) sensitive attributes. As a byproduct of our convergence analysis, we provide the first utility guarantee for a DP algorithm for solving nonconvex-strongly concave min-max problems. Our numerical experiments show that the proposed algorithm consistently offers significant performance gains over the state-of-the-art baselines, and can be applied to larger scale problems with non-binary target/sensitive attributes",
    "checked": true,
    "id": "04a1d57a43c7f92aa4fdd660d2b6c312c8c1cbe4",
    "semantic_title": "stochastic differentially private and fair learning",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=MxvHVNukama": {
    "title": "On The Inadequacy of Optimizing Alignment and Uniformity in Contrastive Learning of Sentence Representations",
    "volume": "poster",
    "abstract": "Contrastive learning is widely used in areas such as visual representation learning (VRL) and sentence representation learning (SRL). Considering the differences between VRL and SRL in terms of negative sample size and evaluation focus, we believe that the solid findings obtained in VRL may not be entirely carried over to SRL. In this work, we consider the suitability of the decoupled form of contrastive loss, i.e., alignment and uniformity, in SRL. We find a performance gap between sentence representations obtained by jointly optimizing alignment and uniformity on the STS task and those obtained using contrastive loss. Further, we find that the joint optimization of alignment and uniformity during training is prone to overfitting, which does not occur on the contrastive loss. Analyzing them based on the variation of the gradient norms, we find that there is a property of ``gradient dissipation'' in contrastive loss and believe that it is the key to preventing overfitting. We simulate similar \"gradient dissipation\" of contrastive loss on four optimization objectives of two forms, and achieve the same or even better performance than contrastive loss on the STS tasks, confirming our hypothesis",
    "checked": true,
    "id": "ce7baa35e8bf53c23e2a396d8ab8881ffb7eddd1",
    "semantic_title": "on the inadequacy of optimizing alignment and uniformity in contrastive learning of sentence representations",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=EVrz7UM-ZDm": {
    "title": "Volumetric Optimal Transportation by Fast Fourier Transform",
    "volume": "poster",
    "abstract": "The optimal transportation map finds the most economical way to transport one probability measure to another, and it has been applied in a broad range of applications in machine learning and computer vision. By the Brenier theory, computing the optimal transport map is equivalent to solving a Monge-Amp\\`ere equation, which is highly non-linear. Therefore, the computation of optimal transportation maps is intrinsically challenging. In this work, we propose a novel and powerful method, the FFT-OT (fast Fourier transform-optimal transport), to compute the 3-dimensional OT problems. The method is based on several key ideas: first, the Monge-Amp\\`ere equation is linearized to a sequence of linear elliptic PDEs with spacial and temporal variant coefficients; second, the obliqueness property of optimal transportation maps is reformulated as a Neumann boundary condition; and third, the variant coefficient elliptic PDEs are approximated by constant coefficient elliptic PDEs and solved by FFT on GPUs. We also prove that the algorithm converges linearly, namely the approximation error decreases exponentially fast. Experimental results show that the FFT-OT algorithm is more than a hundred times faster than the conventional methods based on the convex geometry. Furthermore, the method can be directly applied for sampling from complex 3D density functions in machine learning and magnifying the volumetric data in medical imaging",
    "checked": true,
    "id": "ddd566c2c858468b9882e603d0d74a35d9c59f1a",
    "semantic_title": "volumetric optimal transportation by fast fourier transform",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uKiE0VIluA-": {
    "title": "GFlowNets and variational inference",
    "volume": "poster",
    "abstract": "This paper builds bridges between two families of probabilistic algorithms: (hierarchical) variational inference (VI), which is typically used to model distributions over continuous spaces, and generative flow networks (GFlowNets), which have been used for distributions over discrete structures such as graphs. We demonstrate that, in certain cases, VI algorithms are equivalent to special cases of GFlowNets in the sense of equality of expected gradients of their learning objectives. We then point out the differences between the two families and show how these differences emerge experimentally. Notably, GFlowNets, which borrow ideas from reinforcement learning, are more amenable than VI to off-policy training without the cost of high gradient variance induced by importance sampling. We argue that this property of GFlowNets can provide advantages for capturing diversity in multimodal target distributions. Code: https://github.com/GFNOrg/GFN_vs_HVI",
    "checked": true,
    "id": "d04a26939d9783d75fa307fec3b358a3264e10f0",
    "semantic_title": "gflownets and variational inference",
    "citation_count": 96,
    "authors": []
  },
  "https://openreview.net/forum?id=zlwBI2gQL3K": {
    "title": "Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion",
    "volume": "poster",
    "abstract": "Knowledge graphs (KGs) are powerful in terms of their inference abilities, but are also notorious for their incompleteness and long-tail distribution of relations. To address these challenges and expand the coverage of KGs, few-shot KG completion aims to make predictions for triplets involving novel relations when only a few training triplets are provided as reference. Previous methods have focused on designing local neighbor aggregators to learn entity-level information and/or imposing sequential dependency assumption at the triplet level to learn meta relation information. However, pairwise triplet-level interactions and context-level relational information have been largely overlooked for learning meta representations of few-shot relations. In this paper, we propose a hierarchical relational learning method (HiRe) for few-shot KG completion. By jointly capturing three levels of relational information (entity-level, triplet-level and context-level), HiRe can effectively learn and refine the meta representation of few-shot relations, and consequently generalize well to new unseen relations. Extensive experiments on two benchmark datasets validate the superiority of HiRe over state-of-the-art methods. The code of HiRe can be found in supplementary material and will be released after acceptance",
    "checked": true,
    "id": "9ba447f59da96f6719706e0647f94b46b5dc8153",
    "semantic_title": "hierarchical relational learning for few-shot knowledge graph completion",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=pgHNOcxEdRI": {
    "title": "Function-Consistent Feature Distillation",
    "volume": "poster",
    "abstract": "Feature distillation makes the student mimic the intermediate features of the teacher. Nearly all existing feature-distillation methods use L2 distance or its slight variants as the distance metric between teacher and student features. However, while L2 distance is isotropic w.r.t. all dimensions, the neural network's operation on different dimensions is usually anisotropic, i.e., perturbations with the same 2-norm but in different dimensions of intermediate features lead to changes in the final output with largely different magnitude. Considering this, we argue that the similarity between teacher and student features should \\textit{not} be measured merely based on their appearance (i.e., L2 distance), but should, more importantly, be measured by their difference in function, namely how later layers of the network will read, decode, and process them. Therefore, we propose Function-Consistent Feature Distillation (FCFD), which explicitly optimizes the functional similarity between teacher and student features. The core idea of FCFD is to make teacher and student features not only numerically similar, but more importantly produce similar outputs when fed to the later part of the same network. With FCFD, the student mimics the teacher more faithfully and learns more from the teacher. Extensive experiments on image classification and object detection demonstrate the superiority of FCFD to existing methods. Furthermore, we can combine FCFD with many existing methods to obtain even higher accuracy. Our codes are available at https://github.com/LiuDongyang6/FCFD",
    "checked": true,
    "id": "2ef189e5851377fa7cff5301dadc5c060da86711",
    "semantic_title": "function-consistent feature distillation",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=xLr0I_xYGAs": {
    "title": "The Devil is in the Wrongly-classified Samples: Towards Unified Open-set Recognition",
    "volume": "poster",
    "abstract": "Open-set Recognition (OSR) aims to identify test samples whose classes are not seen during the training process. Recently, Unified Open-set Recognition (UOSR) has been proposed to reject not only unknown samples but also known but wrongly classified samples, which tends to be more practical in real-world applications. In this paper, we deeply analyze the UOSR task under different training and evaluation settings to shed light on this promising research direction. For this purpose, we first evaluate the UOSR performance of several OSR methods and show a significant finding that the uncertainty distribution of almost all these methods is actually closer to the expectation of UOSR than OSR. We show that the reason lies in the known but wrongly classified samples, as their uncertainty distribution is extremely close to unknown samples rather than known and correctly classified samples. Second, we analyze how the two training settings of OSR (i.e., pre-training and outlier exposure) influence the UOSR. We find although they are both beneficial for distinguishing known and correctly classified samples from unknown samples, pre-training is also helpful for identifying known but wrongly classified samples while outlier exposure is not. In addition to different training settings, we also formulate a new evaluation setting for UOSR which is called few-shot UOSR, where only one or five samples per unknown class are available during evaluation to help identify unknown samples. We propose FS-KNNS for the few-shot UOSR to achieve state-of-the-art performance under all settings",
    "checked": true,
    "id": "8edd8cd828bcc3e35f02e35180b2ff920522c3d5",
    "semantic_title": "the devil is in the wrongly-classified samples: towards unified open-set recognition",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=1FxRPKrH8bw": {
    "title": "MCAL: Minimum Cost Human-Machine Active Labeling",
    "volume": "poster",
    "abstract": "Today, ground-truth generation uses data sets annotated by cloud-based annotation services. These services rely on human annotation, which can be prohibitively expensive. In this paper, we consider the problem of hybrid human-machine labeling, which trains a classifier to accurately auto-label part of the data set. However, training the classifier can be expensive too. We propose an iterative approach that minimizes total overall cost by, at each step, jointly determining which samples to label using humans and which to label using the trained classifier. We validate our approach on well known public data sets such as Fashion-MNIST, CIFAR-10, CIFAR-100, and ImageNet. In some cases, our approach has 6× lower overall cost relative to human labeling the entire data set, and is always cheaper than the cheapest competing strategy",
    "checked": false,
    "id": "f2017730f96c350796989e3a8edbb3d6ccc386b8",
    "semantic_title": "interactive classification of maize seeds with batch mode active learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hVVUY7p64WL": {
    "title": "Learnable Topological Features For Phylogenetic Inference via Graph Neural Networks",
    "volume": "poster",
    "abstract": "Structural information of phylogenetic tree topologies plays an important role in phylogenetic inference. However, finding appropriate topological structures for specific phylogenetic inference tasks often requires significant design effort and domain expertise. In this paper, we propose a novel structural representation method for phylogenetic inference based on learnable topological features. By combining the raw node features that minimize the Dirichlet energy with modern graph representation learning techniques, our learnable topological features can provide efficient structural information of phylogenetic trees that automatically adapts to different downstream tasks without requiring domain expertise. We demonstrate the effectiveness and efficiency of our method on a simulated data tree probability estimation task and a benchmark of challenging real data variational Bayesian phylogenetic inference problems",
    "checked": true,
    "id": "1b77f48f75e202527499338113fb321581128952",
    "semantic_title": "learnable topological features for phylogenetic inference via graph neural networks",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=woa783QMul": {
    "title": "Fairness-aware Contrastive Learning with Partially Annotated Sensitive Attributes",
    "volume": "poster",
    "abstract": "Learning high-quality representation is important and essential for visual recognition. Unfortunately, traditional representation learning suffers from fairness issues since the model may learn information of sensitive attributes. Recently, a series of studies have been proposed to improve fairness by explicitly decorrelating target labels and sensitive attributes. Most of these methods, however, rely on the assumption that fully annotated labels on target variable and sensitive attributes are available, which is unrealistic due to the expensive annotation cost. In this paper, we investigate a novel and practical problem of Fair Unsupervised Representation Learning with Partially annotated Sensitive labels (FURL-PS). FURL-PS has two key challenges: 1) how to make full use of the samples that are not annotated with sensitive attributes; 2) how to eliminate bias in the dataset without target labels. To address these challenges, we propose a general Fairness-aware Contrastive Learning (FairCL) framework consisting of two stages. Firstly, we generate contrastive sample pairs, which share the same visual information apart from sensitive attributes, for each instance in the original dataset. In this way, we construct a balanced and unbiased dataset. Then, we execute fair contrastive learning by closing the distance between representations of contrastive sample pairs. Besides, we also propose an unsupervised way to balance the utility and fairness of learned representations by feature reweighting. Extensive experimental results illustrate the effectiveness of our method in terms of fairness and utility, even with very limited sensitive attributes and serious data bias",
    "checked": true,
    "id": "e159d6101d7bbc49e6d712732481cff42b6cc57f",
    "semantic_title": "fairness-aware contrastive learning with partially annotated sensitive attributes",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=_X9Yl1K2mD": {
    "title": "Rotamer Density Estimator is an Unsupervised Learner of the Effect of Mutations on Protein-Protein Interaction",
    "volume": "poster",
    "abstract": "Protein-protein interactions are crucial to many biological processes, and predicting the effect of amino acid mutations on binding is important for protein engineering. While data-driven approaches using deep learning have shown promise, the scarcity of annotated experimental data remains a major challenge. In this work, we propose a new approach that predicts mutational effects on binding using the change in conformational flexibility of the protein-protein interface. Our approach, named Rotamer Density Estimator (RDE), employs a flow-based generative model to estimate the probability distribution of protein side-chain conformations and uses entropy to measure flexibility. RDE is trained solely on protein structures and does not require the supervision of experimental values of changes in binding affinities. Furthermore, the unsupervised representations extracted by RDE can be used for downstream neural network predictions with even greater accuracy. Our method outperforms empirical energy functions and other machine learning-based approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q3-1vRh3HOA": {
    "title": "Dilated convolution with learnable spacings",
    "volume": "poster",
    "abstract": "Recent works indicate that convolutional neural networks (CNN) need large receptive fields (RF) to compete with visual transformers and their attention mechanism. In CNNs, RFs can simply be enlarged by increasing the convolution kernel sizes. Yet the number of trainable parameters, which scales quadratically with the kernel's size in the 2D case, rapidly becomes prohibitive, and the training is notoriously difficult. This paper presents a new method to increase the RF size without increasing the number of parameters. The dilated convolution (DC) has already been proposed for the same purpose. DC can be seen as a convolution with a kernel that contains only a few non-zero elements placed on a regular grid. Here we present a new version of the DC in which the spacings between the non-zero elements, or equivalently their positions, are no longer fixed but learnable via backpropagation thanks to an interpolation technique. We call this method \"Dilated Convolution with Learnable Spacings\" (DCLS) and generalize it to the n-dimensional convolution case. However, our main focus here will be on the 2D case. We first tried our approach on ResNet50: we drop-in replaced the standard convolutions with DCLS ones, which increased the accuracy of ImageNet1k classification at iso-parameters, but at the expense of the throughput. Next, we used the recent ConvNeXt state-of-the-art convolutional architecture and drop-in replaced the depthwise convolutions with DCLS ones. This not only increased the accuracy of ImageNet1k classification but also of typical downstream and robustness tasks, again at iso-parameters but this time with negligible cost on throughput, as ConvNeXt uses separable convolutions. Conversely, classic DC led to poor performance with both ResNet50 and ConvNeXt. The code of the method is based on PyTorch and available at: https://github.com/K-H-Ismail/Dilated-Convolution-with-Learnable-Spacings-PyTorch",
    "checked": true,
    "id": "f47f518893031fc3142a3ba12f7800f784f50b19",
    "semantic_title": "dilated convolution with learnable spacings",
    "citation_count": 39,
    "authors": []
  },
  "https://openreview.net/forum?id=t9Zd7Oi5JPl": {
    "title": "PatchDCT: Patch Refinement for High Quality Instance Segmentation",
    "volume": "poster",
    "abstract": "High-quality instance segmentation has shown emerging importance in computer vision. Without any refinement, DCT-Mask directly generates high-resolution masks by compressed vectors. To further refine masks obtained by compressed vectors, we propose for the first time a compressed vector based multi-stage refinement framework. However, the vanilla combination does not bring significant gains, because changes in some elements of the DCT vector will affect the prediction of the entire mask. Thus, we propose a simple and novel method named PatchDCT, which separates the mask decoded from a DCT vector into several patches and refines each patch by the designed classifier and regressor. Specifically, the classifier is used to distinguish mixed patches from all patches, and to correct previously mispredicted foreground and background patches. In contrast, the regressor is used for DCT vector prediction of mixed patches, further refining the segmentation quality at boundary locations. Experiments on COCO show that our method achieves 2.0\\%, 3.2\\%, 4.5\\% AP and 3.4\\%, 5.3\\%, 7.0\\% Boundary AP improvements over Mask-RCNN on COCO, LVIS, and Cityscapes, respectively. It also surpasses DCT-Mask by 0.7\\%, 1.1\\%, 1.3\\% AP and 0.9\\%, 1.7\\%, 4.2\\% Boundary AP on COCO, LVIS and Cityscapes. Besides, the performance of PatchDCT is also competitive with other state-of-the-art methods",
    "checked": true,
    "id": "48238f26f3fc02377711d5d6f4e8894faa1c883b",
    "semantic_title": "patchdct: patch refinement for high quality instance segmentation",
    "citation_count": 19,
    "authors": []
  },
  "https://openreview.net/forum?id=1ROAstc9jv": {
    "title": "ChiroDiff: Modelling chirographic data with Diffusion Models",
    "volume": "poster",
    "abstract": "Generative modelling over continuous-time geometric constructs, a.k.a $chirographic\\ data$ such as handwriting, sketches, drawings etc., have been accomplished through autoregressive distributions. Such strictly-ordered discrete factorization however falls short of capturing key properties of chirographic data -- it fails to build holistic understanding of the temporal concept due to one-way visibility (causality). Consequently, temporal data has been modelled as discrete token sequences of fixed sampling rate instead of capturing the true underlying concept. In this paper, we introduce a powerful model-class namely Denoising\\ Diffusion\\ Probabilistic\\ Models or DDPMs for chirographic data that specifically addresses these flaws. Our model named \"ChiroDiff\", being non-autoregressive, learns to capture holistic concepts and therefore remains resilient to higher temporal sampling rate up to a good extent. Moreover, we show that many important downstream utilities (e.g. conditional sampling, creative mixing) can be flexibly implemented using ChiroDiff. We further show some unique use-cases like stochastic vectorization, de-noising/healing, abstraction are also possible with this model-class. We perform quantitative and qualitative evaluation of our framework on relevant datasets and found it to be better or on par with competing approaches",
    "checked": true,
    "id": "1927c30e5755b3d40d75162be7213d9cb47543e5",
    "semantic_title": "chirodiff: modelling chirographic data with diffusion models",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=PmP_sf3JkrH": {
    "title": "Real-Time Image Demoir$\\acute{e}$ing on Mobile Devices",
    "volume": "poster",
    "abstract": "Moir$\\acute{e}$ patterns appear frequently when taking photos of digital screens, drastically degrading the image quality. Despite the advance of CNNs in image demoir$\\acute{e}$ing, existing networks are with heavy design, causing massive computation burden for mobile devices. In this paper, we launch the first study on accelerating demoir$\\acute{e}$ing networks and propose a dynamic demoir$\\acute{e}$ing acceleration method (DDA) towards a real-time deployment on mobile devices. Our stimulus stems from a simple-yet-universal fact that moir${\\'e}$ patterns often unbalancedly distribute across an image. Consequently, excessive computation is wasted upon non-moir$\\acute{e}$ areas. Therefore, we reallocate computation costs in proportion to the complexity of image patches. In order to achieve this aim, we measure the complexity of an image patch by a novel moir$\\acute{e}$ prior that considers both colorfulness and frequency information of moir$\\acute{e}$ patterns. Then, we restore higher-complex image patches using larger networks and the lower-complex ones are assigned with smaller networks to relieve the computation burden. At last, we train all networks in a parameter-shared supernet paradigm to avoid additional parameter burden. Extensive experiments on several benchmarks demonstrate the efficacy of our DDA. In addition, the acceleration evaluated on the VIVO X80 Pro smartphone equipped with the chip of Snapdragon 8 Gen 1 also shows that our method can drastically reduce the inference time, leading to a real-time image demoir$\\acute{e}$ing on mobile devices. Source codes and models are released at https://github.com/zyxxmu/DDA",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Kn-HA8DFik": {
    "title": "Cross-Level Distillation and Feature Denoising for Cross-Domain Few-Shot Classification",
    "volume": "poster",
    "abstract": "The conventional few-shot classification aims at learning a model on a large labeled base dataset and rapidly adapting to a target dataset that is from the same distribution as the base dataset. However, in practice, the base and the target datasets of few-shot classification are usually from different domains, which is the problem of cross-domain few-shot classification. We tackle this problem by making a small proportion of unlabeled images in the target domain accessible in the training stage. In this setup, even though the base data are sufficient and labeled, the large domain shift still makes transferring the knowledge from the base dataset difficult. We meticulously design a cross-level knowledge distillation method, which can strengthen the ability of the model to extract more discriminative features in the target dataset by guiding the network's shallow layers to learn higher-level information. Furthermore, in order to alleviate the overfitting in the evaluation stage, we propose a feature denoising operation which can reduce the feature redundancy and mitigate overfitting. Our approach can surpass the previous state-of-the-art method, Dynamic-Distillation, by 5.44% on 1-shot and 1.37% on 5-shot classification tasks on average in the BSCD-FSL benchmark. The implementation code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/CLDFD",
    "checked": true,
    "id": "c8a326aaf615a209d5599929c8e3d2be729ebe21",
    "semantic_title": "cross-level distillation and feature denoising for cross-domain few-shot classification",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=eGm22rqG93": {
    "title": "DELTA: DEGRADATION-FREE FULLY TEST-TIME ADAPTATION",
    "volume": "poster",
    "abstract": "Fully test-time adaptation aims at adapting a pre-trained model to the test stream during real-time inference, which is urgently required when the test distribution differs from the training distribution. Several efforts have been devoted to improving adaptation performance. However, we find that two unfavorable defects are concealed in the prevalent adaptation methodologies like test-time batch normalization (BN) and self-learning. First, we reveal that the normalization statistics in test-time BN are completely affected by the currently received test samples, resulting in inaccurate estimates. Second, we show that during test-time adaptation, the parameter update is biased towards some dominant classes. In addition to the extensively studied test stream with independent and class-balanced samples, we further observe that the defects can be exacerbated in more complicated test environments, such as (time) dependent or class-imbalanced data. We observe that previous approaches work well in certain scenarios while show performance degradation in others due to their faults. In this paper, we provide a plug-in solution called DELTA for Degradation-freE fuLly Test-time Adaptation, which consists of two components: (i) Test-time Batch Renormalization (TBR), introduced to improve the estimated normalization statistics. (ii) Dynamic Online re-weighTing (DOT), designed to address the class bias within optimization. We investigate various test-time adaptation methods on three commonly used datasets with four scenarios, and a newly introduced real-world dataset. DELTA can help them deal with all scenarios simultaneously, leading to SOTA performance",
    "checked": true,
    "id": "92a144817376b2b8014b75a6f575e11ba75e76b0",
    "semantic_title": "delta: degradation-free fully test-time adaptation",
    "citation_count": 69,
    "authors": []
  },
  "https://openreview.net/forum?id=YUDiZcZTI8": {
    "title": "Bit-Pruning: A Sparse Multiplication-Less Dot-Product",
    "volume": "poster",
    "abstract": "Dot-product is a central building block in neural networks. However, multiplication ($\\texttt{mult}$) in dot-product consumes intensive energy and space costs that challenge deployment on resource-constrained edge devices. In this study, we realize energy-efficient neural networks by exploiting a $\\texttt{mult}$-less, sparse dot-product. We first reformulate a dot-product between an integer weight and activation into an equivalent operation comprised of additions followed by bit-shifts ($\\texttt{add-shift-add}$). In this formulation, the number of $\\texttt{add}$ operations equals the number of bits of the integer weight in binary format. Leveraging this observation, we propose Bit-Pruning, which removes unnecessary bits in each weight value during training to reduce the energy consumption of $\\texttt{add-shift-add}$. Bit-Pruning can be seen as soft Weight-Pruning as it prunes bits, not the whole weight element. In extensive experiments, we demonstrate that sparse $\\texttt{mult}$-less networks trained with Bit-Pruning show a better accuracy-energy trade-off than sparse $\\texttt{mult}$ networks trained with Weight-Pruning",
    "checked": true,
    "id": "343c34bb769274911f5d8efd67111b44936d4885",
    "semantic_title": "bit-pruning: a sparse multiplication-less dot-product",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=x5mtJD2ovc": {
    "title": "kNN-Diffusion: Image Generation via Large-Scale Retrieval",
    "volume": "poster",
    "abstract": "Recent text-to-image models have achieved impressive results. However, since they require large-scale datasets of text-image pairs, it is impractical to train them on new domains where data is scarce or not labeled. In this work, we propose using large-scale retrieval methods, in particular, efficient k-Nearest-Neighbors (kNN), which offers novel capabilities: (1) training a substantially small and efficient text-to-image diffusion model using only pre-trained multi-modal embeddings, but without an explicit text-image dataset, (2) generating out-of-distribution images by simply swapping the retrieval database at inference time, and (3) performing text-driven local semantic manipulations while preserving object identity. To demonstrate the robustness of our method, we apply our kNN approach on two state-of-the-art diffusion backbones, and show results on several different datasets. As evaluated by human studies and automatic metrics, our method achieves state-of-the-art results compared to existing approaches that train text-to-image generation models using images-only dataset",
    "checked": true,
    "id": "a225d5d846ba5110232ed5bb32d54ea742b1c2d4",
    "semantic_title": "knn-diffusion: image generation via large-scale retrieval",
    "citation_count": 131,
    "authors": []
  },
  "https://openreview.net/forum?id=nQai_B1Zrt": {
    "title": "Decompose to Generalize: Species-Generalized Animal Pose Estimation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "20c1bbea1b35379dc8c4579f33029a1d89a09ab0",
    "semantic_title": "decompose to generalize: species-generalized animal pose estimation",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=ConT6H7MWL": {
    "title": "IDEAL: Query-Efficient Data-Free Learning from Black-Box Models",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "469dcb13083d763081d8a9863d97298497c7d461",
    "semantic_title": "ideal: query-efficient data-free learning from black-box models",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=AZFvpnnewr": {
    "title": "Trainability Preserving Neural Pruning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "c0d6c6427f0ef27c36b52d45503921166c821120",
    "semantic_title": "trainability preserving neural pruning",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=D-zfUK7BR6c": {
    "title": "Diagnosing and Rectifying Vision Models using Language",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "268b9ea1fa06a24dc12f96b16f60a52ccea352ae",
    "semantic_title": "diagnosing and rectifying vision models using language",
    "citation_count": 56,
    "authors": []
  },
  "https://openreview.net/forum?id=boNyg20-JDm": {
    "title": "Harnessing Out-Of-Distribution Examples via Augmenting Content and Style",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "10b2dc04a91b6e1cb3f24003a988fc07b57df09f",
    "semantic_title": "harnessing out-of-distribution examples via augmenting content and style",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=Kn6i2BZW69w": {
    "title": "DropIT: Dropping Intermediate Tensors for Memory-Efficient DNN Training",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "34b67b0eb233690b76bf9891e9cb95b2e0577098",
    "semantic_title": "dropit: dropping intermediate tensors for memory-efficient dnn training",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=cCFqcrq0d8": {
    "title": "A Unified Framework for Soft Threshold Pruning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3e617414c5ce17b69710897cbd2acd371b91c74b",
    "semantic_title": "a unified framework for soft threshold pruning",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=-CwPopPJda": {
    "title": "TaskPrompter: Spatial-Channel Multi-Task Prompting for Dense Scene Understanding",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2953eba822d9d65f754f18076977e42781e988b9",
    "semantic_title": "taskprompter: spatial-channel multi-task prompting for dense scene understanding",
    "citation_count": 61,
    "authors": []
  },
  "https://openreview.net/forum?id=-HHJZlRpGb": {
    "title": "Learning Domain-Agnostic Representation for Disease Diagnosis",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3085f480e0db0dfde1f23a882c661532af821c30",
    "semantic_title": "learning domain-agnostic representation for disease diagnosis",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=JdgO-ht1uTN": {
    "title": "Logical Entity Representation in Knowledge-Graphs for Differentiable Rule Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "4a29b831e16871526592119aad4a590649572a41",
    "semantic_title": "logical entity representation in knowledge-graphs for differentiable rule learning",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=-2zfgNS917": {
    "title": "BEVDistill: Cross-Modal BEV Distillation for Multi-View 3D Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8ebb8f92fdec4acd0cdba48aabac38572493e28c",
    "semantic_title": "bevdistill: cross-modal bev distillation for multi-view 3d object detection",
    "citation_count": 69,
    "authors": []
  },
  "https://openreview.net/forum?id=MLJ5TF5FtXH": {
    "title": "A Multi-Grained Self-Interpretable Symbolic-Neural Model For Single/Multi-Labeled Text Classification",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "1143ed5a664e0fc2443e0a24fbe0bf274a89b48c",
    "semantic_title": "a multi-grained self-interpretable symbolic-neural model for single/multi-labeled text classification",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=CGuvK3U09LH": {
    "title": "Suppressing the Heterogeneity: A Strong Feature Extractor for Few-shot Segmentation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "9b432bbfa44b93a3598a23fe8c21002401a6e8be",
    "semantic_title": "suppressing the heterogeneity: a strong feature extractor for few-shot segmentation",
    "citation_count": 21,
    "authors": []
  },
  "https://openreview.net/forum?id=hfUJ4ShyDEU": {
    "title": "Achieve the Minimum Width of Neural Networks for Universal Approximation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "011f793c50086565d6c7fd0b5b2e3c1459aa4940",
    "semantic_title": "achieve the minimum width of neural networks for universal approximation",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=NPfDKT9OUJ3": {
    "title": "H2RBox: Horizontal Box Annotation is All You Need for Oriented Object Detection",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "86d48098c7a7b715ef8eea303dc748cc95862d8d",
    "semantic_title": "h2rbox: horizontal box annotation is all you need for oriented object detection",
    "citation_count": 65,
    "authors": []
  },
  "https://openreview.net/forum?id=xzmqxHdZAwO": {
    "title": "Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "8e37b3b30a1fce1a3f41374ceaf168d2e79bf53f",
    "semantic_title": "pushing the limits of fewshot anomaly detection in industry vision: graphcore",
    "citation_count": 80,
    "authors": []
  },
  "https://openreview.net/forum?id=8FroynZv4C": {
    "title": "Representation Learning for Low-rank General-sum Markov Games",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "e2cf40417aa4344fd747cd96e7dd449599c05175",
    "semantic_title": "representation learning for low-rank general-sum markov games",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=APuPRxjHvZ": {
    "title": "Surgical Fine-Tuning Improves Adaptation to Distribution Shifts",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2fe24fa62c5d57c5bd4c93b25740d0779530987f",
    "semantic_title": "surgical fine-tuning improves adaptation to distribution shifts",
    "citation_count": 232,
    "authors": []
  },
  "https://openreview.net/forum?id=RVTOp3MwT3n": {
    "title": "Diversify and Disambiguate: Out-of-Distribution Robustness via Disagreement",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "35af40853f48030c5050c1c3191f6e227ceb264b",
    "semantic_title": "diversify and disambiguate: out-of-distribution robustness via disagreement",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=TQ5WUwS_4ai": {
    "title": "On amortizing convex conjugates for optimal transport",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ffe86e95223b440106a49c0bb0263c696e8459e1",
    "semantic_title": "on amortizing convex conjugates for optimal transport",
    "citation_count": 30,
    "authors": []
  },
  "https://openreview.net/forum?id=I_YZANaz5X": {
    "title": "DualAfford: Learning Collaborative Visual Affordance for Dual-gripper Manipulation",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2e7076bc3d47ad798d98f832ae02c41542ddd1b9",
    "semantic_title": "dualafford: learning collaborative visual affordance for dual-gripper manipulation",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=CjTHVo1dvR": {
    "title": "Molecular Geometry Pretraining with SE(3)-Invariant Denoising Distance Matching",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "5645dfeae81d6d5bc7c5648267837e1e0696100d",
    "semantic_title": "molecular geometry pretraining with se(3)-invariant denoising distance matching",
    "citation_count": 84,
    "authors": []
  },
  "https://openreview.net/forum?id=BqrPeZ_e5P": {
    "title": "SIMPLE: Specialized Model-Sample Matching for Domain Generalization",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "dfcffa149b9f0f6b46be80e8ed331a2dd1102009",
    "semantic_title": "simple: specialized model-sample matching for domain generalization",
    "citation_count": 38,
    "authors": []
  },
  "https://openreview.net/forum?id=6kxApT2r2i": {
    "title": "The Augmented Image Prior: Distilling 1000 Classes by Extrapolating from a Single Image",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d059011edb6567798b2e991a6c4a414a2429b0d9",
    "semantic_title": "the augmented image prior: distilling 1000 classes by extrapolating from a single image",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=07tc5kKRIo": {
    "title": "Delving into Semantic Scale Imbalance",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "d25cb3d6e7c03003ff50492f854fea7e889e815e",
    "semantic_title": "delving into semantic scale imbalance",
    "citation_count": 26,
    "authors": []
  },
  "https://openreview.net/forum?id=jgmuRzM-sb6": {
    "title": "DAG Matters! GFlowNets Enhanced Explainer for Graph Neural Networks",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "2fd0e6aaccee819a880a55d9190700c6b754d32d",
    "semantic_title": "dag matters! gflownets enhanced explainer for graph neural networks",
    "citation_count": 33,
    "authors": []
  },
  "https://openreview.net/forum?id=A3sgyt4HWp": {
    "title": "Contextual Image Masking Modeling via Synergized Contrasting without View Augmentation for Faster and Better Visual Pretraining",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "3dc68067b8ca726360497ddd489b81bcc8d729cf",
    "semantic_title": "contextual image masking modeling via synergized contrasting without view augmentation for faster and better visual pretraining",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=10R_bcjFwJ": {
    "title": "Patch-Level Contrasting without Patch Correspondence for Accurate and Dense Contrastive Representation Learning",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "ee9180c19ac2748985fd1695c1f0b399e7936df0",
    "semantic_title": "patch-level contrasting without patch correspondence for accurate and dense contrastive representation learning",
    "citation_count": 20,
    "authors": []
  },
  "https://openreview.net/forum?id=P5Z-Zl9XJ7": {
    "title": "Continuous-Discrete Convolution for Geometry-Sequence Modeling in Proteins",
    "volume": "poster",
    "abstract": "",
    "checked": true,
    "id": "6964459277134dc5a4fb1732eeb5de6761258b84",
    "semantic_title": "continuous-discrete convolution for geometry-sequence modeling in proteins",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=xmY_plRB15j": {
    "title": "Statistical Property Testing for Generative Models",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "cd82d3889c41fc677667109d567fea81aa60ee0b",
    "semantic_title": "statistical property testing for generative models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5aO1lsEJGu": {
    "title": "Can Conformal Prediction Obtain Meaningful Safety Guarantees for ML Models?",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "cae76a443497f034d3f5132464d3b86fe51c5b65",
    "semantic_title": "can conformal prediction obtain meaningful safety guarantees for ml models?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LcXWYmA8Ek": {
    "title": "A two-parameter learnable Logmoid Activation Unit",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "6d54cfdf5b50c96f50a701f8179e754c3b919ed1",
    "semantic_title": "a two-parameter learnable logmoid activation unit",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rrZtzI7xj2b": {
    "title": "Cross Domain Vulnerability Detection using Graph Contrastive Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "53d15d9654e7407455076616da703c4172a495d6",
    "semantic_title": "cross domain vulnerability detection using graph contrastive learning",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=BWWrDHaP29": {
    "title": "Tiny Attention: A Simple yet Effective Method for Learning Contextual Word Embeddings",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "64afaad957029c3e5aee956ebc43ac4046036a1c",
    "semantic_title": "tiny attention: a simple yet effective method for learning contextual word embeddings",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8WiNDyXgj6": {
    "title": "Training Data Eigenvector Dynamics in the EigenPro Implementation of the Neural Tangent Kernel and Recursive Feature Machines",
    "volume": "tiny",
    "abstract": "There has been much recent work on kernel methods as a viable alternative to deep neural networks (DNNs). The advent of the $\\textit{Neural Tangent Kernel}$ (NTK) has brought on renewed interest in these methods and their application to typical deep learning tasks. Recently, kernels have been shown to be capable of feature learning similar to that of DNNs, termed $\\textit{Recursive Feature Machines}$ (RFMs). In accordance with the growing scale of kernel models, the EigenPro 3 algorithm was proposed to facilitate large-scale training based on preconditioned gradient descent. We propose an accessible framework for observing the eigenvector dynamics of EigenPro's training data in its implementation of these kernel methods, and find empirically that significant change ceases early in training along with apparent bias towards equilibrium. In the case of RFMs, we find that significant change in the training data eigenvectors typically curtails before five iterations, in accordance with findings that RFMs achieve optimal performance in five iterations. This represents a path forward in gaining intuition for the inner workings of large-scale kernel training methods. We provide an easy to use Python implementation of our framework at https://github.com/cgorlla/ep3dynamics",
    "checked": true,
    "id": "20f3bfaf1f853f3233d8dbedbe487ec685412cd7",
    "semantic_title": "training data eigenvector dynamics in the eigenpro implementation of the neural tangent kernel and recursive feature machines",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=fVuTIiTBky": {
    "title": "Metric Transform: Exploring beyond Affine Transform for Neural Networks",
    "volume": "tiny",
    "abstract": "Artificial Neural Networks(ANN) of varying architectures are generally paired with linear transformation at the core. However, we find dot product neurons with global influence less interpretable as compared to a more local influence of euclidean distance (as used in RBF). In this work, we explore the generalization of dot product neurons to lp-norm, metrics, and beyond. We find such metrics as transform performs similarly to affine transform when used in MLP or CNN. Furthermore, we use distance/similarity measuring neurons to interpret and explain input data, overfitting and Residual MLP. We share our code in github",
    "checked": true,
    "id": "fc2a8f16964539e68de3071c559be5955ca3f494",
    "semantic_title": "metric transform: exploring beyond affine transform for neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mIEMVZ47aNA": {
    "title": "MaskedFusion360: Reconstruct LiDAR Data by Querying Camera Features",
    "volume": "tiny",
    "abstract": "In self-driving applications, LiDAR data provides accurate information about distances in 3D but lacks the semantic richness of camera data. Therefore, state-of-the-art methods for perception in urban scenes fuse data from both sensor types. In this work, we introduce a novel self-supervised method to fuse LiDAR and camera data for self-driving applications. We build upon masked autoencoders (MAEs) and train deep learning models to reconstruct masked LiDAR data from fused LiDAR and camera features. In contrast to related methods that use birds-eye-view representations, we fuse features from dense spherical LiDAR projections and features from fish-eye camera crops with a similar field of view. Therefore, we reduce the learned spatial transformations to moderate perspective transformations and do not require additional modules to generate dense LiDAR representations. Code is available at: https://github.com/KIT-MRT/masked-fusion-360",
    "checked": true,
    "id": "7de07e29a2a214dc93212421aa8b5ac9b08af4b1",
    "semantic_title": "maskedfusion360: reconstruct lidar data by querying camera features",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=7QqlQW9hJ8J": {
    "title": "Meta-Learning for Subject Adaptation in Low-Data Environments for EEG-Based Motor Imagery Brain-Computer Interfaces",
    "volume": "tiny",
    "abstract": "Motor imagery classification from Electroencephalogram (EEG) signals involves decoding information during the imagination of specific movements. However, learning representations for EEG-based motor imagery classification is challenging due to inter-subject variability and differences in mental imagery, resulting in poor generalization of deep learning models to new subjects. While pre-trained deep learning models achieve high accuracy on subjects with similar domains, they fail on subjects with dissimilar domains. Optimization-based meta-learning algorithms can address this limitation by learning a good initialization for the model, enabling quick adaptation to new subjects with limited fine-tuning examples. We demonstrate that our Meta Learning approach consistently outperforms Transfer Learning on the BCI Competition IV 2a dataset. Although accuracy varies depending on domain similarity, meta-learning demonstrates efficient adaption to unseen subjects with limited data. By improving generalization across subjects with different domains under low-data environments, we can enhance the reliability and practicality of brain-computer interfaces for real-world applications",
    "checked": true,
    "id": "358a49dfcc12dcb9d9e498ef4d4c8a0de956fbec",
    "semantic_title": "meta-learning for subject adaptation in low-data environments for eeg-based motor imagery brain-computer interfaces",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=AHnLJBD7xKx": {
    "title": "Fostering Effective Communication Between Humans and Machines",
    "volume": "tiny",
    "abstract": "With the growing usage of smartphones, digital communication has become significant. This paper describes the primary research conducted to study user interaction patterns on smartphones. Results show that the time between two touches, or the editorial context duration, is just 5 to 10 seconds for a vast majority of smartphone interactions. So, the paper introduces the novel concept of MicroStimuli, which can generate a response in mere milliseconds, specifically tailored for smartphones. The construct of MicroStimuli is formulated by leveraging the neuroscience of decision-making in response to visual stimuli",
    "checked": true,
    "id": "c98e3702ccfd782681c6e3ceac73f4e0592ca637",
    "semantic_title": "fostering effective communication between humans and machines",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=7lyEQXHkGpl": {
    "title": "Transfer Learning on Kinyarwanda Tweets Sentiment Analysis",
    "volume": "tiny",
    "abstract": "Pretrained models available on platform such as Hugging Face have become a valuable resource for machine learning community, particularly for natural language processing task. In this study, we evaluated the performance of Kinyarwanda and English pretrained models for sentiment analysis of Kinyarwanda tweets through transfer learning using Hugging Face pretrained models and Trainer for implementation. We have found that English pretrained models for translated Kinyarwanda tweets dataset using Google translate out performed Kinyarwanda pretrained models",
    "checked": true,
    "id": "7e6f667ac047ba231ba550f84ec30bfee38ba863",
    "semantic_title": "transfer learning on kinyarwanda tweets sentiment analysis",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=RuCQRXk7a7G": {
    "title": "Symbolic Regression in Financial Economics",
    "volume": "tiny",
    "abstract": "We apply symbolic regression, the machine learning approach of recovering models from data, in financial economics. Specifically, we present a data set consisting of equations that cover a broad range of topics in financial economics. These equations are built off a common set of mathematical symbols but importantly have new variations in functional forms. We test the joint performance of deep learning and genetic programming symbolic regression systems in recovering these non-physical equations",
    "checked": true,
    "id": "2395d5fe450fc66e21c2645a1bc86c31bade1e83",
    "semantic_title": "symbolic regression in financial economics",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=75mWq5j4iso": {
    "title": "FRESCO: Federated Reinforcement Energy System for Cooperative Optimization",
    "volume": "tiny",
    "abstract": "The rise in renewable energy is creating new dynamics in the energy grid that promise to create a cleaner and more participative energy grid, where technology plays a crucial part in creating the required flexibility to achieve the vision of the next-generation grid. This work presents FRESCO, a framework that aims to ease the implementation of energy markets using a hierarchical control architecture of reinforcement learning agents trained using federated learning. The core concept we are proving is that having greedy agents subject to changing conditions from a higher level agent creates a cooperative setup that will allow for fulfilling all the individual objectives. This paper presents a general overview of the framework, the current progress, and some insights we obtained from the recent results",
    "checked": false,
    "id": "7aa03760057a55a52c0c56d5bd408edf3891ffa8",
    "semantic_title": "uav-assisted online machine learning over multi-tiered networks: a hierarchical nested personalized federated learning approach",
    "citation_count": 42,
    "authors": []
  },
  "https://openreview.net/forum?id=jbNqgEJf0EI": {
    "title": "Learning Rotation-Agnostic Representations via Group Equivariant VAEs",
    "volume": "tiny",
    "abstract": "An emerging field in representation learning involves the study of group-equivariant neural networks, that leverage concepts from group representation theory to design neural architectures that can exploit discrete and continuous symmetries to produce more general representations. Following this direction, in this work we demonstrate how an image embedding agnostic to rotations can be naturally obtained by training a variational autoencoder (S-GVAE) equipped with a Group equivariant Convolutional Neural Network (G-CNN) encoder",
    "checked": true,
    "id": "22f0e8082823c0daf3a7f1006e0e4f32a45849c9",
    "semantic_title": "learning rotation-agnostic representations via group equivariant vaes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KPHbtTtCDw": {
    "title": "Can Text Encoders be Deceived by Length Attack?",
    "volume": "tiny",
    "abstract": "Albeit \\textit{de facto} to use in training dense retrieval models, we observe that contrastive learning is prone to length overfitting, making it vulnerable to adversarial length attacks. We examine the behaviour of this phenomenon and propose an editing method to mitigate this problem. We find that our method can effectively improve the robustness of models against length attacks. Its effectiveness can be attributed to reduced length information in the embeddings, more robust intra-document token interaction, and enhanced isotropy at trained length range",
    "checked": true,
    "id": "5b1a26bdf85eb7a939a3e8061250565310dfc09f",
    "semantic_title": "can text encoders be deceived by length attack?",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=kidk_E11QQ": {
    "title": "Whispering Across the Continent: Collecting and Analyzing African Culture Using Community Radios",
    "volume": "tiny",
    "abstract": "African culture is rich and diverse, but much of its knowledge is held by the elders of the community and passed down through oral traditions. With globalization, young Africans are becoming increasingly disconnected from their roots, making it essential to collect and preserve this knowledge. However, the lack of accessible data on African culture presents a significant challenge. This research aims to address this problem by exploring new ways to collect and preserve African cultural data. Specifically, we have developed a device to perform continuous recording of cultural radio programs in local languages, which has enabled us to collect over 1500 hours of audio data. We are also exploring the use of a whisper model, which has proven to be effective in outperforming human transcription and being multilingual. This research project's final goal is to build a language model that understands African culture, providing an effective approach to store this knowledge for future generations to learn about their culture",
    "checked": true,
    "id": "8e75d18347ff5d3cb778efdb8bdfb0f1b2e5126b",
    "semantic_title": "whispering across the continent: collecting and analyzing african culture using community radios",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e2gSQqH3V10": {
    "title": "Handling unstructured data for operator learning using implicit neural representations",
    "volume": "tiny",
    "abstract": "Operator learning methods are too often constrained by a fixed sampling of both the input and output functions. We propose a novel method to allow current operator learning methods to learn on any sampling. We show that our method can perform inference on unseen samplings, and that it allows returning outputs as continuous functions",
    "checked": true,
    "id": "7f9d31705c699b54665f43265e2ba38efb95f784",
    "semantic_title": "handling unstructured data for operator learning using implicit neural representations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=njpSzZ6mCU": {
    "title": "Model Extraction Attacks on DistilBERT",
    "volume": "tiny",
    "abstract": "This paper investigates model extraction attacks, where an adversary can train a substitute model by collecting data through query access to a victim model and stealing its functionality. We use DistilBERT as the victim model due to its smaller size and faster processing speed. The results demonstrate the effectiveness of the model extraction attack and show that fine-tuning more powerful language models can improve accuracy. The study provides important insights into the security of machine learning models",
    "checked": true,
    "id": "3c26202058ff573620e70e340c9c8cafb2094678",
    "semantic_title": "model extraction attacks on distilbert",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qq-bA-VLUN": {
    "title": "One Important Thing To Do Before Federated Training",
    "volume": "tiny",
    "abstract": "Previous research in Federated learning (FL) have emphasized privacy protection, model optimization, and so on, meanwhile, they overlooked how to choose the appropriate FL algorithm for a new federation with preserving data privacy. In our study, we provide a formal problem formulation for algorithm selection in FL and present a novel approach that involves leveraging trained federations to aid with algorithm selection. Empirical results prove the effectiveness of our method",
    "checked": true,
    "id": "01d00477642f43db605cdace9d35bc86aca9ac3d",
    "semantic_title": "one important thing to do before federated training",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=_cL7Uj4LXAJ": {
    "title": "Insights into the mechanism behind reusing Teacher's classifier in Knowledge Distillation",
    "volume": "tiny",
    "abstract": "Knowledge distillation (KD) has emerged as an effective approach to compress deep neural networks by transferring knowledge from a powerful yet cumbersome teacher model to a lightweight student model. Recent research has suggested that re-using the teacher's final layer (i.e., the classifier) can be a straightforward and effective method for knowledge distillation. The underlying mechanism for this method's success remains unclear. Our study aims to shed light on how the knowledge distillation loss affects the alignment between the weights of the student classifier and the teacher classifier. Specifically, we compare the $L^2$ norm of the difference between the weights of the student and the teacher classifier during the training process. Our experiments demonstrate that the knowledge distillation loss encourages alignment between the student and teacher classifiers, as indicated by a strong positive correlation ($>0.97$) between the $L^2$ norm and the loss during training. We also observe that as temperature increases, this alignment decreases and the $L^2$ norm behaves similar to normal (non-KD) training. Our analysis aims to provide to a better understanding of knowledge distillation provide a starting point for the development of new KD frameworks",
    "checked": true,
    "id": "ff5b7dea1166dc549bf6d5d9e474de440c01f245",
    "semantic_title": "insights into the mechanism behind reusing teacher's classifier in knowledge distillation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iCqvQSvar5V": {
    "title": "When will federated learning transfer from generalization to personalization?",
    "volume": "tiny",
    "abstract": "The timing of personalization refers to determining when to train and update personalized models for the participants in Personalized federated learning. Determining the timing for personalization contributes to improving the overall efficiency of federated learning. We propose that training transfers to personalization when the accuracy of the global model reaches a predefined threshold. Experimental results show that this method can effectively improve the accuracy of personalized models in a non-IID scenario",
    "checked": true,
    "id": "b9064b391aec38d3e249669553ff6c314819ce9e",
    "semantic_title": "when will federated learning transfer from generalization to personalization?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S9NTReFikL2": {
    "title": "A Change of Heart: Improving Speech Emotion Recognition through Speech-to-Text Modality Conversion",
    "volume": "tiny",
    "abstract": "Speech Emotion Recognition (SER) is a challenging task. In this paper, we introduce a modality conversion concept aimed at enhancing emotion recognition performance on the MELD dataset. We assess our approach through two experiments: first, a method named Modality-Conversion that employs automatic speech recognition (ASR) systems, followed by a text classifier; second, we assume perfect ASR output and investigate the impact of modality conversion on SER, this method is called Modality-Conversion++. Our findings indicate that the first method yields substantial results, while the second method outperforms state-of-the-art (SOTA) speech-based approaches in terms of SER weighted-F1 (WF1) score on the MELD dataset. This research highlights the potential of modality conversion for tasks that can be conducted in alternative modalities",
    "checked": true,
    "id": "d976c3361b859fe2e07e6ae62b68dd3d59abe499",
    "semantic_title": "a change of heart: improving speech emotion recognition through speech-to-text modality conversion",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=if1Mmrxf-pq": {
    "title": "Fairness Under Partial Observability",
    "volume": "tiny",
    "abstract": "The purpose of this article is to discuss an important challenge faced in ``real life'' when trying to implement \\emph{group} fairness-aware models and algorithms. Here, we focus specifically on the role that uncertainty and ambiguity play and revisit the case where protected attributes are only partially observable",
    "checked": true,
    "id": "4909e5bb98c066d06ab75a57c104b1e0cd875fc6",
    "semantic_title": "fairness under partial observability",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cFtt9fU7YB6": {
    "title": "Geodesic Mode Connectivity",
    "volume": "tiny",
    "abstract": "Mode connectivity is a phenomenon where trained models are connected by a path of low loss. We reframe this in the context of Information Geometry, where neural networks are studied as spaces of parameterized distributions with curved geometry. We hypothesize that shortest paths in these spaces, known as geodesics, correspond to mode-connecting paths in the loss landscape. We propose an algorithm to approximate geodesics and demonstrate that they achieve mode connectivity",
    "checked": true,
    "id": "8f5a0d8ef36338126bf4358614b01fb8d9942d21",
    "semantic_title": "geodesic mode connectivity",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=_cZLvP7LAt7": {
    "title": "Pursuit Policies in Dynamic Environments",
    "volume": "tiny",
    "abstract": "Cooperative pursuit is a popular multi-agent reinforcement learning (MARL) game where a team of predators target prey while avoiding obstacles. Previous literature has largely considered the impact of different predator, prey abilities on learning. Here, we investigate the impact of dynamic environments on learning predator pursuit policies from partial observations with deep Q-learning. Interestingly, we find predators are able to learn cooperative pursuit strategies that leverage moving obstacles",
    "checked": true,
    "id": "ccca54c7136134b84305d3c966f7c3eeb60b5052",
    "semantic_title": "pursuit policies in dynamic environments",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OJILbuOodvm": {
    "title": "Resource-efficient image inpainting",
    "volume": "tiny",
    "abstract": "Image inpainting refers to the synthesis of missing regions in an image, which can help restore occluded or degraded areas and also serve as a precursor task for self-supervision. The current state-of-the-art models for image inpainting are computationally heavy as they are based on vision transformer backbones in adversarial or diffusion settings. This paper diverges from vision transformers by using a computationally-efficient WaveMix-based fully convolutional architecture, which uses a 2D-discrete wavelet transform (DWT) for spatial and multi-resolution token-mixing along with convolutional layers. The proposed model outperforms the current-state-of-the-art models for large mask inpainting on reconstruction quality while also using less than half the parameter count and considerably lower training and evaluation times",
    "checked": true,
    "id": "73f597ac355b85cf399b4fcc33c232ced6ecefd3",
    "semantic_title": "resource-efficient image inpainting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TS8l4VS7_BK": {
    "title": "Recursive Reasoning with Neural Networks",
    "volume": "tiny",
    "abstract": "Many problems can naturally be thought about recursively. However, neural networks fundamentally cannot reason this way on arbitrarily large problems. This is because they do not have the memory to maintain state for the maximum recursion depth required. Solving this issue would enable neural networks to reason like a wide range of classical recursive algorithms (e.g., tree search in model-based RL). To address this, we propose a neural architecture augmented with a stack that learns to save and recall state as needed. We empirically demonstrate the utility of this method on a recursive neural algorithmic reasoning task (learning depth-first search) and show that our architecture leads to improved generalization",
    "checked": true,
    "id": "5fd167a0b6b772e8e98cba3141bf64e6da1aafd9",
    "semantic_title": "recursive reasoning with neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wUEY2CdQGi1": {
    "title": "SUDANESE ARABIC DIALECT ENCODING USING XLM-RoBERTa LANGUAGE MODEL: Zol-ROBERTA",
    "volume": "tiny",
    "abstract": "XLM-RoBERTa has proven to be very efficient at Natural Language Understanding (NLU), as it allows to achieve state-of-the-art results in most NLU tasks. In this work we aim to utilize the power of XLM-RoBERTa in Sudanese Arabic dialect. We collected over 6 million sentences in Sudanese dialect and used them to resume training of the pre-trained XLM-RoBERTa, as it was trained on 2.5T of data across 100 languages filtered from Common Crawl. Our model -Zol-RoBERTa- is expected to achieve better performance on Sudanese Sentiment Analysis, this clarifies that Zol-RoBERTa will work better in understanding Sudanese Dialectic, which is the domain we are targeting",
    "checked": true,
    "id": "9a74998359616ad60de3d7c817a1ae25fdce81e5",
    "semantic_title": "sudanese arabic dialect encoding using xlm-roberta language model: zol-roberta",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PIfJnq9kpdw": {
    "title": "Reducing the Effect of Incomplete Annotations in Object Detection for Histopathology",
    "volume": "tiny",
    "abstract": "Training neural networks for object detection usually requires decent amounts of data to produce great results. Apart from the image variety, the number of annotated objects is a crucial factor for success. In histopathology, the average annotation density is very high, resulting in resource-consuming data preparation for neural network training. We explore the effect of incomplete annotations in object detection. We show that modern object detectors, such as YOLO-v5, can effectively learn from histopathology datasets that lack up to 90% of annotations. Additionally, we suggest an easy model tuning setup to reduce the impact of incomplete annotations and enhance learning capability overall. We publish our code at https://github.com/DenysKaliuzhnyi/yolov5",
    "checked": true,
    "id": "7e7fe6e2b992ffc7d2f2833524b8aaec3bac91e6",
    "semantic_title": "reducing the effect of incomplete annotations in object detection for histopathology",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nSqrgBKBGkv": {
    "title": "Experimenting with Multimodal AutoML: Detection and Evaluation of Alzheimer's Disease",
    "volume": "tiny",
    "abstract": "This paper describes an experiment using AutoML, AutoGluon Tabular, to discover multimodal models for MMSE regression and AD detection. Using the ADReSSo dataset, this paper reports enhanced performance in classification models and comparable performance in regression models to the baseline, achieving a significant improvement of up to 82\\% accuracy on the test dataset. In contrast, the test RMSE has a marginal difference of only 0.28 compared to the baseline",
    "checked": true,
    "id": "d3b089a16905e0b4ec43950d35779501747b8c34",
    "semantic_title": "experimenting with multimodal automl: detection and evaluation of alzheimer's disease",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2KxH_4US0ZH": {
    "title": "GFlowNets with Human Feedback",
    "volume": "tiny",
    "abstract": "We propose the GFlowNets with Human Feedback (GFlowHF) framework to improve the exploration of training language models. For tasks where the reward is unknown, we fit the reward function through human evaluations on different trajectories. The goal of GFlowHF is to learn a policy that is strictly proportional to human ratings, instead of only focusing on human favorite ratings like RLHF. Experiments show that GFlowHF can achieve better exploration ability than RLHF, and thus is more suitable for large-scale language model tasks",
    "checked": true,
    "id": "b9c081f78280110741bc809593effcdd7a96bc8e",
    "semantic_title": "gflownets with human feedback",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=R82eeIF4rP_": {
    "title": "Attention-likelihood relationship in Transformers",
    "volume": "tiny",
    "abstract": "We analyze how large language models (LLMs) represent out-of-context words, investigating their reliance on the given context to capture their semantics. Our likelihood-guided text perturbations reveal a correlation between token likelihood and attention values in transformer-based language models. Extensive experiments reveal that unexpected tokens cause the model to attend less to the information coming from themselves to compute their representations, particularly at higher layers. These findings have valuable implications for assessing the robustness of LLMs in real-world scenarios. Fully reproducible codebase at [url]",
    "checked": true,
    "id": "d51c94df736ed7916af86f9162eb89f03fc6b0d4",
    "semantic_title": "attention-likelihood relationship in transformers",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=cQ_eEMsc6p": {
    "title": "Truly Generative Data Augmentation for Image Segmentation - Case of Cloud Images",
    "volume": "tiny",
    "abstract": "Supervised learning frameworks frequently rely on semantic image segmentation, which necessitates a substantial amount of annotated data. Existing methodologies for data augmentation either employ image transformations that are limited by the cardinality of the original dataset or employ generative augmentation techniques that introduce pixel categorization errors. This paper presents an innovative approach for \"truly\" generative data augmentation for image segmentation, specifically in the context of sky/cloud images. The proposed method involves separate generation of the background clear sky image and the foreground cloud masks using two separate DCGANs, which are subsequently merged to produce augmented images. This organic approach enhances the quality of generated images while preserving accurate pixel categorization. The proposed approach is finally noted to improve the robustness of the sky/cloud image segmentation models",
    "checked": true,
    "id": "165f0c798b3fc9473fe5e61bbffb253532f8d890",
    "semantic_title": "truly generative data augmentation for image segmentation - case of cloud images",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ghfL1e2rOd": {
    "title": "Fast Fourier Convolutions in Self-Supervised Neural Networks for Image Denoising",
    "volume": "tiny",
    "abstract": "Recently, denoising convolutional neural networks (CNN) have started to outperform classical denoising algorithms. However, CNNs performance could be constrained by the limited receptive field of regular convolution. To mitigate this problem, a new modification for CNNs was proposed: Fast Fourier Convolution (FFC). Here, a global receptive field is achieved by using Fourier Transform and convolving spectral representation. The global perception field can help CNNs to better capture dependencies in image regions that are far apart. In this work, we design multiple approaches for incorporating FFC into self-supervised neural networks for image denoising. We evaluate these approaches on three benchmark datasets and compare them with supervised and self-supervised methods. We empirically show that an FFC-enhanced denoising network achieves the state-of-the- art results on the character dataset and shows a comparable level of performance for both grayscale and color natural images",
    "checked": true,
    "id": "f1d714b63b1b89473eb2abfff6920942f5964a61",
    "semantic_title": "fast fourier convolutions in self-supervised neural networks for image denoising",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lpcO1957Tv": {
    "title": "Personalized Federated Learning for Medical Segmentation using Hypernetworks",
    "volume": "tiny",
    "abstract": "In federated learning (FL), several clients jointly train a shared model without sharing their data, maintaining data privacy and reducing communication costs. In personalized federated learning (PFL), each client has their own model, and models are trained jointly. Hypernetworks have been shown to be useful for PFL in classification problems, but it is still not clear how to apply them to problems like segmentation. There, models are very large, and it is not known what parts of models should be personalized, and what parts should be shared across clients. Here, we explore HNs for PFL for solving a problem of image segmentation in the context of medical imaging diagnosis. Using MRI scans for prostate segmentation, we demonstrate that using a hypernetwork to personalize a single convolution layer and the batch-norm layer outperforms local and FL baselines",
    "checked": true,
    "id": "9ac7e82b0387a341b6ee1d6bf7eba02613c71d97",
    "semantic_title": "personalized federated learning for medical segmentation using hypernetworks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=R5NNAThG0i": {
    "title": "Career Path Modeling and Recommendations with Linkedin Career Data and Predicted Salary Estimations",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "d47f3572989cdaa026ff5b42153e7add30d725f5",
    "semantic_title": "career path modeling and recommendations with linkedin career data and predicted salary estimations",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=q_lJooPbX_": {
    "title": "Sleep Deprivation in the Forward-Forward Algorithm",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "bf97e513ac3c7756bccfd69bcbb9196223048da1",
    "semantic_title": "sleep deprivation in the forward-forward algorithm",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nF70Sl-HUZ": {
    "title": "MetaXLR - Mixed Language Meta Representation Transformation for Low-resource Cross-lingual Learning based on Multi-Armed Bandit",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "36f8333e59d41f9ce795e8b6d95eea7ebd310e29",
    "semantic_title": "metaxlr - mixed language meta representation transformation for low-resource cross-lingual learning based on multi-armed bandit",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cKlgcx7nSZ": {
    "title": "Prune and Tune: Improving Efficient Pruning Techniques for Massive Language Models",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "72c03b873e8c5cd86b15bf73186df341da4731c9",
    "semantic_title": "prune and tune: improving efficient pruning techniques for massive language models",
    "citation_count": 16,
    "authors": []
  },
  "https://openreview.net/forum?id=XptW6NuULJ": {
    "title": "Model Extraction Attacks on Arabic BERT-Based APIs",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "0d0f1f455398365f346f742e28be1f2b65435435",
    "semantic_title": "model extraction attacks on arabic bert-based apis",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=baF9FqIdTY": {
    "title": "IMITATION LEARNING USING THE FORWARD-FORWARD ALGORITHM",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "0d5a4c10ce809ae025aedbdd32e90250757b89de",
    "semantic_title": "imitation learning using the forward-forward algorithm",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dGuMR8tLDs": {
    "title": "The Geometry of Multilingual Language Models: An Equality Lens",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "fcf34c027be1828a081079165cc99864589c7a56",
    "semantic_title": "the geometry of multilingual language models: an equality lens",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Muwb2KohnX": {
    "title": "Dynamic Human AI Collaboration",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "770107c53bfb8b1f4f68b632162f057aba575424",
    "semantic_title": "dynamic human ai collaboration",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jd7Hy1jRiv4": {
    "title": "The Responsibility Problem in Neural Networks with Unordered Targets",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "40eee4d569d065b76c63b12a225dc17b535c1d5a",
    "semantic_title": "the responsibility problem in neural networks with unordered targets",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=losgEaOWIL7": {
    "title": "Concept Understanding in Large Language Models: An Empirical Study",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "43b5d1195c762c67db145f69486e12ad7be46b6c",
    "semantic_title": "concept understanding in large language models: an empirical study",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=rAT51tL04I2": {
    "title": "Adaptive Distance Message Passing From the Multi-Relational Edge View",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "4763ce0e77288cb23b5a959f89ec4edf30423a8f",
    "semantic_title": "adaptive distance message passing from the multi-relational edge view",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=DLwlmWwmJBi": {
    "title": "Sustainable Resource Management",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "fb5500ff36f6d18dea9e6ca19040e8e37550ab9b",
    "semantic_title": "sustainable resource management",
    "citation_count": 74,
    "authors": []
  },
  "https://openreview.net/forum?id=n5aZMLXVndP": {
    "title": "Chain Of Thought Prompting Under Streaming Batch: A Case Study",
    "volume": "tiny",
    "abstract": "",
    "checked": false,
    "id": "811115d36e1eabe2cef03b38a0809514e40b658e",
    "semantic_title": "chain-of-thought prompting under streaming batch: a case study",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=F7mdgA7c2zD": {
    "title": "Language Models can do Zero-Shot Visual Referring Expression Comprehension",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "c2817f81a39ebae90889039bd1805bac00c41fe3",
    "semantic_title": "language models can do zero-shot visual referring expression comprehension",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=isodM5jTA7h": {
    "title": "Simple Parameter-free Self-attention Approximation",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "3525e2bdee920e52cc6e80af1ac1a25741e8fa5c",
    "semantic_title": "simple parameter-free self-attention approximation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=cYKtDg5JnxV": {
    "title": "Neuromodulation Gated Transformer",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "060c886bcf59508b61946646fc1a12ac449cfdfb",
    "semantic_title": "neuromodulation gated transformer",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Lm7z2vYergk": {
    "title": "Decomposing Causality and Fairness",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "ba9939879fc313f30dd00c0c1f1ff018e3ca39af",
    "semantic_title": "decomposing causality and fairness",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EARgl3EH-nq": {
    "title": "Self-Supervised Image Denoising with Swin Transformer",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "6e3f4201b1001486c446904b5279cb63d661e430",
    "semantic_title": "self-supervised image denoising with swin transformer",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1wtUadpmVzu": {
    "title": "SimbaML: Connecting Mechanistic Models and Machine Learning with Augmented Data",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "a0d274ce9697e88cc3a7c111307375de9950936c",
    "semantic_title": "simbaml: connecting mechanistic models and machine learning with augmented data",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=zwywBS3GyFs": {
    "title": "GeValDi: Generative Validation of Discriminative Models",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "23b5f6feac78313cf2c1c06c6026bbe0a681b9f5",
    "semantic_title": "gevaldi: generative validation of discriminative models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kbhUUAMZmQT": {
    "title": "Regularized Offline GFlowNets",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "cb06ed4104a9815a9b22830de48c317b94f81fd9",
    "semantic_title": "regularized offline gflownets",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=xZGPLvRpf4N": {
    "title": "SECURE COMMUNICATION MODEL FOR QUANTUM FEDERATED LEARNING: A PROOF OF CONCEPT",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "e2405870f4e5f329179e8fd4fb4db03a44bfef35",
    "semantic_title": "secure communication model for quantum federated learning: a proof of concept",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=wecTsVkrjit": {
    "title": "Learn to Select: Efficient Cross-device Federated Learning via Reinforcement Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "69387c82aa820331b98592deda6046b80517bd00",
    "semantic_title": "learn to select: efficient cross-device federated learning via reinforcement learning",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=hli7A0ioiS_": {
    "title": "A Dynamic Prompt-tuning Method for Data Augmentation with Associated Knowledge",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "2c61efeac33544b45f17bdc30d6c2fcbf7b93c55",
    "semantic_title": "a dynamic prompt-tuning method for data augmentation with associated knowledge",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=1LeLyB6T0JM": {
    "title": "MARKOVIAN EMBEDDINGS FOR COALITIONAL BARGAINING GAMES",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "a4271d3a2da440e5990b83e1c9cf28415b52a5d6",
    "semantic_title": "markovian embeddings for coalitional bargaining games",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1_PEwKmTepo": {
    "title": "The Point to Which Soft Actor-Critic Converges",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "9009db47ae4e3c347173b862cf2af89615414b66",
    "semantic_title": "the point to which soft actor-critic converges",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=qNJRvdKDGYg": {
    "title": "No Double Descent in Self-Supervised Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "82f1c174cff98510856ff734dc8dd0d30b5e624e",
    "semantic_title": "no double descent in self-supervised learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=kBkou5ucR_d": {
    "title": "Resampling Gradients Vanish in Differentiable Sequential Monte Carlo Samplers",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "470be157a912949230b8d8c9d01450af581e51b0",
    "semantic_title": "resampling gradients vanish in differentiable sequential monte carlo samplers",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=uNrSvEr9Lqc": {
    "title": "Generalised Lookahead Optimiser",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "888505467cf3637c32c48ed6b3af05a525f88877",
    "semantic_title": "generalised lookahead optimiser",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d0m0Rl15q3g": {
    "title": "Revisiting CounteRGAN for Counterfactual Explainability of Graphs",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "4897bb71ecc28dffcc6bd3854c0a4c19af539d70",
    "semantic_title": "revisiting countergan for counterfactual explainability of graphs",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=GJhsHNKm7kj": {
    "title": "Language Models Inversely Scale on Piecewise Function Evaluation with Biased Examples",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "0184df15d853852e3fdc790f5aadde1910a6db7c",
    "semantic_title": "language models inversely scale on piecewise function evaluation with biased examples",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iF2w_kqmYmw": {
    "title": "RETHINKING POSITIONAL EMBEDDING: A CASE STUDY IN TEMPORAL EVENT SEQUENCE MODELLING",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "066ddc83465ef428ac62ab099ae29808c850e529",
    "semantic_title": "rethinking positional embedding: a case study in temporal event sequence modelling",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TFrzVBZk05g": {
    "title": "Exploring Efficient and Simple Initialization Strategies for Bayesian Optimization with SETUP-BO",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "10a6b934648f6b25ff5486353a0b2df3b365a4dc",
    "semantic_title": "exploring efficient and simple initialization strategies for bayesian optimization with setup-bo",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x4MuUFPKEIj": {
    "title": "Quota Constraints for Diversity Interventions in Subset Selection",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "981460d5052761f1fcf5ea33bddf6a94f96a3a0c",
    "semantic_title": "quota constraints for diversity interventions in subset selection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zYF6NLJl6LM": {
    "title": "Mitigating Metastable Failures in Distributed Systems with Offline Reinforcement Learning",
    "volume": "tiny",
    "abstract": "This paper introduces a load-shedding mechanism that mitigates metastable failures through offline reinforcement learning (RL). Previous studies have heavily focused on heuristics that are reactive and limited in generalization, while online RL algorithms face challenges in accurately simulating system dynamics and acquiring data with sufficient coverage. In contrast, our algorithm leverages offline RL to learn directly from existing log data. Through extensive empirical experiments, we demonstrate that our algorithm outperforms rule-based methods and supervised learning algorithms in a proactive, adaptive, generalizable, and safe manner. Deployed in a Java compute service with diverse execution times and configurations, our algorithm exhibits faster reaction time and attains the Pareto frontier between throughput and tail latency",
    "checked": true,
    "id": "a6e6b5dfa8292be96a1bb8f8f602748eb04711b9",
    "semantic_title": "mitigating metastable failures in distributed systems with offline reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=-bMH1Sk8SSF": {
    "title": "Knowledge Distillation of BERT Language Model on the Arabic Language",
    "volume": "tiny",
    "abstract": "The absence of good Arabic language models led to significant setbacks in the Arabic language related tasks and lag with respect to robustness and accuracy. While a pre-trained version of BERT on Arabic language is available, a smaller distilled version could be proven to be highly scalable. In this research paper, we propose the development of a smaller and more efficient version of BERT, known as DistilBERT for the Arabic language for the pursuit of achieving comparable results with significantly less computational resources. Employing knowledge distillation to create a compact model allows for wider implementation, even in areas with limited computational resources. Ultimately, this project aims to break down language barriers, bring greater inclusivity and improve the accessibility of the Arabic language in NLP applications worldwide. This project serves as a starting point for further research and investigation of the performance of the Arabic DistilBERT model across various NLP tasks",
    "checked": true,
    "id": "f9e7f464b86d703eb3e472574fcea4cc31d8b0db",
    "semantic_title": "knowledge distillation of bert language model on the arabic language",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DoOiwBcRir3": {
    "title": "Offensiveness as an Opinion: Dissecting population-level Label Distributions",
    "volume": "tiny",
    "abstract": "Human annotation is an essential component for building human-in-the-loop machine learning systems (MLs). The diverse human disagreement that arises during annotation is often obscured because of majority voting label aggregation used for training MLs. When the minority opinion is removed in this process it may also extricate the sentiments held by people in minority demographics. This information is essential when MLs are used for offensive or hate speech identification as some content is offensive to only a minority. Collecting human annotations is an expensive task and it is even more challenging when collecting for minority voices. Population-level learning (PLL) utilizes unsupervised learning methods to represent populations of annotators using existing annotations. We test the viability and transparency of PLL with a large dataset of toxic content. We explore the clusters qualitatively by studying the language of the data items assigned to different clusters. In addition, we quantitatively analyze the nature of human disagreement via the data points assigned to the clusters",
    "checked": true,
    "id": "f8389b298bf82c340d8de1b97c59104f536f8f3c",
    "semantic_title": "offensiveness as an opinion: dissecting population-level label distributions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=z2Gr8YqsimF": {
    "title": "How do ConvNets Understand Image Intensity?",
    "volume": "tiny",
    "abstract": "Convolutional Neural Networks (ConvNets) usually rely on edge/shape information to classify images. Visualization methods developed over the last decade confirm that ConvNets rely on edge information. We investigate situations where the ConvNet needs to rely on image intensity in addition to shape. We show that the ConvNet relies on image intensity information using visualization",
    "checked": true,
    "id": "e00200be457080deee9438d819f24ff41b215562",
    "semantic_title": "how do convnets understand image intensity?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x_adzmY6PQ5": {
    "title": "Learning Weight Sensitivity from Entropy",
    "volume": "tiny",
    "abstract": "Multiple network pruning methods have used connection sensitivity of each weight to prune their network. This paper proposes a meta-learning approach to learn sensitivity of weights based on their entropy, or change, during the training phase. We have experimentally shown the validity of such an approach",
    "checked": true,
    "id": "f9663ca518d6386536bf232f16406dd04f11a8cf",
    "semantic_title": "learning weight sensitivity from entropy",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BQpCuJoMykZ": {
    "title": "A Study on Sample Diversity in Generative Models: GANs vs. Diffusion Models",
    "volume": "tiny",
    "abstract": "In this project, we compare the sample diversity of two generative models: Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPMs). GANs have achieved impressive results in generating high-quality samples, but have been known to suffer from the issue of mode collapse, which can result in a lack of sample diversity. Mode collapse occurs when the generator network in a GAN becomes stuck in a local minimum, causing it to produce samples that are similar to each other rather than sampling from the full range of possibilities in the target distribution. This can lead to a lack of sample diversity, as the generator is unable to explore and represent the full range of features in the data. DDPMs, on the other hand, have demonstrated improved sample diversity compared to GANs. We conducted experiments using both synthetic and image data to explore the connection between mode collapse and sample diversity in these two frameworks. Our findings indicate that by addressing the mode collapse problem, DDPM preserves a comprehensive representation of the distribution",
    "checked": true,
    "id": "fc83e43f07ac7e6dc655fbb957132dc151e06716",
    "semantic_title": "a study on sample diversity in generative models: gans vs. diffusion models",
    "citation_count": 25,
    "authors": []
  },
  "https://openreview.net/forum?id=XCbe51-arJt": {
    "title": "Artificial Intelligent Life: A New Perspective on Artificial General Intelligence",
    "volume": "tiny",
    "abstract": "We propose artificial intelligent life (AILife) as a new perspective to approach artificial general intelligence, similar to a living organism in reality. Unlike machine learning approaches that focus on reward functions and mathematical optimizations, AILife seeks to develop an artificial organism that learns by the mechanism of biological neurons. AILife is composed of a biological-like neuron system to learn from interactions with the world, a sensory system to feel the world, and actuators to perform activities. We show a toy example to explain AILife",
    "checked": true,
    "id": "d112f4d651bed056a3c0648f0ed827bdf80c9e1b",
    "semantic_title": "artificial intelligent life: a new perspective on artificial general intelligence",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cRZSr6Tpr1S": {
    "title": "Generative AI for Therapy? Opportunities and Barriers for ChatGPT in Speech-Language Therapy",
    "volume": "tiny",
    "abstract": "Speech-language pathologists (SLPs) are health professionals who work with children and adults with various communication disorders in areas such as speech, language, hearing, and voice. The rise of voice assistants and chatbots brings new opportunities for SLPs and points to new opportunities and barriers when adopted during clinical service delivery. This paper explores the potential adoption of ChatGPT in speech-language therapy for individuals with receptive and expressive language disorders. By offering SLP critique for ChatGPT's responses to multiple therapeutic use cases, limitations and solutions for improving generative AI tools for speech-language therapy are also discussed",
    "checked": true,
    "id": "0df4a7dd38a3eeab3225c21bfe4a66ccd4aca838",
    "semantic_title": "generative ai for therapy? opportunities and barriers for chatgpt in speech-language therapy",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=1yXbt6_o6av": {
    "title": "The Art of Embedding Fusion: Optimizing Hate Speech Detection",
    "volume": "tiny",
    "abstract": "Hate speech detection is a challenging natural language processing task that requires capturing linguistic and contextual nuances. Pre-trained language models (PLMs) offer rich semantic representations of text that can improve this task. However there is still limited knowledge about ways to effectively combine representations across PLMs and leverage their complementary strengths. In this work, we shed light on various combination techniques for several PLMs and comprehensively analyze their effectiveness. Our findings show that combining embeddings leads to slight improvements but at a high computational cost and the choice of combination has marginal effect on the final outcome",
    "checked": true,
    "id": "c810ceac2f6351491309278b3d837639353977ce",
    "semantic_title": "the art of embedding fusion: optimizing hate speech detection",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=STpRX-XCO6t": {
    "title": "COLLABORATIVE CONCEPT DRIFT DETECTION",
    "volume": "tiny",
    "abstract": "Collaborative Concept Drift Detection (C2D2) combines Fast Correlated Based Filtering (FCBF) and Singular Value Decomposition (SVD) to detect concept drifts in 5 synthetic datasets. We compare our results against 6 diveregence tests and introduce Performance Gain Update Cost Ratio (PGUCR). Post-hoc Tukey HSD test confirmed that C2D2 outperformed the other tests in terms of PGUCR. Much of C2D2's improvement is based on its conservative signals for updates",
    "checked": true,
    "id": "bf9f766b0c6ef0bc6759cf1c39b8d7e20e93a269",
    "semantic_title": "collaborative concept drift detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EyliiBqhFz": {
    "title": "End-to-End Learnable Masks With Differentiable Indexing",
    "volume": "tiny",
    "abstract": "An essential step towards developing efficient learning algorithms involves being able to work with as little data as possible to achieve good performance. For this reason, sparse representation learning is a crucial avenue of computer vision research. However, sparsity-inducing methods like importance sampling rely on non-differentiable operators like masking or top-K selection. While several tricks have been proposed for getting gradients to flow ‘through' the pixels selected by the operators, the actual indices for which pixels are masked or selected are non-differentiable and thus cannot be learned end-to-end. We propose three methods for making operations like masking and top-k selection fully differentiable by allowing gradients to flow through the operator indices and showing how they can be optimized end-to-end using backpropagation. As a result, all three methods can be used as simple layers or submodules in existing neural network libraries",
    "checked": true,
    "id": "b274ec5ad2d9a40471f018de39b46d5da8f34ec1",
    "semantic_title": "end-to-end learnable masks with differentiable indexing",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Hx_iTXnCR5": {
    "title": "FigGen: Text to Scientific Figure Generation",
    "volume": "tiny",
    "abstract": "The generative modeling landscape has experienced tremendous growth in recent years, particularly in generating natural images and art. Recent techniques have shown impressive potential in creating complex visual compositions while delivering impressive realism and quality. However, state-of-the-art methods have been focusing on the narrow domain of natural images, while other distributions remain unexplored. In this paper, we introduce the problem of text-to-figure generation, that is creating scientific figures of papers from text descriptions. We present FigGen, a diffusion-based approach for text-to-figure as well as the main challenges of the proposed task. Code and models are available at https://github.com/joanrod/figure-diffusion",
    "checked": true,
    "id": "9a17c7118143747a38a6a7aeef9818c223cd1708",
    "semantic_title": "figgen: text to scientific figure generation",
    "citation_count": 10,
    "authors": []
  },
  "https://openreview.net/forum?id=OMARmh02Ruk": {
    "title": "Evaluating Impact of Emoticons and Pre-processing on Sentiment Classification of Translated African Tweets",
    "volume": "tiny",
    "abstract": "This paper examines the impact of emoticons and pre-processing on sentiment classification for English translations of 11 African languages. Using AfriSenti-SemEval datasets, Roberta and Twitter-Roberta models are fine-tuned, and standard classification metrics are used to assess performance. The study concludes no significant performance differences with emoticons and pre-processing and no distinction between standard Roberta and domain-specific Twitter-Roberta",
    "checked": true,
    "id": "776367ba701fb755fb37c775cb606aedd23bae48",
    "semantic_title": "evaluating impact of emoticons and pre-processing on sentiment classification of translated african tweets",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=OiSbJbVWBJT": {
    "title": "SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels",
    "volume": "tiny",
    "abstract": "Rule-based text data augmentation is widely used for NLP tasks due to its simplicity. However, this method can potentially damage the original meaning of the text, ultimately hurting the performance of the model. To overcome this limitation, we propose a straightforward technique for applying soft labels to augmented data. We conducted experiments across seven different classification tasks and empirically demonstrated the effectiveness of our proposed approach. We have publicly opened our source code for reproducibility",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5CdkvFyatt2": {
    "title": "MatPropXtractor: Generate to Extract",
    "volume": "tiny",
    "abstract": "The field of materials science has amassed a wealth of information about materials in text publications, however, such information is often confined within the publication. A lack of standardized structure and naming consistency preclude the information from being effectively utilized for research and discovery. We introduce MatPropXtractor, an extraction system that uses pre-trained large language models (LLMs) in a generative setting to extract materials and their properties as reported in the materials science literature. MatPropXtractor consists of a three-step pipeline that includes 1) a document selection tool to identify related articles, 2) a paragraph classifier to identify passages containing important materials properties, and 3) a property extractor exploiting in-context learning in GPT-3. MatPropXtractor extracted 154 material-property pairs from five materials science papers. The extracted pairs were analyzed by an expert and obtained an average precision of 72.73% on paragraph classification and an average precision of 56.7% precision on material-property identification",
    "checked": true,
    "id": "8b13afca6dc2c1920333b8e95d249f7b39df6922",
    "semantic_title": "matpropxtractor: generate to extract",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=-AIukSeLAz9": {
    "title": "Zero-Shot Classification Reveals Potential Positive Sentiment Bias in African Languages Translations",
    "volume": "tiny",
    "abstract": "Natural Language Processing research into African languages has been limited, with over 2000 languages still needing to be studied. We employ the AfriSenti-SemEval dataset, a recently released resource that provides annotated tweets across 13 African languages, for sentiment analysis to address this. However, given the persistent data limitations for specific languages, we translate each language to English and conduct zero-shot classification using a large BART model trained with three candidate labels: positive, neutral, and negative. Intriguingly, our findings indicate that all tweets are classified as positive. Further investigation into prediction probabilities reveals that translation technologies may exhibit a bias in translating African languages toward positive sentiments. This observation highlights the potential impact of translation tools on sentiment analysis and warrants further examination",
    "checked": true,
    "id": "e2da6d12148958943f073e2547297c3414296f20",
    "semantic_title": "zero-shot classification reveals potential positive sentiment bias in african languages translations",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=c-YTzVUkfAW": {
    "title": "Lesion Search with Self-supervised Learning",
    "volume": "tiny",
    "abstract": "Content-based image retrieval (CBIR) with self-supervised learning (SSL) accelerates clinicians' interpretation of similar images without manual annotations. We develop a CBIR from the contrastive learning SimCLR and incorporate a generalized-mean (GeM) pooling followed by L2 normalization to classify lesion types and retrieve similar images before clinicians' analysis. Results have shown improved performance. We additionally build an open-source application for image analysis and retrieval. The application is easy to integrate, relieving manual efforts and suggesting the potential to support clinicians' everyday activities",
    "checked": true,
    "id": "528864c83ea8358a2fa7be56cf0c8170087563fa",
    "semantic_title": "lesion search with self-supervised learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GPA-BPLwYHf": {
    "title": "Feature Importance Analysis for Mini Mental Status Score Prediction in Alzheimer's Disease",
    "volume": "tiny",
    "abstract": "This research article proposes developing predictive models to forecast Mini-Mental State Exam (MMSE) scores using the 54 most important features identified from the current state-of-the-art model. The study employs the SHapley Additive exPlanations (SHAP) method to explore feature importance and interpret model performance. The analysis shows that the Automated Readability Index (ARI) is the most influential feature in predicting MMSE scores. This finding suggests that ARI's capability to capture language impairment and morphosyntax is valuable in predicting cognitive decline in dementia patients. Although the analysis could not evaluate all features, this study provides a foundation for future investigations into features that may assist in predicting MMSE scores and the onset of Dementia",
    "checked": true,
    "id": "5aae970c41cad97985a25f26994b12eea1b26a5f",
    "semantic_title": "feature importance analysis for mini mental status score prediction in alzheimer's disease",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=1F8pPnUinbU": {
    "title": "On a Relation Between the Rate-Distortion Function and Optimal Transport",
    "volume": "tiny",
    "abstract": "We discuss a relationship between rate-distortion and optimal transport (OT) theory, even though they seem to be unrelated at first glance. In particular, we show that a function defined via an extremal entropic OT distance is equivalent to the rate-distortion function. We numerically verify this result as well as previous results that connect the Monge and Kantorovich problems to optimal scalar quantization. Thus, we unify solving scalar quantization and rate-distortion functions in an alternative fashion by using their respective optimal transport solvers",
    "checked": true,
    "id": "f6e0cb69da2607a0334937ef91a0fc8d5bd8f7f0",
    "semantic_title": "on a relation between the rate-distortion function and optimal transport",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=YdGkE4Ugg2C": {
    "title": "Is CLIP Fooled by Optical Illusions?",
    "volume": "tiny",
    "abstract": "Recent large machine learning models such as CLIP have shown impressive generalization performance for various perception tasks. In this work, we explore to what extent they model the human cognitive process. We focus our attention on how these models perceive optical illusions. We present a simple way to assess the effect by presenting illusions in the form of image and text prompts while observing the changes in models' output under different illusory strengths. Our results show that CLIP can indeed be fooled by different types of illusions relating to lightness and geometry",
    "checked": true,
    "id": "c1d72292611405d8aee6a26316e2d84511b258cb",
    "semantic_title": "is clip fooled by optical illusions?",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=_QreMdMNIz-": {
    "title": "Seeing in Words: Learning to Classify through Language Bottlenecks",
    "volume": "tiny",
    "abstract": "Neural networks for computer vision extract uninterpretable features despite achieving high accuracy on benchmarks. In contrast, humans can explain their predictions using succinct and intuitive descriptions. To incorporate explainability into neural networks, we train a vision model whose feature representations are text. We show that such a model can effectively classify ImageNet images, and we discuss the challenges we encountered when training it",
    "checked": true,
    "id": "7343c7426723d3c13096d39093eb636f96240eb1",
    "semantic_title": "seeing in words: learning to classify through language bottlenecks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=0sxmoci9Ma": {
    "title": "Towards Stochastic Gradient Variance Reduction by Solving a Filtering Problem",
    "volume": "tiny",
    "abstract": "Stochastic gradient descent is commonly used to optimize deep neural networks, but it often produces noisy and unreliable gradient estimates that hinder convergence. To address this issue, we introduce \\textbf{Filter Gradient Descent} (FGD), a family of stochastic optimization algorithms that consistently estimate the local gradient by solving an adaptive filtering problem. By incorporating historical states, FGD reduces the variance in stochastic gradient descent and improves the current estimation. We demonstrate the efficacy of FGD in numerical optimization and neural network training, where it outperforms traditional momentum-based methods in terms of robustness and performance. Code is available at \\url{https://github.com/Adamdad/Filter-Gradient-Decent}",
    "checked": true,
    "id": "37f5e160211b3be428195de2e5dba206f7b1030e",
    "semantic_title": "towards stochastic gradient variance reduction by solving a filtering problem",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aVepdnlRb5": {
    "title": "MACHINE TRANSLATION BASELINES FOR ARABIC - SWAHILI",
    "volume": "tiny",
    "abstract": "Building neural machine translation (NMT) systems for low-resource languages poses several challenges, mainly due to the lack of parallel data. In this research, we propose a baseline NMT system for translating between Arabic and Swahili. Despite being spoken by nearly 300 million individuals worldwide, the parallel corpus between these two languages is severely underrepresented. To address this, we scraped and processed the largest high-quality parallel corpus of Swahili and Arabic to our knowledge. We then used state-of-the-art NMT models, including Transformers and multilingual variants of Transformers, to build a baseline for bidirectional Arabic-Swahili NMT. Finally, we report an increase in the performance of our NMT system using the back-translation technique",
    "checked": true,
    "id": "6904cbd7e1a0eca53a6fead063c78480d493142d",
    "semantic_title": "machine translation baselines for arabic - swahili",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=QimsmhYvsf": {
    "title": "Accuracy of white box and black box adversarial attacks on a sign activation 01 loss neural network ensemble",
    "volume": "tiny",
    "abstract": "In this work we ask the question: is an ensemble of single hidden layer sign activation 01 loss networks more robust to white box and black box adversarial attacks than an ensemble of its differentiable counterpart of cross-entropy loss with relu activations and an ensemble of the approximate differentiable counterpart of cross-entropy loss with sign activations? We consider a simple experimental setting of attacking models trained for binary classification on pairwise CIFAR10 datasets - altogether a total of 45 datasets. We study ensembles of {\\bf bcebp}: binary cross-entropy loss with relu activations trained with back-propagation, {\\bf bceban}: binary cross-entropy loss with sign activations trained with back-propagation with the straight through estimator gradient, {\\bf 01scd}: 01-loss with sign activations trained with gradient-free stochastic coordinate descent, and {\\bf bcescd}: binary cross-entropy loss with relu activation trained with gradient-free stochastic coordinate descent (to isolate the effect of 01 loss from gradient-free training). We train each model in an ensemble with a different random number generator seed. Our four models have similar mean test accuracies in the mid to high 80s on pairwise CIFAR10 datasets but under powerful PGD white-box attacks they each drop to near 0\\% except for our 01 loss network ensemble that has 31\\% accuracy. Even training with the gradient-free stochastic coordinate descent can be attacked thus suggesting that the defense lies in 01 loss. In a black-box transfer attack we find adversaries produced from the bcebp model fully transfer to bceban but much less to 01scd - we see the same transferability pattern from bceban to bcebp and 01scd. We also find that adversaries from 01scd barely transfer to bcebp and bceban. While our results are far from those of multi-class and convolutional networks, they suggest that 01 loss models are hard to attack naturally without any adversarial training. All models, data, and code to reproduce results here are available from \\url{https://github.com/xyzacademic/mlp01example}",
    "checked": true,
    "id": "98b66386f0a0d3a74aff41ce4439f0934a1632e1",
    "semantic_title": "accuracy of white box and black box adversarial attacks on a sign activation 01 loss neural network ensemble",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=AidIUjh__t": {
    "title": "TopEx: Topic-based Explanations for Model Comparison",
    "volume": "tiny",
    "abstract": "Meaningfully comparing language models is challenging with current explanation methods. Current explanations are overwhelming for humans due to large vocabularies or incomparable across models. We present TopEx, an explanation method that enables a level playing field for comparing language models via model-agnostic topics. We demonstrate how TopEx can identify similarities and differences between DistilRoBERTa and GPT-2 on a variety of NLP tasks",
    "checked": true,
    "id": "ec5660aeca844379dff83d1e90b93e2dace7bbf7",
    "semantic_title": "topex: topic-based explanations for model comparison",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=cxmjk8O3Yn": {
    "title": "GeneDAE: A Sparse Denoising Autoencoder for Deriving Interpretable Gene Embeddings",
    "volume": "tiny",
    "abstract": "A challenge in genomics research involves identifying functionally relevant genes associated with diseases. We present GeneDAE, a sparse denoising autoencoder that extracts gene representations from large-scale population-level genotype data, which can then be used to identify gene-to-disease associations. The GeneDAE encoder and decoder connections are modeled on a bipartite biological knowledge graph that connects individual variants (single nucleotide polymorphisms; SNPs) to their nearby genes, enabling each node in the hidden layer to be used as an interpretable, multi-purpose gene embedding derived using information only from variants in close proximity that are most likely to impact gene function. We use the UK Biobank dataset and focus on the major histone compatibility complex (MHC) region of the genome, which is critical to immune function and autoimmune disease pathophysiology. Using GeneDAE, we extracted 239 MHC gene embeddings and identified novel gene-to-disease associations",
    "checked": true,
    "id": "03697ab0031e638363040446f7db7b66699956dd",
    "semantic_title": "genedae: a sparse denoising autoencoder for deriving interpretable gene embeddings",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=XHfWgU2IiP": {
    "title": "Improving Hyperspectral Adversarial Robustness Under Multiple Attacks",
    "volume": "tiny",
    "abstract": "Semantic segmentation models classifying hyperspectral images (HSI) are vulnerable to adversarial examples. Traditional approaches to adversarial robustness focus on training or retraining a single network on attacked data, however, in the presence of multiple attacks these approaches decrease in performance compared to networks trained individually on each attack. To combat this issue we propose an Adversarial Discriminator Ensemble Network (ADE-Net) which focuses on attack type detection and adversarial robustness under a unified model to preserve per data-type weight optimally while robustifiying the overall network. In the proposed method, a discriminator network is used to separate data by attack type into their specific attack-expert ensemble network",
    "checked": true,
    "id": "cec0f97eef9efaef18b3f32d602f6f3da6b6bea6",
    "semantic_title": "improving hyperspectral adversarial robustness under multiple attacks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hBz5h3C9Sq": {
    "title": "Prompt Programming for the Visual Domain",
    "volume": "tiny",
    "abstract": "In this work, we ask how text-to-image synthesis via large language models can effectively probe imagery that embodies fidelity and imagination. We investigate this question in the context of prompts (writing to language models) in a novel probing mechanism known as prompt programming, or programming in natural language. We start by refining existing techniques to characterize the effect of templates on visual fidelity then hone in on approaches to capture holistic nuances within the visual domain. We present a systematic analysis of prompt engineering for visual image generation",
    "checked": true,
    "id": "7c710a918a3b41e54c4647135935b39d6ef2aeea",
    "semantic_title": "prompt programming for the visual domain",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ufA2FuCGyz": {
    "title": "Mapping the Typographic Latent Space of Digits",
    "volume": "tiny",
    "abstract": "Since the advancement of handwritten text to typefaces on a computer, the human mind has evolved towards corresponding various typefaces as norms of comprehension. Current-day typefaces, much like those written by hand, exist in disparities and are governed by consensus reached among Typographers. Currently, the PANOSE system, developed in 1998, is the most widely used and accepted method for classifying typefaces based on 10 visual attributes. In this work, we employ Disentangled Beta-VAE's, in an unsupervised learning approach, to map the latent feature space with a dataset of MNIST Style Typographic Images (TMNIST-Digit) of 0-9 digits across 2990 unique font styles. We expose the learning representation across a variety of font styles to enable typographers to contemplate and identify new attributes to their classification system",
    "checked": true,
    "id": "93c7e8fa8b30a931546f9dc33fa3560c44655fa8",
    "semantic_title": "mapping the typographic latent space of digits",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Mrz9PgP3sT": {
    "title": "Hyperbolic Deep Reinforcement Learning for Continuous Control",
    "volume": "tiny",
    "abstract": "Integrating hyperbolic representations with Deep Reinforcement Learning (DRL) has recently been proposed as a promising approach for enhancing generalization and sample-efficiency in discrete control tasks. In this work, we extend hyperbolic RL to continuous control by introducing a novel hyperbolic actor-critic model. Empirically, our simple implementation outperforms its Euclidean counterpart, with significant gains on 16/24 tasks from the DeepMind Control Suite with pixel inputs. Notably, in the low-data regime, our method even outperforms several pre-trained unsupervised RL agents. Our findings show that hyperbolic representations provide a valuable inductive bias for continuous control",
    "checked": true,
    "id": "8bf5f30561c0019fe229dba45b4b0a6ba5bf7f57",
    "semantic_title": "hyperbolic deep reinforcement learning for continuous control",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XXsjViheWZ": {
    "title": "Incorporating Expert Prior Knowledge for Oral Lesion Recognition",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "72cad7c1ef107d1aacbc9e6d533960b97d6b1328",
    "semantic_title": "incorporating expert prior knowledge for oral lesion recognition",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2M8dEAJcG5": {
    "title": "LEARNING LIGHTWEIGHT STRUCTURE-AWARE EMBEDDINGS FOR PROTEIN SEQUENCES",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "ae0f0829a297bdf46eb5aae5a747b87a1c24c765",
    "semantic_title": "learning lightweight structure-aware embeddings for protein sequences",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lmcPpHDa0B": {
    "title": "Proactive policing as reinforcement learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "8fa99a6b2e386f9b69d6d240594aea7a6fb91fab",
    "semantic_title": "proactive policing as reinforcement learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=G0heahVv5Y": {
    "title": "The Small Batch Size Anomaly in Multistep Deep Reinforcement Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "cc4c47070d96579f00844dc91a0324913cc7f56a",
    "semantic_title": "the small batch size anomaly in multistep deep reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VBuUL2IWlq": {
    "title": "Bootstrapping Parallel Anchors for Relative Representations",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "436e4d681c05818928b32da2fb8b5f47c08933ce",
    "semantic_title": "bootstrapping parallel anchors for relative representations",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=qqKO_rrg9y": {
    "title": "A Brief History of the Speculative Measures for Autonomy",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "d8481ef9ca1abffeb1af858f62a004b623b954a5",
    "semantic_title": "a brief history of the speculative measures for autonomy",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=_1z2Bqte5L": {
    "title": "Semantic feature verification in FLAN-T5",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "3cc4629b541f8f6d9e3d3e3dc7639885e1a4ef76",
    "semantic_title": "semantic feature verification in flan-t5",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=XiZOalwf_U": {
    "title": "Augmenting Collective Intelligence through Belbin's Team Roles",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "9a5aae5a3ce1a346b383c7c519eb89f94f884be6",
    "semantic_title": "augmenting collective intelligence through belbin's team roles",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7Zyv70nGl_g": {
    "title": "Text2Face: 3D Morphable Faces From Text",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "b8aa4b1606cd45fa3fbadb6a20f7d8df22b98120",
    "semantic_title": "text2face: 3d morphable faces from text",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oKa5_mxHBV": {
    "title": "Towards Parametric Robust Activation Functions in Adversarial Machine Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "ef5e5b7f1c15758b40d64d37a620bee7e2c60140",
    "semantic_title": "towards parametric robust activation functions in adversarial machine learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iWiwox99aJ": {
    "title": "Understanding Label Bias in Single Positive Multi-Label Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "52a4c9b79c58a020c3e46a7f79b96a790a227731",
    "semantic_title": "understanding label bias in single positive multi-label learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=5lZaexgIey": {
    "title": "Knowledge and Attitude of Medical Students and Doctors towards Artificial Intelligence: A study of University of Ilorin",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "fe79316b4457cafd49dc412e65635bda7732a4bd",
    "semantic_title": "knowledge and attitude of medical students and doctors towards artificial intelligence: a study of university of ilorin",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=K-SVVOIcsP": {
    "title": "Human-machine cooperation for semantic feature listing",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "cb58062526cd92e0cba7b6f50e9cb7bbec1f763a",
    "semantic_title": "human-machine cooperation for semantic feature listing",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=vHOO1lxggJ": {
    "title": "Improving generalization by loss modification",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "3887fdcbb1fc59b9b1f5102435dd4e7a769eac4e",
    "semantic_title": "improving generalization by loss modification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6ry6ibTKOx": {
    "title": "A Rate--Distortion View on Model Updates",
    "volume": "tiny",
    "abstract": "",
    "checked": false,
    "id": "df103405015dabeab25832ae217d31babcee64cd",
    "semantic_title": "a rate-distortion view on model updates",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2g4m5S_knF": {
    "title": "Text-Based Games as a Challenging Benchmark for Large Language Models",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "8ec14fd3a21b9e0724580eaf11d8511e1910fe6d",
    "semantic_title": "text-based games as a challenging benchmark for large language models",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=0Zhwu1VaOs": {
    "title": "Learned Learning Rate Schedules for Deep Neural Network Training Using Reinforcement Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "e8b22993efec83105daae948878a2c2ec0358c85",
    "semantic_title": "learned learning rate schedules for deep neural network training using reinforcement learning",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=CTZigc9V69": {
    "title": "Speaker-Invariant Speech Recognition through Fine-Tuning on Individual-Specific Data with Voice Conversion",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "c192982464c31b73cebd91e75fbbd8588e2710f6",
    "semantic_title": "speaker-invariant speech recognition through fine-tuning on individual-specific data with voice conversion",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SBqbPjVFfm": {
    "title": "Effect of training fragment length on Transformers in text complexity prediction",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "96a15852e710d6dd5bd1da9b0ca15d70c64e0f8b",
    "semantic_title": "effect of training fragment length on transformers in text complexity prediction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lkWvTn2IzA": {
    "title": "Revisiting Bisimulation: A Sampling-Based State Similarity Pseudo-metric",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "ab9492b4750e6597af0d970b1a3fca2127113281",
    "semantic_title": "revisiting bisimulation: a sampling-based state similarity pseudo-metric",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AAu_WuIiwi": {
    "title": "Efficient Learning rate schedules for Stochastic Non-negative Matrix Factorization via Reinforcement Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "d564a44bccb12523b7c29a1765db0b9b71a1a032",
    "semantic_title": "efficient learning rate schedules for stochastic non-negative matrix factorization via reinforcement learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H2mbtfasD4K": {
    "title": "Chaotic Transformers for Deep Reinforcement Learning in Algorithmic Trading",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "90c018fc3d56d5e85f7ebda44c58e5ed9dfd4dfb",
    "semantic_title": "chaotic transformers for deep reinforcement learning in algorithmic trading",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G_MpqMHYo-": {
    "title": "Effects of Single-Attribute Control on the Music Generated by FIGARO",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "d23daa4bdd440152bafc5af180eb610af6febca7",
    "semantic_title": "effects of single-attribute control on the music generated by figaro",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FWohKbMhlo": {
    "title": "Iterative weakly supervised learning for novel class object detection",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "5939065104cdbff80784bb9d8e76db6f5681616f",
    "semantic_title": "iterative weakly supervised learning for novel class object detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LV33sOiYCEP": {
    "title": "BANDIT SAMPLING FOR FASTER NEURAL NETWORK TRAINING WITH SGD",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "896acb4dd67b478e416579a381ded992ebac565d",
    "semantic_title": "bandit sampling for faster neural network training with sgd",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MjVdwBGkys": {
    "title": "Train Monolingual, Infer Bilingual",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "85d98dc35ea922129dea08cdcf3b30e54ba49a92",
    "semantic_title": "train monolingual, infer bilingual",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TPTbHxeR6U": {
    "title": "A Simple, Fast Algorithm for Continual Learning from High-Dimensional Data",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "dc7fca1e888ff0b92afbb79fff3e7022c1f2a628",
    "semantic_title": "a simple, fast algorithm for continual learning from high-dimensional data",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=H9BGkFz-Sm": {
    "title": "Discerning Self-Supervised Learning and Weakly Supervised Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "2e66905243daa4ff84068ebb224d1f94616ecaf1",
    "semantic_title": "discerning self-supervised learning and weakly supervised learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=x2XNoPdXF8J": {
    "title": "DiffGANPaint: Fast Inpainting Using Denoising Diffusion GANs",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "af6d97af92a0d0851f0a8ee8cda3a768dd71d6d1",
    "semantic_title": "diffganpaint: fast inpainting using denoising diffusion gans",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=dJfdug9aGd8": {
    "title": "Effectiveness of Debiasing Techniques: An Indigenous Qualitative Analysis",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "cbef1cd3651e0f7cbd4d8bbea749b1983b5bc54e",
    "semantic_title": "effectiveness of debiasing techniques: an indigenous qualitative analysis",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=FPzByCI0yz1": {
    "title": "An Analysis of Transferability in Network Intrusion Detection using Distributed Deep Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "36a30cdf6069a8caae7ee13234fde9a0f88839e0",
    "semantic_title": "an analysis of transferability in network intrusion detection using distributed deep learning",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=99XvUeDFYTD": {
    "title": "MLP-Attention: Improving Transformer Architecture with MLP Attention Weights",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "2f20f9b4ee90f74d3cfed25b9e7a8e46cb30390e",
    "semantic_title": "mlp-attention: improving transformer architecture with mlp attention weights",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=4isz71_aZN": {
    "title": "Averager Student: Distillation from Undistillable Teacher",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "9a4a3d4a2fbe067ab64f37af8cc192af015a2730",
    "semantic_title": "averager student: distillation from undistillable teacher",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=2rp3guEM3A": {
    "title": "Inducing Document Representations from Graphs: A Blueprint",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "e70319b54101992e6eb7ae6ef2413ec85f05e469",
    "semantic_title": "inducing document representations from graphs: a blueprint",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=a9VgV-hywP": {
    "title": "Uncertainty-Aware Test-Time Augmented Ensemble of BERTs for Classification of Common Mental Illnesses on Social Media Posts",
    "volume": "tiny",
    "abstract": "Given the current state of the world, because of existing situations around the world, millions of people suffering from mental illnesses feel isolated and unable to receive help in person. Psychological studies have shown that our state of mind can manifest itself in the linguistic features we use to communicate. People have increasingly turned to online platforms to express themselves and seek help with their conditions. Deep learning methods have been commonly used to identify and analyze mental health conditions from various sources of information, including social media. Still, they face challenges, including a lack of reliability and overconfidence in predictions resulting in the poor calibration of the models. To solve these issues, We propose UATTA-EB: Uncertainty-Aware Test-Time Augmented Ensembling of BERTs for producing reliable and well-calibrated predictions to classify six possible types of mental illnesses",
    "checked": true,
    "id": "7a81d0cfc8e485f41f8f8e3db2c253a9717d4057",
    "semantic_title": "uncertainty-aware test-time augmented ensemble of berts for classification of common mental illnesses on social media posts",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uMlLT_xuiE": {
    "title": "Predicting Targets with Data from Non-Conforming Sources",
    "volume": "tiny",
    "abstract": "Machine learning applications to real-world settings are often tasked with making predictions on data generated by multiple sources. There are many methods for understanding when data is Out-Of-Distribution (OOD). A less explored area of importance is where OOD data can be considered In-Distribution (ID) when conditioned by its generating data source. Within this preliminary research, we focus on this issue and propose methods for building classification models capable of making predictions on data in which labels can depend on their source",
    "checked": true,
    "id": "dbafa892a687159d498cabde10d7f0e714501097",
    "semantic_title": "predicting targets with data from non-conforming sources",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=o7uGWBK6Uo": {
    "title": "One Explanation Does Not Fit XIL",
    "volume": "tiny",
    "abstract": "Current machine learning models produce outstanding results in many areas but, at the same time, suffer from shortcut learning. To address such flaws, the XIL framework has been proposed to revise a model by employing user feedback on a model's explanation. This work sheds light on the explanations used within this framework. In particular, we investigate simultaneous model revision through multiple explanation methods. To this end, we identified that \\textit{one explanation does not fit XIL} and propose considering multiple ones when revising models via XIL",
    "checked": true,
    "id": "bc0aef2fbc5b0636b1fb2b7651f25b3b01fdc569",
    "semantic_title": "one explanation does not fit xil",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=xKf-LSD2-Jg": {
    "title": "Fast Adversarial CNN-based Perturbation Attack on No-Reference Image- and Video-Quality Metrics",
    "volume": "tiny",
    "abstract": "Modern neural-network-based no-reference image- and video-quality metrics exhibit performance as high as full-reference metrics. These metrics are widely used to improve visual quality in computer vision methods and compare video processing methods. However, these metrics are not stable to traditional adversarial attacks, which can cause incorrect results. Our goal is to investigate the boundaries of no-reference metrics applicability, and in this paper, we propose a fast adversarial perturbation attack on no-reference quality metrics. The proposed attack (FACPA) can be exploited as a preprocessing step in real-time video processing and compression algorithms. This research can yield insights to further aid in designing of stable neural-network-based no-reference quality metrics",
    "checked": true,
    "id": "faf781129098539d157dda2a20eae1ade26975b5",
    "semantic_title": "fast adversarial cnn-based perturbation attack on no-reference image- and video-quality metrics",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=CuE1F1M0_yR": {
    "title": "GraphEx: A User-Centric Model-Level Explainer for Graph Neural Networks",
    "volume": "tiny",
    "abstract": "With the increasing application of Graph Neural Networks (GNNs) in real-world domains, there is a growing need to understand the decision-making process of these models. To address this, we propose GraphEx, a model-level explainer that learns a graph generative model to approximate the distribution of graphs classified into a target class by the GNN model. Unlike existing methods, GraphEx does not require another black box deep model to explain the GNN and can generate a diverse set of explanation graphs with different node and edge features in one shot. Moreover, GraphEx does not need white box access to the GNN model, making it more accessible to end-users. Experiments on both synthetic and real datasets demonstrate that GraphEx can consistently produce explanations aligned with the class identity and can also identify potential limitations of the GNN model",
    "checked": true,
    "id": "698c211d2d1b1fe37eee8f32b77b44c909e3d466",
    "semantic_title": "graphex: a user-centric model-level explainer for graph neural networks",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=vd16AYbem3Z": {
    "title": "Theta sequences as eligibility traces: A biological solution to credit assignment",
    "volume": "tiny",
    "abstract": "Credit assignment problems, for example policy evaluation in RL, often require bootstrapping prediction errors through preceding states or maintaining temporally extended memory traces; solutions which are unfavourable or implausible for biological networks of neurons. We propose theta sequences -- chains of neural activity during theta oscillations in the hippocampus, thought to represent rapid playthroughs of awake behviour -- as a solution. By analysing and simulating a model for theta sequences we show they compress behaviour such that existing but short $\\mathsf{O}(10)$ ms neuronal memory traces are effectively extended allowing for bootstrap-free credit assignment without long memory traces, equivalent to the use of eligibility traces in TD($\\lambda$)",
    "checked": true,
    "id": "aaa87ff6b97f14dcc472ddb69cee56bfe2f9e687",
    "semantic_title": "theta sequences as eligibility traces: a biological solution to credit assignment",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=mvo72yTjhTl": {
    "title": "Federated Learning with Variational Autoencoders",
    "volume": "tiny",
    "abstract": "In this work we investigate the feasibility of using federated learning to train a variational autoencoder capable of generated handwritten digits when trained on the MNIST dataset. It was found that using federated learning we were able to train a model that produced comparable results to a centralised model, both in image reconstructions and image generations",
    "checked": true,
    "id": "273efb0936a3f88d3b6ef09bea84845b8a39ca29",
    "semantic_title": "federated learning with variational autoencoders",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=AXxBPw5zdl4": {
    "title": "TRACTABLE LARGE SCALE CALIBRATION WITH RL",
    "volume": "tiny",
    "abstract": "In this work we show that Reinforcement Learning (RL) is an effective algorithm for calibration problems at a scale which traditionally applied Bayesian approaches struggle. This work uses synthetic data, so has access to ground truth parameters and it can be seen that RL learns different, arguably better information for different parts of the learning process. These exciting results set the foundation for deeper consideration of RL in this space",
    "checked": true,
    "id": "69692a80c3d7d4cac4f68ef7e2a9550e8057fabd",
    "semantic_title": "tractable large scale calibration with rl",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A2VfgYliIT": {
    "title": "A Variational Condition for Minimal-Residual Latent Representations",
    "volume": "tiny",
    "abstract": "Autoencoders are a useful unsupervised-learning architecture that can be used to build surrogate models of systems governed by partial differential equations, enabling a more cost-effective route to study complex phenomena across science and engineering. In this article, we address two key questions underpinning this procedure: whether the reconstructed output satisfies the partial differential equation, and whether other latent vectors not corresponding to the encoding of any training data satisfy the same equation. Our results spell out some relevant conditions, and clarify the different impact of three main design decisions (architecture, training criterion, and choice of training solutions) on the final result",
    "checked": true,
    "id": "42cb2038131acf858ecb7f4104325d1195901d56",
    "semantic_title": "a variational condition for minimal-residual latent representations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=j1gj0ndrk1": {
    "title": "Attention Based Variational Graph Auto-Encoder (AVGAE)",
    "volume": "tiny",
    "abstract": "Recently techniques such as VGAEs (Variational Graph Autoencoder) are quite popular in the unsupervised task setting and in generative modeling. Unlike conventional autoencoders, which typically use fully-connected layers to learn a latent representation of input data, VGAEs operate on graph-structured data. We propose to incorporate attention in VGAEs (AVGAE) for capturing the relationships better thereby increasing the robustness and generalisability. In a VAE, the encoder network learns to map input data to a lower-dimensional latent space, while the decoder network learns to map latent space vectors back to the original input data. Unlike traditional autoencoders, which typically use a fixed encoding function, VAEs use a probabilistic encoding function that maps input data to a probability distribution over the latent space. They have been shown to improve the quality of the generated output, particularly for tasks where the input data is complex and high-dimensional",
    "checked": true,
    "id": "30093dbbbad888c0231fe369376585a2003ee9ad",
    "semantic_title": "attention based variational graph auto-encoder (avgae)",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=-IH_dcPGWM": {
    "title": "Generative STResnet for Crime Prediction",
    "volume": "tiny",
    "abstract": "In this work, we combine STResnet with VAE to generate crime distribution. The outputs can be used for downstream tasks such as patrol deployment planning",
    "checked": true,
    "id": "b0ae9f182b5d19a30901488a29770db82adbe2f0",
    "semantic_title": "generative stresnet for crime prediction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KtVonyo4AS": {
    "title": "A Light Spectrometer Device for Crop Disease Monitoring",
    "volume": "tiny",
    "abstract": "Portable devices for the early detection of crop diseases are needed to support the farmers working in the field. Spectrometers showed their potential in the detection of crop diseases. However, high interpretation skills are needed to use the currently available spectrometers. In this project, we propose a portable device that obtains a spectrum wavelength of 700 nanometers describing the information of the crop. The output of this tool is integrated into a smartphone in the form of an app, making it accessible for use in the field in real applications",
    "checked": true,
    "id": "8f7ba066b624cc25fd1b74cbf868b5b47fbe1f47",
    "semantic_title": "a light spectrometer device for crop disease monitoring",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jbBPBUGk-4": {
    "title": "Can Arterial Blood Pressure Predict Age? A ConvNet Classification Task",
    "volume": "tiny",
    "abstract": "Blood pressure (BP) increases throughout life, and is controlled by several feedback mechanisms in mammals. Therefore, high resolution BP data may contain information related to the health and functionality of those systems, and the organism as a whole. We used beat-to-beat BP data at different sampling rates collected from a heterogeneous population of rats to predict their age, and achieved 90%+ test accuracy, AUROC, and AUPRC across all sampling rates. Higher frequency components appeared to contribute less to 100 Hz sample rate BP data classification, but nonetheless could point to previously unknown Spectro-temporal patterns that the model identified",
    "checked": true,
    "id": "44d1d02e6ede3fa5a2b1752bda5b7a0456834a44",
    "semantic_title": "can arterial blood pressure predict age? a convnet classification task",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IkHVGw_Ipu": {
    "title": "Pay Attention to Multi-Channel for Improving Graph Neural Networks",
    "volume": "tiny",
    "abstract": "We propose Multi-channel Graph Attention (MGAT) to efficiently handle channel-specific representations encoded by convolutional kernels, enhancing the incorporation of attention with graph convolutional network (GCN)-based architectures. Our experiments demonstrate the effectiveness of integrating our proposed MGAT with various spatial-temporal GCN models for improving prediction performance",
    "checked": true,
    "id": "42f5a5b14118c446ad6a845f6ed49841cb6bf7e6",
    "semantic_title": "pay attention to multi-channel for improving graph neural networks",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=8kX0btdpAU5": {
    "title": "pGS-CAM: Interpretable LiDAR Point Cloud Semantic Segmentation via Gradient Based Localization",
    "volume": "tiny",
    "abstract": "To extract the local information required for effective semantic segmentation of point clouds, a number of deep learning architectures typically make use of sophisticated feature extractors. Unfortunately, there has not been a lot of discussion on how to interpret their forecasts, which is essential if deployed in real-world settings. To that end, we propose pGS-CAM (point cloud Grad-Seg-CAM), a quick and effective gradient-based method for class activation mapping in point cloud semantic segmentation architectures. To gain insight into what each intermediate layer of the architecture does, our technique provides a heatmap for the corresponding layer. We use the popular semantic segmentation architecture (RandLA-Net) and a commonly used MLS dataset (SemanticKITTI) for our experimentation",
    "checked": true,
    "id": "490e05f0a13dab3cd8c670c9ff9a8ee60ee939e6",
    "semantic_title": "pgs-cam: interpretable lidar point cloud semantic segmentation via gradient based localization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N0lQfjeNWOE": {
    "title": "Large Language Models Perform Diagnostic Reasoning",
    "volume": "tiny",
    "abstract": "We explore the extension of chain-of-thought (CoT) prompting to medical reasoning for the task of automatic diagnosis. Motivated by doctors' underlying reasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical results demonstrate that by simply prompting large language models trained only on general text corpus with two DR-CoT exemplars, the diagnostic accuracy improves by 15% comparing to standard prompting. Moreover, the gap reaches a pronounced 18% in out-domain settings. Our findings suggest expert-knowledge reasoning in large language models can be elicited through proper promptings",
    "checked": true,
    "id": "4a5af57b2056c4cc0a768d830d5427f0d1bdae33",
    "semantic_title": "large language models perform diagnostic reasoning",
    "citation_count": 23,
    "authors": []
  },
  "https://openreview.net/forum?id=WaAJ883AqiY": {
    "title": "A Simple Loss Function for Convergent Algorithm Synthesis using RNNs",
    "volume": "tiny",
    "abstract": "Running a Recurrent Neural Network (RNN) over the same input multiple times, or iterative reasoning, enables logical extrapolation, where a model can be run on problems larger than the models were trained on. The loss function used to train these networks has a profound impact on their extrapolation ability. In this paper, we propose using a simple loss function called the Delta Loss (Salle & Prates, 2019). We show that the Delta Loss, like the state-of-the-art Progressive Loss (Bansal et al., 2022), leads to convergent algorithm synthesis, but with a simpler formulation, increased training efficiency, and greater robustness",
    "checked": true,
    "id": "9714919fd9afd7cd5e1b028c935bd5e53fec6b15",
    "semantic_title": "a simple loss function for convergent algorithm synthesis using rnns",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=zEGstYVHBt": {
    "title": "The Obscure Limitation of Modular Multilingual Language Models",
    "volume": "tiny",
    "abstract": "We expose the limitation of modular multilingual language models (MLMs) in multilingual inference scenarios with unknown languages. Existing evaluations of modular MLMs exclude the involvement of language identification (LID) modules, which obscures the performance of real-case multilingual scenarios of modular MLMs. In this work, we showcase the effect of adding LID on the multilingual evaluation of modular MLMs and provide discussions for closing the performance gap of caused by the pipelined approach of LID and modular MLMs",
    "checked": true,
    "id": "588ffe65a9a1e4147d8c8bbb2b53cbbb787eaa2d",
    "semantic_title": "the obscure limitation of modular multilingual language models",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=zdhCATDn_Q": {
    "title": "Exploratory Analysis of Scholarly Publications on Artificial Intelligence (AI) in Colonoscopy using Litstudy",
    "volume": "tiny",
    "abstract": "Due to the large number of scholarly papers on AI and colonoscopy and the short research period, it can be difficult to answer general questions about the research area, such as who the key authors are and what the key issues or insights are. We use Litstudy, a Python library, to study colonoscopy AI research. \"AI\" and \"colonoscopy\" keywords were used as search results. 3865 IEEE Xplore and 2007 Springer bibliographies were downloaded. Scopus found 5083 citation papers, excluding 789 unavailable citations. Topic clusters were created using the NMF model with a 0.85 threshold. Topic clouds showed that \"Patient\" occurred most in four topics: 2, 3, 7, and 10. Despite querying IEEE, Springer, and Scopus databases with the \"Artificial Intelligence\" keyword, subject 5 with AI has the lowest topic phrase weight in topic clouds. Topic 10 words cluster on colon cancer rehabilitation in colonoscopy showed weak topic clusters. The project selects scientific articles, analyses and visualises their scholarly contribution using natural language processing (NLP), bibliographic network analysis, and, most importantly, reveals word clusters in AI for colonoscopy publications",
    "checked": true,
    "id": "e2f15c41080565247296c15d0d36a317a43234bb",
    "semantic_title": "exploratory analysis of scholarly publications on artificial intelligence (ai) in colonoscopy using litstudy",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RR_w2fbYmV": {
    "title": "Propagate Deeper and Adaptive Graph Convolutional Networks",
    "volume": "tiny",
    "abstract": "Graph Convolutional Networks (GCNs) are the basic architecture for handling graph-structured data. Deeper GCNs are required for large and sparse graph data. As the number of layers increases, the performance of GCNs degrades, which is commonly attributed to over-smoothing but is constantly debated. In this paper, we eliminate the equivalence between model degradation and over-smoothing or gradient vanishing and propose a systematic solution, an Adaptive DeepGCN (ADGCN) architecture, which makes the model the potential to address all issues. We place learnable parameters at the appropriate locations to make adaptive adjustments to different graph-structured data. We conduct experiments on real-world datasets to verify the stability and adaptability of our architecture",
    "checked": true,
    "id": "9fc710f15dfe8734521f1ae139a704b821602322",
    "semantic_title": "propagate deeper and adaptive graph convolutional networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qW_GZYyn7C": {
    "title": "L2 Norm Guided Adaptive Computation",
    "volume": "tiny",
    "abstract": "Although the human brain can adjust the amount of time and energy it uses to solve problems of varying complexity, many standard neural networks require a fixed computation budget regardless of the problem's complexity. This work introduces L2 Adaptive Computation (LAC), a new algorithm that adjusts the computation budget, by tracking changes in the L2 norm of a neural network's hidden state as layers are applied to the input. Unlike previous methods, LAC does not require additional trainable modules or auxiliary loss terms to make halting decisions. LAC matches the results of best-performing methods on a complex synthetic task and improves image classification accuracy while also increasing efficiency",
    "checked": true,
    "id": "086a3a0a7d3ec2b717f9cc447fdd86344345d0f2",
    "semantic_title": "l2 norm guided adaptive computation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=nazr0QFvHR": {
    "title": "Efficient Temporal Denoising for Improved Depth Map Applications",
    "volume": "tiny",
    "abstract": "Depth estimation involves acquiring three-dimensional information from images, which has numerous applications in downstream tasks. Although several effective monocular depth estimation algorithms have been developed, directly applying frame-by-frame depth estimation can result in flickering, which hinders many video-related applications. Previous video-based approaches have primarily been post-processing methods that utilize spatial information about camera poses to reduce flicker, but they come with a considerable computational cost. In this paper, we introduce the concept of depth map noise to better understand flicker in depth maps and propose a depth noise smoothing network to eliminate visual flicker in depth maps. Our approach can be applied to different depth estimation models and run in real-time for screen-based applications, such as video bokeh",
    "checked": true,
    "id": "5a9c2de5bd177d49d0cb8f40d8c5944a4f7fe0fc",
    "semantic_title": "efficient temporal denoising for improved depth map applications",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=QRKKFN7FLm": {
    "title": "AI-based opportunistic analysis of the CT images during COVID (2021): Does living in a metropolitan area affect the vertebral body mineral density in older people?",
    "volume": "tiny",
    "abstract": "The aim of the study is to reveal the problems of using information on several territorial units (districts) of an integral urban agglomeration for an identification of interdimensional peculiarities of living in a particular area by estimating vertebral bone mineral density in Moscow residents aged 50 and older. The results of this study will provide hypothesis testing for a pilot project to create a model of spatial exposure to the urban environment (Computer Vision Experiment; Clinical Trial: NCT04489992), which will form the basis of identifying individuals (groups of individuals) at risk of \"accelerated\" occupational aging and musculoskeletal diseases",
    "checked": true,
    "id": "af5d90a97b33e9c0278f88639baaf1107d786624",
    "semantic_title": "ai-based opportunistic analysis of the ct images during covid (2021): does living in a metropolitan area affect the vertebral body mineral density in older people?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1PW_txDkX7": {
    "title": "One Student Knows All Experts Know: From Sparse to Dense",
    "volume": "tiny",
    "abstract": "Human education system trains one student by multiple experts. Mixture-of-experts (MoE) is a powerful sparse architecture including multiple experts. However, sparse MoE model is easy to overfit, hard to deploy, and not hardware-friendly for practitioners. In this work, inspired by the human education model, we propose a novel task, knowledge integration, to obtain a dense student model (OneS) as knowledgeable as one sparse MoE. We investigate this task by exploring 4 different ways to gather knowledge from MoE to initialize a dense student model, and we then refine the dense student by knowledge distillation. We evaluate our model on both vision and language tasks. Experimental results show, with $3.7 \\times$ inference speedup, the dense student can still preserve $88.2\\%$ benefits from MoE counterpart",
    "checked": true,
    "id": "9caa83288602f6c3734c78d8d89bb358b263da24",
    "semantic_title": "one student knows all experts know: from sparse to dense",
    "citation_count": 22,
    "authors": []
  },
  "https://openreview.net/forum?id=WkDqZD3VRo": {
    "title": "AN ENSEMBLE LEARNING FRAMEWORK FOR VISIBILITY PREDICTION IN INDO-GANGETIC REGION",
    "volume": "tiny",
    "abstract": "Visibility of an area affects all forms of transportation such as sea, surface and aviation which can further affect the economy of that area. Thus it is very important to accurately estimate the visibility of an area for the upcoming days based on different parameters of the past meteorological data, so that we can take precautions in case of poor visibility. Several machine learning techniques have been already applied on different kinds of data sets to estimate the visibility. However, most of these methods could not perform reasonably well and none of them were applied on the meteorological data of the Indo-Gangetic plane in India, which witnesses widespread fog primarily during winter that badly impacts visibility and therefore transportation. In this spirit, a Extreme Gradient Boosting (XGboost) based regression framework is developed here to estimate the visibility of the Indo-Gangetic plane. The method identifies significant parameters of the data following different standard feature engineering schemes and subsequently implement the XGboost regression model. The experimental results show that the proposed framework outperforms the state of the arts in terms of mean absolute error (MAE) and root mean squared error (RMSE). In future, the aim is to explore the performance of this framework to estimate the visibility of other crucial areas across globe",
    "checked": true,
    "id": "626376ef75e3e6acc0a47a65acfa324b8d23e93d",
    "semantic_title": "an ensemble learning framework for visibility prediction in indo-gangetic region",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fcQFbluDTX": {
    "title": "Evolutionary Federated Learning Using Particle Swarm Optimization",
    "volume": "tiny",
    "abstract": "Efficient communication is a key challenge in federated learning, where multiple clients contribute to a shared model. To address this issue, reducing local computation is an effective solution. This paper proposes an innovative federated learning algorithm that utilizes Particle Swarm Optimization, a powerful evolutionary algorithm, to minimize the computational demands on federated learning clients. Our results show that this algorithm results in significant enhancements in accuracy and faster convergence of loss compared to traditional federated learning methods",
    "checked": true,
    "id": "fc40d2fa2776866781702d14b114264782c0b220",
    "semantic_title": "evolutionary federated learning using particle swarm optimization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0GpMf9UeI3G": {
    "title": "Understanding the Effectiveness of Cross-Domain Contrastive Unsupervised Domain Adaptation",
    "volume": "tiny",
    "abstract": "Unsupervised domain adaptation helps to transfer learned tasks from a source to a target domain in the lack of labeled data. Recently, contrastive learning showed promising results on this setup. However, there are limitations on the performance due to unbalanced objectives between the self-representation and the adaptation tasks. We show that pre-training choices and hard negative mining provide consistent improvements to successfully pair contrastive learning and unsupervised domain adaptation",
    "checked": true,
    "id": "f27afd602cf2213a59b7791e92bd23b4b891ece7",
    "semantic_title": "understanding the effectiveness of cross-domain contrastive unsupervised domain adaptation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A-E41oZCfrf": {
    "title": "Performance Evaluation of Enhanced ConvNeXtTiny-based Fire Detection System in Real-world Scenarios",
    "volume": "tiny",
    "abstract": "Timely detection of fires is crucial for saving human lives and minimizing the economic and ecological impact of such incidents. Although numerous attempts have been made to identify a fire in its early stage, significant challenges remain in achieving accurate and reliable detection. Therefore, we proposed a modified pre-trained ConvNeXtTiny architecture for detecting fire, offering high detection accuracy and fast inference time compared to other alternatives over benchmarks. Our source code of the paper will be publicly available at https://github.com/TaimoorKhan561/ICLR_Source",
    "checked": true,
    "id": "6ef512c1d99f16f4ed17556b576ea28ff06b8309",
    "semantic_title": "performance evaluation of enhanced convnexttiny-based fire detection system in real-world scenarios",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=zZjPRz0EX5T": {
    "title": "Robustness Evaluation of Multi-Agent Reinforcement Learning Algorithms using GNAs",
    "volume": "tiny",
    "abstract": "Recently, multi-agent reinforcement learning (MARL) has shown its ability in solving sequential decision-making problems in complicated multi-agent environments. However, uncertainties from observations and executions undermine its performance when MARL methods are deployed in real-world applications. While crucial for deployment, a systematic robustness evaluation for MARL algorithms is not present. In this work, we utilize Gaussian noise attacks (GNAs) to examine the robustness of a benchmark MARL algorithm: multi-agent deep deterministic policy gradient (MADDPG). To the best of our knowledge, our work is the first to investigate the robustness of MADDPG to GNAs to observation and execution information. Our experiments show that GNA has totally different patterns in observation-wise attacks and execution-wise attacks. Furthermore, there are counter-intuitive insights from the experimental results which could guide researchers in future MARL methods development",
    "checked": true,
    "id": "b1cb0df83b4b3e1972a7f5183906eca70cbd1f80",
    "semantic_title": "robustness evaluation of multi-agent reinforcement learning algorithms using gnas",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PjypHLTo29v": {
    "title": "State Advantage Weighting for Offline RL",
    "volume": "tiny",
    "abstract": "We present \\textit{state advantage weighting} for offline reinforcement learning (RL). In contrast to action advantage $A(s,a)$ that we commonly adopt in QSA learning, we leverage state advantage $A(s,s^\\prime)$ and QSS learning for offline RL, hence decoupling the action from values. We expect the agent can get to the high-reward state and the action is determined by how the agent can get to that corresponding state. Experiments on D4RL datasets show that our proposed method can achieve remarkable performance against the common baselines. Our code is publicly available in https://github.com/dmksjfl/SAW",
    "checked": true,
    "id": "73bfe561d9ed870e4564dd82671a4b8d68af7840",
    "semantic_title": "state advantage weighting for offline rl",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=6I5i0Ytnlul": {
    "title": "Towards Robust Feature Learning with t-vFM Similarity for Continual Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "b580a564e1f1f6e859236e661bbe7e2299f52452",
    "semantic_title": "towards robust feature learning with t-vfm similarity for continual learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=28si4RXwDt1": {
    "title": "When Biology has Chemistry: Solubility And Drug Subcategory Prediction using SMILES Strings",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "8ff0ee656fd05fe96226f7637485124ebbef0beb",
    "semantic_title": "when biology has chemistry: solubility and drug subcategory prediction using smiles strings",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=D2lo4toTUTo": {
    "title": "Answering Questions Over Knowledge Graphs Using Logic Programming Along with Language Models",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "f6341a2657b42ce923068f22347b29d44eec9224",
    "semantic_title": "answering questions over knowledge graphs using logic programming along with language models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=ZTp85mW5nFy": {
    "title": "Contrastive Training with more data",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "2055ccd904cf57e46c777576060fe2470cc2cc19",
    "semantic_title": "contrastive training with more data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GSlYBJ3aOpC": {
    "title": "Statistical Methods for Auditing the Quality of Manual Content Reviews",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "2a9827acf69e8eb254b98fe539a3a9d4602c3b10",
    "semantic_title": "statistical methods for auditing the quality of manual content reviews",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TqkzImZ92t8": {
    "title": "ARTIFICIAL PSYCHOLOGY",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "e006b3396ec1a806bf75c06dc53ccd5c176934cf",
    "semantic_title": "artificial psychology",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=87oCobKKS6x": {
    "title": "Automated Mapping of Healthcare Concepts to a Standardized Healthcare Taxonomy",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "ec718830e0ebbe8e5103bcd28e8bc11d1bafabc1",
    "semantic_title": "automated mapping of healthcare concepts to a standardized healthcare taxonomy",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=frB4MiYGoD_": {
    "title": "RepFair-GAN: Mitigating Representation Bias in GANs Using Gradient Clipping",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "2d69f026f76ab9ee9e609ef888e19bb8498f61b9",
    "semantic_title": "repfair-gan: mitigating representation bias in gans using gradient clipping",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=p7sHcNt_tqo": {
    "title": "Prior knowledge meets Neural ODEs: a two-stage training method for improved explainability",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "6cbb1db6d05afcc4e4e9f5337cddd235b7a3af47",
    "semantic_title": "prior knowledge meets neural odes: a two-stage training method for improved explainability",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=udl9OobOxZu": {
    "title": "Self-Supervised Continual Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "341fba4c3d0b9c86aaf24b0c1d0a754c4b8a6ee9",
    "semantic_title": "self-supervised continual learning",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=MuOFB0LQKcy": {
    "title": "When Spiking Neural Networks Meet Temporal Attention Image Decoding and Adaptive Spiking Neuron",
    "volume": "tiny",
    "abstract": "",
    "checked": false,
    "id": "13c9f89b5f22bcb54d7ead397538fa556a0c45d3",
    "semantic_title": "exploring methods for efficient learning in neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HM_jOWEYL7y": {
    "title": "Characters Are Like Faces",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "f22da03da1a2993fff337c2e25535de59eb47110",
    "semantic_title": "characters are like faces",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uwbyW92Sonu": {
    "title": "A Scalable Self-supervised Learner for Hyperspectral Image Classification",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "cf05d3b0ecc8c63ea20dc5c8bc05e710a5a8b701",
    "semantic_title": "a scalable self-supervised learner for hyperspectral image classification",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=B5riBS9HZGn": {
    "title": "Optimizing MPJPE promotes miscalibration in multi-hypothesis human pose lifting",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "526d50af80bf9c2b02e63e07e0cf2961864e8e98",
    "semantic_title": "optimizing mpjpe promotes miscalibration in multi-hypothesis human pose lifting",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Tbzv_BbjjO8": {
    "title": "Unsupervised Detection of Cell Assemblies with Graph Neural Networks",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "b9fc61a617dfa8c7a8511b1b140e058609067f24",
    "semantic_title": "unsupervised detection of cell assemblies with graph neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wFxjFCHUkS": {
    "title": "Heat Up The Sentiment Learning With ICE",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "2a9a4249cdba97e273d328249e2fb5ea6bfdebc8",
    "semantic_title": "heat up the sentiment learning with ice",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IcDTYTI0Nx": {
    "title": "Almost Sure Last Iterate Convergence of Sharpness-Aware Minimization",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "1a662d260a50e6cf25f09721ba91401a7692a31e",
    "semantic_title": "almost sure last iterate convergence of sharpness-aware minimization",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=WKVH54a1W4": {
    "title": "On the application and impact of ε-DP and fairness in ambulance engagement time prediction",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "9307a862112f6f805e8b4d44fa7c8388fd624893",
    "semantic_title": "on the application and impact of ε-dp and fairness in ambulance engagement time prediction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5-ROmmBJKV": {
    "title": "Adversarial Policy Gradient for Learning Graph-Based Representation in Human Visual Processing",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "ecf023690c1df8327defc87210223ff50fd35fd2",
    "semantic_title": "adversarial policy gradient for learning graph-based representation in human visual processing",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qX8cGLnfAd": {
    "title": "Federated Learning for Local and Global Data Distribution",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "a710ba9176c67e6fd71a9e4ade8ead574e0fc2fb",
    "semantic_title": "federated learning for local and global data distribution",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rLqN6XLbON": {
    "title": "Is DFR for Soft Biometrics Prediction in Unconstrained Images Fair and Effective?",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "edc9eaf79940639ce9f0d1510de86af96fac452a",
    "semantic_title": "is dfr for soft biometrics prediction in unconstrained images fair and effective?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1WEPXTIjAd": {
    "title": "INTEGRATING INFORMATION FROM NATURAL LANGUAGE PARSE TREE TO CODE GENERATION",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "3e26d16ab4c5126877a8ee7228a5a4944aec452d",
    "semantic_title": "integrating information from natural language parse tree to code generation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=-CH1C-aQ5pk": {
    "title": "Pseudo Labels for Single Positive Multi-Label Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "52d4ef25794c2a25729b37d53e2410a2dbe2fac3",
    "semantic_title": "pseudo labels for single positive multi-label learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=osqgjMNm4_": {
    "title": "Drowning Detection based on YOLOv8 improved by GP-GAN Augmentation",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "9c7e46693677cc2cf36f64b06ac2176129bbc1a7",
    "semantic_title": "drowning detection based on yolov8 improved by gp-gan augmentation",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=eaKoBpxCPe": {
    "title": "Beyond Negativity: Re-Analysis and Follow-Up Experiments on Hope Speech Detection",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "d05f8896dc4024ab72d78303455b92399035d5e2",
    "semantic_title": "beyond negativity: re-analysis and follow-up experiments on hope speech detection",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=niyvAOOnwPM": {
    "title": "Group Equivariant Convolutional Networks",
    "volume": "tiny",
    "abstract": "",
    "checked": false,
    "id": "cd731f6ae47458ff140e2d09087d587a89de161c",
    "semantic_title": "study of group equivariant convolutional networks for image classification",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=2Z-dQTRezZ": {
    "title": "Exploring Semantic Variations in GAN Latent Spaces via Matrix Factorization",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "143f8ee84d2387493293eb3c90164ded38fb3efb",
    "semantic_title": "exploring semantic variations in gan latent spaces via matrix factorization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iSkcAjBqUHU": {
    "title": "The Polarised Regime of identifiable Variational Autoencoders",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "4468225f2c8ab4651fef9f6857bd463b85b6904d",
    "semantic_title": "the polarised regime of identifiable variational autoencoders",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=91Bcj6sgcxt": {
    "title": "Uni-Match: A Semantic Unified Model for Query-Product Retrieval",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "440272069e50b7fc367f352abca31f847628aa4f",
    "semantic_title": "uni-match: a semantic unified model for query-product retrieval",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Peb3QdR8zzP": {
    "title": "Hierarchical Dialogue Understanding with Special Tokens and Turn-level Attention",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "1120e598f49a2a1967b11443d459f91dfd3c1d07",
    "semantic_title": "hierarchical dialogue understanding with special tokens and turn-level attention",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=ZCv4E1unfJP": {
    "title": "Large Sparse Kernels for Federated Learning",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "eaced23d57380ee4fe23c7dcd6dec8363167a2ed",
    "semantic_title": "large sparse kernels for federated learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=WFatA9XIQ0m": {
    "title": "Using vision transformer-based GANs against Vision Transformers",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "3b3f3ff503499a4cd73fca99921119f36a0192f2",
    "semantic_title": "using vision transformer-based gans against vision transformers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PaHmtktx86H": {
    "title": "Pivot Pre-finetuning for Low Resource MT: A Case Study in Kikamba",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "91e762b651a75fc0939db0555e69e9af7e3398cc",
    "semantic_title": "pivot pre-finetuning for low resource mt: a case study in kikamba",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WU3veNUvvU": {
    "title": "Unsupervised Learning for Anomaly Detection: A Comparison of Deep Generative Models",
    "volume": "tiny",
    "abstract": "",
    "checked": true,
    "id": "c9f1f3fccc3d9addd98adea5124ce6d1bbeb454b",
    "semantic_title": "unsupervised learning for anomaly detection: a comparison of deep generative models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U4o5iSWSaD": {
    "title": "Bayes classifier cannot be learned from noisy responses with unknown noise rates",
    "volume": "tiny",
    "abstract": "Training a classifier with noisy labels typically requires the learner to specify the distribution of label noise, which is often unknown in practice. Although there have been some recent attempts to relax that requirement, we show that the Bayes decision rule is unidentified in most classification problems with noisy labels. This suggests it is generally not possible to bypass/relax the requirement. In the special cases in which the Bayes decision rule is identified, we develop a simple algorithm to learn the Bayes decision rule, that does not require knowledge of the noise distribution",
    "checked": true,
    "id": "f417d8280f77bc712cef6a002b588e40bba09738",
    "semantic_title": "bayes classifier cannot be learned from noisy responses with unknown noise rates",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ChW0YYRIni": {
    "title": "Contrastive Learning with 3D Shapes",
    "volume": "tiny",
    "abstract": "In fields such as Computer Vision or NLP, there is a large amount of data available which, however, cannot be labeled, as it would be very expensive. A possible solution to this problem is Contrastive Learning, a Self-Supervised technique. This work aims to implement a contrastive learning regime for a non-Euclidean data type, more precisely 3D Point Cloud Shape",
    "checked": true,
    "id": "83fc90e46a40d2066b4e2d9b86078462eecd7442",
    "semantic_title": "contrastive learning with 3d shapes",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ihzsru2bw2": {
    "title": "Adaptive-saturated RNN: Remember more with less instability",
    "volume": "tiny",
    "abstract": "Orthogonal parameterization is a compelling solution to the vanishing gradient problem (VGP) in recurrent neural networks (RNNs). With orthogonal parameters and non-saturated activation functions, gradients in such models are constrained to unit norms. On the other hand, although the traditional vanilla RNNs are seen to have higher memory capacity, they suffer from the VGP and perform badly in many applications. This work proposes Adaptive-Saturated RNNs (asRNN), a variant that dynamically adjusts its saturation level between the two mentioned approaches. Consequently, asRNN enjoys both the capacity of a vanilla RNN and the training stability of orthogonal RNNs. Our experiments show encouraging results of asRNN on challenging sequence learning benchmarks compared to several strong competitors. The research code is accessible at https://github.com/ndminhkhoi46/asRNN/",
    "checked": true,
    "id": "7bbdbf93946cb6e337bf749bc8013717ffa09b9c",
    "semantic_title": "adaptive-saturated rnn: remember more with less instability",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=pKd6q-FrprW": {
    "title": "Stratospheric Aerosols: Establishing a Novel Optical Thickness Benchmark for Effective Climate Change Mitigation",
    "volume": "tiny",
    "abstract": "Global Warming has been a problem at the heart of Earth's environmental issues for nearly 5 decades, with the potential to affect a significant portion of the global population and cause catastrophic irreversible damage to the planet's future. Changes in Earth's climate due to the rise in global temperatures will have an enormous impact on communities around the world, along with a drastic displacement of humans and an extreme loss in natural biodiversity. Current methods of combating this issue have proven to be ineffective, requiring a more comprehensive and innovative approach. This project aims to propose a potential solution to mitigate the effects of global warming and limit temperatures to sustainable levels through the use of stratospheric aerosols. Through a process of data collection, experimentation, and modeling, I was able to correlate the presence of aerosols in the stratosphere to a consequent drop in temperatures and utilize regression prediction to forecast a 16 percent drop in global temperatures after examining the effects of volcanic ash in the stratosphere. I was also able to compare monthly aerosol concentration levels to declines in the growth of temperatures and conclude that by keeping aerosol optical thickness over 0.185, we can stabilize global temperatures and achieve climate change goals set to protect the Earth. By implementing the changes to Earth's atmosphere, we can reflect heat from the Sun and create a cooling effect for the planet, potentially stopping climate change and saving billions of people",
    "checked": true,
    "id": "0aeef56e8a6ca4d7cad011f3ff6aea46c09a3d61",
    "semantic_title": "stratospheric aerosols: establishing a novel optical thickness benchmark for effective climate change mitigation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cKLmwCTFiI": {
    "title": "CausalStructCodec: Causally-aware observational and interventional data generator",
    "volume": "tiny",
    "abstract": "Over the last few years, causal generative models have massively gained popularity. Their main goal is to generate observational, interventional and counterfactual data. They are also interesting for causal discovery or fair Machine Learning. These generators are based on typical data generation architecture, such as VAEs, GANs or normalizing flows. However, a recent data generation architecture, the Codecs, is more computationally efficient and allows for complex data generation. In this work, we introduce the CausalStructCodecs (CSC), a novel causally-aware architecture based on a specific kind of codec, the StructCodec. We show that results for non-complex data are level with state-of-the-art models for observational and interventional data generation, in significantly fewer epochs",
    "checked": true,
    "id": "39103d826e66c0726cbd2506a509daa740776876",
    "semantic_title": "causalstructcodec: causally-aware observational and interventional data generator",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bRI_3OFg4o": {
    "title": "Semantic Similarity Based Label Augmentation for Visual Classification",
    "volume": "tiny",
    "abstract": "Real-world applications may present visual categories for which examples are many but a definition is elusive. When data augmentation helps little and hand-crafted heuristics fail to warrant weak supervision, similarity remains a simple but effective guide for augmenting training labels. This paper showcases, for recognizing clutters in e-commerce photography, how similarity between visual representations pre-trained to capture semantics provides quality supervision. Our approach significantly improves on the label propagation baseline, with classification precision and recall above 0.8 in most cases",
    "checked": true,
    "id": "4960d777f7cf8061d07b1e1427592bba173826e0",
    "semantic_title": "semantic similarity based label augmentation for visual classification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3EfxJTp_-Cj": {
    "title": "Prompt Engineering and Calibration for Zero-Shot Commonsense Reasoning",
    "volume": "tiny",
    "abstract": "Prompt engineering and calibration make large language models excel at reasoning tasks, including multiple choice commonsense reasoning. From a practical perspective, we investigate and evaluate these strategies on smaller language models. Through experiments on five commonsense reasoning benchmarks, we find calibration favors GPT-2 and T5, prompt engineering favors Flan-T5, but their joint effects are mostly negative",
    "checked": true,
    "id": "f2fa1b3dab4441dd48c2fd0ffe865157bd220993",
    "semantic_title": "prompt engineering and calibration for zero-shot commonsense reasoning",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=nbqO93YTz-": {
    "title": "Fidelity of Interpretability Methods and Perturbation Artifacts in Neural Networks",
    "volume": "tiny",
    "abstract": "Despite excellent performance of deep neural networks (DNNs) in image classification, detection, and prediction, characterizing how DNNs make a given decision remains an open problem, resulting in a number of interpretability methods. Post-hoc interpretability methods primarily aim to quantify the importance of input features with respect to the class probabilities. However, due to the lack of ground truth and the existence of interpretability methods with diverse operating characteristics, evaluating these methods is a crucial challenge. A popular approach to evaluate interpretability methods is to perturb input features deemed important for a given prediction and observe the decrease in accuracy. However, perturbation itself may introduce artifacts. We propose a method for estimating the impact of such artifacts on the fidelity estimation by utilizing model accuracy curves from perturbing input features according to the Most Import First (MIF) and Least Import First (LIF) orders. Using the ResNet-50 trained on the ImageNet, we demonstrate the proposed fidelity estimation of four popular post-hoc interpretability methods",
    "checked": true,
    "id": "ccd7a48ae6b279fa531ad721b223bd3ba86c8db6",
    "semantic_title": "fidelity of interpretability methods and perturbation artifacts in neural networks",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=EVz_vcZQvvg": {
    "title": "EDCDE - Extended Discovery of Closed-Form Differential Equations",
    "volume": "tiny",
    "abstract": "Understanding the mathematical connections between variables in a physical system, such as Ordinary Differential Equations (ODEs) is an essential part of the scientific method. This is where symbolic regression plays a key role in looking for closed-form functions given a dataset. We extend the results of the original Discovering Closed-Form ODEs from Observed Trajectories (D-CODE) by considering a generalized variational formulation that can work with most forms of ODEs. We conclude the paper with numerical results and applications",
    "checked": true,
    "id": "1cc561220f836155dbd5f375fbc9836dcd085c28",
    "semantic_title": "edcde - extended discovery of closed-form differential equations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AFLNyWMg4D2": {
    "title": "Synthetic Controls as Balancing Scores",
    "volume": "tiny",
    "abstract": "We outline the factors under which conditioning on Synthetic Control (SC) weights emulates a randomized control trial where the treatment status is independent of potential outcomes. Specifically, we demonstrate that if there exist SC weights such that the treatment effects are exactly identified, and these weights are uniformly and cumulatively bounded, then SC weights are balancing scores",
    "checked": true,
    "id": "b633b34d111f92b14a53d89ff20ce8d424b18f8f",
    "semantic_title": "synthetic controls as balancing scores",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qPwZouq5sY_": {
    "title": "Clustered Federated Learning with Slightly Skewed Labels",
    "volume": "tiny",
    "abstract": "Clustered federated learning methods are proposed to realize the personalization of federated learning. The core of these methods is KMeans while it cannot identify sample from which cluster under slight non-IID data distribution. This paper proposed Gaussian mixture cluster (GMCFL) to measure the probability and uncertainty of that samples belongs to which clusters. This method efficiently aggregated the model parameters between clusters and were robust to non-IID data distribution as well. The empirical results demonstrated our method had better performance than other state-of-the art clustered federated learning methods",
    "checked": true,
    "id": "017566e89a56fc925d5f473de81677f37aeba143",
    "semantic_title": "clustered federated learning with slightly skewed labels",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Jx44OPxLZ2-": {
    "title": "Fusing 3D-CNN and lightweight Swin Transformer networks for HSI",
    "volume": "tiny",
    "abstract": "Recently deep learning has occupied an important position in hyperspectral image (HSI) classification. In this study, we explore the advantages of using convolutional neural networks (CNN) for feature extraction and fusing an advanced shift-window (swin) transformer network based on the transformer model for HSI classification. The swin transformer network attention perception, capable of learning local and global features, can avoid the dependence on single features during HSI classification. The experiments show that our proposed model outperforms traditional machine learning models, and achieves competitive results with advanced models",
    "checked": true,
    "id": "e2416167163ff1457fde7cc8103282ea7bc2ba60",
    "semantic_title": "fusing 3d-cnn and lightweight swin transformer networks for hsi",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=_3_VZtMkvMB": {
    "title": "Compound Tokens: Channel Fusion for Vision-Language Representation Learning",
    "volume": "tiny",
    "abstract": "We present an effective method for fusing visual-and-language representations for several question answering tasks including visual question answering and visual entailment. In contrast to prior works that concatenate unimodal representations or use only cross-attention, we compose multimodal representations via channel fusion. By fusing on the channels, the model is able to more effectively align the tokens compared to standard methods. These multimodal representations, which we call compound tokens are generated with cross-attention transformer layers. We demonstrate the effectiveness of compound tokens using an encoder-decoder vision-language model trained end-to-end in the open-vocabulary setting. Compound Tokens achieve highly competitive performance across a range of question answering tasks including GQA, VQA2.0, and SNLI-VE",
    "checked": true,
    "id": "060e9189c7baf3d02f75688e3b30d7fff10ab78a",
    "semantic_title": "compound tokens: channel fusion for vision-language representation learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=99Go96dla5y": {
    "title": "Message-passing Selection: Towards Interpretable GNNs for Graph Classification",
    "volume": "tiny",
    "abstract": "In this paper, we strive to develop an interpretable GNNs' inference paradigm, termed MSInterpreter, which can serve as a plug-and-play scheme readily applicable to various GNNs' baselines. Unlike the most existing explanation methods, MSInterpreter provides a Message-passing Selection scheme(MSScheme) to select the critical paths for GNNs' message aggregations, which aims at reaching the self-explaination instead of post-hoc explanations. In detail, the elaborate MSScheme is designed to calculate weight factors of message aggregation paths by considering the vanilla structure and node embedding components, where the structure base aims at weight factors among node-induced substructures; on the other hand, the node embedding base focuses on weight factors via node embeddings obtained by one-layer GNN.Finally, we demonstrate the effectiveness of our approach on graph classification benchmarks",
    "checked": true,
    "id": "617bff50277c442fa895611f8f2b97e6ab0d3f30",
    "semantic_title": "message-passing selection: towards interpretable gnns for graph classification",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=OaZktJBVpUy": {
    "title": "MULTI-AGENT REINFORCEMENT LEARNING FOR COALITIONAL BARGAINING GAMES",
    "volume": "tiny",
    "abstract": "In recent years, there has been growing attention to the application of MARL to coalition formation problems, in particular, on coalitional bargaining games as a means of negotiation. However, the lack of theoretical principles for using MARL in coalitional bargaining games remain less explored. This paper aims to address this gap by providing an examination of the theoretical link between coalition formation, coalitional bargaining games, and MARL through the link of stochastic games. Through this analysis, the paper seeks to shed light on the underlying principles that support the use of MARL in coalitional bargaining and to explore the contributions of this approach and its limitations in comparison to traditional game theoretical methods",
    "checked": true,
    "id": "65145dcf3d5e23a579f813d7eabfc9c1d63e90cf",
    "semantic_title": "multi-agent reinforcement learning for coalitional bargaining games",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ChqP6ORFYK6": {
    "title": "Astroformer: More Data might not be all you need for Classification",
    "volume": "tiny",
    "abstract": "Recent advancements in areas such as natural language processing and computer vision rely on intricate and massive models that have been trained using vast amounts of unlabelled or partly labeled data and training or deploying these state-of-the-art methods to resource constraint environments has been a challenge. Galaxy morphologies are crucial to understanding the processes by which galaxies form and evolve. Efficient methods to classify galaxy morphologies are required to extract physical information from modern-day astronomy surveys. In this paper, we introduce Astroformer, a method to learn from less amount of data. We propose using a hybrid transformer-convolutional architecture drawing much inspiration from the success of CoAtNet and MaxViT. Concretely, we use the transformer-convolutional hybrid with a new stack design for the network, a different way of creating a relative self-attention layer, and pair it with a careful selection of data augmentation and regularization techniques. Our approach sets a new state-of-the-art on predicting galaxy morphologies from images on the Galaxy10 DECals dataset, a science objective, which consists of 17736 labeled images achieving $94.86\\%$ top-$1$ accuracy, beating the current state-of-the-art for this task by $4.62\\%$. Furthermore, this approach also sets a new state-of-the-art on CIFAR-100 and Tiny ImageNet. We also find that models and training methods used for larger datasets would often not work very well in the low-data regime",
    "checked": true,
    "id": "da1198c725e2196d6a6f2254cbfd6a5efd92e117",
    "semantic_title": "astroformer: more data might not be all you need for classification",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=EVwbNcRa6Yf": {
    "title": "Error Analysis of Fitted Q-iteration with ReLU-activated Deep Neural Networks",
    "volume": "tiny",
    "abstract": "Deep reinforcement learning (RL) has grown rapidly with the development of backbone feedforward neural networks (FNNs). However, there remains a theoretical gap when researchers conduct error analysis of the FNNs-based RL process. In this work, we provide an error analysis for deep-fitted $Q$-iteration applying ReLU-activated FNNs for value function approximation",
    "checked": true,
    "id": "1610e2645f170b9037b82cf2b0962d580d43ca48",
    "semantic_title": "error analysis of fitted q-iteration with relu-activated deep neural networks",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ddFJsnpZtTX": {
    "title": "General Purpose Artificial Intelligence Systems as Group Agents",
    "volume": "tiny",
    "abstract": "This paper advocates for General Purpose Artificial Intelligence Systems to be viewed as group agents. This view emphasizes their shared agency characteristics and allows for the assignment of collective responsibility, while still recognizing individual accountability when necessary. This perspective could streamline AI regulation, promote responsible use, and ensure accountability",
    "checked": true,
    "id": "1475ad18f42382eec6b7f6bb03318c2383f4b33e",
    "semantic_title": "general purpose artificial intelligence systems as group agents",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=L38bbHmRKx": {
    "title": "An Empirical Study of the Effect of Background Data Size on the Stability of SHapley Additive exPlanations (SHAP) for Deep Learning Models",
    "volume": "tiny",
    "abstract": "SHapley Additive exPlanations (SHAP) is a popular method that requires a background dataset in uncovering the deduction mechanism of artificial neural networks (ANNs). Generally, a background dataset consists of instances randomly sampled from the training dataset. However, the sampling size and its effect on SHAP remain unexplored. In this work, we empirically explored the effect and illustrated several tips when applying SHAP. The code is publicly accessible at https://github.com/Han-Yuan-Med/shap-bg-size",
    "checked": true,
    "id": "bbadd56789b3fc684126b5e1417f13a7a860a758",
    "semantic_title": "an empirical study of the effect of background data size on the stability of shapley additive explanations (shap) for deep learning models",
    "citation_count": 9,
    "authors": []
  },
  "https://openreview.net/forum?id=RNlfw6KXJey": {
    "title": "Interpretable Machine Learning-Based Risk Scoring with Individual and Ensemble Model Selection for Clinical Decision Making",
    "volume": "tiny",
    "abstract": "Clinical scores are highly interpretable and widely used in clinical risk stratification. AutoScore was previously developed as a clinical score generator, integrating the interpretability of clinical scores and the discriminability of machine learning. Although a basic framework has been established, AutoScore leaves room for enhancement: variable ranking via the random forest and manual model selection. In this work, we improved them with additional variable ranking methods and an automatic model selection. We demonstrated that these updates generate clinical scores with fewer variables and higher accuracy. The code is available at https://github.com/Han-Yuan-Med/comparison",
    "checked": true,
    "id": "dd50806df1395fd51021c5c66eb23fc377eebb3d",
    "semantic_title": "interpretable machine learning-based risk scoring with individual and ensemble model selection for clinical decision making",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=g6ZFp73_T7": {
    "title": "Analytical solutions for a family of single layer neural network regression problems",
    "volume": "tiny",
    "abstract": "In this paper, we analyze a family of penalized single layer neural network regression problems wherein the response variable has all non-negative entries. We show analytically that the optimal weights of the problem lie at the vector of zeros, which is a point of non-differentiability",
    "checked": true,
    "id": "70f7498bca7f9470fa09c4f44667c1107bb3d717",
    "semantic_title": "analytical solutions for a family of single layer neural network regression problems",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=Idalad_7wG": {
    "title": "Pretrained Vision Models for Predicting High-Risk Breast Cancer Stage",
    "volume": "tiny",
    "abstract": "Cancer is increasingly a global health issue. Seconding cardiovascular diseases, cancers are the second biggest cause of death in the world with millions of people succumbing to the disease every year. According to the World Health Organization (WHO) report, by the end of 2020, more than 7.8 million women have been diagnosed with breast cancer, making it the world's most prevalent cancer. In this paper, using the Nightingale Open Science dataset of digital pathology (breast biopsy) images, we leverage the capabilities of pre-trained computer vision models for the breast cancer stage prediction task. While individual models achieve decent performances and demonstrate usefulness to the task at hand, we find out that the predictions of an ensemble model are more efficient",
    "checked": true,
    "id": "923e5817facae60be3beceb610d0676c02df7e09",
    "semantic_title": "pretrained vision models for predicting high-risk breast cancer stage",
    "citation_count": 2,
    "authors": []
  }
}