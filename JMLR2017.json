{
  "https://jmlr.org/papers/v18/14-249.html": {
    "title": "Averaged Collapsed Variational Bayes Inference",
    "volume": "main",
    "abstract": "This paper presents the Averaged CVB (ACVB) inference and offers convergence-guaranteed and practically useful fast Collapsed Variational Bayes (CVB) inferences. CVB inferences yield more precise inferences of Bayesian probabilistic models than Variational Bayes (VB) inferences. However, their convergence aspect is fairly unknown and has not been scrutinized. To make CVB more useful, we study their convergence behaviors in a empirical and practical approach. We develop a convergence- guaranteed algorithm for any CVB-based inference called ACVB, which enables automatic convergence detection and frees non- expert practitioners from the difficult and costly manual monitoring of inference processes. In experiments, ACVB inferences are comparable to or better than those of existing inference methods and deterministic, fast, and provide easier convergence detection. These features are especially convenient for practitioners who want precise Bayesian inference with assured convergence",
    "checked": true,
    "id": "0f4cfa8fea4047d20217255964169ade91547fcc",
    "semantic_title": "averaged collapsed variational bayes inference",
    "citation_count": 15,
    "authors": [
      "Katsuhiko Ishiguro",
      "Issei Sato",
      "Naonori Ueda"
    ]
  },
  "https://jmlr.org/papers/v18/14-400.html": {
    "title": "Scalable Influence Maximization for Multiple Products in Continuous-Time Diffusion Networks",
    "volume": "main",
    "abstract": "A typical viral marketing model identifies influential users in a social network to maximize a single product adoption assuming unlimited user attention, campaign budgets, and time. In reality, multiple products need campaigns, users have limited attention, convincing users incurs costs, and advertisers have limited budgets and expect the adoptions to be maximized soon. Facing these user, monetary, and timing constraints, we formulate the problem as a submodular maximization task in a continuous-time diffusion model under the intersection of one matroid and multiple knapsack constraints. We propose a randomized algorithm estimating the user influence (Partial results in the paper on influence estimation have been published in a conference paper: Nan Du, Le Song, Manuel Gomez-Rodriguez, and Hongyuan Zha. Scalable influence estimation in continuous time diffusion networks. In Advances in Neural Information Processing Systems 26, 2013.) in a network ($|\\mathcal{V}|$ nodes, $|\\mathcal{E}|$ edges) to an accuracy of $\\epsilon$ with $n=\\mathcal{O}(1/\\epsilon^2)$ randomizations and $\\tilde{\\mathcal{O}}(n|\\mathcal{E}|+n|\\mathcal{V}|)$ computations. By exploiting the influence estimation algorithm as a subroutine, we develop an adaptive threshold greedy algorithm achieving an approximation factor $k_a/(2+2 k)$ of the optimal when $k_a$ out of the $k$ knapsack constraints are active. Extensive experiments on networks of millions of nodes demonstrate that the proposed algorithms achieve the state-of- the-art in terms of effectiveness and scalability",
    "checked": true,
    "id": "2689fcd90e0654306b51fd67eb8c4ecafc156293",
    "semantic_title": "scalable influence maximization for multiple products in continuous-time diffusion networks",
    "citation_count": 29,
    "authors": [
      "Nan Du",
      "Yingyu Liang",
      "Maria-Florina Balcan",
      "Manuel Gomez-Rodriguez",
      "Hongyuan Zha",
      "Le Song"
    ]
  },
  "https://jmlr.org/papers/v18/15-085.html": {
    "title": "Local algorithms for interactive clustering",
    "volume": "main",
    "abstract": "We study the design of interactive clustering algorithms. The user supervision that we consider is in the form of cluster split/merge requests; such feedback is easy for users to provide because it only requires a high-level understanding of the clusters. Our algorithms start with any initial clustering and only make local changes in each step; both are desirable properties in many applications. Local changes are desirable because in practice edits of other parts of the clustering are considered churn - changes that are perceived as quality-neutral or quality-negative. We show that in this framework we can still design provably correct algorithms given that our data satisfies natural separability properties. We also show that our framework works well in practice",
    "checked": true,
    "id": "042b60abf09707305523b70d87312817654fe180",
    "semantic_title": "local algorithms for interactive clustering",
    "citation_count": 94,
    "authors": [
      "Pranjal Awasthi",
      "Maria Florina Balcan",
      "Konstantin Voevodski"
    ]
  },
  "https://jmlr.org/papers/v18/15-492.html": {
    "title": "SnapVX: A Network-Based Convex Optimization Solver",
    "volume": "MLOSS",
    "abstract": "SnapVX is a high-performance solver for convex optimization problems defined on networks. For problems of this form, SnapVX provides a fast and scalable solution with guaranteed global convergence. It combines the capabilities of two open source software packages: Snap.py and CVXPY. Snap.py is a large scale graph processing library, and CVXPY provides a general modeling framework for small-scale subproblems. SnapVX offers a customizable yet easy-to-use Python interface with out-of- the- box functionality. Based on the Alternating Direction Method of Multipliers (ADMM), it is able to efficiently store, analyze, parallelize, and solve large optimization problems from a variety of different applications. Documentation, examples, and more can be found on the SnapVX website at snap.stanford.edu/snapvx",
    "checked": true,
    "id": "e6ffdba48af4e48a54cadd5fb27bc9244e04b027",
    "semantic_title": "snapvx: a network-based convex optimization solver",
    "citation_count": 21,
    "authors": [
      "David Hallac",
      "Christopher Wong",
      "Steven Diamond",
      "Abhijit Sharang",
      "Rok Sosič",
      "Stephen Boyd",
      "Jure Leskovec"
    ]
  },
  "https://jmlr.org/papers/v18/16-002.html": {
    "title": "Communication-efficient Sparse Regression",
    "volume": "main",
    "abstract": "We devise a communication-efficient approach to distributed sparse regression in the high-dimensional setting. The key idea is to average debiased or desparsified lasso estimators. We show the approach converges at the same rate as the lasso as long as the dataset is not split across too many machines, and consistently estimates the support under weaker conditions than the lasso. On the computational side, we propose a new parallel and computationally-efficient algorithm to compute the approximate inverse covariance required in the debiasing approach, when the dataset is split across samples. We further extend the approach to generalized linear models",
    "checked": true,
    "id": "23a96514f84e452aaa921e8ea3b65b396cab52c8",
    "semantic_title": "communication-efficient sparse regression",
    "citation_count": 152,
    "authors": [
      "Jason D. Lee",
      "Qiang Liu",
      "Yuekai Sun",
      "Jonathan E. Taylor"
    ]
  },
  "https://jmlr.org/papers/v18/16-070.html": {
    "title": "Improving Variational Methods via Pairwise Linear Response Identities",
    "volume": "main",
    "abstract": "Inference methods are often formulated as variational approximations: these approxima- tions allow easy evaluation of statistics by marginalization or linear response, but these estimates can be inconsistent. We show that by introducing constraints on covariance, one can ensure consistency of linear response with the variational parameters, and in so doing inference of marginal probability distributions is improved. For the Bethe approximation and its generalizations, improvements are achieved with simple choices of the constraints. The approximations are presented as variational frameworks; iterative procedures related to message passing are provided for finding the minima",
    "checked": true,
    "id": "d5685cbae73b502f0912dcf0f32ccd3d7d84d152",
    "semantic_title": "improving variational methods via pairwise linear response identities",
    "citation_count": 1,
    "authors": [
      "Jack Raymond",
      "Federico Ricci-Tersenghi"
    ]
  },
  "https://jmlr.org/papers/v18/16-270.html": {
    "title": "Distributed Sequence Memory of Multidimensional Inputs in Recurrent Networks",
    "volume": "main",
    "abstract": "Recurrent neural networks (RNNs) have drawn interest from machine learning researchers because of their effectiveness at preserving past inputs for time-varying data processing tasks. To understand the success and limitations of RNNs, it is critical that we advance our analysis of their fundamental memory properties. We focus on echo state networks (ESNs), which are RNNs with simple memoryless nodes and random connectivity. In most existing analyses, the short-term memory (STM) capacity results conclude that the ESN network size must scale linearly with the input size for unstructured inputs. The main contribution of this paper is to provide general results characterizing the STM capacity for linear ESNs with multidimensional input streams when the inputs have common low- dimensional structure: sparsity in a basis or significant statistical dependence between inputs. In both cases, we show that the number of nodes in the network must scale linearly with the information rate and poly-logarithmically with the input dimension. The analysis relies on advanced applications of random matrix theory and results in explicit non-asymptotic bounds on the recovery error. Taken together, this analysis provides a significant step forward in our understanding of the STM properties in RNNs",
    "checked": true,
    "id": "589f5953378461f86d83c303451392bed9eab760",
    "semantic_title": "distributed sequence memory of multidimensional inputs in recurrent networks",
    "citation_count": 19,
    "authors": [
      "Adam S. Charles",
      "Dong Yin",
      "Christopher J. Rozell"
    ]
  },
  "https://jmlr.org/papers/v18/16-337.html": {
    "title": "Persistence Images: A Stable Vector Representation of Persistent Homology",
    "volume": "main",
    "abstract": "Many data sets can be viewed as a noisy sampling of an underlying space, and tools from topological data analysis can characterize this structure for the purpose of knowledge discovery. One such tool is persistent homology, which provides a multiscale description of the homological features within a data set. A useful representation of this homological information is a persistence diagram (PD). Efforts have been made to map PDs into spaces with additional structure valuable to machine learning tasks. We convert a PD to a finite- dimensional vector representation which we call a persistence image (PI), and prove the stability of this transformation with respect to small perturbations in the inputs. The discriminatory power of PIs is compared against existing methods, showing significant performance gains. We explore the use of PIs with vector-based machine learning tools, such as linear sparse support vector machines, which identify features containing discriminating topological information. Finally, high accuracy inference of parameter values from the dynamic output of a discrete dynamical system (the linked twist map) and a partial differential equation (the anisotropic Kuramoto-Sivashinsky equation) provide a novel application of the discriminatory power of PIs",
    "checked": true,
    "id": "223841a71f5bce4cb03040e229d13e9a71b78ec3",
    "semantic_title": "persistence images: a stable vector representation of persistent homology",
    "citation_count": 569,
    "authors": [
      "Henry Adams",
      "Tegan Emerson",
      "Michael Kirby",
      "Rachel Neville",
      "Chris Peterson",
      "Patrick Shipman",
      "Sofya Chepushtanova",
      "Eric Hanson",
      "Francis Motta",
      "Lori Ziegelmeier"
    ]
  },
  "https://jmlr.org/papers/v18/14-318.html": {
    "title": "Spectral Clustering Based on Local PCA",
    "volume": "main",
    "abstract": "We propose a spectral clustering method based on local principal components analysis (PCA). After performing local PCA in selected neighborhoods, the algorithm builds a nearest neighbor graph weighted according to a discrepancy between the principal subspaces in the neighborhoods, and then applies spectral clustering. As opposed to standard spectral methods based solely on pairwise distances between points, our algorithm is able to resolve intersections. We establish theoretical guarantees for simpler variants within a prototypical mathematical framework for multi-manifold clustering, and evaluate our algorithm on various simulated data sets",
    "checked": true,
    "id": "d3599be5b9a42da86748b3e87ffff42502413a9a",
    "semantic_title": "spectral clustering based on local pca",
    "citation_count": 93,
    "authors": [
      "Ery Arias-Castro",
      "Gilad Lerman",
      "Teng Zhang"
    ]
  },
  "https://jmlr.org/papers/v18/15-038.html": {
    "title": "On Perturbed Proximal Gradient Algorithms",
    "volume": "main",
    "abstract": "We study a version of the proximal gradient algorithm for which the gradient is intractable and is approximated by Monte Carlo methods (and in particular Markov Chain Monte Carlo). We derive conditions on the step size and the Monte Carlo batch size under which convergence is guaranteed: both increasing batch size and constant batch size are considered. We also derive non- asymptotic bounds for an averaged version. Our results cover both the cases of biased and unbiased Monte Carlo approximation. To support our findings, we discuss the inference of a sparse generalized linear model with random effect and the problem of learning the edge structure and parameters of sparse undirected graphical models",
    "checked": true,
    "id": "aab2c7269ef68b9ef9ee5f8b8e90596b2fbae670",
    "semantic_title": "on perturbed proximal gradient algorithms",
    "citation_count": 94,
    "authors": [
      "Yves F. Atchadé",
      "Gersende Fort",
      "Eric Moulines"
    ]
  },
  "https://jmlr.org/papers/v18/15-257.html": {
    "title": "Differential Privacy for Bayesian Inference through Posterior Sampling",
    "volume": "main",
    "abstract": "Differential privacy formalises privacy-preserving mechanisms that provide access to a database. Can Bayesian inference be used directly to provide private access to data? The answer is yes: under certain conditions on the prior, sampling from the posterior distribution can lead to a desired level of privacy and utility. For a uniform treatment, we define differential privacy over arbitrary data set metrics, outcome spaces and distribution families. This allows us to also deal with non-i.i.d or non-tabular data sets. We then prove bounds on the sensitivity of the posterior to the data, which delivers a measure of robustness. We also show how to use posterior sampling to provide differentially private responses to queries, within a decision-theoretic framework. Finally, we provide bounds on the utility of answers to queries and on the ability of an adversary to distinguish between data sets. The latter are complemented by a novel use of Le Cam's method to obtain lower bounds on distinguishability. Our results hold for arbitrary metrics, including those for the common definition of differential privacy. For specific choices of the metric, we give a number of examples satisfying our assumptions",
    "checked": true,
    "id": "80de56e417814d71b6b544aa592b2bec28efe1a4",
    "semantic_title": "differential privacy for bayesian inference through posterior sampling",
    "citation_count": 60,
    "authors": [
      "Christos Dimitrakakis",
      "Blaine Nelson",
      "Zuhe Zhang",
      "Aikaterini Mitrokotsa",
      "Benjamin I. P. Rubinstein"
    ]
  },
  "https://jmlr.org/papers/v18/15-441.html": {
    "title": "Refinery: An Open Source Topic Modeling Web Platform",
    "volume": "MLOSS",
    "abstract": "We introduce Refinery, an open source platform for exploring large text document collections with topic models. Refinery is a standalone web application driven by a graphical interface, so it is usable by those without machine learning or programming expertise. Users can interactively organize articles by topic and also refine this organization with phrase-level analysis. Under the hood, we train Bayesian nonparametric topic models that can adapt model complexity to the provided data with scalable learning algorithms. The project website contains Python code and further documentation",
    "checked": true,
    "id": "ea3ec90c9c0a921f374f5d6697d60b1527b3eadc",
    "semantic_title": "refinery: an open source topic modeling web platform",
    "citation_count": 3,
    "authors": [
      "Daeil Kim",
      "Benjamin F. Swanson",
      "Michael C. Hughes",
      "Erik B. Sudderth"
    ]
  },
  "https://jmlr.org/papers/v18/15-449.html": {
    "title": "Using Conceptors to Manage Neural Long-Term Memories for Temporal Patterns",
    "volume": "main",
    "abstract": "Biological brains can learn, recognize, organize, and re- generate large repertoires of temporal patterns. Here I propose a mechanism of neurodynamical pattern learning and representation, called conceptors, which offers an integrated account of a number of such phenomena and functionalities. It becomes possible to store a large number of temporal patterns in a single recurrent neural network. In the recall process, stored patterns can be morphed and focussed. Parametric families of patterns can be learnt from a very small number of examples. Stored temporal patterns can be content- addressed in ways that are analog to recalling static patterns in Hopfield networks",
    "checked": true,
    "id": "0c497a5b95132d141dd7c310a20c7acbcd32c7c4",
    "semantic_title": "using conceptors to manage neural long-term memories for temporal patterns",
    "citation_count": 47,
    "authors": [
      "Herbert Jaeger"
    ]
  },
  "https://jmlr.org/papers/v18/16-107.html": {
    "title": "Automatic Differentiation Variational Inference",
    "volume": "main",
    "abstract": "Probabilistic modeling is iterative. A scientist posits a simple model, fits it to her data, refines it according to her analysis, and repeats. However, fitting complex models to large data is a bottleneck in this process. Deriving algorithms for new models can be both mathematically and computationally challenging, which makes it difficult to efficiently cycle through the steps. To this end, we develop ADVI. Using our method, the scientist only provides a probabilistic model and a dataset, nothing else. ADVI automatically derives an efficient variational inference algorithm, freeing the scientist to refine and explore many models. ADVI supports a broad class of models ---no conjugacy assumptions are required. We study ADVI across ten modern probabilistic models and apply it to a dataset with millions of observations. We deploy ADVI as part of Stan, a probabilistic programming system",
    "checked": true,
    "id": "30691d2a4eb1a6e88116c357e95b49f9573bcdae",
    "semantic_title": "automatic differentiation variational inference",
    "citation_count": 631,
    "authors": [
      "Alp Kucukelbir",
      "Dustin Tran",
      "Rajesh Ranganath",
      "Andrew Gelman",
      "David M. Blei"
    ]
  },
  "https://jmlr.org/papers/v18/16-174.html": {
    "title": "Empirical Evaluation of Resampling Procedures for Optimising SVM Hyperparameters",
    "volume": "main",
    "abstract": "Tuning the regularisation and kernel hyperparameters is a vital step in optimising the generalisation performance of kernel methods, such as the support vector machine (SVM). This is most often performed by minimising a resampling/cross-validation based model selection criterion, however there seems little practical guidance on the most suitable form of resampling. This paper presents the results of an extensive empirical evaluation of resampling procedures for SVM hyperparameter selection, designed to address this gap in the machine learning literature. We tested 15 different resampling procedures on 121 binary classification data sets in order to select the best SVM hyperparameters. We used three very different statistical procedures to analyse the results: the standard multi- classifier/multi-data set procedure proposed by Dem\\v{s}ar, the confidence intervals on the excess loss of each procedure in relation to 5-fold cross validation, and the Bayes factor analysis proposed by Barber. We conclude that a 2-fold procedure is appropriate to select the hyperparameters of an SVM for data sets for 1000 or more datapoints, while a 3-fold procedure is appropriate for smaller data sets",
    "checked": true,
    "id": "79043b3bf656e7b3c475e07d3b9a473b37ce047c",
    "semantic_title": "empirical evaluation of resampling procedures for optimising svm hyperparameters",
    "citation_count": 52,
    "authors": [
      "Jacques Wainer",
      "Gavin Cawley"
    ]
  },
  "https://jmlr.org/papers/v18/16-274.html": {
    "title": "A Unified Formulation and Fast Accelerated Proximal Gradient Method for Classification",
    "volume": "main",
    "abstract": "Binary classification is the problem of predicting the class a given sample belongs to. To achieve a good prediction performance, it is important to find a suitable model for a given dataset. However, it is often time consuming and impractical for practitioners to try various classification models because each model employs a different formulation and algorithm. The difficulty can be mitigated if we have a unified formulation and an efficient universal algorithmic framework for various classification models to expedite the comparison of performance of different models for a given dataset. In this paper, we present a unified formulation of various classification models (including $C$-SVM, $\\ell_2$-SVM, $\\nu$-SVM, MM-FDA, MM-MPM, logistic regression, distance weighted discrimination) and develop a general optimization algorithm based on an accelerated proximal gradient (APG) method for the formulation. We design various techniques such as backtracking line search and adaptive restarting strategy in order to speed up the practical convergence of our method. We also give a theoretical convergence guarantee for the proposed fast APG algorithm. Numerical experiments show that our algorithm is stable and highly competitive to specialized algorithms designed for specific models (e.g., sequential minimal optimization (SMO) for SVM)",
    "checked": true,
    "id": "810a874a6b9105f48287ca86da7c6ee0ce5300c6",
    "semantic_title": "a unified formulation and fast accelerated proximal gradient method for classification",
    "citation_count": 24,
    "authors": [
      "Naoki Ito",
      "Akiko Takeda",
      "Kim-Chuan Toh"
    ]
  },
  "https://jmlr.org/papers/v18/16-365.html": {
    "title": "Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning",
    "volume": "MLOSS",
    "abstract": "imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the- art methods can be categorized into 4 groups: (i) under- sampling, (ii) over-sampling, (iii) combination of over- and under-sampling, and (iv) ensemble learning methods. The proposed toolbox depends only on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore, it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. Source code, binaries, and documentation can be downloaded from github.com/scikit-learn-contrib/imbalanced-learn",
    "checked": true,
    "id": "05c5b732fb92546c7d6eeabfadb5c14610d07373",
    "semantic_title": "imbalanced-learn: a python toolbox to tackle the curse of imbalanced datasets in machine learning",
    "citation_count": 1729,
    "authors": [
      "Guillaume  Lemaître",
      "Fernando Nogueira",
      "Christos K. Aridas"
    ]
  },
  "https://jmlr.org/papers/v18/14-467.html": {
    "title": "Information-Geometric Optimization Algorithms: A Unifying Picture via Invariance Principles",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a866479d17163dff4a330cfa1682b6c86f74748b",
    "semantic_title": "information-geometric optimization algorithms: a unifying picture via invariance principles",
    "citation_count": 215,
    "authors": [
      "Yann Ollivier",
      "Ludovic Arnold",
      "Anne Auger",
      "Nikolaus Hansen"
    ]
  },
  "https://jmlr.org/papers/v18/14-546.html": {
    "title": "Breaking the Curse of Dimensionality with Convex Neural Networks",
    "volume": "main",
    "abstract": "We consider neural networks with a single hidden layer and non- decreasing positively homogeneous activation functions like the rectified linear units. By letting the number of hidden units grow unbounded and using classical non-Euclidean regularization tools on the output weights, they lead to a convex optimization problem and we provide a detailed theoretical analysis of their generalization performance, with a study of both the approximation and the estimation errors. We show in particular that they are adaptive to unknown underlying linear structures, such as the dependence on the projection of the input variables onto a low-dimensional subspace. Moreover, when using sparsity- inducing norms on the input weights, we show that high- dimensional non-linear variable selection may be achieved, without any strong assumption regarding the data and with a total number of variables potentially exponential in the number of observations. However, solving this convex optimization problem in infinite dimensions is only possible if the non- convex subproblem of addition of a new unit can be solved efficiently. We provide a simple geometric interpretation for our choice of activation functions and describe simple conditions for convex relaxations of the finite-dimensional non- convex subproblem to achieve the same generalization error bounds, even when constant-factor approximations cannot be found. We were not able to find strong enough convex relaxations to obtain provably polynomial-time algorithms and leave open the existence or non-existence of such tractable algorithms with non-exponential sample complexities",
    "checked": true,
    "id": "f9c2ece8262f9dcf4ec176799e88e51adb1fd052",
    "semantic_title": "breaking the curse of dimensionality with convex neural networks",
    "citation_count": 619,
    "authors": [
      "Francis Bach"
    ]
  },
  "https://jmlr.org/papers/v18/15-025.html": {
    "title": "Memory Efficient Kernel Approximation",
    "volume": "main",
    "abstract": "Scaling kernel machines to massive data sets is a major challenge due to storage and computation issues in handling large kernel matrices, that are usually dense. Recently, many papers have suggested tackling this problem by using a low-rank approximation of the kernel matrix. In this paper, we first make the observation that the structure of shift-invariant kernels changes from low-rank to block-diagonal (without any low-rank structure) when varying the scale parameter. Based on this observation, we propose a new kernel approximation framework -- Memory Efficient Kernel Approximation (MEKA), which considers both low-rank and clustering structure of the kernel matrix. We show that the resulting algorithm outperforms state-of-the-art low-rank kernel approximation methods in terms of speed, approximation error, and memory usage. As an example, on the covtype dataset with half a million samples, MEKA takes around 70 seconds and uses less than 80 MB memory on a single machine to achieve 10% relative approximation error, while standard NystrÃ¶m approximation is about 6 times slower and uses more than 400MB memory to achieve similar approximation. We also present extensive experiments on applying MEKA to speed up kernel ridge regression",
    "checked": true,
    "id": "58c85498e23c86f526223e661e250007794c8d67",
    "semantic_title": "memory efficient kernel approximation",
    "citation_count": 151,
    "authors": [
      "Si Si",
      "Cho-Jui Hsieh",
      "Inderjit S. Dhillon"
    ]
  },
  "https://jmlr.org/papers/v18/15-178.html": {
    "title": "On the Equivalence between Kernel Quadrature Rules and Random Feature Expansions",
    "volume": "main",
    "abstract": "We show that kernel-based quadrature rules for computing integrals can be seen as a special case of random feature expansions for positive definite kernels, for a particular decomposition that always exists for such kernels. We provide a theoretical analysis of the number of required samples for a given approximation error, leading to both upper and lower bounds that are based solely on the eigenvalues of the associated integral operator and match up to logarithmic terms. In particular, we show that the upper bound may be obtained from independent and identically distributed samples from a specific non-uniform distribution, while the lower bound if valid for any set of points. Applying our results to kernel-based quadrature, while our results are fairly general, we recover known upper and lower bounds for the special cases of Sobolev spaces. Moreover, our results extend to the more general problem of full function approximations (beyond simply computing an integral), with results in $L_2$- and $L_\\infty$-norm that match known results for special cases. Applying our results to random features, we show an improvement of the number of random features needed to preserve the generalization guarantees for learning with Lipshitz-continuous losses",
    "checked": true,
    "id": "990f341846223e80a4c5fbd5c2be309eb5c8bec9",
    "semantic_title": "on the equivalence between kernel quadrature rules and random feature expansions",
    "citation_count": 262,
    "authors": [
      "Francis Bach"
    ]
  },
  "https://jmlr.org/papers/v18/15-486.html": {
    "title": "Analyzing Tensor Power Method Dynamics in Overcomplete Regime",
    "volume": "main",
    "abstract": "We present a novel analysis of the dynamics of tensor power iterations in the overcomplete regime where the tensor CP rank is larger than the input dimension. Finding the CP decomposition of an overcomplete tensor is NP-hard in general. We consider the case where the tensor components are randomly drawn, and show that the simple power iteration recovers the components with bounded error under mild initialization conditions. We apply our analysis to unsupervised learning of latent variable models, such as multi-view mixture models and spherical Gaussian mixtures. Given the third order moment tensor, we learn the parameters using tensor power iterations. We prove it can correctly learn the model parameters when the number of hidden components $k$ is much larger than the data dimension $d$, up to $k = o(d^{1.5})$. We initialize the power iterations with data samples and prove its success under mild conditions on the signal-to-noise ratio of the samples. Our analysis significantly expands the class of latent variable models where spectral methods are applicable. Our analysis also deals with noise in the input tensor leading to sample complexity result in the application to learning latent variable models",
    "checked": true,
    "id": "0bece2c06144f41ce636a9c0eaef647a42c3326e",
    "semantic_title": "analyzing tensor power method dynamics in overcomplete regime",
    "citation_count": 47,
    "authors": [
      "Animashree An",
      "kumar",
      "Rong Ge",
      "Majid Janzamin"
    ]
  },
  "https://jmlr.org/papers/v18/16-131.html": {
    "title": "JSAT: Java Statistical Analysis Tool, a Library for Machine Learning",
    "volume": "MLOSS",
    "abstract": "Java Statistical Analysis Tool (JSAT) is a Machine Learning library written in pure Java. It works to fill a void in the Java ecosystem for a general purpose library that is relatively high performance and flexible, which is not adequately fulfilled by Weka (Hall et al., 2009) and Java-ML (Abeel et al., 2009). Almost all of the algorithms are independently implemented using an Object- Oriented framework. JSAT is made available under the GNU GPL license here: github.com/EdwardRaff/JSAT",
    "checked": true,
    "id": "8347a5ae3a622ce0aaa7dd674020c18ea9c89fdf",
    "semantic_title": "jsat: java statistical analysis tool, a library for machine learning",
    "citation_count": 46,
    "authors": [
      "Edward Raff"
    ]
  },
  "https://jmlr.org/papers/v18/16-172.html": {
    "title": "Identifying a Minimal Class of Models for High--dimensional Data",
    "volume": "main",
    "abstract": "Model selection consistency in the high--dimensional regression setting can be achieved only if strong assumptions are fulfilled. We therefore suggest to pursue a different goal, which we call a minimal class of models. The minimal class of models includes models that are similar in their prediction accuracy but not necessarily in their elements. We suggest a random search algorithm to reveal candidate models. The algorithm implements simulated annealing while using a score for each predictor that we suggest to derive using a combination of the lasso and the elastic net. The utility of using a minimal class of models is demonstrated in the analysis of two data sets",
    "checked": false,
    "id": "3c7c2f42e87caf4d65a5a0e2d7dafc71a451aa7c",
    "semantic_title": "identifying a minimal class of models for high-dimensional data",
    "citation_count": 15,
    "authors": [
      "Daniel Nevo",
      "Ya'acov Ritov"
    ]
  },
  "https://jmlr.org/papers/v18/16-261.html": {
    "title": "Auto-WEKA 2.0: Automatic model selection and hyperparameter optimization in WEKA",
    "volume": "MLOSS",
    "abstract": "WEKA is a widely used, open-source machine learning platform. Due to its intuitive interface, it is particularly popular with novice users. However, such users often find it hard to identify the best approach for their particular dataset among the many available. We describe the new version of Auto-WEKA, a system designed to help such users by automatically searching through the joint space of WEKA's learning algorithms and their respective hyperparameter settings to maximize performance, using a state-of-the-art Bayesian optimization method. Our new package is tightly integrated with WEKA, making it just as accessible to end users as any other learning algorithm",
    "checked": true,
    "id": "db9dd36e19c8169e0b0e0ca2ccb38ecea2ba0713",
    "semantic_title": "auto-weka 2.0: automatic model selection and hyperparameter optimization in weka",
    "citation_count": 598,
    "authors": [
      "Lars Kotthoff",
      "Chris Thornton",
      "Holger H. Hoos",
      "Frank Hutter",
      "Kevin Leyton-Brown"
    ]
  },
  "https://jmlr.org/papers/v18/16-300.html": {
    "title": "POMDPs.jl: A Framework for Sequential Decision Making under Uncertainty",
    "volume": "MLOSS",
    "abstract": "POMDPs.jl is an open-source framework for solving Markov decision processes (MDPs) and partially observable MDPs (POMDPs). POMDPs.jl allows users to specify sequential decision making problems with minimal effort without sacrificing the expressive nature of POMDPs, making this framework viable for both educational and research purposes. It is written in the Julia language to allow flexible prototyping and large-scale computation that leverages the high-performance nature of the language. The associated JuliaPOMDP community also provides a number of state-of-the-art MDP and POMDP solvers and a rich library of support tools to help with implementing new solvers and evaluating the solution results. The most recent version of POMDPs.jl, the related packages, and documentation can be found at github.com/ JuliaPOMDP/POMDPs.jl",
    "checked": true,
    "id": "5c84814b138a6c882ffed34d89bd8882077a5fed",
    "semantic_title": "pomdps.jl: a framework for sequential decision making under uncertainty",
    "citation_count": 116,
    "authors": [
      "Maxim Egorov",
      "Zachary N. Sunberg",
      "Edward Balaban",
      "Tim A. Wheeler",
      "Jayesh K. Gupta",
      "Mykel J. Kochenderfer"
    ]
  },
  "https://jmlr.org/papers/v18/10-231.html": {
    "title": "Generalized P{\\'o}lya Urn for Time-Varying Pitman-Yor Processes",
    "volume": "main",
    "abstract": "This article introduces a class of first-order stationary time- varying Pitman-Yor processes. Subsuming our construction of time-varying Dirichlet processes presented in (Caron et al., 2007), these models can be used for time-dynamic density estimation and clustering. Our intuitive and simple construction relies on a generalized PÃ³lya urn scheme. Significantly, this construction yields marginal distributions at each time point that can be explicitly characterized and easily controlled. Inference is performed using Markov chain Monte Carlo and sequential Monte Carlo methods. We demonstrate our models and algorithms on epidemiological and video tracking data",
    "checked": true,
    "id": "f01738647271f26d54708069b531c6f55d7ac982",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "François Caron",
      "Willie Neiswanger",
      "Frank Wood",
      "Arnaud Doucet",
      "Manuel Davy"
    ]
  },
  "https://jmlr.org/papers/v18/15-397.html": {
    "title": "Particle Gibbs Split-Merge Sampling for Bayesian Inference in Mixture Models",
    "volume": "main",
    "abstract": "This paper presents an original Markov chain Monte Carlo method to sample from the posterior distribution of conjugate mixture models. This algorithm relies on a flexible split-merge procedure built using the particle Gibbs sampler introduced in Andrieu et al. (2009, 2010). The resulting so-called Particle Gibbs Split-Merge sampler does not require the computation of a complex acceptance ratio and can be implemented using existing sequential Monte Carlo libraries. We investigate its performance experimentally on synthetic problems as well as on geolocation data. Our results show that for a given computational budget, the Particle Gibbs Split-Merge sampler empirically outperforms existing split merge methods. The code and instructions allowing to reproduce the experiments is available at github.com/aroth85/pgsm",
    "checked": true,
    "id": "b9267c0214fcb6e5aacafe93eff1ad76f1fd56a6",
    "semantic_title": "particle gibbs split-merge sampling for bayesian inference in mixture models",
    "citation_count": 20,
    "authors": [
      "Alexandre Bouchard-Côté",
      "Arnaud Doucet",
      "Andrew Roth"
    ]
  },
  "https://jmlr.org/papers/v18/15-613.html": {
    "title": "Certifiably Optimal Low Rank Factor Analysis",
    "volume": "main",
    "abstract": "Factor Analysis (FA) is a technique of fundamental importance that is widely used in classical and modern multivariate statistics, psychometrics, and econometrics. In this paper, we revisit the classical rank-constrained FA problem which seeks to approximate an observed covariance matrix ($\\B\\Sigma$) by the sum of a Positive Semidefinite (PSD) low-rank component ($\\B\\Theta$) and a diagonal matrix ($\\B\\Phi$) (with nonnegative entries) subject to $\\B\\Sigma - \\B\\Phi$ being PSD. We propose a flexible family of rank-constrained, nonlinear Semidefinite Optimization based formulations for this task. We introduce a reformulation of the problem as a smooth optimization problem with convex, compact constraints and propose a unified algorithmic framework, utilizing state of the art techniques in nonlinear optimization to obtain high-quality feasible solutions for our proposed formulation. At the same time, by using a variety of techniques from discrete and global optimization, we show that these solutions are certifiably optimal in many cases, even for problems with thousands of variables. Our techniques are general and make no assumption on the underlying problem data. The estimator proposed herein aids statistical interpretability and provides computational scalability and significantly improved accuracy when compared to current, publicly available popular methods for rank-constrained FA. We demonstrate the effectiveness of our proposal on an array of synthetic and real-life datasets. To our knowledge, this is the first paper that demonstrates how a previously intractable rank-constrained optimization problem can be solved to provable optimality by coupling developments in convex analysis and in global and discrete optimization",
    "checked": true,
    "id": "2523b796d50720685258144eb66585855c3eb018",
    "semantic_title": "certifiably optimal low rank factor analysis",
    "citation_count": 34,
    "authors": [
      "Dimitris Bertsimas",
      "Martin S. Copenhaver",
      "Rahul Mazumder"
    ]
  },
  "https://jmlr.org/papers/v18/15-651.html": {
    "title": "Group Sparse Optimization via lp,q Regularization",
    "volume": "main",
    "abstract": "In this paper, we investigate a group sparse optimization problem via $\\ell_{p,q}$ regularization in three aspects: theory, algorithm and application. In the theoretical aspect, by introducing a notion of group restricted eigenvalue condition, we establish an oracle property and a global recovery bound of order $\\mathcal{O}(\\lambda^\\frac{2}{2-q})$ for any point in a level set of the $\\ell_{p,q}$ regularization problem, and by virtue of modern variational analysis techniques, we also provide a local analysis of recovery bound of order $\\mathcal{O}(\\lambda^2)$ for a path of local minima. In the algorithmic aspect, we apply the well-known proximal gradient method to solve the $\\ell_{p,q}$ regularization problems, either by analytically solving some specific $\\ell_{p,q}$ regularization subproblems, or by using the Newton method to solve general $\\ell_{p,q}$ regularization subproblems. In particular, we establish a local linear convergence rate of the proximal gradient method for solving the $\\ell_{1,q}$ regularization problem under some mild conditions and by first proving a second-order growth condition. As a consequence, the local linear convergence rate of proximal gradient method for solving the usual $\\ell_{q}$ regularization problem ($0<q<1$) is obtained. Finally in the aspect of application, we present some numerical results on both the simulated data and the real data in gene transcriptional regulation",
    "checked": true,
    "id": "1db7e65053bb5a2e11659c0d851609e1ec8d6f0a",
    "semantic_title": "group sparse optimization via lp,q regularization",
    "citation_count": 75,
    "authors": [
      "Yaohua Hu",
      "Chong Li",
      "Kaiwen Meng",
      "Jing Qin",
      "Xiaoqi Yang"
    ]
  },
  "https://jmlr.org/papers/v18/16-460.html": {
    "title": "Preference-based Teaching",
    "volume": "main",
    "abstract": "We introduce a new model of teaching named preference-based teaching and a corresponding complexity parameter---the preference-based teaching dimension (PBTD)---representing the worst-case number of examples needed to teach any concept in a given concept class. Although the PBTD coincides with the well- known recursive teaching dimension (RTD) on finite classes, it is radically different on infinite ones: the RTD becomes infinite already for trivial infinite classes (such as half- intervals) whereas the PBTD evaluates to reasonably small values for a wide collection of infinite classes including classes consisting of so-called closed sets w.r.t. a given closure operator, including various classes related to linear sets over $\\mathbb{N}_0$ (whose RTD had been studied quite recently) and including the class of Euclidean half-spaces. On top of presenting these concrete results, we provide the reader with a theoretical framework (of a combinatorial flavor) which helps to derive bounds on the PBTD",
    "checked": true,
    "id": "39043c793428b36b53451f89bc885d91bdf5cf29",
    "semantic_title": "preference-based teaching",
    "citation_count": 37,
    "authors": [
      "Ziyuan Gao",
      "Christoph Ries",
      "Hans U. Simon",
      "S",
      "ra Zilles"
    ]
  },
  "https://jmlr.org/papers/v18/13-336.html": {
    "title": "Nonparametric Risk Bounds for Time-Series Forecasting",
    "volume": "main",
    "abstract": "We derive generalization error bounds for traditional time- series forecasting models. Our results hold for many standard forecasting tools including autoregressive models, moving average models, and, more generally, linear state-space models. These non-asymptotic bounds need only weak assumptions on the data-generating process, yet allow forecasters to select among competing models and to guarantee, with high probability, that their chosen model will perform well. We motivate our techniques with and apply them to standard economic and financial forecasting tools---a GARCH model for predicting equity volatility and a dynamic stochastic general equilibrium model (DSGE), the standard tool in macroeconomic forecasting. We demonstrate in particular how our techniques can aid forecasters and policy makers in choosing models which behave well under uncertainty and mis-specification",
    "checked": true,
    "id": "11699a49dfe5c469267cfa63ae31e7fe176c7d52",
    "semantic_title": "nonparametric risk bounds for time-series forecasting",
    "citation_count": 25,
    "authors": [
      "Daniel J. McDonald",
      "Cosma Rohilla Shalizi",
      "Mark Schervish"
    ]
  },
  "https://jmlr.org/papers/v18/14-188.html": {
    "title": "Online Bayesian Passive-Aggressive Learning",
    "volume": "main",
    "abstract": "We present online Bayesian Passive-Aggressive (BayesPA) learning, a generic online learning framework for hierarchical Bayesian models with max-margin posterior regularization. We show that BayesPA subsumes the standard online Passive- Aggressive (PA) learning and extends naturally to incorporate latent variables for both parametric and nonparametric Bayesian inference, therefore providing great flexibility for explorative analysis. As an important example, we apply BayesPA to topic modeling and derive efficient online learning algorithms for max-margin topic models. We further develop nonparametric BayesPA topic models to infer the unknown number of topics in an online manner. Experimental results on 20newsgroups and a large Wikipedia multi-label dataset (with 1.1 millions of training documents and 0.9 million of unique terms in the vocabulary) show that our approaches significantly improve time efficiency while achieving comparable accuracy with the corresponding batch algorithms",
    "checked": true,
    "id": "7c3ef4431ebbf02bdc8ad3c716453b5e12422dd3",
    "semantic_title": "online bayesian passive-aggressive learning",
    "citation_count": 37,
    "authors": [
      "Tianlin Shi",
      "Jun Zhu"
    ]
  },
  "https://jmlr.org/papers/v18/15-104.html": {
    "title": "Asymptotic Analysis of Objectives Based on Fisher Information in Active Learning",
    "volume": "main",
    "abstract": "Obtaining labels can be costly and time-consuming. Active learning allows a learning algorithm to intelligently query samples to be labeled for a more efficient learning. Fisher information ratio (FIR) has been used as an objective for selecting queries. However, little is known about the theory behind the use of FIR for active learning. There is a gap between the underlying theory and the motivation of its usage in practice. In this paper, we attempt to fill this gap and provide a rigorous framework for analyzing existing FIR-based active learning methods. In particular, we show that FIR can be asymptotically viewed as an upper bound of the expected variance of the log-likelihood ratio. Additionally, our analysis suggests a unifying framework that not only enables us to make theoretical comparisons among the existing querying methods based on FIR, but also allows us to give insight into the development of new active learning approaches based on this objective",
    "checked": true,
    "id": "4cdcbc5f8ff509904b432eed361af1f1be714a7c",
    "semantic_title": "asymptotic analysis of objectives based on fisher information in active learning",
    "citation_count": 26,
    "authors": [
      "Jamshid Sourati",
      "Murat Akcakaya",
      "Todd K. Leen",
      "Deniz Erdogmus",
      "Jennifer G. Dy"
    ]
  },
  "https://jmlr.org/papers/v18/15-468.html": {
    "title": "A Spectral Algorithm for Inference in Hidden semi-Markov Models",
    "volume": "main",
    "abstract": "Hidden semi-Markov models (HSMMs) are latent variable models which allow latent state persistence and can be viewed as a generalization of the popular hidden Markov models (HMMs). In this paper, we introduce a novel spectral algorithm to perform inference in HSMMs. Unlike expectation maximization (EM), our approach correctly estimates the probability of given observation sequence based on a set of training sequences. Our approach is based on estimating moments from the sample, whose number of dimensions depends only logarithmically on the maximum length of the hidden state persistence. Moreover, the algorithm requires only a few matrix inversions and is therefore computationally efficient. Empirical evaluations on synthetic and real data demonstrate the advantage of the algorithm over EM in terms of speed and accuracy, especially for large data sets",
    "checked": true,
    "id": "aa3899d2c1d13aaf9670e89cd478a84c8e467274",
    "semantic_title": "a spectral algorithm for inference in hidden semi-markov models",
    "citation_count": 10,
    "authors": [
      "Igor Melnyk",
      "Arindam Banerjee"
    ]
  },
  "https://jmlr.org/papers/v18/16-166.html": {
    "title": "Simplifying Probabilistic Expressions in Causal Inference",
    "volume": "main",
    "abstract": "Obtaining a non-parametric expression for an interventional distribution is one of the most fundamental tasks in causal inference. Such an expression can be obtained for an identifiable causal effect by an algorithm or by manual application of do-calculus. Often we are left with a complicated expression which can lead to biased or inefficient estimates when missing data or measurement errors are involved. We present an automatic simplification algorithm that seeks to eliminate symbolically unnecessary variables from these expressions by taking advantage of the structure of the underlying graphical model. Our method is applicable to all causal effect formulas and is readily available in the R package causaleffect",
    "checked": true,
    "id": "191d99fb17e4b0e70893fae9f51e1a8d246e4904",
    "semantic_title": "simplifying probabilistic expressions in causal inference",
    "citation_count": 12,
    "authors": [
      "Santtu Tikka",
      "Juha Karvanen"
    ]
  },
  "https://jmlr.org/papers/v18/16-217.html": {
    "title": "Nearly optimal classification for semimetrics",
    "volume": "main",
    "abstract": "We initiate the rigorous study of classification in semimetric spaces, which are point sets with a distance function that is non-negative and symmetric, but need not satisfy the triangle inequality. We define the density dimension dens and discover that it plays a central role in the statistical and algorithmic feasibility of learning in semimetric spaces. We compute this quantity for several widely used semimetrics and present nearly optimal sample compression algorithms, which are then used to obtain generalization guarantees, including fast rates. Our claim of near-optimality holds in both computational and statistical senses. When the sample has radius $R$ and margin $\\gamma$, we show that it can be compressed down to roughly $d=(R/\\gamma)^{\\text{dens}}$ points, and further that finding a significantly better compression is algorithmically intractable unless P=NP. This compression implies generalization via standard Occam-type arguments, to which we provide a nearly matching lower bound",
    "checked": true,
    "id": "a96c125f91def81a16ab0c76fd9dceaf7849fa5e",
    "semantic_title": "nearly optimal classification for semimetrics",
    "citation_count": 18,
    "authors": [
      "Lee-Ad Gottlieb",
      "Aryeh Kontorovich",
      "Pinhas Nisnevitch"
    ]
  },
  "https://jmlr.org/papers/v18/16-223.html": {
    "title": "Bridging Supervised Learning and Test-Based Co-optimization",
    "volume": "main",
    "abstract": "This paper takes a close look at the important commonalities and subtle differences between the well-established field of supervised learning and the much younger one of co-optimization. It explains the relationships between the problems, algorithms and views on cost and performance of the two fields, all throughout providing a two-way dictionary for the respective terminologies used to describe these concepts. The intent is to facilitate advancement of both fields through transfer and cross-pollination of ideas, techniques and results. As a proof of concept, a theoretical study is presented on the connection between existence / lack of free lunch in the two fields, showcasing a few ideas for improving computational complexity of certain supervised learning approaches",
    "checked": true,
    "id": "cf90f4d719742c9f8974f1603e5329d8b0c65db5",
    "semantic_title": "bridging supervised learning and test-based co-optimization",
    "citation_count": 6,
    "authors": [
      "Elena Popovici"
    ]
  },
  "https://jmlr.org/papers/v18/16-509.html": {
    "title": "GFA: Exploratory Analysis of Multiple Data Sources with Group Factor Analysis",
    "volume": "MLOSS",
    "abstract": "The R package GFA provides a full pipeline for factor analysis of multiple data sources that are represented as matrices with co-occurring samples. It allows learning dependencies between subsets of the data sources, decomposed into latent factors. The package also implements sparse priors for the factorization, providing interpretable biclusters of the multi-source data",
    "checked": true,
    "id": "626b1a48e0ee7f5714693c5dea3fe9f5eab07cd7",
    "semantic_title": "gfa: exploratory analysis of multiple data sources with group factor analysis",
    "citation_count": 17,
    "authors": [
      "Eemeli Leppäaho",
      "Muhammad Ammad-ud-din",
      "Samuel Kaski"
    ]
  },
  "https://jmlr.org/papers/v18/16-537.html": {
    "title": "GPflow: A Gaussian Process Library using TensorFlow",
    "volume": "MLOSS",
    "abstract": "GPflow is a Gaussian process library that uses TensorFlow for its core computations and Python for its front end. The distinguishing features of GPflow are that it uses variational inference as the primary approximation method, provides concise code through the use of automatic differentiation, has been engineered with a particular emphasis on software testing and is able to exploit GPU hardware",
    "checked": true,
    "id": "c4be5b937c819d1432c5343d1ea07a5269a0380d",
    "semantic_title": "gpflow: a gaussian process library using tensorflow",
    "citation_count": 572,
    "authors": [
      "Alexander G. de G. Matthews",
      "Mark van der Wilk",
      "Tom Nickson",
      "Keisuke Fujii",
      "Alexis Boukouvalas",
      "Pablo Le{\\'o}n-Villagr{\\'a}",
      "Zoubin Ghahramani",
      "James Hensman"
    ]
  },
  "https://jmlr.org/papers/v18/16-132.html": {
    "title": "COEVOLVE: A Joint Point Process Model for Information Diffusion and Network Evolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": "d4872aebf6f8e8644d93f55a6aef042de18d61a6",
    "semantic_title": "coevolve: a joint point process model for information diffusion and network co-evolution",
    "citation_count": 216,
    "authors": [
      "Mehrdad Farajtabar",
      "Yichen Wang",
      "Manuel Gomez-Rodriguez",
      "Shuang Li",
      "Hongyuan Zha",
      "Le Song"
    ]
  },
  "https://jmlr.org/papers/v18/16-198.html": {
    "title": "Learning Local Dependence In Ordered Data",
    "volume": "main",
    "abstract": "In many applications, data come with a natural ordering. This ordering can often induce local dependence among nearby variables. However, in complex data, the width of this dependence may vary, making simple assumptions such as a constant neighborhood size unrealistic. We propose a framework for learning this local dependence based on estimating the inverse of the Cholesky factor of the covariance matrix. Penalized maximum likelihood estimation of this matrix yields a simple regression interpretation for local dependence in which variables are predicted by their neighbors. Our proposed method involves solving a convex, penalized Gaussian likelihood problem with a hierarchical group lasso penalty. The problem decomposes into independent subproblems which can be solved efficiently in parallel using first-order methods. Our method yields a sparse, symmetric, positive definite estimator of the precision matrix, encoding a Gaussian graphical model. We derive theoretical results not found in existing methods attaining this structure. In particular, our conditions for signed support recovery and estimation consistency rates in multiple norms are as mild as those in a regression problem. Empirical results show our method performing favorably compared to existing methods. We apply our method to genomic data to flexibly model linkage disequilibrium. Our method is also applied to improve the performance of discriminant analysis in sound recording classification",
    "checked": true,
    "id": "29365331f6a56938bdcd2abd8e186d127a709af0",
    "semantic_title": "learning local dependence in ordered data",
    "citation_count": 32,
    "authors": [
      "Guo Yu",
      "Jacob Bien"
    ]
  },
  "https://jmlr.org/papers/v18/16-391.html": {
    "title": "Bayesian Learning of Dynamic Multilayer Networks",
    "volume": "main",
    "abstract": "A plethora of networks is being collected in a growing number of fields, including disease transmission, international relations, social interactions, and others. As data streams continue to grow, the complexity associated with these highly multidimensional connectivity data presents novel challenges. In this paper, we focus on the time-varying interconnections among a set of actors in multiple contexts, called layers. Current literature lacks flexible statistical models for dynamic multilayer networks, which can enhance quality in inference and prediction by efficiently borrowing information within each network, across time, and between layers. Motivated by this gap, we develop a Bayesian nonparametric model leveraging latent space representations. Our formulation characterizes the edge probabilities as a function of shared and layer-specific actors positions in a latent space, with these positions changing in time via Gaussian processes. This representation facilitates dimensionality reduction and incorporates different sources of information in the observed data. In addition, we obtain tractable procedures for posterior computation, inference, and prediction. We provide theoretical results on the flexibility of our model. Our methods are tested on simulations and infection studies monitoring dynamic face-to-face contacts among individuals in multiple days, where we perform better than current methods in inference and prediction",
    "checked": true,
    "id": "727898f95fbdc494e7e02b0406e33cecda39dc7d",
    "semantic_title": "bayesian learning of dynamic multilayer networks",
    "citation_count": 20,
    "authors": [
      "Daniele Durante",
      "Nabanita Mukherjee",
      "Rebecca C. Steorts"
    ]
  },
  "https://jmlr.org/papers/v18/16-538.html": {
    "title": "Time-Accuracy Tradeoffs in Kernel Prediction: Controlling Prediction Quality",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f68f682f9bf329dbba8c228989162ac7b4855e2c",
    "semantic_title": "time-accuracy tradeoffs in kernel prediction: controlling prediction quality",
    "citation_count": 10,
    "authors": [
      "Samory Kpotufe",
      "Nakul Verma"
    ]
  },
  "https://jmlr.org/papers/v18/16-564.html": {
    "title": "Asymptotic behavior of Support Vector Machine for spiked population model",
    "volume": "main",
    "abstract": "For spiked population model, we investigate the large dimension $N$ and large sample size $M$ asymptotic behavior of the Support Vector Machine (SVM) classification method in the limit of $N,M\\rightarrow\\infty$ at fixed $\\alpha=M/N$. We focus on the generalization performance by analytically evaluating the angle between the normal direction vectors of SVM separating hyperplane and corresponding Bayes optimal separating hyperplane. This is an analogous result to the one shown in Paul (2007) and Nadler (2008) for the angle between the sample eigenvector and the population eigenvector in random matrix theorem. We provide not just bound, but sharp prediction of the asymptotic behavior of SVM that can be determined by a set of nonlinear equations. Based on the analytical results, we propose a new method of selecting tuning parameter which significantly reduces the computational cost. A surprising finding is that SVM achieves its best performance at small value of the tuning parameter under spiked population model. These results are confirmed to be correct by comparing with those of numerical simulations on finite-size systems. We also apply our formulas to an actual dataset of breast cancer and find agreement between analytical derivations and numerical computations based on cross validation",
    "checked": true,
    "id": "6eef85cd80123e770b8304ae08957f59ff22e05a",
    "semantic_title": "asymptotic behavior of support vector machine for spiked population model",
    "citation_count": 28,
    "authors": [
      "Hanwen Huang"
    ]
  },
  "https://jmlr.org/papers/v18/16-601.html": {
    "title": "Distributed Semi-supervised Learning with Kernel Ridge Regression",
    "volume": "main",
    "abstract": "This paper provides error analysis for distributed semi- supervised learning with kernel ridge regression (DSKRR) based on a divide-and-conquer strategy. DSKRR applies kernel ridge regression (KRR) to data subsets that are distributively stored on multiple servers to produce individual output functions, and then takes a weighted average of the individual output functions as a final estimator. Using a novel error decomposition which divides the generalization error of DSKRR into the approximation error, sample error and distributed error, we find that the sample error and distributed error reflect the power and limitation of DSKRR, compared with KRR processing the whole data. Thus a small distributed error provides a large range of the number of data subsets to guarantee a small generalization error. Our results show that unlabeled data play important roles in reducing the distributed error and enlarging the number of data subsets in DSKRR. Our analysis also applies to the case when the regression function is out of the reproducing kernel Hilbert space. Numerical experiments including toy simulations and a music-prediction task are employed to demonstrate our theoretical statements and show the power of unlabeled data in distributed learning",
    "checked": true,
    "id": "9f637f97fb9a1035a68098ef7a7d8addf6c017cf",
    "semantic_title": "distributed semi-supervised learning with kernel ridge regression",
    "citation_count": 94,
    "authors": [
      "Xiangyu Chang",
      "Shao-Bo Lin",
      "Ding-Xuan Zhou"
    ]
  },
  "https://jmlr.org/papers/v18/15-205.html": {
    "title": "On Markov chain Monte Carlo methods for tall data",
    "volume": "main",
    "abstract": "Markov chain Monte Carlo methods are often deemed too computationally intensive to be of any practical use for big data applications, and in particular for inference on datasets containing a large number $n$ of individual data points, also known as tall datasets. In scenarios where data are assumed independent, various approaches to scale up the Metropolis- Hastings algorithm in a Bayesian inference context have been recently proposed in machine learning and computational statistics. These approaches can be grouped into two categories: divide-and-conquer approaches and, subsampling-based algorithms. The aims of this article are as follows. First, we present a comprehensive review of the existing literature, commenting on the underlying assumptions and theoretical guarantees of each method. Second, by leveraging our understanding of these limitations, we propose an original subsampling-based approach relying on a control variate method which samples under regularity conditions from a distribution provably close to the posterior distribution of interest, yet can require less than $O(n)$ data point likelihood evaluations at each iteration for certain statistical models in favourable scenarios. Finally, we emphasize that we have only been able so far to propose subsampling-based methods which display good performance in scenarios where the Bernstein-von Mises approximation of the target posterior distribution is excellent. It remains an open challenge to develop such methods in scenarios where the Bernstein-von Mises approximation is poor",
    "checked": true,
    "id": "e01a2082464b3598962ed697e7b6942a0f8477f0",
    "semantic_title": "on markov chain monte carlo methods for tall data",
    "citation_count": 250,
    "authors": [
      "Rémi Bardenet",
      "Arnaud Doucet",
      "Chris Holmes"
    ]
  },
  "https://jmlr.org/papers/v18/15-240.html": {
    "title": "Explaining the Success of AdaBoost and Random Forests as Interpolating Classifiers",
    "volume": "main",
    "abstract": "There is a large literature explaining why AdaBoost is a successful classifier. The literature on AdaBoost focuses on classifier margins and boosting's interpretation as the optimization of an exponential likelihood function. These existing explanations, however, have been pointed out to be incomplete. A random forest is another popular ensemble method for which there is substantially less explanation in the literature. We introduce a novel perspective on AdaBoost and random forests that proposes that the two algorithms work for similar reasons. While both classifiers achieve similar predictive accuracy, random forests cannot be conceived as a direct optimization procedure. Rather, random forests is a self- averaging, interpolating algorithm which creates what we denote as a spiked-smooth classifier, and we view AdaBoost in the same light. We conjecture that both AdaBoost and random forests succeed because of this mechanism. We provide a number of examples to support this explanation. In the process, we question the conventional wisdom that suggests that boosting algorithms for classification require regularization or early stopping and should be limited to low complexity classes of learners, such as decision stumps. We conclude that boosting should be used like random forests: with large decision trees, without regularization or early stopping",
    "checked": true,
    "id": "f39fabe0c7f3a5d2a19259348985a5e99bf81330",
    "semantic_title": "explaining the success of adaboost and random forests as interpolating classifiers",
    "citation_count": 237,
    "authors": [
      "Abraham J. Wyner",
      "Matthew Olson",
      "Justin Bleich",
      "David Mease"
    ]
  },
  "https://jmlr.org/papers/v18/15-659.html": {
    "title": "Clustering from General Pairwise Observations with Applications to Time-varying Graphs",
    "volume": "main",
    "abstract": "We present a general framework for graph clustering and bi- clustering where we are given a general observation (called a label) between each pair of nodes. This framework allows a rich encoding of various types of pairwise interactions between nodes. We propose a new tractable and robust approach to this problem based on convex optimization and maximum likelihood estimators. We analyze our algorithms under a general statistical model extending the planted partition and stochastic block models. Both sufficient and necessary conditions are provided for successful recovery of the underlying clusters. Our theoretical results subsume many existing graph clustering results for a wide range of settings, including planted partition, weighted clustering, submatrix localization and partially observed graphs. Furthermore, our results are applicable to novel settings including time-varying graphs, providing new insights to solutions of these problems. We provide empirical results on both synthetic and real data that corroborate with our theoretical findings",
    "checked": true,
    "id": "53ecda4c0acae30d780358e52748030149f34822",
    "semantic_title": "clustering from general pairwise observations with applications to time-varying graphs",
    "citation_count": 3,
    "authors": [
      "Shiau Hong Lim",
      "Yudong Chen",
      "Huan Xu"
    ]
  },
  "https://jmlr.org/papers/v18/16-100.html": {
    "title": "Uniform Hypergraph Partitioning: Provable Tensor Methods and Sampling Techniques",
    "volume": "main",
    "abstract": "In a series of recent works, we have generalised the consistency results in the stochastic block model literature to the case of uniform and non-uniform hypergraphs. The present paper continues the same line of study, where we focus on partitioning weighted uniform hypergraphs---a problem often encountered in computer vision. This work is motivated by two issues that arise when a hypergraph partitioning approach is used to tackle computer vision problems: (i) The uniform hypergraphs constructed for higher-order learning contain all edges, but most have negligible weights. Thus, the adjacency tensor is nearly sparse, and yet, not binary. (ii) A more serious concern is that standard partitioning algorithms need to compute all edge weights, which is computationally expensive for hypergraphs. This is usually resolved in practice by merging the clustering algorithm with a tensor sampling strategy---an approach that is yet to be analysed rigorously. We build on our earlier work on partitioning dense unweighted uniform hypergraphs (Ghoshdastidar and Dukkipati, ICML, 2015), and address the aforementioned issues by proposing provable and efficient partitioning algorithms. Our analysis justifies the empirical success of practical sampling techniques. We also complement our theoretical findings by elaborate empirical comparison of various hypergraph partitioning schemes",
    "checked": true,
    "id": "be849fbd09b263d2c5db0ab9a113002b2ef1d5d8",
    "semantic_title": "uniform hypergraph partitioning: provable tensor methods and sampling techniques",
    "citation_count": 41,
    "authors": [
      "Debarghya Ghoshdastidar",
      "Ambedkar Dukkipati"
    ]
  },
  "https://jmlr.org/papers/v18/16-146.html": {
    "title": "Reconstructing Undirected Graphs from Eigenspaces",
    "volume": "main",
    "abstract": "We aim at recovering the weighted adjacency matrix $\\mathsf{W}$ of an undirected graph from a perturbed version of its eigenspaces. This situation arises for instance when working with stationary signals on graphs or Markov chains observed at random times. Our approach relies on minimizing a cost function based on the Frobenius norm of the commutator $\\mathsf{A} \\mathsf{B}-\\mathsf{B} \\mathsf{A}$ between symmetric matrices $\\mathsf{A}$ and $\\mathsf{B}$. We describe a particular framework in which we have access to an estimation of the eigenspaces and provide support selection procedures from theoretical and practical points of view. In the ErdÅs-RÃ©nyi model on $N$ vertices with no self-loops, we show that identifiability (i.e., the ability to reconstruct $\\mathsf{W}$ from the knowledge of its eigenspaces) follows a sharp phase transition on the expected number of edges with threshold function $N\\log N/2$. Simulated and real life numerical experiments assert our methodology",
    "checked": true,
    "id": "89b3458006f056a840ea4f4960c6eab0968999dd",
    "semantic_title": "reconstructing undirected graphs from eigenspaces",
    "citation_count": 8,
    "authors": [
      "Yohann De Castro",
      "Thibault Espinasse",
      "Paul Rochet"
    ]
  },
  "https://jmlr.org/papers/v18/16-632.html": {
    "title": "An Optimal Algorithm for Bandit and Zero-Order Convex Optimization with Two-Point Feedback",
    "volume": "main",
    "abstract": "We consider the closely related problems of bandit convex optimization with two-point feedback, and zero-order stochastic convex optimization with two function evaluations per round. We provide a simple algorithm and analysis which is optimal for convex Lipschitz functions. This improves on Duchi et al. (2015), which only provides an optimal result for smooth functions; Moreover, the algorithm and analysis are simpler, and readily extend to non-Euclidean problems. The algorithm is based on a small but surprisingly powerful modification of the gradient estimator",
    "checked": true,
    "id": "436445b4cf3fe25e5778b5838eb623accad428e5",
    "semantic_title": "an optimal algorithm for bandit and zero-order convex optimization with two-point feedback",
    "citation_count": 212,
    "authors": [
      "Ohad Shamir"
    ]
  },
  "https://jmlr.org/papers/v18/17-061.html": {
    "title": "Perishability of Data: Dynamic Pricing under Varying-Coefficient Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "403594304795a58284fcb3c22e125bc8cae8236b",
    "semantic_title": "perishability of data: dynamic pricing under varying-coefficient models",
    "citation_count": 32,
    "authors": [
      "Adel Javanmard"
    ]
  },
  "https://jmlr.org/papers/v18/14-453.html": {
    "title": "Two New Approaches to Compressed Sensing Exhibiting Both Robust Sparse Recovery and the Grouping Effect",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9d1b887ce124edcf5906223e86f8c213f27d93fb",
    "semantic_title": "two new approaches to compressed sensing exhibiting both robust sparse recovery and the grouping effect",
    "citation_count": 19,
    "authors": [
      "Mehmet Eren Ahsen",
      "Niharika Challapalli",
      "Mathukumalli Vidyasagar"
    ]
  },
  "https://jmlr.org/papers/v18/15-495.html": {
    "title": "On the Consistency of Ordinal Regression Methods",
    "volume": "main",
    "abstract": "Many of the ordinal regression models that have been proposed in the literature can be seen as methods that minimize a convex surrogate of the zero-one, absolute, or squared loss functions. A key property that allows to study the statistical implications of such approximations is that of Fisher consistency. Fisher consistency is a desirable property for surrogate loss functions and implies that in the population setting, i.e., if the probability distribution that generates the data were available, then optimization of the surrogate would yield the best possible model. In this paper we will characterize the Fisher consistency of a rich family of surrogate loss functions used in the context of ordinal regression, including support vector ordinal regression, ORBoosting and least absolute deviation. We will see that, for a family of surrogate loss functions that subsumes support vector ordinal regression and ORBoosting, consistency can be fully characterized by the derivative of a real-valued function at zero, as happens for convex margin-based surrogates in binary classification. We also derive excess risk bounds for a surrogate of the absolute error that generalize existing risk bounds for binary classification. Finally, our analysis suggests a novel surrogate of the squared error loss. We compare this novel surrogate with competing approaches on 9 different datasets. Our method shows to be highly competitive in practice, outperforming the least squares loss on 7 out of 9 datasets",
    "checked": true,
    "id": "24def5b14643ab40ba1789e86c24516dd6d8a8fa",
    "semantic_title": "on the consistency of ordinal regression methods",
    "citation_count": 62,
    "authors": [
      "Fabian Pedregosa",
      "Francis Bach",
      "Alexandre Gramfort"
    ]
  },
  "https://jmlr.org/papers/v18/15-596.html": {
    "title": "Statistical Inference with Unnormalized Discrete Models and Localized Homogeneous Divergences",
    "volume": "main",
    "abstract": "In this paper, we focus on parameters estimation of probabilistic models in discrete space. A naive calculation of the normalization constant of the probabilistic model on discrete space is often infeasible and statistical inference based on such probabilistic models has difficulty. In this paper, we propose a novel estimator for probabilistic models on discrete space, which is derived from an empirically localized homogeneous divergence. The idea of the empirical localization makes it possible to ignore an unobserved domain on sample space, and the homogeneous divergence is a discrepancy measure between two positive measures and has a weak coincidence axiom. The proposed estimator can be constructed without calculating the normalization constant and is asymptotically consistent and Fisher efficient. We investigate statistical properties of the proposed estimator and reveal a relationship between the empirically localized homogeneous divergence and a mixture of the $\\alpha$-divergence. The $\\alpha$-divergence is a non- homogeneous discrepancy measure that is frequently discussed in the context of information geometry. Using the relationship, we also propose an asymptotically consistent estimator of the normalization constant. Experiments showed that the proposed estimator comparably performs to the maximum likelihood estimator but with drastically lower computational cost",
    "checked": true,
    "id": "1e2215a0eb75dc38b0126838f3234175090bdc78",
    "semantic_title": "statistical inference with unnormalized discrete models and localized homogeneous divergences",
    "citation_count": 8,
    "authors": [
      "Takashi Takenouchi",
      "Takafumi Kanamori"
    ]
  },
  "https://jmlr.org/papers/v18/16-011.html": {
    "title": "Density Estimation in Infinite Dimensional Exponential Families",
    "volume": "main",
    "abstract": "In this paper, we consider an infinite dimensional exponential family $\\mathcal{P}$ of probability densities, which are parametrized by functions in a reproducing kernel Hilbert space $\\mathcal{H}$, and show it to be quite rich in the sense that a broad class of densities on $\\mathbb{R}^d$ can be approximated arbitrarily well in Kullback-Leibler (KL) divergence by elements in $\\mathcal{P}$. Motivated by this approximation property, the paper addresses the question of estimating an unknown density $p_0$ through an element in $\\mathcal{P}$. Standard techniques like maximum likelihood estimation (MLE) or pseudo MLE (based on the method of sieves), which are based on minimizing the KL divergence between $p_0$ and $\\mathcal{P}$, do not yield practically useful estimators because of their inability to efficiently handle the log-partition function. We propose an estimator $\\hat{p}_n$ based on minimizing the Fisher divergence, $J(p_0\\Vert p)$ between $p_0$ and $p\\in \\mathcal{P}$, which involves solving a simple finite-dimensional linear system. When $p_0\\in\\mathcal{P}$, we show that the proposed estimator is consistent, and provide a convergence rate of $n^{-\\min\\left\\{\\frac{2}{3},\\frac{2\\beta+1}{2\\beta+2}\\right\\}}$ in Fisher divergence under the smoothness assumption that $\\log p_0\\in\\mathcal{R}(C^\\beta)$ for some $\\beta\\ge 0$, where $C$ is a certain Hilbert-Schmidt operator on $\\mathcal{H}$ and $\\mathcal{R}(C^\\beta)$ denotes the image of $C^\\beta$. We also investigate the misspecified case of $p_0\\notin\\mathcal{P}$ and show that $J(p_0\\Vert\\hat{p}_n)\\rightarrow \\inf_{p\\in\\mathcal{P}}J(p_0\\Vert p)$ as $n\\rightarrow \\infty$, and provide a rate for this convergence under a similar smoothness condition as above. Through numerical simulations we demonstrate that the proposed estimator outperforms the non- parametric kernel density estimator, and that the advantage of the proposed estimator grows as $d$ increases",
    "checked": true,
    "id": "21fafb9789b4c9ddfc324044868109b17419c914",
    "semantic_title": "density estimation in infinite dimensional exponential families",
    "citation_count": 119,
    "authors": [
      "Bharath Sriperumbudur",
      "Kenji Fukumizu",
      "Arthur Gretton",
      "Aapo Hyv\\\"{a}rinen",
      "Revant Kumar"
    ]
  },
  "https://jmlr.org/papers/v18/16-061.html": {
    "title": "Lens Depth Function and k-Relative Neighborhood Graph: Versatile Tools for Ordinal Data Analysis",
    "volume": "main",
    "abstract": "In recent years it has become popular to study machine learning problems in a setting of ordinal distance information rather than numerical distance measurements. By ordinal distance information we refer to binary answers to distance comparisons such as $d(A,B)<d(C,D)$. For many problems in machine learning and statistics it is unclear how to solve them in such a scenario. Up to now, the main approach is to explicitly construct an ordinal embedding of the data points in the Euclidean space, an approach that has a number of drawbacks. In this paper, we propose algorithms for the problems of medoid estimation, outlier identification, classification, and clustering when given only ordinal data. They are based on estimating the lens depth function and the $k$-relative neighborhood graph on a data set. Our algorithms are simple, are much faster than an ordinal embedding approach and avoid some of its drawbacks, and can easily be parallelized",
    "checked": true,
    "id": "5cb510ea5ab90fc34fb11d74cc23b248dd16515d",
    "semantic_title": "lens depth function and k-relative neighborhood graph: versatile tools for ordinal data analysis",
    "citation_count": 35,
    "authors": [
      "Matthäus Kleindessner",
      "Ulrike von Luxburg"
    ]
  },
  "https://jmlr.org/papers/v18/16-214.html": {
    "title": "Joint Label Inference in Networks",
    "volume": "main",
    "abstract": "We consider the problem of inferring node labels in a partially labeled graph where each node in the graph has multiple label types and each label type has a large number of possible labels. Our primary example, and the focus of this paper, is the joint inference of label types such as hometown, current city, and employers for people connected by a social network; by predicting these user profile fields, the network can provide a better experience to its users. Existing approaches such as Label Propagation (Zhu et al., 2003) fail to consider interactions between the label types. Our proposed method, called EDGEEXPLAIN explicitly models these interactions, while still allowing scalable inference under a distributed message- passing architecture. On a large subset of the Facebook social network, collected in a previous study (Chakrabarti et al., 2014), EDGEEXPLAIN outperforms label propagation for several label types, with lifts of up to $120\\%$ for recall@1 and $60\\%$ for recall@3",
    "checked": true,
    "id": "b7b4c93c8364c0629eecf94cdb9dae6b98d6810c",
    "semantic_title": "joint label inference in networks",
    "citation_count": 7,
    "authors": [
      "Deepayan Chakrabarti",
      "Stanislav Funiak",
      "Jonathan Chang",
      "Sofus A. Macskassy"
    ]
  },
  "https://jmlr.org/papers/v18/16-245.html": {
    "title": "Achieving Optimal Misclassification Proportion in Stochastic Block Models",
    "volume": "main",
    "abstract": "Community detection is a fundamental statistical problem in network data analysis. In this paper, we present a polynomial time two-stage method that provably achieves optimal statistical performance in misclassification proportion for stochastic block model under weak regularity conditions. Our two-stage procedure consists of a refinement stage motivated by penalized local maximum likelihood estimation. This stage can take a wide range of weakly consistent community detection procedures as its initializer, to which it applies and outputs a community assignment that achieves optimal misclassification proportion with high probability. The theoretical property is confirmed by simulated examples",
    "checked": true,
    "id": "60845819aeedbadda293b6098a8d712f86860981",
    "semantic_title": "achieving optimal misclassification proportion in stochastic block models",
    "citation_count": 227,
    "authors": [
      "Chao Gao",
      "Zongming Ma",
      "Anderson Y. Zhang",
      "Harrison H. Zhou"
    ]
  },
  "https://jmlr.org/papers/v18/16-497.html": {
    "title": "On the Propagation of Low-Rate Measurement Error to Subgraph Counts in Large Networks",
    "volume": "main",
    "abstract": "Our work in this paper is inspired by a statistical observation that is both elementary and broadly relevant to network analysis in practice---that the uncertainty in approximating some true graph $G=(V,E)$ by some estimated graph $\\hat{G}=(V,\\hat{E})$ manifests as errors in our knowledge of the presence/absence of edges between vertex pairs, which must necessarily propagate to any estimates of network summaries $\\eta(G)$ we seek. Motivated by the common practice of using plug-in estimates $\\eta(\\hat{G})$ as proxies for $\\eta(G)$, our focus is on the problem of characterizing the distribution of the discrepancy $D=\\eta(\\hat{G}) - \\eta(G)$, in the case where $\\eta(\\cdot)$ is a subgraph count. Specifically, we study the fundamental case where the statistic of interest is $|E|$, the number of edges in $G$. Our primary contribution in this paper is to show that in the empirically relevant setting of large graphs with low-rate measurement errors, the distribution of $D_E=|\\hat{E}| - |E|$ is well-characterized by a Skellam distribution, when the errors are independent or weakly dependent. Under an assumption of independent errors, we are able to further show conditions under which this characterization is strictly better than that of an appropriate normal distribution. These results derive from our formulation of a general result, quantifying the accuracy with which the difference of two sums of dependent Bernoulli random variables may be approximated by the difference of two independent Poisson random variables, i.e., by a Skellam distribution. This general result is developed through the use of Stein's method, and may be of some general interest. We finish with a discussion of possible extension of our work to subgraph counts $\\eta(G)$ of higher order",
    "checked": true,
    "id": "7dbe30a7e7dad2551c751fefb12d734856684ee5",
    "semantic_title": "on the propagation of low-rate measurement error to subgraph counts in large networks",
    "citation_count": 19,
    "authors": [
      "Prakash Balach",
      "ran",
      "Eric D. Kolaczyk",
      "Weston D. Viles"
    ]
  },
  "https://jmlr.org/papers/v18/16-526.html": {
    "title": "Dense Distributions from Sparse Samples: Improved Gibbs Sampling Parameter Estimators for LDA",
    "volume": "main",
    "abstract": "We introduce a novel approach for estimating Latent Dirichlet Allocation (LDA) parameters from collapsed Gibbs samples (CGS), by leveraging the full conditional distributions over the latent variable assignments to efficiently average over multiple samples, for little more computational cost than drawing a single additional collapsed Gibbs sample. Our approach can be understood as adapting the soft clustering methodology of Collapsed Variational Bayes (CVB0) to CGS parameter estimation, in order to get the best of both techniques. Our estimators can straightforwardly be applied to the output of any existing implementation of CGS, including modern accelerated variants. We perform extensive empirical comparisons of our estimators with those of standard collapsed inference algorithms on real-world data for both unsupervised LDA and Prior-LDA, a supervised variant of LDA for multi-label classification. Our results show a consistent advantage of our approach over traditional CGS under all experimental conditions, and over CVB0 inference in the majority of conditions. More broadly, our results highlight the importance of averaging over multiple samples in LDA parameter estimation, and the use of efficient computational techniques to do so",
    "checked": true,
    "id": "e77cbb9c8ae3a35bcef724b16bc43d5d561550aa",
    "semantic_title": "dense distributions from sparse samples: improved gibbs sampling parameter estimators for lda",
    "citation_count": 32,
    "authors": [
      "Yannis Papanikolaou",
      "James R. Foulds",
      "Timothy N. Rubin",
      "Grigorios Tsoumakas"
    ]
  },
  "https://jmlr.org/papers/v18/17-189.html": {
    "title": "Fundamental Conditions for Low-CP-Rank Tensor Completion",
    "volume": "main",
    "abstract": "We consider the problem of low canonical polyadic (CP) rank tensor completion. A completion is a tensor whose entries agree with the observed entries and its rank matches the given CP rank. We analyze the manifold structure corresponding to the tensors with the given rank and define a set of polynomials based on the sampling pattern and CP decomposition. Then, we show that finite completability of the sampled tensor is equivalent to having a certain number of algebraically independent polynomials among the defined polynomials. Our proposed approach results in characterizing the maximum number of algebraically independent polynomials in terms of a simple geometric structure of the sampling pattern, and therefore we obtain the deterministic necessary and sufficient condition on the sampling pattern for finite completability of the sampled tensor. Moreover, assuming that the entries of the tensor are sampled independently with probability $p$ and using the mentioned deterministic analysis, we propose a combinatorial method to derive a lower bound on the sampling probability $p$, or equivalently, the number of sampled entries that guarantees finite completability with high probability. We also show that the existing result for the matrix completion problem can be used to obtain a loose lower bound on the sampling probability $p$. In addition, we obtain deterministic and probabilistic conditions for unique completability. It is seen that the number of samples required for finite or unique completability obtained by the proposed analysis on the CP manifold is orders-of- magnitude lower than that is obtained by the existing analysis on the Grassmannian manifold",
    "checked": true,
    "id": "c897cee9b439e66408faa514d3c69b88051d3de6",
    "semantic_title": "fundamental conditions for low-cp-rank tensor completion",
    "citation_count": 48,
    "authors": [
      "Morteza Ashraphijuo",
      "Xiaodong Wang"
    ]
  },
  "https://jmlr.org/papers/v18/14-317.html": {
    "title": "Parallel Symmetric Class Expression Learning",
    "volume": "main",
    "abstract": "In machine learning, one often encounters data sets where a general pattern is violated by a relatively small number of exceptions (for example, a rule that says that all birds can fly is violated by examples such as penguins). This complicates the concept learning process and may lead to the rejection of some simple and expressive rules that cover many cases. In this paper we present an approach to this problem in description logic learning by computing partial descriptions (which are not necessarily entirely complete) of both positive and negative examples and combining them. Our Symmetric Parallel Class Expression Learning approach enables the generation of general rules with exception patterns included. We demonstrate that this algorithm provides significantly better results (in terms of metrics such as accuracy, search space covered, and learning time) than standard approaches on some typical data sets. Further, the approach has the added benefit that it can be parallelised relatively simply, leading to much faster exploration of the search tree on modern computers",
    "checked": true,
    "id": "9f2e72969b0a795d349c90ba6542217afa7202b6",
    "semantic_title": "parallel symmetric class expression learning",
    "citation_count": 20,
    "authors": [
      "An C. Tran",
      "Jens Dietrich",
      "Hans W. Guesgen",
      "Stephen Marsl,"
    ]
  },
  "https://jmlr.org/papers/v18/15-251.html": {
    "title": "Learning Partial Policies to Speedup MDP Tree Search via Reduction to I.I.D. Learning",
    "volume": "main",
    "abstract": "A popular approach for online decision-making in large MDPs is time-bounded tree search. The effectiveness of tree search, however, is largely influenced by the action branching factor, which limits the search depth given a time bound. An obvious way to reduce action branching is to consider only a subset of potentially good actions at each state as specified by a provided partial policy. In this work, we consider offline learning of such partial policies with the goal of speeding up search without significantly reducing decision-making quality. Our first contribution consists of reducing the learning problem to set learning. We give a reduction-style analysis of three such algorithms, each making different assumptions, which relates the set learning objectives to the sub-optimality of search using the learned partial policies. Our second contribution is to describe concrete implementations of the algorithms within the popular framework of Monte-Carlo tree search. Finally, the third contribution is to evaluate the learning algorithms on two challenging MDPs with large action branching factors. The results show that the learned partial policies can significantly improve the anytime performance of Monte-Carlo tree search",
    "checked": true,
    "id": "a9ba244c9abcefaa9f5758b8c31592db0be0188a",
    "semantic_title": "learning partial policies to speedup mdp tree search via reduction to i.i.d. learning",
    "citation_count": 10,
    "authors": [
      "Jervis Pinto",
      "Alan Fern"
    ]
  },
  "https://jmlr.org/papers/v18/15-376.html": {
    "title": "Hierarchically Compositional Kernels for Scalable Nonparametric Learning",
    "volume": "main",
    "abstract": "We propose a novel class of kernels to alleviate the high computational cost of large-scale nonparametric learning with kernel methods. The proposed kernel is defined based on a hierarchical partitioning of the underlying data domain, where the NystrÃ¶m method (a globally low-rank approximation) is married with a locally lossless approximation in a hierarchical fashion. The kernel maintains (strict) positive-definiteness. The corresponding kernel matrix admits a recursively off- diagonal low-rank structure, which allows for fast linear algebra computations. Suppressing the factor of data dimension, the memory and arithmetic complexities for training a regression or a classifier are reduced from $O(n^2)$ and $O(n^3)$ to $O(nr)$ and $O(nr^2)$, respectively, where $n$ is the number of training examples and $r$ is the rank on each level of the hierarchy. Although other randomized approximate kernels entail a similar complexity, empirical results show that the proposed kernel achieves a matching performance with a smaller $r$. We demonstrate comprehensive experiments to show the effective use of the proposed kernel on data sizes up to the order of millions",
    "checked": true,
    "id": "581ace3120b3ef3ae67496723f773117bf781260",
    "semantic_title": "hierarchically compositional kernels for scalable nonparametric learning",
    "citation_count": 24,
    "authors": [
      "Jie Chen",
      "Haim Avron",
      "Vikas Sindhwani"
    ]
  },
  "https://jmlr.org/papers/v18/15-482.html": {
    "title": "Sharp Oracle Inequalities for Square Root Regularization",
    "volume": "main",
    "abstract": "We study a set of regularization methods for high-dimensional linear regression models. These penalized estimators have the square root of the residual sum of squared errors as loss function, and any weakly decomposable norm as penalty function. This fit measure is chosen because of its property that the estimator does not depend on the unknown standard deviation of the noise. On the other hand, a generalized weakly decomposable norm penalty is very useful in being able to deal with different underlying sparsity structures. We can choose a different sparsity inducing norm depending on how we want to interpret the unknown parameter vector $\\beta$. Structured sparsity norms, as defined in Micchelli et al. (2010), are special cases of weakly decomposable norms, therefore we also include the square root LASSO (Belloni et al., 2011), the group square root LASSO (Bunea et al., 2014) and a new method called the square root SLOPE (in a similar fashion to the SLOPE from Bogdan et al. 2015). For this collection of estimators our results provide sharp oracle inequalities with the Karush-Kuhn-Tucker conditions. We discuss some examples of estimators. Based on a simulation we illustrate some advantages of the square root SLOPE",
    "checked": true,
    "id": "c0b7cf9b918ffbf7a990610235b0f5f82e7800df",
    "semantic_title": "sharp oracle inequalities for square root regularization",
    "citation_count": 29,
    "authors": [
      "Benjamin Stucky",
      "Sara van de Geer"
    ]
  },
  "https://jmlr.org/papers/v18/15-566.html": {
    "title": "Soft Margin Support Vector Classification as Buffered Probability Minimization",
    "volume": "main",
    "abstract": "In this paper, we show that the popular C-SVM, soft-margin support vector classifier is equivalent to minimization of Buffered Probability of Exceedance (bPOE), a recently introduced characterization of uncertainty. To show this, we introduce a new SVM formulation, called the EC-SVM, which is derived from a simple bPOE minimization problem that is easy to interpret with a meaningful free parameter, optimal objective value, and probabilistic derivation. Over the range of its free parameter, the EC-SVM has both a convex and non-convex case which we connect to existing SVM formulations. We first show that the C-SVM, formulated with any regularization norm, is equivalent to the convex EC-SVM. Similarly, we show that the E$\\nu$-SVM is equivalent to the EC-SVM over its entire parameter range, which includes both the convex and non-convex case. These equivalences, coupled with the interpretability of the EC-SVM, allow us to gain surprising new insights into the C-SVM and fully connect soft margin support vector classification with superquantile and bPOE concepts. We also show that the EC-SVM can easily be cast as a robust optimization problem, where bPOE is minimized with data lying in a fixed uncertainty set. This reformulation allows us to clearly differentiate between the convex and non-convex case, with convexity associated with pessimistic views of uncertainty and non-convexity associated with optimistic views of uncertainty. Finally, we address some practical considerations. First, we show that these new insights can assist in making parameter selection more efficient. Second, we discuss optimization approaches for solving the EC-SVM. Third, we address the issue of generalization, providing generalization bounds for both bPOE and misclassification rate",
    "checked": true,
    "id": "308467c72d9e3b812d76d9bec16edcaca5586231",
    "semantic_title": "soft margin support vector classification as buffered probability minimization",
    "citation_count": 22,
    "authors": [
      "Matthew Norton",
      "Alexander Mafusalov",
      "Stan Uryasev"
    ]
  },
  "https://jmlr.org/papers/v18/15-615.html": {
    "title": "Variational Particle Approximations",
    "volume": "main",
    "abstract": "Approximate inference in high-dimensional, discrete probabilistic models is a central problem in computational statistics and machine learning. This paper describes discrete particle variational inference (DPVI), a new approach that combines key strengths of Monte Carlo, variational and search- based techniques. DPVI is based on a novel family of particle- based variational approximations that can be fit using simple, fast, deterministic search techniques. Like Monte Carlo, DPVI can handle multiple modes, and yields exact results in a well- defined limit. Like unstructured mean-field, DPVI is based on optimizing a lower bound on the partition function; when this quantity is not of intrinsic interest, it facilitates convergence assessment and debugging. Like both Monte Carlo and combinatorial search, DPVI can take advantage of factorization, sequential structure, and custom search operators. This paper defines DPVI particle-based approximation family and partition function lower bounds, along with the sequential DPVI and local DPVI algorithm templates for optimizing them. DPVI is illustrated and evaluated via experiments on lattice Markov Random Fields, nonparametric Bayesian mixtures and block-models, and parametric as well as non-parametric hidden Markov models. Results include applications to real-world spike-sorting and relational modeling problems, and show that DPVI can offer appealing time/accuracy trade-offs as compared to multiple alternatives",
    "checked": true,
    "id": "c3048b130ed9a362e40bba0a66971663db1fec73",
    "semantic_title": "variational particle approximations",
    "citation_count": 56,
    "authors": [
      "Ardavan Saeedi",
      "Tejas D. Kulkarni",
      "Vikash K. Mansinghka",
      "Samuel J. Gershman"
    ]
  },
  "https://jmlr.org/papers/v18/16-003.html": {
    "title": "A Bayesian Framework for Learning Rule Sets for Interpretable Classification",
    "volume": "main",
    "abstract": "We present a machine learning algorithm for building classifiers that are comprised of a small number of short rules. These are restricted disjunctive normal form models. An example of a classifier of this form is as follows: If $X$ satisfies (condition $A$ AND condition $B$) OR (condition $C$) OR $\\cdots$, then $Y=1$. Models of this form have the advantage of being interpretable to human experts since they produce a set of rules that concisely describe a specific class. We present two probabilistic models with prior parameters that the user can set to encourage the model to have a desired size and shape, to conform with a domain-specific definition of interpretability. We provide a scalable MAP inference approach and develop theoretical bounds to reduce computation by iteratively pruning the search space. We apply our method (Bayesian Rule Sets -- BRS) to characterize and predict user behavior with respect to in-vehicle context-aware personalized recommender systems. Our method has a major advantage over classical associative classification methods and decision trees in that it does not greedily grow the model",
    "checked": true,
    "id": "8bd4850cc2ac1a328deaeb97bcc76fb43284d50a",
    "semantic_title": "a bayesian framework for learning rule sets for interpretable classification",
    "citation_count": 186,
    "authors": [
      "Tong Wang",
      "Cynthia Rudin",
      "Finale Doshi-Velez",
      "Yimin Liu",
      "Erica Klampfl",
      "Perry MacNeille"
    ]
  },
  "https://jmlr.org/papers/v18/16-079.html": {
    "title": "A Robust-Equitable Measure for Feature Ranking and Selection",
    "volume": "main",
    "abstract": "In many applications, not all the features used to represent data samples are important. Often only a few features are relevant for the prediction task. The choice of dependence measures often affect the final result of many feature selection methods. To select features that have complex nonlinear relationships with the response variable, the dependence measure should be equitable, a concept proposed by Reshef et al. (2011); that is, the dependence measure treats linear and nonlinear relationships equally. Recently, Kinney and Atwal (2014) gave a mathematical definition of self- equitability. In this paper, we introduce a new concept of robust-equitability and identify a robust- equitable copula dependence measure, the robust copula dependence (RCD) measure. RCD is based on the $L_1$-distance of the copula density from uniform and we show that it is equitable under both equitability definitions. We also prove theoretically that RCD is much easier to estimate than mutual information. Because of these theoretical properties, the RCD measure has the following advantages compared to existing dependence measures: it is robust to different relationship forms and robust to unequal sample sizes of different features. Experiments on both synthetic and real-world data sets confirm the theoretical analysis, and illustrate the advantage of using the dependence measure RCD for feature selection",
    "checked": true,
    "id": "2d9072ed612c1cecbf7acae29342ad7dc0a6f7cc",
    "semantic_title": "a robust-equitable measure for feature ranking and selection",
    "citation_count": 47,
    "authors": [
      "A. Adam Ding",
      "Jennifer G. Dy",
      "Yi Li",
      "Yale Chang"
    ]
  },
  "https://jmlr.org/papers/v18/16-108.html": {
    "title": "Multiscale Strategies for Computing Optimal Transport",
    "volume": "main",
    "abstract": "This paper presents a multiscale approach to efficiently compute approximate optimal transport plans between point sets. It is particularly well-suited for point sets that are in high- dimensions, but are close to being intrinsically low- dimensional. The approach is based on an adaptive multiscale decomposition of the point sets. The multiscale decomposition yields a sequence of optimal transport problems, that are solved in a top-to-bottom fashion from the coarsest to the finest scale. We provide numerical evidence that this multiscale approach scales approximately linearly, in time and memory, in the number of nodes, instead of quadratically or worse for a direct solution. Empirically, the multiscale approach results in less than one percent relative error in the objective function. Furthermore, the multiscale plans constructed are of interest by themselves as they may be used to introduce novel features and notions of distances between point sets. An analysis of sets of brain MRI based on optimal transport distances illustrates the effectiveness of the proposed method on a real world data set. The application demonstrates that multiscale optimal transport distances have the potential to improve on state-of-the-art metrics currently used in computational anatomy",
    "checked": true,
    "id": "a01d9d9c5915bcfd3458b19120f01dbd44633e0d",
    "semantic_title": "multiscale strategies for computing optimal transport",
    "citation_count": 32,
    "authors": [
      "Samuel Gerber",
      "Mauro Maggioni"
    ]
  },
  "https://jmlr.org/papers/v18/16-142.html": {
    "title": "Non-parametric Policy Search with Limited Information Loss",
    "volume": "main",
    "abstract": "Learning complex control policies from non-linear and redundant sensory input is an important challenge for reinforcement learning algorithms. Non-parametric methods that approximate values functions or transition models can address this problem, by adapting to the complexity of the data set. Yet, many current non-parametric approaches rely on unstable greedy maximization of approximate value functions, which might lead to poor convergence or oscillations in the policy update. A more robust policy update can be obtained by limiting the information loss between successive state-action distributions. In this paper, we develop a policy search algorithm with policy updates that are both robust and non-parametric. Our method can learn non- parametric control policies for infinite horizon continuous Markov decision processes with non-linear and redundant sensory representations. We investigate how we can use approximations of the kernel function to reduce the time requirements of the demanding non-parametric computations. In our experiments, we show the strong performance of the proposed method, and how it can be approximated efficiently. Finally, we show that our algorithm can learn a real-robot under-powered swing-up task directly from image data",
    "checked": true,
    "id": "f325b087b0a1a3995ea559aac42cd87c2a796b9a",
    "semantic_title": "non-parametric policy search with limited information loss",
    "citation_count": 27,
    "authors": [
      "Herke van Hoof",
      "Gerhard Neumann",
      "Jan Peters"
    ]
  },
  "https://jmlr.org/papers/v18/16-184.html": {
    "title": "Tests of Mutual or Serial Independence of Random Vectors with Applications",
    "volume": "main",
    "abstract": "The problem of testing mutual independence between many random vectors is addressed. The closely related problem of testing serial independence of a multivariate stationary sequence is also considered. The MÃ¶bius transformation of characteristic functions is used to characterize independence. A generalization to $p$ vectors of distance covariance and Hilbert-Schmidt independence criterion ($HSIC$) tests with the translation invariant kernel of a stable probability distribution is proposed. Both test statistics can be expressed in a simple form as a sum over all elements of a componentwise product of $p$ doubly-centered matrices. It is shown that an $HSIC$ statistic with sufficiently small scale parameters is equivalent to a distance covariance statistic. Consistency and weak convergence of both types of statistics are established. Approximation of $p$-values is made by randomization tests without recomputing interpoint distances for each randomized sample. The dependogram is adapted to the proposed tests for the graphical identification of sources of dependencies. Empirical rejection rates obtained through extensive simulations confirm both the applicability of the testing procedures in small samples and the high level of competitiveness in terms of power. Applications to meteorological and financial data provide some interesting interpretations of dependencies revealed by dependograms",
    "checked": true,
    "id": "f681220b3a123be2f27423e3aec5490bbe269d2d",
    "semantic_title": "tests of mutual or serial independence of random vectors with applications",
    "citation_count": 12,
    "authors": [
      "Martin Bilodeau",
      "Aurélien Guetsop Nangue"
    ]
  },
  "https://jmlr.org/papers/v18/16-258.html": {
    "title": "Recovering PCA and Sparse PCA via Hybrid-(l1,l2) Sparse Sampling of Data Elements",
    "volume": "main",
    "abstract": "This paper addresses how well we can recover a data matrix when only given a few of its elements. We present a randomized algorithm that element-wise sparsifies the data, retaining only a few of its entries. Our new algorithm independently samples the data using probabilities that depend on both squares ($\\ell_2$ sampling) and absolute values ($\\ell_1$ sampling) of the entries. We prove that this hybrid algorithm ($i$) achieves a near-PCA reconstruction of the data, and ($ii$) recovers sparse principal components of the data, from a sketch formed by a sublinear sample size. Hybrid-($\\ell_1,\\ell_2$) inherits the $\\ell_2$-ability to sample the important elements, as well as the regularization properties of $\\ell_1$ sampling, and maintains strictly better quality than either $\\ell_1$ or $\\ell_2$ on their own. Extensive experimental results on synthetic, image, text, biological, and financial data show that not only are we able to recover PCA and sparse PCA from incomplete data, but we can speed up such computations significantly using our sparse sketch",
    "checked": false,
    "id": "1c435d538ebcaf2361a89c3f77c568c5ec4eff1c",
    "semantic_title": "recovering pca and sparse pca via hybrid-(l1, l2) sparse sampling of data elements",
    "citation_count": 14,
    "authors": [
      "Abhisek Kundu",
      "Petros Drineas",
      "Malik Magdon-Ismail"
    ]
  },
  "https://jmlr.org/papers/v18/16-296.html": {
    "title": "Quantifying the Informativeness of Similarity Measurements",
    "volume": "main",
    "abstract": "In this paper, we describe an unsupervised measure for quantifying the 'informativeness' of correlation matrices formed from the pairwise similarities or relationships among data instances. The measure quantifies the heterogeneity of the correlations and is defined as the distance between a correlation matrix and the nearest correlation matrix with constant off-diagonal entries. This non-parametric notion generalizes existing test statistics for equality of correlation coefficients by allowing for alternative distance metrics, such as the Bures and other distances from quantum information theory. For several distance and dissimilarity metrics, we derive closed-form expressions of informativeness, which can be applied as objective functions for machine learning applications. Empirically, we demonstrate that informativeness is a useful criterion for selecting kernel parameters, choosing the dimension for kernel-based nonlinear dimensionality reduction, and identifying structured graphs. We also consider the problem of finding a maximally informative correlation matrix around a target matrix, and explore parameterizing the optimization in terms of the coordinates of the sample or through a lower-dimensional embedding. In the latter case, we find that maximizing the Bures-based informativeness measure, which is maximal for centered rank-1 correlation matrices, is equivalent to minimizing a specific matrix norm, and present an algorithm to solve the minimization problem using the norm's proximal operator. The proposed correlation denoising algorithm consistently improves spectral clustering. Overall, we find informativeness to be a novel and useful criterion for identifying non-trivial correlation structure",
    "checked": true,
    "id": "be6f7ff9724de39139a9a0bcb1cf73874fc7b5c0",
    "semantic_title": "quantifying the informativeness of similarity measurements",
    "citation_count": 14,
    "authors": [
      "Austin J. Brockmeier",
      "Tingting Mu",
      "Sophia Ananiadou",
      "John Y. Goulermas"
    ]
  },
  "https://jmlr.org/papers/v18/16-305.html": {
    "title": "Time for a Change: a Tutorial for Comparing Multiple Classifiers Through Bayesian Analysis",
    "volume": "main",
    "abstract": "The machine learning community adopted the use of null hypothesis significance testing (NHST) in order to ensure the statistical validity of results. Many scientific fields however realized the shortcomings of frequentist reasoning and in the most radical cases even banned its use in publications. We should do the same: just as we have embraced the Bayesian paradigm in the development of new machine learning methods, so we should also use it in the analysis of our own results. We argue for abandonment of NHST by exposing its fallacies and, more importantly, offer better---more sound and useful--- alternatives for it",
    "checked": true,
    "id": "8ce2c4a374e8b37e3eef080c956f22cfc6ea25d6",
    "semantic_title": "time for a change: a tutorial for comparing multiple classifiers through bayesian analysis",
    "citation_count": 357,
    "authors": [
      "Alessio Benavoli",
      "Giorgio Corani",
      "Janez Demšar",
      "Marco Zaffalon"
    ]
  },
  "https://jmlr.org/papers/v18/16-326.html": {
    "title": "Relational Reinforcement Learning for Planning with Exogenous Effects",
    "volume": "main",
    "abstract": "Probabilistic planners have improved recently to the point that they can solve difficult tasks with complex and expressive models. In contrast, learners cannot tackle yet the expressive models that planners do, which forces complex models to be mostly handcrafted. We propose a new learning approach that can learn relational probabilistic models with both action effects and exogenous effects. The proposed learning approach combines a multi-valued variant of inductive logic programming for the generation of candidate models, with an optimization method to select the best set of planning operators to model a problem. We also show how to combine this learner with reinforcement learning algorithms to solve complete problems. Finally, experimental validation is provided that shows improvements over previous work in both simulation and a robotic task. The robotic task involves a dynamic scenario with several agents where a manipulator robot has to clear the tableware on a table. We show that the exogenous effects learned by our approach allowed the robot to clear the table in a more efficient way",
    "checked": true,
    "id": "9f06375a01ffbdf1244e5217fdc8fb3d7b41cffb",
    "semantic_title": "relational reinforcement learning for planning with exogenous effects",
    "citation_count": 66,
    "authors": [
      "David Mart\\'{i}nez",
      "Guillem Aleny\\`{a}",
      "Tony Ribeiro",
      "Katsumi Inoue",
      "Carme Torras"
    ]
  },
  "https://jmlr.org/papers/v18/16-362.html": {
    "title": "Bayesian Tensor Regression",
    "volume": "main",
    "abstract": "We propose a Bayesian approach to regression with a scalar response on vector and tensor covariates. Vectorization of the tensor prior to analysis fails to exploit the structure, often leading to poor estimation and predictive performance. We introduce a novel class of multiway shrinkage priors for tensor coefficients in the regression setting and present posterior consistency results under mild conditions. A computationally efficient Markov chain Monte Carlo algorithm is developed for posterior computation. Simulation studies illustrate substantial gains over existing tensor regression methods in terms of estimation and parameter inference. Our approach is further illustrated in a neuroimaging application",
    "checked": true,
    "id": "03e2ba1bc02d230661adfcda9ed2953fb2d7f741",
    "semantic_title": "bayesian tensor regression",
    "citation_count": 100,
    "authors": [
      "Rajarshi Guhaniyogi",
      "Shaan Qamar",
      "David B. Dunson"
    ]
  },
  "https://jmlr.org/papers/v18/16-429.html": {
    "title": "Robust Discriminative Clustering with Sparse Regularizers",
    "volume": "main",
    "abstract": "Clustering high-dimensional data often requires some form of dimensionality reduction, where clustered variables are separated from noise-looking variables. We cast this problem as finding a low-dimensional projection of the data which is well-clustered. This yields a one-dimensional projection in the simplest situation with two clusters, and extends naturally to a multi-label scenario for more than two clusters. In this paper, (a) we first show that this joint clustering and dimension reduction formulation is equivalent to previously proposed discriminative clustering frameworks, thus leading to convex relaxations of the problem; (b) we propose a novel sparse extension, which is still cast as a convex relaxation and allows estimation in higher dimensions; (c) we propose a natural extension for the multi-label scenario; (d) we provide a new theoretical analysis of the performance of these formulations with a simple probabilistic model, leading to scalings over the form $d=O(\\sqrt{n})$ for the affine invariant case and $d=O(n)$ for the sparse case, where $n$ is the number of examples and $d$ the ambient dimension; and finally, (e) we propose an efficient iterative algorithm with running-time complexity proportional to $O(nd^2)$, improving on earlier algorithms for discriminative clustering with the square loss, which had quadratic complexity in the number of examples",
    "checked": true,
    "id": "df66473d58b0ab0aa5decea55e684fd94438b502",
    "semantic_title": "robust discriminative clustering with sparse regularizers",
    "citation_count": 18,
    "authors": [
      "Nicolas Flammarion",
      "Balamurugan Palaniappan",
      "Francis Bach"
    ]
  },
  "https://jmlr.org/papers/v18/16-466.html": {
    "title": "Making Decision Trees Feasible in Ultrahigh Feature and Label Dimensions",
    "volume": "main",
    "abstract": "Due to the non-linear but highly interpretable representations, decision tree (DT) models have significantly attracted a lot of attention of researchers. However, it is difficult to understand and interpret DT models in ultrahigh dimensions and DT models usually suffer from the curse of dimensionality and achieve degenerated performance when there are many noisy features. To address these issues, this paper first presents a novel data- dependent generalization error bound for the perceptron decision tree (PDT), which provides the theoretical justification to learn a sparse linear hyperplane in each decision node and to prune the tree. Following our analysis, we introduce the notion of budget-aware classifier (BAC) with a budget constraint on the weight coefficients, and propose a supervised budgeted tree (SBT) algorithm to achieve non-linear prediction performance. To avoid generating an unstable and complicated decision tree and improve the generalization of the SBT, we present a pruning strategy by learning classifiers to minimize cross-validation errors on each BAC. To deal with ultrahigh label dimensions, based on three important phenomena of real-world data sets from a variety of application domains, we develop a sparse coding tree framework for multi-label annotation problems and provide the theoretical analysis. Extensive empirical studies verify that 1) SBT is easy to understand and interpret in ultrahigh dimensions and is more resilient to noisy features. 2) Compared with state-of-the-art algorithms, our proposed sparse coding tree framework is more efficient, yet accurate in ultrahigh label and feature dimensions",
    "checked": true,
    "id": "70c2701361ff5e39ca5250069a1ac8dda4d4123f",
    "semantic_title": "making decision trees feasible in ultrahigh feature and label dimensions",
    "citation_count": 71,
    "authors": [
      "Weiwei Liu",
      "Ivor W. Tsang"
    ]
  },
  "https://jmlr.org/papers/v18/16-498.html": {
    "title": "Learning Scalable Deep Kernels with Recurrent Structure",
    "volume": "main",
    "abstract": "Many applications in speech, robotics, finance, and biology deal with sequential data, where ordering matters and recurrent structures are common. However, this structure cannot be easily captured by standard kernel functions. To model such structure, we propose expressive closed-form kernel functions for Gaussian processes. The resulting model, GP-LSTM, fully encapsulates the inductive biases of long short-term memory (LSTM) recurrent networks, while retaining the non-parametric probabilistic advantages of Gaussian processes. We learn the properties of the proposed kernels by optimizing the Gaussian process marginal likelihood using a new provably convergent semi-stochastic gradient procedure, and exploit the structure of these kernels for scalable training and prediction. This approach provides a practical representation for Bayesian LSTMs. We demonstrate state-of-the-art performance on several benchmarks, and thoroughly investigate a consequential autonomous driving application, where the predictive uncertainties provided by GP- LSTM are uniquely valuable",
    "checked": true,
    "id": "0f71a2b6e26a0b97364d221d55ccfd1956fcf0f2",
    "semantic_title": "learning scalable deep kernels with recurrent structure",
    "citation_count": 101,
    "authors": [
      "Maruan Al-Shedivat",
      "Andrew Gordon Wilson",
      "Yunus Saatchi",
      "Zhiting Hu",
      "Eric P. Xing"
    ]
  },
  "https://jmlr.org/papers/v18/16-505.html": {
    "title": "Convolutional Neural Networks Analyzed via Convolutional Sparse Coding",
    "volume": "main",
    "abstract": "Convolutional neural networks (CNN) have led to many state-of- the-art results spanning through various fields. However, a clear and profound theoretical understanding of the forward pass, the core algorithm of CNN, is still lacking. In parallel, within the wide field of sparse approximation, Convolutional Sparse Coding (CSC) has gained increasing attention in recent years. A theoretical study of this model was recently conducted, establishing it as a reliable and stable alternative to the commonly practiced patch-based processing. Herein, we propose a novel multi-layer model, ML-CSC, in which signals are assumed to emerge from a cascade of CSC layers. This is shown to be tightly connected to CNN, so much so that the forward pass of the CNN is in fact the thresholding pursuit serving the ML-CSC model. This connection brings a fresh view to CNN, as we are able to attribute to this architecture theoretical claims such as uniqueness of the representations throughout the network, and their stable estimation, all guaranteed under simple local sparsity conditions. Lastly, identifying the weaknesses in the above pursuit scheme, we propose an alternative to the forward pass, which is connected to deconvolutional and recurrent networks, and also has better theoretical guarantees",
    "checked": true,
    "id": "2ccdebc1ebfd103f6c97cd31059936e2e7c48dc1",
    "semantic_title": "convolutional neural networks analyzed via convolutional sparse coding",
    "citation_count": 259,
    "authors": [
      "Vardan Papyan",
      "Yaniv Romano",
      "Michael Elad"
    ]
  },
  "https://jmlr.org/papers/v18/16-568.html": {
    "title": "Stochastic Primal-Dual Coordinate Method for Regularized Empirical Risk Minimization",
    "volume": "main",
    "abstract": "We consider a generic convex optimization problem associated with regularized empirical risk minimization of linear predictors. The problem structure allows us to reformulate it as a convex-concave saddle point problem. We propose a stochastic primal-dual coordinate (SPDC) method, which alternates between maximizing over a randomly chosen dual variable and minimizing over the primal variables. An extrapolation step on the primal variables is performed to obtain accelerated convergence rate. We also develop a mini-batch version of the SPDC method which facilitates parallel computing, and an extension with weighted sampling probabilities on the dual variables, which has a better complexity than uniform sampling on unnormalized data. Both theoretically and empirically, we show that the SPDC method has comparable or better performance than several state-of-the-art optimization methods",
    "checked": true,
    "id": "75359c49a6abdd5fba642f46ec44812ed8e8a648",
    "semantic_title": "stochastic primal-dual coordinate method for regularized empirical risk minimization",
    "citation_count": 252,
    "authors": [
      "Yuchen Zhang",
      "Lin Xiao"
    ]
  },
  "https://jmlr.org/papers/v18/17-003.html": {
    "title": "Angle-based Multicategory Distance-weighted SVM",
    "volume": "main",
    "abstract": "Classification is an important supervised learning technique with numerous applications. We develop an angle-based multicategory distance-weighted support vector machine (MDWSVM) classification method that is motivated from the binary distance-weighted support vector machine (DWSVM) classification method. The new method has the merits of both support vector machine (SVM) and distance-weighted discrimination (DWD) but also alleviates both the data piling issue of SVM and the imbalanced data issue of DWD. Theoretical and numerical studies demonstrate the advantages of MDWSVM method over existing angle-based methods",
    "checked": true,
    "id": "a877b837fbb0942dd3eccc3c1a00d3bc2af16e52",
    "semantic_title": "angle-based multicategory distance-weighted svm",
    "citation_count": 9,
    "authors": [
      "Hui Sun",
      "Bruce A. Craig",
      "Lingsong Zhang"
    ]
  },
  "https://jmlr.org/papers/v18/17-032.html": {
    "title": "Minimax Estimation of Kernel Mean Embeddings",
    "volume": "main",
    "abstract": "In this paper, we study the minimax estimation of the Bochner integral \\[ \\mu_k(P) := \\int_\\mathcal{X} k(\\cdot,x)\\, dP(x), \\] also called the kernel mean embedding, based on random samples drawn i.i.d. from $P$, where $k:\\mathcal{X}\\times\\mathcal{X}\\rightarrow \\mathbb{R}$ is a positive definite kernel. Various estimators (including the empirical estimator), $\\hat{\\theta}_n$ of $\\mu_k(P)$ are studied in the literature wherein all of them satisfy $\\|\\hat{\\theta}_n-\\mu_k(P)\\|_{\\mathcal{H}_k}=O_P(n^{-1/2})$ with $\\mathcal{H}_k$ being the reproducing kernel Hilbert space induced by $k$. The main contribution of the paper is in showing that the above mentioned rate of $n^{-1/2}$ is minimax in $\\|\\cdot\\|_{\\mathcal{H}_k}$ and $\\|\\cdot\\|_{L^2(\\mathbb{R}^d)}$-norms over the class of discrete measures and the class of measures that has an infinitely differentiable density, with $k$ being a continuous translation- invariant kernel on $\\mathbb{R}^d$. The interesting aspect of this result is that the minimax rate is independent of the smoothness of the kernel and the density of $P$ (if it exists)",
    "checked": true,
    "id": "1911e2685d9b471203f53da4d437c9adcf406cac",
    "semantic_title": "minimax estimation of kernel mean embeddings",
    "citation_count": 76,
    "authors": [
      "Ilya Tolstikhin",
      "Bharath K. Sriperumbudur",
      "Krikamol Mu",
      "et"
    ]
  },
  "https://jmlr.org/papers/v18/17-039.html": {
    "title": "The Impact of Random Models on Clustering Similarity",
    "volume": "main",
    "abstract": "Clustering is a central approach for unsupervised learning. After clustering is applied, the most fundamental analysis is to quantitatively compare clusterings. Such comparisons are crucial for the evaluation of clustering methods as well as other tasks such as consensus clustering. It is often argued that, in order to establish a baseline, clustering similarity should be assessed in the context of a random ensemble of clusterings. The prevailing assumption for the random clustering ensemble is the permutation model in which the number and sizes of clusters are fixed. However, this assumption does not necessarily hold in practice; for example, multiple runs of K-means clustering reurns clusterings with a fixed number of clusters, while the cluster size distribution varies greatly. Here, we derive corrected variants of two clustering similarity measures (the Rand index and Mutual Information) in the context of two random clustering ensembles in which the number and sizes of clusters vary. In addition, we study the impact of one-sided comparisons in the scenario with a reference clustering. The consequences of different random models are illustrated using synthetic examples, handwriting recognition, and gene expression data. We demonstrate that the choice of random model can have a drastic impact on the ranking of similar clustering pairs, and the evaluation of a clustering method with respect to a random baseline; thus, the choice of random clustering model should be carefully justified",
    "checked": true,
    "id": "9e115c09286b51b20a40e59bffd5d7c7f063ecfe",
    "semantic_title": "the impact of random models on clustering similarity",
    "citation_count": 107,
    "authors": [
      "Alexander J. Gates",
      "Yong-Yeol Ahn"
    ]
  },
  "https://jmlr.org/papers/v18/17-081.html": {
    "title": "Hierarchical Clustering via Spreading Metrics",
    "volume": "main",
    "abstract": "We study the cost function for hierarchical clusterings introduced by (Dasgupta, 2016) where hierarchies are treated as first-class objects rather than deriving their cost from projections into flat clusters. It was also shown in (Dasgupta, 2016) that a top-down algorithm based on the uniform Sparsest Cut problem returns a hierarchical clustering of cost at most $O\\left(\\alpha_n \\log n\\right)$ times the cost of the optimal hierarchical clustering, where $\\alpha_n$ is the approximation ratio of the Sparsest Cut subroutine used. Thus using the best known approximation algorithm for Sparsest Cut due to Arora-Rao- Vazirani, the top-down algorithm returns a hierarchical clustering of cost at most $O\\left(\\log^{3/2} n\\right)$ times the cost of the optimal solution. We improve this by giving an $O(\\log{n})$-approximation algorithm for this problem. Our main technical ingredients are a combinatorial characterization of ultrametrics induced by this cost function, deriving an Integer Linear Programming (ILP) formulation for this family of ultrametrics, and showing how to iteratively round an LP relaxation of this formulation by using the idea of sphere growing which has been extensively used in the context of graph partitioning. We also prove that our algorithm returns an $O(\\log{n})$- approximate hierarchical clustering for a generalization of this cost function also studied in (Dasgupta, 2016). Experiments show that the hierarchies found by using the ILP formulation as well as our rounding algorithm often have better projections into flat clusters than the standard linkage based algorithms. We conclude with constant factor inapproximability results for this problem: 1) no polynomial size LP or SDP can achieve a constant factor approximation for this problem and 2) no polynomial time algorithm can achieve a constant factor approximation under the Small Set Expansion hypothesis",
    "checked": true,
    "id": "24bdbbfa99c2d951e7d684100cd5b2f70a7a8b56",
    "semantic_title": "hierarchical clustering via spreading metrics",
    "citation_count": 70,
    "authors": [
      "Aurko Roy",
      "Sebastian Pokutta"
    ]
  },
  "https://jmlr.org/papers/v18/17-156.html": {
    "title": "The MADP Toolbox: An Open Source Library for Planning and Learning in (Multi-)Agent Systems",
    "volume": "MLOSS",
    "abstract": "This article describes the Multiagent Decision Process (MADP) Toolbox, a software library to support planning and learning for intelligent agents and multiagent systems in uncertain environments. Key features are that it supports partially observable environments and stochastic transition models; has unified support for single- and multiagent systems; provides a large number of models for decision-theoretic decision making, including one-shot and sequential decision making under various assumptions of observability and cooperation, such as Dec-POMDPs and POSGs; provides tools and parsers to quickly prototype new problems; provides an extensive range of planning and learning algorithms for single- and multiagent systems; is released under the GNU GPL v3 license; and is written in C++ and designed to be extensible via the object-oriented paradigm",
    "checked": true,
    "id": "9e239bf2deca8a875751f7193f8a3d1c3567b7ed",
    "semantic_title": "the madp toolbox: an open source library for planning and learning in (multi-)agent systems",
    "citation_count": 20,
    "authors": [
      "Frans A. Oliehoek",
      "Matthijs T. J. Spaan",
      "Bas Terwijn",
      "Philipp Robbel",
      "Jo\\~{a}o V. Messias"
    ]
  },
  "https://jmlr.org/papers/v18/14-428.html": {
    "title": "A survey of Algorithms and Analysis for Adaptive Online Learning",
    "volume": "main",
    "abstract": "We present tools for the analysis of Follow-The-Regularized- Leader (FTRL), Dual Averaging, and Mirror Descent algorithms when the regularizer (equivalently, prox-function or learning rate schedule) is chosen adaptively based on the data. Adaptivity can be used to prove regret bounds that hold on every round, and also allows for data-dependent regret bounds as in AdaGrad-style algorithms (e.g., Online Gradient Descent with adaptive per-coordinate learning rates). We present results from a large number of prior works in a unified manner, using a modular and tight analysis that isolates the key arguments in easily re-usable lemmas. This approach strengthens previously known FTRL analysis techniques to produce bounds as tight as those achieved by potential functions or primal-dual analysis. Further, we prove a general and exact equivalence between adaptive Mirror Descent algorithms and a corresponding FTRL update, which allows us to analyze Mirror Descent algorithms in the same framework. The key to bridging the gap between Dural Averaging and Mirror Descent algorithms lies in an analysis of the FTRL-Proximal algorithm family. Our regret bounds are proved in the most general form, holding for arbitrary norms and non- smooth regularizers with time-varying weight",
    "checked": true,
    "id": "b86524dd0e2eba0f1b6e56bd2b1c0b0fcd28d60b",
    "semantic_title": "a survey of algorithms and analysis for adaptive online learning",
    "citation_count": 175,
    "authors": [
      "H. Brendan McMahan"
    ]
  },
  "https://jmlr.org/papers/v18/14-484.html": {
    "title": "A distributed block coordinate descent method for training l1 regularized linear classifiers",
    "volume": "main",
    "abstract": "Distributed training of $l_1$ regularized classifiers has received great attention recently. Most existing methods approach this problem by taking steps obtained from approximating the objective by a quadratic approximation that is decoupled at the individual variable level. These methods are designed for multicore systems where communication costs are low. They are inefficient on systems such as Hadoop running on a cluster of commodity machines where communication costs are substantial. In this paper we design a distributed algorithm for $l_1$ regularization that is much better suited for such systems than existing algorithms. A careful cost analysis is used to support these points and motivate our method. The main idea of our algorithm is to do block optimization of many variables on the actual objective function within each computing node; this increases the computational cost per step that is matched with the communication cost, and decreases the number of outer iterations, thus yielding a faster overall method. Distributed Gauss-Seidel and Gauss-Southwell greedy schemes are used for choosing variables to update in each step. We establish global convergence theory for our algorithm, including Q-linear rate of convergence. Experiments on two benchmark problems show our method to be much faster than existing methods",
    "checked": false,
    "id": "0a0db79baaa21d33b53ccb565ded1c7f8cfe0ded",
    "semantic_title": "a dual augmented block minimization framework for learning with limited memory",
    "citation_count": 6,
    "authors": [
      "Dhruv Mahajan",
      "S. Sathiya Keerthi",
      "S. Sundararajan"
    ]
  },
  "https://jmlr.org/papers/v18/15-586.html": {
    "title": "Distributed Learning with Regularized Least Squares",
    "volume": "main",
    "abstract": "We study distributed learning with the least squares regularization scheme in a reproducing kernel Hilbert space (RKHS). By a divide-and-conquer approach, the algorithm partitions a data set into disjoint data subsets, applies the least squares regularization scheme to each data subset to produce an output function, and then takes an average of the individual output functions as a final global estimator or predictor. We show with error bounds and learning rates in expectation in both the $L^2$-metric and RKHS-metric that the global output function of this distributed learning is a good approximation to the algorithm processing the whole data in one single machine. Our derived learning rates in expectation are optimal and stated in a general setting without any eigenfunction assumption. The analysis is achieved by a novel second order decomposition of operator differences in our integral operator approach. Even for the classical least squares regularization scheme in the RKHS associated with a general kernel, we give the best learning rate in expectation in the literature",
    "checked": true,
    "id": "c1a46d9a0972fb0ec0977d24a191f612e7401369",
    "semantic_title": "distributed learning with regularized least squares",
    "citation_count": 177,
    "authors": [
      "Shao-Bo Lin",
      "Xin Guo",
      "Ding-Xuan Zhou"
    ]
  },
  "https://jmlr.org/papers/v18/15-650.html": {
    "title": "Identifying Unreliable and Adversarial Workers in Crowdsourced Labeling Tasks",
    "volume": "main",
    "abstract": "We study the problem of identifying unreliable and adversarial workers in crowdsourcing systems where workers (or users) provide labels for tasks (or items). Most existing studies assume that worker responses follow specific probabilistic models; however, recent evidence shows the presence of workers adopting non-random or even malicious strategies. To account for such workers, we suppose that workers comprise a mixture of honest and adversarial workers. Honest workers may be reliable or unreliable, and they provide labels according to an unknown but explicit probabilistic model. Adversaries adopt labeling strategies different from those of honest workers, whether probabilistic or not. We propose two reputation algorithms to identify unreliable honest workers and adversarial workers from only their responses. Our algorithms assume that honest workers are in the majority, and they classify workers with outlier label patterns as adversaries. Theoretically, we show that our algorithms successfully identify unreliable honest workers, workers adopting deterministic strategies, and worst- case sophisticated adversaries who can adopt arbitrary labeling strategies to degrade the accuracy of the inferred task labels. Empirically, we show that filtering out outliers using our algorithms can significantly improve the accuracy of several state-of-the-art label aggregation algorithms in real-world crowdsourcing datasets",
    "checked": true,
    "id": "3233a971dc5fee45568f63f6b6a1cac1d1ada66f",
    "semantic_title": "identifying unreliable and adversarial workers in crowdsourced labeling tasks",
    "citation_count": 32,
    "authors": [
      "Srikanth Jagabathula",
      "Lakshminarayanan Subramanian",
      "Ashwin Venkataraman"
    ]
  },
  "https://jmlr.org/papers/v18/16-212.html": {
    "title": "An Easy-to-hard Learning Paradigm for Multiple Classes and Multiple Labels",
    "volume": "main",
    "abstract": "Many applications, such as human action recognition and object detection, can be formulated as a multiclass classification problem. One-vs-rest (OVR) is one of the most widely used approaches for multiclass classification due to its simplicity and excellent performance. However, many confusing classes in such applications will degrade its results. For example, hand clap and boxing are two confusing actions. Hand clap is easily misclassified as boxing, and vice versa. Therefore, precisely classifying confusing classes remains a challenging task. To obtain better performance for multiclass classifications that have confusing classes, we first develop a classifier chain model for multiclass classification (CCMC) to transfer class information between classifiers. Then, based on an analysis of our proposed model, we propose an easy- to-hard learning paradigm for multiclass classification to automatically identify easy and hard classes and then use the predictions from simpler classes to help solve harder classes. Similar to CCMC, the classifier chain (CC) model is also proposed by Read et al. (2009) to capture the label dependency for multi-label classification. However, CC does not consider the order of difficulty of the labels and achieves degenerated performance when there are many confusing labels. Therefore, it is non- trivial to learn the appropriate label order for CC. Motivated by our analysis for CCMC, we also propose the easy-to-hard learning paradigm for multi-label classification to automatically identify easy and hard labels, and then use the predictions from simpler labels to help solve harder labels. We also demonstrate that our proposed strategy can be successfully applied to a wide range of applications, such as ordinal classification and relationship prediction. Extensive empirical studies validate our analysis and the effectiveness of our proposed easy-to-hard learning strategies",
    "checked": true,
    "id": "d602ddda1727cc41394ac71f9d418786788d6931",
    "semantic_title": "an easy-to-hard learning paradigm for multiple classes and multiple labels",
    "citation_count": 91,
    "authors": [
      "Weiwei Liu",
      "Ivor W. Tsang",
      "Klaus-Robert M\\\"{u}ller"
    ]
  },
  "https://jmlr.org/papers/v18/17-048.html": {
    "title": "Fisher Consistency for Prior Probability Shift",
    "volume": "main",
    "abstract": "We introduce Fisher consistency in the sense of unbiasedness as a desirable property for estimators of class prior probabilities. Lack of Fisher consistency could be used as a criterion to dismiss estimators that are unlikely to deliver precise estimates in test data sets under prior probability and more general data set shift. The usefulness of this unbiasedness concept is demonstrated with three examples of classifiers used for quantification: Adjusted Count, EM-algorithm and CDE- Iterate. We find that Adjusted Count and EM-algorithm are Fisher consistent. A counter-example shows that CDE-Iterate is not Fisher consistent and, therefore, cannot be trusted to deliver reliable estimates of class probabilities",
    "checked": true,
    "id": "0cda0e817717478b58c7b6b222f8344d8ff8ac8b",
    "semantic_title": "fisher consistency for prior probability shift",
    "citation_count": 38,
    "authors": [
      "Dirk Tasche"
    ]
  },
  "https://jmlr.org/papers/v18/17-113.html": {
    "title": "openXBOW -- Introducing the Passau Open-Source Crossmodal Bag-of-Words Toolkit",
    "volume": "MLOSS",
    "abstract": "We introduce openXBOW, an open-source toolkit for the generation of bag-of-words (BoW) representations from multimodal input. In the BoW principle, word histograms were first used as features in document classification, but the idea was and can easily be adapted to, e.g., acoustic or visual descriptors, introducing a prior step of vector quantisation. The openXBOW toolkit supports arbitrary numeric input features and text input and concatenates computed sub-bags to a final bag. It provides a variety of extensions and options. To our knowledge, openXBOW is the first publicly available toolkit for the generation of crossmodal bags-of-words. The capabilities of the tool have been exemplified in different scenarios: sentiment analysis in tweets, classification of snore sounds, and time-dependent emotion recognition based on acoustic, linguistic, and visual information, where improved results over other feature representations were observed",
    "checked": false,
    "id": "16cfa5ab8025bccca5c6bd07b62f7716d6926ade",
    "semantic_title": "openxbow - introducing the passau open-source crossmodal bag-of-words toolkit",
    "citation_count": 168,
    "authors": [
      "Maximilian Schmitt",
      "Björn Schuller"
    ]
  },
  "https://jmlr.org/papers/v18/17-176.html": {
    "title": "Optimal Rates for Multi-pass Stochastic Gradient Methods",
    "volume": "main",
    "abstract": "We analyze the learning properties of the stochastic gradient method when multiple passes over the data and mini-batches are allowed. We study how regularization properties are controlled by the step-size, the number of passes and the mini-batch size. In particular, we consider the square loss and show that for a universal step-size choice, the number of passes acts as a regularization parameter, and optimal finite sample bounds can be achieved by early-stopping. Moreover, we show that larger step-sizes are allowed when considering mini-batches. Our analysis is based on a unifying approach, encompassing both batch and stochastic gradient methods as special cases. As a byproduct, we derive optimal convergence results for batch gradient methods (even in the non-attainable cases)",
    "checked": true,
    "id": "f053f86502b6d9f025f2dc957c756155536241e4",
    "semantic_title": "optimal rates for multi-pass stochastic gradient methods",
    "citation_count": 70,
    "authors": [
      "Junhong Lin",
      "Lorenzo Rosasco"
    ]
  },
  "https://jmlr.org/papers/v18/17-375.html": {
    "title": "Rank Determination for Low-Rank Data Completion",
    "volume": "main",
    "abstract": "Recently, fundamental conditions on the sampling patterns have been obtained for finite completability of low-rank matrices or tensors given the corresponding ranks. In this paper, we consider the scenario where the rank is not given and we aim to approximate the unknown rank based on the location of sampled entries and some given completion. We consider a number of data models, including single-view matrix, multi-view matrix, CP tensor, tensor-train tensor and Tucker tensor. For each of these data models, we provide an upper bound on the rank when an arbitrary low-rank completion is given. We characterize these bounds both deterministically, i.e., with probability one given that the sampling pattern satisfies certain combinatorial properties, and probabilistically, i.e., with high probability given that the sampling probability is above some threshold. Moreover, for both single-view matrix and CP tensor, we are able to show that the obtained upper bound is exactly equal to the unknown rank if the lowest-rank completion is given. Furthermore, we provide numerical experiments for the case of single-view matrix, where we use nuclear norm minimization to find a low-rank completion of the sampled data and we observe that in most of the cases the proposed upper bound on the rank is equal to the true rank",
    "checked": true,
    "id": "256720dfa089f3cef74621f2df5373771bcda15c",
    "semantic_title": "rank determination for low-rank data completion",
    "citation_count": 20,
    "authors": [
      "Morteza Ashraphijuo",
      "Xiaodong Wang",
      "Vaneet Aggarwal"
    ]
  },
  "https://jmlr.org/papers/v18/17-033.html": {
    "title": "Bayesian Network Learning via Topological Order",
    "volume": "main",
    "abstract": "We propose a mixed integer programming (MIP) model and iterative algorithms based on topological orders to solve optimization problems with acyclic constraints on a directed graph. The proposed MIP model has a significantly lower number of constraints compared to popular MIP models based on cycle elimination constraints and triangular inequalities. The proposed iterative algorithms use gradient descent and iterative reordering approaches, respectively, for searching topological orders. A computational experiment is presented for the Gaussian Bayesian network learning problem, an optimization problem minimizing the sum of squared errors of regression models with L1 penalty over a feature network with application of gene network inference in bioinformatics",
    "checked": true,
    "id": "ad9be2c7a8a9952d28243b4758192e96ffbb08ae",
    "semantic_title": "bayesian network learning via topological order",
    "citation_count": 26,
    "authors": [
      "Young Woong Park",
      "Diego Klabjan"
    ]
  },
  "https://jmlr.org/papers/v18/16-590.html": {
    "title": "Stability of Controllers for Gaussian Process Dynamics",
    "volume": "main",
    "abstract": "Learning control has become an appealing alternative to the derivation of control laws based on classic control theory. However, a major shortcoming of learning control is the lack of performance guarantees which prevents its application in many real-world scenarios. As a step towards widespread deployment of learning control, we provide stability analysis tools for controllers acting on dynamics represented by Gaussian processes (GPs). We consider differentiable Markovian control policies and system dynamics given as (i) the mean of a GP, and (ii) the full GP distribution. For both cases, we analyze finite and infinite time horizons. Furthermore, we study the effect of disturbances on the stability results. Empirical evaluations on simulated benchmark problems support our theoretical results",
    "checked": true,
    "id": "2ab73b9498c9b3dac7819d9744c9ca1c88c774f0",
    "semantic_title": "stability of controllers for gaussian process dynamics",
    "citation_count": 29,
    "authors": [
      "Julia Vinogradska",
      "Bastian Bischoff",
      "Duy Nguyen-Tuong",
      "Jan Peters"
    ]
  },
  "https://jmlr.org/papers/v18/16-335.html": {
    "title": "Harder, Better, Faster, Stronger Convergence Rates for Least-Squares Regression",
    "volume": "main",
    "abstract": "We consider the optimization of a quadratic objective function whose gradients are only accessible through a stochastic oracle that returns the gradient at any given point plus a zero-mean finite variance random error. We present the first algorithm that achieves jointly the optimal prediction error rates for least-squares regression, both in terms of forgetting the initial conditions in $O(1/n^2)$, and in terms of dependence on the noise and dimension $d$ of the problem, as $O(d/n)$. Our new algorithm is based on averaged accelerated regularized gradient descent, and may also be analyzed through finer assumptions on initial conditions and the Hessian matrix, leading to dimension- free quantities that may still be small in some distances while the âoptimalâ terms above are large. In order to characterize the tightness of these new bounds, we consider an application to non-parametric regression and use the known lower bounds on the statistical performance (without computational limits), which happen to match our bounds obtained from a single pass on the data and thus show optimality of our algorithm in a wide variety of particular trade-offs between bias and variance",
    "checked": true,
    "id": "9ffc2368a492669f1c330e3d787c04878d9c8ab7",
    "semantic_title": "harder, better, faster, stronger convergence rates for least-squares regression",
    "citation_count": 208,
    "authors": [
      "Aymeric Dieuleveut",
      "Nicolas Flammarion",
      "Francis Bach"
    ]
  },
  "https://jmlr.org/papers/v18/16-596.html": {
    "title": "Confidence Sets with Expected Sizes for Multiclass Classification",
    "volume": "main",
    "abstract": "Multiclass classification problems such as image annotation can involve a large number of classes. In this context, confusion between classes can occur, and single label classification may be misleading. We provide in the present paper a general device that, given an unlabeled dataset and a score function defined as the minimizer of some empirical and convex risk, outputs a set of class labels, instead of a single one. Interestingly, this procedure does not require that the unlabeled dataset explores the whole classes. Even more, the method is calibrated to control the expected size of the output set while minimizing the classification risk. We show the statistical optimality of the procedure and establish rates of convergence under the Tsybakov margin condition. It turns out that these rates are linear on the number of labels. We apply our methodology to convex aggregation of confidence sets based on the $V$-fold cross validation principle also known as the superlearning principle (van der Laan et al., 2007). We illustrate the numerical performance of the procedure on real data and demonstrate in particular that with moderate expected size, w.r.t. the number of labels, the procedure provides significant improvement of the classification risk",
    "checked": true,
    "id": "5e715aa7f7154405bf797589cdc5b965c083e696",
    "semantic_title": "confidence sets with expected sizes for multiclass classification",
    "citation_count": 25,
    "authors": [
      "Christophe Denis",
      "Mohamed Hebiri"
    ]
  },
  "https://jmlr.org/papers/v18/16-285.html": {
    "title": "Online Learning to Rank with Top-k Feedback",
    "volume": "main",
    "abstract": "We consider two settings of online learning to rank where feedback is restricted to top ranked items. The problem is cast as an online game between a learner and sequence of users, over $T$ rounds. In both settings, the learners objective is to present ranked list of items to the users. The learner's performance is judged on the entire ranked list and true relevances of the items. However, the learner receives highly restricted feedback at end of each round, in form of relevances of only the top $k$ ranked items, where $k \\ll m$. The first setting is non-contextual, where the list of items to be ranked is fixed. The second setting is contextual, where lists of items vary, in form of traditional query-document lists. No stochastic assumption is made on the generation process of relevances of items and contexts. We provide efficient ranking strategies for both the settings. The strategies achieve $O(T^{2/3})$ regret, where regret is based on popular ranking measures in first setting and ranking surrogates in second setting. We also provide impossibility results for certain ranking measures and a certain class of surrogates, when feedback is restricted to the top ranked item, i.e. $k=1$. We empirically demonstrate the performance of our algorithms on simulated and real world data sets",
    "checked": true,
    "id": "a95a776a5b0f0fbfa7def13b56304c7d4218218d",
    "semantic_title": "online learning to rank with top-k feedback",
    "citation_count": 11,
    "authors": [
      "Sougata Chaudhuri",
      "Ambuj Tewari"
    ]
  },
  "https://jmlr.org/papers/v18/16-603.html": {
    "title": "A Unifying Framework for Gaussian Process Pseudo-Point Approximations using Power Expectation Propagation",
    "volume": "main",
    "abstract": "Gaussian processes (GPs) are flexible distributions over functions that enable high-level assumptions about unknown functions to be encoded in a parsimonious, flexible and general way. Although elegant, the application of GPs is limited by computational and analytical intractabilities that arise when data are sufficiently numerous or when employing non-Gaussian models. Consequently, a wealth of GP approximation schemes have been developed over the last 15 years to address these key limitations. Many of these schemes employ a small set of pseudo data points to summarise the actual data. In this paper we develop a new pseudo-point approximation framework using Power Expectation Propagation (Power EP) that unifies a large number of these pseudo-point approximations. Unlike much of the previous venerable work in this area, the new framework is built on standard methods for approximate inference (variational free- energy, EP and Power EP methods) rather than employing approximations to the probabilistic generative model itself. In this way all of the approximation is performed at `inference time' rather than at `modelling time', resolving awkward philosophical and empirical questions that trouble previous approaches. Crucially, we demonstrate that the new framework includes new pseudo-point approximation methods that outperform current approaches on regression and classification tasks",
    "checked": true,
    "id": "9e333f1918a7363494d1142ade0d4ef47437030d",
    "semantic_title": "a unifying framework for gaussian process pseudo-point approximations using power expectation propagation",
    "citation_count": 127,
    "authors": [
      "Thang D. Bui",
      "Josiah Yan",
      "Richard E. Turner"
    ]
  },
  "https://jmlr.org/papers/v18/16-504.html": {
    "title": "Accelerating Stochastic Composition Optimization",
    "volume": "main",
    "abstract": "We consider the stochastic nested composition optimization problem where the objective is a composition of two expected- value functions. We propose a new stochastic first-order method, namely the accelerated stochastic compositional proximal gradient (ASC-PG) method. This algorithm updates the solution based on noisy gradient queries using a two-timescale iteration. The ASC-PG is the first proximal gradient method for the stochastic composition problem that can deal with nonsmooth regularization penalty. We show that the ASC-PG exhibits faster convergence than the best known algorithms, and that it achieves the optimal sample-error complexity in several important special cases. We demonstrate the application of ASC-PG to reinforcement learning and conduct numerical experiments",
    "checked": true,
    "id": "d53d179dfba4804799278fcefa414c2017f391dc",
    "semantic_title": "accelerating stochastic composition optimization",
    "citation_count": 134,
    "authors": [
      "Mengdi Wang",
      "Ji Liu",
      "Ethan X. Fang"
    ]
  },
  "https://jmlr.org/papers/v18/16-478.html": {
    "title": "Distributed Bayesian Learning with Stochastic Natural Gradient Expectation Propagation and the Posterior Server",
    "volume": "main",
    "abstract": "This paper makes two contributions to Bayesian machine learning algorithms. Firstly, we propose stochastic natural gradient expectation propagation (SNEP), a novel alternative to expectation propagation (EP), a popular variational inference algorithm. SNEP is a black box variational algorithm, in that it does not require any simplifying assumptions on the distribution of interest, beyond the existence of some Monte Carlo sampler for estimating the moments of the EP tilted distributions. Further, as opposed to EP which has no guarantee of convergence, SNEP can be shown to be convergent, even when using Monte Carlo moment estimates. Secondly, we propose a novel architecture for distributed Bayesian learning which we call the posterior server. The posterior server allows scalable and robust Bayesian learning in cases where a data set is stored in a distributed manner across a cluster, with each compute node containing a disjoint subset of data. An independent Monte Carlo sampler is run on each compute node, with direct access only to the local data subset, but which targets an approximation to the global posterior distribution given all data across the whole cluster. This is achieved by using a distributed asynchronous implementation of SNEP to pass messages across the cluster. We demonstrate SNEP and the posterior server on distributed Bayesian learning of logistic regression and neural networks",
    "checked": true,
    "id": "56d355e49d96d2d1873af5834b9378e2a411e360",
    "semantic_title": "distributed bayesian learning with stochastic natural gradient expectation propagation and the posterior server",
    "citation_count": 61,
    "authors": [
      "Leonard Hasenclever",
      "Stefan Webb",
      "Thibaut Lienart",
      "Sebastian Vollmer",
      "Balaji Lakshminarayanan",
      "Charles Blundell",
      "Yee Whye Teh"
    ]
  },
  "https://jmlr.org/papers/v18/16-046.html": {
    "title": "Optimal Dictionary for Least Squares Representation",
    "volume": "main",
    "abstract": "Dictionaries are collections of vectors used for the representation of a class of vectors in Euclidean spaces. Recent research on optimal dictionaries is focused on constructing dictionaries that offer sparse representations, i.e., $\\ell_0$-optimal representations. Here we consider the problem of finding optimal dictionaries with which representations of a given class of vectors is optimal in an $\\ell_2$-sense: optimality of representation is defined as attaining the minimal average $\\ell_2$-norm of the coefficients used to represent the vectors in the given class. With the help of recent results on rank-1 decompositions of symmetric positive semidefinite matrices, we provide an explicit description of $\\ell_2$-optimal dictionaries as well as their algorithmic constructions in polynomial time",
    "checked": true,
    "id": "158f24e318639c1686859f8a4a7bc2ec596f4939",
    "semantic_title": "optimal dictionary for least squares representation",
    "citation_count": 7,
    "authors": [
      "Mohammed Rayyan Sheriff",
      "Debasish Chatterjee"
    ]
  },
  "https://jmlr.org/papers/v18/16-289.html": {
    "title": "Computational Limits of A Distributed Algorithm for Smoothing Spline",
    "volume": "main",
    "abstract": "In this paper, we explore statistical versus computational trade-off to address a basic question in the application of a distributed algorithm: what is the minimal computational cost in obtaining statistical optimality? In smoothing spline setup, we observe a phase transition phenomenon for the number of deployed machines that ends up being a simple proxy for computing cost. Specifically, a sharp upper bound for the number of machines is established: when the number is below this bound, statistical optimality (in terms of nonparametric estimation or testing) is achievable; otherwise, statistical optimality becomes impossible. These sharp bounds partly capture intrinsic computational limits of the distributed algorithm considered in this paper, and turn out to be fully determined by the smoothness of the regression function. We name the asymptotic analysis on such split-and-aggregation estimation/inference as splitotic theory. As a side remark, we argue that sample splitting may be viewed as an alternative form of regularization, playing a similar role as smoothing parameter",
    "checked": true,
    "id": "509ba8fc524d48f14821531617cdf26d55ac7f51",
    "semantic_title": "computational limits of a distributed algorithm for smoothing spline",
    "citation_count": 52,
    "authors": [
      "Zuofeng Shang",
      "Guang Cheng"
    ]
  },
  "https://jmlr.org/papers/v18/15-631.html": {
    "title": "Hinge-Loss Markov Random Fields and Probabilistic Soft Logic",
    "volume": "main",
    "abstract": "A fundamental challenge in developing high-impact machine learning technologies is balancing the need to model rich, structured domains with the ability to scale to big data. Many important problem areas are both richly structured and large scale, from social and biological networks, to knowledge graphs and the Web, to images, video, and natural language. In this paper, we introduce two new formalisms for modeling structured data, and show that they can both capture rich structure and scale to big data. The first, hinge-loss Markov random fields (HL-MRFs), is a new kind of probabilistic graphical model that generalizes different approaches to convex inference. We unite three approaches from the randomized algorithms, probabilistic graphical models, and fuzzy logic communities, showing that all three lead to the same inference objective. We then define HL- MRFs by generalizing this unified objective. The second new formalism, probabilistic soft logic (PSL), is a probabilistic programming language that makes HL-MRFs easy to define using a syntax based on first-order logic. We introduce an algorithm for inferring most-probable variable assignments (MAP inference) that is much more scalable than general-purpose convex optimization methods, because it uses message passing to take advantage of sparse dependency structures. We then show how to learn the parameters of HL-MRFs. The learned HL-MRFs are as accurate as analogous discrete models, but much more scalable. Together, these algorithms enable HL-MRFs and PSL to model rich, structured data at scales not previously possible",
    "checked": false,
    "id": "550f7dba7757f22afd87786749509574609d6180",
    "semantic_title": "hinge-loss markov random fields and probabilistic soft logic: a scalable approach to structured prediction",
    "citation_count": 362,
    "authors": [
      "Stephen H. Bach",
      "Matthias Broecheler",
      "Bert Huang",
      "Lise Getoor"
    ]
  },
  "https://jmlr.org/papers/v18/16-342.html": {
    "title": "Clustering with Hidden Markov Model on Variable Blocks",
    "volume": "main",
    "abstract": "Large-scale data containing multiple important rare clusters, even at moderately high dimensions, pose challenges for existing clustering methods. To address this issue, we propose a new mixture model called Hidden Markov Model on Variable Blocks (HMM-VB) and a new mode search algorithm called Modal Baum-Welch (MBW) for mode-association clustering. HMM-VB leverages prior information about chain-like dependence among groups of variables to achieve the effect of dimension reduction. In case such a dependence structure is unknown or assumed merely for the sake of parsimonious modeling, we develop a recursive search algorithm based on BIC to optimize the formation of ordered variable blocks. The MBW algorithm ensures the feasibility of clustering via mode association, achieving linear complexity in terms of the number of variable blocks despite the exponentially growing number of possible state sequences in HMM-VB. In addition, we provide theoretical investigations about the identifiability of HMM-VB as well as the consistency of our approach to search for the block partition of variables in a special case. Experiments on simulated and real data show that our proposed method outperforms other widely used methods",
    "checked": true,
    "id": "ba606ac6a5fca8cd4899aa7adaeed0a61f9365f7",
    "semantic_title": "clustering with hidden markov model on variable blocks",
    "citation_count": 6,
    "authors": [
      "Lin Lin",
      "Jia Li"
    ]
  },
  "https://jmlr.org/papers/v18/16-191.html": {
    "title": "Approximation Vector Machines for Large-scale Online Learning",
    "volume": "main",
    "abstract": "One of the most challenging problems in kernel online learning is to bound the model size and to promote model sparsity. Sparse models not only improve computation and memory usage, but also enhance the generalization capacity -- a principle that concurs with the law of parsimony. However, inappropriate sparsity modeling may also significantly degrade the performance. In this paper, we propose Approximation Vector Machine (AVM), a model that can simultaneously encourage sparsity and safeguard its risk in compromising the performance. In an online setting context, when an incoming instance arrives, we approximate this instance by one of its neighbors whose distance to it is less than a predefined threshold. Our key intuition is that since the newly seen instance is expressed by its nearby neighbor the optimal performance can be analytically formulated and maintained. We develop theoretical foundations to support this intuition and further establish an analysis for the common loss functions including Hinge, smooth Hinge, and Logistic (i.e., for the classification task) and $\\ell_{1}$, $\\ell_{2}$, and $\\varepsilon$-insensitive (i.e., for the regression task) to characterize the gap between the approximation and optimal solutions. This gap crucially depends on two key factors including the frequency of approximation (i.e., how frequent the approximation operation takes place) and the predefined threshold. We conducted extensive experiments for classification and regression tasks in batch and online modes using several benchmark datasets. The quantitative results show that our proposed AVM obtained comparable predictive performances with current state-of-the-art methods while simultaneously achieving significant computational speed-up due to the ability of the proposed AVM in maintaining the model size",
    "checked": true,
    "id": "129df08120e9d74bdc8648f876e9852175f22b5d",
    "semantic_title": "approximation vector machines for large-scale online learning",
    "citation_count": 24,
    "authors": [
      "Trung Le",
      "Tu Dinh Nguyen",
      "Vu Nguyen",
      "Dinh Phung"
    ]
  },
  "https://jmlr.org/papers/v18/14-223.html": {
    "title": "Efficient Sampling from Time-Varying Log-Concave Distributions",
    "volume": "main",
    "abstract": "We propose a computationally efficient random walk on a convex body which rapidly mixes with respect to a fixed log-concave distribution and closely tracks a time-varying log-concave distribution. We develop general theoretical guarantees on the required number of steps; this number can be calculated on the fly according to the distance from and the shape of the next distribution. We then illustrate the technique on several examples. Within the context of exponential families, the proposed method produces samples from a posterior distribution which is updated as data arrive in a streaming fashion. The sampling technique can be used to track time-varying truncated distributions, as well as to obtain samples from a changing mixture model, fitted in a streaming fashion to data. In the setting of linear optimization, the proposed method has oracle complexity with best known dependence on the dimension for certain geometries. In the context of online learning and repeated games, the algorithm is an efficient method for implementing no-regret mixture forecasting strategies. Remarkably, in some of these examples, only one step of the random walk is needed to track the next distribution",
    "checked": true,
    "id": "60eecd70439ba37a26579a6cd132a5389e829937",
    "semantic_title": "efficient sampling from time-varying log-concave distributions",
    "citation_count": 46,
    "authors": [
      "Hariharan Narayanan",
      "Alexer Rakhlin"
    ]
  },
  "https://jmlr.org/papers/v18/16-017.html": {
    "title": "Document Neural Autoregressive Distribution Estimation",
    "volume": "main",
    "abstract": "We present an approach based on feed-forward neural networks for learning the distribution over textual documents. This approach is inspired by the Neural Autoregressive Distribution Estimator (NADE) model which has been shown to be a good estimator of the distribution over discrete-valued high-dimensional vectors. In this paper, we present how NADE can successfully be adapted to textual data, retaining the property that sampling or computing the probability of an observation can be done exactly and efficiently. The approach can also be used to learn deep representations of documents that are competitive to those learned by alternative topic modeling approaches. Finally, we describe how the approach can be combined with a regular neural network N-gram model and substantially improve its performance, by making its learned representation sensitive to the larger, document-level context",
    "checked": true,
    "id": "5ea43195b341621da3642598749f91804e62ceb7",
    "semantic_title": "document neural autoregressive distribution estimation",
    "citation_count": 27,
    "authors": [
      "Stanislas Lauly",
      "Yin Zheng",
      "Alex",
      "re Allauzen",
      "Hugo Larochelle"
    ]
  },
  "https://jmlr.org/papers/v18/17-007.html": {
    "title": "Target Curricula via Selection of Minimum Feature Sets: a Case Study in Boolean Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7ef0e4c805ee61ae013f13b247ba8d58ca36cf81",
    "semantic_title": "target curricula via selection of minimum feature sets: a case study in boolean networks",
    "citation_count": 2,
    "authors": [
      "Shannon Fenn",
      "Pablo Moscato"
    ]
  },
  "https://jmlr.org/papers/v18/16-463.html": {
    "title": "A General Distributed Dual Coordinate Optimization Framework for Regularized Loss Minimization",
    "volume": "main",
    "abstract": "In modern large-scale machine learning applications, the training data are often partitioned and stored on multiple machines. It is customary to employ the data parallelism approach, where the aggregated training loss is minimized without moving data across machines. In this paper, we introduce a novel distributed dual formulation for regularized loss minimization problems that can directly handle data parallelism in the distributed setting. This formulation allows us to systematically derive dual coordinate optimization procedures, which we refer to as Distributed Alternating Dual Maximization (DADM). The framework extends earlier studies described in (Boyd et al., 2011; Ma et al., 2017; Jaggi et al., 2014; Yang, 2013) and has rigorous theoretical analyses. Moreover, with the help of the new formulation, we develop the accelerated version of DADM (Acc-DADM) by generalizing the acceleration technique from (Shalev-Shwartz and Zhang, 2014) to the distributed setting. We also provide theoretical results for the proposed accelerated version, and the new result improves previous ones (Yang, 2013; Ma et al., 2017) whose iteration complexities grow linearly on the condition number. Our empirical studies validate our theory and show that our accelerated approach significantly improves the previous state- of-the-art distributed dual coordinate optimization algorithms",
    "checked": true,
    "id": "0e4ba334d7edadbea528055b43c2c3e3ffd5a5a4",
    "semantic_title": "a general distributed dual coordinate optimization framework for regularized loss minimization",
    "citation_count": 22,
    "authors": [
      "Shun Zheng",
      "Jialei Wang",
      "Fen Xia",
      "Wei Xu",
      "Tong Zhang"
    ]
  },
  "https://jmlr.org/papers/v18/16-491.html": {
    "title": "Second-Order Stochastic Optimization for Machine Learning in Linear Time",
    "volume": "main",
    "abstract": "First-order stochastic methods are the state-of-the-art in large-scale machine learning optimization owing to efficient per-iteration complexity. Second-order methods, while able to provide faster convergence, have been much less explored due to the high cost of computing the second-order information. In this paper we develop second-order stochastic methods for optimization problems in machine learning that match the per- iteration cost of gradient based methods, and in certain settings improve upon the overall running time over popular first-order methods. Furthermore, our algorithm has the desirable property of being implementable in time linear in the sparsity of the input data",
    "checked": true,
    "id": "f3ed7343727361a25e77fdef315850bdaf29d20e",
    "semantic_title": "second-order stochastic optimization for machine learning in linear time",
    "citation_count": 187,
    "authors": [
      "Naman Agarwal",
      "Brian Bullins",
      "Elad Hazan"
    ]
  },
  "https://jmlr.org/papers/v18/17-055.html": {
    "title": "Regularized Estimation and Testing for High-Dimensional Multi-Block Vector-Autoregressive Models",
    "volume": "main",
    "abstract": "Dynamical systems comprising of multiple components that can be partitioned into distinct blocks originate in many scientific areas. A pertinent example is the interactions between financial assets and selected macroeconomic indicators, which has been studied at aggregate level---e.g. a stock index and an employment index---extensively in the macroeconomics literature. A key shortcoming of this approach is that it ignores potential influences from other related components (e.g. Gross Domestic Product) that may impact the system's dynamics and structure and thus produces incorrect results. To mitigate this issue, we consider a multi-block linear dynamical system with Granger-causal ordering between blocks, wherein the blocks' temporal dynamics are described by vector autoregressive processes and are influenced by blocks higher in the system hierarchy. We derive the maximum likelihood estimator for the posited model for Gaussian data in the high- dimensional setting based on appropriate regularization schemes for the parameters of the block components. To optimize the underlying non-convex likelihood function, we develop an iterative algorithm with convergence guarantees. We establish theoretical properties of the maximum likelihood estimates, leveraging the decomposability of the regularizers and a careful analysis of the iterates. Finally, we develop testing procedures for the null hypothesis of whether a block Granger-causes another block of variables. The performance of the model and the testing procedures are evaluated on synthetic data, and illustrated on a data set involving log-returns of the US S&P100 component stocks and key macroeconomic variables for the 2001--16 period",
    "checked": true,
    "id": "04a78e3d452b2c5241e30d03afe265366fadacac",
    "semantic_title": "regularized estimation and testing for high-dimensional multi-block vector-autoregressive models",
    "citation_count": 41,
    "authors": [
      "Jiahe Lin",
      "George Michailidis"
    ]
  },
  "https://jmlr.org/papers/v18/17-423.html": {
    "title": "Learning Theory of Distributed Regression with Bias Corrected Regularization Kernel Network",
    "volume": "main",
    "abstract": "Distributed learning is an effective way to analyze big data. In distributed regression, a typical approach is to divide the big data into multiple blocks, apply a base regression algorithm on each of them, and then simply average the output functions learnt from these blocks. Since the average process will decrease the variance, not the bias, bias correction is expected to improve the learning performance if the base regression algorithm is a biased one. Regularization kernel network is an effective and widely used method for nonlinear regression analysis. In this paper we will investigate a bias corrected version of regularization kernel network. We derive the error bounds when it is applied to a single data set and when it is applied as a base algorithm in distributed regression. We show that, under certain appropriate conditions, the optimal learning rates can be reached in both situations",
    "checked": true,
    "id": "2b0afb1b62147b2767c781cf7a758a013c95ae05",
    "semantic_title": "learning theory of distributed regression with bias corrected regularization kernel network",
    "citation_count": 40,
    "authors": [
      "Zheng-Chu Guo",
      "Lei Shi",
      "Qiang Wu"
    ]
  },
  "https://jmlr.org/papers/v18/17-049.html": {
    "title": "Probabilistic Line Searches for Stochastic Optimization",
    "volume": "main",
    "abstract": "In deterministic optimization, line searches are a standard tool ensuring stability and efficiency. Where only stochastic gradients are available, no direct equivalent has so far been formulated, because uncertain gradients do not allow for a strict sequence of decisions collapsing the search space. We construct a probabilistic line search by combining the structure of existing deterministic methods with notions from Bayesian optimization. Our method retains a Gaussian process surrogate of the univariate optimization objective, and uses a probabilistic belief over the Wolfe conditions to monitor the descent. The algorithm has very low computational cost, and no user- controlled parameters. Experiments show that it effectively removes the need to define a learning rate for stochastic gradient descent",
    "checked": true,
    "id": "c94e0f79f030d142f9c2b9274cbeacaa019231b1",
    "semantic_title": "probabilistic line searches for stochastic optimization",
    "citation_count": 123,
    "authors": [
      "Maren Mahsereci",
      "Philipp Hennig"
    ]
  },
  "https://jmlr.org/papers/v18/17-014.html": {
    "title": "Learning Instrumental Variables with Structural and Non-Gaussianity Assumptions",
    "volume": "main",
    "abstract": "Learning a causal effect from observational data requires strong assumptions. One possible method is to use instrumental variables, which are typically justified by background knowledge. It is possible, under further assumptions, to discover whether a variable is structurally instrumental to a target causal effect $X \\rightarrow Y$. However, the few existing approaches are lacking on how general these assumptions can be, and how to express possible equivalence classes of solutions. We present instrumental variable discovery methods that systematically characterize which set of causal effects can and cannot be discovered under local graphical criteria that define instrumental variables, without reconstructing full causal graphs. We also introduce the first methods to exploit non-Gaussianity assumptions, highlighting identifiability problems and solutions. Due to the difficulty of estimating such models from finite data, we investigate how to strengthen assumptions in order to make the statistical problem more manageable",
    "checked": true,
    "id": "d603cc8ae3cfa9418499443f25034359fa8afd17",
    "semantic_title": "learning instrumental variables with structural and non-gaussianity assumptions",
    "citation_count": 17,
    "authors": [
      "Ricardo Silva",
      "Shohei Shimizu"
    ]
  },
  "https://jmlr.org/papers/v18/15-403.html": {
    "title": "Classification of Time Sequences using Graphs of Temporal Constraints",
    "volume": "main",
    "abstract": "We introduce two algorithms that learn to classify Symbolic and Scalar Time Sequences (SSTS); an extension of multivariate time series. An SSTS is a set of \\emph{events} and a set of scalars. An event is defined by a symbol and a time-stamp. A scalar is defined by a symbol and a function mapping a number for each possible time stamp of the data. The proposed algorithms rely on temporal patterns called Graph of Temporal Constraints (GTC). A GTC is a directed graph in which vertices express occurrences of specific events, and edges express temporal constraints between occurrences of pairs of events. Additionally, each vertex of a GTC can be augmented with numeric constraints on scalar values. We allow GTCs to be cyclic and/or disconnected. The first of the introduced algorithms extracts sets of co-dependent GTCs to be used in a voting mechanism. The second algorithm builds decision forest like representations where each node is a GTC. In both algorithms, extraction of GTCs and model building are interleaved. Both algorithms are closely related to each other and they exhibit complementary properties including complexity, performance, and interpretability. The main novelties of this work reside in direct building of the model and efficient learning of GTC structures. We explain the proposed algorithms and evaluate their performance against a diverse collection of 59 benchmark data sets. In these experiments, our algorithms come across as highly competitive and in most cases closely match or outperform state-of-the-art alternatives in terms of the computational speed while dominating in terms of the accuracy of classification of time sequences",
    "checked": true,
    "id": "b7891d44a1bcd11d5fea06d7d0f1ebadf8beb3be",
    "semantic_title": "classification of time sequences using graphs of temporal constraints",
    "citation_count": 35,
    "authors": [
      "Mathieu Guillame-Bert",
      "Artur Dubrawski"
    ]
  },
  "https://jmlr.org/papers/v18/16-640.html": {
    "title": "Distributed Stochastic Variance Reduced Gradient Methods by Sampling Extra Data with Replacement",
    "volume": "main",
    "abstract": "We study the round complexity of minimizing the average of convex functions under a new setting of distributed optimization where each machine can receive two subsets of functions. The first subset is from a random partition and the second subset is randomly sampled with replacement. Under this setting, we define a broad class of distributed algorithms whose local computation can utilize both subsets and design a distributed stochastic variance reduced gradient method belonging to in this class. When the condition number of the problem is small, our method achieves the optimal parallel runtime, amount of communication and rounds of communication among all distributed first-order methods up to constant factors. When the condition number is relatively large, a lower bound is provided for the number of rounds of communication needed by any algorithm in this class. Then, we present an accelerated version of our method whose the rounds of communication matches the lower bound up to logarithmic terms, which establishes that this accelerated algorithm has the lowest round complexity among all algorithms in our class under this new setting",
    "checked": true,
    "id": "49a0450f5760f8d36bc696a71cace7622145c207",
    "semantic_title": "distributed stochastic variance reduced gradient methods by sampling extra data with replacement",
    "citation_count": 30,
    "authors": [
      "Jason D. Lee",
      "Qihang Lin",
      "Tengyu Ma",
      "Tianbao Yang"
    ]
  },
  "https://jmlr.org/papers/v18/17-306.html": {
    "title": "Kernel Partial Least Squares for Stationary Data",
    "volume": "main",
    "abstract": "We consider the kernel partial least squares algorithm for non- parametric regression with stationary dependent data. Probabilistic convergence rates of the kernel partial least squares estimator to the true regression function are established under a source and an effective dimensionality condition. It is shown both theoretically and in simulations that long range dependence results in slower convergence rates. A protein dynamics example shows high predictive power of kernel partial least squares",
    "checked": true,
    "id": "b025dd91ab89703557f1cfc98dd405065a405723",
    "semantic_title": "kernel partial least squares for stationary data",
    "citation_count": 4,
    "authors": [
      "Marco Singer",
      "Tatyana Krivobokova",
      "Axel Munk"
    ]
  },
  "https://jmlr.org/papers/v18/16-655.html": {
    "title": "Robust and Scalable Bayes via a Median of Subset Posterior Measures",
    "volume": "main",
    "abstract": "We propose a novel approach to Bayesian analysis that is provably robust to outliers in the data and often has computational advantages over standard methods. Our technique is based on splitting the data into non-overlapping subgroups, evaluating the posterior distribution given each independent subgroup, and then combining the resulting measures. The main novelty of our approach is the proposed aggregation step, which is based on the evaluation of a median in the space of probability measures equipped with a suitable collection of distances that can be quickly and efficiently evaluated in practice. We present both theoretical and numerical evidence illustrating the improvements achieved by our method",
    "checked": true,
    "id": "f3e7f7d55495cca618a90055246defe4b22235d3",
    "semantic_title": "robust and scalable bayes via a median of subset posterior measures",
    "citation_count": 100,
    "authors": [
      "Stanislav Minsker",
      "Sanvesh Srivastava",
      "Lizhen Lin",
      "David B. Dunson"
    ]
  },
  "https://jmlr.org/papers/v18/16-093.html": {
    "title": "Statistical and Computational Guarantees for the Baum-Welch Algorithm",
    "volume": "main",
    "abstract": "The Hidden Markov Model (HMM) is one of the mainstays of statistical modeling of discrete time series, with applications including speech recognition, computational biology, computer vision and econometrics. Estimating an HMM from its observation process is often addressed via the Baum-Welch algorithm, which is known to be susceptible to local optima. In this paper, we first give a general characterization of the basin of attraction associated with any global optimum of the population likelihood. By exploiting this characterization, we provide non-asymptotic finite sample guarantees on the Baum-Welch updates and show geometric convergence to a small ball of radius on the order of the minimax rate around a global optimum. As a concrete example, we prove a linear rate of convergence for a hidden Markov mixture of two isotropic Gaussians given a suitable mean separation and an initialization within a ball of large radius around (one of) the true parameters. To our knowledge, these are the first rigorous local convergence guarantees to global optima for the Baum-Welch algorithm in a setting where the likelihood function is nonconvex. We complement our theoretical results with thorough numerical simulations studying the convergence of the Baum-Welch algorithm and illustrating the accuracy of our predictions",
    "checked": true,
    "id": "5b433f3304a9628153ed91669cf9a623636adc84",
    "semantic_title": "statistical and computational guarantees for the baum-welch algorithm",
    "citation_count": 36,
    "authors": [
      "Fanny Yang",
      "Sivaraman Balakrishnan",
      "Martin J. Wainwright"
    ]
  },
  "https://jmlr.org/papers/v18/16-374.html": {
    "title": "Online but Accurate Inference for Latent Variable Models with Local Gibbs Sampling",
    "volume": "main",
    "abstract": "We study parameter inference in large-scale latent variable models. We first propose a unified treatment of online inference for latent variable models from a non-canonical exponential family, and draw explicit links between several previously proposed frequentist or Bayesian methods. We then propose a novel inference method for the frequentist estimation of parameters, that adapts MCMC methods to online inference of latent variable models with the proper use of local Gibbs sampling. Then, for latent Dirichlet allocation,we provide an extensive set of experiments and comparisons with existing work, where our new approach outperforms all previously proposed methods. In particular, using Gibbs sampling for latent variable inference is superior to variational inference in terms of test log-likelihoods. Moreover, Bayesian inference through variational methods perform poorly, sometimes leading to worse fits with latent variables of higher dimensionality",
    "checked": true,
    "id": "c547533ec65a44fef542d3a3696f12b71cb0c676",
    "semantic_title": "online but accurate inference for latent variable models with local gibbs sampling",
    "citation_count": 16,
    "authors": [
      "Christophe Dupuy",
      "Francis Bach"
    ]
  },
  "https://jmlr.org/papers/v18/16-541.html": {
    "title": "Poisson Random Fields for Dynamic Feature Models",
    "volume": "main",
    "abstract": "We present the Wright-Fisher Indian buffet process (WF- IBP), a probabilistic model for time-dependent data assumed to have been generated by an unknown number of latent features. This model is suitable as a prior in Bayesian nonparametric feature allocation models in which the features underlying the observed data exhibit a dependency structure over time. More specifically, we establish a new framework for generating dependent Indian buffet processes, where the Poisson random field model from population genetics is used as a way of constructing dependent beta processes. Inference in the model is complex, and we describe a sophisticated Markov Chain Monte Carlo algorithm for exact posterior simulation. We apply our construction to develop a nonparametric focused topic model for collections of time-stamped text documents and test it on the full corpus of NIPS papers published from 1987 to 2015",
    "checked": true,
    "id": "bfca83a1791ab542ed94060330f95844e92966e0",
    "semantic_title": "poisson random fields for dynamic feature models",
    "citation_count": 52,
    "authors": [
      "Valerio Perrone",
      "Paul A. Jenkins",
      "Dario Spanò",
      "Yee Whye Teh"
    ]
  },
  "https://jmlr.org/papers/v18/16-577.html": {
    "title": "Gap Safe Screening Rules for Sparsity Enforcing Penalties",
    "volume": "main",
    "abstract": "In high dimensional regression settings, sparsity enforcing penalties have proved useful to regularize the data-fitting term. A recently introduced technique called screening rules propose to ignore some variables in the optimization leveraging the expected sparsity of the solutions and consequently leading to faster solvers. When the procedure is guaranteed not to discard variables wrongly the rules are said to be safe. In this work, we propose a unifying framework for generalized linear models regularized with standard sparsity enforcing penalties such as $\\ell_1$ or $\\ell_1/\\ell_2$ norms. Our technique allows to discard safely more variables than previously considered safe rules, particularly for low regularization parameters. Our proposed Gap Safe rules (so called because they rely on duality gap computation) can cope with any iterative solver but are particularly well suited to (block) coordinate descent methods. Applied to many standard learning tasks, Lasso, Sparse Group Lasso, multi-task Lasso, binary and multinomial logistic regression, etc., we report significant speed-ups compared to previously proposed safe rules on all tested data sets",
    "checked": true,
    "id": "c3f7842b05298a6d53fae724c39705c1e5ff098c",
    "semantic_title": "gap safe screening rules for sparsity enforcing penalties",
    "citation_count": 114,
    "authors": [
      "Eugene Ndiaye",
      "Olivier Fercoq",
      "Alex",
      "re Gramfort",
      "Joseph Salmon"
    ]
  },
  "https://jmlr.org/papers/v18/16-501.html": {
    "title": "Minimax Filter: Learning to Preserve Privacy from Inference Attacks",
    "volume": "main",
    "abstract": "Preserving privacy of continuous and/or high-dimensional data such as images, videos and audios, can be challenging with syntactic anonymization methods which are designed for discrete attributes. Differentially privacy, which uses a more rigorous definition of privacy loss, has shown more success in sanitizing continuous data. However, both syntactic and differential privacy are susceptible to inference attacks, i.e., an adversary can accurately infer sensitive attributes from sanitized data. The paper proposes a novel filter-based mechanism which preserves privacy of continuous and high-dimensional attributes against inference attacks. Finding the optimal utility-privacy tradeoff is formulated as a min-diff-max optimization problem. The paper provides an ERM-like analysis of the generalization error and also a practical algorithm to perform minimax optimization. In addition, the paper proposes a noisy minimax filter which combines minimax filter and differentially-private mechanism. Advantages of the method over purely noisy mechanisms is explained and demonstrated with examples. Experiments with several real-world tasks including facial expression classification, speech emotion classification, and activity classification from motion, show that the minimax filter can simultaneously achieve similar or higher target task accuracy and lower inference accuracy, often significantly lower than previous methods",
    "checked": true,
    "id": "33ba1c0cd1857b107d658cb900be75083c5a35b3",
    "semantic_title": "minimax filter: learning to preserve privacy from inference attacks",
    "citation_count": 76,
    "authors": [
      "Jihun Hamm"
    ]
  },
  "https://jmlr.org/papers/v18/16-563.html": {
    "title": "Knowledge Graph Completion via Complex Tensor Factorization",
    "volume": "main",
    "abstract": "In statistical relational learning, knowledge graph completion deals with automatically understanding the structure of large knowledge graphs---labeled directed graphs---and predicting missing relationships---labeled edges. State-of-the-art embedding models propose different trade-offs between modeling expressiveness, and time and space complexity. We reconcile both expressiveness and complexity through the use of complex-valued embeddings and explore the link between such complex-valued embeddings and unitary diagonalization. We corroborate our approach theoretically and show that all real square matrices---thus all possible relation/adjacency matrices---are the real part of some unitarily diagonalizable matrix. This results opens the door to a lot of other applications of square matrices factorization. Our approach based on complex embeddings is arguably simple, as it only involves a Hermitian dot product, the complex counterpart of the standard dot product between real vectors, whereas other methods resort to more and more complicated composition functions to increase their expressiveness. The proposed complex embeddings are scalable to large data sets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks",
    "checked": true,
    "id": "a4dfb121275a6408d290b803baf8c9caeb23dc5b",
    "semantic_title": "knowledge graph completion via complex tensor factorization",
    "citation_count": 259,
    "authors": [
      "Théo Trouillon",
      "Christopher R. Dance",
      "Éric Gaussier",
      "Johannes Welbl",
      "Sebastian Riedel",
      "Guillaume Bouchard"
    ]
  },
  "https://jmlr.org/papers/v18/16-190.html": {
    "title": "Stabilized Sparse Online Learning for Sparse Data",
    "volume": "main",
    "abstract": "Stochastic gradient descent (SGD) is commonly used for optimization in large-scale machine learning problems. Lanford et al. (2009) introduce a sparse online learning method to induce sparsity via truncated gradient. With high- dimensional sparse data, however, this method suffers from slow convergence and high variance due to heterogeneity in feature sparsity. To mitigate this issue, we introduce a stabilized truncated stochastic gradient descent algorithm. We employ a soft- thresholding scheme on the weight vector where the imposed shrinkage is adaptive to the amount of information available in each feature. The variability in the resulted sparse weight vector is further controlled by stability selection integrated with the informative truncation. To facilitate better convergence, we adopt an annealing strategy on the truncation rate, which leads to a balanced trade-off between exploration and exploitation in learning a sparse weight vector. Numerical experiments show that our algorithm compares favorably with the original truncated gradient SGD in terms of prediction accuracy, achieving both better sparsity and stability",
    "checked": true,
    "id": "82616585490603906c23fddf6ceebadf01179223",
    "semantic_title": "stabilized sparse online learning for sparse data",
    "citation_count": 9,
    "authors": [
      "Yuting Ma",
      "Tian Zheng"
    ]
  },
  "https://jmlr.org/papers/v18/17-101.html": {
    "title": "Active-set Methods for Submodular Minimization Problems",
    "volume": "main",
    "abstract": "We consider the submodular function minimization (SFM) and the quadratic minimization problems regularized by the Lovasz extension of the submodular function. These optimization problems are intimately related; for example, min-cut problems and total variation denoising problems, where the cut function is submodular and its Lovasz extension is given by the associated total variation. When a quadratic loss is regularized by the total variation of a cut function, it thus becomes a total variation denoising problem and we use the same terminology in this paper for general submodular functions. We propose a new active-set algorithm for total variation denoising with the assumption of an oracle that solves the corresponding SFM problem. This can be seen as local descent algorithm over ordered partitions with explicit convergence guarantees. It is more flexible than the existing algorithms with the ability for warm-restarts using the solution of a closely related problem. Further, we also consider the case when a submodular function can be decomposed into the sum of two submodular functions $F_1$ and $F_2$ and assume SFM oracles for these two functions. We propose a new active-set algorithm for total variation denoising (and hence SFM by thresholding the solution at zero). This algorithm also performs local descent over ordered partitions and its ability to warm start considerably improves the performance of the algorithm. In the experiments, we compare the performance of the proposed algorithms with state-of-the-art algorithms, showing that it reduces the calls to SFM oracles",
    "checked": true,
    "id": "76b14a52ff0aac1cddc70dda831405507dd654a5",
    "semantic_title": "active-set methods for submodular minimization problems",
    "citation_count": 7,
    "authors": [
      "K. S. Sesh Kumar",
      "Francis Bach"
    ]
  },
  "https://jmlr.org/papers/v18/17-197.html": {
    "title": "A Bayesian Mixed-Effects Model to Learn Trajectories of Changes from Repeated Manifold-Valued Observations",
    "volume": "main",
    "abstract": "We propose a generic Bayesian mixed-effects model to estimate the temporal progression of a biological phenomenon from observations obtained at multiple time points for a group of individuals. The progression is modeled by continuous trajectories in the space of measurements. Individual trajectories of progression result from spatiotemporal transformations of an average trajectory. These transformations allow for the quantification of changes in direction and pace at which the trajectories are followed. The framework of Riemannian geometry allows the model to be used with any kind of measurements with smooth constraints. A stochastic version of the Expectation-Maximization algorithm is used to produce maximum a posteriori estimates of the parameters. We evaluated our method using a series of neuropsychological test scores from patients with mild cognitive impairments, later diagnosed with Alzheimer's disease, and simulated evolutions of symmetric positive definite matrices. The data-driven model of impairment of cognitive functions illustrated the variability in the ordering and timing of the decline of these functions in the population. We showed that the estimated spatiotemporal transformations effectively put into correspondence significant events in the progression of individuals",
    "checked": true,
    "id": "bfc6019602cc7274322b73875746b964ce7637ca",
    "semantic_title": "a bayesian mixed-effects model to learn trajectories of changes from repeated manifold-valued observations",
    "citation_count": 55,
    "authors": [
      "Jean-Baptiste Schiratti",
      "Stéphanie Allassonnière",
      "Olivier Colliot",
      "Stanley Durrleman"
    ]
  },
  "https://jmlr.org/papers/v18/17-214.html": {
    "title": "Stochastic Gradient Descent as Approximate Bayesian Inference",
    "volume": "main",
    "abstract": "Stochastic Gradient Descent with a constant learning rate (constant SGD) simulates a Markov chain with a stationary distribution. With this perspective, we derive several new results. (1) We show that constant SGD can be used as an approximate Bayesian posterior inference algorithm. Specifically, we show how to adjust the tuning parameters of constant SGD to best match the stationary distribution to a posterior, minimizing the Kullback-Leibler divergence between these two distributions. (2) We demonstrate that constant SGD gives rise to a new variational EM algorithm that optimizes hyperparameters in complex probabilistic models. (3) We also show how to tune SGD with momentum for approximate sampling. (4) We analyze stochastic-gradient MCMC algorithms. For Stochastic- Gradient Langevin Dynamics and Stochastic-Gradient Fisher Scoring, we quantify the approximation errors due to finite learning rates. Finally (5), we use the stochastic process perspective to give a short proof of why Polyak averaging is optimal. Based on this idea, we propose a scalable approximate MCMC algorithm, the Averaged Stochastic Gradient Sampler",
    "checked": true,
    "id": "ea68a5c75e0e228e54efd91db972f71c1a917e51",
    "semantic_title": "stochastic gradient descent as approximate bayesian inference",
    "citation_count": 545,
    "authors": [
      "Stephan M",
      "t",
      "Matthew D. Hoffman",
      "David M. Blei"
    ]
  },
  "https://jmlr.org/papers/v18/17-203.html": {
    "title": "STORE: Sparse Tensor Response Regression and Neuroimaging Analysis",
    "volume": "main",
    "abstract": "Motivated by applications in neuroimaging analysis, we propose a new regression model, Sparse TensOr REsponse regression (STORE), with a tensor response and a vector predictor. STORE embeds two key sparse structures: element-wise sparsity and low-rankness. It can handle both a non-symmetric and a symmetric tensor response, and thus is applicable to both structural and functional neuroimaging data. We formulate the parameter estimation as a non-convex optimization problem, and develop an efficient alternating updating algorithm. We establish a non- asymptotic estimation error bound for the actual estimator obtained from the proposed algorithm. This error bound reveals an interesting interaction between the computational efficiency and the statistical rate of convergence. When the distribution of the error tensor is Gaussian, we further obtain a fast estimation error rate which allows the tensor dimension to grow exponentially with the sample size. We illustrate the efficacy of our model through intensive simulations and an analysis of the Autism spectrum disorder neuroimaging data",
    "checked": true,
    "id": "e61237c75d7f2aa51cdda7eb5bc936286a8b668d",
    "semantic_title": "store: sparse tensor response regression and neuroimaging analysis",
    "citation_count": 84,
    "authors": [
      "Will Wei Sun",
      "Lexin Li"
    ]
  },
  "https://jmlr.org/papers/v18/16-634.html": {
    "title": "A Survey of Preference-Based Reinforcement Learning Methods",
    "volume": "main",
    "abstract": "Reinforcement learning (RL) techniques optimize the accumulated long-term reward of a suitably chosen reward function. However, designing such a reward function often requires a lot of task- specific prior knowledge. The designer needs to consider different objectives that do not only influence the learned behavior but also the learning progress. To alleviate these issues, preference-based reinforcement learning algorithms (PbRL) have been proposed that can directly learn from an expert's preferences instead of a hand-designed numeric reward. PbRL has gained traction in recent years due to its ability to resolve the reward shaping problem, its ability to learn from non numeric rewards and the possibility to reduce the dependence on expert knowledge. We provide a unified framework for PbRL that describes the task formally and points out the different design principles that affect the evaluation task for the human as well as the computational complexity. The design principles include the type of feedback that is assumed, the representation that is learned to capture the preferences, the optimization problem that has to be solved as well as how the exploration/exploitation problem is tackled. Furthermore, we point out shortcomings of current algorithms, propose open research questions and briefly survey practical tasks that have been solved using PbRL",
    "checked": true,
    "id": "84082634110fcedaaa32632f6cc16a034eedb2a0",
    "semantic_title": "a survey of preference-based reinforcement learning methods",
    "citation_count": 282,
    "authors": [
      "Christian Wirth",
      "Riad Akrour",
      "Gerhard Neumann",
      "Johannes Fürnkranz"
    ]
  },
  "https://jmlr.org/papers/v18/16-266.html": {
    "title": "Generalized SURE for optimal shrinkage of singular values in low-rank matrix denoising",
    "volume": "main",
    "abstract": "We consider the problem of estimating a low-rank signal matrix from noisy measurements under the assumption that the distribution of the data matrix belongs to an exponential family. In this setting, we derive generalized Stein's unbiased risk estimation (SURE) formulas that hold for any spectral estimators which shrink or threshold the singular values of the data matrix. This leads to new data-driven spectral estimators, whose optimality is discussed using tools from random matrix theory and through numerical experiments. Under the spiked population model and in the asymptotic setting where the dimensions of the data matrix are let going to infinity, some theoretical properties of our approach are compared to recent results on asymptotically optimal shrinking rules for Gaussian noise. It also leads to new procedures for singular values shrinkage in finite-dimensional matrix denoising for Gamma- distributed and Poisson-distributed measurements",
    "checked": true,
    "id": "763c32dd1143b7c167057d59ed1412cb142fa63c",
    "semantic_title": "generalized sure for optimal shrinkage of singular values in low-rank matrix denoising",
    "citation_count": 20,
    "authors": [
      "Jérémie Bigot",
      "Charles Deledalle",
      "Delphine Féral"
    ]
  },
  "https://jmlr.org/papers/v18/16-232.html": {
    "title": "Dimension Estimation Using Random Connection Models",
    "volume": "main",
    "abstract": "Information about intrinsic dimension is crucial to perform dimensionality reduction, compress information, design efficient algorithms, and do statistical adaptation. In this paper we propose an estimator for the intrinsic dimension of a data set. The estimator is based on binary neighbourhood information about the observations in the form of two adjacency matrices, and does not require any explicit distance information. The underlying graph is modelled according to a subset of a specific random connection model, sometimes referred to as the Poisson blob model. Computationally the estimator scales like $n\\log n$, and we specify its asymptotic distribution and rate of convergence. A simulation study on both real and simulated data shows that our approach compares favourably with some competing methods from the literature, including approaches that rely on distance information",
    "checked": true,
    "id": "cc06013efbc59a39443942dad79fb99bb2ad03dc",
    "semantic_title": "dimension estimation using random connection models",
    "citation_count": 5,
    "authors": [
      "Paulo Serra",
      "Michel M",
      "jes"
    ]
  },
  "https://jmlr.org/papers/v18/15-464.html": {
    "title": "Bayesian Inference for Spatio-temporal Spike-and-Slab Priors",
    "volume": "main",
    "abstract": "In this work, we address the problem of solving a series of underdetermined linear inverse problemblems subject to a sparsity constraint. We generalize the spike-and-slab prior distribution to encode a priori correlation of the support of the solution in both space and time by imposing a transformed Gaussian process on the spike-and-slab probabilities. An expectation propagation (EP) algorithm for posterior inference under the proposed model is derived. For large scale problems, the standard EP algorithm can be prohibitively slow. We therefore introduce three different approximation schemes to reduce the computational complexity. Finally, we demonstrate the proposed model using numerical experiments based on both synthetic and real data sets",
    "checked": true,
    "id": "05831deafee9d75c5b580b06784aee804e60f8c7",
    "semantic_title": "bayesian inference for spatio-temporal spike-and-slab priors",
    "citation_count": 31,
    "authors": [
      "Michael Riis Andersen",
      "Aki Vehtari",
      "Ole Winther",
      "Lars Kai Hansen"
    ]
  },
  "https://jmlr.org/papers/v18/15-143.html": {
    "title": "Adaptive Randomized Dimension Reduction on Massive Data",
    "volume": "main",
    "abstract": "The scalability of statistical estimators is of increasing importance in modern applications. One approach to implementing scalable algorithms is to compress data into a low dimensional latent space using dimension reduction methods. In this paper, we develop an approach for dimension reduction that exploits the assumption of low rank structure in high dimensional data to gain both computational and statistical advantages. We adapt recent randomized low-rank approximation algorithms to provide an efficient solution to principal component analysis (PCA), and we use this efficient solver to improve estimation in large- scale linear mixed models (LMM) for association mapping in statistical genomics. A key observation in this paper is that randomization serves a dual role, improving both computational and statistical performance by implicitly regularizing the covariance matrix estimate of the random effect in an LMM. These statistical and computational advantages are highlighted in our experiments on simulated data and large-scale genomic studies",
    "checked": true,
    "id": "a6b5020a47f25e2fe7e99d044b759b0adca892af",
    "semantic_title": "adaptive randomized dimension reduction on massive data",
    "citation_count": 17,
    "authors": [
      "Gregory Darnell",
      "Stoyan Georgiev",
      "Sayan Mukherjee",
      "Barbara E Engelhardt"
    ]
  },
  "https://jmlr.org/papers/v18/16-572.html": {
    "title": "A Nonconvex Approach for Phase Retrieval: Reshaped Wirtinger Flow and Incremental Algorithms",
    "volume": "main",
    "abstract": "We study the problem of solving a quadratic system of equations, i.e., recovering a vector signal $\\boldsymbol{x}\\in \\mathbb{R}^n$ from its magnitude measurements $y_i=|\\langle \\boldsymbol{a}_i, \\boldsymbol{x}\\rangle|, i=1,..., m$. We develop a gradient descent algorithm (referred to as RWF for reshaped Wirtinger flow) by minimizing the quadratic loss of the magnitude measurements. Comparing with Wirtinger flow (WF) (Candes et al., 2015), the loss function of RWF is nonconvex and nonsmooth, but better resembles the least-squares loss when the phase information is also available. We show that for random Gaussian measurements, RWF enjoys linear convergence to the true signal as long as the number of measurements is $\\mathcal{O}(n)$. This improves the sample complexity of WF ($\\mathcal{O}(n\\log n)$), and achieves the same sample complexity as truncated Wirtinger flow (TWF) (Chen and Candes, 2015), but without any sophisticated truncation in the gradient loop. Furthermore, RWF costs less computationally than WF, and runs faster numerically than both WF and TWF. We further develop an incremental (stochastic) version of RWF (IRWF) and connect it with the randomized Kaczmarz method for phase retrieval. We demonstrate that IRWF outperforms existing incremental as well as batch algorithms with experiments",
    "checked": true,
    "id": "4adc2fa636a382d73a33dde767cbbdb46604e631",
    "semantic_title": "a nonconvex approach for phase retrieval: reshaped wirtinger flow and incremental algorithms",
    "citation_count": 110,
    "authors": [
      "Huishuai Zhang",
      "Yingbin Liang",
      "Yuejie Chi"
    ]
  },
  "https://jmlr.org/papers/v18/16-382.html": {
    "title": "Consistency, Breakdown Robustness, and Algorithms for Robust Improper Maximum Likelihood Clustering",
    "volume": "main",
    "abstract": "The robust improper maximum likelihood estimator (RIMLE) is a new method for robust multivariate clustering finding approximately Gaussian clusters. It maximizes a pseudo- likelihood defined by adding a component with improper constant density for accommodating outliers to a Gaussian mixture. A special case of the RIMLE is MLE for multivariate finite Gaussian mixture models. In this paper we treat existence, consistency, and breakdown theory for the RIMLE comprehensively. RIMLE's existence is proved under non-smooth covariance matrix constraints. It is shown that these can be implemented via a computationally feasible Expectation-Conditional Maximization algorithm",
    "checked": true,
    "id": "5f06539b727930a6927d8288f96b05535aa50481",
    "semantic_title": "consistency, breakdown robustness, and algorithms for robust improper maximum likelihood clustering",
    "citation_count": 26,
    "authors": [
      "Pietro Coretto",
      "Christian Hennig"
    ]
  },
  "https://jmlr.org/papers/v18/17-175.html": {
    "title": "On Computationally Tractable Selection of Experiments in Measurement-Constrained Regression Models",
    "volume": "main",
    "abstract": "We derive computationally tractable methods to select a small subset of experiment settings from a large pool of given design points. The primary focus is on linear regression models, while the technique extends to generalized linear models and Delta's method (estimating functions of linear regression models) as well. The algorithms are based on a continuous relaxation of an otherwise intractable combinatorial optimization problem, with sampling or greedy procedures as post-processing steps. Formal approximation guarantees are established for both algorithms, and numerical results on both synthetic and real-world data confirm the effectiveness of the proposed methods",
    "checked": true,
    "id": "4ffeb1a74cdb4c1f687d00dd3eec044a67509070",
    "semantic_title": "on computationally tractable selection of experiments in measurement-constrained regression models",
    "citation_count": 31,
    "authors": [
      "Yining Wang",
      "Adams Wei Yu",
      "Aarti Singh"
    ]
  },
  "https://jmlr.org/papers/v18/14-348.html": {
    "title": "Generalized Conditional Gradient for Sparse Estimation",
    "volume": "main",
    "abstract": "Sparsity is an important modeling tool that expands the applicability of convex formulations for data analysis, however it also creates significant challenges for efficient algorithm design. In this paper we investigate the generalized conditional gradient (GCG) algorithm for solving sparse optimization problems--- demonstrating that, with some enhancements, it can provide a more efficient alternative to current state of the art approaches. After studying the convergence properties of GCG for general convex composite problems, we develop efficient methods for evaluating polar operators, a subroutine that is required in each GCG iteration. In particular, we show how the polar operator can be efficiently evaluated in learning low-rank matrices, instantiated with detailed examples on matrix completion and dictionary learning. A further improvement is achieved by interleaving GCG with fixed-rank local subspace optimization. A series of experiments on matrix completion, multi-class classification, and multi-view dictionary learning shows that the proposed method can significantly reduce the training cost of current alternatives",
    "checked": true,
    "id": "aa59b3facccb4d40377d5a08ce0d2d26fec8c200",
    "semantic_title": "generalized conditional gradient for sparse estimation",
    "citation_count": 76,
    "authors": [
      "Yaoliang Yu",
      "Xinhua Zhang",
      "Dale Schuurmans"
    ]
  },
  "https://jmlr.org/papers/v18/17-079.html": {
    "title": "Following the Leader and Fast Rates in Online Linear Prediction: Curved Constraint Sets and Other Regularities",
    "volume": "main",
    "abstract": "Follow the leader (FTL) is a simple online learning algorithm that is known to perform well when the loss functions are convex and positively curved. In this paper we ask whether there are other settings when FTL achieves low regret. In particular, we study the fundamental problem of linear prediction over a convex, compact domain with non-empty interior. Amongst other results, we prove that the curvature of the boundary of the domain can act as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero, FTL enjoys logarithmic regret, while for polytope domains and stochastic data it enjoys finite expected regret. The former result is also extended to strongly convex domains by establishing an equivalence between the strong convexity of sets and the minimum curvature of their boundary, which may be of independent interest. Building on a previously known meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the smaller regret of FTL when the data is `easy'. Finally, we show that such guarantees are achievable directly (e.g., by the follow the regularized leader algorithm or by a shrinkage-based variant of FTL) when the constraint set is an ellipsoid",
    "checked": true,
    "id": "6351807959b22a8181470e57a1e91fdeb687943c",
    "semantic_title": "following the leader and fast rates in online linear prediction: curved constraint sets and other regularities",
    "citation_count": 80,
    "authors": [
      "Ruitong Huang",
      "Tor Lattimore",
      "András György",
      "Csaba Szepesvári"
    ]
  },
  "https://jmlr.org/papers/v18/16-422.html": {
    "title": "Regularization and the small-ball method II: complexity dependent error rates",
    "volume": "main",
    "abstract": "We study estimation properties of regularized procedures of the form $\\hat f \\in\\arg\\min_{f\\in F}\\Big(\\frac{1}{N}\\sum_{i=1}^N\\big(Y_i-f(X_i)\\big)^2+\\lambda \\Psi(f)\\Big)$ for a convex class of functions $F$, regularization function $\\Psi(\\cdot)$ and some well chosen regularization parameter $\\lambda$, where the given data is an independent sample $(X_i, Y_i)_{i=1}^N$. We obtain bounds on the $L_2$ estimation error rate that depend on the complexity of the true model $F^*:=\\{f\\in F: \\Psi(f)\\leq\\Psi(f^*)\\}$, where $f^*\\in\\arg\\min_{f\\in F}\\mathbb{E}(Y-f(X))^2$ and the $(X_i,Y_i)$'s are independent and distributed as $(X,Y)$. Our estimate holds under weak stochastic assumptions -- one of which being a small-ball condition satisfied by $F$ -- and for rather flexible choices of regularization functions $\\Psi(\\cdot)$. Moreover, the result holds in the learning theory framework: we do not assume any a-priori connection between the output $Y$ and the input $X$. As a proof of concept, we apply our general estimation bound to various choices of $\\Psi$, for example, the $\\ell_p$ and $S_p$-norms (for $p\\geq1$), weak-$\\ell_p$, atomic norms, max- norm and SLOPE. In many cases, the estimation rate almost coincides with the minimax rate in the class $F^*$",
    "checked": true,
    "id": "d73d8b9942f72b2c37dae2d654089da74e40ea3d",
    "semantic_title": "regularization and the small-ball method ii: complexity dependent error rates",
    "citation_count": 35,
    "authors": [
      "Guillaume Lecué",
      "Shahar Mendelson"
    ]
  },
  "https://jmlr.org/papers/v18/15-076.html": {
    "title": "Matrix Completion with Noisy Entries and Outliers",
    "volume": "main",
    "abstract": "This paper considers the problem of matrix completion when the observed entries are noisy and contain outliers. It begins with introducing a new optimization criterion for which the recovered matrix is defined as its solution. This criterion uses the celebrated Huber function from the robust statistics literature to downweigh the effects of outliers. A practical algorithm is developed to solve the optimization involved. This algorithm is fast, straightforward to implement, and monotonic convergent. Furthermore, the proposed methodology is theoretically shown to be stable in a well defined sense. Its promising empirical performance is demonstrated via a sequence of simulation experiments, including image inpainting",
    "checked": true,
    "id": "856dd08dceeb4056ba2eff6465e4e438afa9308e",
    "semantic_title": "matrix completion with noisy entries and outliers",
    "citation_count": 30,
    "authors": [
      "Raymond K. W. Wong",
      "Thomas C. M. Lee"
    ]
  },
  "https://jmlr.org/papers/v18/17-275.html": {
    "title": "Faithfulness of Probability Distributions and Graphs",
    "volume": "main",
    "abstract": "A main question in graphical models and causal inference is whether, given a probability distribution $P$ (which is usually an underlying distribution of data), there is a graph (or graphs) to which $P$ is faithful. The main goal of this paper is to provide a theoretical answer to this problem. We work with general independence models, which contain probabilistic independence models as a special case. We exploit a generalization of ordering, called preordering, of the nodes of (mixed) graphs. This allows us to provide sufficient conditions for a given independence model to be Markov to a graph with the minimum possible number of edges, and more importantly, necessary and sufficient conditions for a given probability distribution to be faithful to a graph. We present our results for the general case of mixed graphs, but specialize the definitions and results to the better-known subclasses of undirected (concentration) and bidirected (covariance) graphs as well as directed acyclic graphs",
    "checked": true,
    "id": "2dc0e869afaf0a784904c70f90cb0422b69e7d5c",
    "semantic_title": "faithfulness of probability distributions and graphs",
    "citation_count": 34,
    "authors": [
      "Kayvan Sadeghi"
    ]
  },
  "https://jmlr.org/papers/v18/16-645.html": {
    "title": "Community Extraction in Multilayer Networks with Heterogeneous Community Structure",
    "volume": "main",
    "abstract": "Multilayer networks are a useful way to capture and model multiple, binary or weighted relationships among a fixed group of objects. While community detection has proven to be a useful exploratory technique for the analysis of single-layer networks, the development of community detection methods for multilayer networks is still in its infancy. We propose and investigate a procedure, called Multilayer Extraction, that identifies densely connected vertex-layer sets in multilayer networks. Multilayer Extraction makes use of a significance based score that quantifies the connectivity of an observed vertex-layer set through comparison with a fixed degree random graph model. Multilayer Extraction directly handles networks with heterogeneous layers where community structure may be different from layer to layer. The procedure can capture overlapping communities, as well as background vertex-layer pairs that do not belong to any community. We establish consistency of the vertex-layer set optimizer of our proposed multilayer score under the multilayer stochastic block model. We investigate the performance of Multilayer Extraction on three applications and a test bed of simulations. Our theoretical and numerical evaluations suggest that Multilayer Extraction is an effective exploratory tool for analyzing complex multilayer networks. Publicly available code is available at github.com/jdwilson4/Multila yerExtraction",
    "checked": true,
    "id": "9b858140e6fccbd628a54bfbd08ff496b138923f",
    "semantic_title": "community extraction in multilayer networks with heterogeneous community structure",
    "citation_count": 53,
    "authors": [
      "James D. Wilson",
      "John Palowitch",
      "Shankar Bhamidi",
      "Andrew B. Nobel"
    ]
  }
}