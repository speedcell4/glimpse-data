{
  "https://openreview.net/forum?id=ALCpkWP8jw": {
    "title": "A Gaussian matrix graphical encoder in sports medicine diagnosis combining structured and unstructured data",
    "volume": "review",
    "abstract": "We study the integration of Electronic Medical Records (EMRs) from clinical study into a joint predictive model. Compared to the totally black-box models, a competitive model with explainable structure is much more desirable. To tackle this challenge, this paper introduces a novel Gaussian Matrix Graphical Encoder(GMGE) based on matrix normal graphical model to encode unstructured medical text and simultaneously learn the underlying conditional dependency graph of concepts. We further present DiMES, a Diagnostic Model with Explainable Structure, which integrates the concept graph generated by GMGE with structured data such as patient's physical examination measures. Utilizing Graph Convolutional Networks (GCNs), DiMES encodes patient features based on the concept graph for downstream tasks, providing clinicians with accurate predictive information to assist in diagnostic decisions and treatment plan design. The effectiveness of the proposed DiMES is validated through its application on four downstream diagnostic predictive tasks(ACL, PCL, MMI and PS)",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Umh1zgd1pc": {
    "title": "Rethinking Pragmatics in Large Language Models: Towards Open-Ended Evaluation and Preference Tuning",
    "volume": "review",
    "abstract": "This study addresses the challenges of assessing and enhancing social-pragmatic inference in large language models (LLMs). We first highlight the inadequacy of current accuracy-based multiple choice question answering (MCQA) formats in assessing social-pragmatic reasoning, and propose the direct evaluation of models' free-form responses as measure, which - as our results show - correlates better with human judgement. Further, we explore the enhancement of pragmatic abilities in LLMs, proposing the use of preference optimization (PO) over supervised finetuning (SFT) since there's no ``gold'' answer in responding to a social situation. Our results indicate that preferential tuning significantly outperforms and proves more robust than SFT across pragmatic phenomena, and offers a near-free launch to enhance models' pragmatic ability without compromising generic abilities. Lastly, we delve into LLMs' internal space and demonstrate that the substantial boost of the model's pragmatic reasoning capabilities is linked to deeper layer representation, mirroring human's high-level thinking. Our experiments span multiple pragmatic and social reasoning data sources, covering diverse phenomena, as well as a image referential game requiring multimodal theory of mind (ToM). With our refined paradigms for evaluating and enhancing pragmatic inference, this paper offers key insights for developing more socially aware language models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cJqAmdfCPs": {
    "title": "Bayelemabaga: Creating Resources for Bambara NLP",
    "volume": "review",
    "abstract": "In low-resource settings, the problem is often not only the amount of data available, but also the quality, and in ways that are entirely foreign to high-resourced languages. For instance, many extreme low-resource languages have only recently acquired writing systems. This may result in multiple writing systems competing for dominance or, within a single writing system, non-standardized spelling. Translating to and from low-resource languages is a challenge for machine translation (MT) systems due to a lack of suitable parallel data. In this case study, we focus on the impact of manual data cleaning on the performance of learning machine translation models. We focus on Bambara, the vehicular language of Mali, and introduce the largest curated dataset for multilingual translation. We finetune six commonly used transformer-based language models, i.e., AfriMBART, AfriMT5, AfriM2M100, Mistral, Open-Llama-7B, and Meta-Llama3-8B on three existing Bambara-French language pair datasets and our curated dataset. We show that our new aligned and curated multilingual dataset enhances the translation quality of all studied models using the BLEU, CHRF++, and AfriCOMET evaluation metrics",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E2jDWy4rIu": {
    "title": "Visualizing Entity States in Recipes by Generating Step Images",
    "volume": "review",
    "abstract": "Procedural texts, such as recipes and instruction manuals, are crucial for understanding processes involving multiple entities over time. Entity state tracking, which monitors the states of specific entities at each time step, is a key task in this domain. However, existing benchmarks heavily rely on manually annotated datasets, limiting scalability. We propose a novel task of step image generation in recipes, using step images as visual supervision for tracking entity states in procedural text without relying on manually annotated data. By generating step images, we can visualize the entity states in each step. For this task, we collect high-quality multimodal recipe datasets, theSpruceEats. Addressing the limitation of existing two-stage methods in achieving deep interaction between text and image, this paper introduces an explicit state modeling approach based on multimodal generative models. Experiments on theSpruceEats dataset demonstrate that our method enhance entity state tracking and image generation quality compared to existing methods, improving the CLIP similarity metric by 10.2% compared to existing methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EmWhceeJx9": {
    "title": "Arc Representation for Graph-based Dependency Parsing",
    "volume": "review",
    "abstract": "In this paper, we address the explicit representation of arcs in graph-based syntactic dependency parsing, departing from conventional approaches where parsing algorithms compute dependency arc scores directly from input token representations. We propose to augment the parser with an intermediate arc representation, arguing for two main advantages. Firstly, arc vectors encapsulate richer information, improving the capabilities of scoring functions. Secondly, by introducing refinement layers, we allow interactions between arc representations, facilitating interactions between arcs. We demonstrate the efficacy of this approach through evaluations on PTB and UD treebanks. Our approach achieves an LAS error rate reduction of 1.0\\% on the PTB test set, and 1.7\\% on UD, over the best SOTA model",
    "checked": false,
    "id": "b112a4a27c7e97229f9c12372efb7be047e10ff0",
    "semantic_title": "auxiliary tasks to boost biaffine semantic dependency parsing",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=ivJRLEXIPs": {
    "title": "Refract ICL: Rethinking Example Selection in the Era of Million-Token Models",
    "volume": "review",
    "abstract": "The emergence of long-context large language models (LLMs) has enabled the use of hundreds, or even thousands, of demonstrations for in-context learning (ICL) – a previously impractical regime. This paper investigates whether traditional ICL selection strategies, which balance the similarity of ICL examples to the test input (using a text retriever) with diversity within the ICL set, remain effective when utilizing a large number of demonstrations. Our experiments demonstrate that, while longer contexts can accommodate more examples, simply increasing the number of demonstrations does not guarantee improved performance. Smart ICL selection remains crucial, even with thousands of demonstrations. To further enhance ICL in this setting, we introduce Refract ICL, a novel ICL selection algorithm specifically designed to focus LLM attention on challenging examples by strategically repeating them within the context and incorporating zero-shot predictions as error signals. Our results show that Refract ICL significantly improves the performance of extremely long-context models such as Gemini 1.5 Pro, particularly on tasks with a smaller number of output classes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JPwP3EpeCM": {
    "title": "Dual-Phase Accelerated Prompt Optimization",
    "volume": "review",
    "abstract": "Gradient-free prompt optimization methods have made significant strides in enhancing the performance of closed-source Large Language Model (LLMs) across a wide range of tasks. However, existing approaches make light of the importance of high-quality prompt initialization and the identification of effective optimization directions, thus resulting in substantial optimization steps to obtain satisfactory performance. In this light, we aim to accelerate prompt optimization process to tackle the challenge of low convergence rate. We propose a dual-phase approach which starts with generating high-quality initial prompts by adopting a well-designed meta-instruction to delve into task-specific information, and iteratively optimize the prompts at the sentence level, leveraging previous tuning experience to expand prompt candidates and accept effective ones. Extensive experiments on eight datasets demonstrate the effectiveness of our proposed method, achieving a consistent accuracy gain over baselines with less than five optimization steps",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RBHRmQAvJ9": {
    "title": "Evaluating LLMs' Mathematical and Coding Competency through Ontology-guided Interventions",
    "volume": "review",
    "abstract": "Recent advancements in Large Language Models (LLMs) have showcased striking results on existing logical reasoning benchmarks, with some models even surpassing human performance. However, the true depth of their competencies and robustness in reasoning tasks remains an open question. To this end, in this paper, we focus on two popular reasoning tasks: arithmetic reasoning and code generation. Particularly, we introduce: (i) a general ontology of perturbations for maths and coding questions, (ii) a semi-automatic method to apply these perturbations, and (iii) two datasets, MORE and CORE, respectively, of perturbed maths and coding problems to probe LLM capabilities in numeric reasoning and coding tasks. Through comprehensive evaluations of both closed-source and open-source LLMs, we show a significant performance drop across all the models against the perturbed questions, suggesting that the current LLMs lack robust problem solving skills and structured reasoning abilities in many areas, as defined by our ontology",
    "checked": true,
    "id": "1a1063e0e2707d8c540d88a49084bf683477c57e",
    "semantic_title": "evaluating llms' mathematical and coding competency through ontology-guided interventions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=NyZtxWIj8L": {
    "title": "Vanilla Transformers are Transfer Capability Teachers",
    "volume": "review",
    "abstract": "Recently, Mixture of Experts (MoE) Transformers have garnered increasing attention due to their advantages in model capacity and computational efficiency. However, studies have indicated that MoE Transformers underperform vanilla Transformers in many downstream tasks, significantly diminishing the practical value of MoE models. To explain this issue, we propose that the pre-training performance and transfer capability of a model are joint determinants of its downstream task performance. MoE models, in comparison to vanilla models, have poorer transfer capability, leading to their subpar performance in downstream tasks. To address this issue, we introduce the concept of transfer capability distillation, positing that although vanilla models have weaker performance, they are effective teachers of transfer capability. The MoE models guided by vanilla models can achieve both strong pre-training performance and transfer capability, ultimately enhancing their performance in downstream tasks. We design a specific distillation method and conduct experiments on the BERT architecture. Experimental results show a significant improvement in downstream performance of MoE models, and many further evidences also strongly support the concept of transfer capability distillation. Finally, we attempt to interpret transfer capability distillation and provide some insights from the perspective of model feature",
    "checked": true,
    "id": "ecc547edb0e38b25e60a4200ec46c59d5947a064",
    "semantic_title": "vanilla transformers are transfer capability teachers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5uGSREmvi0": {
    "title": "MCQFormatBench: Robustness Tests for Multiple-Choice Questions",
    "volume": "review",
    "abstract": "Multiple-choice questions (MCQs) are often used to evaluate large language models (LLMs). They measure LLMs' general common sense and reasoning abilities, as well as their knowledge in specific domains such as medicine. However, the robustness of LLMs to a variety of question formats in MCQs has not been thoroughly evaluated. While there are studies on the sensitivity of LLMs to input variations, research into their responsiveness to different question formats is still limited. Therefore, in this study, we propose a method to construct tasks to comprehensively evaluate the robustness against format changes of MCQs by decomposing the answering process into several steps. Using this dataset, we evaluate six LLMs, such as Llama3-70B and Mixtral-8x7B. Consequently, the lack of robustness to differences in the format of MCQs becomes evident. It is crucial to consider whether the format of MCQs influences their evaluation scores when assessing LLMs using MCQ datasets",
    "checked": false,
    "id": "570e4fec8c8f1c96b76accbb07d40e0528aafb4a",
    "semantic_title": "large language models are not robust multiple choice selectors",
    "citation_count": 94,
    "authors": []
  },
  "https://openreview.net/forum?id=2nPRjjdLyT": {
    "title": "Causal Inference in Large Language Model: A Survey",
    "volume": "review",
    "abstract": "Causal inference has been a pivotal challenge across diverse domains such as medicine and economics, demanding a complicated integration of human knowledge, numerical reasoning, and data processing capabilities. Recent advancements in natural language processing (NLP), particularly with the advent of large language models (LLMs), have introduced transformative opportunities for traditional causal inference tasks. This paper reviews recent progress in applying LLMs to causal inference, encompassing various tasks spanning different levels of causation. We summarize their causal problems, methodologies, and present comparison of their evaluation results in different scenarios. Furthermore, we discuss key findings, emerging trends, and outline directions for future research, underscoring the potential implications of integrating LLMs in advancing causal inference methodologies",
    "checked": false,
    "id": "94a3653fa6f468daf8e4a85f90525e76921b583b",
    "semantic_title": "causal inference with latent variables: recent advances and future prospectives",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y1tPrJWYFE": {
    "title": "NPC: Personalized Next Profile Crafting Using Previous Role-Play Bots",
    "volume": "review",
    "abstract": "Personalization and role-playing are two important research topics for the LLM community. However, the exploration in the direction of personalized role-playing especially rare. The primary obstacle in personalized role-playing is the absence of a dataset containing role-playing dialogues with personalized information. To overcome this obstacle, we introduce a new large-scale personalized role-playing dataset Multi-Bot Tailored Interaction Dataset (MBTI), which includes the entire interaction history from creating bot to deeply engaged conversation between 1238 users and 8477 Bots. More importantly, we propose a new pipeline called \"Next Profile Crafting (NPC)\" for crafting role profiles with cross-bot insights to achieve personalization before the conversation. This method is based on the bot persona link among historical bots that user has multi-turn interaction with. We conducted tests using both trained and untrained approaches, as well as open-source and proprietary large language models, highlighting significant disparities in the effectiveness of personalized crafting in the NPC task. Our findings indicate substantial room for improvement in current methodologies",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VkBZ42ouIB": {
    "title": "QReT: Quality Aware Token Count Reduction",
    "volume": "review",
    "abstract": "LLMs are widely used nowadays by several enterprises for various use cases. This is due to their general applicability and demonstrated success across multiple domains and tasks. However, there is a monetary cost associated with the use of commercially available inference APIs to LLMs. This cost generally depends on the number of input and output tokens and the cost parameters of the provider. In this work, we propose a framework QReT for reducing the input token count in prompts in a controllable quality aware manner. QReT first paraphrases the prompt to reduce token counts while maintaining quality measures. Secondly, it applies certain heuristics, again a controlled manner to reduce the final token count, without affecting the understanding by LLMs (hence, the output quality). We empirically validate QReT across several datasets and tasks and show its effectiveness",
    "checked": false,
    "id": "03f6e2a8d55c8d56ec3da47f5ed450d16332ba36",
    "semantic_title": "library aware power conscious realization of complementary boolean functions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DwRLo6toLN": {
    "title": "Defending Jailbreak Prompts via In-Context Adversarial Game",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities across diverse applications. However, concerns regarding their security, particularly the vulnerability to jailbreak attacks, persist. Drawing inspiration from adversarial training in deep learning and LLM agent learning processes, we introduce the In-Context Adversarial Game (ICAG) for defending against jailbreaks without the need for fine-tuning. ICAG leverages agent learning to conduct an adversarial game, aiming to dynamically extend knowledge to defend against jailbreaks. Unlike traditional methods that rely on static datasets, ICAG employs an iterative process to enhance both the defense and attack agents. This continuous improvement process strengthens defenses against newly generated jailbreak prompts. Our empirical studies affirm ICAG's efficacy, where LLMs safeguarded by ICAG exhibit significantly reduced jailbreak success rates across various attack scenarios. Moreover, ICAG demonstrates remarkable transferability to other LLMs, indicating its potential as a versatile defense mechanism",
    "checked": true,
    "id": "50ceabc6aa41e08480fa5976342bfe04bb47bce3",
    "semantic_title": "defending jailbreak prompts via in-context adversarial game",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=40xgCdANT4": {
    "title": "Dynamics of Instruction Tuning: Each Ability of Large Language Models Has Its Own Growth Pace",
    "volume": "review",
    "abstract": "Instruction tuning is a burgeoning method to elicit the general intelligence of Large Language Models (LLMs). However, the understanding of its scaling properties remains underexplored. While some research advocates for expanding the number of instructions, others suggest that a small set of well-chosen examples is adequate. To understand such discrepancy, our work systematically studies the effectiveness of data volume, parameter size, and data construction methods on the development of each underlying ability of LLM, such as creative writing, code generation, and logical reasoning. Our study reveals three primary findings: (i) Despite these factors significantly influencing overall model performance, some abilities are more responsive to scaling, while others show high resistance. (ii) The sensitivity of different abilities to these factors can be explained by their Complexity and Transference, which indicate the relative importance of each factor in learning specific abilities. (iii) Tailoring data construction based on these sensitivities results in performance gains on two public benchmarks. Additionally, we curate a comprehensive dataset containing over 40k instances across ten abilities for our experiments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pqIpMxy70A": {
    "title": "Reward Modeling Requires Automatic Adjustment Based on Data Quality",
    "volume": "review",
    "abstract": "In Reinforcement Learning from Human Feedback (RLHF), the reward model plays a crucial role in aligning language model outputs with human values. The human preference data used to train the reward model consists of a prompt and a response pair, with humans annotating which response better aligns with human value preferences. Due to the complexity and subjectivity of the annotation task, multiple organizations including OpenAI and Anthropic report significant noise in the human preference datasets, leading to instability and deviation in reward model training from human values. We discover that the difference in scores assigned to response pairs by the reward model effectively indicates the quality of data, and data of varying qualities show significant distinctions in reward model training. We introduce a method that automatically adjusts reward modeling based on data quality, reducing the impact of noise and making full use of dataset. Experiments on multiple human preference datasets demonstrate that our method stabilizes reward model training and significantly enhances the alignment performance of RLHF",
    "checked": false,
    "id": "05d8876cba1208490b1e242becce321a45f511bb",
    "semantic_title": "gedss: a generic framework to enhance model robustness for intrusion detection on noisy data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wqs9Beej1n": {
    "title": "Gradient Localization Improves Lifelong Pretraining of Language Models",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) trained on web-scale text corpora have been shown to capture world knowledge in their parameters. However, the mechanism by which language models store different types of knowledge is poorly understood. In this work, we examine two types of knowledge relating to temporally sensitive entities and demonstrate that each type is localized to different sets of parameters within the LLMs. We hypothesize that the lack of consideration of the locality of knowledge in existing continual learning methods is responsible for failed uptake of new information and catastrophic forgetting of previously learned information. We demonstrate that targeted training to these relevant layers can improve the performance of continually learned language under temporal drift",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7SlzDFnejn": {
    "title": "Expanding Search Space with Diverse Prompting Agents: An Efficient Sampling Approach for LLM Mathematical Reasoning",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in many complex tasks including mathematical reasoning. However, traditional approaches heavily rely on ensuring self-consistency within single prompting method, which limits the exploration of diverse problem-solving strategies. This study addresses these limitations by performing an experimental analysis of distinct prompting methods within the domain of mathematical reasoning. Our findings demonstrate that each method explores a distinct search space, and this differentiation becomes more evident with increasing problem complexity. To leverage this phenomenon, we applied efficient sampling process that uniformly combines samples from these diverse methods, which not only expands the maximum search space but achieves higher performance with fewer runs compared to single methods. Especially, within the subset of difficult questions of MATH dataset named MATH-hard, The maximum search space was achieved while utilizing approximately 43% fewer runs than single methods on average. These findings highlight the importance of integrating diverse problem-solving strategies to enhance the reasoning abilities of LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J9vbZnEoxi": {
    "title": "Coarse and Fine-grained Confidence Calibration of LLM-based Text-to-SQL Generation",
    "volume": "review",
    "abstract": "Calibration plays a crucial role as LLMs are increasingly deployed to convert natural language questions into SQL over commercial databases. In this work, we study the calibration of the confidence attached to both the whole query, and for the first time, to sub-parts of the query. For whole queries, we demonstrate that the simple baseline of deriving confidence from model assigned whole sequence probability yields the best calibration surpassing recent self-check and verbalization methods. For fine-grained calibration, we propose a novel method of assigning confidence to nodes of a logical relational algebra tree representation of the SQL string. We present an extensive comparison spanning two popular Text-to-SQL benchmarks on multiple LLMs, and draw interesting insights about various calibration methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WoBLg8E8Sm": {
    "title": "Inference-Time Decontamination: Reusing Leaked Benchmarks for Large Language Model Evaluation",
    "volume": "review",
    "abstract": "The training process of large language models (LLMs) often involves varying degrees of test data contamination. Although current LLMs are achieving increasingly better performance on various benchmarks, their performance in practical applications does not always match their benchmark results. Leakage of benchmarks can prevent the accurate assessment of LLMs' true performance. However, constructing new benchmarks is costly, labor-intensive and still carries the risk of leakage. Therefore, in this paper, we ask the question Can we reuse these leaked benchmarks for LLM evaluation? We propose Inference-Time Decontamination (ITD) to address this issue by detecting and rewriting leaked samples without altering their difficulties. ITD can mitigate performance inflation caused by memorizing leaked benchmarks. Our proof-of-concept experiments demonstrate that ITD reduces inflated accuracy by 22.9\\% on GSM8K and 19.0\\% on MMLU. On MMLU, using Inference-time Decontamination can lead to a decrease in the results of Phi3 and Mistral by 6.7\\% and 3.6\\% respectively. We hope that ITD can provide more truthful evaluation results for large language models",
    "checked": true,
    "id": "a1d29e4da609746b0c927ef141f31445e769ec3c",
    "semantic_title": "inference-time decontamination: reusing leaked benchmarks for large language model evaluation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OfEDtLFtYh": {
    "title": "To Stay or Not to Stay: Insights on Factors in Role-playing Dialogs",
    "volume": "review",
    "abstract": "With the growing humanlike nature of dialog agents, people are now engaging in extended conversations that can stretch from brief moments to substantial periods of time. Understanding the factors that contribute to sustaining these interactions is crucial, yet existing studies primarily focusing on short-term simulations that rarely explore such prolonged and real conversations. In this paper, we investigate the factors influencing retention rates in real interactions with role-playing models. By analyzing a large dataset of interactions between real users and thousands of characters, we systematically examine multiple factors and assess their impact on user retention rate. Surprisingly, we find that the degree to which the bot embodies the roles it plays has limited influence on retention rates, while the length of each turn it speaks significantly affects retention rates. This study sheds light on the critical aspects of user engagement with role-playing models and provides valuable insights for future improvements in the development of large language models for role-playing purposes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WL0TCM2ijw": {
    "title": "Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?",
    "volume": "review",
    "abstract": "Large Language Models have demonstrates remarkable performance in solving math problems, a hallmark of human intelligence. Despite high success rates on current benchmarks, however, these often feature simple problems with only one or two unknowns, which do not sufficiently challenge their reasoning capacities. This paper introduces a novel benchmark, BeyondX, designed to address these limitations by incorporating problems with multiple unknowns. Recognizing the challenges in proposing multi-unknown problems from scratch, we developed BeyondX using an innovative automated pipeline that progressively increases complexity by expanding the number of unknowns in simpler problems. Empirical study on BeyondX reveals that the performance of existing LLMs, even those fine-tuned specifically on math tasks, significantly decreases as the number of unknowns increases - with a performance drop of up to 70% observed in GPT-4. To tackle these challenges, we propose the Formulate-and-Solve strategy, a generalized prompting approach that effectively handles problems with an arbitrary number of unknowns. Our findings reveal that this strategy not only enhances LLM performance on the BeyondX benchmark but also provides deeper insights into the computational limits of LLMs when faced with more complex mathematical challenges",
    "checked": true,
    "id": "432b119c85f21462784f5be5d3b48b03ec423294",
    "semantic_title": "solving for x and beyond: can large language models solve complex math problems with more-than-two unknowns?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YBswWaS21w": {
    "title": "Retrieval-DPO: Retrieval-augmented preference optimization with non-paired preference data",
    "volume": "review",
    "abstract": "Aligning Large Language Models (LLMs) with human feedback is important and challenging. \\citet{rafailov2023direct} propose Direct Preference Optimization (DPO), a simple but effective alignment method which is reinforcement learning free. However, DPO requires paired preference data which is harder and more expensive to obtain compared to binary preference data. We propose a retrieval-based method named Retrieval-DPO to align LLMs under binary preference data situation. The core idea of our method is that learning how to align can be achieved with non-paired preference data of similar questions rather than strictly paired preference data considering the learning process of human. For instance, to teach the LLM to learn how to treat multiple perspectives, other comprehensive golden answers of similar question may have similar positive effects as the golden answer of the same question. Following this idea, we retrieve an example with opposite label from the retrieval database for a binary preference data in the training set. After the retrieval process, we get a pair of preference data but with possibly different questions and then adopt the DOVE \\cite{bansal2024comparing} optimization objective for the alignment. We compare Retrieval-DPO with other preference optimization algorithms which do not need paired preference data such as Kahneman-Tversky Optimization (KTO) and Unified Language Model Alignment (ULMA). We find that our method significantly outperforms KTO and ULMA on helpful-base subset of HH dataset (over 13\\%) and slightly outperforms KTO on harmless-base subset of HH dataset and controlled sentiment generation task. Besides, our method is not sensitive to the ratio of the number of positive examples to the number of negative examples without additional hyperparameter tuning",
    "checked": false,
    "id": "fc24091a9b44953c71084449b4fa0eabfb58abb3",
    "semantic_title": "knowpo: knowledge-aware preference optimization for controllable knowledge selection in retrieval-augmented language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PqH6FU8HOj": {
    "title": "On the Client Preference of LLM Fine-tuning in Federated Learning",
    "volume": "review",
    "abstract": "Reinforcement learning with human feedback (RLHF) fine-tunes a pretrained large language model (LLM) using preference datasets, enabling the LLM to generate outputs that align with human preferences. Given the sensitive nature of these preference datasets held by various clients, there is a need to implement RLHF within a federated learning (FL) framework, where clients are reluctant to share their data due to privacy concerns. To address this, we introduce a feasible framework in which clients collaboratively train a binary selector with their preference datasets using our proposed FedBis. With a well-trained selector, we can further enhance the LLM that generates human-preferred completions. Meanwhile, we propose a novel algorithm, FedBiscuit, that trains multiple selectors by organizing clients into balanced and disjoint clusters based on their preferences. Compared to the FedBis, FedBisuit demonstrates superior performance in simulating human preferences for pairwise completions. Our extensive experiments on federated human preference datasets -- marking the first benchmark to address heterogeneous data partitioning among clients -- demonstrate that FedBisuit outperforms FedBis and even surpasses traditional centralized training",
    "checked": true,
    "id": "fc73b75cfc94f4955daf23cb4f6954351dfa76f7",
    "semantic_title": "on the client preference of llm fine-tuning in federated learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CiU8jOrPPD": {
    "title": "ModeLing: A Novel Dataset for Testing Linguistic Reasoning in Language Models",
    "volume": "review",
    "abstract": "We introduce ModeLing, a novel benchmark of Linguistics Olympiad-style puzzles which tests few-shot reasoning in AI systems. Solving these puzzles necessitates inferring aspects of a language's grammatical structure from a small number of examples. Such puzzles provide a natural testbed for language models, as they require compositional generalization and few-shot inductive reasoning. Consisting solely of new puzzles written specifically for this work, ModeLing has no risk of appearing in the training data of existing AI systems: this ameliorates the risk of data leakage, a potential confounder for many prior evaluations of reasoning. Evaluating several large open source language models and GPT on our benchmark, we observe non-negligible accuracy, demonstrating few-shot emergent reasoning ability which cannot merely be attributed to shallow memorization. However, imperfect model performance suggests that ModeLing can be used to measure further progress in linguistic reasoning",
    "checked": true,
    "id": "e35c5f517e547bde2ae4d77a535d3e5584805f02",
    "semantic_title": "modeling: a novel dataset for testing linguistic reasoning in language models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=8bEuhpV2vH": {
    "title": "Enhancing Emotion Recognition in Conversations through Global Context: An Empirical Analysis",
    "volume": "review",
    "abstract": "According to multimodal and contextualized nature of the human conversation, correctly identifying an emotion for given utterance in the conversation has always been a challenging task. Recent research benefits from Graph Neural Networks by capturing implicit relationship of temporally proximate utterances. In this paper, we expand the structure of the graph exploited by these models reflecting the global context of the conversation and explore how leveraging conversational context and interactions can lead to more accurate emotion recognition. We empirically analyze the modules on Emotion Recognition in Conversation models, showing this approach enhances the performance of these models. Our experiments show that incorporating global conversational context has a positive effect on the performance of emotion recognition",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qlts1JVWpX": {
    "title": "AntiSemRO: Studying the Romanian expression of Antisemitism",
    "volume": "review",
    "abstract": "With far-right ideology rising in popularity, online environment embodies hateful attitudes. The Covid-19 pandemic and the violent wars in Ukraine and Palestine contributed to a growth in antisemitic discourse. This study introduces an annotated dataset for the study of antisemitic hate speech in Romanian along with several baseline models using classical machine learning models and transformer models for the classification of antisemitic discourse in the online medium",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ymuD7hlrvu": {
    "title": "REPOPILOT: Software Agents To Resolve Software Engineering Tasks at Repository-Level Scale",
    "volume": "review",
    "abstract": "Coding assistants based on Large Language Models (LLMs) have recently surged in popularity. A significant challenge for LLMs is accurately responding to user queries at the scale of entire code repositories. We propose RepoPilot, a multi-agent-based system capable of effectively navigating through source code repositories to collect relevant information, editing code and execute programs. We demonstrate the effectiveness of RepoPilot through extensive evaluations on challenging benchmarks, including SWE-bench and an automatically collected code generation dataset. On SWE-bench Lite, RepoPilot achieves a 17\\% pass rate, establishing competitive results compared to the baseline while maintains low cost and also excels in other code intelligence tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dIkMv4eZQD": {
    "title": "Social Bias in Large Language Models For Bangla: An Empirical Study on Gender and Religious Bias",
    "volume": "review",
    "abstract": "The rapid growth of Large Language Models (LLMs) has put forward the study of biases as a crucial field. It is important to assess the influence of different types of biases embedded in LLMs to ensure fair use in sensitive fields. Although there have been extensive works on bias assessment in English, such efforts are rare and scarce for a major language like Bangla. In this work, we examine two types of social biases in LLM generated outputs for Bangla language. Our main contributions in this work are: (1) bias studies on two different social biases for Bangla (2) a curated dataset for bias measurement benchmarking (3) two different probing techniques for bias detection in the context of Bangla. This is the first work of such kind involving bias assessment of LLMs for Bangla to the best of our knowledge. All our code and resources will be made publicly available for the progress of bias related research in Bangla NLP",
    "checked": true,
    "id": "b6d4eea463fc1717cbc45b4ac3ae55bddfb5090d",
    "semantic_title": "social bias in large language models for bangla: an empirical study on gender and religious bias",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=E8pNK3YAdO": {
    "title": "Hint-before-Solving: A Framework to Effectively Utilizing Inherent Knowledge of Large Language Model",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) have recently showcased remarkable generalizability in various domains. Despite their extensive knowledge, LLMs still face challenges in efficiently utilizing encoded knowledge to develop accurate and logical reasoning. To mitigate this problem, we introduced the Hint-before-Solving framework (HinSo), which guides the model in generating hints (e.g., specific knowledge or key ideas) for solving the problem before the step-by-step solution. Our studies involving 5 LLMs across 7 datasets of mathematical and commonsense reasoning results indicated that introducing hints before problem-solving can significantly enhance the performance of CoT. To investigate whether LLMs can learn the HinSo pattern and improve their generalization ability, we constructed two large-scale and high-quality training datasets, HST-S and HST-L, containing 7.5k and 75k samples, respectively. The experimental results of supervised fine-tuning (SFT) showed that, under the same settings, the performance of model trained on the HinSo-formatted data improved significantly compared to CoT-formatted data, with a performance increase of 5.1% and 5.6% on the GSM8K, respectively. We make our code and dataset publicly available at \\url{https://github.com/sfhff216/hsp}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZI99Mbqyge": {
    "title": "Are Expert-Level Language Models Expert-Level Annotators?",
    "volume": "review",
    "abstract": "Data annotation refers to the labeling or tagging of textual data with relevant information. A large body of works have reported positive results on leveraging LLMs as an alternative to human annotators. However, existing studies focus on classic NLP tasks, and the extent to which LLMs as data annotators perform in domains requiring expert knowledge remains underexplored. In this work, we investigate comprehensive approaches across three highly specialized domains and discuss practical suggestions from a cost-effectiveness perspective. To the best of our knowledge, we present the first systematic evaluation of LLMs as expert-level data annotators",
    "checked": false,
    "id": "1eb1a8c7f88de27af224153f43ecdd41774600f2",
    "semantic_title": "promptagent: strategic planning with language models enables expert-level prompt optimization",
    "citation_count": 48,
    "authors": []
  },
  "https://openreview.net/forum?id=S7he4lxunu": {
    "title": "Understanding the Relationship between Prompts and Response Uncertainty in Large Language Models",
    "volume": "review",
    "abstract": "Large language models (LLMs) are widely used in decision-making, but their reliability, especially in critical tasks like healthcare, is not well-established. Therefore, understanding how LLMs reason and make decisions is crucial for their safe deployment. This paper investigates how the uncertainty of responses generated by LLMs relates to the information provided in the input prompt. Leveraging the insight that LLMs learn to infer latent concepts during pretraining, we propose a prompt-response concept model that explains how LLMs generate responses and helps understand the relationship between prompts and response uncertainty. We show that the uncertainty decreases as the prompt's informativeness increases, similar to epistemic uncertainty. Our detailed experimental results on real datasets validate our proposed model",
    "checked": false,
    "id": "d4838211d7f65628f56b9f6faab30a95ff7b51f8",
    "semantic_title": "for prediction city region re-weighting",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Wf3f7Fz3C7": {
    "title": "CodeGRAG: Bridging the Gap between Natural Language and Programming Language via Graphical Retrieval Augmented Generation",
    "volume": "review",
    "abstract": "Utilizing large language models to generate codes has shown promising meaning in software development revolution. Despite the intelligence shown by the general large language models, their specificity in code generation can still be improved due to the syntactic gap and mismatched vocabulary existing among natural language and different programming languages. In this paper, we propose CodeGRAG, a Graphical Retrieval Augmented Code Generation framework to enhance the performance of LLMs. CodeGRAG builds the graphical view of code blocks based on the control flow and data flow of them to fill the gap between programming languages and natural language, which can facilitate natural language based LLMs for better understanding of code syntax and serve as a bridge among different programming languages. To take the extracted structural knowledge into the foundation models, we propose 1) a hard meta-graph prompt template to transform the challenging graphical representation into informative knowledge for tuning-free models and 2) a soft prompting technique that injects the domain knowledge of programming languages into the model parameters via finetuning the models with the help of a pretrained GNN expert model. CodeGRAG significantly improves the code generation ability of LLMs and can even offer performance gain for cross-lingual code generation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WfHQCaUhi6": {
    "title": "VLV-Bench: A Comprehensive benchmark for very long-form videos understanding",
    "volume": "review",
    "abstract": "Understanding long videos, ranging from tens of minutes to several hours, presents unique challenges in video comprehension. Despite the increasing importance of long-form video content, existing benchmarks primarily focus on shorter clips. To address this gap, we introduce a comprehensive benchmark for Very Long Videos understanding (VLV-Bench), which presents 1) The longest video duration, averaging 76.34 minutes; 2) The largest number of question-answer pairs, 108.2K; 3) Diversity in questions that examine nine different skills and include both multiple-choice questions and open-ended questions; 4) Human-centric, as the video sources come from movies and daily TV shows, with specific human-level question designs such as Movie Spoiler Questions that require critical thinking and comprehensive understanding. Using VLV-Bench, we comprehensively evaluate existing Large Multi-Modality Models (LMMs) on each skill, including the commercial model Gemini 1.5 Flash and the open-source models. The evaluation shows significant challenges in our benchmark. Our results show that the best AI models such Gemini struggles to perform well with 42.72 % average accuracy and 2.71 out of 5 average score. We hope this benchmark will stimulate the LMMs community towards long video and human-level understanding. Our benchmark can be accessed at (https://vlv-bench.github.io/VLV-website/) and will be made publicly available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vUGoG1TM0x": {
    "title": "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension",
    "volume": "review",
    "abstract": "Referring Expression Comprehension (REC) is a crucial cross-modal task that objectively evaluates the capabilities of language understanding, image comprehension, and language-to-image grounding. Consequently, it serves as an ideal testing ground for Multi-modal Large Language Models (MLLMs). In pursuit of this goal, we have established a new REC dataset characterized by two key features: Firstly, it is designed with controllable varying levels of difficulty, necessitating multi-level fine-grained reasoning across object categories, attributes, and multi-hop relationships. Secondly, it includes negative text and images created through fine-grained editing and generation based on existing data, thereby testing the model's ability to correctly reject scenarios where the target object is not visible in the image—an essential aspect often overlooked in existing datasets and approaches. Utilizing this high-quality dataset, we conducted comprehensive evaluations of both state-of-the-art specialist models and MLLMs. Our findings indicate that there remains a significant gap in achieving satisfactory grounding performance. We anticipate that our dataset will inspire new approaches to enhance visual reasoning and develop more advanced cross-modal interaction strategies, ultimately unlocking the full potential of MLLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3p8FbDD1uI": {
    "title": "Evaluating LLMs' capability on Satisfying Lexical Constraint",
    "volume": "review",
    "abstract": "Lexical Constrained Generation (LCG) is a fundamental task in text generation. Recent advancement of large pretrained language models (LLMs) has enabled prompt-based controlling for LCG. Despite growing interest in assessing LLMs' capabilities in various aspects, there remains a lack of thorough investigation. To address this gap, we systematically analyze the performance of LLMs on satisfying lexical constraints with prompt-based controlling, as well as their efficacy in downstream applications (such as recipe generation, table-to-text, profile writing, etc). Through extensive experimentation, we identified several key observations that elucidate the limitations of LLMs in LCG, including (1) position bias, where LLMs tend to satisfy constraints that appear in specific positions within the input; (2) insensitive decoding parameters, which minimally impact the performance of LLMs; and (3) the inherent complexity of certain constraints (i.e. compound word). We conclude that there is a complexity bottleneck: LLMs still face significant challenges in consistently satisfying lexical constraints. Additionally, we introduce the Divide and Conquer Generation strategy, effective for both white-box and black-box LLMs, significantly enhancing their performance in LCG tasks. This strategy boosts LLMs' success rate by 93% in the most challenging LCG task, which is 40% more than the baseline. Our analysis aims to provide valuable insights into the performance of LLMs in LCG, and our proposed strategy offers a pathway to more sophisticated and customized text generation applications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S3lYBpVDkQ": {
    "title": "ALERTS: Active Learning and Ensemble LLM Real-Time Switch for Real-World Data Drift Challenges",
    "volume": "review",
    "abstract": "In the rapidly changing real-world scenarios, data drift and ``cold-start'' issues present significant challenges for the development of machine learning models, along with the high cost and resource scarcity of domain experts. Traditional compact models fine-tuned on small number of domain-specific examples often outperform generic LLMs, despite the fine-tuned models struggling with rapid data changes. This study introduces ALERTS, an ensemble system designed to address these data challenges. The system comprises 1) an LLM to enhance early-stage performance and adapt to sudden data drifts, 2) an Active Learning (AL)-assisted compact model iteratively fine-tuned on annotations from daily human expert workflows, and 3) a switch mechanism that evaluates both models in real-time and selects the best-performing ones. We conducted empirical studies to understand the performance between LLMs and AL-assisted compact models, then evaluated our system's effectiveness through AL simulations of real-world scenarios. Our work offers a novel framework for developing robust language model systems across various dynamic real-world scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b1sX4irpzf": {
    "title": "Self-Harmonized Chain of Thought",
    "volume": "review",
    "abstract": "Chain-of-Thought (CoT) prompting reveals that large language models are capable of performing complex reasoning via intermediate steps. CoT prompting is primarily categorized into three approaches. The first approach utilizes straightforward prompts like ``Let's think step by step'' to generate a sequential thought process before yielding an answer. The second approach makes use of human-crafted, step-by-step demonstrations to guide the model's reasoning process. The third automates the generation of reasoned demonstrations with the 'Let's think step by step'.This approach sometimes leads to reasoning errors, highlighting the need to diversify demonstrations to mitigate its misleading effects. However, diverse demonstrations pose challenges for effective representations. In this work, we propose ECHO, a self-harmonized chain-of-thought prompting method. It consolidates diverse solution paths into a uniform and effective solution pattern.ECHO demonstrates the best overall performance across three reasoning domains",
    "checked": false,
    "id": "d36770f542facfa60896593ca02bb1ce680f0499",
    "semantic_title": "categorical matrix of vitacultural methodology: from thought-activity to canon",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=YG1TnDkc8O": {
    "title": "Query-based Cross-Modal Projector Bolstering Mamba Multimodal LLM",
    "volume": "review",
    "abstract": "The Transformer's quadratic complexity with input length imposes an unsustainable computational load on large language models (LLMs). In contrast, the Selective Scan Structured State-Space Model, or Mamba, addresses this computational challenge effectively. This paper explores a query-based cross-modal projector designed to bolster Mamba's efficiency for vision-language modeling by compressing visual tokens based on input through the cross-attention mechanism. This innovative projector also removes the need for manually designing the 2D scan order of original image features when converting them into an input sequence for Mamba LLM. Experimental results across various vision-language understanding benchmarks show that the proposed cross-modal projector enhances Mamba-based multimodal LLMs, boosting both performance and throughput",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zBJIOrpbPx": {
    "title": "Deciphering Multi-task Learning: Comparative Insights for Similar and Dissimilar Tasks",
    "volume": "review",
    "abstract": "Multi-task learning (MTL), which emerged as a powerful concept in the era of machine learning, employs a shared model trained to handle multiple tasks at the same time. Numerous advantages of this novel approach inspire us to investigate the insights of various tasks with similar (Identification of Sentiment, Emotion, Sarcasm, Irony, Hate and Offensive) and dissimilar (Identification of Sentiment, Claim, Language) genres and to analyze the change in their performances with respect to long and short head approaches. We shed light on the methods employed and critical observations to promote more efficient learning paradigm across similar and dissimilar tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0O7N7fTKGE": {
    "title": "Training Data Extraction Attack from Large Language Models in Federated Learning Through Frequent Sequence Mining",
    "volume": "review",
    "abstract": "Large language models (LLMs) are vulnerable to data extraction attacks due to their tendency to memorize precise training data. In contrast, Federated Learning (FL) has the potential to mitigate privacy leakage. This underscores the need for an assessment of the privacy risks associated with LLMs trained with FL algorithms, which remains an underexplored question. In this study, we evaluate the privacy leakage of LLMs trained with FL algorithms on the public datasets extended with automatically annotated Personally Identifiable Information (PII) to evaluate the leakage of PII and training example outputs. Through extensive experiments, we find out that FL algorithms indeed mitigate privacy leaks compared to their counterparts on centralized data. In addition, we discover a novel data extraction attack method, called cross-client security theft, which can recover up to 40\\% of unique PII mentions in target devices by accessing only one of the FL participants. These findings highlight the potential privacy risks of FL for LLMs and underscore the need to explore new protective mechanisms in future research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n9dV9E7RVj": {
    "title": "LLM-Powered Multi-Agent Proactive Communication System for Embodied Intelligence",
    "volume": "review",
    "abstract": "We presents a novel multi-robot collaboration framework leveraging large language models (LLMs) for improved communication, planning, and execution. By integrating a centralized message pool and LLM-assisted decision-making, our system addresses limitations of existing multi-agent frameworks. Experiments in the MuJoCo simulation environment demonstrate significant improvements in task completion rates, communication effectiveness, and decision-making accuracy. Our proactive communication system reduces redundancy and enhances fault tolerance, enabling efficient handling of unexpected situations. Future work will focus on improving information synchronization and multi-system collaboration, further enhancing efficiency and scalability in complex environments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AkIq6Mpx2G": {
    "title": "Human-Readable Representation for Graph Neural Networks",
    "volume": "review",
    "abstract": "This research presents an innovative method for representing nodes in graph neural networks (GNNs) using human-readable text in natural language, diverging from the traditional numerical embeddings. By employing a large language model (LLM) as a projector, we train GNNs to aggregate information from neighboring nodes and update node representations iteratively. Our experiments on the MovieLens dataset, widely used for recommendation tasks, demonstrate that human-readable representations effectively capture useful information for recommendations. This suggests that LLMs can successfully aggregate neighborhood information in a graph. Furthermore, fine-tuning the LLMs can improve their ability to generate more application-specific human-readable representations. This technique not only facilitates the incorporation of world knowledge into GNNs but also enhances their interpretability and allows for human intervention in their behavior. Our approach shows significant potential for making graph neural networks more understandable and controllable",
    "checked": false,
    "id": "67c0a7c64b62c2b6370c3788c685d00d610963d6",
    "semantic_title": "page: prototype-based model-level explanations for graph neural networks",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=GXkjWKYumX": {
    "title": "Visibility vs. Engagement: How Two Indian News Websites Reported on LGBTQ+ Individuals and Communities during the Pandemic",
    "volume": "review",
    "abstract": "Online news media outlets were an important source of information for people with digital access during the COVID–19 pandemic. In India, where \"transgender\" was legally recognised as a category only in 2014, and same–sex marriages are yet to be legalised, it becomes crucial to analyse whether and how news media reported the lived realities of vulnerable LGBTQ+ communities during the pandemic. This study analysed articles from online editions of two English–language newspaper websites, which differed vastly in their circulation figures—The Times of India and The Indian Express. The results of our study suggest that these newspaper websites covered articles surrounding various aspects of the lives of LGBTQ+ individuals with a greater focus on transgender communities. However, they lacked quality and depth. Focusing on the period spanning March 2020 to August 2021, we analysed articles from The Times of India and The Indian Express using distil–RoBERTa–base and ChatGPT–3.5 for sentiment analysis and BERTopic for topic modelling. We also compared our results to the period before the pandemic (January 2019–December 2019) to understand the shift in topics and sentiments across the two newspaper websites. Our topic modelling results indicate that The Times of India and The Indian Express primarily wrote soft news on LGBTQ+ communities. Similarly, our sentiment analysis results indicate a difference in prevailing sentiment as depicted by the two models. Furthermore, our manual analysis of the articles indicates that the language used in certain articles by The Times of India was transphobic and obsolete. Our study captures the visibility and representation of the LGBTQ+ communities in online Indian news media outlets, the language they use, and the narratives they follow",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=51Gq1Qw9vc": {
    "title": "CPTQuant - A Novel Mixed Precision Post-Training Quantization Techniques for Large Language Models",
    "volume": "review",
    "abstract": "Large language models have transformed the comprehension and generation of natural language tasks, but they come with substantial memory and computational requirements. Quantization techniques have emerged as a promising avenue for addressing these challenges while preserving accuracy and making energy efficient. We propose CPTQuant, a comprehensive strategy that introduces correlation-based (CMPQ), pruning-based (PMPQ), and Taylor decomposition-based (TDMPQ) mixed precision techniques. CMPQ adapts the precision level based on canonical correlation analysis of different layers. PMPQ optimizes precision layer-wise based on their sensitivity to sparsity. TDMPQ modifies precision using Taylor decomposition to assess each layer's sensitivity to input perturbation. These strategies allocate higher precision to more sensitive layers while diminishing precision to robust layers. CPTQuant assesses the performance across BERT, OPT-125M, OPT-350M, OPT-1.3B, and OPT-2.7B. We demonstrate up to 4x compression and a 2x-fold increase in efficiency with minimal accuracy drop compared to Hugging Face FP16. PMPQ stands out for achieving a considerably higher model compression. Sensitivity analyses across various LLMs show that the initial and final 30% of layers exhibit higher sensitivities than the remaining layers. PMPQ demonstrates an 11% higher compression ratio than other methods for classification tasks, while TDMPQ achieves a 30% greater compression ratio for language modeling tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fQI2qNhs0d": {
    "title": "Ask the experts: sourcing a high-quality nutrition counseling dataset through Human-AI collaboration",
    "volume": "review",
    "abstract": "Recent publicly available Large Language Models (LLMs) are being employed by end-users for various tasks, including sensitive ones such as health counseling, disregarding potential safety concerns. It is thus necessary to understand how adequately LLMs perform in such domains. We conduct a case study on ChatGPT in nutrition counseling, a popular use-case where the model supports a user with their dietary struggles. We crowd-source real-world diet-related struggles, then work with nutrition experts to generate supportive text using ChatGPT. Finally, experts evaluate the safety and text quality of ChatGPT's output. The result is the HAI-coaching dataset, containing ~2.4K crowdsourced dietary struggles and ~97K corresponding ChatGPT-generated and expert-annotated supportive texts. We analyse ChatGPT's performance, discovering potentially harmful behaviours, especially for sensitive topics like mental health. Finally, we use HAI-coaching to test open LLMs on various downstream tasks, showing that even the latest models struggle to achieve good performance. HAI-coaching is available at https://anonymous.4open.science/r/3z2",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IIYiBQraWe": {
    "title": "Solving the Inverse Alignment Problem for Efficient RLHF",
    "volume": "review",
    "abstract": "Collecting high-quality preference datasets for reinforcement learning from human feedback (RLHF) is resource-intensive and challenging. As a result, researchers often train reward models on extensive offline datasets which aggregate diverse generation sources and scoring/alignment policies. We hypothesize that this aggregation has an averaging effect on reward model scores, which limits signal and impairs the alignment process. Inspired by the field of inverse RL, we define the ``inverse alignment problem'' in language model training, where our objective is to optimize the critic's reward for a fixed actor and a fixed offline preference dataset. We hypothesize that solving the inverse alignment problem will improve reward model quality by providing clearer feedback on the policy's current behavior. To that end, we investigate whether repeatedly fine-tuning a reward model on subsets of the offline preference dataset aligned with a periodically frozen policy during RLHF improves upon vanilla RLHF. Our empirical results demonstrate that this approach facilitates superior alignment and faster convergence compared to using an unaligned or out-of-distribution reward model relative to the LLM policy",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rDb0EUHIgu": {
    "title": "SedarEval: Automated Evaluation using Self-Adaptive Rubrics",
    "volume": "review",
    "abstract": "The evaluation paradigm of LLM-as-judge gains popularity due to its significant reduction in human labor and time costs. This approach utilizes one or more large language models (LLMs) to assess the quality of outputs from other LLMs. However, existing methods rely on generic scoring rubrics that fail to consider the specificities of each question and its problem-solving process, compromising precision and stability in assessments. Inspired by human examination scoring processes, we propose a new evaluation paradigm based on self-adaptive rubrics. Specifically, we create detailed scoring rubrics for each question, capturing the primary and secondary criteria in a structured format of scoring and deduction points that mimic a human evaluator's analytical process. Building on this paradigm, we further develop a novel benchmark called INSDA, which covers a range of domains including long-tail knowledge, mathematics, coding, and logical reasoning. INSDA consists of 1,000 meticulously crafted questions, each with its own self-adaptive rubric. To further streamline the evaluation, we train a specialized evaluator language model (evaluator LM) to supplant human graders. Using the same training data, our evaluator LM achieves a higher concordance rate with human grading results than other paradigms, including GPT-4, highlighting the superiority and efficiency of our approach",
    "checked": false,
    "id": "07ba6561ed3904d3e61a1750759066520a098b54",
    "semantic_title": "classroom evaluation of a gamified adaptive tutoring system",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=1xGA00uVtD": {
    "title": "Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models",
    "volume": "review",
    "abstract": "Causal graph recovery is traditionally done using statistical estimation-based methods or based on individual's knowledge about variables of interests. They often suffer from data collection biases and limitations of individuals' knowledge. The advance of large language models (LLMs) provides opportunities to address these problems. We propose a novel method that leverages LLMs to deduce causal relationships in general causal graph recovery tasks. This method leverages knowledge compressed in LLMs and knowledge LLMs extracted from scientific publication database as well as experiment data about factors of interest to achieve this goal. Our method gives a prompting strategy to extract associational relationships among those factors and a mechanism to perform causality verification for these associations. Comparing to other LLM-based methods that directly instruct LLMs to do the highly complex causal reasoning, our method shows clear advantage on causal graph quality on benchmark datasets. More importantly, as causality among some factors may change as new research results emerge, our method show sensitivity to new evidence in the literature and can provide useful information for updating causal graphs accordingly",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=c4BKOnm6uN": {
    "title": "TALEC: Teach Your LLM to Evaluate in Specific Domain with In-house Criteria by Criteria Division and Zero-shot Plus Few-shot",
    "volume": "review",
    "abstract": "With the rapid development of large language models (LLM), the evaluation of LLM becomes increasingly important. Measuring text gener- ation tasks such as summarization and article creation is very difficult. Especially in spe- cific application domains (e.g., to-business or to-customer service), in-house evaluation cri- teria have to meet not only general standards (correctness, helpfulness and creativity, etc.) but also specific needs of customers and busi- ness security requirements at the same time, making the evaluation more difficult. So far, the evaluation of LLM in business scenarios has mainly relied on manual, which is expensive and time-consuming. In this paper, we propose a model-based evaluation method: TALEC, which allows users to flexibly set their own evaluation criteria, and uses in-context learning (ICL) to teach judge model these in-house cri- teria. In addition, we try combining zero-shot and few-shot to make the judge model focus on more information. We also propose a prompt paradigm and an engineering approach to ad- just and iterate the shots ,helping judge model to better understand the complex criteria. We then compare fine-tuning with ICL, finding that fine-tuning can be replaced by ICL. TALEC demonstrates a strong capability to accurately reflect human preferences and achieves a cor- relation of over 80% with human judgments, outperforming even the inter-human correlation in some tasks",
    "checked": true,
    "id": "6eec3166b5c0920573cd838e6d308c416dc06da4",
    "semantic_title": "talec: teach your llm to evaluate in specific domain with in-house criteria by criteria division and zero-shot plus few-shot",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XEISCKCFtK": {
    "title": "On the Fragility of Active Learners for Text Classification",
    "volume": "review",
    "abstract": "Active learning (AL) techniques optimally utilize a labeling budget by iteratively selecting instances that are most valuable for learning. However, they lack \"prerequisite checks\", i.e., there are no prescribed criteria to pick an AL algorithm best suited for a dataset. A practitioner must pick a technique they \\emph{trust} would beat random sampling, based on prior reported results, and hope that it is resilient to the many variables in their environment: dataset, labeling budget and prediction pipelines. The important questions then are: how often on average, do we expect any AL technique to reliably beat the computationally cheap and easy-to-implement strategy of random sampling? Does it at least make sense to use AL in an ``Always ON'' mode in a prediction pipeline, so that while it might not always help, it never under-performs random sampling? How much of a role does the prediction pipeline play in AL's success? We examine these questions in detail for the task of text classification using pre-trained representations, which are ubiquitous today. Our primary contribution here is a rigorous evaluation of AL techniques, old and new, across setups that vary wrt datasets, text representations and classifiers. This unlocks multiple insights around warm-up times, i.e., number of labels before gains from AL are seen, viability of an ``Always ON'' mode and the relative significance of different factors. Additionally, we release a framework for rigorous benchmarking of AL techniques for text classification",
    "checked": true,
    "id": "a24650d2caf7a3bee9b17d2dc436f63f1629d205",
    "semantic_title": "on the fragility of active learners for text classification",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5kxm5l55Nv": {
    "title": "PSST: A Benchmark for Evaluation-driven Text Public-Speaking Style Transfer",
    "volume": "review",
    "abstract": "Language style is necessary for AI systems to accurately understand and generate diverse human language. However, previous text style transfer primarily focused on sentence-level data-driven approaches, limiting exploration of potential problems in large language models (LLMs) and the ability to meet complex application needs. To overcome these limitations, we introduce a novel task called Public-Speaking Style Transfer (PSST), which aims to simulate humans to transform passage-level, official texts into a public-speaking style. Grounded in the analysis of real-world data from a linguistic perspective, we decompose public-speaking style into key sub-styles to pose challenges and quantify the style modeling capability of LLMs. For such intricate text style transfer, we further propose a fine-grained evaluation framework to analyze the characteristics and identify the problems of stylized texts. Comprehensive experiments suggest that current LLMs struggle to generate public speaking texts that align with human preferences, primarily due to excessive stylization and loss of semantic information. We will release our data, code, and model upon acceptance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FlnkfDLudm": {
    "title": "On the Universal Truthfulness Hyperplane Inside LLMs",
    "volume": "review",
    "abstract": "While large language models (LLMs) have demonstrated remarkable abilities across various fields, hallucination remains a significant challenge. Recent studies have explored hallucinations through the lens of internal representations, proposing mechanisms to decipher LLMs' adherence to facts. However, these approaches often fail to generalize to out-of-distribution data, leading to concerns about whether internal representation patterns reflect fundamental factual awareness, or only overfit spurious correlations on the specific datasets. In this work, we investigate whether a universal truthfulness hyperplane that distinguishes the model's factually correct and incorrect outputs exists within the model. To this end, we scale up the number of training datasets and conduct an extensive evaluation -- we train the truthfulness hyperplane on a diverse collection of over 40 datasets and examine its cross-task, cross-domain, and in-domain generalization. Our results indicate that increasing the diversity of the training datasets significantly enhances the performance in all scenarios, while the volume of data samples plays a less critical role. This finding supports the optimistic hypothesis that a universal truthfulness hyperplane may indeed exist within the model, offering promising directions for future research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UPRRMBSCVJ": {
    "title": "ECON: On the Detection and Resolution of Evidence Conflicts",
    "volume": "review",
    "abstract": "The rise of large language models (LLMs) has significantly influenced the quality of information in decision-making systems, leading to the prevalence of AI-generated content and challenges in detecting misinformation and managing conflicting information, or \"inter-evidence conflicts.\" This study introduces a method for generating diverse, validated evidence conflicts to simulate real-world misinformation scenarios. We evaluate conflict detection methods, including Natural Language Inference (NLI) models, factual consistency (FC) models, and LLMs, on these conflicts (\\textbf{RQ1}) and analyze LLMs' conflict resolution behaviors (\\textbf{RQ2}). Our key findings include: (1) NLI and LLM models exhibit high precision in detecting answer conflicts, though weaker models suffer from low recall; (2) FC models struggle with lexically similar answer conflicts, while NLI and LLM models handle these better; and (3) stronger models like GPT-4 show robust performance, especially with nuanced conflicts. For conflict resolution, LLMs often favor one piece of conflicting evidence without justification and rely on internal knowledge if they have prior beliefs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nG4y9gy0jn": {
    "title": "HALLUCHECK: An Efficient & Effective Fact-Based Approach Towards Factual Hallucination Detection Of LLMs Through Self-Consistency",
    "volume": "review",
    "abstract": "Large language models (LLMs) frequently generate inaccurate responses -- this can be particularly dangerous in sensitive areas like medicine and healthcare. Current methods for detecting hallucinations involve sampling answers multiple times, making them computationally intensive. In this study, we introduce HalluCheck, a novel hallucination detection module that identifies factual elements or atomic facts within a text. HalluCheck operates on the premise that responses to questions probing factual answers should be consistent both within a single LLM and across different LLMs. To improve system robustness, we incorporate a token-probability-based double-check mechanism. For hallucinated facts, inconsistencies or a lack of model confidence during generation will be evident. We evaluate our detection module on fact-based datasets such as NQ\\_Open, HotpotQA, and WebQ, by building upon open-source LLMs such as LLaMa-2 (7B)-Instruct and Mistral-7B-Instruct. Finally, we compare the generated output with the correct answers to determine sentence-level AUC-ROC scores for hallucination detection. Our results demonstrate that HalluCheck can (i) detect hallucinated facts and (ii) achieve significantly higher AUC-ROC scores compared to existing baselines that operate under similar conditions, specifically those that do not utilize external databases for hallucination detection",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=olGXnHrQSs": {
    "title": "Discourse Parsing in the Wild : Enhancing Discourse Parsing for Localized Structures from Social Media with LLM-Generated Data",
    "volume": "review",
    "abstract": "This study addresses challenges in discourse parsing for localized discourse structures on Social Media by using Large Language Models to generate synthetic data. We focus on a specific discourse structure in online immigration-related discussions, characterized by joint joint evaluation coherence relations. Our approach includes annotating and generating synthetic data, then evaluating two parsers—bottom-up and a top-down parser—trained on this data. We focus on parsing in real-world scenarios where edu segmentation is performed from scratch, reflecting practical parser use for discourse analysis beyond annotated RST corpora. We highlight the challenge of identifying coherence relations in longer texts, a task often overlooked in tree-based evaluations which typically assess the entire structure",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=811DnH3ZqN": {
    "title": "Boosting Decision-Making Ability of LLMs with Speculative Reward Model Cost-Effectively",
    "volume": "review",
    "abstract": "Efficient decision-making in Large Language Models (LLMs) for intricate tasks is impeded by the substantial inference cost. The prevailing search algorithms tend to focus solely on performance enhancement, ignoring the cost-effectiveness trade-off. To address these challenges, we first utilize the 3E Criteria to systematically evaluate the cost-benefit balance of current search strategies. We found current methods typically sacrifice vast efficiency for marginal improvement of effectiveness. In order to empower LLMs effective decision-making capability with balanced efficiency, we present a plug-and-play framework with Speculative Reward Model (SRM), which leverages external reward assigner to speculate the preferential actions, not just rely on self-evaluation inside LLMs. Through speculative verification approach for pruning and efficient navigation toward more promising steps, SRM boosts decision-making ability of LLM cost-effectively. We evaluate SRM on several complex decision-making tasks including mathematical reasoning, planning and numerical reasoning for specific fields. Our results demonstrate the superiority of SRM for inference efficiency, which significantly lowers cost to a fraction of the original search framework's by 1/10 on average, without sacrificing effectiveness",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jicM6vUE6E": {
    "title": "IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language",
    "volume": "review",
    "abstract": "Hate speech poses a significant threat to social harmony. Over the past two years, Indonesia has seen a ten-fold increase in the online hate speech ratio, underscoring the urgent need for effective detection mechanisms. However, progress is hindered by the limited availability of labeled data for Indonesian texts. The condition is even worse for marginalized minorities, such as Shia, LGBTQ, and other ethnic minorities because hate speech is underreported and less understood by detection tools. Furthermore, the lack of accommodation for subjectivity in current datasets compounds this issue. To address this, we introduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity classification dataset. Comprising 43,692 entries annotated by 19 diverse individuals, the dataset focuses on texts targeting vulnerable groups in Indonesia, specifically during the hottest political event in the country: the presidential election. We establish baselines for seven binary classification tasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet) fine-tuned for hate speech classification. Furthermore, we demonstrate how incorporating demographic information can enhance the zero-shot performance of the large language model, gpt-3.5-turbo. However, we also caution that an overemphasis on demographic information can negatively impact the fine-tuned model performance due to data fragmentation",
    "checked": true,
    "id": "3d4b5e6f59deba7a4fb76fa095ea6a562a8f5ee0",
    "semantic_title": "indotoxic2024: a demographically-enriched dataset of hate speech and toxicity types for indonesian language",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cU2EUwz0mv": {
    "title": "Mixture-of-Subspaces in Low-Rank Adaptation",
    "volume": "review",
    "abstract": "In this paper, we introduce a subspace-inspired Low-Rank Adaptation (LoRA) method, which is computationally efficient, easy to implement, and readily applicable to large language, multimodal, and diffusion models. Initially, we equivalently decompose the weights of LoRA into two subspaces, and find that simply mixing them can enhance performance. To study such a phenomenon, we revisit it through a fine-grained subspace lens, showing that such modification is equivalent to employing a fixed mixer to fuse the subspaces. To be more flexible, we jointly learn the mixer with the original LoRA weights, and term the method as Mixture-of-Subspaces LoRA (MoSLoRA). MoSLoRA consistently outperforms LoRA on tasks in different modalities, including commonsense reasoning, visual instruction tuning, and subject-driven text-to-image generation, demonstrating its effectiveness and robustness",
    "checked": true,
    "id": "e2403e398314d49c5f56e05105a420a6f93e3cb2",
    "semantic_title": "mixture-of-subspaces in low-rank adaptation",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=MHyCm3J9C2": {
    "title": "Measure LLM knowledge via RIG (Raw Information Gain) over preliminarily crafted probes",
    "volume": "review",
    "abstract": "We propose a novel high-level approach to analyze models in a different way: we could estimate amount of information receipted by a model using a crafted set of control statements. We introduce a new metrics RIG (raw information gain) in order to do so. Any LLM (large language model) could be considered a \"black box\" of compressed information. It is hard to measure what amount of information is stored inside the model regarding any domain. The contrast between the size of a trained model of around 43GB compared to 15 trillion tokens of training data is staggering The other issue is to figure out where do the limits come from: is it an architectural constraint or is the limitation coming from the data used in training. So far the most common way to identify if the model is properly trained and contains necessary information is to put it through a list of benchmarks and the decision is based on either it's ranking or some educated guess of a score threshold. Keeping in mind that the most of those benchmarks become part of training data for upcoming models we face a vicious cycle of never ending benchmark creation. Taken into account constant size growth of both language models and datasets we face an challenge of losing a track of what is efficient and what is not to train models as well as simple scale of the datasets makes them almost impossible to supervise at all, what is an immense obstacle when we need to update any language model according to different environments those are implemented at and we need to bring ethical issues, actuality of the human knowledge and controversial statements altogether",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7G3BTM5BFQ": {
    "title": "Pairing Analogy-Augmented Generation with Procedural Memory for Procedural Q&A",
    "volume": "review",
    "abstract": "While LLMs in the RAG paradigm have shown remarkable performance on a variety of tasks, they still under-perform on unseen domains, especially on complex tasks like procedural question answering. In this work, we introduce a novel formalism and structure for manipulating text-based procedures. Based on this formalism, we further present a novel dataset called LCStep, scraped from the LangChain Python docs. Moreover, we extend the traditional RAG system to propose a novel system called Analogy Augmented Generation (AAG), that draws inspiration from human analogical reasoning and ability to assimilate past experiences to solve unseen problems. The proposed method uses a frozen language model with a custom procedure memory store to adapt to specialized knowledge. We demonstrate that AAG outperforms few-shot and RAG baselines on LCStep, RecipeNLG, and the CHAMP datasets under a pairwise LLM-based evaluation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QzaK1U1S1w": {
    "title": "LogicPro: Logical Reasoning Enhanced with Program Examples",
    "volume": "review",
    "abstract": "In this paper, we present a novel approach, called \\textbf{LogicPro}, to enhance \\underline{Logic} reasoning through \\underline{Pro}gram examples to improve multiple complex reasoning tasks simultaneously. We do this effectively by simply utilizing widely available algorithmic problems and their code solutions. First, we constructed diverse input test samples based on algorithmic questions and code solutions. Then, we designed different logic reasoning questions based on the algorithmic problems and test samples. Finally, combining the intermediate variable outputs of the code solutions and the logic reasoning questions, we obtain the final reasoning path through a large language model. Based on this, we are able to construct very rich \\textit{SFT} data. At the same time, we construct a diverse and scalable dataset of logical reasoning evaluation by treating each algorithmic question as a reasoning rule. As a result, our approach achieves significant improvements on multiple models for BBH dataset (20+ subsets), GSM8K and HellSwag datasets, and significantly outperforms a wide range of existing logical reasoning datasets. In addition, our eval data distinguishes well between existing models and brings new challenges to the model",
    "checked": false,
    "id": "1b234c4a18f54329820a9ec2e8da0abec6e7149e",
    "semantic_title": "simply logical - intelligent reasoning by example",
    "citation_count": 81,
    "authors": []
  },
  "https://openreview.net/forum?id=cojlzteFYT": {
    "title": "Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) offer the potential for automatic time series analysis and reporting, which is a critical task across many domains, spanning healthcare, finance, climate, energy, and many more. In this paper, we propose a framework for rigorously evaluating the capabilities of LLMs on time series understanding, encompassing both univariate and multivariate forms. We introduce a comprehensive taxonomy of time series features, a critical framework that delineates various characteristics inherent in time series data. Leveraging this taxonomy, we have systematically designed and synthesized a diverse dataset of time series, embodying the different outlined features, each accompanied by textual descriptions. This dataset acts as a solid foundation for assessing the proficiency of LLMs in comprehending time series. Our experiments shed light on the strengths and limitations of state-of-the-art LLMs in time series understanding, revealing which features these models readily comprehend effectively and where they falter. In addition, we uncover the sensitivity of LLMs to factors including the formatting of the data, the position of points queried within a series and the overall time series length",
    "checked": true,
    "id": "80b06bb6b5ab0e6e6de9eecf8d5829dec2f6df57",
    "semantic_title": "evaluating large language models on time series feature understanding: a comprehensive taxonomy and benchmark",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aJjVT5ri76": {
    "title": "A Narrative Framework for Analyzing Partisan Perspectives in Event Discourse",
    "volume": "review",
    "abstract": "Experts from several domains, especially political science, are interested in analyzing political discourse associated with real-world news events. This process would typically require researchers to manually analyze a large collection of news articles on a given event, in order to characterize the underlying partisan perspectives from each side of the political map. Instead, in this work, we propose a systematic approach to summarize partisan perspectives, in an automated manner. Our framework allows us to represent each news article with a predefined structure, comprising of talking points, which we then cluster to identify the repeating themes that collectively shape the narrative of an event. Then, we utilize the resulting clusters to generate a summary for each ideology, left and right, that indicates how each side discusses the event. We show the effectiveness of our framework in capturing partisan perspectives across automated proxy tasks, and human evaluation over a set of events. We release the dataset derived from our narrative framework to the research community",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gpo4L9k1Ol": {
    "title": "From Instructions to Basic Human Values: A Survey of Alignment Goals for Big Model",
    "volume": "review",
    "abstract": "As big models demonstrate remarkable performance across diverse tasks, concerns about their potential risks and social harms are raised. Extensive efforts have been made towards aligning big models with humans to ensure their responsible development and human profits maximization. Nevertheless, the question `what to align with' remains largely unexplored. It is critical to precisely define the objectives for big models to pursue, since aligning with inappropriate goals could cause disaster, e.g., chatbots promote abusive or biased contents when only instructed to interact freely. This paper conducts a comprehensive survey of different alignment goals, tracing their evolution paths to identify the most appropriate goal for big models. Specifically, we categorize existing goals into four levels: human instructions, human preferences, value principles and basic values, revealing a learning process from basic abilities to intrinsic value concepts. For each goal, we elaborate its definition, limitation, how techniques are designed to achieve it and how to evaluate the alignment. Posing basic values as a promising goal, we discuss technical challenges and future research directions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BqGUy8eT4C": {
    "title": "RepoHyper: Hybrid Retrieval for Repository-level Code Completion",
    "volume": "review",
    "abstract": "Code Large Language Models (CodeLLMs) have demonstrated impressive proficiency in code completion tasks. However, they often fall short of fully understanding the extensive context of a project repository, such as the intricacies of relevant files and class hierarchies, which can result in less precise completions. To overcome these limitations, we present \\tool, a multifaceted framework designed to address the complex challenges associated with repository-level code completion. Central to \\tool is the {\\em Repo-level Semantic Graph} (RSG), a novel semantic graph structure that encapsulates the vast context of code repositories. Furthermore, \\tool leverages \\textit{Expand and Refine} retrieval method, including a graph expansion and a link prediction algorithm applied to the RSG, enabling the effective retrieval and prioritization of relevant code snippets. Our evaluations show that \\tool markedly outperforms existing techniques in repository-level code completion, showcasing enhanced accuracy across various datasets when compared to several strong baselines",
    "checked": false,
    "id": "d7fc8fc5510f31469ba263253ec54edd7821cf8d",
    "semantic_title": "repohyper: better context retrieval is all you need for repository-level code completion",
    "citation_count": 12,
    "authors": []
  },
  "https://openreview.net/forum?id=xmG4oGCxJH": {
    "title": "Towards Expert Legal LLM Responses: Logical Structure and Semantic Information Integration",
    "volume": "review",
    "abstract": "Large language models (LLMs) have demonstrated excellent performance across various fields. Nevertheless, they exhibit notable deficiencies when addressing legal questions. In the legal field, LLMs often provide generalized responses, lacking the necessary specificity for expert legal advice. Additionally, they tend to provide answers that appear correct but are unreliable due to issues with hallucination. Retrieval-Augmented Generation (RAG) is a popular approach to addressing these issues. However, existing methods often focus solely on semantic-level similarity, neglecting the logical structure relationships between different legal questions. In this paper, we propose a Logical-Semantic Integration Model (LSIM), which consists of three components. First, reinforcement learning is used to predict the fact-rule chain of thought for the given question. Secondly, the DSSM model that integrates logical structure and semantic information is used to retrieve the most relevant candidate questions from the database. Finally, in-context learning is used to generate the final answer. Experiments on a real-world legal QA dataset, using both automated evaluation metrics and human evaluation, demonstrate the effectiveness of the proposed method. The dataset will be released to the community to promote the development of the legal QA field。",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eMUKOywNK3": {
    "title": "CPsyExam: A Chinese Benchmark for Evaluating Psychology using Examinations",
    "volume": "review",
    "abstract": "In this paper, we introduce a novel psychological benchmark, CPsyExam, constructed from questions sourced from Chinese examination systems. CPsyExam is designed to prioritize psychological knowledge and case analysis separately, recognizing the significance of applying psychological knowledge to real-world scenarios. We collect 22k questions from 39 psychology-related subjects across four Chinese examination systems. From the pool of 22k questions, we utilize 4k to create the benchmark that offers balanced coverage of subjects and incorporates a diverse range of case analysis techniques. Furthermore, we evaluate a range of existing large language models(LLMs), spanning from open-sourced to proprietary models. Our experiments and analysis demonstrate that CPsyExam serves as an effective benchmark for enhancing the understanding of psychology within LLMs and enables the comparison of LLMs across various granularities",
    "checked": true,
    "id": "10da92399630f5ee4e37f51ac21d278d829e9253",
    "semantic_title": "cpsyexam: a chinese benchmark for evaluating psychology using examinations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FVTPELeltD": {
    "title": "Direct Multi-Turn Preference Optimization for Language Agents",
    "volume": "review",
    "abstract": "Adapting Large Language Models (LLMs) for agent tasks is critical in developing language agents. Direct Preference Optimization (DPO) is a promising technique for this adaptation with the alleviation of compounding errors, offering a means to directly optimize Reinforcement Learning (RL) objectives. However, applying DPO to multi-turn tasks presents challenges due to the inability to cancel the partition function. Overcoming this obstacle involves making the partition function independent of the current state and addressing length disparities between preferred and dis-preferred trajectories. In this light, we replace the policy constraint with the state-action occupancy measure constraint in the RL objective and add length normalization to the Bradley-Terry model, yielding a novel loss function named DMPO for multi-turn agent tasks with theoretical explanations. Extensive experiments on three multi-turn agent task datasets confirm the effectiveness and superiority of the DMPO loss",
    "checked": true,
    "id": "3b5778b0aec88c1921fee7538400e49bed42a5fa",
    "semantic_title": "direct multi-turn preference optimization for language agents",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oFq2Pn8Xqr": {
    "title": "CONSTRUCTURE: Benchmarking CONcept STRUCTUre REasoning for Multimodal Large Language Models",
    "volume": "review",
    "abstract": "Multimodal Large Language Models (MLLMs) have shown promising results in various tasks, but their ability to perceive the visual world with deep, hierarchical understanding similar to humans remains uncertain. To address this gap, we introduce CONSTRUCTURE, a novel concept-level benchmark to assess MLLMs' hierarchical concept understanding and reasoning abilities. Our goal is to evaluate MLLMs across four key aspects: 1) Understanding atomic concepts at different levels of abstraction; 2) Performing upward abstraction reasoning across concepts; 3) Achieving downward concretization reasoning across concepts; and 4) Conducting multi-hop reasoning between sibling or common ancestor concepts. Our findings indicate that even state-of-the-art multimodal models struggle with concept structure reasoning (e.g., GPT-4o averages a score of 62.1\\%). We summarize key findings of MLLMs in concept structure reasoning evaluation. Morever, we provide key insights from experiments using CoT prompting and fine-tuning to enhance their abilities",
    "checked": false,
    "id": "681cee58cf7e54199191cf9e0baf6851d8356704",
    "semantic_title": "complex qa and language models hybrid architectures, survey",
    "citation_count": 11,
    "authors": []
  },
  "https://openreview.net/forum?id=JVtQWJXang": {
    "title": "Chain of Condition: Construct, Verify and Solve Conditions for Conditional Question Answering",
    "volume": "review",
    "abstract": "Conditional question answering (CQA) is an important task that aims to find probable answers and identify conditions that need to be satisfied to support the answer. Existing approaches struggle with CQA due to two main challenges: (1) precisely identifying conditions and their logical relationship, and (2) verifying and solving the conditions. To address these challenges, we propose Chain of Condition, a novel prompting approach by firstly identifying all conditions and constructing their logical relationships explicitly according to the document, then verifying whether these conditions are satisfied, finally solving the logical expression by tools to indicate any missing conditions and generating the answer based on the resolved conditions. The experiments on two benchmark conditional question answering datasets shows chain of condition outperforms existing prompting baselines, establishing a new state-of-the-art. Furthermore, with backbone models like GPT-3.5-Turbo or GPT-4, it surpasses all supervised baselines with only few-shot settings",
    "checked": true,
    "id": "d8a3d1088540065be6bc41365750055125039a40",
    "semantic_title": "chain of condition: construct, verify and solve conditions for conditional question answering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YHUUBTF2HW": {
    "title": "Towards Strategic Persuasion: Unveiling Users' Susceptibility to Persuasive Strategies in Dialogues",
    "volume": "review",
    "abstract": "Generative AI's rapid evolution has made dialogue systems indispensable tools. While persuasive strategies have been incorporated in dialogue systems to provide personalized services, current research primarily focuses on studying persuasive strategies from persuader's perspective, with limited exploration of persuadee's susceptibility towards these strategies. To bridge this gap, we introduce a novel task called Susceptibility Strategy Detection, aimed at identifying the persuasive strategies that users are most susceptible to. To support this new task, we develop a refined dataset P4G+, and propose a dual attitude-sensitive framework to detect susceptibility strategy by analyzing the persuasive process, user interactions, and content within dialogues. Comprehensive experiments have demonstrated the efficacy of our approach in identifying users' susceptible strategies. The code and dataset will be made available upon acceptance of this paper",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wNvMf766ZJ": {
    "title": "Improving Language Model Self-Correction with Meta-Feedback",
    "volume": "review",
    "abstract": "Large language models (LLMs) are capable of self-correct their responses by generating feedback and refining the initial output. However, their performance may sometimes decline following self-correction, either because the feedback contains errors or because they unnecessarily attempt to refine an already accurate response. To address these limitations, we investigate whether LLMs can generate meta-feedback that pinpoints errors in the feedback rather than the response.While the ability of LLMs to generate self-feedback has been well-researched, their potential to provide constructive meta-feedback remains under-explored. We design a novel self-correction prompting framework, Feedback-on-Feedback (FoF), which leverages meta-feedback to improve the feedback before refining the response. Our framework first samples multiple feedbacks for the initial response, and prompts the LLM to generate a meta-feedback that analyze the inconsistency between these feedbacks. Based on the meta-feedback, the LLM generates a refined feedback that subsequently guides the revision of the response. Our FoF framework uniformly outperforms competitive baselines across two base models in different sizes and three datasets spanning arithmetic reasoning, machine translation and programming, with an improvement of up to 1.68% in GSM8K task by LLaMA3-8B model",
    "checked": false,
    "id": "df90ee11ed6378635f22e6d0061cf67dd0bacd13",
    "semantic_title": "meta-rewarding language models: self-improving alignment with llm-as-a-meta-judge",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=rvXzn73Gxm": {
    "title": "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA",
    "volume": "review",
    "abstract": "Long-context modeling capabilities of Large Language Models (LLMs) have garnered widespread attention, leading to the emergence of LLMs with ultra-context windows. Meanwhile, benchmarks for evaluating long-context language models are gradually catching up. However, existing benchmarks employ irrelevant noise texts to artificially extend the length of test cases, diverging from the real-world scenarios of long-context applications. To bridge this gap, we propose a novel long-context benchmark, Loong, aligning with realistic scenarios through extended multi-document question answering (QA). Unlike typical document QA, in Loong's test cases, each document is relevant to the final answer, ignoring any document will lead to the failure of the answer. Furthermore, Loong introduces four types of tasks with a range of context lengths: Spotlight Locating, Comparison, Clustering, and Chain of Reasoning, to facilitate a more realistic and comprehensive evaluation of long-context understanding. Extensive experiments indicate that existing long-context language models still exhibit considerable potential for enhancement. Retrieval augmented generation (RAG) achieves poor performance, demonstrating that Loong can reliably assess the model's long-context modeling capabilities",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=heAXhUzqYI": {
    "title": "FD-Bench: Evaluating the Decision-Making Capability of LLM Agents in Dynamic Scenarios through Fire Evacuation",
    "volume": "review",
    "abstract": "LLMs as general-purpose agents have gained widespread application in practical domains due to robust autonomous decision-making capabilities and extensive world knowledge. However, recent studies have highlighted that the dynamicity inherent in real-world environments poses significant challenges to the decision-making abilities of LLM agents, making the investigation of LLM decision-making boundaries in dynamic environments an urgent and formidable task. Current evaluation benchmarks primarily focus on assessing LLM decision-making performance in static and interactive environments, which significantly differ from the dynamicity present in real-world scenarios. Furthermore, existing evaluation frameworks lack fine-grained assessments of LLMs' capabilities, providing limited insights during the evaluation process and hindering a comprehensive understanding of the models' capabilities. To address these limitations, we propose FD-Bench, a framework for evaluating the decision-making abilities of LLM agents in dynamic scenarios. FD-Bench employs a fire evacuation scenario as a representative dynamic setting, offering a generalized evaluation framework and a step-wise evaluation strategy to comprehensively analyze and capture variations in decision-making abilities. This framework provides a comprehensive understanding of the decision-making capabilities and limitations of LLM agents in dynamic environments, laying the foundation for their potential deployment in more realistic physical scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1a5gtWNCAr": {
    "title": "Advancing Idiomatic Understanding: Evaluating GPT­3.5 and Google Translate for Persian­English Translations",
    "volume": "review",
    "abstract": "Figurative language, especially idiomatic expressions, poses significant translation challenges due to its cultural and contextual nuances. Large Language Models (LLMs) like GPT-3.5 have shown greater capability in translating figurative language compared to state-of-the-art neural machine translation (NMT) systems. However, the impact of different prompting methods and combining NMTs and LLMs on idiom translation remains unexplored. This paper introduces two parallel datasets for Persian\\rightarrow English and English\\rightarrow Persian translation to address these challenges. The Persian idiom examples are sampled from our PersianIdioms resource, which is compiled from an online dictionary and contains 2200 idioms with their meanings and popularity scores. Using these datasets, we evaluate GPT models, Google Translate, and their combination, focusing on idiom translation accuracy, fluency, and contextual relevance. Additionally, we assess existing automatic evaluation metrics and GPT-3.5 and GPT-4 for evaluating idiomatic translations. Our results indicate that while Google Translate shows superior fluency, GPT-3.5 excels in accurately translating idioms. We also show that models are better at translating English idioms than Persian ones, and different configurations of models perform differently depending on the direction of translation. We will release all our resources and annotations upon publication",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3ilKqohjYS": {
    "title": "TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities",
    "volume": "review",
    "abstract": "Task-oriented dialogue (TOD) systems aim to efficiently handle task-oriented conversations, including information gathering. How to utilize ToD accurately, efficiently and effectively for information gathering has always been a critical and challenging task. Recent studies have demonstrated that Large Language Models (LLMs) excel in dialogue, instruction generation, and reasoning, and can significantly enhance the performance of TOD through fine-tuning. However, current datasets primarily cater to user-led systems and are limited to predefined specific scenarios and slots, thereby necessitating improvements in the proactiveness, diversity, and capabilities of TOD. In this study, we present a detailed multi-domain task-oriented data construction process for conversations, and a Chinese dialogue dataset generated based on this process, \\textbf{TransferTOD}, which authentically simulates human-machine dialogues in 30 popular life service scenarios. Leveraging this dataset, we trained a \\textbf{TransferTOD-7B} model using full-parameter fine-tuning, showcasing notable abilities in slot filling and questioning. Our work has demonstrated its strong generalization capabilities in various downstream scenarios, significantly enhancing both data utilization efficiency and system performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X9lpoxnJLu": {
    "title": "Bayesian Calibration of Win Rate Estimation with LLM Evaluators",
    "volume": "review",
    "abstract": "Recent advances in large language models (LLMs) show the potential of using LLMs as evaluators for assessing the quality of generations from LLMs. However, applying LLM evaluators naively to compare different systems can lead to unreliable results due to inaccuracy and intrinsic bias of LLM evaluators. In order to mitigate this problem, we propose two calibration methods, Bayesian Win-Rate Sampling (BWRS) and Bayesian Dawid-Skene, which both leverage Bayesian inference to more accurately infer the true win rate of generative language models. We empirically validate our methods on seven datasets including story generation, summarization, and instruction following. We show that both our methods are effective in improving the accuracy of win rate estimation using LLMs as evaluators, offering a promising direction for reliable automatic text quality evaluation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dfIZ6FQw3M": {
    "title": "EchoSight: Advancing Visual-Language Models with Wiki Knowledge",
    "volume": "review",
    "abstract": "Knowledge-based Visual Question Answering (KVQA) tasks require answering questions about images using extensive background knowledge. Despite significant advancements, generative models often struggle with these tasks due to the limited integration of external knowledge. In this paper, we introduce **EchoSight**, a novel multimodal Retrieval-Augmented Generation (RAG) framework that enables large language models (LLMs) to answer visual questions requiring fine-grained encyclopedic knowledge. To strive for high-performing retrieval, EchoSight first searches wiki articles by using visual-only information, subsequently, these candidate articles are further reranked according to their relevance to the combined text-image query. This approach significantly improves the integration of multimodal knowledge, leading to enhanced retrieval outcomes and more accurate VQA responses. Our experimental results on the E-VQA and InfoSeek datasets demonstrate that EchoSight establishes new state-of-the-art results in knowledge-based VQA, achieving an accuracy of 41.8% on E-VQA and 31.3% on InfoSeek",
    "checked": true,
    "id": "7242478180247ef7bf335112aed16d4fc5d2d133",
    "semantic_title": "echosight: advancing visual-language models with wiki knowledge",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dJyrh0FxYg": {
    "title": "Do Explanations Help or Hurt? Saliency Maps vs Natural Language Explanations in a Clinical Decision-Support Setting",
    "volume": "review",
    "abstract": "As AI models are becoming more powerful, their adoption is becoming more widespread, including in safety-critical domains. Explainable AI (XAI) has the aim of making these models safer to use, for instance by making their decision-making process more transparent. However, current explainability methods are seldom evaluated in the way they are intended to be used: by real-world end users. To address this, we conducted a large-scale user study with 85 clinicians in the context of human-AI collaborative chest X-ray analysis. We evaluated three types of explanations: saliency maps, natural language explanations, and their combination. We specifically examine how different explanation types influence users depending on whether the AI is correct. We find that the quality of explanations, i.e., how much correct information they entail, and how much this aligns with AI correctness, significantly impacts the usefulness of the different explanation types",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lD0mamNmAM": {
    "title": "Exploring Domain Adaptation with LLMs for Real-World Augmented Question Answer Generation (RA-QAG) in Children Storytelling",
    "volume": "review",
    "abstract": "In the real world, external domain-specific knowledge is commonly required, for instance, teachers often apply their expertise to ask preschoolers educational-crafted, story-inspired questions beyond the story content during interactive storytelling; however, existing storytelling systems could not effectively support such activity as the generated questions are mostly text-based. We formulate this type of common real-world application as a novel Real-World Augmented QAG (RA-QAG) task. This work aims to explore how well LLMs, equipped with various domain adaptation strategies (e.g., few-shot In-Context Learning, Chain-of-Thoughts, Retrieval-Augmented Generation), perform on the RA-QAG task in the context of children storytelling. We design and experiment with end-to-end and 2-Step QAG pipelines with different domain adaptation strategies to explore whether they can identify real-world knowledge and create QA pairs aligned with experts' annotation. Our automatic evaluation and human evaluation show that 1) RAG is a promising direction to approach real-world domain-specific tasks; 2) human experts still have more nuanced knowledge from which generic LLMs need to learn",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7nOqhiXc10": {
    "title": "TAGCOS: Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data",
    "volume": "review",
    "abstract": "Instruction tuning has achieved unprecedented success in NLP, turning large language models into versatile chatbots. However, the increasing variety and volume of instruction datasets demand significant computational resources. To address this, it is essential to extract a small and highly informative subset (i.e., \\textit{Coreset}) that achieves comparable performance to the full dataset. Achieving this goal poses non-trivial challenges: 1) data selection requires accurate data representations that reflect the training samples' quality, 2) considering the diverse nature of instruction datasets, and 3) ensuring the efficiency of the coreset selection algorithm for large models. To address these challenges, we propose \\textit{\\textbf{T}ask-\\textbf{A}gnostic \\textbf{G}radient \\textbf{C}lustered C\\textbf{O}reset \\textbf{S}election} (\\textbf{\\ModelNameAbbre}). Specifically, we leverage sample gradients as the data representations, perform clustering to group similar data, and apply an efficient greedy algorithm for coreset selection. Experimental results show that our algorithm, selecting only 5\\% of the data, surpasses other unsupervised methods and achieves performance close to that of the full dataset",
    "checked": true,
    "id": "754989f5d425f7d5dd03dcc9ffc029b6df82384b",
    "semantic_title": "tagcos: task-agnostic gradient clustered coreset selection for instruction tuning data",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=FGZdm3jagP": {
    "title": "Improving Automatic Speech Recognition with Decoder-Centric Regularisation in Encoder-Decoder Models",
    "volume": "review",
    "abstract": "This paper introduces $\\textbf{De}$coder-$\\textbf{C}$entric $\\textbf{R}$egularisation in $\\textbf{E}$ncoder-$\\textbf{D}$ecoder (DeCRED) architecture for automatic speech recognition, where auxiliary classifier(s) are introduced in layers of the decoder module. Leveraging these classifiers, we propose two decoding strategies that re-estimate the next token probabilities. Pilot experiments conducted on the independent in-domain datasets identify the suitable placement and weighting of the auxiliary classifiers, resulting in a consistent word-error-rate (WER) reduction of up to 9% relative across different model sizes. Further experiments on a collection of multi-domain English datasets showed that DeCRED obtained competitive WERs as compared to Whisper-medium and outperformed OWSM v3; while relying only on a fraction of training data and model size. Finally, we also study the generalisation capabilities of DeCRED by evaluating on out-of-domain datasets, where we show an absoulte reduction of 2.7 and 2.9 WERs on AMI and Gigaspeech datasets respectively",
    "checked": false,
    "id": "3c692fe94d9bcd9d73e15d98f517386eac92c457",
    "semantic_title": "anatomy of industrial scale multilingual asr",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=NSlnJ03iaY": {
    "title": "Dynamic Order Template Prediction for Generative Aspect-Based Sentiment Analysis",
    "volume": "review",
    "abstract": "Aspect-based sentiment analysis (ABSA) assesses sentiments towards specific aspects within texts, resulting in detailed sentiment tuples. Previous ABSA models often use static templates to predict all of the elements in the tuples, and these models often fail to accurately capture dependencies between elements. Multi-view prompting method improves the performance of ABSA by predicting tuples with various templates and then ensembling the results. However, this method suffers from inefficiencies and out-of-distribution errors. In this paper, we propose a Dynamic Order Template (DOT) method for ABSA, which dynamically generates necessary views for each instance based on instance-level entropy. Ensuring the diverse and relevant view generation, our proposed method improves F1-scores on ASQP and ACOS datasets while significantly reducing inference time",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1h8rggcwWE": {
    "title": "MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme for Aspect Sentiment Triplet Extraction",
    "volume": "review",
    "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to co-extract the sentiment triplets in a given corpus. Existing approaches within the pretraining-finetuning paradigm tend to either meticulously craft complex tagging schemes and classification heads, or incorporate external semantic augmentation to enhance performance. In this study, we, for the first time, re-evaluate the redundancy in tagging schemes and the internal enhancement in pretrained representations. We propose a method to improve and utilize pretrained representations by integrating a minimalist tagging scheme and a novel token-level contrastive learning strategy. The proposed approach demonstrates comparable or superior performance compared to state-of-the-art techniques while featuring a more compact design and reduced computational overhead. Additionally, we are the first to formally evaluate GPT-4's performance in few-shot learning and Chain-of-Thought scenarios for this task. The results demonstrate that the pretraining-finetuning paradigm remains highly effective even in the era of large language models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kadMXEYf0Z": {
    "title": "Language Models as Simulations of Early Language Acquisition: analysis of expressive vocabulary",
    "volume": "review",
    "abstract": "Large language models (LLMs) have been shown to develop linguistic competence from mere exposure to language content, making them a promising avenue for investigating infants' language learning processes \\citep{lavechin2023babyslm,chang2022word}. Nevertheless, LLMs typically require orders of magnitude more data than children, and language outcomes cannot be directly compared. Here, we introduce \\textit{machine-CDI}, a metric based on the learner's output to enable a direct comparison of machines and infants on their expressive vocabulary as a function of input quantity. This metric adapts the Communicative Development Inventories \\citep{fenson2007macarthur,frank2017wordbank}, a normalized inventory of words to quantify child language development, to the evaluation set of language models. We illustrate machine-CDI by comparing the expressive vocabulary in infants and character language models (LSTMs and Transformers) trained on English audiobooks. The results show that language models approximately match the children's learning curves, although Transformers are delayed compared to LSTMs. A further analysis show that the models are more impacted by word frequency than children, with a large delay in acquiring low frequency words for models. This delay is found to be linked to the more general phenomenon of long tail truncation observed in language models, which makes them unable to learn words based on few shot observations. These results shed new light on the principles of language acquisition, and highlights important divergences in how humans and modern algorithms learn to process natural language",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vaEBK5FCLu": {
    "title": "A Closer Look into Mixture-of-Experts in Large Language Models",
    "volume": "review",
    "abstract": "Mixture-of-experts (MoE) architecture is gaining increasing attention due to its unique properties and remarkable performance, especially for language tasks. By sparsely activating a subset of parameters for each token, MoE architecture could increase the model size without sacrificing computational efficiency, achieving a better trade-off between performance and training costs. However, the underlying mechanism of MoE still lacks further exploration, and its modularization degree remains questionable. In this paper, we make an initial attempt to understand the inner workings of MoE-based large language models (LLMs). Concretely, we comprehensively study the parametric and behavioural features of three recent MoE-based models and reveal some intriguing observations, including (1) Neurons act like fine-grained experts and (2) The router of MoE usually selects experts with larger output norms. (3) The expert diversity increases as the layer increases, while the last layer is an outlier. Based on these observations, we also provide suggestions for a broad spectrum of MoE practitioners, such as router design and expert allocation. We hope this work could shed light on future research on the MoE framework and other modular architectures",
    "checked": true,
    "id": "f9088e3759b3b92fa33656e694730d14d9946d19",
    "semantic_title": "a closer look into mixture-of-experts in large language models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=PuUESZkwMT": {
    "title": "Exploring the Potential of Foundation Models as Reliable AI Contact Centers",
    "volume": "review",
    "abstract": "The emergence of foundation models with high generalization performance increases expectations for their use in Contact Center (CC) applications (e.g., AI agents). However, research on foundation model-based AICCs has not been sufficiently explored, and there is also a lack of phone call-based customer service datasets to evaluate their performance fairly across various attributes. Reference-based evaluation metrics may not be suitable for evaluating AI agent responses because they fail to account for multiple valid responses generated by AI agents. While we consider human evaluation (e.g., surveys) to be the ideal metric for AICCs, it can generally be costly, and specifically challenging to conduct immediately after a conversation. In this study, we explore whether foundation models in AICCs can provide fair and reliable answers, as well as discuss the need for an automatic evaluation method suitable for phone call-based customer service. Specifically, (1) we present audio-text data to validate the reliability and fairness of the foundation model-based AI agent across different subgroups based on regions, genders, and ages. (2) We customize a system prompt by combining domain-specific information and response guidance to apply foundation models to AICCs. (3) We propose an automatic evaluation method using LLMs called a generative model-based hierarchical dialogue evaluation metric and compare it with human evaluators to further investigate the feasibility of using a foundation model-based evaluation method",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XRuU1qscaR": {
    "title": "Beyond Token Generation: Adaptive Chunk-Distilled Language Modeling",
    "volume": "review",
    "abstract": "The remarkable capabilities of Large Language Models (LLMs) in text generation have been widely recognized. However, their inefficiency in generating text at the token level leaves room for improvement, and adapting these models to new data remains a challenging task. To tackle these challenges, we introduce a novel approach to language modeling -- Chunk-Distilled Language Modeling (CD-LM). By integrating deep neural networks with a straightforward retrieval module, our method allows the generation of text chunks containing fine-grained information through multiple tokens at a single decoding step. Our retrieval framework enables flexible construction of model- or domain-specific datastores, either leveraging the internal knowledge of pre-trained or fine-tuned models, or incorporating expert insights from human-annotated corpus. This adaptability allows for enhanced control over language model distribution without necessitating additional training. We present a formal formulation of our {\\name} framework, along with quantifiable performance metrics, demonstrating its efficacy in optimizing language model performance and efficiency across a diverse set of downstream tasks, including language modeling, text generation, and domain adaptation",
    "checked": false,
    "id": "fe99095df95638b6768e1c10682034d25353ed89",
    "semantic_title": "musegraph: graph-oriented instruction tuning of large language models for generic graph mining",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=IEAKog8TLo": {
    "title": "Iterative Context Vectors: Boost In-Context Learning within Activations",
    "volume": "review",
    "abstract": "In-context learning has become a standard learning paradigm for language models. However, current prompt engineering methods, which function within the token space, may restrict their effectiveness. We propose to explore the potential of activation space through Iterative Context Vectors (ICVs), a technique aimed at improving task performance without backpropagation. ICVs are employed by first extracting and iteratively refining activations within a language model, then applying them during inference with minimal computational and memory overhead. We evaluate ICVs across a range of tasks using various models and observe significant improvements. Our findings suggest that activation steering can serve as a promising direction for in-context learning, thereby opening new avenues for future research",
    "checked": false,
    "id": "5fbc97965c1221975e160193d64d220c21efaec9",
    "semantic_title": "non-iterative calculation of parameters of a linear classifier with a threshold activation function",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rTkhl8Z2Zz": {
    "title": "A Survey on Combating Hate Speech by Detection and Prevention",
    "volume": "review",
    "abstract": "With the rise in social media (SM) platforms that offer easy access, community formation, and online debate, the issue of hate speech has risen rapidly. The hate detection, and countering it becomes a growing challenge to society, researchers, companies, and policymakers. Hate speech is in the form of text or multimodal such as memes, GIFs, audio, or video. The scientific study of hate speech from a computer science view has gained attention in recent years. Mostly it is considered a supervised task where the annotated corpora and shared resources play a big role. To combat it, SM, employing modern AI tools is getting attention. This survey comprehensively examines the work done to combat hate in the English language so far. This structures the state-of-the-art methodologies employed for unimodal identification, studies conducted in multimodal hate identification, the role of Explainable AI, prevention of hate speech through style transfer, and counter-narrative generation for the English language. The efficacy and limitations are also discussed. Compared with the earlier surveys this paper concisely gives a well-organized presentation of the methods to combat hate",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4VzHv5s0Hp": {
    "title": "Personalized Preference Optimization for Text-to-Image Generation using Large Language Models",
    "volume": "review",
    "abstract": "Preference optimization is a crucial aspect of generative models, ensuring that the generated content aligns with users' preferences. While previous research has focused on optimizing for average preferences, text-to-image tasks require a personalized approach due to the diversity of individual preferences. In this study, we propose a two-stage framework for personalized preference optimization in text-to-image generation. The first stage, personalized image aesthetic assessment (PIAA), learns user preferences from a small amount of user image rating data. The second stage, prompt optimization, optimizes the text-to-image model's prompt to generate images that receive high scores from the learned preference model. We employ Large Language Models (LLMs) for the prompt optimization process. Through extensive experimentation with various configurations in the PIAA and prompt optimization stages, we demonstrate that our approach can generate novel images that align with individual user preferences, even with limited user data. Our research lays the foundation for future work on personalized content generation",
    "checked": false,
    "id": "cfb9eba1b5c55bb0052df41eaaff8716f9c420bd",
    "semantic_title": "pmg : personalized multimodal generation with large language models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=StzzP3HLho": {
    "title": "An Empirical Study of Gendered Stereotypes in Emotional Attributes for Bangla in Multilingual Large Language Models",
    "volume": "review",
    "abstract": "With the rapid growth of Large Language models, more and more jobs are being automated by using LLMs. Therefore, it is very important to assess the fairness of LLMs. Studies reveal the reflection of societal norms and biases in LLMs, which creates a risk of propagating societal stereotypes in downstream tasks. Numerous works have been done in various NLP applications regarding bias exhibition via LLMs and more so on gender bias. However there is a gap on the study of bias in emotional attributes, although human emotion and gender are closely related in societal discourse for almost all societies. The gap is even larger for a low resource language like Bangla. Historically women were more associated with emotional responses like empathy, fear or guilt, whereas men were more associated with anger, bravado, authority etc. This resonates with the societal system in areas where Bangla is prevalent. We offer the first thorough investigation of gendered emotion attribution in Bangla for both closed and open source LLMs in this work. Our aim is to elucidate the intricate societal relationship between gender and emotion specifically within the context of Bangla. All of our resources including code and data will be publicly available to support future research on Bangla NLP",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p9o4HVN12w": {
    "title": "DOLMA: Visual Instruction Tuning for Document AI",
    "volume": "review",
    "abstract": "The rapid expansion of Vision-Language Models (VLMs) has spurred research into their applicability across various domains. While VLMs excel in understanding environmental contexts, their effectiveness declines with visually-rich scanned documents. Although some VLMs use Optical Character Recognition (OCR) to mitigate this, OCR alone is insufficient for the complex textual and visual insights required. Developing tailored models for Document AI applications also demands substantial labeled data and high training costs. To address these challenges, we conducted experiments with various models, data types, architectures, and training methodologies. Based on our findings, we introduce DOLMA, an OCR-free vision-language model designed for diverse Document AI applications in a zero-shot setting. Despite having a moderate parameter count of 7 billion, DOLMA performs on par with models ten times larger on numerous Document AI benchmarks. The complete model, including weights, training data, and code, is publicly available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UslFMTBEFc": {
    "title": "Towards One-to-Many Visual Question Answering",
    "volume": "review",
    "abstract": "Most existing Visual Question Answering (VQA) systems are constrained to support domain-specific questions, i.e., to train different models separately for different VQA tasks, thus generalizing poorly to others. For example, models trained on the reasoning-focused dataset GQA struggle to effectively handle samples from the knowledge-emphasizing dataset OKVQA. Meanwhile, in real-world scenarios, it is user-unfriendly to restrict the domain of questions. Therefore, this paper proposes a necessary task: One-to-Many Visual Question Answering, of which the ultimate goal is to enable a single model to answer as many different domains of questions as possible by the effective integration of available VQA resources. To this end, we first investigate into ten common VQA datasets, and break the task of VQA down into the integration of three key abilities. Then, considering assorted questions rely on different VQA abilities, this paper proposes a novel dynamic Mixture of LoRAs (MoL) strategy. MoL mixes three individually trained LoRA adapters (corresponding to each VQA ability) dynamically for different samples demanding various VQA abilities. The proposed MoL strategy is verified to be highly effective by experiments, establishing SOTAs on four datasets. In addition, MoL generalizes well to three extra zero-shot datasets. Data and codes will be released",
    "checked": false,
    "id": "b2fcce1e640e761522030e55f3f9ab53e3b14963",
    "semantic_title": "toward unsupervised realistic visual question answering",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=WpJj2Dh1me": {
    "title": "Head-wise Shareable Attention for Large Language Models",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) suffer from huge number of parameters, which restricts their deployment on edge devices. Weight sharing is one promising solution that encourages weight reuse, effectively reducing memory usage with less performance drop. However, current weight sharing techniques primarily focus on small-scale models like BERT and employ coarse-grained sharing rules, e.g., layer-wise. This becomes limiting given the prevalence of LLMs and sharing an entire layer or block obviously diminishes the flexibility of weight sharing. In this paper, we present a perspective on head-wise shareable attention for large language models. We further propose two memory-efficient methods that share parameters across attention heads, with a specific focus on LLMs. % to reduce the memory usage for large PLMs. Both of them use the same dynamic strategy to select the shared weight matrices. The first method directly reuses the pre-trained weights without retraining, denoted as $\\textbf{DirectShare}$. The second method first post-trains with constraint on weight matrix similarity and then shares, denoted as $\\textbf{PostShare}$. Experimental results reveal our head-wise shared models still maintain satisfactory capabilities, demonstrating the feasibility of fine-grained weight sharing applied to LLMs",
    "checked": true,
    "id": "ee92723f03475fcfbb37ce8b8c888c497453ceb9",
    "semantic_title": "head-wise shareable attention for large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QDEQWe4mqm": {
    "title": "ShareLoRA: Less Tuning, More Performance for LoRA Fine-tuning of LLMs",
    "volume": "review",
    "abstract": "Due to the prohibitively expensive full fine-tuning costs of large language models (LLMs), various popular parameter-efficient fine-tuning (PEFT) methods have been developed. These methods majorly rely on fine-tuning few add-on modules, popularly referred to as {\\it adapters}, that corresponds to only \\textit{small fraction of LLM parameters}. In specific, low rank adaptation (LoRA), has demonstrated impressive parameter efficiency while yielding performance close to the full fine-tuning. However, classical LoRA may still fine-tune more parameters as compared to the inherent rank of the pre-trained weights \\cite{aghajanyan2020intrinsic}, leaving room for further parameter reduction. To mitigate this, only recently, few researches had proposed various freezing strategy of LoRA projection matrices, however, at the cost of additional FLOPs. To improve fine-tuning efficiency, in this work, we present ShareLoRA, that leverages a novel approach to use the redundancy in pre-trained model weights and share LoRA modules to significantly reduce the trainable parameter counts. In specific, \\autolora{} automatically finds the redundancy of the pre-trained weights and determines which LoRA adapters can share parameters. For this, \\autolora{} uses the similarity between representations to assess the information redundancy and a greedy algorithm to maximize the sharing of LoRA modules. We performed extensive evaluations with LLaMA family LLMs across various tasks. In specific, at reduced PEFT parameter count of up to \\textbf{23}$\\%$, ShareLoRA performs similar or better that of the existing PEFT alternatives",
    "checked": false,
    "id": "e923cdf6414b38fc639b015af43ac8aa82109411",
    "semantic_title": "iapt: instruction-aware prompt tuning for large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6F7jCU8yeA": {
    "title": "Disentangle to Decay: Linear Attention with Trainable Decay Factor",
    "volume": "review",
    "abstract": "Linear attention enhances inference efficiency of Transformer and has attracted research interests as an efficient backbone of language models. Existing linear attention based models usually exploit decay factor based positional encoding (PE), where attention scores decay exponentially with increasing relative distance. However, most work manually designs a non-trainable base of exponential calculation (decay factor), which limits further optimization. Our analysis reveals that direct training decay factor is unstable. To address this problem, we propose a novel PE for linear attention named Disentangle to Decay (D2D). D2D disentangles decay factor into two parts to achieve further optimization and stable training. Moreover, D2D can be transformed into recurrent form for efficient inference. Experiments demonstrate that D2D achieves stable training of decay factor, and enhances performance of linear attention in both normal context length and length extrapolation scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IqUrqS3k3b": {
    "title": "Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay Scoring Methods based on Linguistically-informed Counterfactuals",
    "volume": "review",
    "abstract": "While current automated essay scoring (AES) methods demonstrate high scoring agreement with human raters, their decision-making mechanisms are not fully understood. Our proposed method, using counterfactual intervention assisted by Large Language Models (LLMs), reveals that BERT-like models primarily focus on sentence-level features, whereas LLMs such as GPT-3.5, GPT-4 and Llama-3 are sensitive to conventions \\& accuracy, language complexity, and organization, indicating a more comprehensive rationale alignment with scoring rubrics. Moreover, LLMs can discern counterfactual interventions when giving feedback on essays. Our approach improves understanding of neural AES methods and can also apply to other domains seeking transparency in model-driven decisions. Access codes and data at anonymous repo during review: \\url{https://anonymous.4open.science/r/beyond-agreement-aes-2024-8321}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nPymxunXjT": {
    "title": "Exploring the Role of Semantic Parsing on Downstream Tasks for Large Language Models",
    "volume": "review",
    "abstract": "Semantic Parsing focuses on converting sentences into structured forms. While previous studies show its benefits for smaller models, the impact on Large Language Models (LLMs) remains under explored. Our paper explores whether integrating Semantic Parsing can enhance LLMs' performance in downstream tasks. Unlike prior approaches, we propose SENSE, adding semantic parsing hint instead results into prompt and find that this approach consistently improves performance across tasks, highlighting the potential of semantic information integration in enhancing LLM capabilities",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t9kPsStbHo": {
    "title": "Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization",
    "volume": "review",
    "abstract": "The concept of *persona*, originally adopted in dialogue literature, has re-surged as a promising framework for tailoring large language models (LLMs) to specific context (*e.g.*, personalized search, LLM-as-a-judge). However, the growing research on leveraging persona in LLMs is relatively disorganized and lacks a systematic taxonomy. To close the gap, we present a comprehensive survey to categorize the current state of the field. We identify two lines of research, namely (1) *LLM Role-Playing*, where personas are assigned to LLMs, and (2) *LLM Personalization*, where LLMs take care of user personas. Additionally, we introduce existing methods for LLM personality evaluation. To the best of our knowledge, we present the first survey for role-playing and personalization in LLMs under the unified view of persona. We continuously maintain a paper collection to foster future endeavors",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GooteJNbmR": {
    "title": "HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild",
    "volume": "review",
    "abstract": "Hallucinations pose a significant challenge to the reliability of large language models (LLMs) in critical domains. Recent benchmarks designed to assess LLM hallucinations within conventional NLP tasks, such as knowledge-intensive question answering (QA) and summarization, are insufficient for capturing the complexities of user-LLM interactions in dynamic, real-world settings. To address this gap, we introduce HaluEval-Wild, the first benchmark specifically designed to evaluate LLM hallucinations in the wild. We meticulously collect challenging (adversarially filtered by Alpaca) user queries from ShareGPT, an existing real-world user-LLM interaction datasets, to evaluate the hallucination rates of various LLMs. Upon analyzing the collected queries, we categorize them into five distinct types, which enables a fine-grained analysis of the types of hallucinations LLMs exhibit, and synthesize the reference answers with the powerful GPT-4 model and retrieval-augmented generation (RAG). Our benchmark offers a novel approach towards enhancing our comprehension of and improving LLM reliability in scenarios reflective of real-world interactions",
    "checked": true,
    "id": "03cfdde24c6b9837ad8933cb535a2c4a7c0fd971",
    "semantic_title": "halueval-wild: evaluating hallucinations of language models in the wild",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=VPFgn7AEu1": {
    "title": "TableBench: A Capability-Based Table Benchmark for Large Language Models",
    "volume": "review",
    "abstract": "The rapid advancement of techniques in large language models (LLMs) for processing tabular data necessitates improvements in evaluation benchmarks. However, most of existing table benchmarks offer evaluation from a singular task-based perspective, failing to provide a comprehensive and meticulous assessment of the LLMs' table-related capabilities. To address this gap, we introduce TableBench, a capability-based benchmark tailored to evaluate the performance of LLMs on tabular data. Our framework intricately outlines 10 essential capabilities required from the point a model receives a table-related input to the generation of an output, with each capability tested across 6 table formats. We evaluate 20 models using TableBench and observe that GPT-4 and GPT-4o achieve the highest scores, while phi3-small outperform other open-source models of similar scale. Drawing from our evaluation, we present a series of valuable insights, which can serve as a pivotal reference for future table-related LLM research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q0OBwmXQHd": {
    "title": "$SusGen-GPT$: A Data-Centric LLM for Financial NLP and Sustainability Report Generation",
    "volume": "review",
    "abstract": "The rapid growth of the financial sector and the increasing emphasis on Environmental, Social, and Governance (ESG) considerations have highlighted the need for advanced natural language processing (NLP) tools. Despite significant advancements, there remains a lack of open-source Large Language Models (LLMs) proficient across both general finance and ESG domains, such as generating ESG reports. To address this gap, we propose $SusGen-30k$, a high-quality, category-balanced dataset that comprises seven financial NLP tasks and ESG report generation. Additionally, we propose $TCFD-Bench$, a benchmark designed to enhance the evaluation of sustainability report generation. Employing a data-centric methodology, we developed a suite of models, referred to as $SusGen-GPT$. When trained on our curated dataset, these suites of models achieved state-of-the-art performance, surpassing the benchmarks set by models of significantly larger size. By doing so, we introduce a data-centric approach to effectively address the aforementioned existing challenges, aiming to foster continual development in the financial and ESG research community",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PJo8pRbiLy": {
    "title": "Leveraging Cross-Lingual Knowledge from Pre-Trained Models for Low-Resource Neural Machine Translation",
    "volume": "review",
    "abstract": "Neural machine translation (NMT) quality significantly depends on large parallel corpora, making low-resource language translation a challenge. This paper introduces a novel approach that leverages cross-lingual alignment knowledge from multilingual pre-trained language models (PLMs) to enhance low-resource NMT. Our method segments the translation model into source encoding, target encoding, and alignment modules, each initialized with different pre-trained BERT models. Experiments on four translation directions with two low-resource language pairs demonstrate significant BLEU score improvements, validating the efficacy of our approach",
    "checked": false,
    "id": "5495e6f7990423e0f4c73cab1bfdc63b1970eb20",
    "semantic_title": "pre-training synthetic cross-lingual decoder for multilingual samples adaptation in e-commerce neural machine translation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N4391IEP0c": {
    "title": "Do LLMs Play Dice? Exploring Probability Distribution Sampling in Large Language Models for Behavioral Simulation",
    "volume": "review",
    "abstract": "With the rapid advancement of large language models (LLMs) for handling complex language tasks, an increasing number of studies are employing LLMs as agents to emulate the sequential decision-making processes of humans often represented as Markov decision-making processes (MDPs). The actions in MDPs adhere to specific probability distributions and require iterative sampling. This arouses curiosity regarding the capacity of LLM agents to comprehend probability distributions, thereby guiding the agent's behavioral decision-making through probabilistic sampling and generating behavioral sequences. To answer the above question, we divide the problem into two main aspects: sequence simulation with known probability distribution and sequence simulation with unknown probability distribution. Our analysis indicates that LLM agents can understand probabilities, but they struggle with probability sampling. Their ability to perform probabilistic sampling can be improved to some extent by integrating coding tools, but this level of sampling precision still makes it difficult to simulate human behavior as agents",
    "checked": true,
    "id": "1d03bc20b66001f702c163f7abeac2121649ef8b",
    "semantic_title": "do llms play dice? exploring probability distribution sampling in large language models for behavioral simulation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eE2eVW4JFG": {
    "title": "How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data",
    "volume": "review",
    "abstract": "Recently, there has been a growing interest in studying how to construct better code instruction tuning data. However, we find Code models trained with these datasets exhibit high performance on HumanEval but perform worse on other benchmarks such as LiveCodeBench. Upon further investigation, we discover many datasets suffer from significant data leakage. After cleaning up most of the leaked data, we find that some datasets previously considered high-quality perform poorly. This discovery reveals a new challenge: identifying which dataset genuinely qualify as high-quality code instruction data. To address this, we propose an efficient code data selection strategy for selecting samples. Our approach is based on three dimensions: instruction complexity, response quality, and instruction diversity. Based on our selected data, we present XCoder, a family of models finetuned from LLaMA3. Experiments show Xcoder achieves new state-of-the-art performance using fewer training data, which verify the effectiveness of our data strategy. Moreover, we perform a comprehensive analysis on the data composition and find existing code datasets have different characteristics according to their construction methods, which provide new insights for future code LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k5skat8pmi": {
    "title": "Controlled Cloze-test Question Generation with Surrogate Models for IRT Assessment",
    "volume": "review",
    "abstract": "Item difficulty plays a crucial role in adaptive testing. However, few works have focused on generating questions of varying difficulty levels, especially for multiple-choice (MC) cloze tests. We propose training pre-trained language models (PLMs) as surrogate models to enable item response theory (IRT) assessment, avoiding the need for human test subjects. We also propose two strategies to control the difficulty levels of the distractors using ranking rules to reduce invalid distractors. Experimentation on a benchmark dataset demonstrates that our proposed framework and methods can effectively control and evaluate the difficulty levels of MC cloze tests",
    "checked": false,
    "id": "416d9636d9cee2bc5013d8202ccfe8adfbd24e31",
    "semantic_title": "controlling cloze-test question item difficulty with plm-based surrogate models for irt assessment",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VcXuAzw62v": {
    "title": "YAYI-UIE: A Chat-Enhanced Instruction Tuning Framework for Universal Information Extraction",
    "volume": "review",
    "abstract": "The difficulty of the information extraction task lies in dealing with the task-specific label schemas and heterogeneous data structures. Recent work has proposed methods based on large language models to uniformly model different information extraction tasks. However, these existing methods are deficient in their information extraction capabilities for Chinese languages other than English. In this paper, we propose an end-to-end chat-enhanced instruction tuning framework for universal information extraction (YAYI-UIE), which supports both Chinese and English. Specifically, we utilize dialogue data and information extraction data to enhance the information extraction performance jointly. Experimental results show that our proposed framework achieves state-of-the-art performance on Chinese datasets while also achieving comparable performance on English datasets under both supervised settings and zero-shot settings",
    "checked": true,
    "id": "0670e318213958cab2c22f2917768cb33465350e",
    "semantic_title": "yayi-uie: a chat-enhanced instruction tuning framework for universal information extraction",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=bHKYYqJqoo": {
    "title": "Towards Robust Cross-Prompt Essay Trait Scoring: A Generative Model Framework with Ranking Loss",
    "volume": "review",
    "abstract": "Automated Essay Scoring (AES) aims to evaluate the overall quality of essays, while essay trait scoring provides a detailed assessment by assigning separate scores to specific traits. Prompt-specific AES models have shown success, but their application to ``unseen'' prompts remains challenging due to limited prompt and essay diversity, hindering the generalization ability. This paper introduces GenAES, a generative model framework for cross-prompt essay trait scoring, leveraging large language models (LLMs) to augment prompts and essays. GenAES further develops a prompt encoder to manage representations of unseen prompts and introduces a ranking loss to evaluate the similarity of unlabeled generated essays with the source essays. Experimental results show GenAES improves generalization, achieving state-of-the-art performance on the ASAP++ dataset, with 6.5% and 7.3% gains in average QWK scores over prompts and traits, respectively. The generated prompts and essays are released to facilitate future research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YpB7vxyFXl": {
    "title": "ZK-GenMed: A Zero-shot Knowledge Generative Medical Large Language Model",
    "volume": "review",
    "abstract": "Advancements in Natural Language Processing (NLP) have led to the development of Large Language Models (LLMs), which have demonstrated remarkable capabilities in various tasks, domains, and settings. These models have demonstrated efficacy in various training and evaluation scenarios, including zero-shot learning and instruction settings. They have been effectively applied to reasoning, summarizing, and answering questions. Moreover, LLMs have been used in various industries, including the medical profession, where they have been used for jobs requiring accuracy, such as answering questions. However, much research hasn't been done on LLMs' potential for resolving medical questions in a zero-shot manner. To close this knowledge gap, we provide a novel framework called ZK-GenMed, which uses LLMs' advantages to produce the information needed to answer medical questions in a zero-shot scenario. This framework combines the generated knowledge with ranking strategies to extract relevant information, meaningfully enabling the model to answer medical questions. Experimental results demonstrate significant improvements, with marginal gains of over 10\\% on various datasets, highlighting the potential of ZK-GenMed for medical question-answering applications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OEn7Z6JQdY": {
    "title": "SafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance",
    "volume": "review",
    "abstract": "As the development of large language models (LLMs) rapidly advances, securing these models effectively without compromising their utility has become a pivotal area of research. However, current defense strategies against jailbreak attacks (i.e., efforts to bypass security protocols) often suffer from limited adaptability, restricted general capability, and high cost. To address these challenges, we introduce SafeAligner, a methodology implemented at the decoding stage to fortify defenses against jailbreak attacks. We begin by developing two specialized models: the Sentinel Model, which is trained to foster safety, and the Intruder Model, designed to generate riskier responses. SafeAligner leverages the disparity in security levels between the responses from these models to differentiate between harmful and beneficial tokens, effectively guiding the safety alignment by altering the output token distribution of the target model. Extensive experiments show that SafeAligner can increase the likelihood of beneficial tokens, while reducing the occurrence of harmful ones, thereby ensuring secure alignment with minimal loss to generality",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yE1NZQy5BA": {
    "title": "Chain of Evidences and Evidence to Generate: Prompting for Context Grounded and Retrieval Augmented Reasoning",
    "volume": "review",
    "abstract": "While chain-of-thoughts (CoT) prompting has revolutionized how LLMs perform reasoning tasks, its current methods and variations (e.g, Self-consistency, ReACT, Reflexion, Tree-of-Thoughts (ToT), Cumulative Reasoning (CR) etc.,) suffer from limitations like limited context grounding, hallucination/inconsistent output generation, and iterative sluggishness. To overcome these challenges, we introduce a novel mono/dual-step prompting framework built upon two unique strategies \\textbf{Chain of Evidences (CoE)} and \\textbf{Evidence to Generate (E2G)}. Instead of unverified reasoning claims, our innovative approaches leverage the power of \"evidence for decision making\" by first focusing exclusively on the thought sequences explicitly mentioned in the context which then serve as extracted evidence, guiding the LLM's output generation process with greater precision and efficiency. This simple yet potent approach unlocks the full potential of chain-of-thoughts prompting, facilitating faster, more reliable, and contextually aware reasoning in LLMs. Our framework consistently achieves remarkable results across various knowledge-intensive reasoning and generation tasks, surpassing baseline approaches with state-of-the-art LLMs. For instance, (i) on the LogiQA benchmark using GPT-4, CoE achieves a new state-of-the-art accuracy of 53.8\\%, surpassing CoT by 18\\%, ToT by 11\\%, and CR by 9\\%; (ii) CoE with PaLM-2 outperforms the variable-shot performance of Gemini Ultra by 0.9 F1 points, achieving an F1 score of 83.3 on DROP",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SAYWfha12M": {
    "title": "Exploring the Practicality of Generative Retrieval on Dynamic Corpora",
    "volume": "review",
    "abstract": "Benchmarking the performance of information retrieval (IR) is mostly conducted with a fixed set of documents (static corpora). However, in realistic scenarios, this is rarely the case and the documents to be retrieved are constantly updated and added. In this paper, we focus on Generative Retrievals (GR), which apply autoregressive language models to IR problems, and explore their adaptability and robustness in dynamic scenarios. We also conduct an extensive evaluation of computational and memory efficiency, crucial factors for real-world deployment of IR systems handling vast and ever-changing document collections. Our results on the StreamingQA benchmark demonstrate that GR is more adaptable to evolving knowledge (+ 4 -- 11\\%), robust in learning knowledge with temporal information, and efficient in terms of inference FLOPs ($\\times 2$), indexing time ($\\times 6$), and storage footprint ($\\times 4$) compared to Dual Encoders (DE), which are commonly used in retrieval systems. Our paper highlights the potential of GR for future use in practical IR systems within dynamic environments",
    "checked": true,
    "id": "5e52c1c4fc90870df11efd1348f54bc56407d773",
    "semantic_title": "exploring the practicality of generative retrieval on dynamic corpora",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=yGXVC2BqaY": {
    "title": "Commonsense Knowledge Editing Based on Free-Text in LLMs",
    "volume": "review",
    "abstract": "Knowledge editing technology is crucial for maintaining the accuracy and timeliness of large language models (LLMs) . However, the setting of this task overlooks a significant portion of commonsense knowledge based on free-text in the real world, characterized by broad knowledge scope, long content and non instantiation. The editing objects of previous methods (e.g., MEMIT) were single token or entity, which were not suitable for commonsense knowledge in free-text form. To address the aforementioned challenges, we conducted experiments from two perspectives: knowledge localization and knowledge editing. Firstly, we introduced Knowledge Localization for Free-Text(KLFT) method, revealing the challenges associated with the distribution of commonsense knowledge in MLP and Attention layers, as well as in decentralized distribution. Next, we propose a Dynamics-aware Editing Method(DEM), which utilizes a Dynamics-aware Module to locate the parameter positions corresponding to commonsense knowledge, and uses Knowledge Editing Module to update knowledge. The DEM method fully explores the potential of the MLP and Attention layers, and successfully edits commonsense knowledge based on free-text. The experimental results indicate that the DEM can achieve excellent editing performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fmum61rEUg": {
    "title": "Beyond Task-Specific Fine-tuning: Exploring the Impact of Diverse Data on LLM Performance",
    "volume": "review",
    "abstract": "This study explores the efficacy of fine-tuning large language models (LLMs) using non-task-specific datasets, challenging the traditional reliance on task-specific datasets. Based on the SUP-NATINST and Stanford Alpaca dataset, this research explores some schemes to enhance the application capabilities of LLMs in specific domains through strategic data selection. The main contributions include an innovative fine-tuning strategy that emphasizes the importance of dataset selection by comparing non-task-specific datasets with task-specific datasets, demonstrating the potential advantages of unconventional datasets in improving model task performance. The study also reveals the model's performance sensitivity to data ratios, challenges the concept of optimal data ratios, and explores the impact of data volume changes on model accuracy. Furthermore, it deepens the understanding of how different task types affect model performance fine-tuning. By analyzing the performance across different tasks and dimensions and dissecting the impact of data ratio changes, the research indicates that non-specific task data allocation can achieve better performance than specific task datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jum5GgEV0h": {
    "title": "The influence of pretraining model's life of orientation leaning on mental health disease detection",
    "volume": "review",
    "abstract": "With the popularity of the Internet, online social media has increasingly become a platform for people to share their attitudes towards life, such as optimism and pessimism about the future. While the Internet embraces various views, it also quietly deepens the formation of impressions on different views and attitudes. A large part of these texts will form the corpus of the pre-trained model, and the model may learn the tendency of life attitudes in the corpus. Our work develops new methods to (1) measure life attitude biases in LMs trained on such corpora and (2) measure the judgement impact of downstream models trained on different life attitude corpus. We focus on mental health disorder detection, aiming to empirically quantify the effects of life attitude (optimism, pessimism) leaning in pretraining data on the influence of risk-related tasks. Our findings reveal that pretrained LMs do have life attitude leanings that reinforce the polarization present in pretraining corpora, propagating life attitude biases into mental health disorder detection.We discussed strategies that might mitigate or leverage models of different life attitude leaning",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hIEXCK91Vl": {
    "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents",
    "volume": "review",
    "abstract": "Large language models (LLMs) have exhibited great potential in autonomously completing tasks across real-world applications. Despite this, these LLM agents introduce unexpected safety risks when operating in interactive environments. Instead of centering on the harmlessness of LLM-generated content in most prior studies, this work addresses the imperative need for benchmarking the behavioral safety of LLM agents within diverse environments. We introduce R-Judge, a benchmark crafted to evaluate the proficiency of LLMs in judging and identifying safety risks given agent interaction records. R-Judge comprises 569 records of multi-turn agent interaction, encompassing 27 key risk scenarios among 5 application categories and 10 risk types. It is of high-quality curation with annotated safety labels and risk descriptions. Evaluation of 11 LLMs on R-Judge shows considerable room for enhancing the risk awareness of LLMs: The best-performing model, GPT-4o, achieves 74.42% while no other models significantly exceed the random. Moreover, we reveal that risk awareness in open agent scenarios is a multi-dimensional capability involving knowledge and reasoning, thus challenging for LLMs. With further experiments, we find that fine-tuning on safety judgment significantly improve model performance while straightforward prompting mechanisms fail. R-Judge is publicly available at Annoymous",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S3hKLXwOZ5": {
    "title": "Key Verbatim Extraction from Clinical Notes: A Hierarchical Multimodal Cross-Attention Approach",
    "volume": "review",
    "abstract": "Clinical notes are essential for physicians to accurately assess patient conditions, particularly in oncology where records are extensive. Efficient and effective information extraction from these notes is crucial for effective treatment. This is not a trivial task due to the lengthy and specialized content in the notes. Current methods that capture token-level or sentence-level relations, which are context-dependent, are sometimes insufficient for knowledge-intensive tasks such as information extraction from EHR that require external knowledge. To address this, we introduce a knowledge-enhanced hierarchical multimodal cross-attention approach. This method employs a cross-attention mechanism to integrate textual knowledge with patient network knowledge, aiming to synthesize information across multiple data levels, including word, sentence, note, and patient levels. This approach can efficiently highlight key sentences in clinical notes. We validate our method using extensive experiments on a large real-world dataset. The results demonstrate that our proposed model outperforms baseline models by up to 4.17% and 2.79% regarding F1 and accuracy",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DanhjcTL2T": {
    "title": "AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment",
    "volume": "review",
    "abstract": "The use of Large Language Models (LLMs), which demonstrate impressive capabilities in natural language understanding and reasoning, in Embodied AI is a rapidly developing area. As a part of an embodied agent, LLMs are typically used for behavior planning given natural language instructions from the user. However, dealing with ambiguous instructions in real-world environments remains a challenge for LLMs. Various methods for task disambiguation have been proposed. However, it is difficult to compare them because they work with different data. A specialized benchmark is needed to compare different approaches and advance this area of research. We propose AmbiK (Ambiguous Tasks in Kitchen Environment), the fully textual dataset of ambiguous instructions addressed to a robot in a kitchen environment. AmbiK was collected with the assistance of LLMs and is human-validated. It comprises 500 pairs of ambiguous tasks and their unambiguous counterparts, categorized by ambiguity type (human preference, common sense knowledge, safety), with environment descriptions, clarifying questions and answers, and task plans, for a total of 1000 tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MtQiTZCtjq": {
    "title": "Should multiple defendants and charges be treated separately in legal judgment prediction: An exploratory study and dataset",
    "volume": "review",
    "abstract": "Legal judgment prediction offers a compelling method to aid legal practitioners and researchers. However, the research question remains relatively under-explored: Should multiple defendants and charges be treated separately in Legal judgment prediction? To address this, we introduce a new dataset namely multi-person multi-charge prediction MPMCP, and seek the answer by evaluating the performance of several prevailing legal \\acp{LLM} on four practical legal judgment scenarios: (S1) single defendant with a single charge, (S2) single defendant with multiple charges, (S3) multiple defendants with a single charge, and (S4) multiple defendants with multiple charges. We evaluate the dataset across two Legal judgment prediction tasks, i.e., charge prediction and penalty term prediction. We have conducted extensive experiments and found that the scenario involving multiple defendants and multiple charges (S4) poses the greatest challenges, followed by S2, S3, and S1. The impact varies significantly depending on the model. For example, in S4 compared to S1, InternLM2 achieves approximately 4.5\\% lower F1-score and 2.8\\% higher LogD, while Lawformer demonstrates around 19.7\\% lower F1-score and 19.0\\% higher LogD",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zbMg3gM1De": {
    "title": "Interpretable Composition Attribution Enhancement for Visio-linguistic Compositional Understanding",
    "volume": "review",
    "abstract": "Contrastively trained vision-language models such as CLIP have achieved remarkable progress in vision and language representation learning. Despite the promising progress, their proficiency in compositional reasoning over attributes and relations (eg, distinguishing between \"the car is underneath the person\" and \"the person is underneath the car\") remains notably inadequate. We investigate the cause for this deficient behavior is the composition attribution issue, where the attribution scores (eg, attention scores or GradCAM scores) for relations (eg, underneath) or attributes (eg, red) in text are substantially lower than those for object terms. In this work, we show such issue is mitigated via a novel framework called CAE (Composition Attribution Enhancement). This generic framework incorporates various interpretable attribution methods to encourages the model to pay greater attention on composition words denoting relationships and attributes within the text. Detailed analysis shows that our approach enables the models to adjust and rectify the attribution on the texts. Extensive experiments across seven benchmarks reveal that our framework significantly enhances the ability to discern intricate details and construct more sophisticated interpretations of combined visual and linguistic elements",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l8Oql9HsyK": {
    "title": "POMEM: In-Context Knowledge Post Editing on Massive-Editing Memory in Language Language Models",
    "volume": "review",
    "abstract": "Parameter updating (PU), while being widely used in $\\textit{knowledge editing}$, has still shown limited performances in terms of generalization and locality metrics, likely due to the catastrophic forgetting, the riffle effects, or the unseen contexts. This paper proposes a novel $\\textit{in-context post-editing}$, which is subsequently applied to the PU-based prediction results, namely $\\textbf{POMEM}$ -- In-context knowledge $\\textbf{po}$st $\\textbf{e}$diting on $\\textbf{m}$assive-$\\textbf{e}$diting $\\textbf{m}$emory -- which consists of two different types of in-context post-editing prompting method, divided into the \"in-scope\" and \"out-of-scope\" post-editing methods, shortly referred to as Copier and Recaller, respectively; 1) $\\textbf{Copier}$ is specially designed for in-scope cases, mainly aiming to further enhance the generalization editing ability; 2) $\\textbf{Recaller}$ is designed for out-of-scope cases, which involves a novel \"recalling\" prompt which aims to recover the prediction result of \"original pre-edited\" model under using the PU-based \"edited\" model. Experiment results on Counterfact dataset show that POMEM leads to the state-of-the-art performances. Our codes are publicly available at \\url{https://github.com/XXX/XXX}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dHLogaGMts": {
    "title": "BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models",
    "volume": "review",
    "abstract": "Safety backdoor attacks in large language models (LLMs) enable harmful behaviors to be stealthily triggered while evading detection during normal interactions. The high dimensionality of the trigger search space and the diverse range of potential malicious behaviors in LLMs make this a critical open problem. This paper presents BEEAR, a novel mitigation method based on a key insight: backdoor triggers induce a uniform drift in the model's embedding space, irrespective of the trigger's form or targeted behavior. Leveraging this observation, we introduce a bi-level optimization approach. The inner level identifies universal perturbations to the decoder's embeddings that steer the model towards defender-defined unwanted behaviors; the outer level fine-tunes the model to reinforce safe behaviors against these perturbations. Our experiments demonstrate the effectiveness of this approach, reducing the success rate of safety backdoor attacks from over 95\\% to $<$1\\% for general harmful behaviors and from 47\\% to 0\\% for Sleeper Agents, without compromising the model's helpfulness. Notably, our method relies only on defender-defined sets of safe and unwanted behaviors without any assumptions about the trigger location or attack mechanism. This work represents the first practical framework to counter safety backdoors in LLMs and provides a foundation for future advancements in AI safety and security",
    "checked": true,
    "id": "b15493107b8e3193aae28d818ef265f0e8790f49",
    "semantic_title": "beear: embedding-based adversarial removal of safety backdoors in instruction-tuned language models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=4ViDfPhtNJ": {
    "title": "Synergizing Foundation Models and Federated Learning: A Survey",
    "volume": "review",
    "abstract": "The recent development of Foundation Models (FMs), represented by large language models, vision transformers, and multimodal models, has been making a significant impact on both academia and industry. Compared with small-scale models, FMs have a much stronger demand for high-volume data during the pre-training phase. Although general FMs can be pre-trained on data collected from open sources such as the Internet, domain-specific FMs need proprietary data, posing a practical challenge regarding the amount of data available due to privacy concerns. Federated Learning (FL) is a collaborative learning paradigm that breaks the barrier of data availability from different participants. Therefore, it provides a promising solution to customize and adapt FMs to a wide range of domain-specific tasks using distributed datasets whilst preserving privacy. This survey paper discusses the potentials and challenges of synergizing FL and FMs and summarizes core techniques, future directions, and applications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ijOjOtCulk": {
    "title": "COFFEE-GYM: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code",
    "volume": "review",
    "abstract": "This paper presents Coffee-Gym, a comprehensive RL environment for training models that provide feedback on code editing. Coffee-Gym includes two major components: (1) Coffee, a dataset containing humans' code edit traces for coding questions and human-written feedback for editing erroneous code; (2) CoffeeEval, a reward function that faithfully reflects the helpfulness of feedback by assessing the performance of the revised code in unit tests. With them, Coffee-Gym addresses the unavailability of high-quality datasets for training feedback models with RL, and provides more accurate rewards than the SOTA reward model (i.e., GPT-4). By applying Coffee-Gym, we elicit feedback models that outperform baselines in enhancing open-source code LLMs' code editing, making them comparable with closed-source LLMs. We make the dataset and the model checkpoint publicly available in https://huggingface.co/spaces/Coffee-Gym/Project-Coffee-Gym",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZzAGwGFC6d": {
    "title": "MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction",
    "volume": "review",
    "abstract": "Molecular property prediction (MPP) is a fundamental and crucial task in drug discovery. However, prior methods are limited by the requirement for a large number of labeled molecules and their restricted ability to generalize for unseen and new tasks, both of which are essential for real-world applications. To address these challenges, we present MolecularGPT for few-shot MPP. From a perspective on instruction tuning, we fine-tune large language models (LLMs) based on curated molecular instructions spanning over 1000 property prediction tasks. This enables building a versatile and specialized LLM that can be adapted to novel MPP tasks without any fine-tuning through zero- and few-shot in-context learning (ICL). MolecularGPT exhibits competitive in-context reasoning capabilities across 10 downstream evaluation datasets, setting new benchmarks for few-shot molecular prediction tasks. More importantly, with just two-shot examples, MolecularGPT can outperform standard supervised graph neural network methods on 4 out of 7 datasets. It also excels state-of-the-art LLM baselines by up to 16.6\\% increase on classification accuracy and decrease of 199.17 on regression metrics (e.g., RMSE) under zero-shot. This study demonstrates the potential of LLMs as effective few-shot molecular property predictors. Our model and curated instruction set will be open-sourced",
    "checked": true,
    "id": "443e5490e7f9fedf912a330fc7a0456d4247ab3d",
    "semantic_title": "moleculargpt: open large language model (llm) for few-shot molecular property prediction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EYKzVrsXPt": {
    "title": "LEMMA: Towards LVLM-Enhanced Multimodal Misinformation Detection with External Knowledge Augmentation",
    "volume": "review",
    "abstract": "The rise of multimodal misinformation on social platforms poses significant challenges for individuals and societies. Its increased credibility and broader impact make detection more complex, requiring robust reasoning across diverse media types and profound knowledge for accurate verification. The emergence of Large Vision Language Model (LVLM) offers a potential solution to this problem. Leveraging their proficiency in processing visual and textual information, LVLM demonstrates promising capabilities in recognizing complex information and exhibiting strong reasoning skills. We investigate the potential of LVLM on multimodal misinformation detection and find that even though LVLM has a superior performance compared to LLMs, its profound reasoning may present limited power with a lack of evidence. Based on these observations, we propose LEMMA: LVLM-Enhanced Multimodal Misinformation Detection with External Knowledge Augmentation. LEMMA leverages LVLM intuition and reasoning capabilities while augmenting them with external knowledge to enhance the accuracy of misinformation detection. Our external knowledge extraction module adopts multi-query generation and image source tracing to enhance the rigor and comprehensiveness of LVLM's reasoning. We observed that LEMMA improves the accuracy over the top baseline LVLM by 9% and 13% on Twitter and Fakeddit datasets respectively",
    "checked": true,
    "id": "00c6a500726a85090e1b2e7e8f4c5226ff56d86d",
    "semantic_title": "lemma: towards lvlm-enhanced multimodal misinformation detection with external knowledge augmentation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=01F6uQeZeN": {
    "title": "Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups",
    "volume": "review",
    "abstract": "Complex Word Identification (CWI) is an important step in the lexical simplification task and has recently become a task on its own. Some variations of this binary classification task have emerged, such as lexical complexity prediction (LCP) and complexity evaluation of multi-word expressions (MWE). Large language models (LLMs) recently became popular in the Natural Language Processing community because of their versatility and capability to solve unseen tasks in zero/few-shot settings. Our work investigates LLM usage, specifically open-source models such as Llama 2, Llama 3, and Vicuna v1.5, and closed-source, such as ChatGPT-3.5-turbo and GPT-4o, in the CWI, LCP, and MWE settings. We evaluate zero-shot, few-shot, and fine-tuning settings and show that LLMs struggle in certain conditions or achieve comparable results against existing methods. In addition, we provide some views on meta-learning combined with prompt learning. In the end, we conclude that the current state of LLMs cannot or barely outperform existing methods, which are usually much smaller",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iMNstxxsWo": {
    "title": "Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) have shown promising performance in text-to-SQL, which involves translating natural language questions into SQL queries. However, current text-to-SQL LLMs are computationally expensive and challenging to deploy in real-world applications, highlighting the importance of compressing them. To achieve this goal, knowledge distillation (KD) is a common approach, which aims to distill the larger teacher model into a smaller student model. While numerous KD methods for autoregressive LLMs have emerged recently, it is still under-explored whether they work well in complex text-to-SQL scenarios. To this end, we conduct a series of analyses and reveal that these KD methods generally fall short in balancing performance and efficiency. In response to this problem, we propose to improve the KD with imperfect data, namely KID, which effectively boosts the performance without introducing much training budget. The core of KID is to efficiently mitigate the training-inference mismatch by simulating the cascading effect of inference in the imperfect training data. Extensive experiments on 5 text-to-SQL benchmarks show that, KID can not only achieve consistent and significant performance gains (up to +5.83% average score) across all model types and sizes, but also effectively improve the training efficiency",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CE07aE1kTR": {
    "title": "GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization",
    "volume": "review",
    "abstract": "News summarization in today's global scene can be daunting with its flood of multilingual content and varied viewpoints from different sources. However, current studies often neglect such real-world scenarios as they tend to focus solely on either single-language or single-document tasks. To bridge this gap, we aim to unify Multi-lingual, Cross-lingual and Multi-document Summarization into a novel task, i.e., MCMS, which encapsulates the real-world requirements all-in-one. Nevertheless, the lack of a benchmark inhibits researchers from adequately studying this invaluable problem. To tackle this, we have meticulously constructed the GLOBESUMM dataset by first collecting a wealth of multilingual news reports and restructuring them into event-centric format. Additionally, we introduce the method of protocol-guided prompting for high-quality and cost-effective reference annotation. In MCMS, we also highlight the challenge of conflicts between news reports, in addition to the issues of redundancies and omissions, further enhancing the complexity of GLOBESUMM. Through extensive experimental analysis, we validate the quality of our dataset and elucidate the inherent challenges of the task. We firmly believe that GLOBESUMM, given its challenging nature, will greatly contribute to the multilingual communities and the evaluation of LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yvqWdJqYN1": {
    "title": "Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with Large Language Models",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) have been revolutionizing a myriad of natural language processing tasks with their diverse zero-shot capabilities. Indeed, existing work has shown that LLMs can be used to great effect for many tasks, such as information retrieval (IR), and passage ranking. However, current state-of-the-art results heavily lean on the capabilities of the LLM being used. Currently, proprietary, and very large LLMs such as GPT-4 are the highest performing passage re-rankers. Hence, users without the resources to leverage top of the line LLMs, or ones that are closed source, are at a disadvantage. In this paper, we investigate the use of a pre-filtering step before passage re-ranking in IR. Our experiments show that by using a small number of human generated relevance scores, coupled with LLM relevance scoring, it is effectively possible to filter out irrelevant passages before re-ranking. Our experiments also show that this pre-filtering then allows the LLM to perform significantly better at the re-ranking task. Indeed, our results show that smaller models such as Mixtral can become competitive with much larger proprietary models (e.g., ChatGPT and GPT-4)",
    "checked": true,
    "id": "8678ac94e115f67cb0cef698f573942882cfbc5c",
    "semantic_title": "re-ranking step by step: investigating pre-filtering for re-ranking with large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uH2AUUscub": {
    "title": "Large Language Model is a Better Context Extractor for Aspect-Based Sentiment Analysis",
    "volume": "review",
    "abstract": "Previous Aspect-Based Sentiment Analysis (ABSA) studies have often incorporated syntactic information to connect contextual details with the designated aspect. These methods rely on complex model design to obtain syntactic structure information, further acquiring crucial semantic insights. Considering the potent contextualization abilities of the Large Language Model (LLM), we present the Low-Rank Adaptation plus In-domain Dynamic Examplar (LoRA-IDE) framework. This framework effectively aligns the task and sentence context information with the target aspect, leveraging the power of LLM. Specifically, we employ the LoRA training strategy to enable LLM to learn the context information of ABSA and promote the model's understanding of the connection between sentence context and aspects through the use of curated, designed instructions with IDE. Experimental results demonstrate that our proposed approach not only improves the performance of LLM on ABSA but also outperforms the current state-of-the-art model on two benchmarks at a large scale. The codes will be released upon the acceptance of this paper",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fzhUuW3kzO": {
    "title": "Augmenting Document-level Relation Extraction with Efficient Multi-Supervision",
    "volume": "review",
    "abstract": "Despite its popularity in sentence-level relation extraction, distantly supervised data is rarely utilized by existing work in document-level relation extraction due to its noisy nature and low information density. Among its current applications, distantly supervised data is mostly used as a whole for pertaining, which is of low time efficiency. To fill in the gap of efficient and robust utilization of distantly supervised training data, we propose Efficient Multi-Supervision for document-level relation extraction, in which we first select a subset of informative documents from the massive dataset by combining distant supervision with expert supervision, then train the model with Multi-Supervision Ranking Loss that integrates the knowledge from multiple sources of supervision to alleviate the effects of noise. The experiments demonstrate the effectiveness of our method in improving the model performance with higher time efficiency than existing baselines",
    "checked": true,
    "id": "5bc1c611be14665d4c7086f7571323fa60c3d5c7",
    "semantic_title": "augmenting document-level relation extraction with efficient multi-supervision",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ozR7qitndD": {
    "title": "{MOPO: Multi-Objective Prompt Optimization for Affective Text Generation",
    "volume": "review",
    "abstract": "Emotions are expressed differently and in different context and domain. On Twitter, for instance, an author might simply use the hashtag \\#anger to express this affective state, while in a news headline, such an emotion needs to be written in a polite manner. To enable conditional text generation models to create appropriate texts, users need a parameter that allows them to choose the appropriate way to express an emotion. To achieve this, we introduce MOPO, a Multi-Objective Prompt Optimization methodology. MOPO optimizes prompts according to multiple objectives and outputs a set of prompts for different preference weightings of the objectives. Users can then choose the most appropriate prompt for their context. We evaluate MOPO using three objectives, determined by various domain-specific emotion classifiers. Our findings indicate that MOPO improves performance by up to 15 pp across all objectives with only a minimal loss (1--2 pp) for any single objective compared to single-objective optimization. These minor performance losses are offset by a broader generalization across multiple objectives -- which is not possible with single-objective optimization. Additionally, MOPO reduces computational resources by simultaneously optimizing for multiple objectives, eliminating separate optimizations for each objective",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zbLxByF6Sg": {
    "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "Recent advancements in Large Language Models have transformed ML/AI development, necessitating a reevaluation of AutoML principles for the Retrieval-Augmented Generation (RAG) systems. To address the challenges of hyper-parameter optimization and online adaptation in RAG, we propose the AutoRAG-HP framework, which formulates the hyper-parameter tuning as an online multi-armed bandit (MAB) problem and introduces a novel two-level Hierarchical MAB (Hier-MAB) method for efficient exploration of large search spaces. We conduct extensive experiments on tuning hyper-parameters, such as top-k retrieved documents, prompt compression ratio, and embedding methods, using the ALCE-ASQA and Natural Questions datasets. Our evaluation from jointly optimization all three hyper-parameters demonstrate that MAB-based online learning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with prominent gradients in search space, using only $\\sim20$% of the LLM API calls required by the Grid Search approach. Additionally, the proposed Hier-MAB approach outperforms other baselines in more challenging optimization scenarios",
    "checked": true,
    "id": "758881985475e137439da465fadf968aead68c4c",
    "semantic_title": "autorag-hp: automatic online hyper-parameter tuning for retrieval-augmented generation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3sFwiyoWNg": {
    "title": "LoPT: Low-Rank Prompt Tuning for Parameter Efficient Language Models",
    "volume": "review",
    "abstract": "In prompt tuning, a prefix or suffix text is added to the prompt, and the embeddings (soft prompts) or token indices (hard prompts) of the prefix/suffix are optimized to gain more control over language models for specific tasks. This approach eliminates the need for hand-crafted prompt engineering or explicit model fine-tuning. Prompt tuning is significantly more parameter-efficient than model fine-tuning, as it involves optimizing partial inputs of language models to produce desired outputs. In this work, we aim to further reduce the amount of trainable parameters required for a language model to perform well on specific tasks. We propose Low-rank Prompt Tuning (LoPT), a low-rank model for prompts that achieves efficient prompt optimization. The proposed method demonstrates similar outcomes to full parameter prompt tuning while reducing the number of trainable parameters by a factor of 5. It also provides promising results compared to the state-of-the-art methods that would require 10 to 20 times more parameters",
    "checked": true,
    "id": "43033574192c5e37a2ea11f192cb1518ce6a06dc",
    "semantic_title": "lopt: low-rank prompt tuning for parameter efficient language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=i2zEZWQJAY": {
    "title": "Dynamic Prefix as Instructor for Incremental Named Entity Recognition: A Unified Seq2Seq Generation Framework",
    "volume": "review",
    "abstract": "The Incremental Named Entity Recognition (INER) task aims to update a model to extract entities from an expanding set of entity type candidates due to concerns related to data privacy and scarcity. However, conventional incremental learning methods for INER often suffer from the catastrophic forgetting problem, which leads to the degradation of the model's performance on previously encountered entity types. In this paper, we propose a parameter-efficient dynamic prefix method and formalize INER as a unified seq2seq generation task. By employing the dynamic prefix as a task instructor to guide the generative model, our approach can preserve task-invariant knowledge while adapting to new entities with minimal parameter updates, making it particularly effective in low-resource scenarios. Additionally, we design a generative label augmentation strategy and a novel self-entropy loss to balance the stability and plasticity of the model. Empirical experiments on NER benchmarks demonstrate the effectiveness of our proposed method in addressing the challenges associated with INER",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F0rlA94Rj2": {
    "title": "A View of Large Language Models in HPC: Challenges and Opportunities",
    "volume": "review",
    "abstract": "There is a growing interest in using machine learning techniques to automate and improve the process of generating code. With the rapid development of large language models (LLMs), various models have been created to help write and optimize code. However, they do not yet meet the stringent requirements of high-performance computing (HPC), where highly optimized and efficient code is essential. This paper explores the research direction of adapting and using LLMs for HPC code generation. We present the reasoning behind our position and suggest how existing ideas can be adapted and enhanced to meet the demands of HPC applications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9E8IZ8dOuA": {
    "title": "MC-MKE: A Fine-Grained Multimodal Knowledge Editing Benchmark Emphasizing Modality Consistency",
    "volume": "review",
    "abstract": "Multimodal large language models (MLLMs) are prone to non-factual or outdated knowledge issues, which can manifest as misreading and misrecognition errors due to the complexity of multimodal knowledge. Previous benchmarks have not systematically analyzed the performance of editing methods in correcting these two error types. To better represent and correct these errors, we decompose multimodal knowledge into its visual and textual components. Different error types correspond to different editing formats, which edits distinct part of the multimodal knowledge. We present MC-MKE, a fine-grained **M**ultimodal **K**nowledge **E**diting benchmark emphasizing **M**odality **C**onsistency. Our benchmark facilitates independent correction of misreading and misrecognition errors by editing the corresponding knowledge component. We evaluate three multimodal knowledge editing methods on MC-MKE, revealing their limitations, particularly in terms of modality consistency. Our work highlights the challenges posed by multimodal knowledge editing and motivates further research in developing effective techniques for this task",
    "checked": true,
    "id": "8efecf2a2192c81be47fb0214c14b76aa9472ced",
    "semantic_title": "mc-mke: a fine-grained multimodal knowledge editing benchmark emphasizing modality consistency",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v6ivlRk0i5": {
    "title": "Claim Check-Worthiness Detection: How Well do LLMs Grasp Annotation Guidelines?",
    "volume": "review",
    "abstract": "The rising threat of disinformation underscores the need to fully or partially automate the fact-checking process. Identifying text segments requiring fact-checking is known as claim detection (CD) and claim check-worthiness detection (CW), the latter incorporating complex domain-specific criteria of worthiness and often framed as a ranking task. Zero- and few-shot LLM prompting is an attractive option for both tasks, as it bypasses the need for labeled datasets and allows verbalized claim and worthiness criteria to be directly used for prompting. We evaluate the LLMs' predictive accuracy and accuracy on five CD/CW datasets from diverse domains, each utilizing a different worthiness criterion. We examine two key aspects: (1) how to best distill factuality and worthiness criteria into a prompt, and (2) how much context to provide for each claim. To this end, we experiment with different levels of prompt verbosity and varying amounts of contextual information given to the model. We additionally evaluate the top-performing models with ranking metrics, resembling prioritization done by fact-checkers. Our results show that optimal prompt verbosity varies, meta-data alone adds more performance boost than co-text, and confidence scores can be directly used to produce reliable check-worthiness rankings",
    "checked": true,
    "id": "295f118d7ebfa0f0ee4066249fe4c8277b6ad042",
    "semantic_title": "claim check-worthiness detection: how well do llms grasp annotation guidelines?",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=XX29vP3tfY": {
    "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
    "volume": "review",
    "abstract": "Large language models (LLMs) have played a fundamental role in various natural language processing tasks with powerful prompt techniques. However, in real-world applications, there are often similar prompt components for repeated queries, which causes significant computational burdens during inference. Existing prompt compression and direct fine-tuning methods aim to tackle these challenges, yet they frequently struggle to strike an optimal balance between cost-efficiency and performance effectiveness, especially in complex tasks such as NL2Code. In this paper, we propose a novel method namely PromptIntern to internalize the prompt knowledge into model parameters via progressive fine-tuning. Our method enables LLMs to emulate the human learning process for a new task, where detailed templates and examples in a prompt are gradually internalized and phased out progressively as the model grows accustomed to the task. Extensive experiments demonstrate that our method can reduce the inference tokens by 67-90\\%, saves 39-90\\% cost, and speedups inference by 1.1-5.1x",
    "checked": true,
    "id": "e7e35bf7e359535b75344e9ba7fb9c6224ffd77b",
    "semantic_title": "promptintern: saving inference costs by internalizing recurrent prompt during large language model fine-tuning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lT9xK9pfLp": {
    "title": "Towards Multimodal Question Answering in Educational Domain",
    "volume": "review",
    "abstract": "The proliferation of educational videos on the Internet has changed the educational landscape by enabling students to learn complex concepts at their own pace. Our work outlines the vision of an automated tutor – a multimodal QA system to answer questions from students watching a video. This can make doubt resolution faster and further improve learning experience. In this work, we take first steps towards building such a QA system. We curate and release a dataset named EduVidQA, with 3,158 videos and 18,474 QA-pairs. However, building and evaluating a QA system proves challenging, because (1) existing evaluation metrics do not correlate with human judgments, and (2) a student question could be answered in many different ways, and training on a single gold answer often confuses the model and makes it worse. We conclude with important research questions to develop this research area further",
    "checked": false,
    "id": "b5c62408df08da36d9cdfd38886193b451157a3b",
    "semantic_title": "eduvqa – visual question answering: an educational perspective",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Bk8hNalWin": {
    "title": "Token-Ensemble Text Generation: On Attacking the Automatic AI-Generated Text Detection",
    "volume": "review",
    "abstract": "The robustness of AI-content detection models against sophisticated adversarial strategies, such as paraphrasing or word switching, is a rising concern in natural language generation (NLG) applications. This study proposes a novel token-ensemble generation strategy to challenge the robustness of current AI-content detection approaches by utilizing multiple sets of candidate generative large language models (LLMs). By randomly sampling token(s) from candidate language model sets, we find the token-ensemble approach significantly drops the performance of AI-content detection models. We evaluate the text quality produced under different token-ensemble settings based on annotations from hired human experts. We proposed a fine-tuned Llama2 model to distinguish the token-ensemble-generated text more accurately. Our findings underscore our proposed text generation approach's great potential in deceiving and improving detection models. This study's datasets, codes, and annotations are open-sourced",
    "checked": true,
    "id": "658c852761dda1372c50d0698093532518c92387",
    "semantic_title": "token-ensemble text generation: on attacking the automatic ai-generated text detection",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=vWYvYGLm3z": {
    "title": "CAMEL: Counterfactuals As a Means for EvaLuating faithfulness of attribution methods in causal language models",
    "volume": "review",
    "abstract": "Despite the widespread adoption of decoder-only autoregressive language models, explainability evaluation research has predominantly focused on encoder-only models, specifically masked language models (MLMs). Evaluating the faithfulness of an explanation method—how accurately the method explains the inner workings and decision-making of the model—is very challenging because it is very hard to separate the model from its explanation. Most faithfulness evaluation techniques corrupt or remove some input tokens considered important according to a particular attribution (feature importance) method and observe the change in the model's output. While these faithfulness evaluation techniques are suitable for MLMs, as they involve corrupted or masked inputs during pretraining, they create out-of-distribution inputs for CLMs due to the fundamental difference in their training objective of next token prediction. In this study, we propose a technique that leverages counterfactual generation to evaluate the faithfulness of attribution methods for autoregressive language modeling scenarios. Our technique creates natural, fluent, and in-distribution counterfactuals, something that we show is important for a faithfulness evaluation method. We apply our method to several attribution methods and evaluate their faithfulness in predicting the important tokens of a few large language models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=57QSR3rrZo": {
    "title": "Negating Negatives: Alignment with Human Negative Samples via Distributional Dispreference Optimization",
    "volume": "review",
    "abstract": "Large language models (LLMs) have revolutionized the role of AI, yet pose potential social risks. To steer LLMs towards human preference, alignment technologies have been introduced and gained increasing attention. Nevertheless, existing methods heavily rely on high-quality positive-negative training pairs, suffering from noisy positive responses that are barely distinguishable from negative ones. Given recent LLMs' proficiency in generating helpful responses, this work pivots towards a new research question: **can we achieve alignment using solely human-annotated negative samples, preserving helpfulness while reducing harmfulness?** For this purpose, we propose Distributional Dispreference Optimization (D$^2$O), which maximizes the discrepancy between dispreferred responses and the generated non-negative ones. In this way, D$^2$O effectively eschews harmful information without incorporating noisy positive samples, while avoiding collapse using self-generated responses as anchors. We demonstrate that D$^2$O can be regarded as learning a distributional preference model reflecting human dispreference against negative responses, which is theoretically an upper bound of the instance-level DPO. Extensive experiments manifest that our method achieves comparable generation quality and surpasses the latest strong baselines in producing less harmful and more informative responses with better training stability and faster convergence",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TUb54qvNV9": {
    "title": "Tokenization Falling Short: The Curse of Tokenization",
    "volume": "review",
    "abstract": "Language models typically tokenize raw text into sequences of subword identifiers from a predefined vocabulary, a process inherently sensitive to typographical errors, length variations, and largely oblivious to the internal structure of tokens—issues we term the curse of tokenization. In this study, we delve into these drawbacks and demonstrate that large language models (LLMs) remain susceptible to these problems. This study systematically investigates these challenges and their impact on LLMs through three critical research questions: (1) complex problem solving, (2) token structure probing, and (3) resilience to typographical variation. Our findings reveal that scaling model parameters can mitigate the issue of tokenization; however, LLMs still suffer from biases induced by typos and other text format variations. Our experiments show that subword regularization such as BPE-dropout can mitigate this issue. We will release our code and data to facilitate further research",
    "checked": true,
    "id": "b81281c0a5d340e908a7e348b0a0521c069131f2",
    "semantic_title": "tokenization falling short: the curse of tokenization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ti4SbPA3a2": {
    "title": "A LLM-based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation",
    "volume": "review",
    "abstract": "The proliferation of misinformation and harmful narratives in online discourse has underscored the critical need for effective Counter Narrative (CN) generation techniques. However, existing automatic evaluation methods often lack interpretability and fail to capture the nuanced relationship between generated CNs and human perceptions. Aiming to achieve a higher correlation with human judgments, this paper proposes a novel approach to asses generated CNs that consists on the use of a Large Language Model (LLM) as a evaluator. By comparing generated CNs pairwise in a tournament-style format, we establish a model ranking pipeline that achieves a correlation of 0.88 with human preference. As an additional contribution, we leverage LLMs as zero-shot CN generators and conduct a comparative analysis of chat, instruct, and base models, exploring their respective strengths and limitations. Through meticulous evaluation, including fine-tuning experiments, we elucidate the differences in performance and responsiveness to domain-specific data. We conclude that chat-aligned models in zero-shot are the best option for carrying out the task, provided they do not refuse to generate an answer due to security concerns",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U338AuBmpo": {
    "title": "MedThink: Explaining Medical Visual Question Answering via Multimodal Decision-Making Rationale",
    "volume": "review",
    "abstract": "Medical Visual Question Answering (MedVQA) provides language responses to image-based medical inquiries, facilitating more accurate diagnoses. However, existing MedVQA methods lack interpretability and transparency. To address this, we introduce a semi-automated annotation process and create new benchmark datasets, R-RAD and R-SLAKE, incorporating multimodal language models and human annotations. Additionally, we develop a framework, MedThink, to fine-tune lightweight generative models with medical decision-making rationales. This framework employs three distinct strategies to generate decision outcomes and corresponding rationales, effectively showcasing the medical decision-making process during reasoning. MedThink achieves 83.5\\% accuracy on R-RAD and 86.3\\% on R-SLAKE, outperforming current baselines. Dataset and code will be released",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yt0GQNJNDs": {
    "title": "CERD: A Comprehensive Chinese Rhetoric Dataset for Rhetorical Understanding and Generation in Essays",
    "volume": "review",
    "abstract": "Existing rhetorical understanding and generation datasets or corpora primarily focus on single coarse-grained categories or fine-grained categories, neglecting the common interrelations between different rhetorical devices by treating them as independent sub-tasks. In this paper, we propose the $\\textbf{C}$hinese $\\textbf{E}$ssay $\\textbf{R}$hetoric $\\textbf{D}$ataset (CERD), consisting of 4 commonly used coarse-grained categories including metaphor, personification, hyperbole and parallelism and 23 fine-grained categories across both form and content levels. CERD is a manually annotated and comprehensive Chinese rhetoric dataset with five interrelated sub-tasks. Unlike previous work, our dataset aids in understanding various rhetorical devices, recognizing corresponding rhetorical components, and generating rhetorical sentences under given conditions, thereby improving the author's writing proficiency and language usage skills. Extensive experiments are conducted to demonstrate the interrelations between multiple tasks in CERD, as well as to establish a benchmark for future research on rhetoric. The experimental results indicate that Large Language Models achieve the best performance across most tasks, and jointly fine-tuning with multiple tasks further enhances performance. The dataset and code will be released in a future version",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aEZgQVIFaP": {
    "title": "Holistic Evaluation for Interleaved Text-and-Image Generation",
    "volume": "review",
    "abstract": "Interleaved text-and-image generation has been an intriguing research direction, where the models are required to generate both images and text pieces in an arbitrary order. Despite the emerging advancements in interleaved generation, the progress in its evaluation still significantly lags behind. Existing evaluation benchmarks do not support arbitrarily interleaved images and text for both inputs and outputs, and they only cover a limited number of domains and use cases. Also, current works predominantly use similarity-based metrics which fall short in assessing the quality in open-ended scenarios. To this end, we introduce InterleavedBench, the first benchmark carefully curated for the evaluation of interleaved text-and-image generation. InterleavedBench features a rich array of tasks to cover diverse real-world use cases. In addition, we present InterleavedEval, a strong reference-free metric powered by GPT-4o to deliver accurate and explainable evaluation. We carefully define five essential evaluation aspects for InterleavedEval, including text quality, perceptual quality, image coherence, text-image coherence, and helpfulness, to ensure a comprehensive and fine-grained assessment. Through extensive experiments and rigorous human evaluation, we show that our benchmark and metric can effectively evaluate the existing models with a strong correlation with human judgments surpassing previous reference-based metrics. We also provide substantial findings and insights to foster future research in interleaved generation and its evaluation",
    "checked": true,
    "id": "1b6f04a3cfab8804a1d16b83f1853fdd0b682865",
    "semantic_title": "holistic evaluation for interleaved text-and-image generation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=KMb5KB4jDq": {
    "title": "C-LLM: Learn to Check Chinese Spelling Errors Character by Character",
    "volume": "review",
    "abstract": "Chinese Spell Checking (CSC) aims to detect and correct spelling errors in sentences. Despite Large Language Models (LLMs) exhibit robust capabilities and are widely applied in various tasks, their performance on CSC is often unsatisfactory. We find that LLMs fail to meet the Chinese character-level constraints of the CSC task, namely equal length and phonetic similarity, leading to a performance bottleneck. Further analysis reveal that this issue stems from the granularity of tokenization, as current mixed character-word tokenization struggles to satisfy these character-level constraints. To address this issue, we propose C-LLM, a Large Language Model-based Chinese Spell Checking method that learns to check errors Character by Character. Character-level tokenization enables the model to learn character-level alignment, effectively mitigating issues related to character-level constraints. Furthermore, CSC is simplified to replication-dominated and substitution-supplemented tasks. Experiments on two CSC benchmarks demonstrate that C-LLM achieves a 2.1\\% enhancement in general scenarios and a significant 12\\% improvement in vertical domain scenarios compared to existing methods, establishing state-of-the-art performance",
    "checked": true,
    "id": "4b6749c981de4c3f519ef18749ecd3059abbff32",
    "semantic_title": "c-llm: learn to check chinese spelling errors character by character",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8QvzkkuM1T": {
    "title": "CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration",
    "volume": "review",
    "abstract": "Existing LLMs exhibit remarkable performance on various NLP tasks, but still struggle with complex real-world tasks, even equipped with advanced strategies like CoT and ReAct. In this work, we propose the CoAct framework, which transfers the hierarchical planning and collaboration patterns in human society to LLM systems. Specifically, our CoAct framework involves two agents: (1) A global planning agent, to comprehend the problem scope, formulate macro-level plans and provide detailed sub-task descriptions to local execution agents, which serves as the initial rendition of a global plan. (2) A local execution agent, to operate within the multi-tier task execution structure, focusing on detailed execution and implementation of specific tasks within the global plan. Experimental results on the WebArena benchmark show that CoAct can re-arrange the process trajectory when facing failures, and achieves superior performance over baseline methods on long-horizon web tasks",
    "checked": true,
    "id": "e93f1fdaecd63298d60fd2574ae4f241912edb37",
    "semantic_title": "coact: a global-local hierarchy for autonomous agent collaboration",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nMQgHmhKDD": {
    "title": "LegalViz: Legal Text Visualization by Text To Diagram Generation",
    "volume": "review",
    "abstract": "Legal documents including judgments, court orders, government ordinances, professional papers, and textbooks of judicial examinations require highly sophisticated legal knowledge for understanding. To disclose expert knowledge for non-experts, we explore the problem of visualizing legal texts with easy-to-understand diagrams and propose a novel dataset of LegalViz with 23 languages and 5,580 cases of legal document and visualization pairs, using the DOT graph description language of Graphviz. LegalViz provides a simple diagram from a complicated legal corpus identifying legal entities, rules, statements, and transactions at a glance, that are important in each judgment. In addition, we provide a new evaluation approach for the legal diagram visualization by considering the graph and text similarities. We conducted empirical studies on few-shot and finetuning large language models for generating legal diagrams and evaluated them with the graph and text evaluation metrics by each model in 23 languages and confirmed the effectiveness of our dataset",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XHLVUIbnJh": {
    "title": "Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems",
    "volume": "review",
    "abstract": "End-to-end Task-Oriented Dialog (TOD) systems typically require extensive training datasets to perform well. In contrast, large language model (LLM) based TOD systems can excel even with limited data due to their ability to learn tasks through in-context exemplars. However, these models lack alignment with the style of responses in training data and often generate comprehensive responses, making it difficult for users to grasp the information quickly. In response, we propose *SyncTOD* that synergizes LLMs with task-specific hints to improve alignment in low-data settings. *SyncTOD* employs small auxiliary models to provide hints and select exemplars for in-context prompts. With *ChatGPT*, *SyncTOD* achieves superior performance compared to LLM-based baselines and SoTA models in low-data settings, while retaining competitive performance in full-data settings",
    "checked": true,
    "id": "d4dcd6eaab30e47ed3ba526663bdaa99e74a16e4",
    "semantic_title": "synergizing in-context learning with hints for end-to-end task-oriented dialog systems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t9dGSDTtFx": {
    "title": "Enhancing Zero-shot Emotion Perception in Conversation through the Internal-to-External Chain-of-Thought",
    "volume": "review",
    "abstract": "An excellent emotional dialogue model needs to rapidly adapt to new scenarios and perform emotion analysis to meet rapidly changing demands. Therefore, enhancing the model's zero-shot emotion-related capabilities in the dialogue domain has become a new challenge. However, current research shows that large language models (LLMs) perform poorly in zero-shot emotion-related tasks and the Emotion Recognition in Conversations (ERC) task alone doesn't comprehensively reflect the model's emotion understanding capabilities. In this paper, we propose an Emotion Perception in Conversation (EPC) task, which includes both ERC and Emotion Inference in Conversations (EIC), to evaluate the model's emotion perception capabilities in dialogue comprehensively. We propose an Internal-to-External Chain-of-Thought (IoECoT) method for the EPC task. This is a plug-and-play method that first extracts personality information of the dialogue participants from the dialogue history as internal factors influencing emotions, and then uses the sentiment polarity of the historical utterances as external factors. Finally, emotions are perceived by combining internal and external factors. Additionally, we conduct extensive experiments, and the results show that IoECoT significantly outperforms other baselines across multiple models and datasets, demonstrating that IoECoT effectively enhances the emotion perception capabilities of LLMs in zero-shot scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8eMZBseusC": {
    "title": "Playing with News Context for Algorithmic Trading",
    "volume": "review",
    "abstract": "The application of reinforcement learning for algorithmic trading in the spot market using numerical data is a well-studied problem. However, news data consists of hard-to-quantify information which the investors use to base their trading decisions. Thus factoring in news data for algorithmic trading can improve the trading performance of the RL agent. This paper proposes an RL-based framework that performs algorithmic trading in the futures market by combining news data and price data. We propose two approaches for representing the context of the news data: sentiment-aware approach and context-aware approach. We investigate the effect of these approaches on the trading performance of the RL agent. We further compare the performance of on-policy and off-policy RL algorithms. The models are evaluated by trading in the NIFTY 50 index. The evaluation of the models show that using context-aware approach for representation of news data significantly improves the return (\\%) and also reduces the maximum drawdown of the trading model during a trading session",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KtaD0vl1e7": {
    "title": "ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs",
    "volume": "review",
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities across various tasks, but their performance is highly sensitive to the prompts utilized. This variability poses challenges for accurate assessment and user satisfaction. Current research frequently overlooks instance-level prompt variations and their implications on subjective evaluations. To address these shortcomings, we introduce \\textbf{ProSA}, a framework designed to evaluate and comprehend prompt sensitivity in LLMs. ProSA incorporates a novel sensitivity metric, \\texttt{PromptSensiScore}, and leverages decoding confidence to elucidate underlying mechanisms. Our extensive study, spanning multiple tasks, uncovers that prompt sensitivity fluctuates across datasets and models, with larger models exhibiting enhanced robustness. We observe that few-shot examples can alleviate this sensitivity issue, and subjective evaluations are also susceptible to prompt sensitivities, particularly in complex, reasoning-oriented tasks. Furthermore, our findings indicate that higher model confidence correlates with increased prompt robustness. We believe this work will serve as a helpful tool in studying prompt sensitivity of LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=94L33aYLJd": {
    "title": "MASAI: Modular Architecture for Software-engineering AI Agents",
    "volume": "review",
    "abstract": "A common method to solve complex problems in software engineering, is to divide the problem into multiple sub-problems. Inspired by this, we propose a Modular Architecture for Software-engineering AI (MASAI) agents, where different LLM-powered sub-agents are instantiated with well-defined objectives and strategies tuned to achieve those objectives. Our modular architecture offers several advantages: (1) employing and tuning different problem-solving strategies across sub-agents, (2) enabling sub-agents to gather information from different sources scattered throughout a repository, and (3) avoiding unnecessarily long trajectories which inflate costs and add extraneous context. MASAI enabled us to achieve the highest performance (28.33% resolution rate) on the popular and highly challenging SWE-bench Lite dataset consisting of 300 GitHub issues from 11 Python repositories. We conduct a comprehensive evaluation of MASAI relative to other agentic methods and analyze the effects of our design decisions and their contribution to the success of MASAI",
    "checked": true,
    "id": "c0b6149a7ff72817d5cdb008566dc4f0ca9b9379",
    "semantic_title": "masai: modular architecture for software-engineering ai agents",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=4U9A3aR5pJ": {
    "title": "Detecting Infrastructure Bias in LLM Generated Text",
    "volume": "review",
    "abstract": "In this study, we explore potential biases in large language models (LLMs) from a novel perspective. We focus on detecting racial bias in texts generated by these models that describe the physical environments of diverse racial communities and the narratives of their inhabitants. Our study reveals statistically significant infrastructure biases in popular LLMs, including ChatGPT, Gemma and Llama 3, suggesting potential racial biases linked to built environment features",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=igWWeJesIr": {
    "title": "Double-Checker: Large Language Model as a Checker for Few-shot Named Entity Recognition",
    "volume": "review",
    "abstract": "Recently, few-shot Named Entity Recognition (NER) has attracted significant attention due to the high cost of obtaining high-quality labeled data. Decomposition-based methods have demonstrated remarkable performance on this task, which initially train a type-independent span detector and subsequently classify the detected spans based on their types. However, this framework has an evident drawback as a domain-agnostic detector cannot ensure the identification of only those entity spans that are specific to the target domain. To address this issue, we propose Double-Checker, which leverages collaboration between Large Language Models (LLMs) and small models. Specifically, we employ LLMs to verify candidate spans predicted by the small model and eliminate any spans that fall outside the scope of the target domain. Extensive experiments validate the effectiveness of our method, consistently yielding improvements over two baseline approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cpzV5YpC1h": {
    "title": "QuanSIRA: The Quantitative Investment Risk Modeling in Stock Markets with Large Language Models",
    "volume": "review",
    "abstract": "Stock market analysis is important for investors to make financial decisions. Stock price prediction is widely investigated in the natural language processing area due to the superiority of large language models. Recent works have developed several datasets for stock price predictions. However, investment risk, considered an essential factor for investors, is rarely discussed in NLP applications, and there are limited datasets for investment risk analysis. In this work, we propose methods to quantify investment risk and introduce the dataset QuanSIRA. Using this benchmark, we investigate the applications of large language models in tackling quantitative investment risk analysis. The experimental results show the difficulty of investment risk analysis. The model built on pre-trained large language models obtained F1 scores of 68.07 and 65.01 in the in-stock benchmark and the cross-stock benchmark of investment risk prediction task",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=i7KbJCPlOL": {
    "title": "Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews",
    "volume": "review",
    "abstract": "The integrity of the peer-review process is vital for maintaining scientific rigor and trust within the academic community. With the steady increase in the usage of large language models (LLMs) like ChatGPT in academic writing, there is a growing concern that AI-generated texts could compromise the scientific publishing including peer-reviews. Previous works have focused on generic AI-generated text detection or have presented an approach for estimating the fraction of peer-reviews that can be AI-generated. Our focus here is to solve a real-world problem by assisting the editor or chair in determining whether a review is written by ChatGPT or not. To address this, we introduce the Term Frequency (TF) model, which posits that AI often repeats tokens, and the Review Regeneration (RR) model which is based on the idea that ChatGPT generates similar outputs upon re-prompting. We stress test these detectors against token attack and paraphrasing. Finally we propose an effective defensive strategy to reduce the effect of paraphrasing on our models. Our findings suggest both our proposed methods perform better than other AI text detectors. Our RR model is more robust, although our TF model performs better than the RR model without any attacks. We make our code, dataset, model public",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rD2HwXN7bx": {
    "title": "Refining Multilingual Pronunciation through G2P and ASR Integration",
    "volume": "review",
    "abstract": "Pronunciation dictionaries are indispensable for applications in speech synthesis and language learning, providing word pronunciations across diverse languages. Grapheme-to-Phoneme (G2P) models are pivotal in creating these dictionaries. However, variations in pronunciation can arise due to language, context, dialect, and acoustic conditions, potentially introducing inaccuracies. To address this, we introduce an approach to refine G2P model outputs by utilizing an alignment and weighting algorithm to integrate results from an acoustic phone recognizer across several high and low-resource languages",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2kYbu7XQxI": {
    "title": "Skill based framework for harnessing emergent abilities of LLMs for knowledge management",
    "volume": "review",
    "abstract": "This paper introduces a skill-based framework for enhancing the emergent abilities of Large Language Models (LLMs) within knowledge management applications, leveraging Retrieval-Augmented Generation (RAG). LLMs exhibit emergent abilities that can significantly impact their performance in complex tasks. Our approach explores and harnesses these abilities by defining skills, optimizing model performance through the DSPy framework, and assessing impact using a combination of discrete and continuous metrics. We conducted experiments on LLMs of varying scales, focusing on models like GPT-3.5 and Mistral 7B, across skill associated datasets (Emotion-based, fact-based persona, persona emotional state, crisp answers). Our results indicate that the DSPy optimization enhances LLM performance, particularly in generating contextually rich responses while reducing operational costs. This study not only sheds light on the mechanisms through which emergent abilities develop in LLMs but also illustrates how skill-based frameworks can systematically leverage these properties to improve efficiency and effectiveness in real-world applications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U1AaWjiFH6": {
    "title": "Self-Distillation Across Modalities: Enhancing Cross-Modal Correlation Perception for Effective Multimodal Fake News Detection",
    "volume": "review",
    "abstract": "The proliferation of multimodal fake news content has garnered increasing attention. Existing multimodal fake news detection methods have significantly contributed to the automation of fake news detection. However, these methods often rely on explicit cross-modal consistency, while the impact of consistency on the veracity of news is not absolute. In this paper, we propose a novel Self-Distillation Across Modalities (SDAM) method for multimodal fake news detection. Our approach leverages internal self-distillation from multimodal representations to the unimodal, implicitly capturing cross-modal correlation. Additionally, SDAM employs a structured segmentation of text based on human biological habits, capturing global textual information while minimally affecting the number of input tokens. Extensive experiments demonstrate that SDAM exhibits superior performance in multimodal fake news detection",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hPHe91dZ9H": {
    "title": "WIKIGENBENCH: Exploring Full-length Wikipedia Generation for New Events",
    "volume": "review",
    "abstract": "Generating comprehensive and accurate Wikipedia articles for newly emerging real-world events presents significant challenges. Previous efforts have often fallen short by focusing only on short snippets, neglecting verifiability, or ignoring the impact of the pre-training corpus. In this paper, we simulate a real-world scenario where structured, full-length Wikipedia articles with citations are generated for new events using input documents from web sources. To minimize data leakage in Large Language Models (LLMs), we select recent events and construct a new benchmark, WIKIGENBENCH, consisting of 1320 events paired with their corresponding related web documents. We also design a comprehensive set of systematic metrics and LLM-based baseline methods to evaluate the capability of LLMs in generating factual, full-length Wikipedia articles. The data and code will be released upon acceptance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f3TRCoTDME": {
    "title": "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language processing, demonstrating exceptional reasoning, tool usage, and memory capabilities. As their applications expand into multi-agent environments, there arises a need for a comprehensive evaluation framework that captures LLMs' reasoning, planning, collaboration, and other social abilities. This work introduces a novel competition-based benchmark framework specifically designed to assess LLMs within multi-agent settings, providing quantitative metrics to evaluate their judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality. To create diverse environments, we utilize two social deduction games alongside three game theory scenarios. Our frame is fortified with the probabilistic graphic modeling (PGM) method, enhancing the LLMs' capabilities in navigating complex social and cognitive dimensions. We evaluate seven LLMs, quantitatively highlighting a significant capability gap of over threefold between the strongest, GPT-4, and the weakest, Llama-2-70B. It also confirms that our PGM enhancement boosts the abilities of all selected models by an average of 37\\%. Our codes are in the anonymous link https://anonymous.4open.science/r/magic_anonym-5366",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ld5fGYUK9n": {
    "title": "MOCK: Can LLMs Really Understand Humor-Sarcasm?",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) have demonstrated the capacity to engage in interaction with humans, employing humor and sarcasm. However, their true comprehension of humor and sarcasm remains a subject of inquiry. This work introduces the hu$\\textbf{M}$or-sarcasm c$\\textbf{O}$mprehension ben$\\textbf{C}$hmar$\\textbf{K}$, named MOCK, to systematically evaluate LLMs' abilities to detect, match, and explain humor-sarcasm across diverse scenes, including cartoon, post, and comedy. Our comprehensive assessment reveals significant gap between the performance of LLMs and human on humor-sarcasm comprehension. To bridge this gap, we propose a Chain-of-Task approach that integrates the three comprehension sub-tasks (\\ie detecting, matching and explaining), leveraging their interrelatedness to enhance humor-sarcasm comprehension. Additionally, we propose a novel humor-sarcasm generation task and explore the potential of MOCK to improve LLMs' humor-sarcasm generation capabilities. The evaluation results verify that humor-sarcasm comprehension can significantly enhance humor-sarcasm generation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RCeC68JlL1": {
    "title": "ConceptPsy: A Benchmark Suite with Conceptual Comprehensiveness in Psychology",
    "volume": "review",
    "abstract": "The effective incorporation of Large Language Models (LLMs) into the field of psychology necessitates a comprehensive domain benchmark to guide their development and adaptation. Existing Chinese benchmarks in the style of MMLU, such as CMMLU, do include psychology subjects, but their concept coverage is far from exhaustive. The number of questions in each domain is just in the hundreds, and an uneven question sampling process can lead to a ``concept bias'' issue. This bias, stemming from using a question set with a low concept coverage rate to represent a subject, can potentially lead to skewed results. To address this, we present ConceptPsy, a Chinese conceptual benchmark specifically designed for evaluating LLMs' complex reasoning and knowledge in psychology. ConceptPsy encompasses 12 core subjects and 1,383 concepts from official exams. To avoid copyright issues, we prompt \\texttt{GPT-4} to generate questions for each of the concepts, which are then validated by psychology professionals to ensure high quality. Besides the overall scores, we annotate each question with a chapter label to provide fine-grained results. We evaluate a range of LLMs on ConceptPsy and the results show significant performance differences across psychology concepts, even among models from the same series. We anticipate the comprehensive concept coverage and the fine-grained strengths and weaknesses identified by ConceptPsy can facilitate the development and growth of the Chinese psychology domain",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VOV0ymQGk2": {
    "title": "Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning",
    "volume": "review",
    "abstract": "Despite significant advancements, there is a limited understanding of how large language models (LLMs) utilize knowledge for reasoning. To address this, we propose a method that deconstructs complex real-world questions into a graph, representing each question as a node with parent nodes of background knowledge needed to solve the question. We develop the DepthQA set, deconstructing questions into three depths: (i) recalling conceptual knowledge, (ii) applying procedural knowledge, and (iii) analyzing strategic knowledge. Based on a hierarchical graph, we quantify forward discrepancy, discrepancies in LLMs' performance on simpler sub-problems versus complex questions. We also measure backward discrepancy, where LLMs answer complex questions but struggle with simpler ones. Our analysis shows that smaller models have more discrepancies than larger models. Additionally, guiding models from simpler to complex questions through multi-turn interactions improves performance across model sizes, highlighting the importance of structured intermediate steps in knowledge reasoning. This work enhances our understanding of LLM reasoning and suggests ways to improve their problem-solving abilities",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NjbjefmfAB": {
    "title": "Not Everything is All You Need: Toward Low-Redundant Optimization for Large Language Model Alignment",
    "volume": "review",
    "abstract": "Large language models (LLMs) are still struggling in aligning with human preference in complex tasks and scenarios. They are prone to overfit into the unexpected patterns or superficial styles in the training data. We conduct an empirical study that only selects the top-10\\% most updated parameters in LLMs for alignment training, and see improvements in the convergence process and final performance. It indicates the existence of redundant neurons in LLMs for alignment training. To reduce its influence, we propose a low-redundant alignment method named $\\textbf{ALLO}$, focusing on optimizing the most related neurons with the most useful supervised signals. Concretely, we first identify the neurons that are related to the human preference data by a gradient-based strategy, then identify the alignment-related key tokens by reward models for computing loss. Besides, we also decompose the alignment process into the forgetting and learning stages, where we first forget the tokens with unaligned knowledge and then learn aligned knowledge, by updating different ratios of neurons, respectively. Experimental results on 10 datasets have shown the effectiveness of ALLO. Our code and data will be publicly released",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eX0cMTH433": {
    "title": "WTU-EVAL: A Whether-or-Not Tool Usage Evaluation Benchmark for Large Language Models",
    "volume": "review",
    "abstract": "Although Large Language Models (LLMs) excel in NLP tasks, they still need external tools to extend their ability. Current research on tool learning with LLMs often assumes mandatory tool use, which does not always align with real-world situations, where the necessity for tools is uncertain, and incorrect or unnecessary use of tools can damage the general abilities of LLMs. Therefore, we propose to explore whether LLMs can discern their ability boundaries and use tools flexibly. We then introduce the Whether-or-not tool usage Evaluation benchmark (WTU-Eval) to assess LLMs with eleven datasets, where six of them are tool-usage datasets, and five are general datasets. LLMs are prompted to use tools according to their needs. The results of eight LLMs on WTU-Eval reveal that LLMs frequently struggle to determine tool use in general datasets, and LLMs' performance in tool-usage datasets improves when their ability is similar to ChatGPT. In both datasets, incorrect tool usage significantly impairs LLMs' performance. To mitigate this, we also develop the finetuning dataset to enhance tool decision-making. Fine-tuning Llama2-7B results in a 14\\% average performance improvement and a 16.8\\% decrease in incorrect tool usage. We will release the WTU-Eval benchmark",
    "checked": true,
    "id": "c8a5e1b37c448b0e17720b3c4e65d5b36c695638",
    "semantic_title": "wtu-eval: a whether-or-not tool usage evaluation benchmark for large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dI5asbPk6H": {
    "title": "SCoPe: Submodular Combinatorial Prototype Learner for Continuous Speech Keyword Spotting",
    "volume": "review",
    "abstract": "Keyword Spotting (KwS) in the continuous speech setting encapsulates localization and recognition of keywords amongst a large volume of non-keyword tokens, further exemplified by variation in speakers and presence of rare keywords. Our paper presents a novel Submodular Combinatorial Prototype (SCoPe) learning framework that not only contrasts between target keywords but also ensures sufficient separation of keywords with non-keyword tokens. Additionally, our work proposes a weakly-supervised training strategy, utilizing forced-alignment on phoneme level embeddings to guide a windowing function to correctly localize keywords of interest. We evaluate our model on the popular LibriSpeech and L2-Arctic datasets under varying numbers of keywords demonstrating a class-imbalanced distribution, and show that our proposed architecture consistently outperforms existing baselines by upto 1.8%",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EjzgVCaP80": {
    "title": "BiasDora: Exploring Hidden Biased Associations in Vision-Language Models",
    "volume": "review",
    "abstract": "Existing works examining Vision Language Models (VLMs) for social biases predominantly focus on a limited set of documented bias associations, such as gender-profession or race-crime. This narrow scope often overlooks a vast range of unexamined implicit associations, restricting the identification and, hence, mitigation of such biases. We address this gap by probing VLMs to (1) uncover hidden, implicit associations across 9 bias dimensions. We systematically explore diverse input and output modalities and (2) demonstrate how biased associations vary in their negativity, toxicity, and extremity. Our work (3) identifies subtle and extreme biases that are typically not recognized by existing methodologies. We make the **D**ataset **o**f **r**etrieved **a**ssociations, (__Dora__), publicly available",
    "checked": true,
    "id": "69f58648780d6de2fe79745790a5b974927735f3",
    "semantic_title": "biasdora: exploring hidden biased associations in vision-language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jOHp3SYZJm": {
    "title": "Automated Grammar Error Correction for Urdu using Deep Learning",
    "volume": "review",
    "abstract": "Automated Grammar Error Correction (GEC) is an active area of research within the field of Natural Language Processing (NLP), yet its scope remains restricted to English and other resource-rich languages. Urdu is a language that is widely spoken in South Asia. However, due to the lack of annotated datasets no work has been in field of GEC for Urdu language. This paper presents an GEC model for Urdu. In addition, we also present a dataset that contains 1200 pairs of grammatically correct and incorrect sentences in Urdu that was manually curated from children books. Moreover, we also scrapped 400 children stories from Rekhta, an Urdu Literary website, and introduced errors probabilistically to create a dataset with 36,000 pairs of grammatically correct and incorrect sentences. The model that we used was mT5, which is a multilingual version of T5 transformer based model presented by Google. We trained the model in two stages. First, we trained the model on the manually curated dataset. Then, we trained the same model on the dataset that was scrapped from web. Finally, we tested the model by on Wikipedia Edit History dataset containing only grammatical errors which were identified using ERRANT. F0.5 Score, GLEU, Recall and Precision were used as evaluation criteria. The F0.5 scores for the test dataset after fine tuning the MT5 Base model on Raw + Synthetic Dataset are: NOUN INFL 0.63, ADP INFL 0.76, VERB INFL 0.73, VERB FORM 0.66, ADJ INFL 0.76, and PRON INFL 0.74. Additionally, our study is the first to focus on GEC systems, as to the best of our knowledge, no prior work has been done in this field",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X7KPsMrYtL": {
    "title": "Not all Layers of LLMs are Necessary during Inference",
    "volume": "review",
    "abstract": "The inference phase of Large Language Models (LLMs) is very expensive. An ideal inference stage of LLMs could utilize fewer computational resources while still maintaining its capabilities (e.g., generalization and in-context learning ability). In this paper, we try to answer the question, \"During LLM inference, can we use shallow layers for easy instances; and deep layers for hard ones?\" To answer this question, we first indicate that Not all Layers are Necessary during Inference by statistically analyzing the activated layers across tasks. Then, we propose a simple algorithm named AdaInfer to determine the inference termination moment based on the input instance adaptively. More importantly, AdaInfer does not alter LLM parameters and maintains generalizability across tasks. Experiments on well-known LLMs (i.e., Llama2 series and OPT) show that AdaInfer can achieve an average of 17.8% pruning ratio, even up to 43% on sentiment tasks while maintaining comparable performance with minimal loss (<1%). Additionally, this method is orthogonal to other model acceleration techniques, potentially boosting inference efficiency further",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MPBrmuOOX7": {
    "title": "DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging",
    "volume": "review",
    "abstract": "Reinforcement learning from human feedback (RLHF) is a popular strategy for aligning large language models (LLMs) with desired behaviors. Reward modeling is a crucial step in RLHF. However, collecting paired preference data for training reward models is often costly and time-consuming, especially for domain-specific preferences requiring expert annotation. To address this challenge, we propose the \\textbf{Do}main knowled\\textbf{ge} merged \\textbf{R}eward \\textbf{M}odel (DogeRM), a novel framework that integrates domain-specific knowledge into a general reward model by model merging. The experiments demonstrate that DogeRM enhances performance across different benchmarks and provide a detailed analysis showcasing the effects of model merging, showing the great potential of facilitating model alignment",
    "checked": true,
    "id": "6f8d26bef8ac26f747a8bd9919109798f61eb0ed",
    "semantic_title": "dogerm: equipping reward models with domain knowledge through model merging",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J8Nzr2T5eJ": {
    "title": "ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets",
    "volume": "review",
    "abstract": "This work addresses the timely yet underexplored problem of performing inference and finetuning of a proprietary LLM owned by a model provider entity on the confidential/private data of another data owner entity, in a way that ensures the confidentiality of both the model and the data. Hereby, the finetuning is conducted offsite, i.e., on the computation infrastructure of a third-party cloud provider. We tackle this problem by proposing \\texttt{ObfuscaTune}, a novel, efficient and fully utility-preserving approach that combines a simple yet effective obfuscation technique with an efficient usage of confidential computing (only $~5\\%$ of the model parameters are placed on TEE). We empirically demonstrate the effectiveness of \\texttt{ObfuscaTune} by validating it on GPT-2 models with different sizes on four NLP benchmark datasets. Finally, we compare to a naive version of our approach to highlight the necessity of using random matrices with low condition numbers in our approach to reduce errors induced by the obfuscation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6DOAoQANIB": {
    "title": "Robust AI-Generated Text Detection by Restricted Embeddings",
    "volume": "review",
    "abstract": "Growing amount and quality of AI-generated texts makes detecting such content more difficult. In most real-world scenarios, the domain (style and topic) of generated data and the generator model are not known in advance. In this work, we focus on the robustness of classifier-based detectors of AI-generated text, namely their ability to transfer to unseen generators or semantic domains. We investigate the geometry of the embedding space of Transformer-based text encoders and show that clearing out harmful linear subspaces helps to train a robust classifier, ignoring domain-specific spurious features. We investigate several subspace decomposition and feature selection strategies and achieve significant improvements over state of the art methods in cross-domain and cross-generator transfer. Our best approaches for head-wise and coordinate-based subspace removal increase the mean out-of-distribution (OOD) classification score by 9% and 14% for RoBERTa and BERT embeddings respectively",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ILJTa37aUN": {
    "title": "LAR: LLM Assisted Retrieval",
    "volume": "review",
    "abstract": "Large language models (LLMs), have demonstrated significant success in natural language understanding and generation tasks. In this work, we propose LAR (Large language model Assisted Retrieval) to harness LLMs towards enhancing the effectiveness of retrieval models, thereby improving the relevance of information retrieval from datasets. Our approach augments a retriever engine by incorporating a subsequent refinement step to the query, utilizing an LLM. This approach showcases the potential of combining retrieval models with LLMs to advance information retrieval systems. We demonstrate the efficacy of LAR through extensive evaluations, specifically showing enhanced performance on the BEIR retrieval benchmark. Furthermore, our methodology exhibits notable improvements on downstream tasks such as question answering, as demonstrated on the NarrativeQA dataset",
    "checked": false,
    "id": "db22b645cb9d213095089a9ba88d02d18e6543a6",
    "semantic_title": "avatar: optimizing llm agents for tool-assisted knowledge retrieval",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=O65aiPtB1t": {
    "title": "LightCache: Efficient Inference for Transformers via KV Cache Compression in Feature Dimension",
    "volume": "review",
    "abstract": "KV Cache Optimization is a crucial topic in improving the inference efficiency and length extrapolation of Transformer-based Large Language Models (LLMs). Previous KV Cache Optimization approaches often focus on pruning or compressing the sequence dimension, leading to an irreversible loss of contextual information. In this work, we propose LightCache, a novel KV Cache optimization approach that operates on the feature dimension. LightCache employs parameter-aware compression and full-context cache selection, allowing it to reduce memory usage and enhance computational efficiency without sacrificing contextual information. Importantly, LightCache enables a training-free integration with LLMs. Experiments demonstrate that LightCache outperforms classic extrapolation, quantization, and context-pruning methods in long-context evaluation. In terms of efficiency, LightCache reduces the KV Cache size by over 60\\% and achieves 1.7$\\sim$2.4$\\times$ memory efficiency as well as 1.5$\\sim$3.6$\\times$ speedup in 32K context length",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7BsrRLQQxt": {
    "title": "Representation Alignment and Adversarial Networks for Cross-lingual Dependency Parsing",
    "volume": "review",
    "abstract": "Thanks to the strong representation capability of pre-trained language models, dependency parsing in rich-resource language has achieved remarkable improvements. However, the parsing accuracy drops sharply when the model is transferred to low-resource language due to distribution shifts. To alleviate this issue, we propose a representation alignment and adversarial model to filter out useful knowledge from rich-resource language and ignore useless ones. Our proposed model consists of two components, i.e., an alignment network in the input layer for selecting useful language-specific representation features and an adversarial network in the encoder layer for augmenting the language-invariant contextualized features. Experiments on the benchmark datasets show that our proposed model outperforms RoBARTa-enhanced strong baseline models by 1.37 LAS and 1.34 UAS. Detailed analysis shows that both alignment and adversarial networks are equally important in alleviating the distribution shifts problem and can benefit from each other. In addition, the comparative experiments demonstrate that both the alignment and adversarial networks can substantially facilitate extracting and utilizing relevant target language features, thereby increasing the adaptation capability of our proposed model",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rNzTEAwhnY": {
    "title": "Reverse Thinking in Large Language Models",
    "volume": "review",
    "abstract": "Humans are accustomed to reading and writing in a forward manner, and this natural bias extends to text understanding in auto-regressive large language models (LLMs). This paper investigates whether LLMs, like humans, struggle with reverse thinking, specifically with reversed text inputs. We found that publicly available pre-trained LLMs cannot understand such inputs. However, LLMs trained from scratch with both forward and reverse texts can understand them equally well during inference. Our case study shows that different-content texts result in different losses if input (to LLMs) in different directions---some get lower losses for forward while some for reverse. This leads us to a simple and nice solution for data selection based on the loss differences between forward and reverse directions. Using our selected data in continued pretraining can boost LLMs' performance by a large margin for the task of Massive Multitask Language Understanding",
    "checked": false,
    "id": "3ae618cf5c264dcbf6c4d30ce40c4315502fe6de",
    "semantic_title": "re-thinking inverse graphics with large language models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=oriK8vHGQe": {
    "title": "HAF-RM: A Hybrid Alignment Framework for Reward Model Training",
    "volume": "review",
    "abstract": "The reward model has become increasingly important in alignment, assessment, and data construction for large language models (LLMs). Most existing researchers focus on enhancing reward models through data improvements, following the conventional training framework for reward models that directly optimizes the predicted rewards. In this paper, we propose a hybrid alignment framework **HaF-RM** for reward model training by introducing an additional constraint on token-level policy probabilities in addition to the reward score. It can simultaneously supervise the internal preference model at the token level and optimize the mapping layer of the reward model at the sequence level. Theoretical justifications and experiment results on five datasets show the validity and effectiveness of our proposed hybrid framework for training a high-quality reward model. By decoupling the reward modeling procedure and incorporating hybrid supervision, our **HaF-RM** framework offers a principled and effective approach to enhancing the performance and alignment of reward models, a critical component in the responsible development of powerful language models. We release our code at [https://haf-rm-anonymized.github.io](https://haf-rm-anonymized.github.io)",
    "checked": true,
    "id": "581d831fcea84501bec33161c716d5bf94a8a345",
    "semantic_title": "haf-rm: a hybrid alignment framework for reward model training",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vmcyBaTX4r": {
    "title": "Aligning Translation-Specific Understanding to General Understanding in Large Language Models",
    "volume": "review",
    "abstract": "Large Language models (LLMs) have exhibited remarkable abilities in understanding complex texts, offering a promising path towards human-like translation performance. However, this study reveals the misalignment between the translation-specific understanding and the general understanding inside LLMs. This understanding misalignment leads to LLMs mistakenly or literally translating some complicated concepts that they accurately comprehend in the general scenarios (e.g., QA). To align the translation-specific understanding to the general one, we propose a novel translation process, DUAT (Difficult words Understanding Aligned Translation), explicitly incorporating the general understanding on the complicated content incurring inconsistent understandings to guide the translation. Specifically, DUAT performs cross-lingual interpretation for the difficult-to-translate words and enhances the translation with the generated interpretations. Furthermore, we reframe the external tools to improve DUAT in detecting difficult words and generating helpful interpretations. We conduct experiments on the self-constructed benchmark Challenge-WMT, consisting of samples that are prone to mistranslation. Human evaluation results on high-resource and low-resource language pairs indicate that DUAT significantly facilitates the understanding alignment, which improves the translation quality (up to +3.85 COMET) and reduces translation literalness by -25% ∼ -51%",
    "checked": true,
    "id": "a23a89855e3af2e6cec7fd4a01e12cacdf6c727f",
    "semantic_title": "aligning translation-specific understanding to general understanding in large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qjgx06oQDl": {
    "title": "Achieving >97% on GSM8K: Deeply Understanding the Problems Makes LLMs Better Solvers for Math Word Problems",
    "volume": "review",
    "abstract": "Chain-of-Thought (CoT) prompting has enhanced the performance of Large Language Models (LLMs) across various reasoning tasks. However, CoT still falls short in dealing with complex math word problems, as it usually suffers from three pitfalls: semantic misunderstanding errors, calculation errors and step-missing errors. Prior studies involve addressing the calculation errors and step-missing errors, but neglect the semantic misunderstanding errors, which is the major factor limiting the LLMs' performance. To this end, we propose a simple-yet-effective method, namely Deeply Understanding the Problems (DUP), to improve the LLMs' math problem-solving ability by addressing semantic misunderstanding errors. The core of our method is to encourage the LLMs to deeply understand the problems and extract the key problem-solving information used for better reasoning. Extensive experiments on 10 diverse reasoning benchmarks show that our DUP method consistently outperforms the other counterparts by a large margin. More encouragingly, DUP achieves a new SOTA result on the GSM8K benchmark, with an accuracy of 97.1% under zero-shot setting",
    "checked": false,
    "id": "dd3dd5e7e3a2718336039112a3f734347da5c1f4",
    "semantic_title": "achieving>97% on gsm8k: deeply understanding the problems makes llms better solvers for math word problems",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Z4OYxFi4s7": {
    "title": "A ∧ B ⇔ B ∧ A: Evaluating and Improving Logical Reasoning Ability of Large Language Models",
    "volume": "review",
    "abstract": "We introduce LogicAsker, a novel approach for evaluating and enhancing the logical reasoning capabilities of large language models (LLMs) such as ChatGPT and GPT-4. Despite their prowess in tasks like writing assistance, code generation, and machine translation, assessing LLMs' ability to reason has been challenging. Traditional evaluations often prioritize accuracy on downstream tasks over direct assessments of reasoning processes. LogicAsker addresses this gap by employing a set of atomic reasoning skills grounded in propositional and predicate logic to systematically examine and improve the reasoning prowess of LLMs. Our methodology reveals significant gaps in LLMs' learning of logical rules, with identified reasoning failures ranging from 29% to 90% across different models. Moreover, we leverage these findings to construct targeted demonstration examples and fine-tune data, notably enhancing logical reasoning in models like GPT-4o by up to 5%. To our knowledge, this is the first effort to utilize test case outcomes to effectively refine LLMs' formal reasoning capabilities. We will make our code, data, and results publicly available to facilitate further research and replication of our findings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2KtL13evFm": {
    "title": "Multilingual Fact-Checking using LLMs",
    "volume": "review",
    "abstract": "Due to the recent rise in digital misinformation, there has been great interest shown in using LLMs for fact-checking and claim verification. In this paper, we answer the question: Do LLMs know multilingual facts and can they use this knowledge for effective fact-checking? To this end, we create a benchmark by filtering multilingual claims from the X-fact dataset and evaluating the multilingual fact-checking capabilities of five LLMs across five diverse languages: Spanish, Italian, Portuguese, Turkish, and Tamil on our benchmark. We employ three different prompting techniques: Zero-Shot, English Chain-of-Thought, and Cross-Lingual Prompting, using both greedy and self-consistency decoding. We extensively analyze our results and find that GPT-4o achieves the highest accuracy, but zero-shot prompting with self-consistency was the most effective overall. We also show that techniques like Chain-of-Thought and Cross-Lingual Prompting, which are designed to improve reasoning abilities, do not necessarily improve the fact-checking abilities of LLMs. Interestingly, we find a strong negative correlation between model accuracy and the amount of internet content for a given language. This suggests that LLMs are better at fact-checking from knowledge in low-resource languages. We hope that this study will encourage more work on multilingual fact-checking using LLMs",
    "checked": false,
    "id": "a56cc09fd52b40203c5f38b01b20592f21a48548",
    "semantic_title": "multilingual detection of check-worthy claims using world languages and adapter fusion",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=ZQ8ahykTmc": {
    "title": "Adaptive Prompts for Efficient RLHF",
    "volume": "review",
    "abstract": "The alignment problem, ensuring AI systems adhere to human values, remains a significant challenge despite the collection of increasingly high-quality and expensive datasets. Reinforcement Learning from Human Feedback (RLHF) offers a promising solution, leveraging human judgment during training. However, standard RLHF often relies on static prompts, potentially wasting resources and neglecting areas needing improvement. This work proposes a novel approach for efficient and effective RLHF fine-tuning of large language models (LLMs). We introduce a dynamic prompt generation system that adapts based on the model's intermediate performance. This allows the model to focus on areas requiring the most human guidance, leading to faster and more targeted alignment. We evaluate our method by comparing three models trained with the same resources: a standard RLHF baseline, a Starts-On-Policy (SOP) model with static prompts based on initial performance, and our Always-On-Policy (AOP) model with dynamically generated prompts. Results demonstrate that AOP significantly outperforms all other models showcasing the effectiveness of our approach",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2qr92Iex3u": {
    "title": "DISC: Plug-and-Play Decoding Intervention with Similarity of Characters for Chinese Spelling Check",
    "volume": "review",
    "abstract": "One of the key challenges in Chinese spelling check (CSC) is ensuring that modifications remain faithful to the original intent of the sentence. Confusion sets are commonly used to mitigate this issue; however, it is challenging to construct high-quality confusion sets and integrate them into the model. In this paper, we propose a plug-and-play DISC (Decoding Intervention with Similarity of Characters) module for CSC models to address these challenges. DISC measures phonetic and glyph similarities between characters and incorporates this similarity information in the decoding stage. This method can be easily integrated into various existing CSC models, such as ReaLiSe, SCOPE, and ReLM, without additional training costs. Experiments on three CSC benchmarks demonstrate that our proposed method significantly improves model performance, approaching and even surpassing the current state-of-the-art models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1ex0hyw6R8": {
    "title": "Fine-tuning Large Language Models with Human-inspired Learning Strategies in Medical Question Answering",
    "volume": "review",
    "abstract": "Training Large Language Models (LLMs) incurs substantial data-related costs, motivating the development of data-efficient training methods through optimised data ordering and selection. Human-inspired learning strategies, such as curriculum learning, offer possibilities for efficient training by ordering data according to common human learning practices. Despite evidence that curriculum learning improves performance of natural language understanding tasks in fine-tuning LLMs, its application to domain-specific question-answering remains underexplored. In this work, we comprehensively examine the effectiveness of human-inspired learning strategies for fine-tuning LLMs in medical question answering. Our work complements previous studies by extending the evaluation to non-curriculum-based learning across multiple language models, using both human-defined and automated data labels. Our results show moderate impact in using human-inspired learning strategies for fine-tuning LLMs, with maximum accuracy gains of 1.77\\% per model and 1.81\\% per dataset. However, the effectiveness of these learning strategies varies significantly across different model-dataset combinations, suggesting caution in generalising human-inspired strategies for fine-tuning language models. We also find that curriculum learning using LLM-defined question difficulty outperformed human-defined difficulty, highlighting the potential of using model-generated metrics in optimal curriculum design",
    "checked": true,
    "id": "560631f2889bdebf695d1012e55caf95d421a039",
    "semantic_title": "fine-tuning large language models with human-inspired learning strategies in medical question answering",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dZ0VyV7adK": {
    "title": "LEMoE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models",
    "volume": "review",
    "abstract": "Large language models (LLMs) require continual knowledge updates to stay abreast of the ever-changing world facts, prompting the formulation of lifelong model editing task. While recent years have witnessed the development of various techniques for single and batch editing, these methods either fail to apply or perform sub-optimally when faced with lifelong editing. In this paper, we introduce LEMoE, an advanced Mixture of Experts (MoE) adaptor for lifelong model editing. We first analyze the factors influencing the effectiveness of conventional MoE adaptor in lifelong editing, including catastrophic forgetting, inconsistent routing and order sensitivity. Based on these insights, we propose a tailored module insertion method to achieve lifelong editing, incorporating a novel KV anchor routing to enhance routing consistency between training and inference stage, along with a concise yet effective clustering-based editing order planning. Experimental results demonstrate the effectiveness of our method in lifelong editing, surpassing previous model editing techniques while maintaining outstanding performance in batch editing task. Our code will be available",
    "checked": true,
    "id": "6202c20b152b6b9f379aa1714bbd01594dcc990a",
    "semantic_title": "lemoe: advanced mixture of experts adaptor for lifelong model editing of large language models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=t7onBnDHYW": {
    "title": "The Reason behind Good or Bad: Towards a Better Mathematical Verifier with Natural Language Feedback",
    "volume": "review",
    "abstract": "Mathematical verfier achieves success in mathematical reasoning tasks by validating the correctness of solutions. However, existing verifiers are trained with binary classification labels, which are not informative enough for the model to accurately assess the solutions. To mitigate the aforementioned insufficiency of binary labels, we introduce step-wise natural language feedbacks as rationale labels (i.e., the correctness of the current step and the explanations). In this paper, we propose **Math-Minos**, a natural language feedback enhanced verifier by constructing automatically-generated training data and a two-stage training paradigm for effective training and efficient inference. Our experiments reveal that a small set (30k) of natural language feedbacks can significantly boost the performance of the verifier by the accuracy of 1.6% (86.6% → 88.2%) on GSM8K and 0.8% (37.8% → 38.6%) on MATH",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lPJqEBRQD0": {
    "title": "Sparse Contrastive Learning of Sentence Embeddings",
    "volume": "review",
    "abstract": "Recently, SimCSE, a simple contrastive learning framework for sentence embeddings, has shown the feasibility of contrastive learning in training sentence embeddings and illustrates its expressiveness in spanning an aligned and uniform embedding space. However, prior studies have shown that dense models could contain harmful parameters that affect the model performance. This prompted us to consider whether SimCSE might also have similar harmful parameters. To tackle the problem, parameter sparsification is applied, where alignment and uniformity scores are used to measure the contribution of each parameter to the overall quality of sentence embeddings. Drawing from a preliminary study, we hypothesize that parameters with minimal contributions are detrimental, and sparsifying them would result in an improved model performance. Accordingly, a sparsified SimCSE (SparseCSE) is proposed. To systematically explore the ubiquity of detrimental parameters and the removal of them, extensive experiments are conducted on the standard semantic textual similarity (STS) tasks and transfer learning tasks. The results show that the proposed SparseCSE significantly outperform SimCSE. Furthermore, through an in-depth analysis, we establish the validity and stability of our sparsification method, showcasing that the embedding space generated by SparseCSE exhibits an improved alignment compared to that produced by SimCSE. Importantly, the uniformity remains uncompromised",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LOrTiRUy2a": {
    "title": "AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging",
    "volume": "review",
    "abstract": "As an effective alternative to the direct fine-tuning on target tasks in specific languages, cross-lingual transfer addresses the challenges of limited training data by decoupling \"task ability\" and \"language ability\", achieved by fine-tuning on the target task in the source language and another selected task in the target language, respectively. However, they fail to fully separate the task ability from the source language or the language ability from the chosen task. In this paper, we acknowledge the mutual reliance between task ability and language ability and direct our attention toward the gap between the target language and the source language on tasks. As the gap removes the impact of tasks, we assume that it remains consistent across tasks. Based on this assumption, we propose a new cross-lingual transfer method called $\\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a reference task, we can determine that the divergence of adapters fine-tuned on the reference task in both languages follows the same distribution as the divergence of adapters fine-tuned on the target task in both languages. Hence, we can obtain target adapters by combining the other three adapters. Furthermore, we propose a structure-adaptive adapter merging method. Our empirical results demonstrate that our approach yields new and effective cross-lingual transfer, outperforming existing methods across all settings",
    "checked": true,
    "id": "bba9778411de8940585fc730a2836d45e2292875",
    "semantic_title": "adamergex: cross-lingual transfer with large language models via adaptive adapter merging",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=2U97bAEame": {
    "title": "Religious Bias Landscape in Language and Text-to-Image Models: Analysis, Detection, and Debiasing Strategies",
    "volume": "review",
    "abstract": "The increasing utilization of language models necessitates critical examinations of their inherent biases, particularly concerning religion. This study thoroughly examines religious bias across a wide range of language models, encompassing pre-trained models like BERT, RoBERTa, ALBERT, and DistilBERT, alongside diverse open-source large language models such as GPT-2, Llama-3, Mixtral-8x7B, Vicuna-13B, and closed-source models including GPT-3.5 and GPT-4, along with DALL·E 3 for image generation. Using diverse methodologies like mask filling, prompt completion, and image generation, we assess each model's handling of content related to different religions to uncover any underlying biases. We also investigate cross-domain bias concerning gender, age, and nationality within the context of religious content. Furthermore, this paper explores the effectiveness of targeted debiasing techniques, employing corrective prompts to mitigate identified biases. Our findings indicate that language models continue to exhibit biases in both text and image generation. However, the use of debiasing prompts has proven effective in mitigating these biases",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0YJERBwdYc": {
    "title": "KGLens: Towards Efficient and Effective Knowledge Probing of Large Language Models with Knowledge Graphs",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) might hallucinate facts, while curated Knowledge Graph (KGs) are typically factually reliable especially with domain-specific knowledge. Measuring the alignment between KGs and LLMs can effectively probe the factualness and identify the knowledge blind spots of LLMs. However, verifying the LLMs over extensive KGs can be expensive. In this paper, we present KGLens, a Thompson-sampling-inspired framework aimed at effectively and efficiently measuring the alignment between KGs and LLMs. KGLens features a graph-guided question generator for converting KGs into natural language, along with a carefully designed importance sampling strategy based on parameterized KG structure to expedite KG traversal. Our simulation experiment compares the brute force method with KGLens under six different sampling methods, demonstrating that our approach achieves superior probing efficiency. Leveraging KGLens, we conducted in-depth analyses of the factual accuracy of ten LLMs across three large domain-specific KGs from Wikidata, composing over 19K edges, 700 relations, and 21K entities. Human evaluation results indicate that KGLens can assess LLMs with a level of accuracy nearly equivalent to that of human annotators, achieving 95.7% of the accuracy rate",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=elE5RA9TDB": {
    "title": "Thread: A Logic-Based Data Organization Paradigm for How-To Question Answering with Retrieval Augmented Generation",
    "volume": "review",
    "abstract": "Current question answering systems leveraging retrieval augmented generation perform well in answering factoid questions but face challenges with non-factoid questions, particularly how-to queries requiring detailed step-by-step instructions and explanations. In this paper, we introduce Thread, a novel data organization paradigm that transforms documents into logic units based on their inter-connectivity. Extensive experiments across open-domain and industrial scenarios demonstrate that Thread outperforms existing data organization paradigms in RAG-based QA systems, significantly improving the handling of how-to questions",
    "checked": true,
    "id": "35adc58a2d9d3affa1a8d211bd1536d129658a35",
    "semantic_title": "thread: a logic-based data organization paradigm for how-to question answering with retrieval augmented generation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GtbhHl56Ht": {
    "title": "From Semantic Alignment to LLM Hallucination Origins: An Algorithmic Approach",
    "volume": "review",
    "abstract": "We introduce a new text alignment algorithm that can produce fine-grained alignment between a query document and database documents. Our work explores two under-explored directions: i) alignment granularity at text segment level as opposed to traditional entire document retrieval, and ii) alignment directed by semantic similarity instead of exact matches. We utilize text embeddings produced by Large Language Models (LLM) and perform efficient queries through nearest neighbor data structures. We also introduce an attack strategy exploiting temporal inconsistencies to induce hallucinations in Large Language Models (LLMs) and apply our alignment algorithm to trace these hallucinations back to their possible origins in training data. By creating a database of relevant web documents using keyword filtering on Common Crawl data, our approach demonstrates the effectiveness of identifying candidate origins of LLM hallucinations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w1jGpGzcyQ": {
    "title": "Lifelong Event Detection via Optimal Transport",
    "volume": "review",
    "abstract": "Continual Event Detection (CED) poses a formidable challenge due to the catastrophic forgetting phenomenon, where learning new tasks (with new coming event types) hampers performance on previous ones. In this paper, we introduce a novel approach, Lifelong Event Detection via Optimal Transport (**LEDOT**), that leverages optimal transport principles to align the optimization of our classification module with the intrinsic nature of each class, as defined by their pre-trained language modeling. Our method integrates replay sets, prototype latent representations, and an innovative Optimal Transport component. Extensive experiments on MAVEN and ACE datasets demonstrate LEDOT's superior performance, consistently outperforming state-of-the-art baselines. The results underscore LEDOT as a pioneering solution in continual event detection, offering a more effective and nuanced approach to addressing catastrophic forgetting in evolving environments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dDCdV3VcrY": {
    "title": "Pamba: Transplanting Transformer Blocks with Mamba",
    "volume": "review",
    "abstract": "To combine the Transformer's long-context copying and retrieval capabilities and Mamba's low-memory requirement, we introduce Pamba-1.1B, a hybrid architecture by replacing top Pythia-1.4B Transformer blocks with trained-from-scratch Mamba-1.4B blocks and healing the model through a two-stage fine-tuning process. Pamba-1.1B demonstrates enhanced language modeling abilities and 30\\% memory savings compared to the baseline Transformer model (Pythia-1.4B), as well as superior long-context copying capabilities compared to Mamba-1.4B. Furthermore, compared to other hybrid models like RecurrentGemma-2B (Griffin), Pamba-1.1B excels in specific long-context copying tasks, while also being more memory-efficient. Our code is available at: https://anonymous.4open.science/r/Transformer_Mamba_Transplantation-3C51/",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U6h4JPvX9M": {
    "title": "Exploring Synthetic Data Generation Techniques for Employment Type Classification in Job Advertisements",
    "volume": "review",
    "abstract": "The classification of employment types in online job advertisements (OJAs) is crucial for labor market analysis and recruitment. This study addresses the limitations of manual data annotation by leveraging synthetic data generation (SDG) techniques using large language models (LLMs). We evaluate four SDG methods—plain prompting, sampling, precise attributes, and adjective attributes—to generate synthetic job ads and assess their impact on classification model performance. Our analysis focuses on the balance between dataset size, data diversity and label-fit, and we explore the use of Natural Language Inference (NLI) filtering to enhance data quality. Results show that models trained on synthetic data can effectively classify real-world job ads, achieving competitive performance. However, we observed significant volatility in outcomes, which we could not fully explain. By making our code and data publicly available, we provide the research community with opportunities to further investigate SDG techniques. By publishing our best models, we offer researchers tools capable of achieving up to 96% F1 on a real-world dataset for classifying German OJAs by employment type",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=klIxQ7VWBl": {
    "title": "Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales",
    "volume": "review",
    "abstract": "Human-like personality traits have recently been discovered in large language models, raising the hypothesis that their (known and as yet undiscovered) biases conform with human latent psychological constructs. While large conversational models may be tricked into answering psychometric questionnaires, the latent psychological constructs of thousands of simpler transformers, trained for other tasks, cannot be assessed because appropriate psychometric methods are currently lacking. Here, we show how standard psychological questionnaires can be reformulated into natural language inference prompts, and we provide a code library to support the psychometric assessment of arbitrary models. We demonstrate, using a sample of 88 publicly available models, the existence of human-like mental health-related constructs—including anxiety, depression, and the sense of coherence—which conform with standard theories in human psychology and show similar correlations and mitigation strategies. The ability to interpret and rectify the performance of language models by using psychological tools can boost the development of more explainable, controllable, and trustworthy models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xXu4txKpBI": {
    "title": "Integrating Plutchik's Theory with Mixture of Experts for Enhancing Emotion Classification",
    "volume": "review",
    "abstract": "Emotion significantly influences human behavior and decision-making processes. We propose a labeling methodology grounded in Plutchik's Wheel of Emotions theory for emotion classification. Furthermore, we employ a Mixture of Experts (MoE) architecture to evaluate the efficacy of this labeling approach, by identifying the specific emotions that each expert learns to classify. Experimental results reveal that our methodology improves the performance of emotion classification",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xgOmjXHPA7": {
    "title": "RoundTripOCR: A Data Generation Technique for Enhancing OCR Error Correction in Low-Resource Devanagari Languages",
    "volume": "review",
    "abstract": "Optical Character Recognition (OCR) technology has revolutionized the digitization of printed text, enabling efficient data extraction and analysis across various domains. Just like Machine Translation systems, OCR systems are prone to errors stemming from factors such as poor image quality, diverse fonts, and language variations. In this work, we address the challenge of data generation and post-OCR error correction, specifically for low-resource languages. We propose a novel approach for synthetic data generation for Devanagari languages, RoundTripOCR, that tackles the scarcity of the OCR Error Correction dataset. In this work, we release a post-OCR text correction dataset for Hindi, Marathi, Bodo, Nepali, Konkani and Sanskrit. We also present a novel approach for OCR error correction by leveraging techniques from machine translation. Our method involves translating the erroneous OCR output into a corrected form by treating the OCR errors as mistranslations in a parallel text corpus. We employ a state-of-the-art pre-trained transformer model, mBART, to learn the mapping from erroneous to correct text pairs, effectively correcting OCR errors",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fwIEViaMuW": {
    "title": "Mitigating the Language Mismatch and Repetition Issues in LLM-based Machine Translation via Model Editing",
    "volume": "review",
    "abstract": "Large Language Models have recently revolutionized the NLP field, while they still fall short in some specific down-stream tasks. In the work, we focus on utilizing LLMs to perform machine translation, where we observe that two patterns of errors frequently occur and drastically affect the translation quality: language mismatch and repetition. The work sets out to explore the potential for mitigating these two issues by leveraging model editing methods, e.g., by locating FFN neurons or something that are responsible for the errors and deactivating them in the inference time. We find that directly applying such methods either limited effect on the targeted errors or has significant negative side-effect on the general translation quality, indicating that the located components may also be crucial for ensuring machine translation with LLMs on the rails. To this end, we propose to refine the located components by fetching the intersection of the locating results under different language settings, filtering out the aforementioned information that is irrelevant to targeted errors. The experiment results empirically demonstrate that our methods can effectively reduce the language mismatch and repetition ratios and meanwhile enhance or keep the general translation quality in most cases",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uabufUkyQl": {
    "title": "HalluAttack: Mitigating Hallucinations in LLMs via Counterfactual Instruction Fine Tuning",
    "volume": "review",
    "abstract": "LLMs encapsulate a vast range of world knowledge with huge mount of pretraining data. While these models have demonstrated remarkable capabilities in various applications, they are prone to generating content infused with hallucinations, compromising the trustworthiness of their output. This phenomenon raises concerns of LLM applications, particularly when the dissemination of misleading information can have detrimental impacts. In this paper, we propose a simple yet effective method called \\textsc{HalluAttack} which generates high quality counterfactual instruction data in order to reduce the hallucinations. We observe that these counterfactual instruction data can unlock the self-reflection ability of LLMs, and the LLMs will use knowledge learnt from pretraining phase more accurately. We conducted experiments across multiple open-source LLMs to evaluate the effectiveness of our proposed approach\\footnote{The data we used for fine-tuning is publicly available in \\url{https://github.com/oldstree/halluattack}}. Results consistently demonstrate that, through counterfactual attack and subsequent fine-tuning, we are able to significantly improve the model performance on hallucination benchmarks (e.g. TruthfulQA and HalluQA). Moreover, we also find that the LLMs fine-tuned with counterfactual instruction data can also achieve gains on public general benchmarks like C-Eval, MMLU and GSM8K, which also demonstrate the effectiveness of our approach on hallucination mitigation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=erqoeO6lFu": {
    "title": "Take the essence and discard the dross: A Rethinking on Data Selection for Fine-Tuning Large Language Models",
    "volume": "review",
    "abstract": "Data selection for fine-tuning Large Language Models (LLMs) aims to select a high-quality subset from a given candidate dataset to train a Pending Fine-tune Model (PFM) into a Selective-Enhanced Model (SEM). It can improve the model performance and accelerate the training process. Although a few surveys have investigated related works of data selection, there is a lack of comprehensive comparison between existing methods due to their various experimental settings. To address this issue, we first propose a three-stage scheme for data selection and comprehensively review existing works according to this scheme. Then, we design a unified comparing method with ratio-based efficiency indicators and ranking-based feasibility indicators to overcome the difficulty of comparing various models with diverse experimental settings. After an in-depth comparative analysis, we find that the more targeted method with data-specific and model-specific quality labels has higher efficiency, but the introduction of additional noise information should be avoided when designing selection algorithms. Finally, we summarize the trends in data selection and highlight the short-term and long-term challenges to guide future research",
    "checked": true,
    "id": "2a88c2b6a7d838f5635e707070440353b8980b33",
    "semantic_title": "take the essence and discard the dross: a rethinking on data selection for fine-tuning large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=12fPx9tG61": {
    "title": "Towards Faithful Knowledge Graph Explanation Through Deep Alignment in Commonsense Question Answering",
    "volume": "review",
    "abstract": "The fusion of language models (LMs) and knowledge graphs (KGs) is widely used in commonsense question answering, but generating faithful explanations remains challenging. Current methods often overlook path decoding faithfulness, leading to divergence between graph encoder outputs and model predictions. We identify confounding effects and LM-KG misalignment as key factors causing spurious explanations. To address this, we introduce the LM-KG Fidelity metric to assess KG representation reliability and propose the LM-KG Distribution-aware Alignment (LKDA) algorithm to improve explanation faithfulness. Without ground truth, we evaluate KG explanations using the proposed Fidelity-Sparsity Trade-off Curve. Experiments on CommonsenseQA and OpenBookQA show that LKDA significantly enhances explanation fidelity and model performance, highlighting the need to address distributional misalignment for reliable commonsense reasoning",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CABNvm4tQ5": {
    "title": "MEMLLM: Finetuning LLMs to Use Explicit Read-Write Memory",
    "volume": "review",
    "abstract": "While current large language models (LLMs) perform well on many knowledge-related tasks, they are limited by relying on their parameters as an implicit storage mechanism. As a result, they struggle with memorizing rare events and with updating their memory as facts change over time. In addition, the uninterpretable nature of parametric memory makes it challenging to prevent hallucination. Model editing and augmenting LLMs with parameters specialized for memory are only partial solutions. In this paper, we introduce MemLLM, a novel method of enhancing LLMs by integrating a structured and explicit read-and-write memory module. MemLLM tackles the aforementioned challenges by enabling dynamic interaction with the memory and improving the LLM's capabilities in using stored knowledge. Our experiments indicate that MemLLM enhances the LLM's performance and interpretability, in language modeling in general and knowledge-intensive tasks in particular. We see MemLLM as an important step towards making LLMs more grounded and factual through memory augmentation",
    "checked": false,
    "id": "47c8f0d7232f52f1a48e933e32309dc35ad85f49",
    "semantic_title": "memllm: finetuning llms to use an explicit read-write memory",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=BM5O1r4T2r": {
    "title": "Benchmarking Foundation Models on Exceptional Cases: Dataset Creation and Validation",
    "volume": "review",
    "abstract": "Foundation models (FMs) have achieved significant success across various tasks, leading to research on benchmarks for commonsense and reasoning abilities. However, there is a lack of studies on FMs performance in exceptional scenarios. This paper addresses these cases for the first time, developing a novel dataset for comprehensive FMs evaluation across multiple modalities, including graphic novels, calligraphy, news articles, and lyrics. It includes tasks for instance classification, character recognition, token prediction, and text generation. The paper also proposes prompt engineering techniques like Chain-of-Thought (CoT) and CoT+Few-Shot to enhance performance. Validation of FMs using various methods revealed improvements. The code repository is accessible at: https://anonymous.4open.science/r/Exceptional-Dataset-for-FMs/README.md",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=np6hrTv7aW": {
    "title": "Induction Heads as a Primary Mechanism for Pattern Matching in In-context Learning",
    "volume": "review",
    "abstract": "Large language models (LLMs) have shown a remarkable ability to learn and perform complex tasks through in-context learning (ICL). However, a comprehensive understanding of its internal mechanisms is still lacking. This paper explores the role of induction heads in a few-shot ICL setting. We analyse two state-of-the-art models, Llama-3-8B and InternLM2-20B on abstract pattern recognition and NLP tasks. Our results show that even a minimal ablation of induction heads leads to ICL performance decreases of up to ~32\\% for abstract pattern recognition tasks, bringing the performance close to random. For NLP tasks, this ablation substantially decreases the model's ability to benefit from examples, bringing few-shot ICL performance close to that of zero-shot prompts. We further use attention knockout to disable specific induction patterns, and present fine-grained evidence for the role that induction mechanism plays in ICL",
    "checked": false,
    "id": "6d84377d5765229d621c4b2a209e44479ef33516",
    "semantic_title": "induction heads as an essential mechanism for pattern matching in in-context learning",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=FHmsbqAiH0": {
    "title": "Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors",
    "volume": "review",
    "abstract": "Multiple-choice visual question answering (VQA) is to automatically choose a correct answer from a set of choices after reading an image. Existing efforts have been devoted to a separate generation of an image-related question, a correct answer, or challenge distractors. By contrast, we turn to a holistic generation and optimization of questions, answers, and distractors (QADs) in this study. This integrated generation strategy eliminates the need for human curation and guarantees information consistency. Furthermore, we first propose to put the spotlight on different image regions to diversify QADs. Accordingly, a novel framework ReBo is formulated in this paper. ReBo cyclically generates each QAD based on a recurrent multimodal encoder, and each generation is focusing on a different area of the image compared to those already concerned by the previously generated QADs. In addition to traditional VQA comparisons with state-of-the-art approaches, we also validate the capability of ReBo in generating augmented data to benefit VQA models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l6y6Ei4TjA": {
    "title": "Temporal Knowledge Graph Question Answering: A Survey",
    "volume": "review",
    "abstract": "Knowledge Base Question Answering (KBQA) has been a long-standing field to answer questions based on knowledge bases. Recently, the evolving dynamics of knowledge have attracted a growing interest in Temporal Knowledge Graph Question Answering (TKGQA), an emerging task to answer temporal questions. However, this field grapples with ambiguities in defining temporal questions and lacks a systematic categorization of existing methods for TKGQA. In response, this paper provides a thorough survey from two perspectives: the taxonomy of temporal questions and the methodological categorization for TKGQA. Specifically, we first establish a detailed taxonomy of temporal questions engaged in prior studies. Subsequently, we provide a comprehensive review of TKGQA techniques of two categories: semantic parsing-based and TKG embedding-based. Building on this review, the paper outlines potential research directions aimed at advancing the field of TKGQA. This work aims to serve as a comprehensive reference for TKGQA and to stimulate further research",
    "checked": true,
    "id": "2b55fc06077910c9f83137513764248388aac051",
    "semantic_title": "temporal knowledge graph question answering: a survey",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OhozicmObs": {
    "title": "Unlocking the Global Synergies in Low-Rank Adapters",
    "volume": "review",
    "abstract": "Low-rank adaption (LoRA) has been the de-facto parameter-efficient fine-tuning technique for large language models. We present HeteroLoRA, a light-weight search algorithm that leverages zero-cost proxies to allocate the limited LoRA trainable parameters across the model for better fine-tuned performance. In addition to the allocation for the standard LoRA-adapted models, we also demonstrate the efficacy of HeteroLoRA by performing the allocation in a more challenging search space that includes LoRA modules and LoRA-adapted shortcut connections. Experiments show that HeteroLoRA enables improvements in model performance given the same parameter budge. For example, on RTE, we see an improvement of 6.7% in accuracy with a similar training parameter budget compared to a variety of state-of-the-art methods. We will open-source our algorithm once the paper is accepted",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EmzhaCoNIv": {
    "title": "Adversarial Winograd Schema Challenge",
    "volume": "review",
    "abstract": "While Large Language Models (LLMs) have showcased remarkable proficiency in reasoning, there is still a concern about hallucinations and unreliable reasoning issues due to semantic associations and superficial logical chains. To evaluate the extent to which LLMs perform robust reasoning instead of relying on superficial logical chains, we propose a new evaluation dataset, the Adversarial Winograd Schema Challenge (AWSC), based on the famous Winograd Schema Challenge (WSC) dataset. By simply replacing the entities with those that are more associated with the wrong answer, we find that the performance of LLMs drops significantly despite the rationale of reasoning remaining the same. Furthermore, we propose Abstraction-of-Thought (AoT), a novel prompt method for recovering adversarial cases to normal cases to improve LLMs' robustness and consistency in reasoning, as demonstrated by experiments on AWSC",
    "checked": false,
    "id": "b4355875a250258eddea5e7abc979f23e8209a4a",
    "semantic_title": "who killed the winograd schema challenge?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4HOMjp5q6M": {
    "title": "FASST: Fast LLM-based Simultaneous Speech Translation",
    "volume": "review",
    "abstract": "Simultaneous speech translation (SST) takes streaming speech input and generates text translation on the fly. Existing methods either have high latency due to recomputation of input representations, or fall behind of offline ST in translation quality. In this paper, we propose FASST, a fast large language model based method for streaming speech translation. We propose blockwise-causal speech encoding and consistency mask, so that streaming speech input can be encoded incrementally without recomputation. Furthermore, we develop a two-stage training strategy to optimize FASST for simultaneous inference. We evaluate FASST and multiple strong prior models on MuST-C dataset. Experiment results show that FASST achieves the best quality-latency tradeoff. It outperforms the previous best model by an average of 1.5 BLEU under the same latency for English to Spanish translation",
    "checked": true,
    "id": "39cb370560705ae11184a10c28e9a0fb787b470f",
    "semantic_title": "fasst: fast llm-based simultaneous speech translation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=obohYdeCYf": {
    "title": "ExpertEase: A Multi-Agent Framework for Grade-Specific Document Simplification with Large Language Models",
    "volume": "review",
    "abstract": "Text simplification is crucial for making texts more accessible, yet current research primarily focuses on sentence-level simplification, neglecting document-level simplification and the different reading levels of target audiences. To bridge these gaps, we introduce ExpertEase, a multi-agent framework for grade-specific document simplification using Large Language Models (LLMs). ExpertEase simulates real-world text simplification by introducing expert, teacher, and student agents that cooperate on the task and rely on external tools for calibration. Experiments demonstrate that this multi-agent approach significantly enhances LLMs' ability to simplify reading materials for diverse audiences. Furthermore, we evaluate the performance of LLMs varying in size and type, and compare LLM-generated texts with human-authored ones, highlighting their potential in educational resource development and guiding future research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FAILS1a5pf": {
    "title": "GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning",
    "volume": "review",
    "abstract": "We introduce GrammaMT, a grammatically-aware prompting approach for machine translation that uses Interlinear Glossed Text (IGT), a common form of linguistic annotation describing lexical and functional morphemes of source sentences. GrammaMT proposes two prompting strategies: gloss-shot and chain-gloss. Both are training-free, require only a few examples, and involve minimal effort to collect, making them well-suited for low-resource setups. Experiments and ablation studies on open-source instruction-tuned LLMs, across three different benchmarks, demonstrate the benefits of leveraging interlinear gloss resources for machine translation. GrammaMT improves the translation performance for various low-resource to high-resource languages in the largest existing corpus of IGT data, on the challenging 2023 SIGMORPHON Shared Task data across rarely-seen, endangered languages, and even in an out-of-domain setting within FLORES",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=39KtrP3axP": {
    "title": "CrAM: Credibility-Aware Attention Modification in LLMs for Combating Misinformation in RAG",
    "volume": "review",
    "abstract": "Retrieval-Augmented Generation (RAG) can alleviate hallucinations of Large Language Models (LLMs) by referencing external documents. However, the misinformation in external documents may mislead LLMs' generation. To address this issue, we explore the task of \"credibility-aware RAG\", in which LLMs automatically adjust the influence of retrieved documents based on their credibility scores to counteract misinformation. To this end, we introduce a plug-and-play method named $\\textbf{Cr}$edibility-aware $\\textbf{A}$ttention $\\textbf{M}$odification (CrAM). CrAM identifies influential attention heads in LLMs and adjusts their attention scores based on the credibility of the documents, thereby reducing the impact of low-credibility documents. Experiments on Natual Questions and TriviaQA using Llama2-13B, Llama3-8B, and Qwen-7B show that CrAM improves the RAG performance of LLMs against misinformation pollution by over 20%, even surpassing supervised fine-tuning methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gHRYAU6Wrd": {
    "title": "FinLlama: LLM-Based Financial Sentiment Analysis for Algorithmic Trading",
    "volume": "review",
    "abstract": "Online sources of financial news have a profound influence on both market movements and trading decisions. Standard sentiment analysis employs a lexicon-based approach to aid financial decisions, but struggles with context sensitivity and word ordering. On the other hand, Large Language Models (LLMs) are powerful, but are not finance-specific and require significant computational resources. To this end, we introduce a finance specific LLM framework, based on the Llama 2 7B foundational model, in order to benefit from its generative nature and comprehensive language manipulation. Such a generator-discriminator scheme, referred to as FinLlama, both classifies sentiment valence and quantifies its strength, offering a nuanced insight into financial news. The FinLlama model is fine-tuned on supervised financial sentiment analysis data, to make it handle the complexities of financial lexicon and context, and is equipped with a neural network-based decision mechanism. The subsequent parameter-efficient fine-tuning optimises trainable parameters, thus minimising computational and memory requirements without sacrificing accuracy. Simulation results demonstrate the ability of FinLlama to increase market returns in portfolio management scenarios, yielding high-return and resilient portfolios, even during volatile periods",
    "checked": false,
    "id": "15b0a6ccb198b2936e36266be992da78a29953fd",
    "semantic_title": "finllama: financial sentiment classification for algorithmic trading applications",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=6qioVR5ecT": {
    "title": "Multi-property Steering of Large Language Models with Dynamic Activation Composition",
    "volume": "review",
    "abstract": "Activation steering methods were shown to be effective in conditioning language model generation by additively intervening over models' intermediate representations. However, the evaluation of these techniques has so far been limited to single conditioning properties and synthetic settings. In this work, we conduct a comprehensive evaluation of various activation steering strategies, highlighting the property-dependent nature of optimal parameters to ensure a robust effect throughout generation. To address this issue, we propose Dynamic Activation Composition, an information-theoretic approach to modulate the steering intensity of one or more properties throughout generation. Our experiments on multi-property steering show that our method successfully maintains high conditioning while minimizing the impact of conditioning on generation fluency",
    "checked": true,
    "id": "cdab286b5b28f03aa9dda2b818f30f8a32a809d4",
    "semantic_title": "multi-property steering of large language models with dynamic activation composition",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Cg7sGNXwRQ": {
    "title": "Improving LLM Pretraining by Filtering Out Advertisements",
    "volume": "review",
    "abstract": "Data has been recognized as a vital factor for Large Language Models (LLMs), prompting the development of various data selection methods to optimize pretraining data. Among these, the loss-based filtering method has gained popularity due to its straightforwardness. However, our empirical findings suggest that this approach may lead to performance degradation on knowledge-intensive benchmarks, such as the MMLU. To address this issue, we propose filtering out low-information text, particularly advertisements, which constitute a significant portion of internet content. We employed a 100M parameter proxy model to compare these two methods. Despite its smaller size, the proxy model's results accurately predict the downstream metrics when scaled to 3B models. This study demonstrates that a 100M parameter proxy model is sufficient for comparing different data selection strategies, and our experiments across various benchmarks confirm the effectiveness of eliminating advertisements from pretraining data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g9MgAxi6ix": {
    "title": "SiRA: Sparse Mixture of Low Rank Adaptation",
    "volume": "review",
    "abstract": "Parameter Efficient Tuning (PET) techniques such as Low-rank Adaptation~(LoRA) are effective methods to adapt Large Language Models to downstream tasks. We propose Sparse mixture of low Rank Adaption~(SiRA), which uses Sparse Mixture of Experts (SMoE) by enforcing conditional computation with top k LoRA weights. SiRA is optimized through a combination of training techniques, including an auxiliary loss encouraging load balancing, a capacity limit which restricts the maximum number of tokens each expert can process, and novel expert dropout on top of the gating network. Through extensive experiments, we show that SiRA performs better than LoRA and other mixture of expert approaches across different single-task and multiple-task settings. Results show SiRA has more orthogonal low rank spaces and consumes less computing resources compared to other MoE variants",
    "checked": true,
    "id": "525cd5d5c7d823d0b2ad4eaf086622940d45ed6d",
    "semantic_title": "sira: sparse mixture of low rank adaptation",
    "citation_count": 17,
    "authors": []
  },
  "https://openreview.net/forum?id=QoSLasuLAa": {
    "title": "COMPACT: Compressing Retrieved Documents Actively for Question Answering",
    "volume": "review",
    "abstract": "Retrieval-augmented generation supports language models to strengthen their factual groundings by providing external context. However, language models often face challenges in locating and integrating extensive information, diminishing their effectiveness in solving complex questions. Query-focused compression tackles this issue by filtering out information irrelevant to the query, but current methods still struggle in realistic scenarios where crucial information may not be located with a single-step approach. To overcome this limitation, we introduce COMPACT, a novel framework that employs an active strategy to condense extensive documents without losing key information. COMPACT flexibly operates as a cost-efficient plug-in module with any off-the-shelf retriever or reader model, achieving extremely high compression rates (44x). Our experiments demonstrate that COMPACT brings significant improvements in both compression rate and QA performance on multi-hop question-answering datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OG8oRwEREg": {
    "title": "FinanceGPT-B: A Large Language Model with Multi-Stage Structure for Financial Breakout Detection",
    "volume": "review",
    "abstract": "Trading range breakout is a key method in the technical analysis of financial trading, widely employed by traders in financial markets such as stocks, futures, and foreign exchange. However, distinguishing between true and false breakout and providing the correct rationale cause significant challenges to investors. Traditional quantitative methods require large amounts of data and cannot directly present the reasoning process to users, making them less than perfect in this field. Recently, large language models have achieved success in various downstream applications, but their effectiveness in the domain of financial breakout detection has been subpar. The reason is that the unique data and specific knowledge are required in breakout detection. To address these issues, we created the first financial breakout dataset and introduce FinanceGPT-B, the premier large language model for financial breakout detection. Furthermore, we have developed a novel framework for large language models, namely multi-stage structure, effectively reducing mistakes in downstream applications. Experimental results indicate that compared to GPT-3.5, FinanceGPT-B improves the average accuracy of answers and rational by 49.97\\%, with the multi-stage structure contributing 9.72\\% to the improvement. Additionally, it outperforms ChatGPT-4 by 37.30\\%",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YEPygp6YTS": {
    "title": "A Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models",
    "volume": "review",
    "abstract": "Due to the continuous emergence of new data, version updates have become an indispensable requirement for Large Language Models (LLMs). The training paradigms for version updates of LLMs include pre-training from scratch (PTFS) and continual pre-training (CPT). Preliminary experiments demonstrate that PTFS exhibits better pre-training performance, while the training cost of CPT is lower. Moreover, their performance and training cost gaps gradually widen with the version updates processing. To investigate the underlying reasons for this phenomenon, we analyze the effect of learning rate adjustments during the two stages of CPT: preparing an initialization checkpoint and conducting pre-training based on this checkpoint. We find that a large learning rate in the first stage and a complete learning rate decaying process in the second stage are crucial for version updates of LLMs. Hence, we propose a learning rate path switching training paradigm. Our paradigm comprises one main path, where we pre-train a LLM with the maximal learning rate, and multiple branching paths, each of which corresponds to an update of the LLM with newly-added training data. Compared with PTFS, when training four versions of LLMs, our paradigm can reduce the total training cost to 58% while maintaining comparable pre-training performance. In addition, we also validate the generalization of our paradigm, further proving its practicability",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ex4LKiSAKc": {
    "title": "Ground Every Sentence: Improving Retrieval-Augmented LLMs with Interleaved Reference-Claim Generation",
    "volume": "review",
    "abstract": "Retrieval-Augmented Generation (RAG) has been widely adopted to enhance Large Language Models (LLMs) in knowledge-intensive tasks. Recently, Attributed Text Generation (ATG) has attracted growing attention, which provides citations to support the model's responses in RAG, so as to enhance the credibility of LLM-generated content and facilitate verification. Prior methods mainly adopt coarse-grained attributions, linking to passage-level references or providing paragraph-level citations. However, these methods still fall short in verifiability and require certain time costs for fact checking. This paper proposes a fine-grained ATG method called ReClaim (Refer & Claim), which alternates the generation of references and answers step by step. Unlike traditional coarse-grained attribution, ReClaim allows the model to add sentence-level fine-grained citations to each answer sentence in long-form question-answering tasks. Our experiments encompass various training and inference methods and multiple LLMs, verifying the effectiveness of our approach",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XwJFHV5C8l": {
    "title": "Continual Learning for Large Language Models: A Survey",
    "volume": "review",
    "abstract": "Large language models (LLMs) are not amenable to frequent re-training, due to high training costs arising from their massive scale. However, updates are necessary to endow LLMs with new skills and keep them up-to-date with rapidly evolving human knowledge. This paper surveys recent works on continual learning for LLMs. Due to the unique nature of LLMs, we catalog continue learning techniques in a novel multi-staged categorization scheme, involving continual pretraining, instruction tuning, and alignment. We contrast continual learning for LLMs with simpler adaptation methods used in smaller models, as well as with other enhancement strategies like retrieval-augmented generation and model editing. Moreover, informed by a discussion of benchmarks and evaluation, we identify several challenges and future work directions for this crucial task",
    "checked": true,
    "id": "bd0cd89337cc40d39d3a4cbe9c8709e06e877f3e",
    "semantic_title": "continual learning for large language models: a survey",
    "citation_count": 41,
    "authors": []
  },
  "https://openreview.net/forum?id=K7hZCc3d95": {
    "title": "On the Reliability of Psychological Scales on Large Language Models",
    "volume": "review",
    "abstract": "Recent research has extended beyond assessing the performance of Large Language Models (LLMs) to examining their characteristics from a psychological standpoint, acknowledging the necessity of understanding their behavioral characteristics. The administration of personality tests to LLMs has emerged as a noteworthy area in this context. However, the suitability of employing psychological scales, initially devised for humans, on LLMs is a matter of ongoing debate. Our study aims to determine the reliability of applying personality assessments to LLMs, explicitly investigating whether LLMs demonstrate consistent personality traits. Analyzing responses under 2,500 settings reveals that various LLMs show consistency in responses to the Big Five Inventory, indicating a high degree of reliability. Furthermore, our research explores the potential of gpt-3.5-turbo to emulate diverse personalities and represent various groups—a capability increasingly sought after in social sciences for substituting human participants with LLMs to reduce costs. Our findings reveal that LLMs have the potential to represent different personalities with specific prompt instructions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ahh5eXkKKc": {
    "title": "To Know or Not To Know? Analyzing Self-Consistency of Large Language Models under Ambiguity",
    "volume": "review",
    "abstract": "One of the major aspects contributing to the striking performance of large language models (LLMs) is the vast amount of factual knowledge accumulated during pre-training. Yet, many LLMs suffer from self-inconsistency, which raises doubts about their trustworthiness and reliability. In this paper, we focus on entity type ambiguity and analyze current state-of-the-art LLMs for their proficiency and consistency in applying their factual knowledge when prompted for entities under ambiguity. To do so, we propose an evaluation protocol that disentangles knowing from applying knowledge and test state-of-the-art LLMs on 49 entities. Our experiments reveal that LLMs perform poorly with ambiguous prompts, achieving only 80% accuracy. Our results further demonstrate systematic discrepancies in LLM behavior and their failure to consistently apply information, indicating that the models can exhibit knowledge without being able to utilize it, significant biases for preferred readings, as well as self-inconsistencies. Our study highlights the importance of handling entity ambiguity in future for more trustworthy LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K0ajSlez2E": {
    "title": "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection",
    "volume": "review",
    "abstract": "Despite the remarkable ability of large language models (LLMs) in language comprehension and generation, they often suffer from producing factually incorrect information, also known as hallucination. A promising solution to this issue is verifiable text generation, which prompts LLMs to generate content with citations for accuracy verification. However, verifiable text generation is non-trivial due to the focus-shifting phenomenon, the intricate reasoning needed to align the claim with correct citations, and the dilemma between the precision and breadth of retrieved documents. In this paper, we present VTG, an innovative framework for Verifiable Text Generation with evolving memory and self-reflection. VTG introduces evolving long short-term memory to retain both valuable documents and recent documents. A two-tier verifier equipped with an evidence finder is proposed to rethink and reflect on the relationship between the claim and citations. Furthermore, active retrieval and diverse query generation are utilized to enhance both the precision and breadth of the retrieved documents. We conduct extensive experiments on five datasets across three knowledge-intensive tasks and the results reveal that VTG significantly outperforms baselines",
    "checked": true,
    "id": "69e2aa1723b46e4df0445e8ecb838636b0911cd7",
    "semantic_title": "towards verifiable text generation with evolving memory and self-reflection",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=QyEBiBFC7C": {
    "title": "Beyond English: Examining the Impact of Prompt Translation Strategies in Multilingual Natural Language Tasks",
    "volume": "review",
    "abstract": "Despite advances in the multilingual capabilities of Large Language Models (LLMs) across diverse Natural Language Processing (NLP) tasks, English remains the dominant language for LLM research and development. This has led to the widespread practice of pre-translation, i.e., translating the task prompt into English before inference. Selective pre-translation, a more surgical approach, focuses on translating specific prompt components. However, its current use lacks a systematic research foundation. Consequently, the optimal pre-translation strategy for various multilingual settings and tasks remains unclear. In this work, we aim to uncover the optimal setup for pre-translation by systematically assessing its modes of use. Specifically, we view the prompt as a modular entity, composed of four functional parts: instruction, context, examples (zero-shot / few-shot), and output, either of which could be translated or not. We evaluate pre-translation strategies across 35 languages covering both low and high-resource languages, and assessing various capabilities including Question Answering (QA), Natural Language Inference (NLI), Named Entity Recognition (NER), and Abstractive Summarization. Our experiments uncover the impact of factors as translation quality, similarity to English, and the size of pre-trained data, on the model performance with pre-translation. Finally, we suggest practical guidelines for choosing the optimal strategy in various multilingual scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JMzb5fRm2k": {
    "title": "PreAlign: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment",
    "volume": "review",
    "abstract": "Large language models demonstrate reasonable multilingual abilities, despite predominantly English-centric pretraining. However, the spontaneous multilingual alignment in these models is shown to be weak, leading to unsatisfactory cross-lingual transfer and knowledge sharing. Previous works attempt to address this issue by explicitly injecting multilingual alignment information during or after pretraining. Thus for the early stage in pretraining, the alignment is weak for sharing information or knowledge across languages. In this paper, we propose PreAlign, a framework that establishes multilingual alignment prior to language model pretraining. PreAlign injects multilingual alignment by initializing the model to generate similar representations of aligned words and preserves this alignment using a code-switching strategy during pretraining. Extensive experiments in a synthetic English to English-Clone setting demonstrate that \\method significantly outperforms standard multilingual joint training in language modeling, zero-shot cross-lingual transfer, and cross-lingual knowledge application. Further experiments in real-world scenarios further validate PreAlign's effectiveness across various model sizes",
    "checked": true,
    "id": "a3ca19771db42fa926f61d79eac4958b8a2e2b66",
    "semantic_title": "prealign: boosting cross-lingual transfer by early establishment of multilingual alignment",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SxGFTTQwCm": {
    "title": "Zero-Shot Fact Verification via Natural Logic and Large Language Models",
    "volume": "review",
    "abstract": "The recent development of fact verification systems with natural logic has enhanced their explainability by aligning claims with evidence through set-theoretic operators, providing faithful justifications. Despite these advancements, such systems often rely on a large amount of training data annotated with natural logic. To address this issue, we propose a zero-shot method that utilizes the generalization capabilities of instruction-tuned large language models. To comprehensively assess the zero-shot capabilities of our method and other fact verification systems, we evaluate all models on both artificial and real-world claims, including datasets in Danish and Mandarin Chinese. We compare our method against other fact verification systems in two setups. First, in the zero-shot generalization setup, our approach outperforms other systems that were not specifically trained on natural logic data, achieving an average accuracy improvement of 8.61 points over the best-performing baseline. Second, in the zero-shot transfer setup, we demonstrate that current natural-logic-based systems do not generalize well to other domains. Our method performs better on all datasets with real-world claims compared to systems that were trained on datasets with artificial claims",
    "checked": false,
    "id": "09238228c405323bcb20232f424258a8872f150c",
    "semantic_title": "few-shot image classification by generating natural language rules",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=og2LJuXqmP": {
    "title": "Using Ordinal Labels for Text Augmentation and Simultaneous Contrastive Learning for DownStream Task",
    "volume": "review",
    "abstract": "Leveraging large language models, advancements in text augmentation and embedding models for downstream tasks have shown promise, However yet challenges remain in distinguishing texts with similar meanings. The proposed scheme, incorporating ordered labels to enhance sequence information, employs an integrated technique combining Contrastive and Downstream Learning. The proposed scheme outperforms Full Fine-Tuning methods using only classfication learning in text classification because it effectively uses ordered labels to train the model to distinguish similar texts with greater accuracy. our method boosts data diversity and model accuracy by refining the model's sensitivity to nuances, utilizing strongly hard-negative samples in generated texts to further enhance Contrastive Learning outcomes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eUCxcWsha8": {
    "title": "Tutor-ICL: Guiding Large Language Models for Improved In-Context Learning Performance",
    "volume": "review",
    "abstract": "There has been a growing body of work focusing on the in-context learning (ICL) abilities of large language models (LLMs). However, it is an open question of how effective ICL can be. This paper presents Tutor-ICL, a simple prompting method that guides LLMs through the ICL process, inspired by how effective instructors might engage their students in learning a task. Specifically, we propose presenting exemplar answers in a comparative format rather than the traditional single-answer format. We also show that including the test instance before the exemplars can improve performance, making it easier for LLMs to focus on relevant exemplars. Lastly, we include a summarization step before attempting the test, following a common human practice. Experiments on various classification tasks, conducted across both decoder-only LLMs (Llama 2, 3) and encoder-decoder LLMs (Flan-T5-XL, XXL), show that Tutor-ICL consistently boosts performance, achieving up to a 13.76% increase in accuracy",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Vm0KCWkLHb": {
    "title": "Mitigating Hallucination Caused by Excessive Reliance on LLM within MLLM instead of Images",
    "volume": "review",
    "abstract": "In the domain of multimodal generation and comprehension, multimodal large language models (MLLMs), which integrate visual encoders with large language models, have garnered significant success. However, solely relying on modal connection layers/modules to unify these models can lead to a neglect of image information, resulting in visual hallucinations. This manifests as generated text that is independent of the image content, such as descriptions of objects not present within the image. To mitigate this issue, we introduce a fine-tuning approach: Adversarial Contrast Dual Fine-tuning (ACD for short). This approach leverages the MLLM itself and employs the Fast Gradient Sign Method (FGSM) to generate adversarial image samples. During fine-tuning, both the original and adversarial images are utilized to perform dual contrastive fine-tuning on the MLLM. The experimental results show that our method significantly reduces hallucinations without any external annotations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jL5iBVC1xq": {
    "title": "CharSS: Character-Level Transformer Model for Sanskrit Word Segmentation",
    "volume": "review",
    "abstract": "Subword tokens in Indian languages inherently carry meaning, and isolating them can enhance NLP tasks, making sub-word segmentation a crucial process. Segmenting Sanskrit and other Indian languages into subtokens is not straightforward, as it may include sandhi, which may lead to changes in the word boundaries. We propose a new approach of utilizing a CharSS: Character-level Transformer model for Sanskrit Word Segmentation. We perform experiments on three benchmark datasets to compare the performance of our method against existing methods. On the UoH+SandhiKosh dataset, our method outperforms the current state-of-the-art system by an absolute gain of 6.72 points in split prediction accuracy. On the hackathon dataset our method achieves a gain of 2.27 points over the current SOTA system in terms of perfect match metric. We also propose a use-case of Sanskrit-based segments for a linguistically informed translation of technical terms to lexically similar low-resource Indian languages. In two separate experimental settings for this task, we achieve an average improvement of 8.46 and 6.79 chrF++ scores, respectively",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s90ShMOcYq": {
    "title": "Can Frozen Large Language Models Solve Visual Reasoning?",
    "volume": "review",
    "abstract": "We present ReasonLM, a simple framework which utilizes a pre-trained, frozen large language model (LLM) for visual reasoning tasks, and achieves competitive performance on ACRE and MEWL. We demonstrate for the first time that a frozen LLM serves as a task-agnostic reasoning machine for diverse reasoning tasks that involve object recognition, causal induction, and relation modeling. ReasonLM does not rely on synthesizing symbolic programs or self-supervised visual representation learning. Rather, it learns an object-centric, light-weight visual encoder from scratch. Via its simplified design, we investigate the essential design choices for strong visual reasoning performance. Code and model will be released",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zfAmHkODTf": {
    "title": "NYK-MS: A Well-annotated Multi-modal Metaphor and Sarcasm Understanding Benchmark on Cartoon-Caption Dataset",
    "volume": "review",
    "abstract": "Metaphor and sarcasm are common figurative expressions in people's communication, especially on the Internet or the memes popular among teenagers. We create a new benchmark named NYK-MS (NewYorKer for Metaphor and Sarcasm), which contains 1,583 samples for metaphor understanding tasks and 1,578 samples for sarcasm understanding tasks. These tasks include whether it contains metaphor/sarcasm, which word or object contains metaphor/sarcasm, what does it satirize and why does it contains metaphor/sarcasm, all of the 7 tasks are well-annotated by at least 3 annotators. We annotate the dataset for several rounds to improve the consistency and quality, and use GUI and GPT-4V to raise our efficiency. Based on the benchmark, we conduct plenty of experiments. In the zero-shot experiments, we show that Large Language Models (LLM) and Large Multi-modal Models (LMM) can't do classification task well, and as the scale increases, the performance on other 5 tasks improves. In the experiments on traditional pre-train models, we show the enhancement with augment and alignment methods, which prove our benchmark is consistent with previous dataset and requires the model to understand both of the two modalities",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2p3FI7YZHu": {
    "title": "SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support",
    "volume": "review",
    "abstract": "Developing specialized dialogue systems for mental health support requires multi-turn conversation data, which has recently garnered increasing attention. However, gathering and releasing large-scale, real-life multi-turn conversations to facilitate advancements in mental health presents challenges due to data privacy protection, as well as the time and cost involved. To address the challenges related to data scarcity, we introduce SMILE, a single-turn to multi-turn inclusive language expansion technique with a solid theoretical foundation that prompts ChatGPT to transform public single-turn dialogues into multi-turn ones. Our study first focuses on basic characteristics, dialogue diversity, and quality among four large language models, verifying that our proposed method is superior to other baseline methods and that GPT-4o is the optimal option. Thus, we employ our method to generate a large-scale, diverse, and high-quality dialogue dataset named SmileChat, consisting of 13k dialogues. Finally, we utilize SmileChat to fine-tune six large language models, giving birth to mental health chatbots, MeChat. Empirical evaluations demonstrate that MeChat excels in generating empathic, professional, helpful, and safe responses in mental health support, showing its high quality and practicality",
    "checked": true,
    "id": "83bc360fa9874564cf8ccbd3a00e6e14dbe4e4e6",
    "semantic_title": "smile: single-turn to multi-turn inclusive language expansion via chatgpt for mental health support",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=SgPmlIRgBC": {
    "title": "Enhance Reasoning of Large Language Models via Macro-Micro Self-Training",
    "volume": "review",
    "abstract": "Decomposing complex problems into smaller stages has proven to be highly effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, as the reasoning process becomes more intricate, uncertainties and errors tend to accumulate, making it challenging to achieve precise final outcomes. Overcoming this challenge and addressing uncertainty in multi-step reasoning necessitates innovative approaches. In this regard, we propose a novel macro-micro self-training method. Our approach leverages self-evaluation and self-modification to enable LLMs to continuously refine their outputs. Through self-evaluation, LLMs assess the accuracy of their generated outputs, while the critical aspect of self-modification allows for iterative refinement of these outputs. To ensure comprehensive refinement, we combine macro evaluation and modification of the entire code structure with micro analysis, where each line of code is individually assessed and refined in line with the problem statement. This dual approach ensures coherent handling of both syntax and semantics. Empirically, our results demonstrate the effectiveness of our approach, as it outperforms existing methods across all settings. Our method enables LLMs to achieve new levels of reasoning capability, providing superior performance in various tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QelMGP8yie": {
    "title": "Demostrations Aren't All You Need For Long-form Generation! Learning Task-Inherent Attribute Guidelines For Large Language Models",
    "volume": "review",
    "abstract": "We study the sufficiency of demonstrations in enabling pre-trained large language models (LLMs) to implicitly learn the underlying task distribution for long-form generation. We prove the answer is no. For any long-form generation task, we show that if an LLM fails to initially grasp the task's language distribution, demonstrations alone are insufficient. This gap is caused by a lack of explicit task-language distribution characterization exposed to the model. Addressing this by capturing these distributions explicitly through task guidelines enhances model performance. We then present LongGuide, the first efficient algorithm that generates two types of guidelines as additional instructions for LLMs: (i) Metric Guideline (MG) that instructs models to optimize for selected metrics; and (ii) Output Constraint Guideline (OCG) that constrains generation at both the token and sentence levels. LongGuide automatically selects the most useful combination of guidelines, improving strong open- and closed-source LLMs by 5.39% and 6.58% under zero- and few-shot settings across seven tasks. Furthermore, LongGuide enhances LLMs beyond demonstrations, is learnable by weaker models to enhance stronger ones, and synergistically combines with prompt optimizers",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dPELTS1rUK": {
    "title": "Iterative Data Augmentation with Large Language Models for Aspect-based Sentiment Analysis",
    "volume": "review",
    "abstract": "Aspect-based Sentiment Analysis (ABSA) is an important sentiment analysis task, which aims to determine the sentiment polarity towards an aspect in a sentence. Due to the expensive and limited labeled data, data augmentation (DA) has become the standard for improving the performance of ABSA. However, current DA methods usually have some shortcomings: 1) poor fluency and coherence, 2) lack of diversity of generated data, and 3) reliance on some existing labeled data, hindering its applications in real-world scenarios. In response to these problems, we propose a systematic iterative data augmentation framework, namely IterD, to boost the performance of ABSA. The core of IterD is to leverage the powerful ability of large language models (LLMs) to iteratively generate more fluent and diverse synthetic labeled data, starting from an unsupervised sentence corpus. Extensive experiments on 4 widely-used ABSA benchmarks show that IterD brings consistent and significant performance gains among 5 baseline ABSA models. More encouragingly, the synthetic data generated by IterD can achieve comparable or even better performance against the manually annotated data",
    "checked": true,
    "id": "84334c25e410e1e2998f1cdb6c490aab5d32855d",
    "semantic_title": "iterative data augmentation with large language models for aspect-based sentiment analysis",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t4xLFxSsjr": {
    "title": "Graph Elicitation for Guiding Multi-Step Reasoning in Large Language Models",
    "volume": "review",
    "abstract": "Chain-of-Thought (CoT) prompting along with sub-question generation and answering has enhanced multi-step reasoning capabilities of Large Language Models (LLMs). However, prompting the LLMs to directly generate sub-questions is suboptimal since they sometimes generate redundant or irrelevant questions. To deal with them, we propose a GE-Reasoning method, which directs LLMs to generate proper sub-questions and corresponding answers. Concretely, given an input question, we first prompt the LLM to generate knowledge triplets, forming a graph representation of the question. Unlike conventional knowledge triplets, our approach allows variables as head or tail entities, effectively representing a question as knowledge triplets. Second, for each triplet, the LLM generates a corresponding sub-question and answer along with using knowledge retrieval. If the prediction confidence exceeds a threshold, the sub-question and prediction are incorporated into the prompt for subsequent processing. This approach encourages that sub-questions are grounded in the extracted knowledge triplets, reducing redundancy and irrelevance. Our experiments demonstrate that our approach outperforms previous CoT prompting methods and their variants on multi-hop question-answering benchmark datasets",
    "checked": true,
    "id": "5baaa716bbd880b940028ad3dd4f13e71b9cd856",
    "semantic_title": "graph elicitation for guiding multi-step reasoning in large language models",
    "citation_count": 4,
    "authors": []
  },
  "https://openreview.net/forum?id=it6eZSe3TG": {
    "title": "MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension",
    "volume": "review",
    "abstract": "Large language models are playing an increasingly significant role in molecular research, yet existing models often generate erroneous information. Traditional evaluations fail to assess a model's factual correctness. To rectify this absence, we present MoleculeQA, a novel question answering (QA) dataset which possesses 62K QA pairs over 23K molecules. Each QA pair, composed of a manual question, a positive option and three negative options, has consistent semantics with a molecular description from authoritative corpus. MoleculeQA is not only the first benchmark to evaluate molecular factual correctness but also the largest molecular QA dataset. A comprehensive evaluation on MoleculeQA for existing molecular LLMs exposes their deficiencies in specific aspects and pinpoints crucial factors for molecular modeling. Furthermore, we employ MoleculeQA in reinforcement learning to mitigate model hallucinations, thereby enhancing the factual correctness of generated information",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rw3Gzlopou": {
    "title": "Navigating Hallucinations for Reasoning of Unintentional Activities",
    "volume": "review",
    "abstract": "In this work we present a novel task of understanding unintentional human activities in videos. We formalize this problem as a reasoning task under zero-shot scenario, where given a video of an unintentional activity we want to know why it transitioned from intentional to unintentional. We first evaluate the effectiveness of current state-of-the-art Large Multimodal Models on this reasoning task and observe that they suffer from hallucination. We further propose a novel prompting technique, termed as Dream of Thoughts (DoT), which allows the model to navigate through hallucinated thoughts to achieve better reasoning. To evaluate the performance on this task, we also introduce three different specialized metrics designed to quantify the models reasoning capability. We perform our experiments on three datasets, OOPs, UCF-Crimes, and ReUAct, and our findings show that DOT prompting technique is able to outperform standard prompting, while minimizing hallucinations",
    "checked": true,
    "id": "f12b2e22ed2530e2b87054e5735208449616bf3c",
    "semantic_title": "navigating hallucinations for reasoning of unintentional activities",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=Fe8vovPrCt": {
    "title": "Divide-or-Conquer? Which Part Should You Distill Your LLM?",
    "volume": "review",
    "abstract": "Recent methods have demonstrated that Large Language Models (LLMs) can solve reasoning tasks better when they are encouraged to solve subtasks of the main task first. In this paper we devise a similar strategy that breaks down reasoning tasks into a problem decomposition phase and a problem solving phase and show that the strategy is able to outperform a single stage solution. Further, we hypothesize that the decomposition should be easier to distill into a smaller model compared to the problem solving because the latter requires large amounts of domain knowledge while the former only requires learning general problem solving strategies. We propose methods to distill these two capabilities and evaluate their impact on reasoning outcomes and inference cost. We find that we can distill the problem decomposition phase and at the same time achieve good generalization across tasks, datasets, and models. However, it is harder to distill the problem solving capability without losing performance and the resulting distilled model struggles with generalization. These results indicate that by using smaller, distilled problem decomposition models in combination with problem solving LLMs we can achieve reasoning with cost-efficient inference and local adaptation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xa4GYUSvhW": {
    "title": "HyperLoRA: Efficient Cross-task Generalization via Constrained Low-Rank Adapters Generation",
    "volume": "review",
    "abstract": "Adapting pre-trained language models (PLMs) for cross-task generalization is a crucial research area within the field of NLP. While fine-tuning and in-context learning are effective approaches for adapting LMs to emerging tasks, they can be costly and inefficient. Recently, some researchers have focused on achieving efficient task adaptation via hypernetwork, which is a meta network that generates task-specific weights based on task-oriented information without any optimization. However, the training of hypernetworks often lacks stability since the optimization signal is not straightforward, and the task information is not adequately representative. Moreover, previous works train hypenetworks with the general corpus, which is struggling with few-shot adaptation. To address these issues, we introduce HyperLoRA, a hypernetwork for LoRA parameters generation involving hypernetwork pre-training on instruction-following data and generalization fine-tuning on sparse task data. Furthermore, we utilize a constrained training loss and a gradient-based demonstration selection strategy to enhance the training stability and performance. Experimental results and analysis across four benchmark datasets (P3, S-NI, BBH, and SuperGLUE) demonstrate the proposed approach has flexible generalization ability and superior performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IBPBukWkGx": {
    "title": "AIGT: AI Generative Table Based on Prompt Enhancement",
    "volume": "review",
    "abstract": "Tabular data, comprising over 80\\% of enterprise data assets, is crucial across various fields. With growing concerns about privacy protection and data-sharing restrictions, generating high-quality synthetic tabular data has become essential. Recent advancements demonstrate that large language models (LLMs) can effectively generate realistic tabular data by leveraging semantic information and avoiding the curse of dimensionality inherent in one-hot encoding of high-dimensional data. However, current methods do not fully exploit the rich information within tables. To address this, we introduce $\\underline{AI} ~\\underline{G}enerative ~\\underline{T}able$ based on prompt enhancement, a novel approach that utilizes metadata information, such as table descriptions and schemas, as prompts to generate ultra-high-quality synthetic data. To circumvent the token limit constraints of LLMs, we propose long-token partitioning algorithms that enable \\ours{} to model tables of arbitrary scale. AIGT achieves state-of-the-art performance on 20 public datasets and multi-scenario datasets within the Alipay risk control system. The source code, data, and other artifacts are available in supplementary materials",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3PvvmeHJAc": {
    "title": "LaCo: Large Language Model Pruning via Layer Collapse",
    "volume": "review",
    "abstract": "Large language models (LLMs) based on transformer are witnessing a notable trend of size expansion, which brings considerable costs to both model training and inference. However, existing methods such as model quantization, knowledge distillation, and model pruning are constrained by various issues, including hardware support limitations, the need for extensive training, and alterations to the model internal structure. In this paper, we propose a concise layer-wise structured pruner called \\textit{Layer Collapse (LaCo)}, in which rear model layers collapse into a prior layer, enabling a rapid reduction in model size while preserving the model structure. Comprehensive experiments show that our method maintains an average task performance of over 80\\% at pruning ratios of 25-30\\%, significantly outperforming existing state-of-the-art structured pruning methods. We also conduct post-training experiments to confirm that the \\textit{LaCo} effectively inherits the parameters of the original model. Additionally, we perform ablation studies on various settings of \\textit{LaCo}. Finally, we discuss our motivation from the perspective of layer-wise similarity and evaluate the performance of the pruned LLMs across various pruning ratios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2cRuzDyVcd": {
    "title": "Evaluating Image Review Ability of Vision Language Models",
    "volume": "review",
    "abstract": "Large-scale Vision-Language Models (LVLMs) can process both images and text, demonstrating advanced capabilities in multimodal tasks like image captioning and visual question answering (VQA). However, it remains unclear whether they have an ability to understand and evaluate images, particularly in capturing the nuanced impressions and evaluations. To address this, we propose an image review evaluation method using rank correlation analysis. Our method asks a model to rank five review texts for an image. We then compare the model's rankings with human rankings to measure correlation. This enables effective evaluation of review texts that do not have a single correct answer. We validate this approach with a benchmark dataset of images from 15 categories, each with five review texts and annotated rankings in English and Japanese, resulting in over 2,000 data instances. Our experiments show that LVLMs excel at distinguishing between high-quality and low-quality reviews",
    "checked": true,
    "id": "c1e88bd7fe8c3174a697c6814a044f899f04db4e",
    "semantic_title": "evaluating image review ability of vision language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ndjti4Nxkh": {
    "title": "SNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions",
    "volume": "review",
    "abstract": "Instruction-following large language models (LLMs), such as ChatGPT, have become increasingly popular with the general audience, many of whom are incorporating them into their daily routines. However, these LLMs inadvertently disclose personal or copyrighted information, which calls for a machine unlearning method to remove selective knowledge. Previous attempts sought to forget the link between the target information and its associated entities, but it rather led to generating undesirable responses about the target, compromising the end-user experience. In this work, we propose SNAP, an innovative framework designed to selectively unlearn information by 1) training an LLM with \\textit{negative instructions} to generate obliterated responses, 2) augmenting hard positives to retain the original LLM performance, and 3) applying the novel Wasserstein regularization to ensure adequate deviation from the initial weights of the LLM. We evaluate our framework on various NLP benchmarks and demonstrate that our approach retains the original LLM capabilities, while successfully unlearning the specified information",
    "checked": true,
    "id": "dcdf8c252362752911c6b928e2683c5e698a2d1b",
    "semantic_title": "snap: unlearning selective knowledge in large language models with negative instructions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XAciMT4JvK": {
    "title": "Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages",
    "volume": "review",
    "abstract": "LLMs have become a go-to solution not just for text generation, but also for natural language understanding (NLU) tasks. Acquiring extensive knowledge through language modeling on web-scale corpora, they excel on English NLU, yet struggle to extend their NLU capabilities to underrepresented languages. In contrast, machine translation models (MT) produce excellent multilingual representations, resulting in strong translation performance even for low-resource languages. MT encoders, however, lack the knowledge necessary for comprehensive NLU that LLMs obtain through language modeling training on immense corpora. In this work, we get the best both worlds by integrating MT encoders directly into LLM backbones via sample-efficient self-distillation. The resulting MT-LLMs preserve the inherent multilingual representational alignment from the MT encoder, allowing lower-resource languages to tap into the rich knowledge embedded in English-centric LLMs. Merging the MT encoder and LLM in a single model, we mitigate the propagation of translation errors and inference overhead of MT decoding inherent to discrete translation-based cross-lingual transfer (e.g., translate-test). Evaluation spanning three prominent NLU tasks and 127 predominantly low-resource languages renders MT-LLMs highly effective in cross-lingual transfer. MT-LLMs substantially and consistently outperform translation-test based on the same MT model, showing that we truly unlock multilingual language understanding for LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rU9hzxdjIB": {
    "title": "Zero-shot Multi-Hop Question Answering via Monte-Carlo Tree Search with Large Language Models",
    "volume": "review",
    "abstract": "Recent advances in large language models (LLMs) have significantly impacted the domain of multi-hop question answering (MHQA), where systems are required to aggregate information and infer answers from disparate pieces of text. However, the autoregressive nature of LLMs inherently poses a challenge as errors may accumulate if mistakes are made in the intermediate reasoning steps. This paper introduces **M**onte-Carlo tree search for **Z**ero-shot multi-hop **Q**uestion **A**nswering (MZQA), a framework based on Monte-Carlo tree search (MCTS) to identify optimal reasoning paths in MHQA tasks, mitigating the error propagation from sequential reasoning processes. Unlike previous works, we propose a zero-shot prompting method, which relies solely on instructions without the support of hand-crafted few-shot examples that typically require domain expertise. We also introduce a behavioral cloning approach (MZQA-BC) trained on self-generated MCTS inference trajectories, achieving an over 10-fold increase in reasoning speed with bare compromise in performance. The efficacy of our method is validated on standard benchmarks such as HotpotQA, 2WikiMultihopQA, and MuSiQue, demonstrating that it outperforms existing frameworks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nQTpIJjcfX": {
    "title": "Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion",
    "volume": "review",
    "abstract": "During pre-training, the Text-to-Image (T2I) diffusion models encode factual knowledge into their parameters. These parameterized facts enable realistic image generation, but they may become obsolete over time, thereby misrepresenting the current state of the world. Knowledge editing techniques aim to update model knowledge in a targeted way. However, facing the dual challenges posed by inadequate editing datasets and unreliable evaluation criterion, the development of T2I knowledge editing encounter difficulties in effectively generalizing injected knowledge. In this work, we design a T2I knowledge editing framework by comprehensively spanning on three phases: First, we curate a dataset \\textbf{CAKE}, comprising paraphrase and multi-object test, to enable more fine-grained assessment on knowledge generalization. Second, we propose a novel criterion, \\textbf{adaptive CLIP threshold}, to effectively filter out false successful images under the current criterion and achieve reliable editing evaluation. Finally, we introduce \\textbf{MPE}, a simple but effective approach for T2I knowledge editing. Instead of tuning parameters, MPE precisely recognizes and edits the outdated part of the conditioning text-prompt to accommodate the up-to-date knowledge. A straightforward implementation of MPE (Based on in-context learning) exhibits better overall performance than previous model editors. We hope these efforts can further promote faithful evaluation of T2I knowledge editing methods.\\footnote{Our code will be made publicly available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IVgiXnhIbt": {
    "title": "An Evaluation Mechanism of LLM-based Agents on Manipulating APIs",
    "volume": "review",
    "abstract": "LLM-based agents can greatly extend the abilities of LLMs and thus attract sharply increased studies. An ambitious vision -- serving users by manipulating massive API-based tools -- has been proposed and explored. However, we find a widely accepted evaluation mechanism for generic agents is still missing. This work aims to fill this gap. We decompose tool use capability into seven aspects and form a thorough evaluation schema. In addition, we design and release an instruction dataset and a toolset -- the two sides that the agents bridge between -- following the principle of reflecting real-world challenges. Furthermore, we evaluate multiple generic agents. Our findings can inspire future research in improving LLM-based agents and rethink the philosophy of API design",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jilpfuICJn": {
    "title": "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering",
    "volume": "review",
    "abstract": "Knowledge Graph Question Answering (KGQA) methods seek to answer Natural Language questions using the relational information stored in Knowledge Graphs (KGs). With the recent advancements of Large Language Models (LLMs) and their remarkable reasoning abilities, there is a growing trend to leverage them for KGQA. However, existing methodologies have only focused on answering factual questions, e.g., \"In which city was Silvio Berlusconi's first wife born?\", leaving questions involving commonsense reasoning that real-world users may pose more often, e.g., \"Do I need separate visas to see the Venus of Willendorf and attend the Olympics this summer?\" unaddressed. In this work, we first observe that existing LLM-based methods for KGQA struggle with hallucination on such questions, especially on queries targeting long-tail entities (e.g., non-mainstream and recent entities), thus hindering their applicability in real-world applications especially since their reasoning processes are not easily verifiable. In response, we propose Right for Right Reasons (R^3), a commonsense KGQA methodology that allows for a verifiable reasoning procedure by axiomatically surfacing intrinsic commonsense knowledge of LLMs and grounding every factual reasoning step on KG triples. Through experimental evaluations across three different tasks—question answering, claim verification, and preference matching—our findings showcase R^3 as a superior approach, outperforming existing methodologies and notably reducing instances of hallucination and reasoning errors",
    "checked": true,
    "id": "59395cf4f9346ef4ccb37499a3a7e52c2978fc61",
    "semantic_title": "right for right reasons: large language models for verifiable commonsense knowledge graph question answering",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=H06ZGKJJ4C": {
    "title": "Revisiting the Knowledge Recall and Selection in Chinese Spelling Correction",
    "volume": "review",
    "abstract": "Chinese Spelling Correction (CSC) task is very challenging in the natural language processing area. However, the performance improvement is quite limited, primarily because the infusion of knowledge is limited. Previous work involved confusion sets as additional knowledge, but the size was too small and served only as a role of additional feature. To address this, we propose a knowledge recall and selection network (ReSC). First through four recall methods to achieve an average recall rate above 93\\%, with individual character recall of around 150 related characters/words. Subsequently, we proposed a Knowledge Selection Algorithm, choosing the appropriate characters or words from numerous recall sets. The knowledge selection network is highly efficient, as the F1 score nearly reached 100\\%. Extensive experiments have proven ReSC is able to inject substantial amount of entities with even a lower False Positive Rate. This novel network acheves the new SOTA results across three domain-specific datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qCdRbiOqWV": {
    "title": "Learning from Errors: A Data-Efficient Adaptation Method of Large Language Models for Code Generation",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) have achieved substantial advances in code generation tasks, but they still struggle in specific code generation scenarios. These scenarios often require LLMs to be adapted to meet specific needs, but the limited training data available in practice leads to poor code generation performance. Therefore, how to effectively adapt LLMs to new scenarios with less training data is a major challenge for current code generation. In this paper, we propose a novel and effective adaptation method DEED, which stands for Data-Efficient adaptation based on Error-Driven learning for code generation. DEED leverages the errors made by LLM as learning opportunities and overcomes its own shortcomings through error revision, thereby achieving efficient learning. Specifically, DEED includes identifying the erroneous code generated by LLM, using Self-revise for code revision, optimizing the model with the revised code, and iteratively adapting the process for continuous improvement. Experimental results show that DEED achieves superior performance compared with mainstream fine-tuning and prompting methods using only a small amount of training data, with an average relative improvement of 54.7% on Pass@1 on multiple code generation datasets. We also verify the effectiveness of Self-revise, which generates revised code that optimizes the model more efficiently compared to the code samples from datasets. Moreover, DEED consistently shows strong performance across various LLMs, highlighting its generalizability",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zhBbq1RfFf": {
    "title": "Logic Consistency Makes Large Language Models Personalized Reasoning Teachers",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) have advanced natural language processing significantly with Chain-of-Thought (CoT) reasoning and In-Context Learning (ICL), but their deployment is limited by high computational and operational costs. This paper introduces Personalized Chain-of-Thought Distillation (PeCoTD), a novel approach to transfer reasoning capabilities from LLMs to smaller, more deployable models. Recognizing the comprehension difficulties small LMs face with LLM-generated rationales, we first develop a metric called Self Logic Consistency (SLC) to assess rationale quality. This refinement process ensures the maintenance of semantic equivalence with the original LLM rationales, facilitating more effective fine-tuning and avoiding distribution shifts. This approach, focusing on data quality in Knowledge Distillation (KD), mitigates comprehension variability in small LMs and extends the applicability of CoT KD strategies. Our experiments show that PeCoTD significantly improves the reasoning abilities of small models across diverse datasets",
    "checked": false,
    "id": "58fce438f817b46d37d072f8af7dfa4fd2dcd866",
    "semantic_title": "can language models teach weaker agents? teacher explanations improve students via personalization",
    "citation_count": 5,
    "authors": []
  },
  "https://openreview.net/forum?id=qVYFTgVOLn": {
    "title": "Knowledge Distillation of Black-Box Large Language Models",
    "volume": "review",
    "abstract": "Given the exceptional performance of proprietary large language models (LLMs) like GPT-4, recent research has increasingly focused on boosting the capabilities of smaller models through knowledge distillation (KD) from these powerful yet black-box teachers. While leveraging the high-quality outputs of these teachers is advantageous, the inaccessibility of their internal states often limits effective knowledge transfer. To overcome this limitation, we introduce Proxy-KD, a novel method that uses a proxy model to facilitate the efficient transfer of knowledge from black-box LLMs to smaller models. Our experiments show that Proxy-KD not only enhances the performance of KD from black-box teacher models but also surpasses traditional white-box KD techniques.~This approach presents a compelling new avenue for distilling knowledge from advanced LLMs",
    "checked": false,
    "id": "f5359f596e0306599b4aa4157e6fe03567b35c01",
    "semantic_title": "knowledge distillation of large language models",
    "citation_count": 51,
    "authors": []
  },
  "https://openreview.net/forum?id=bjtLHkVsv2": {
    "title": "TTQA-RS- A break-down prompting approach for Multi-hop Table-Text Question Answering with Reasoning and Summarization",
    "volume": "review",
    "abstract": "Question answering (QA) over tables and text has gained much popularity over the years. Multi-hop table-text QA requires multiple hops between the table and text, making it a challenging QA task. Although several works have attempted to solve the table-text QA task, most involve training the models and requiring labeled data. In this paper, we have proposed a model - \"TTQA-RS: A break-down prompting approach for Multi-hop Table-Text Question Answering with Reasoning and Summarization. Our model uses augmented knowledge including table-text summary with decomposed sub-question with answer for a reasoning-based table-text QA. Using open-source language models our model outperformed all existing prompting methods for table-text QA tasks on existing table-text QA datasets like HybridQA and OTT-QA's development set. Our results are comparable with the training-based state-of-the-art models, demonstrating the potential of prompt-based approaches using open-source LLMs. Additionally, by using GPT-4 with LLaMA3-70B, our model achieved state-of-the-art performance for prompting-based methods on multi-hop table-text QA",
    "checked": true,
    "id": "2a8686ced6bf48e404560ab7d09e3d0af6d5149d",
    "semantic_title": "ttqa-rs- a break-down prompting approach for multi-hop table-text question answering with reasoning and summarization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4rxo5Hk2QJ": {
    "title": "Identifying Nuances of Multi-Task Learning for Bengali and English Emotional Texts",
    "volume": "review",
    "abstract": "In this paper, we present a multi-task learning (MTL) model to classify sentiment and emotion in Bengali and English languages. For this multi-task learning work, different Bengali and English datasets were collected from publicly available sources and developed two MTL models by utilizing pre-trained mBERT and MuRIL models. Our proposed MTL model outperforms their corresponding standalone classifiers with an average F1-score of 0.5728 (+0.041) and 0.7590 (+0.046) for Bengali sentiment, emotion and English sentiment, emotion classification tasks respectively",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UwM5gX2wHN": {
    "title": "Span-based Multi-grained Word Segmentation with Natural Annotations",
    "volume": "review",
    "abstract": "Multi-grained word segmentation (MWS) differs from traditional single-grained word segmentation (SWS) by dividing a sentence into multiple word sequences at varying granularities. The scarcity of annotated MWS data has led previous studies to use automatically generated pseudo MWS data and treat MWS as a tree parsing task. However, this method is limited by the low quality of the pseudo data. In this work, we directly utilize multiple single-grained datasets and implement multi-task learning for MWS. To better address conflicts arising from words segmented at different granularities, we employ a span-based word segmentation model. Additionally, we incorporate naturally annotated BAIKE data to improve model performance in cross-domain applications. Experimental results demonstrate that our method achieved an F1 score improvement of 0.83 on the NEWS dataset and 4.8 on the BAIKE dataset. Furthermore, by employing data augmentation, we obtained an additional F1 score improvement of 2.23 on the BAIKE dataset",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dPYUU61lIE": {
    "title": "Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models",
    "volume": "review",
    "abstract": "Emotions play important epistemological and cognitive roles in our lives, revealing our values and guiding our actions. Previous work has shown that LLMs display biases in emotion attribution along gender lines. However, unlike gender, which says little about our values, religion, as a socio-cultural system, prescribes a set of beliefs and values for its followers. Religions, therefore, cultivate certain emotions. Moreover, these rules are explicitly laid out and interpreted by religious leaders. Using emotion attribution, we explore how different religions are represented in LLMs. We find that: Major religions in the US and European countries are represented with more nuance, displaying a more shaded model of their beliefs. Eastern religions like Hinduism and Buddhism are strongly stereotyped. Judaism and Islam are stigmatized -- the models' refusal skyrocket. We ascribe these to cultural bias in LLMs and the scarcity of NLP literature on religion. In the rare instances where religion is discussed, it is often in the context of toxic language, perpetuating the perception of these religions as inherently toxic. This finding underscores the urgent need to address and rectify these biases. Our research underscores the crucial role emotions play in our lives and how our values influence them",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q3pRHLxMDc": {
    "title": "IntCoOp: Interpretability-Aware Vision-Language Prompt Tuning",
    "volume": "review",
    "abstract": "Image-text contrastive models such as CLIP learn transferable and robust representations for zero-shot transfer to a variety of downstream tasks. However, to obtain strong downstream performances, prompts need to be carefully curated, which can be a tedious engineering task. To address the issue of manual prompt engineering, prompt-tuning is used where a set of contextual vectors are learned by leveraging information from the training data. Despite their effectiveness, existing prompt-tuning frameworks often lack interpretability, thus limiting their ability to understand the compositional nature of images. In this work, we first identify that incorporating compositional attributes (e.g., a \"green\" tree frog) in the design of manual prompts can significantly enhance image-text alignment scores. Building upon this observation, we propose a novel and interpretable prompt-tuning method named IntCoOp, which learns to jointly align attribute-level inductive biases and class embeddings during prompt-tuning. To assess the effectiveness of our approach, we evaluate IntCoOp across two representative tasks in a few-shot learning setup: generalization to novel classes, and unseen domain shifts. Through extensive experiments across 10 downstream datasets on CLIP, we find that introducing attribute-level inductive biases leads to superior performance against state-of-art prompt tuning frameworks. Notably, in a 16-shot setup, IntCoOp improves CoOp by 7.35% in average performance across 10 diverse datasets",
    "checked": true,
    "id": "eff8782850cca1291fec91bbb5607b054cbbe892",
    "semantic_title": "intcoop: interpretability-aware vision-language prompt tuning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fyIE0G23ob": {
    "title": "Tool Graph Retriever: Exploring Dependency Graph-based Tool Retrieval for Large Language Models",
    "volume": "review",
    "abstract": "With the remarkable advancement of AI agents, the number of their equipped tools is increasing rapidly. However, integrating all tool information into the limited model context becomes impractical, highlighting the need for efficient tool retrieval methods. In this regard, dominant methods primarily rely on semantic similarities between tool descriptions and user queries to retrieve relevant tools. However, they often consider each tool independently, overlooking dependencies between tools, which may lead to the omission of prerequisite tools for successful task execution. To deal with this defect, in this paper, we propose Tool Graph Retriever (TGR), which exploits the dependencies among tools to learn better tool representations for retrieval. First, we construct a dataset termed TDI300K to train a discriminator for identifying tool dependencies. Then, we represent all candidate tools as a tool dependency graph and use graph convolution to integrate the dependencies into their representations. Finally, these updated tool representations are employed for online retrieval. Experimental results on several commonly used datasets show that our TGR can bring a performance improvement to existing dominant methods, achieving SOTA performance. Moreover, in-depth analyses also verify the importance of tool dependencies and the effectiveness of our TGR",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nvVv9udFyo": {
    "title": "Mitigating Biases of Large Language Models in Stance Detection with Calibration",
    "volume": "review",
    "abstract": "Large language models (LLMs) have achieved remarkable progress in many natural language processing tasks. However, our experiment reveals that, in stance detection tasks, LLMs may generate biased stances due to sentiment-stance spurious correlations and preference towards certain individuals and topics, thus harming their performance. Therefore, in this paper, we propose to Mitigate Biases of LLMs in stance detection with Calibration (MB-Cal). To be specific, a novel calibration network is devised to calibrate potential bias in the stance prediction of LLMs. Further, to address the challenge of effectively learning bias representations and the difficulty in the generalizability of debiasing, we construct counterfactual augmented data. This approach enhances the calibration network, facilitating the debiasing and out-of-domain generalization. Experimental results on in-target and zero-shot stance detection tasks show that the proposed MB-Cal can effectively mitigate biases of LLMs, achieving state-of-the-art results",
    "checked": true,
    "id": "7b7853b6d8659d9027590f14639ccf5a616b2bca",
    "semantic_title": "mitigating biases of large language models in stance detection with calibration",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=tbMeasOfX9": {
    "title": "Causal Discovery Inspired Unsupervised Domain Adaptation for Emotion-Cause Pair Extraction",
    "volume": "review",
    "abstract": "This paper tackles the task of emotion-cause pair extraction in the unsupervised domain adaptation setting. The problem is challenging as the distributions of the events causing emotions in target domains are dramatically different than those in source domains, despite the distributions of emotional expressions between domains are overlapped. Inspired by causal discovery, we propose a novel deep latent model in the variational autoencoder (VAE) framework, which not only captures the underlying latent structures of data but also utilizes the easily transferable knowledge of emotions as the bridge to link the distributions of events in different domains. To facilitate knowledge transfer across domains, we also propose a novel variational posterior regularization technique to disentangle the latent representations of emotions from those of events in order to mitigate the damage caused by the spurious correlations related to the events in source domains. Through extensive experiments, we demonstrate that our model outperforms the strongest baseline by approximately 11.05\\% on a Chinese benchmark and 2.45\\% on a English benchmark in terms of weighted-average F1 score. The source code will be publicly available upon acceptance",
    "checked": true,
    "id": "7710fe5287a50ce6b0f4f12ed617f9b5f057738e",
    "semantic_title": "causal discovery inspired unsupervised domain adaptation for emotion-cause pair extraction",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YSpiATIH97": {
    "title": "Navigating Alignment Pitfalls: Assessing Suggestions to Combat Sycophancy",
    "volume": "review",
    "abstract": "Sycophancy causes models to produce answers that cater to user expectations rather than providing truthful responses. Previous research has found that model scaling, instruction tuning, and human feedback may increase sycophancy. However, these studies primarily focused on closed-source models and used indirect analysis to demonstrate the influence of human feedback. Our study focuses on sycophancy in open-source models, which are commonly used for specialized domain applications. We investigated the impact of human feedback on sycophancy by directly comparing models aligned with human feedback to those not aligned. To address sycophancy, we proposed assessing the user's expected answer rather than ignoring it. Consequently, we developed the Assessing Suggested Answer Preferences (ASAP) dataset and demonstrated that ASAP can enhance the model's assessment ability and reduce sycophancy across tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1twynEXRxS": {
    "title": "Resource-Efficient and Model-Independent Data Selection Framework for Instruction Fine-Tuning",
    "volume": "review",
    "abstract": "Large language models (LLMs) possess powerful capabilities and play a crucial role in daily life. Instruction fine-tuning is essential for training LLMs, enabling them to understand human instructions and produce the desired output. Selecting appropriate data for instruction fine-tuning is essential but challenging, existing data selection methods struggle to balance effectiveness and efficiency in real-world scenarios. Given that instruction fine-tuning requires models to respond to a wide variety of questions, we focus on output quality to assess the quality of instruction fine-tuning samples. In this work, we propose a novel data selection framework that evaluates data from unknown sources based on its output. To guide the model in distinguishing instruction fine-tuning data, we train a discriminator that uses outputs from models of varying quality as supervision signals. We establish principles to evaluate model quality, asserting that a model's quality is higher if it is a newer version, has more parameters, and achieves higher scores on well-known benchmarks. This way, the discriminator learns the differences between outputs from different models, enabling it to categorize unknown data into the most similar model outputs. We conduct experiments to prove that our method is resource-efficient and model-independent",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=blEJ6z1bvu": {
    "title": "Focused Large Language Models are Stable Many-Shot Learners",
    "volume": "review",
    "abstract": "In-Context Learning (ICL) enables large language models (LLMs) to achieve rapid task adaptation by learning from demonstrations. With the increase in available context length of LLMs, recent experiments have shown that the performance of ICL does not necessarily scale well in many-shot (demonstration) settings. We hypothesize that the reason lies in more demonstrations dispersing the model attention from the query, hindering its understanding of key content, which we validate both theoretically and experimentally. Inspired by how humans learn from examples, we propose a training-free method FocusICL, which conducts triviality filtering to avoid attention being diverted by unimportant contents at token-level and operates hierarchical attention to further ensure sufficient attention towards current query at demonstration-level. We also design an efficient hyperparameter searching strategy for FocusICL based on model perplexity of demonstrations. Comprehensive experiments validate that FocusICL achieves an average performance improvement of 5.2% over vanilla ICL and scales well with many-shot demonstrations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rwhZhPgj0V": {
    "title": "RaTEScore: A Metric for Entity-Aware Radiology Text Similarity",
    "volume": "review",
    "abstract": "This paper proposes a new entity-aware lightweight metric for assessing accuracy of generated medical free-form text from AI models. Our metric, termed as Radiological Report Text Evaluation (RaTEScore), is designed to focus on key medical entities, such as diagnostic outcomes, anatomies, while demonstrating robustness against complex medical synonyms and sensitivity to negation expressions. Technically, we establish a new large-scale medical NER dataset RaTE-NER and train an NER model on it. Leveraging it, we decompose complex radiological reports into medical entities. We define the final metric by comparing the similarity based on the entity embeddings computed from language model and their corresponding types, forcing the metrics to focus on clinically critical statements. In experiments, our score demonstrates superior performance on aligning with human preference than other metrics, both on the existing public benchmarks and our new proposed RaTE-Eval benchmark",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZyRyfvPUhs": {
    "title": "Investigating Bias in LLM-Based Bias Detection: Disparities between LLMs and Human Perception",
    "volume": "review",
    "abstract": "The pervasive spread of misinformation and disinformation in social media underscores the critical importance of detecting media bias. While robust Large Language Models (LLMs) have emerged as foundational tools for bias prediction, concerns about inherent biases within these models persist. In this work, we investigate the presence and nature of bias within LLMs and its consequential impact on media bias detection. Departing from conventional approaches that focus solely on bias detection in media content, we delve into biases within the LLM systems themselves. Through meticulous examination, we probe whether LLMs exhibit biases, particularly in political bias prediction and text continuation tasks. Additionally, we explore bias across diverse topics, aiming to uncover nuanced variations in bias expression within the LLM framework. Importantly, we propose debiasing strategies, including prompt engineering and model fine-tuning. Extensive analysis of bias tendencies across different LLMs sheds light on the broader landscape of bias propagation in language models. This study advances our understanding of LLM bias, offering critical insights into its implications for bias detection tasks and paving the way for more robust and equitable AI systems",
    "checked": true,
    "id": "0fd73d32176189f7980847206a9d797c3b0f4e1d",
    "semantic_title": "investigating bias in llm-based bias detection: disparities between llms and human perception",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=cqu4AWqdqH": {
    "title": "PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning",
    "volume": "review",
    "abstract": "Recent advancements in large language models (LLMs) have raised concerns about inference costs, increasing the need for research into model compression. While knowledge distillation (KD) is a prominent method for this, research on KD for generative language models like LLMs is relatively sparse, and the approach of distilling student-friendly knowledge, which has shown promising performance in KD for classification models, remains unexplored in generative language models. To explore this approach, we propose PromptKD, a simple yet effective method that utilizes prompt tuning - for the first time in KD - to enable generative language models to transfer student-friendly knowledge. Unlike previous works in classification that require fine-tuning the entire teacher model for extracting student-friendly knowledge, PromptKD achieves similar effects by adding a small number of prompt tokens and tuning only the prompt with student guidance. Extensive experiments on instruction-following datasets show that PromptKD achieves state-of-the-art performance while adding only 0.0007% of the teacher's parameters as prompts. Further analysis suggests that distilling student-friendly knowledge alleviates exposure bias effectively throughout the entire training process, leading to performance enhancements",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=42W3lwlZY6": {
    "title": "Improving Translation between Spanish and Mapudungun through Transfer Learning",
    "volume": "review",
    "abstract": "Neural Machine Translation (NMT) systems for lower-resource languages like Mapudungun face significant challenges due to limited training data and linguistic complexities. This project aims to improve translation between Spanish and Mapudungun through transfer learning, leveraging pre-trained models on Spanish-English and Spanish-Finnish language pairs. Our contributions include demonstrating the effectiveness of transfer learning in this context and providing a comparative analysis of different parent models. Our main findings show that transfer learning enhances translation performance, with not much of a difference between the Spanish-English and Spanish-Finnish pre-trained model performance. This suggests that factors beyond morphological similarity, such as data quality or tokenization methods, play a crucial role in transfer learning success. These insights hope to pave the way for future research into optimizing translation tools for low-resource languages and involving communities in the development process",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JsqTM04zoa": {
    "title": "The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism",
    "volume": "review",
    "abstract": "Current evaluations of large language models (LLMs) often overlook non-determinism, typically focusing on a single output per example. This limits our understanding of LLM performance variability in real-world applications. Our study addresses this issue by exploring key questions about the performance differences between greedy decoding and sampling, identifying benchmarks' consistency regarding non-determinism, and examining unique model behaviors. Our findings reveal and quantify significant performance gaps between greedy and sampling methods across various benchmarks, with sampling excelling in creative tasks and greedy decoding favoring deterministic tasks. We also observe consistent performance across different LLM sizes and alignment methods, noting that alignment can reduce sampling variance. Moreover, our best-of-N sampling approach demonstrates that smaller LLMs can match or surpass larger models such as GPT-4-Turbo, highlighting the untapped potential of smaller LLMs. This research shows the importance of considering non-determinism in LLM evaluations and provides insights for future LLM development and evaluation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JyjbGaYs2e": {
    "title": "SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation",
    "volume": "review",
    "abstract": "Adaptive Retrieval-Augmented Generation (RAG) is an effective strategy to alleviate hallucination of large language models (LLMs). It dynamically determines whether LLMs need external knowledge for generation and invokes retrieval accordingly. This paper introduces **Self-aware Knowledge Retrieval** (SeaKR), a novel adaptive RAG model that extracts self-aware uncertainty of LLMs from their internal states. SeaKR activates retrieval when the LLMs present high self-aware uncertainty for generation. To effectively integrate retrieved knowledge snippets, SeaKR re-ranks them based on LLM's self-aware uncertainty to preserve the snippet that reduces their uncertainty to the utmost. To facilitate solving complex tasks that require multiple retrievals, SeaKR utilizes their self-aware uncertainty to choose among different reasoning strategies. Our experiments on both complex and simple Question Answering datasets show that SeaKR outperforms existing adaptive RAG methods",
    "checked": true,
    "id": "2a7720c878c20ed21608978e31507ca9d9936d1c",
    "semantic_title": "seakr: self-aware knowledge retrieval for adaptive retrieval augmented generation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=kBaTgEPgcl": {
    "title": "Named Entity Recognition in COVID-19 tweets with Entity Knowledge Augmentation",
    "volume": "review",
    "abstract": "The COVID-19 pandemic causes severe social and economic disruption around the world, raising various subjects that are discussed or argued over on social media. Identifying pandemic-related named entities as expressed on social media is fundamental and important for understanding the discussions on the pandemic. However, there is limited work on named entity recognition on this topic due to the following challenges: 1) annotated data is rare and insufficient to train a robust recognition model, and 2) named entity recognition in COVID-19 requires extensive knowledge of the pandemic. To address this, we propose a novel entity knowledge augmentation for named entity recognition systems in COVID-19 tweets. Experiments carried out on the COVID-19 tweets dataset show that our proposed entity knowledge augmentation improves NER performance, achieving an F1 score of 84.10",
    "checked": false,
    "id": "8431f99edcc5abb7527dfc993af7916f437b50fc",
    "semantic_title": "mets-cov: a dataset of medical entity and targeted sentiment on covid-19 related tweets",
    "citation_count": 13,
    "authors": []
  },
  "https://openreview.net/forum?id=JMwjgXHLCj": {
    "title": "FunLMs: Methods for Fine-tuning LLMs to Generate Humor",
    "volume": "review",
    "abstract": "This paper explores advancements in computational humor through the fine-tuning of large language models (LLMs) on curated datasets of English and Russian jokes. Experiments with fine-tuning on humorous data are conducted to see if generative humor is a viable idea. Different LLMs, sampling techniques and data curation are implemented for enhancing the coherence and effectiveness of humor generation providing a light computational approach for such tasks. We test the proposed methods on different formats and languages and conclude that generating humorous texts with LLMs is feasible though it requires substantial efforts in data preparation and evaluation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=imbmw0VVRC": {
    "title": "Analyzing and Evaluating Correlation Measures in NLG Meta-Evaluation",
    "volume": "review",
    "abstract": "The correlation between NLG automatic evaluation metrics and human evaluation is the most critical criterion for assessing the capability of an evaluation metric. However, different grouping methods and choices of correlation coefficients result in at least 12 types of correlation measures. For a long time, little has been known about their characteristics. Therefore, this paper illustrates the relationships between different correlation measures and demonstrates how the degree of data discretization affects their values through statistical simulations. Additionally, we designed algorithms to evaluate the discriminative power and ranking consistency of 12 correlation measures using empirical data from 6 datasets and 32 evaluation metrics, uncovering many interesting conclusions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U5qeRWEOkQ": {
    "title": "Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?",
    "volume": "review",
    "abstract": "Solving grid puzzles involves a significant amount of logical reasoning. Hence, it is a good domain to evaluate reasoning capability of a model which can then guide us to improve the reasoning ability of models. However, most existing works evaluate only the final predicted answer of a puzzle, without delving into an in-depth analysis of the LLMs' reasoning chains (such as where they falter) or providing any finer metrics to evaluate them. Since LLMs may rely on simple heuristics or artifacts to predict the final answer, it is crucial to evaluate the generated reasoning chain beyond overall correctness measures, for accurately evaluating the reasoning abilities of LLMs. To this end, we first develop GridPuzzle, an evaluation dataset comprising of 274 grid-based puzzles with different complexities. Second, we propose a new error taxonomy derived from manual analysis of reasoning chains from LLMs including GPT-4, Claude-3, Gemini, Mistral, and Llama-2. Then, we develop a LLM-based framework for large-scale subjective evaluation (i.e., identifying errors) and an objective metric, PuzzleEval, to evaluate the correctness of reasoning chains. Evaluating reasoning chains from LLMs leads to several interesting findings. We further show that existing prompting methods used for enhancing models' reasoning abilities do not improve performance on GridPuzzle. This highlights the importance of understanding fine-grained errors and presents a challenge for future research to enhance LLMs' puzzle-solving abilities by developing methods that address these errors",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xIowecGhF3": {
    "title": "LLM-based Affective Text Generation Quality Based on Different Quantization Values",
    "volume": "review",
    "abstract": "Large language models in Natural Language Processing (NLP) exhibit a remarkable capacity for tasks such as language generation, translation, and contextual comprehension. In order to achieve these results, the model uses a large number of parameters, requiring a significant number of computational resources for training or utilization. Reducing the precision bits makes the models smaller, resulting in fewer computational resources needed to use the models, at the cost of lowering overall accuracy. This paper addresses the trade-off between different quantization values, GPU RAM utilization, and text quality in affective text generation (e.g., ``I really enjoy running in the snow-covered forest''). To evaluate, we use an emotion classifier and ten seed prompts to generate affective text. We test three setups of precision bits (8, 16, and 32) across two open weight language models. Our findings demonstrate that bit reductions leads to memory savings, achieving a reduction of 76 \\%. However, this optimization comes with a trade-off, leading to a decrease of up to 10 pp in F$_1$ score for larger models and an increase of 10 pp for smaller models, along with roughly double the inference time. In terms of text quality, larger models at lower quantization levels generally outperform smaller, higher-precision models -- while requiring similar memory",
    "checked": false,
    "id": "a48a3cfde9e9a6f02821ea28698012e4d3e1cd73",
    "semantic_title": "qaq: quality adaptive quantization for llm kv cache",
    "citation_count": 8,
    "authors": []
  },
  "https://openreview.net/forum?id=frpq5dUxhW": {
    "title": "Robust Text Classification: Analyzing Prototype-Based Networks",
    "volume": "review",
    "abstract": "Downstream applications often require text classification models to be accurate and robust. While the accuracy of the state-of-the-art Language Models (LMs) approximates human performance, they often exhibit a drop in performance on noisy data found in the real world. This lack of robustness can be concerning, as even small perturbations in the text, irrelevant to the target task, can cause classifiers to incorrectly change their predictions. A potential solution can be the family of Prototype-Based Networks (PBNs) that classifies examples based on their similarity to prototypical examples of a class (prototypes) and has been shown to be robust to noise for computer vision tasks. In this paper, we study whether the robustness properties of PBNs transfer to text classification tasks under both targeted and static adversarial attack settings. Our results show that PBNs, as a mere architectural variation of vanilla LMs, offer more robustness compared to vanilla LMs under both targeted and static settings. We showcase how PBNs' interpretability can help us to understand PBNs' robustness properties. Finally, our ablation studies reveal the sensitivity of PBNs' robustness to how strictly clustering is done in the training phase, as tighter clustering results in less robust PBNs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UgDosMbD7E": {
    "title": "LAiW: A Chinese Legal Large Language Models Benchmark",
    "volume": "review",
    "abstract": "General and legal domain LLMs have demonstrated strong performance in various tasks of LegalAI. However, their current evaluations lack alignment with the fundamental logic of legal reasoning, the legal syllogism. This hinders trust and understanding from legal experts. To bridge this gap, we introduce LAiW, the first Chinese legal LLM benchmark structured around the legal syllogism. We evaluate legal LLMs across three levels of capability, each reflecting a progressively more complex stage of legal syllogism: fundamental information retrieval, legal principle inference, and advanced legal applications, and encompassing a wide range of tasks in different legal scenarios. Our automatic evaluation reveals that LLMs, despite their ability to answer complex legal questions, lack the inherent logical processes of the legal syllogism. This limitation poses a barrier to acceptance by legal professionals. Furthermore, manual evaluation with legal experts confirms this issue and highlights the importance of pre-training to enhance the legal syllogism of LLMs. Future research may prioritize addressing this gap to unlock the full potential of LLMs in legal applications",
    "checked": false,
    "id": "c96b62643d08afa7cb852b7371c08ddc2a86b080",
    "semantic_title": "laiw: a chinese legal large language models benchmark a technical report",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5x6rnuzzUy": {
    "title": "Unsupervised Human Preference Learning",
    "volume": "review",
    "abstract": "Large language models demonstrate impressive reasoning abilities but struggle to provide personalized content due to their lack of individual user preference information. Existing methods, such as in-context learning and parameter-efficient fine-tuning, fall short in capturing the complexity of human preferences, especially given the small, personal datasets individuals possess. In this paper, we propose a novel approach utilizing small parameter models as preference agents to generate natural language rules that guide a larger, pre-trained model, enabling efficient personalization. Our method involves a small, local \"steering wheel\" model that directs the outputs of a much larger foundation model, producing content tailored to an individual's preferences while leveraging the extensive knowledge and capabilities of the large model. Importantly, this personalization is achieved without the need to fine-tune the large model. Experimental results on email and article datasets, demonstrate that our technique significantly outperforms baseline personalization methods. By allowing foundation models to adapt to individual preferences in a data- and compute-efficient manner, our approach paves the way for highly personalized language model applications",
    "checked": false,
    "id": "02b78ca6de66023924cffe33bae338de144f47fa",
    "semantic_title": "unsupervised domain adaptation for preference learning based speech emotion recognition",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=TMFGQCXTTZ": {
    "title": "Giving Control Back to Models: Enabling Offensive Language Detection Models to Autonomously Identify and Mitigate Biases",
    "volume": "review",
    "abstract": "The rapid development of social media has led to an increase in online harassment and offensive speech, posing significant challenges for effective content moderation. Existing automated detection models often exhibit a bias towards predicting offensive speech based on specific vocabulary, which not only compromises model fairness but also potentially exacerbates biases against vulnerable and minority groups. Addressing these issues, this paper proposes a bias self-awareness and data self-iteration framework for mitigating model biases.This framework aims to \"giving control back to models: enabling offensive language detection models to autonomously identify and mitigate biases\" through bias self-awareness algorithms and self-iterative data augmentation method. Experimental results demonstrate that the proposed framework effectively reduces the false positive rate of models in both in-distribution and out-of-distribution tests, enhances model accuracy and fairness, and shows promising performance improvements in detecting offensive speech on larger-scale datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WVWetUqnk0": {
    "title": "Prompt Engineering for Domain-Specific Geo-spatial Named Entity Disambiguation",
    "volume": "review",
    "abstract": "Despite the scarcity of employing transformer approaches for toponym resolution, this study leverages oral and transcribed text data to address the disambiguation of diverse named entities, including place names such as camps, ghettos, and streets. We utilise generative AI techniques, incorporating prompt engineering, to effectively disambiguate these named entities within geographical contexts. Our methodology aims to demonstrate how leveraging prompt engineering from general large language models (LLMs) can be effectively employed for less commonly addressed topics, such as toponym resolution in the field of Natural Language Processing (NLP). We have evaluated the few-shot chain of thought (COT) prompting approach combining the knowledge base (KB) as a retriever to provide the fewshots required for the reasoning process of LLM. This technique illustrates the efficacy of these advanced approaches in accurately identifying and resolving toponyms in complex textual datasets, thereby contributing valuable insights to the field of geographic information systems and digital humanities",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hmk7Bf6HFg": {
    "title": "$R3$-NL2GQL: A Model Coordination and Knowledge Graph Alignment Approach for NL2GQL",
    "volume": "review",
    "abstract": "While current tasks of converting natural language to SQL (NL2SQL) using Foundation Models have shown impressive achievements, adapting these approaches for converting natural language to Graph Query Language (NL2GQL) encounters hurdles due to the distinct nature of GQL compared to SQL, alongside the diverse forms of GQL. Moving away from traditional rule-based and slot-filling methodologies, we introduce a novel approach, $R^3$-NL2GQL, integrating both small and large Foundation Models for ranking, rewriting, and refining tasks. This method leverages the interpretative strengths of smaller models for initial ranking and rewriting stages, while capitalizing on the superior generalization and query generation prowess of larger models for the final transformation of natural language queries into GQL formats. Addressing the scarcity of datasets in this emerging field, we have developed a bilingual dataset, sourced from graph database manuals and selected open-source Knowledge Graphs (KGs). Our evaluation of this methodology on this dataset demonstrates its promising efficacy and robustness",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eQiQOOJ2OR": {
    "title": "LexMatcher: Dictionary-centric Data Curation for LLM-based Machine Translation",
    "volume": "review",
    "abstract": "The fine-tuning of open-source large language models (LLMs) for machine translation has recently received considerable attention, marking a shift towards data-centric research from traditional neural machine translation. However, the area of data collection for instruction fine-tuning in machine translation remains relatively underexplored. In this paper, we present LexMatcher, a simple yet effective method for data curation, the design of which is driven by the coverage of senses found in bilingual dictionaries. The construction process comprises data retrieval from an existing corpus and data augmentation that supplements the infrequent senses of polysemous words. Utilizing LLaMA2 as our base model, our approach outperforms the established baselines on the WMT2022 test sets and also exhibits remarkable performance in tasks related to word sense disambiguation and specialized terminology translation. These results underscore the effectiveness of LexMatcher in enhancing LLM-based machine translation",
    "checked": false,
    "id": "b5c70c2f9ae398b2458e1cf79cbf75d6131cfe6c",
    "semantic_title": "lexmatcher: dictionary-centric data collection for llm-based machine translation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ft1N1XC7EK": {
    "title": "Counterfactual Debating with Preset Stances for Hallucination Elimination of LLMs",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) excel in various natural language processing tasks but struggle with hallucination issues. Existing solutions have considered utilizing LLMs' inherent reasoning abilities to alleviate hallucination, such as self-correction and diverse sampling methods. However, these methods often overtrust LLMs' initial answers due to inherent biases. The key to alleviating this issue lies in overriding LLMs' inherent biases for answer inspection. To this end, we propose a CounterFactual Multi-Agent Debate (CFMAD) framework. CFMAD presets the stances of LLMs to override their inherent biases by compelling LLMs to generate justifications for a predetermined answer's correctness. The LLMs with different predetermined stances are engaged with a skeptical critic for counterfactual debate on the rationality of generated justifications. Finally, the debate process is evaluated by a third-party judge to determine the final answer. Extensive experiments on four datasets of three tasks demonstrate the superiority of CFMAD over existing methods",
    "checked": true,
    "id": "53dcdf3c6e0640bef458f97332063bbf7389721b",
    "semantic_title": "counterfactual debating with preset stances for hallucination elimination of llms",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=373APLOCkq": {
    "title": "Increasing the Difficulty of Automatically Generated Questions via Reinforcement Learning with Synthetic Preference",
    "volume": "review",
    "abstract": "The demand for high-quality question-answering (QA) datasets has surged with the proliferation of language models and conversational agents in various emerging domains. As these models become ever more capable, the possibility of applying them to more challenging tasks is growing. Manual dataset annotation is costly and time-consuming, necessitating a more efficient approach. Automatically generated questions often suffer from a lack of quality or difficulty; hence, we propose a methodology to increase the difficulty of automatically generated questions using synthetic preference data, derived from SQuAD, to fine tune a question generation model using reinforcement learning. We empirically show an improvement in question difficulty over a supervised-finetuned model with minimal impact on question validity and perform an extensive error analysis. We believe our methodology provides a feasible approach to creating high quality synthetic datasets in emerging domains",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AuEHTm0CDy": {
    "title": "Chain-of-Discussion: A Multi-Model Framework for Complex Evidence-Based Question Answering",
    "volume": "review",
    "abstract": "Open-ended question answering requires models to find appropriate evidence to form well-reasoned, comprehensive and helpful answers. In practical applications, models also need to engage in extended discussions on potential scenarios closely relevant to the question. With augmentation of retrieval module, open-source Large Language Models~(LLMs) can produce coherent answers often with different focuses, but are still sub-optimal in terms of reliable evidence selection and in-depth question analysis. In this paper, we propose a novel Chain-of-Discussion framework to leverage the synergy among multiple open-source LLMs aiming to provide *more correct* and *more comprehensive* answers for open-ended QA, although they are not strong enough individually. Our experiments show that discussions among multiple LLMs play a vital role in enhancing the quality of answers. We will release our data and code for further research",
    "checked": true,
    "id": "12fa32d4ba0da26372747eaff7b34f353e26e838",
    "semantic_title": "chain-of-discussion: a multi-model framework for complex evidence-based question answering",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=wf1WhsmwFJ": {
    "title": "``It takes two to tango\": A Combination of Closed-Domain and Open-Domain Few-Shot Prompting for Claim Verification",
    "volume": "review",
    "abstract": "The widespread use of social media platforms has resulted in the swift dissemination of misinformation and fake news, creating a critical need for the development of computational models for automated fact-checking. Existing work on claim verification mainly relies on supervised learning from manually annotated claim-evidence pairs, which is resource-intensive and prone to biases, limiting their generalization across domains. To address this gap, we investigate zero-shot domain adaptation for claim verification, where no labeled training data is available for the target domain. We propose a hybrid approach that combines utilizing labeled training data from a source domain via in-context learning, along with topically relevant contexts from target document collections such as Wikipedia by means of RAG. We conduct experiments to evaluate zero-shot domain adaptation of claim verification for three target domains, namely climate change, scientific publications, and COVID-19 with the training set of the FEVER dataset as the source domain. We find that our proposed approach outperforms supervised models for domain adaptation, several LLM prompting-based models including zero-shot, and few-shot prompting from the source domain, and an RAG-based approach over a target collection of Wikipedia",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DgC6HolAhm": {
    "title": "What if...?: Thinking Counterfactual Keywords Helps to Mitigate Hallucination in Large Multi-modal Models",
    "volume": "review",
    "abstract": "This paper presents a way of enhancing the reliability of Large Multi-modal Models (LMMs) in addressing hallucination, where the models generate cross-modal inconsistent responses. Without additional training, we propose Counterfactual Inception, a novel method that implants counterfactual thinking into LMMs using self-generated counterfactual keywords. Our method is grounded in the concept of counterfactual thinking, a cognitive process where human considers alternative realities, enabling more extensive context exploration. Bridging the human cognition mechanism into LMMs, we aim for the models to engage with and generate responses that span a wider contextual scene understanding, mitigating hallucinatory outputs. We further introduce Plausibility Verification Process (PVP), a simple yet robust keyword constraint that effectively filters out sub-optimal keywords to enable the consistent triggering of counterfactual thinking in the model responses. Comprehensive analyses across various LMMs, including both open-source and proprietary models, corroborate that counterfactual thinking significantly reduces hallucination and helps to broaden contextual understanding based on true visual clues",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TNOnM4CQsl": {
    "title": "RAGAR, Your Falsehood Radar: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models",
    "volume": "review",
    "abstract": "The escalating challenge of misinformation, particularly in political discourse, requires advanced fact-checking solutions; this is even clearer in the more complex scenario of multimodal claims. We tackle this issue using a multimodal large language model in conjunction with retrieval-augmented generation (RAG), and introduce two novel reasoning techniques: Chain of RAG (CoRAG) and Tree of RAG (ToRAG). They fact-check multimodal claims by extracting both textual and image content, retrieving external information, and reasoning subsequent questions to be answered based on prior evidence. We achieve a weighted F1-score of 0.85, surpassing a baseline reasoning technique by 0.14 points. Human evaluation confirms that the vast majority of our generated fact-check explanations contain all information from gold standard data",
    "checked": true,
    "id": "f89ed27318cb930ae884af0c62be37f0355571b5",
    "semantic_title": "ragar, your falsehood radar: rag-augmented reasoning for political fact-checking using multimodal large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QZKn0P5dAE": {
    "title": "Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning",
    "volume": "review",
    "abstract": "Efficient fine-tuning plays a fundamental role in modern large models, with low-rank adaptation emerging as a particularly promising approach. However, the existing variants of LoRA are hampered by limited expressiveness, a tendency to overfit, and sensitivity to hyperparameter settings. This paper presents LoRA Slow Cascade Learning (LoRASC), an innovative technique designed to enhance LoRA's expressiveness and generalization capabilities while preserving its training efficiency. Our approach augments expressiveness through a cascaded learning strategy that enables a mixture-of-low-rank adaptation, thereby increasing the model's ability to capture complex patterns. Additionally, we introduce a slow-fast update mechanism and cascading noisy tuning to bolster generalization. The extensive experiments on various language and vision datasets, as well as robustness benchmarks, demonstrate that the proposed method not only significantly outperforms existing baselines, but also mitigates overfitting, enhances model stability, and improves OOD robustness",
    "checked": true,
    "id": "2ca52ea75fc02a3f08988794241cad9e30444db4",
    "semantic_title": "expressive and generalizable low-rank adaptation for large models via slow cascaded learning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=djmJmRxHd4": {
    "title": "CoCoST: Automatic Complex Code Generation with Online Searching and Correctness Testing",
    "volume": "review",
    "abstract": "Large Language Models have revolutionized code generation ability by converting natural language descriptions into executable code. However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and lack of supplementary contents. To address these challenges, we introduce the CoCoST framework, which enhances complex code generation by online searching for more information with planned queries and correctness testing for code refinement. Moreover, CoCoST serializes the complex inputs and outputs to improve comprehension and generates test cases to ensure the adaptability for real-world applications. CoCoST is validated through rigorous experiments on the DS-1000 and ClassEval datasets. Experimental results show that CoCoST substantially improves the quality of complex code generation, highlighting its potential to enhance the practicality of LLMs in generating complex code",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mX0QrIco2B": {
    "title": "A Retrieval Augmentation Approach for Aligning to Pluralistic Values",
    "volume": "review",
    "abstract": "Aligning LLM outputs to human preferences and values is important for reducing harms of AI deployments. However, human values are pluralistic with different population groups and communities having potentially conflicting preferences. Existing fine-tuning and prompting approaches have primarily focused around alignment towards shared values. In this paper, we propose a new approach for pluralistic alignment that uses retrieval-based in-context examples to augment alignment prompts. We introduce a framework, SPICA, consisting of three components to facilitate this: ``scenario banks'', group-informed retrieval measures, and contrastive prompts. We evaluate SPICA with human participants reflecting groups with different values, and find that SPICA outperforms relevance metrics like semantic similarity, selecting few-shot examples that better match group preferences (22.1\\% lower RMSE). In an end-to-end setting, we also find that SPICA produces more preferable responses when explicitly aligning to group preferences (+0.07 / 5-point scale)",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=24MpT2xc5X": {
    "title": "LM2: A Simple Society of Language Models Solves Complex Reasoning",
    "volume": "review",
    "abstract": "Despite demonstrating emergent reasoning abilities, Large Language Models (LLMS) often lose track of complex, multi-step reasoning. Existing studies show that providing guidance via decomposing the original question into multiple subproblems elicits more robustness in LLM reasoning -- a decomposer generates the subproblems, and a solver solves each of these subproblems. However, these techniques fail to accommodate coordination between the decomposer and the solver modules (either in a single model or different specialized ones) -- the decomposer does not keep track of the ability of the solver to follow the decomposed reasoning. In this paper, we propose LM2 to address these challenges. LM2 modularizes the decomposition, solution, and verification into three different language models. The decomposer module identifies the key concepts necessary to solve the problem and generates step-by-step subquestions according to the reasoning requirement. The solver model generates the solution to the subproblems that are then checked by the verifier module; depending upon the feedback from the verifier, the reasoning context is constructed using the subproblems and the solutions. These models are trained to coordinate using policy learning. Exhaustive experimentation suggests the superiority of LM2 over existing methods on in- and out-domain reasoning problems, outperforming the best baselines by 8.1% on MATH, 7.71% on JEEBench, and 9.7% on MedQA problems",
    "checked": true,
    "id": "448c54a59b18b6eada98be058d42378891e211e6",
    "semantic_title": "lm2: a simple society of language models solves complex reasoning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VkuIeJNrVM": {
    "title": "Finding Safety Neurons in Large Language Models",
    "volume": "review",
    "abstract": "Large language models (LLMs) excel in various capabilities but also pose safety risks such as generating harmful content and misinformation, even after safety alignment. In this paper, we explore the inner mechanisms of safety alignment from the perspective of mechanistic interpretability, focusing on identifying and analyzing *safety neurons* within LLMs that are responsible for safety behaviors. We propose generation-time activation contrasting to locate these neurons and dynamic activation patching to evaluate their causal effects. Experiments on multiple recent LLMs show that: (1) Safety neurons are sparse and effective. We can restore $90$\\% safety performance with intervention only on about $5$\\% of all the neurons. (2) Safety neurons encode transferrable mechanisms. They exhibit consistent effectiveness on different red-teaming datasets. The finding of safety neurons also interprets ''alignment tax''. We observe that the identified key neurons for safety and helpfulness significantly overlap, but they require different activation patterns of the shared neurons. Furthermore, we demonstrate an application of safety neurons in detecting unsafe outputs before generation. Our findings may promote further research on understanding LLM alignment. The source codes will be publicly released to facilitate future research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0KEarh7j3Q": {
    "title": "DPPA: Merging Large Language Model using Dynamic Pruning and Partition Amplification",
    "volume": "review",
    "abstract": "Model merging aims to combine models with different capabilities into a single unified model, providing multiple capabilities without the necessity of retraining with the original training data. However, as distinctions between fine-tuned and base models grow, especially for large language models, current methods suffer significant performance drops, hindering true multi-domain capabilities. In this study, we propose a two-stage method, called Dynamic Pruning and Partition Amplification (DPPA), to address the challenge of merging models with significant distinctions. First, we introduce Dynamic Pruning (DP) to discover significant parameters and remove redundant ones. Subsequently, we propose Dynamic Partition Amplification (DPA) to restore the capability in the domain. Experimental results demonstrate that our approach performs outstandingly, improving model merging performance by almost 20\\%",
    "checked": false,
    "id": "08920921ce6f4efe0dd92f6005a755b07d4ce760",
    "semantic_title": "dppa: pruning method for large language model to model merging",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=26QCPvQ0hg": {
    "title": "Prefix-VAE: Efficient and Consistent Short-Text Topic Modeling with LLMs",
    "volume": "review",
    "abstract": "Topic models are compelling methods for discovering latent semantics in a document collection. However, it assumes that a document has sufficient co-occurrence information to be effective. However, in short texts, co-occurrence information is minimal, which results in feature sparsity in document representation. Therefore, existing topic models- whether probabilistic or neural- mostly struggle to mine patterns from them to generate coherent topics. In this paper, we first explore the capability of large language models (LLMs) to generate longer texts from shorter ones before applying them to traditional topic modeling. To further improve the efficiency and solve the problem of the semantic inconsistency from LLM-generated texts, we propose to use prefix tuning to train a smaller language model coupled with a variational autoencoder for short-text topic modeling. Extensive experiments on multiple real-world datasets under extreme data sparsity scenarios show that our models can generate high-quality topics that outperform state-of-the-art models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AoC7R3yrZJ": {
    "title": "M$^{2}$Chat: Empowering VLM for Multimodal LLM Interleaved Text-Image Generation",
    "volume": "review",
    "abstract": "In this paper, we propose \\textbf{$M^{2}Chat$}, a novel unified multimodal LLM framework for generating interleaved text-image conversation across various scenarios. Specifically, we propose an $M^{3}Adapter$ that efficiently integrates granular low-level visual information and high-level semantic features from multi-modality prompts. Upon the well-aligned fused feature, $M^{3}Adapter$ tailors a learnable gating strategy to balance the model creativity and consistency across various tasks adaptively. Moreover, to further enhance the effectiveness of $M^{3}Adapter$ while preserving the coherence of semantic context comprehension, we introduce a two-stage $M^{3}FT$ fine-tuning strategy. This strategy optimizes disjoint groups of parameters for image-text alignment and visual-instruction respectively. Extensive experiments demonstrate our $M^{2}Chat$ surpasses state-of-the-art counterparts across diverse benchmarks, showcasing its prowess in interleaving generation, storytelling, and multimodal dialogue systems",
    "checked": true,
    "id": "320f152689743a4e977ef85e4e43485033fcc0a0",
    "semantic_title": "m$^{2}$chat: empowering vlm for multimodal llm interleaved text-image generation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=1C1LSKfoyc": {
    "title": "Mixture of Cluster-Conditional LoRA Experts for Vision-Language Instruction Tuning",
    "volume": "review",
    "abstract": "Instruction tuning of Large Vision-language Models (LVLMs) has revolutionized the development of versatile models with zero-shot generalization across a wide range of downstream vision-language tasks. However, the diversity of training tasks of different sources and formats would lead to inevitable task conflicts, where different tasks conflict for the same set of model parameters, resulting in sub-optimal instruction-following abilities. To address that, we propose the Mixture of Cluster-conditional LoRA Experts (MoCLE), a novel Mixture of Experts (MoE) architecture designed to activate the task-customized model parameters based on the instruction clusters. A separate universal expert is further incorporated to improve generalization capabilities of MoCLE for novel instructions. Extensive experiments on InstructBLIP and LLaVA demonstrate the effectiveness of MoCLE",
    "checked": true,
    "id": "2d4a853affeb0b164fc1134df612aea658f36459",
    "semantic_title": "mixture of cluster-conditional lora experts for vision-language instruction tuning",
    "citation_count": 37,
    "authors": []
  },
  "https://openreview.net/forum?id=E05bFZcUQG": {
    "title": "Data in Formation: Structuring Data to Solve Linguistic Analogical Tasks",
    "volume": "review",
    "abstract": "This study explores the impact of structured synthetic data on the performance of linguistic tasks in limited data or low-quality data scenarios. Using Blackbird Language Matrices (BLMs), linguistic analogues of Raven's Progressive Matrices, as a case study task, we explore how data size and structure influence task solving. This multiple-choice puzzle consists of structured contexts and answer sets of sentences. We devise a context that has two properties: analogical internal structure and implicit annotation of properties needed to find the solution. The answer set elicits contrastive learning and supports careful error analysis. We also propose a method to semi-automatically create synthetic data for the BLM task. Our experiments show that structured data improves performance even with small training sizes. They also show that both analogically-structured contexts and implicit annotation are useful. These results suggest that careful data structuration of small amount of data can be used to mitigate the typical resource demands in NLP tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7O4Bpy8MKj": {
    "title": "Are Large Language Models Meta Reasoners?",
    "volume": "review",
    "abstract": "In this paper, we introduce Meta-Reasoning Prompting (MRP), a novel approach inspired by human meta-reasoning to enhance the flexibility and generality of large language models (LLMs). Traditional in-context learning techniques, such as Tree-of-Thoughts, show promise but lack consistent state-of-the-art performance across diverse tasks due to their specialized nature. MRP addresses this limitation by dynamically selecting and applying different reasoning methods based on the specific requirements of each task, optimizing both performance and computational efficiency. The MRP framework operates in two phases: initially, the LLM selects the most appropriate reasoning method using task input cues and objective descriptions of available methods; subsequently, it applies the chosen method to complete the task. This dynamic strategy mirrors human meta-reasoning, allowing the model to excel in a wide range of problem domains. We evaluate the effectiveness of MRP through comprehensive benchmarks. The results demonstrate that MRP achieves or approaches state-of-the-art performance across these diverse tasks. MRP represents a significant advancement in enabling LLMs to autonomously select suitable reasoning methods, enhancing their ability to handle diverse and complex problem domains efficiently",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rCMNqF8Oeq": {
    "title": "CASE: Efficient Curricular Data Pre-training for Building Assistive Psychology Expert Models",
    "volume": "review",
    "abstract": "The limited availability of psychologists necessitates efficient identification of individuals requiring urgent mental healthcare. This study explores the use of Natural Language Processing (NLP) pipelines to analyze text data from online mental health forums used for consultations. By analyzing forum posts, these pipelines can flag users who may require immediate professional attention. A crucial challenge in this domain is data privacy and scarcity. To address this, we propose utilizing readily available curricular texts used in institutes specializing in mental health for pre-training the NLP pipelines. This helps us mimic the training process of a psychologist. Our work presents CASE-BERT that flags potential mental health disorders based on forum text. CASE-BERT demonstrates superior performance compared to existing methods, achieving an f1 score of 0.91 for Depression and 0.88 for Anxiety, two of the most commonly reported mental health disorders. Our code is publicly available \\footnote{https://anonymous.4open.science/r/CASE-FB26/README.md}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LU91EkeNru": {
    "title": "FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) with chain-of-thought (COT) prompting have demonstrated impressive abilities on simple nature language inference tasks. However, they tend to perform poorly on Multi-hop Question Answering (MHQA) tasks due to several challenges, including hallucination, error propagation and limited context length. We propose a prompt method Finite State Machine (FSM) to enhance the reasoning capabilities of LLM for complex tasks in addition to improved effectiveness and trustworthiness. Different from chain-of-thought (COT) methods, FSM addresses MHQA by iteratively decomposing a question into multi-turn sub-questions, and self-correcting in time, improving the accuracy of answers in each step. Specifically, FSM addresses one sub-question at a time and decides on the next step based on its current result and state, in an automaton-like format. Experiments on benchmarks show the effectiveness of our method. Although our method performs on par with the baseline on relatively simpler datasets, it excels on challenging datasets like Musique. Moreover, this approach mitigates the hallucination phenomenon, wherein the correct final answer can be recovered despite errors in the intermediate reasoning steps. Furthermore, our method improves LLMs' ability to follow specified output format requirements, significantly reducing the difficulty of answer interpretation and the need for reformatting",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sV75BwXVtt": {
    "title": "Major Entity Identification: A Generalizable Alternative to Coreference Resolution",
    "volume": "review",
    "abstract": "The limited generalization of coreference resolution (CR) models has been a major bottleneck in the task's broad application. Prior work has identified annotation differences, especially for mention detection, as one of the main reasons for the generalization gap and proposed using additional annotated target domain data. Rather than relying on this additional annotation, we propose an alternative formulation of the CR task, Major Entity Identification (MEI), where we: (a) assume the target entities to be specified in the input, and (b) limit the task to only the frequent entities. Through extensive experiments, we demonstrate that MEI models generalize well across domains on multiple datasets with supervised models and LLM-based few-shot prompting. Additionally, the MEI task fits the classification framework, which enables the use of classification-based metrics that are more robust than the current CR metrics. Finally, MEI is also of practical use as it allows a user to search for all mentions of a particular entity or a group of entities of interest",
    "checked": true,
    "id": "eecc71949047e5d69c0fdc41911fd4583b7e64b2",
    "semantic_title": "major entity identification: a generalizable alternative to coreference resolution",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GP5hWLoxBv": {
    "title": "Scaling Behavior for Numeral System: Tokenize Your Numbers into $1$-digit",
    "volume": "review",
    "abstract": "Though Large Language Models (LLMs) have shown remarkable abilities in mathematics reasoning, they are still struggling with performing numeric operations accurately, such as addition and multiplication. Numbers can be tokenized into tokens in various ways by different LLMs and affect the numeric operations performance. Currently, there are two representatives: 1) Tokenize into $1$-digit, and 2) Tokenize into $1\\sim 3$ digit. The difference is roughly equivalent to using different numeral systems (namely base $10$ or base $10^{3}$). In light of this, we study the scaling behavior of different numeral systems in the context of transformer-based large language models. We empirically show that a base $10$ system is consistently more data-efficient than a base $10^{2}$ or $10^{3}$ system across training data scale, model sizes under from-scratch training settings, while different number systems have very similar performances when fine-tuned. Through thorough analysis and experiments, we conclude that tokenizing numbers into $1$-digit is more favorable for LLMs in numerical operations. Additionally, we reveal \\textit{extrapolation} behavior patterns on addition and multiplication that sheds light on the mechanism learnt by the models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LWGnAptrul": {
    "title": "Multi-Loss Fusion: Angular and Contrastive Integration for Machine-Generated Text Detection",
    "volume": "review",
    "abstract": "Modern natural language generation (NLG) systems have led to the development of synthetic human-like open-ended texts, posing concerns as to who the original author of a text is. To address such concerns, we introduce DeB-Ang: the utilisation of a custom DeBERTa model with angular loss and contrastive loss functions for effective class separation in neural text classification tasks. We expand the application of this model on binary machine-generated text detection and multi-class neural authorship attribution. We demonstrate improved performance on many benchmark datasets whereby the accuracy for machine-generated text detection was increased by as much as 38.04\\% across all datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=il0rzVS0Wk": {
    "title": "When Parts are Greater Than Sums: Individual LLM Components Can Outperform Full Models",
    "volume": "review",
    "abstract": "This paper studies in-context learning (ICL) by decomposing the output of large language models into the individual contributions of attention heads and MLPs (components). We observe curious components: good-performing ones that individually do well on a classification task, even when the model performs poorly; bad-performing ones that do much worse than chance; and label-biased components that always predict the same label. We find that component accuracies are well-correlated across different demonstration sets and perturbations of prompt templates, even when the full-model accuracy varies greatly. Based on our findings, we propose component reweighting, which learns to linearly re-scale the component activations from a few labeled examples. Given 24 labeled examples, our method improves by an average of 6.0% accuracy points over 24-shot ICL across 8 tasks on Llama-2-7B. Overall, this paper both enriches our understanding of ICL and provides a practical method for improvement by examining model internals",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ar6EquF1PB": {
    "title": "Inverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models Without Preference Data",
    "volume": "review",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has proven effective in aligning large language models with human intentions, yet it often relies on complex methodologies like Proximal Policy Optimization (PPO) that require extensive hyper-parameter tuning and present challenges in sample efficiency and stability. In this paper, we introduce Inverse-Q*, an innovative framework that transcends traditional RL methods by optimizing token-level reinforcement learning without the need for additional reward or value models. Inverse-Q* leverages direct preference optimization techniques but extends them by estimating the conditionally optimal policy directly from the model's responses, facilitating more granular and flexible policy shaping. Our approach reduces reliance on human annotation and external supervision, making it especially suitable for low-resource settings. We present extensive experimental results demonstrating that Inverse-Q* not only matches but potentially exceeds the effectiveness of PPO in terms of convergence speed and the alignment of model responses with human preferences. Our findings suggest that Inverse-Q* offers a practical and robust alternative to conventional RLHF approaches, paving the way for more efficient and adaptable model training approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CD1fVpd3tr": {
    "title": "Delta-LoRA: Fine-Tuning High-Rank Parameters with the Delta of Low-Rank Matrices",
    "volume": "review",
    "abstract": "In this paper, we present \\textbf{Delta-LoRA}, which is a novel parameter-efficient approach to fine-tune large language models (LLMs). In contrast to LoRA and other low-rank adaptation methods such as AdaLoRA, Delta-LoRA not only updates the low-rank matrices $A$ and $B$, but also propagate the learning to the pre-trained weights $W$ via updates utilizing the delta of the product of two low-rank matrices ($A^{(t+1)}B^{(t+1)} - A^{(t)}B^{(t)}$). Such a strategy effectively addresses the limitation that the incremental update of low-rank matrices is inadequate for learning representations capable for downstream tasks. Moreover, as the update of $W$ does not need to compute the gradients of $W$ and store their momentums, Delta-LoRA shares comparable memory requirements and computational costs with LoRA. Extensive experiments show that Delta-LoRA significantly outperforms existing low-rank adaptation methods. We further support these results with comprehensive analyses that underscore the effectiveness of Delta-LoRA",
    "checked": true,
    "id": "587d0627031c165985c69036f62d5d21fc38e3f7",
    "semantic_title": "delta-lora: fine-tuning high-rank parameters with the delta of low-rank matrices",
    "citation_count": 24,
    "authors": []
  },
  "https://openreview.net/forum?id=IFlWg1wfiu": {
    "title": "SafetyQuizzer: Evaluating the Safety of LLMs in a More Sustained Manner",
    "volume": "review",
    "abstract": "As the expansion of application of Large Language Models (LLMs), concerns about the safety of LLMs have grown among researchers. Numerous previous studies demonstrated the potential risks of LLMs to generate harmful contents and proposed various safety assessment benchmarks aimed at evaluating the safety risks. However, the evaluation questions in current benchmarks are not only too straightforward to be easily rejected by target LLMs, but also difficult to update questions with practical significance due to their lack of correlation with real-world events, thereby making these benchmarks challenging to sustainably apply in continuous evaluaton tasks. To address these limitations, we propose SafetyQuizzer, a question generation framework for evaluating the safety of LLMs in a more sustained manner. SafetyQuizzer leverages fine-tuned LLM and jailbreaking attack templates to generate weakly offensive questions and so reduces the decline rate. Additionally, by employing retrieval-augmented generation, SafetyQuizzer incorporates the latest events into evaluation questions, overcoming the challenge of question updates and introducing a new dimension of event relevance to enhance the quality of evaluation questions. Our experiments show that evaluation questions generated by SafetyQuizzer significantly reduce the decline rate compared to other benchmarks while still maintaining comparable attack success rate. Warning: this paper contains examples that may be offensive or upsetting",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xv4CnSdNJM": {
    "title": "Distilling Opinions at Scale: Incremental Opinion Summarization using XL-OPSUMM",
    "volume": "review",
    "abstract": "Opinion summarization in e-commerce encapsulates the collective views of numerous users about a product based on their reviews. Typically, a product on an e-commerce platform has thousands of reviews, each review comprising around 10-15 words. While Large Language Models (LLMs) have shown proficiency in summarization tasks, they struggle to handle such a large volume of reviews due to context limitations. To address this, we propose a scalable framework called XL-OPSUMM, that generates summaries incrementally with the help of an Aspect Dictionary (Refer to Section 3). However, the existing test set, AMASUM, has only 560 reviews per product on average. Due to the lack of a test set with thousands of reviews, we created a new test set called XL-FLIPKART by gathering data from the Flipkart website and generating summaries using GPT-4. Through various automatic evaluations and extensive analysis, we evaluated the framework's efficiency on two datasets, AMASUM and Xl-Flipkart. Experimental results show that our framework, XL-OPSUMM, powered by Llama-3-8B-8k, achieves an average ROUGE-1 F1 gain of 4.38% and a ROUGE-L F1 gain of 3.70% over the next best-performing model",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CTFm5LlSnG": {
    "title": "Automatically Enhanced Instruction-following Capabilities of Large Language Models via Execution Feedback",
    "volume": "review",
    "abstract": "One core capability of large language models (LLMs) is to follow natural language instructions. However, the issue of automatically constructing high-quality training data to enhance the complex instruction-following abilities of LLMs without manual annotation remains unresolved. In this paper, we introduce AutoIF, the first scalable and reliable method for automatically generating instruction-following training data. AutoIF transforms the validation of instruction-following data quality into code verification, requiring LLMs to generate instructions, the corresponding code to check the correctness of the instruction responses, and unit test samples to verify the code's correctness. Then, execution feedback-based rejection sampling can generate data for Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) training. AutoIF achieves significant improvements across three training algorithms, SFT, Offline DPO, and Online DPO, when applied to the top open-source LLMs, Qwen2 and Llama3, in self-alignment and strong-to-weak distillation settings",
    "checked": false,
    "id": "50650e66ce7c454595862aac70c2a3e9dde23387",
    "semantic_title": "self-play with execution feedback: improving instruction-following capabilities of large language models",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=xsxmKbOA5f": {
    "title": "Ladder: A Model-Agnostic Framework Boosting LLM-based Machine Translation to the Next Level",
    "volume": "review",
    "abstract": "General-purpose Large Language Models (LLMs) like GPT-4 have achieved remarkable advancements in machine translation (MT) by leveraging extensive web content. On the other hand, translation-specific LLMs are built by pre-training on domain-specific monolingual corpora and fine-tuning with human-annotated translation data. Despite the superior performance, these methods either demand an unprecedented scale of computing and data or substantial human editing and annotation efforts. In this paper, we develop Ladder, a novel model-agnostic and cost-effective tool to refine the performance of general LLMs for MT. Ladder is trained on pseudo-refinement triplets which can be easily obtained from existing LLMs without additional human cost. During training, we propose a hierarchical fine-tuning strategy with an easy-to-hard schema, improving Ladder's refining performance progressively. The trained Ladder can be seamlessly integrated with any general-purpose LLMs to boost their translation performance. By utilizing Gemma-2B/7B as the backbone, Ladder-2B can elevate raw translations to the level of top-tier open-source models (e.g., refining BigTranslate-13B with +6.91 BLEU and +3.52 COMET for XX→En), and Ladder-7B can further enhance model performance to be on par with the state-of-the-art GPT-4. Extensive ablation and analysis corroborate the effectiveness of Ladder in diverse settings. Data and code will be released",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ezz0bOHOhg": {
    "title": "Large Language Models Encode Geoscience Knowledge",
    "volume": "review",
    "abstract": "Large language models (LLMs) have shed light on potential inter-discipline applications to foster scientific discoveries of a specific domain by using artificial intelligence (AI for science, AI4S). In this study, we introduce A Data-centric Recipe for advancing the application of Large Language Models (LLMs) in the realm of geoscience. Leveraging the versatility of LLMs and their potential for interdisciplinary applications, particularly in Artificial Intelligence for Science (AI4S), we propose a methodology to tailor an open-source LLM to the geoscience domain, with potential for broader interdisciplinary use. This involves further pre-training the model with a comprehensive geoscience text corpus and fine-tuning it using a custom instruction tuning dataset. Our efforts culminate in multiple size of LLM specialized for geoscience tasks. Through rigorous evaluation on geoscience examinations and open-domain questions, our model exhibits state-of-the-art performance across a diverse array of Natural Language Processing tasks within the geoscience domain",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6ZKHA0ZgU4": {
    "title": "DDPC: Dual Dynamic Presentation with Contrastive Learning for Robust Temporal Knowledge Graph Completion",
    "volume": "review",
    "abstract": "Temporal knowledge graph completion has made significant progress, but several research gaps persist. This study addresses the challenges of temporal changes by proposing DDP and DDPC, novel dual-perspective learning frameworks that integrate static and temporal knowledge using a dual-layer embedding mechanism and a contrastive learning-enhanced version, respectively. This approach effectively captures both dynamic changes and time-invariant properties of entities and relations, optimizing the completeness and accuracy of information. Additionally, a perturbation learning mechanism is introduced to enhance the model's robustness to anomalous data and noise by simulating data perturbations during training, improving adaptability and stability in changing environments. DDPC achieves state-of-the-art results on multiple standard evaluation datasets, experimentally verifying the effectiveness of the proposed theories and methods. This study contributes to advancing the field of temporal knowledge graph completion by developing an innovative framework that integrates temporal and static perspectives, enhances robustness, and undergoes rigorous evaluations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v9LcSZuTDz": {
    "title": "Sentium: Sentiment Evaluation through Neurosymbolic Taxonomy - an Interpretable and Understandable Model",
    "volume": "review",
    "abstract": "Sentiment analysis has seen rapid progress driven by deep learning, but the opaque black-box nature of these models hinders trustworthy deployment in high-stakes domains where interpretability is crucial. We propose \\textbf{Sentium} (\\textbf{S}entiment \\textbf{E}valuation through \\textbf{N}eurosymbolic \\textbf{T}axonomy, an \\textbf{I}nterpretable and \\textbf{U}nderstandable \\textbf{M}odel), a cognitively-inspired architecture that closely emulates human sentiment comprehension processes. Sentium takes a hybrid approach by combining structured sentiment knowledge with neural models, achieving state-of-the-art performance while maintaining transparency through explicit compositional reasoning over semantic propositions. Compared to state-of-the-art financial language models, Sentium showed substantially lower misclassification rates for predicting true negatives as positive (Sentium=1.97\\%; FLANG-BERT \\citep{shah2022flue} =6.78\\%, FinBERT \\citep{araci2019finbert} =10.17\\%). The code are available at: https://github.com/anonymous-submission",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lRYgIWNbFL": {
    "title": "ValueDCG: Measuring Comprehensive Human Value Understanding Ability of Language Models",
    "volume": "review",
    "abstract": "",
    "checked": true,
    "id": "53898f11fa6bad10a2faf480e741cfc76a020558",
    "semantic_title": "valuedcg: measuring comprehensive human value understanding ability of language models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=uTfn2rGEgl": {
    "title": "MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization",
    "volume": "review",
    "abstract": "RL-based techniques can be employed to search for prompts that, when fed into a target language model, maximize a set of user-specified reward functions. However, in many target applications, the natural reward functions are in tension with one another -- for example, content preservation vs. style matching in style transfer tasks. Current techniques focus on maximizing the average of reward functions, which does not necessarily lead to prompts that achieve balance across rewards -- an issue that has been well-studied in the multi-objective and robust optimization literature. In this paper, we conduct an empirical comparison of several existing multi-objective optimization techniques adapted to this new setting: RL-based discrete prompt optimization. We compare two methods optimizing the volume of the Pareto reward surface and one method that chooses an update direction that benefits all rewards simultaneously. We evaluate performance on two NLP tasks: style transfer and machine translation, each using three competing reward functions. Our experiments demonstrate that multi-objective methods that directly optimize the volume of the Pareto reward surface perform better and achieve a better balance of all rewards than those that attempt to find monotonic update directions",
    "checked": true,
    "id": "564bffb42edb6a24be8b144f22eec97e0579028b",
    "semantic_title": "morl-prompt: an empirical analysis of multi-objective reinforcement learning for discrete prompt optimization",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=bRQEN4N4qo": {
    "title": "The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention",
    "volume": "review",
    "abstract": "Using prompt-based \"diversity interventions\" is a typical way to improve diversity for Text-to-Image models to depict individuals with various racial or gender traits. However, this strategy might result in nonfactual demographic distribution, especially when generating real historical figures. In this work, we propose **DemOgraphic FActualIty Representation (DoFaiR)**, a benchmark to quantify the trade-off between using diversity interventions and preserving demographic factuality in Text-to-Image models. DoFaiR consists of 756 test instances, various diversity prompts, and evaluation metrics to reveal the factuality tax of diversity instructions through an automated, fact-checked, and evidence-supported evaluation pipeline. Experiments with DALLE-3 on DoFaiR unveil that diversity-oriented instructions improve the number of different gender and racial groups in generated images at the cost of accurate historical demographic distributions. To resolve this issue, we propose **Fact-Augmented Intervention** (FAI), which instructs a Large Language Model (LLM) to reflect on factual information about gender and racial compositions of generation subjects in history and incorporate it into the generation context of T2I models. By orienting model generations using the reflected historical truths, FAI remarkably preserves demographic factuality under diversity interventions, while also boosting diversity",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kzYxvGY9au": {
    "title": "AggregHate: An Efficient Aggregative Approach for the Detection of Hatemongers on Social Platforms",
    "volume": "review",
    "abstract": "The automatic detection of online hate speech serves as a crucial step in the detoxification of the online discourse. Moreover, accurate classification can promote a better understanding of the proliferation of hate as a social phenomenon. While most prior work focus on the detection of hateful utterances, we argue that focusing on the user level is as important, albeit challenging. In this paper we consider a multimodal aggregative approach for the detection of hate-mongers, taking into account the potentially hateful texts, user activity, and the user network. We evaluate our methods on three unique datasets X (Twitter), Gab, and Parler showing that a processing a user's texts in her social context significantly improves the detection of hate mongers, compared to previously used text and graph-based methods. Our method can be then used to improve the classification of coded messages, dog-whistling, and racial gas-lighting, as well as inform intervention measures. Moreover, our approach is highly efficient even for very large datasets and networks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TOoUxtY6us": {
    "title": "Intention Analysis Makes LLMs A Good Jailbreak Defender",
    "volume": "review",
    "abstract": "Aligning large language models (LLMs) with human values, particularly in the face of complex and stealthy jailbreak attacks, presents a formidable challenge. In this study, we present a simple yet highly effective defense strategy, i.e., Intention Analysis ($\\mathbb{IA}$). The principle behind $\\mathbb{IA}$ is to trigger LLMs' inherent self-correct and improve ability through a two-stage process: 1) analyzing essential intention of the user input, and 2) providing final policy-aligned response based on the first round conversation. Notably, $\\mathbb{IA}$ is an inference-only method, thus could enhance the safety of LLMs without compromising their helpfulness. Extensive experiments on varying jailbreak benchmarks across ChatGLM, Llama2, Llama3, Vicuna, MPT, DeepSeek, and GPT-3.5 show that $\\mathbb{IA}$ could consistently and significantly reduce the harmfulness in responses (averagely -48.2\\% attack success rate) without compromising the general helpfulness. Encouragingly, with the help of our $\\mathbb{IA}$, Vicuna-7B even outperforms GPT-3.5 in terms of attack success rate. We empirically demonstrate that, to some extent, $\\mathbb{IA}$ is robust to errors in generated intentions. Further analyses present some insights into how $\\mathbb{IA}$ mechanism works and suggest two directions to improve its performance. The code will be released",
    "checked": true,
    "id": "8fd29e810540c40846cddce3cbdf5060cd59fb57",
    "semantic_title": "intention analysis makes llms a good jailbreak defender",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=WGFxKLHIAB": {
    "title": "Vikhr: The Family of Open-Source Instruction-Tuned Large Language Models for Russian",
    "volume": "review",
    "abstract": "There has been a surge in the development of various Large Language Models (LLMs). However, text generation for languages other than English often faces significant challenges, including poor generation quality and the reduced computational performance due to the disproportionate representation of tokens in model's vocabulary. In this work, we address these issues and introduce Vikhr, a new state-of-the-art open-source instruction-tuned LLM designed specifically for the Russian language. ``Vikhr'' refers to the name of the Mistral LLM series and means ``strong gust of wind.'' Unlike previous efforts for Russian that utilize computationally inexpensive LoRA adapters on top of English-oriented models, Vikhr features an adapted tokenizer vocabulary and undergoes the continued pre-training and instruction tuning of all weights. This approach not only enhances the model's performance but also significantly improves its computational and contextual efficiency. The remarkable performance of Vikhr across various Russian-language benchmarks can also be attributed to our efforts in expanding instruction datasets and corpora for continued pre-training. Vikhr not only sets the new state of the art among open-source LLMs for Russian, but even outperforms some proprietary closed-source models on certain benchmarks. The model weights, instruction sets, and code are publicly available",
    "checked": true,
    "id": "c9128e2b411ab8779abd83a7e2ff9ae0af935b33",
    "semantic_title": "vikhr: the family of open-source instruction-tuned large language models for russian",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=c4MnHb4UHb": {
    "title": "Step-by-Step Evaluation of Gender Bias in Large Language Models",
    "volume": "review",
    "abstract": "Large language models (LLMs) tend to internalize and reproduce discriminatory societal biases. A natural language reasoning process provided by Chain-of-Thought (CoT) prompting helps determine whether the LLM is reasoning based on correct grasp. However, it is not clarified whether such information provided by CoT leads to accurately evaluating the LLM's social biases. In this paper, we introduce a benchmark to evaluate gender-related social biases based on the step-by-step process using CoT prompts. We construct the benchmark for an English reasoning task where the LLM is given a list of words comprising feminine, masculine, and gendered occupational words, and is required to count the number of feminine and masculine words. Our CoT prompts require the LLM to explicitly indicate whether each word in the word list is feminine or masculine. Experimental results show that considering both the step-by-step process and predictions of LLMs improves the quality of bias evaluation. Furthermore, despite the simplicity of the task of counting words, our benchmark produces evaluations of gender-related social biases that are comparable to existing human-scratched benchmarks",
    "checked": false,
    "id": "5da06eb3a746932acfe36b81c7c640c3d969ae70",
    "semantic_title": "evaluating gender bias in large language models via chain-of-thought prompting",
    "citation_count": 15,
    "authors": []
  },
  "https://openreview.net/forum?id=0t5MiMx3ji": {
    "title": "Debiasing Transformer Models through Weight Masking: Addressing Gender Confounding Shift in Dementia Detection",
    "volume": "review",
    "abstract": "Deep language models are often described as \"black-box\" systems due to their opaque inference procedures. This presents a challenge in understanding the information they capture, and how it is encoded within transformer networks, raising the possibility that encoded biases may remain undetected. This work addresses confounding bias learned during model fine-tuning, when a pretrained language model is adapted to downstream domains and tasks. Building on previous methodologies, we extend them by proposing the Extended Confounding Filter and the Dual Filter. These methods aim to isolate and address weights within the transformer network that are associated with confounding variables through distinct training phases. We evaluate these methods on the \\textit{DementiaBank} dataset, a first-person narrative dataset that contains language of patients with cognitive impairment and healthy controls. We aim to demonstrate the applicability of the proposed methods in the domain of dementia detection as a means to correct for gender-related disparities in class distribution at training time. Our results show that transformer models can overfit to the subpopulation distribution in the training data. By disrupting the weights associated with known confounders, we show that fairer models can be achieved with reduced prediction bias towards specific subgroups. Moreover, our findings highlight resilience of the model against weights deletion and show a trade-off between model performance in dementia detection and the reduction of disparities across gender groups",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NkXvCeorhW": {
    "title": "AppAgent: Multimodal Agents as Smartphone Users",
    "volume": "review",
    "abstract": "Recent advancements in large language models (LLMs) have led to the creation of intelligent agents capable of performing complex tasks. This paper introduces a novel LLM-based multimodal agent framework designed to operate smartphone applications. Our framework enables the agent to operate smartphone applications through a simplified action space, mimicking human-like interactions such as tapping and swiping. This novel approach bypasses the need for system back-end access, thereby broadening its applicability across diverse apps. Central to our agent's functionality is its innovative learning method. The agent learns to navigate and use new apps either through autonomous exploration or by observing human demonstrations. This process generates a knowledge base that the agent refers to for executing complex tasks across different applications. To demonstrate the practicality of our agent, we conducted extensive testing over 50 tasks in 10 different applications, including social media, email, maps, shopping, and sophisticated image editing tools. The results affirm our agent's proficiency in handling a diverse array of high-level tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0kqZox6BPU": {
    "title": "Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation",
    "volume": "review",
    "abstract": "Distractor generation task focuses on generating incorrect but plausible options for objective questions such as fill-in-the-blank and multiple-choice questions. This task is widely utilized in educational settings across various domains and subjects The effectiveness of these questions in assessments relies on the quality of the distractors, as they challenge examinees to select the correct answer from a set of misleading options. The evolution of artificial intelligence (AI) has transitioned the task from traditional methods to the use of neural networks and pre-trained language models. This shift has established new benchmarks and expanded the use of advanced deep learning methods in generating distractors. This survey explores distractor generation tasks, datasets, methods, and current evaluation metrics for English objective questions, covering both text-based and multi-modal domains. It also evaluates existing AI models and benchmarks and discusses potential future research directions",
    "checked": false,
    "id": "2f949cb7375c7bf8a884d492018d61fceefdb847",
    "semantic_title": "distractor generation for multiple-choice questions: a survey of methods, datasets, and evaluation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=mUmFgGtWni": {
    "title": "Atomic Self-Consistency for Better Long Form Generations",
    "volume": "review",
    "abstract": "Recent work has aimed to improve LLM generations by filtering out hallucinations, thereby improving the precision of the information in responses. Correctness of a long-form response, however, also depends on the recall of multiple pieces of information relevant to the question. In this paper, we introduce Atomic Self-Consistency (ASC), a technique for improving the recall of relevant information in an LLM response. ASC follows recent work, Universal Self-Consistency (USC) in using multiple stochastic samples from an LLM to improve the long-form response. Unlike USC which only focuses on selecting the best single generation, ASC picks authentic subparts from the samples and merges them into a superior composite answer. Through extensive experiments and ablations, we show that merging relevant subparts of multiple samples performs significantly better than picking a single sample. ASC demonstrates significant gains over USC on multiple factoids and open-ended QA datasets - ASQA, QAMPARI, QUEST, ELI5 with ChatGPT and Llama3. Our analysis also reveals untapped potential for enhancing long-form generations using approach of merging multiple samples",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v7s4HVQ9bt": {
    "title": "AutoScraper: A Progressive Understanding Web Agent for Web Scraper Generation",
    "volume": "review",
    "abstract": "Web scraping is a powerful technique that extracts data from websites, enabling automated data collection, enhancing data analysis capabilities, and minimizing manual data entry efforts. Existing methods, wrappers-based methods suffer from limited adaptability and scalability when faced with a new website, while language agents, empowered by large language models (LLMs), exhibit poor reusability in diverse web environments. In this work, we introduce the paradigm of generating web scrapers with LLMs and propose AutoScraper, a two-stage framework that can handle diverse and changing web environments more efficiently. AutoScraper leverages the hierarchical structure of HTML and similarity across different web pages for generating web scrapers. Besides, we propose a new executability metric for better measuring the performance of web scraper generation tasks. We conduct comprehensive experiments with multiple LLMs and demonstrate the effectiveness of our framework. Our work is now open-source",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=COyVDgtnxp": {
    "title": "Simulating Classroom Education with LLM-Empowered Agents",
    "volume": "review",
    "abstract": "Large language models (LLMs) have been employed in various intelligent educational tasks to assist teaching. While preliminary explorations have focused on independent LLM-empowered agents for specific educational tasks, the potential for LLMs within a multi-agent collaborative framework to simulate a classroom with real user participation remains unexplored. In this work, we propose SimClass, a multi-agent classroom simulation framework involving user participation. We recognize representative class roles and introduce a novel class control mechanism for automatic classroom teaching, and conduct user experiments in two real-world courses. Utilizing the Flanders Interactive Analysis System and Community of Inquiry theoretical frame works from educational analysis, we demonstrate that LLMs can simulate traditional classroom interaction patterns effectively while enhancing user's experience. We also observe emergent group behaviors among agents in SimClass, where agents collaborate to create enlivening interactions in classrooms to improve user learning process. We hope this work pioneers the application of LLM-empowered multi-agent systems in virtual classroom teaching",
    "checked": true,
    "id": "a7a4aafe038f0c78b8b5320b537bdd3fb8c2b28d",
    "semantic_title": "simulating classroom education with llm-empowered agents",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=bRXFB375r8": {
    "title": "Smurfs: Leveraging Multiple Proficiency Agents with Context-Efficiency for Tool Planning",
    "volume": "review",
    "abstract": "The emergence of large language models~(LLMs) has opened up unprecedented possibilities for automating complex tasks that are often comparable to human performance. Despite their capabilities, LLMs still encounter difficulties in completing tasks that require high levels of accuracy and complexity due to their inherent limitations in handling multifaceted problems single-handedly. This paper introduces `Smurfs', a cutting-edge multi-agent framework designed to revolutionize the application of LLMs. By seamlessly transforming a conventional LLM into a synergistic multi-agent ensemble, Smurfs can enhance the model's ability to solve complex tasks at no additional cost. This is achieved through innovative prompting strategies that allocate distinct roles within the model, thereby facilitating collaboration among specialized agents and forming an intelligent multi-agent system. Our empirical investigation on both open-ended task of StableToolBench and closed-ended task on HotpotQA showcases Smurfs' superior capability in intricate tool utilization scenarios. Notably, Smurfs outmatches all the baseline methods in both experiments, setting new state-of-the-art performance. Furthermore, through comprehensive ablation studies, we dissect the contribution of the core components of the multi-agent framework to its overall efficacy. This not only verifies the effectiveness of the framework, but also sets a route for future exploration of multi-agent LLM systems",
    "checked": true,
    "id": "4df39291087ea56c5c11a3f5e007c13b523bb97a",
    "semantic_title": "smurfs: leveraging multiple proficiency agents with context-efficiency for tool planning",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eOrss1nk6d": {
    "title": "Scaling Laws for Linear Complexity Language Models",
    "volume": "review",
    "abstract": "The interest in linear complexity models for large language models is on the rise, although their scaling capacity remains uncertain. In this study, we present the scaling laws for linear complexity language models to establish a foundation for their scalability. Specifically, we examine the scaling behaviors of three efficient linear architectures. These include TNL, a linear attention model with data-independent decay; HGRN2, a linear RNN with data-dependent decay; and cosFormer2, a linear attention model without decay. We also include LLaMA as a baseline architecture for softmax attention for comparison. These models were trained with six variants, ranging from 70M to 7B parameters on a 300B-token corpus, and evaluated with a total of 1,376 intermediate checkpoints on various downstream tasks. These tasks include validation loss, commonsense reasoning, and information retrieval and generation. The study consumes over 200k H100/H800 GPU hours and reveals that existing linear complexity language models exhibit similar scaling capabilities as conventional transformer-based models while also demonstrating superior linguistic proficiency and knowledge retention",
    "checked": true,
    "id": "685283f452856d3d70902860e5b0634e695d9a42",
    "semantic_title": "scaling laws for linear complexity language models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=jf5IAH5Ht2": {
    "title": "Take Off the Training Wheels! Progressive In-Context Learning for Effective Alignment",
    "volume": "review",
    "abstract": "Recent studies have explored the working mechanisms of In-Context Learning (ICL). However, they mainly focus on classification and simple generation tasks, limiting their broader application to more complex generation tasks in practice. To address this gap, we investigate the impact of demonstrations on token representations within the practical alignment tasks. We find that the transformer embeds the task function learned from demonstrations into the separator token representation, which plays an important role in the generation of prior response tokens. Once the prior response tokens are determined, the demonstrations become redundant. Motivated by this finding, we propose an efficient Progressive In-Context Alignment (PICA) method consisting of two stages. In the first few-shot stage, the model generates several prior response tokens via standard ICL while concurrently extracting the ICL vector that stores the task function from the separator token representation. In the following zero-shot stage, this ICL vector guides the model to generate responses without further demonstrations. Extensive experiments demonstrate that our PICA not only surpasses vanilla ICL but also achieves comparable performance to other alignment tuning methods. The proposed training-free method reduces the time cost (e.g., 5.45×) with improved alignment performance (e.g., 6.57+). Consequently, our work highlights the application of ICL for alignment and calls for a deeper understanding of ICL for complex generations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9LdWG0PCsh": {
    "title": "The Role of Role Design in In-Context Learning for Large Language Models",
    "volume": "review",
    "abstract": "In-context learning (ICL) enables Large Language Models (LLMs) to generate predictions based on prompts without additional fine-tuning. While prompt engineering has been widely studied, the impact of role design within prompts remains underexplored. This study examines the influence of role configurations in zero-shot and few-shot learning scenarios using GPT-3.5 and GPT-4o from OpenAI and Llama2-7b Llama2-13b from Meta. We evaluate the models' performance across datasets, focusing on tasks like sentiment analysis, text classification, and question answering. F1 scores are used to measure the effectiveness of different role designs. Our findings highlight the potential of role-based prompt structuring to enhance LLM performance, offering new insights for optimizing prompt design strategies in natural language processing tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nvh98zb6yp": {
    "title": "Self-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models",
    "volume": "review",
    "abstract": "As large language models (LLMs) appear to behave increasingly human-like in text-based interactions, more and more researchers become interested in investigating personality in LLMs. However, the diversity of psychological personality research and the rapid development of LLMs have led to a broad yet fragmented landscape of studies in this interdisciplinary field. Extensive studies across different research focuses, different personality psychometrics, and different LLMs make it challenging to have a holistic overview and further pose difficulties in applying findings to real-world applications. In this paper, we present a comprehensive review by categorizing current studies into three research problems: self-assessment, exhibition, and recognition, based on the intrinsic characteristics and external manifestations of personality in LLMs. For each problem, we provide a thorough analysis and conduct in-depth comparisons of their corresponding solutions. Besides, we summarize research findings and open challenges from current studies and further discuss their underlying causes. We also collect extensive publicly available resources to facilitate interested researchers and developers. Lastly, we discuss the potential future research directions and application scenarios. Our paper is the first comprehensive survey of up-to-date literature on personality in LLMs. By presenting a clear taxonomy, in-depth analysis, promising future directions, and extensive resource collections, we aim to provide a better understanding and facilitate further advancements in this emerging field",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TcI0p8NvZd": {
    "title": "Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models",
    "volume": "review",
    "abstract": "Code retrieval aims to identify code from extensive codebases that semantically aligns with a given query code snippet. Collecting a broad and high-quality set of query and code pairs is crucial to the success of this task. However, existing data collection methods struggle to effectively balance scalability and annotation quality. In this paper, we first analyze the factors influencing the quality of function annotations generated by Large Language Models (LLMs). We find that the invocation of intra-repository functions and third-party APIs plays a significant role. Building on this insight, we propose a novel annotation method that enhances the annotation context by incorporating the content of functions called within the repository and information on third-party API functionalities. Additionally, we integrate LLMs with a novel sorting method to address the multi-level function call relationships within repositories. Furthermore, by applying our proposed method across a range of repositories, we have developed the Query4Code dataset. The quality of this synthesized dataset is validated through both model training and human evaluation, demonstrating high-quality annotations. Moreover, cost analysis confirms the scalability of our annotation method",
    "checked": false,
    "id": "d44031f253668c61ac6d68b95bbe9cac57730d51",
    "semantic_title": "soft prompt tuning for augmenting dense retrieval with large language models",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=CAbTWafsgh": {
    "title": "MemDPT: Differential Privacy for Memory Efficient Language Models",
    "volume": "review",
    "abstract": "Large language models have consistently demonstrated remarkable performance across a wide spectrum of applications. Nonetheless, the deployment of these models can inadvertently expose user privacy to potential risks. The substantial memory demands of these models during training represent a significant resource consumption challenge. The sheer size of these models imposes a considerable burden on memory resources, which is a matter of significant concern in practice. In this paper, we present an innovative training framework MemDPT that not only reduces the memory cost of large language models but also places a strong emphasis on safeguarding user data privacy. MemDPT provides edge network and reverse network designs to accommodate various differential privacy memory-efficient fine-tuning schemes. Our approach not only achieves $2 \\sim 3 \\times$ memory optimization but also provides robust privacy protection, ensuring that user data remains secure and confidential. Extensive experiments have demonstrated that MemDPT can effectively provide differential privacy efficient fine-tuning across various task scenarios",
    "checked": false,
    "id": "4f71f3ba99d63848868c56a021568157670c1813",
    "semantic_title": "dp-memarc: differential privacy transfer learning for memory efficient language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IDXjH7Q8T4": {
    "title": "FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation",
    "volume": "review",
    "abstract": "Large language models (LLMs) have become increasingly prevalent in our daily lives, leading to an expectation for LLMs to be trustworthy ---- both accurate and well-calibrated (the prediction confidence should align with its ground truth correctness likelihood). Nowadays, fine-tuning has become the most popular method for adapting a model to practical usage by significantly increasing accuracy on downstream tasks. Despite the great accuracy it achieves, we found fine-tuning is still far away from satisfactory trustworthiness due to \"tuning-induced mis-calibration\". In this paper, we delve deeply into why and how mis-calibration exists in fine-tuned models, and how distillation can alleviate the issue. Then we further propose a brand new method named Efficient Trustworthy Distillation (FIRST), which utilizes a small portion of teacher's knowledge to obtain a reliable language model in a cost-efficient way. Specifically, we identify the \"concentrated knowledge\" phenomenon during distillation, which can significantly reduce the computational burden. Then we apply a \"trustworthy maximization\" process to optimize the utilization of this small portion of concentrated knowledge before transferring it to the student. Experimental results demonstrate the effectiveness of our method, where better accuracy (+2.3\\%) and less mis-calibration (-10\\%) are achieved on average across both in-domain and out-of-domain scenarios, indicating better trustworthiness",
    "checked": false,
    "id": "fa85ded1c64dbcb7c641e93943c2af2256091c80",
    "semantic_title": "combining machine learning, patient reported outcomes and value based healthcare: a protocol for scoping reviews (preprint)",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zhwylVPqZn": {
    "title": "Expert Margin Optimization: Enhancing Multi-Domain Translation Capabilities of LLM with MoE-LoRA",
    "volume": "review",
    "abstract": "In the realm of machine translation utilizing Large Language Models (LLMs), the standard workflow involves Cross-Lingual Alignment learning followed by Instruction-tuning. Low-Rank Adaptation (LoRA) has been a widely-used and effective method for fine-tuning LLMs. However, LoRA alone exhibits limited benefits when confronted with multi-task or multi-domain scenarios. Given the prevalent existence of multi-domain challenges in machine translation, this paper focuses on enhancing the Multi-Domain Translation Capabilities of LLMs. We extend LoRA to Mixture of Experts (MoE) architecture, defined as MoE-LoRA, to address domain conflicts in multi-domain settings. Our approach involves introducing MoE-LoRA solely at higher layers to target specific domain-related knowledge acquisition, preceded by General Cross-Lingual Alignment during the training process. Particularly, we propose a methodology called Expert Margin Optimization to facilitate the transfer of additional knowledge from other domains to enhance the inputs specific to a domain. Experimental validations conducted on the English-to-German and English-to-Chinese translation directions using the Llama2-7B and Llama3-8B models demonstrate consistent improvements in BLEU and COMET scores, highlighting the efficacy of our proposed approach",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KY3roODQ47": {
    "title": "LLMs for Extremely Low-Resource Finno-Ugric Languages",
    "volume": "review",
    "abstract": "The advancement of large language models (LLMs) has predominantly focused on high-resource languages, leaving low-resource languages, such as those in the Finno-Ugric family, significantly underrepresented. This paper addresses this gap by focusing on Võro, Livonian, and Komi. We cover almost the entire cycle of LLM creation, from data collection to instruction tuning and evaluation. Our contributions include developing multilingual base and instruction-tuned models; creating evaluation benchmarks, including the SMUGRI-MT-Bench multi-turn conversational benchmark; and conducting human evaluation. We intend for this work to promote linguistic diversity, ensuring that lesser-resourced languages can benefit from advancements in NLP",
    "checked": false,
    "id": "9e5f2a3ad112b3b8c25be3961dde6955eb00c301",
    "semantic_title": "building an extremely low resource language to high resource language machine translation system from scratch",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=QeZwkjuq4J": {
    "title": "CHESS: Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification",
    "volume": "review",
    "abstract": "Deploying large language models (LLMs) on edge devices presents significant challenges due to the substantial computational overhead and memory requirements. Activation sparsification can mitigate these challenges by reducing the number of activated neurons during inference. Existing methods typically employ thresholding-based sparsification based on the statistics of activation tensors. However, these methods do not model the impact of activation sparsification on performance, resulting in significant performance degradation. To address this issue, this paper reformulates the activation sparsification problem and proposes , a general activation sparsification approach via \\textbf{CH}annel-wise thr\\textbf{E}sholding and \\textbf{S}elective \\textbf{S}parsification. First, channel-wise thresholding assigns a unique threshold to each activation channel in FFN layers. Then, selective sparsification involves choosing specific layers in the attention modules to apply thresholding-based activation sparsification. Finally, this paper shows the detailed implementation of sparse kernels to accelerate the LLM inference. Experimental results demonstrate that the proposed CHESS achieves lower performance degradation over 8 downstream tasks while activating fewer parameters, thus speeding up the LLM inference by up to 1.27x",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SzRQxGCQor": {
    "title": "KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions",
    "volume": "review",
    "abstract": "Recent studies have demonstrated that large language models (LLMs) are susceptible to being misled by false premise questions (FPQs), leading to errors in factual knowledge, know as factuality hallucination. Existing benchmarks that assess this vulnerability primarily rely on manual construction, resulting in limited scale and lack of scalability. In this work, we introduce an automated, scalable pipeline to create FPQs based on knowledge graphs (KGs). The first step is modifying true triplets extracted from KGs to create false premises. Subsequently, utilizing the state-of-the-art capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed method, we present a comprehensive benchmark, the Knowledge Graph-based False Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three knowledge domains, at six levels of confusability, and in two task formats. Using KG-FPQ, we conduct extensive evaluations on several representative LLMs and provide valuable insights",
    "checked": true,
    "id": "000d4c828826fb786bcb466f88db1fb0b9cec0f2",
    "semantic_title": "kg-fpq: evaluating factuality hallucination in llms with knowledge graph-based false premise questions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jrXVmwaFIr": {
    "title": "IoA: Linking Collaborative Agent Efforts with the Internet of Agents",
    "volume": "review",
    "abstract": "The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate efficient collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. We believe that this direction holds potential for better multi-agent systems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pL85yVw6Yp": {
    "title": "Efficient LLM Pruning with Token-Dependency Awareness and Hardware-Adapted Inference",
    "volume": "review",
    "abstract": "Structured pruning removes entire components, like attention heads or hidden dimensions to yield faster dense large language models. However, previous methods are time-consuming and inference speedup is bottlenecked by inefficient GPU parallel processing due to mismatch in pruned weight block dimensions with tensor cores. Moreover, pruning of heads in grouped query attentions is not widely attempted due to challenges with their interdependencies. To address these limitations, we propose (1) a structured pruning method for LLMs with grouped-query attention (GQA) that learn appropriate key, value and shared query heads to retain according to their importance for accurate prediction. (2) a post-pruning weight update to better retain the performance of pruned LLMs. (3) a post-pruning dimension adaptation step to enhance GPU utilization of pruned models and significantly speed up inference. Our method speeds up inference by up to 60% over previous approaches. Evaluated on several language benchmarks using variants of LLaMA models and Mistral, our method shows a reduction in pruning time by upto 90% with higher inference speed and performance over a range of sparsity ratios. Additionally, our findings suggest that pruning can alleviate prediction confusion in certain scenarios",
    "checked": false,
    "id": "58700f3740105e3422eb030305372b6d8bc44986",
    "semantic_title": "hardware-aware parallel prompt decoding for memory-efficient acceleration of llm inference",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=DGjv5L30cn": {
    "title": "Predicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models",
    "volume": "review",
    "abstract": "Accurate assessment of personality traits is crucial for effective psycho-counseling, yet traditional methods like self-report questionnaires are time-consuming and biased. This study exams whether Large Language Models (LLMs) can predict the Big Five personality traits directly from counseling dialogues and introduces an innovative framework to perform the task. Our framework applies role-play and questionnaire-based prompting to condition LLMs on counseling sessions, simulating client responses to the Big Five Inventory. We evaluated our framework on 853 real-world counseling sessions, finding a significant correlation between LLM-predicted and actual Big Five traits, proving the validity of framework. Moreover, ablation studies highlight the importance of role-play simulations and task simplification via questionnaires in enhancing prediction accuracy. Meanwhile, our fine-tuned Llama3-8B model, utilizing Direct Preference Optimization with Supervised Fine-Tuning, achieves a 130.95\\% improvement, surpassing the state-of-the-art Qwen1.5-110B by 36.94\\% in personality prediction validity. In conclusion, LLMs can predict personality based on counseling dialogues. Our code and model are publicly available at \\url{https://github.com/Anonymous-gwFabfaH/BigFive-LLM-Predictor}, providing a valuable tool for future research in computational psychometrics",
    "checked": true,
    "id": "922e122e11d6c60249e96bf2c89235d8f30e66a2",
    "semantic_title": "predicting the big five personality traits in chinese counselling dialogues using large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Hn6CZ6m7QO": {
    "title": "Reasoning Robustness of LLMs to Adversarial Typographical Errors",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning using Chain-of-Thought (CoT) prompting. However, CoT can be biased by users' instruction. In this work, we study the reasoning robustness of LLMs to typographical errors, which can naturally occur in users' queries. We design an Adversarial Typo Attack ($\\texttt{ATA}$) algorithm that iteratively samples typos for words that are important to the query and selects the edit that is most likely to succeed in attacking. It shows that LLMs are sensitive to minimal adversarial typographical changes. Notably, with 1 character edit, Mistral-7B's accuracy drops from 43.7\\% to 38.6\\% on GSM8K, while with 8 character edits the performance further drops to 19.2\\%. To extend our evaluation to larger and closed-source LLMs, we develop the $\\texttt{R$^2$ATA}$ benchmark, which assesses models' $\\underline{R}$easoning $\\underline{R}$obustness to $\\underline{\\texttt{ATA}}$. It includes adversarial typographical questions derived from three widely-used reasoning datasets—GSM8K, BBH, and MMLU—by applying $\\texttt{ATA}$ to open-source LLMs. $\\texttt{R$^2$ATA}$ demonstrates remarkable transferability and causes notable performance drops across multiple super large and closed-source LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MumfvVOHTQ": {
    "title": "Unveiling Wisdom: Inspirational Quote Extraction using a Retrieval Augmented Multi-Task Reader",
    "volume": "review",
    "abstract": "Inspirational quotes from famous individuals are often used to convey thoughts in news articles, essays, and everyday conversations. In this paper, we propose a novel context-based quote extraction system that aims to predict the most relevant quote from a long text. We formulate this quote extraction as an open domain question answering problem first by employing a vector-store based retriever and then applying a multi-task reader. We curate three context-based quote extraction dataset and introduce a novel multi-task framework that improves the state-of-the-art performance, achieving a maximum improvement of 5.08% in BoW F1-score",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BTOfSCbjC5": {
    "title": "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures",
    "volume": "review",
    "abstract": "Explaining Artificial Intelligence (AI) decisions is a major challenge nowadays in AI, in particular when applied to sensitive scenarios like medicine and law. However, the need to explain the rationale behind decisions is a main issues also for human-based deliberation as it is important to justify why a certain decision has been taken. Resident medical doctors for instance are required not only to provide a (possibly correct) diagnosis, but also to explain how they reached a certain conclusion. Developing new tools to aid residents to train their explanation skills is therefore a central objective of AI in education. In this paper, we follow this direction, and we present, to the best of our knowledge, the first multilingual dataset for Medical Question Answering where correct and incorrect diagnoses for a clinical case are enriched with a natural language explanation written by doctors. These explanations have been manually annotated with argument components (i.e., premise, claim) and argument relations (i.e., attack, support). The Multilingual CasiMedicos-arg dataset consists of 558 clinical cases (English, Spanish, French, Italian) with explanations, where we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106 attack relations. We conclude by showing how competitive baselines perform over this challenging dataset for the argument mining task",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uQDOxlH9LO": {
    "title": "Decoding Susceptibility: Modeling Misbelief to Misinformation Through a Computational Approach",
    "volume": "review",
    "abstract": "Susceptibility to misinformation describes the degree of belief in unverifiable claims, a latent aspect of individuals' mental processes that is not observable. Existing susceptibility studies heavily rely on self-reported beliefs, which can be subject to bias, expensive to collect, and challenging to scale for downstream applications. To address these limitations, in this work, we propose a computational approach to efficiently model users' latent susceptibility levels. As shown in previous work, susceptibility is influenced by various factors (e.g., demographic factors, political ideology), and directly influences people's reposting behavior on social media. To represent the underlying mental process, our susceptibility modeling incorporates these factors as inputs, guided by the supervision of people's sharing behavior. Using COVID-19 as a testbed, our experiments demonstrate a significant alignment between the susceptibility scores estimated by our computational modeling and human judgments, confirming the effectiveness of this latent modeling approach. Furthermore, we apply our model to annotate susceptibility scores on a large-scale dataset and analyze the relationships between susceptibility with various factors. Our analysis reveals that political leanings, etc., psychological factors exhibit varying degrees of association with susceptibility to COVID-19 misinformation, and shows that susceptibility is unevenly distributed across different professional and geographical backgrounds",
    "checked": false,
    "id": "43cbfe896a3b3e5194f43a2161f40e29463ff29d",
    "semantic_title": "decoding susceptibility: modeling misbelief to misinformation through a computational approach (preprint)",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Txi2KnUmiH": {
    "title": "On the Role of Entity and Event Level Conceptualization in Generalizable Reasoning: A Survey of Tasks, Methods, Applications, and Future Directions",
    "volume": "review",
    "abstract": "Entity- and event-level conceptualization, as fundamental elements of human cognition, plays a pivotal role in generalizable reasoning. This process involves abstracting specific instances into higher-level concepts and forming abstract knowledge that can be applied in unfamiliar or novel situations, which can enhance models' inferential capabilities and support the effective transfer of knowledge across various domains. Despite its significance, there is currently a lack of a systematic overview that comprehensively examines existing works in the definition, execution, and application of conceptualization to enhance reasoning tasks. In this paper, we address this gap by presenting the first comprehensive survey of 150+ papers, categorizing various definitions, resources, methods, and downstream applications related to conceptualization into a unified taxonomy, with a focus on the entity and event levels. Furthermore, we shed light on potential future directions in this field and hope to garner more attention from the community",
    "checked": true,
    "id": "d70a1f45665fcef448ce4daedeac34f5f4befaa2",
    "semantic_title": "on the role of entity and event level conceptualization in generalizable reasoning: a survey of tasks, methods, applications, and future directions",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YI8HSqgwjp": {
    "title": "Benchmarking the Ability of Large Language Models to Reason about Event Sequences",
    "volume": "review",
    "abstract": "The ability to reason about events and their temporal relations is a key aspect in Natural Language Understanding. In this paper, we investigate the ability of Large Language Models to resolve temporal references with respect to longer event sequences. Given that events rarely occur in isolation, it is crucial to determine the extent to which Large Language Models can reason about longer sequences of events. Towards this goal, we introduce a novel synthetic benchmark dataset comprising of 2200 questions to test the abilities of LLMs to reason about events using a Question Answering task as proxy. We compare the performance of 4 state of the art LLMs on the benchmark, analyzing their performance in dependence of the length of the event sequence considered as well as of the explicitness of the temporal reference. Our results show that, while the benchmarked LLMs can answer questions over event sequences with a handful of events and explicit temporal references successfully, performance clearly deteriorates with larger event sequence length and when temporal references get less explicit",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lMd0iIOwyX": {
    "title": "Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study",
    "volume": "review",
    "abstract": "Large language models (LLMs) have shown significant achievements in solving a wide range of tasks. Recently, LLMs' capability to store, retrieve and infer with symbolic knowledge has drawn a great deal of attention, showing their potential to understand structured information. However, it is not yet known whether LLMs can understand Description Logic (DL) ontologies. In this work, we empirically analyze the LLMs' capability of understanding DL-Lite ontologies covering 6 representative tasks from syntactic and semantic aspects. With extensive experiments, we demonstrate both the effectiveness and limitations of LLMs in understanding DL-Lite ontologies. We find that LLMs can understand formal syntax and model-theoretic semantics of concepts and roles. However, LLMs struggle with understanding TBox NI transitivity and handling ontologies with large ABoxes. We hope that our experiments and analyses provide more insights into LLMs and inspire to build more faithful knowledge engineering solutions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U8HPrsnLcb": {
    "title": "Identify High-Risk Suicidal Posts and Psychological Risk Factors on Social Media Using a Two-Stage Deep Learning Model",
    "volume": "review",
    "abstract": "Our study aims to utilize psychological risk factors to detect articles on social media that are at high risk for suicidal content. We propose a two-stage model structure: the first stage labels each sentence in an article with risk factors, and the second stage uses this information as features to predict the crisis level of the article. Our models were trained using a dataset that we developed, which consists of social media posts from Dcard. These posts were labeled by psychological professionals and will be publicly released. Our approach achieved an accuracy and F1-score of 0.96 in classifying high-crisis-level articles. Our research facilitates the automatic detection of high-crisis-level articles for further analysis of risk factors, enhancing interdisciplinary collaboration between natural language processing, deep learning, and psychology",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tBaSkqpU1S": {
    "title": "Learnability of Indirect Evidence in Language Models",
    "volume": "review",
    "abstract": "What kinds of and how much data is necessary for language models to acquire grammatical knowledge to judge sentence acceptability? Recent language models still have much room for improvement in their data efficiency compared to humans. In this paper, we investigate whether language models efficiently use indirect data (indirect evidence), from which they infer sentence acceptability. In contrast, humans use indirect evidence efficiently, which is considered one of the inductive biases contributing to efficient language acquisition. To explore this question, we inject synthetic instances with newly coined \"wug\" words into pretraining data and explore the model's behavior on evaluation data that assess grammatical acceptability regarding those words. We prepare the injected instances by varying their levels of indirectness and quantity. Our experiments surprisingly show that language models do not acquire grammatical knowledge even after repeated exposure to instances with the same structure but differing only in lexical items from evaluation instances in certain language phenomena. Our findings suggest a potential direction for future research: developing models that use latent indirect evidence to acquire grammatical knowledge",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tb9te4v9KK": {
    "title": "Can Large Language Models Unlock Novel Scientific Research Ideas?",
    "volume": "review",
    "abstract": "$\\textit{``An idea is nothing more nor less than a new combination of old elements\"}$ (Young, J.W.). The widespread adoption of Large Language Models (LLMs) and publicly available ChatGPT have marked a significant turning point in the integration of Artificial Intelligence (AI) into people's everyday lives. This study explores the capability of LLMs in generating novel research ideas based on information from research papers. We conduct a thorough examination of 4 LLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and Physics). We found that the future research ideas generated by Claude-2 and GPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini. We also found that Claude-2 generates more diverse future research ideas than GPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the novelty, relevancy, and feasibility of the generated future research ideas. This investigation offers insights into the evolving role of LLMs in idea generation, highlighting both its capability and limitations. Our work contributes to the ongoing efforts in evaluating and utilizing language models for generating future research ideas. We make our datasets and codes publicly available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vFf7ZDoLA2": {
    "title": "Model Tells Itself Where to Attend: Faithfulness Meets Automatic Attention Steering",
    "volume": "review",
    "abstract": "Large language models (LLMs) have demonstrated remarkable performance across various real-world tasks. However, recent studies reveal that LLMs often struggle to fully comprehend and effectively utilize their input contexts, resulting in responses that lack faithfulness or suffer from hallucination. This difficulty becomes particularly evident when the contexts are lengthy or contain distracting information, which can divert LLMs from fully capturing essential evidence. Most prior work focuses on designing effective prompts to guide LLMs in utilizing contextual information more faithfully. For instance, iterative prompting highlights key information through two high-level prompting steps that first ask the LLM to identify important pieces of context and then derive answers accordingly. However, prompting methods are constrained to highlighting key information implicitly in token space, which is often insufficient to fully steer the model's attention. To improve model faithfulness more reliably, we propose AutoPASTA, a method that automatically identifies contextual key information and explicitly highlights it by steering the model's attention scores. Similar to prompting, AutoPASTA is applied at inference time and does not require changing any model parameters. Our experiments on open-book QA demonstrate that AutoPASTA can effectively guide models to grasp essential contextual information, leading to substantially improved model faithfulness and performance, e.g., an average improvement of 11.26% for LLAMA3-8B-Instruct. Code will be publicly available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X9h5qaKqqT": {
    "title": "Hallucination Mitigating for Medical Report Generation",
    "volume": "review",
    "abstract": "In the realm of medical report generation (MRG), the integration of natural language processing has emerged as a vital tool to alleviate the workload of radiologists. Despite the impressive capabilities demonstrated by large vision language models (LVLMs) in understanding natural language, their susceptibility to generating plausible yet inaccurate claims, known as ``hallucinations'', raises concerns—especially in the nuanced and critical field of medical. In this work, we introduce a framework, Knowledge-Enhanced with Fine-Grained Reinforced Rewards Medical Report Generation (KERM), to tackle the issue. Our approach refines the input to the LVLM by first utilizing MedCLIP for knowledge retrieval, incorporating relevant lesion fact sentences from a curated knowledge corpus. We then introduce a novel purification module to ensure the retrieved knowledge is contextually relevant to the patient's clinical context. Subsequently, we employ fine-grained rewards to guide these models in generating highly supportive and clinically relevant descriptions, ensuring the alignment of model's outputs with desired behaviors. Experimental results on IU-Xray and MIMIC-CXR datasets validate the effectiveness of our approach in mitigating hallucinations and enhancing report quality",
    "checked": false,
    "id": "f818e71f883aa8eb515331b01e24ba3530968664",
    "semantic_title": "cross-modal causal intervention for medical report generation",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=t04AUXMwIx": {
    "title": "Mitigating the Privacy Issues in Retrieval-Augmented Generation (RAG) via Pure Synthetic Data",
    "volume": "review",
    "abstract": "Retrieval-augmented generation (RAG) enhances the outputs of language models by integrating relevant information retrieved from external knowledge sources. However, when the retrieval process involves private data, RAG systems may face severe privacy risks, potentially leading to the leakage of sensitive information. To address this issue, we propose using synthetic data as a privacy-preserving alternative for the retrieval data. We propose SAGE, a novel two-stage synthetic data generation paradigm. In the stage-1, we employ an attribute-based extraction and generation approach to preserve key contextual information from the original data. In the stage-2, we further enhance the privacy properties of the synthetic data through an agent-based iterative refinement process. Extensive experiments demonstrate that using our synthetic data as the retrieval context achieves comparable performance to using the original data while substantially reducing privacy risks. Our work takes the first step towards investigating the possibility of generating high-utility and privacy-preserving synthetic data for RAG, opening up new opportunities for the safe application of RAG systems in various domains",
    "checked": true,
    "id": "dcdcf97a86050202d0a804202e56e5878c167951",
    "semantic_title": "mitigating the privacy issues in retrieval-augmented generation (rag) via pure synthetic data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rhdC4p4ujD": {
    "title": "Understanding the Therapeutic Relationship between Counselors and Clients in Online Text-based Counseling using LLMs",
    "volume": "review",
    "abstract": "Robust therapeutic relationships between counselors and clients are fundamental to counseling effectiveness. The assessment of therapeutic alliance is well-established in traditional face-to-face therapy but may not directly translate to text-based settings. With millions of individuals seeking support through online text-based counseling, understanding the relationship in such contexts is crucial. In this paper, we present an automatic approach using large language models (LLMs) to understand the development of therapeutic alliance in text-based counseling. We develop a theoretically grounded framework with detailed guidelines for characterizing the alliance. We collect a comprehensive counseling dataset and conduct multiple expert evaluations on a subset based on this framework. Our LLM-based approach, combined with guidelines and simultaneous extraction of supportive evidence underlying its predictions, demonstrates effectiveness in identifying the therapeutic alliance. Through further LLM-based evaluations on additional conversations, our findings underscore the challenges counselors face in cultivating strong online relationships with clients. Furthermore, we demonstrate the potential of LLM-based feedback mechanisms to enhance counselors' ability to build relationships, supported by a small-scale proof-of-concept",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KoKV0CFGTB": {
    "title": "WundtGPT: Shaping Large Language Models To Be An Empathetic, Proactive Psychologist",
    "volume": "review",
    "abstract": "Large language models (LLMs) are raging over the medical domain, and their momentum has carried over into the mental health domain, leading to the emergence of few mental health LLMs. Although such mental health LLMs could provide reasonable suggestions for psychological counseling, how to develop an authentic and effective doctor-patient relationship (DPR) through LLMs is still an important problem. To fill this gap, we dissect DPR into two key attributes, i.e., the psychologist's empathy and proactive guidance. We thus present WundtGPT, an empathetic and proactive mental health large language model that is acquired by fine-tuning it with instruction and real conversation between psychologists and patients. It is designed to assist psychologists in diagnosis and help patients who are reluctant to communicate face-to-face understand their psychological conditions. Its uniqueness lies in that it could not only pose purposeful questions to guide patients in detailing their symptoms but also offer warm emotional reassurance. In particular, WundtGPT incorporates \\textbf{Collection of Questions}, \\textbf{Chain of Psychodiagnosis}, and \\textbf{Empathy Constraints} into a comprehensive prompt for eliciting LLMs' questions and diagnoses. Additionally, WundtGPT proposes a reward model to promote alignment with empathetic mental health professionals, which encompasses two key factors: cognitive empathy and emotional empathy. We offer a comprehensive evaluation of our proposed model. Based on these outcomes, we further conduct the manual evaluation based on proactivity, effectiveness, professionalism and coherence. We notice that WundtGPT can offer professional and effective consultation. The model is available at huggingface",
    "checked": true,
    "id": "6a7246a8cf065cf2858fee9d9ccca298e9ae4546",
    "semantic_title": "wundtgpt: shaping large language models to be an empathetic, proactive psychologist",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dBbWg7LQWK": {
    "title": "KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning",
    "volume": "review",
    "abstract": "Autoregressive large language models (LLMs) pre-trained by next token prediction are inherently proficient in generative tasks. However, their performance on knowledge-driven tasks such as factual knowledge querying remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured knowledge bases, can provide reliable knowledge for LLMs, potentially compensating for their knowledge deficiencies. Aligning LLMs with explicit, structured knowledge from KGs has been a challenge; previous attempts either failed to effectively align knowledge representations or compromised the generative capabilities of LLMs, leading to less-than-optimal outcomes. This paper proposes \\textbf{KaLM}, a \\textit{Knowledge-aligned Language Modeling} approach, which fine-tunes autoregressive LLMs to align with KG knowledge via the joint objective of explicit knowledge alignment and implicit knowledge alignment. The explicit knowledge alignment objective aims to directly optimize the knowledge representation of LLMs through dual-view knowledge graph contrastive learning. The implicit knowledge alignment objective focuses on incorporating textual patterns of knowledge into LLMs through triple completion language modeling. Notably, our method achieves a significant performance boost in evaluations of knowledge-driven tasks, specifically embedding-based knowledge graph completion and generation-based knowledge graph question answering",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BjtAS1vMxV": {
    "title": "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian",
    "volume": "review",
    "abstract": "Norwegian, spoken by only 5 million population, is under-representative within the most impressive breakthroughs in NLP tasks. To the best of our knowledge, there has not yet been a comprehensive evaluation of the existing language models (LMs) on Norwegian generation tasks during the article writing process. To fill this gap, we 1) compiled the existing Norwegian dataset and pre-trained 4 Norwegian Open Language Models varied from parameter scales and architectures, collectively called NorGLM; 2) introduced a comprehensive benchmark, NLEBench, for evaluating natural language generation capabilities in Norwegian, encompassing translation and human annotation. Based on the investigation, we find that: 1) the mainstream, English-dominated LM GPT-3.5 has limited capability in understanding the Norwegian context; 2) the increase in model parameter scales demonstrates limited impact on the performance of downstream tasks when the pre-training dataset is constrained in size; 3) smaller models also demonstrate the reasoning capability through Chain-of-Thought; 4) a multi-task dataset that includes synergy tasks can be used to verify the generalizability of LLMs on natural language understanding and, meanwhile, test the interconnectedness of these NLP tasks. We share our resources and code for reproducibility under a CC BY-NC 4.0 license",
    "checked": true,
    "id": "0ad16e2c1c30d8ed5b63970e5fb3459a08218ea3",
    "semantic_title": "nlebench+norglm: a comprehensive empirical analysis and benchmark dataset for generative language models in norwegian",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=atQoQJa3Sz": {
    "title": "Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation",
    "volume": "review",
    "abstract": "Despite recent advancements in language and vision modeling, integrating rich multimodal knowledge into recommender systems continues to pose significant challenges. This is primarily due to the need for efficient recommendation, which requires adaptive and interactive responses. In this study, we focus on sequential recommendation and introduce a lightweight framework called full-scale Matryoshka representation learning for multimodal recommendation (fMRLRec). Our fMRLRec captures item features at different granularities, learning informative representations for efficient recommendation across multiple dimensions. To integrate item features from diverse modalities, fMRLRec employs a simple mapping to project multimodal item features into an aligned feature space. Additionally, we design an efficient linear transformation that embeds smaller features into larger ones, substantially reducing memory requirements for large-scale training on recommendation data. Combined with improved state space modeling techniques, fMRLRec scales to different dimensions and only requires one-time training to produce multiple models tailored to various granularities. We demonstrate the effectiveness and efficiency of fMRLRec on multiple benchmark datasets, which consistently achieves superior performance over state-of-the-art baseline methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tf8PJtuaGq": {
    "title": "KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs",
    "volume": "review",
    "abstract": "Multilingual knowledge graphs (KGs) provide high-quality relational and textual information for various NLP applications but they are often incomplete, especially in non-English languages. Previous research has shown that combining information from several knowledge graphs in different languages aids both Knowledge Graph Completion (KGC), the task of predicting of missing relations between entities, and Knowledge Graph Enhancement (KGE), the task of predicting missing textual information for entities. While previous efforts have considered KGC and KGE as independent tasks, we hypothesize that they are interdependent and mutually beneficial. To this end, we introduce KG-TRICK, a novel sequence-to-sequence framework that unifies the tasks of textual and relational information completion for multilingual knowledge graphs. KG-TRICK demonstrates that i) it is possible to unify the tasks of KGC and KGE into one single framework, and ii) combining textual information from multiple languages is beneficial to improve the completeness of a KG. As part of our contributions, we also introduce WikiKGE++, the largest manually-curated benchmark for textual information completion of KGs, which features over 30,000 instances across 10 diverse languages",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TWGjxLNW7g": {
    "title": "SSP: Story-Space Prompting Improves the Reader Immersion in Long Story Generation",
    "volume": "review",
    "abstract": "Generating long-form stories with neural network models, even the large language models (LLMs), e.g., GPT, has always been criticized for lacking interestingness and coherence, thus greatly diminishing the reader's sense of immersion. In this paper, we present a novel \"story space\" prompting (SSP) solution, which provides a coherent and consistent background to support long-term storytelling. Specifically, we first define the story space intricately connected to the given story premise. Then, Our framework systematically generates the story space by progressively constructing it from an abstract representation to a more informative and detailed one. Empirically, we implement our plug-in method upon an existing advanced story generation framework (Yang et al., 2023) and evaluate its impact on both interestingness and coherence. Our findings emphasize the significance of our SSP in enhancing reader enjoyment and immersion, contributing to advancements in long-form story generation",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bCAxEwwmBr": {
    "title": "Fact-Level Confidence Calibration: Empowering Confidence-Guided LLM Self-Correction",
    "volume": "review",
    "abstract": "Confidence calibration in LLMs, i.e., aligning their self-assessed confidence with the actual accuracy of their responses, enabling them to self-evaluate the correctness of their outputs. However, current calibration methods for LLMs typically estimate two scalars to represent overall response confidence and correctness, which is inadequate for long-form generation where the response includes multiple atomic facts and may be partially confident and correct. These methods also overlook the relevance of each fact to the query. To address these challenges, we propose a Fact-Level Calibration framework that operates at a finer granularity, calibrating confidence to relevance-weighted correctness at the fact level. Furthermore, comprehensive analysis under the framework inspired the development of Confidence-guided Fact-level self-correction (ConFact), which uses high-confidence facts within a response as additional knowledge to improve low-confidence ones. Extensive experiments across four datasets and six models demonstrate that ConFact effectively mitigates hallucinations without requiring external knowledge sources such as retrieval systems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nvvg466R6g": {
    "title": "Hybrid Generative and Commonsense Knowledge for Script Event Prediction",
    "volume": "review",
    "abstract": "Script event prediction aims to predict subsequent events given contextual events, which requires inferring correlations between contexts and candidate events. Current research focuses on improving script event prediction using external knowledge and pre-trained language models, but faces the problems of sparse event-level correlation knowledge and separation of word-level correlation knowledge. In this paper, we propose a novel model CoGen-Predictor based on hybrid generative and commonsense knowledge that combines explicit event-level and implicit word-level correlation knowledge for prediction. CoGen-Predictor constructs event-level correlations through a commonsense knowledge base and updates the event representations using graph neural networks, then learns word-level contextual event correlations through a generative approach. Experimental results on the multi-choice narrative cloze (MCNC) task demonstrate the effectiveness of the model",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2HYsVlsGfX": {
    "title": "Reconstruct Your Previous Conversations! Comprehensively Investigating Privacy Leakage Risks in Conversations with GPT Models",
    "volume": "review",
    "abstract": "Significant advancements have been made in the field of large language models recently, represented by GPT models. Users frequently have multi-round private conversations with cloud-hosted GPT models for task optimization. Yet, this operational paradigm introduces additional attack surfaces, particularly in custom GPTs and hijacked chat sessions. In this paper, we introduce a straightforward yet potent Conversation Reconstruction Attack, that employs malicious prompts to query GPT models to leak previous conversations. Our comprehensive examination of privacy risks during GPT interactions under this attack reveals GPT-4's considerable resilience. We present two advanced attacks targeting improved reconstruction of past conversations, demonstrating significant privacy leakage across all models under these advanced techniques. Evaluating various defense mechanisms, we find them ineffective against these attacks. Our findings highlight the ease with which privacy can be compromised in interactions with GPT models, urging the community to safeguard against potential abuses of these models' capabilities",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SzzfKS6rnJ": {
    "title": "From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models",
    "volume": "review",
    "abstract": "It is imperative for Large language models (LLMs) to follow instructions with elaborate requirements (i.e. Complex Instructions Following}). Yet, it remains under-explored how to enhance the ability of LLMs to follow complex instructions with multiple constraints. To bridge the gap, we initially study what training data is effective in enhancing complex constraints following abilities. We found that training LLMs with instructions containing multiple constraints enhances their understanding of complex instructions, especially those with lower complexity levels. Additionally, we further propose methods addressing how to obtain and utilize the effective training data. Finally, we conduct extensive experiments to prove the effectiveness of our methods in terms of overall performance and training efficiency. We also demonstrate that our methods improve models' ability to follow instructions generally and generalize effectively across out-of-domain, in domain, and adversarial settings, while maintaining general capabilities",
    "checked": true,
    "id": "ad5c359094dbfb68b1e09b22e2be3ce6dac33e3d",
    "semantic_title": "from complex to simple: enhancing multi-constraint complex instruction following ability of large language models",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=JFdKwzKSrY": {
    "title": "Dynamic Multi-granularity Attribution Network for Aspect-based Sentiment Analysis",
    "volume": "review",
    "abstract": "Aspect-based sentiment analysis (ABSA) aims to predict the sentiment polarity of a specific aspect within a given sentence. Most existing methods predominantly leverage semantic or syntactic information based on attention scores, which are susceptible to interference caused by irrelevant contexts and often lack sentiment knowledge at a data-specific level. In this paper, we propose a novel Dynamic Multi-granularity Attribution Network (DMAN) from the perspective of attribution. Initially, we leverage Integrated Gradients to dynamically extract importance scores for each token, which contain underlying reasoning knowledge for sentiment analysis. Subsequently, we aggregate attribution representations from multiple semantic granularities in natural language, enhancing profound understanding of the semantics. Finally, we integrate attribution scores with syntactic information to more accurately capture the relationships between aspects and their relevant contexts during the sentence understanding process. Extensive experiments on five benchmark datasets demonstrate the effectiveness of our proposed method",
    "checked": false,
    "id": "972cb3b6691d6915db719ad576d04be822723f8e",
    "semantic_title": "green supplier selection based on sequential group three-way decision making",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=iLhpEOXBdZ": {
    "title": "Discrete Diffusion Language Model for Long Text Summarization",
    "volume": "review",
    "abstract": "While diffusion models excel at conditional generating high-quality images, prior works in discrete diffusion models were not evaluated on conditional long-text generation. In this work, we address the limitations of prior discrete diffusion models for conditional long-text generation, particularly in long sequence-to-sequence tasks such as abstractive summarization. Despite fast decoding speeds compared to autoregressive methods, previous diffusion models failed on the abstractive summarization task due to the incompatibility between the backbone architectures and the random noising process. To overcome these challenges, we introduce a novel semantic-aware noising process that enables Transformer backbones to handle long sequences effectively. Additionally, we propose CrossMamba, an adaptation of the Mamba model to the encoder-decoder paradigm, which integrates seamlessly with the random absorbing noising process. Our approaches achieve state-of-the-art performance on three benchmark summarization datasets: Gigaword, CNN/DailyMail, and Arxiv, outperforming existing discrete diffusion models on ROUGE metrics as well as possessing much faster speed in inference compared to autoregressive models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4hlnbLp0k4": {
    "title": "Latent Segment Language Models",
    "volume": "review",
    "abstract": "Tokenization is a critical step in every NLP system, yet most works treat it as an isolated component separate from the models they are building. In this paper, we present a framework to jointly learn next-token prediction and segmentation from a sequence of characters or bytes. We evaluate our model on language modeling benchmarks in English, Chinese, and Japanese using both character and byte vocabularies. Our model consistently outperforms baselines on Chinese benchmarks with character vocabulary and shows significant improvements with byte vocabulary. Further latency improvements are achieved by adapting different pooling strategies while maintaining comparable results to the best models. Our main contributions are threefold: we propose a language model that learns to segment the input sequence, conforming to the desired segmentation prior; we demonstrate that our model achieves shorter latency than baselines in token generation; and we show that our model can be applied to three different languages—English, Chinese, and Japanese—demonstrating its potential for wider NLP applications. Our source code will be released on GitHub",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NnpVpW7A3x": {
    "title": "IncogniText: Privacy-enhancing Conditional Text Anonymization via LLM-based Private Attribute Randomization",
    "volume": "review",
    "abstract": "In this work, we address the problem of text anonymization where the goal is to prevent adversaries from correctly inferring private attributes of the author, while keeping the text utility, i.e., meaning and semantics. We propose IncogniText, a technique that anonymizes the text to mislead a potential adversary into predicting a wrong private attribute value. Our empirical evaluation shows a reduction of private attribute leakage by more than $90\\%$. Finally, we demonstrate the maturity of IncogniText for real-world applications by distilling its anonymization capability into a set of LoRA parameters associated with an on-device model",
    "checked": true,
    "id": "70acacd0c50c7fc30f7e7ede1546b945918a3c93",
    "semantic_title": "incognitext: privacy-enhancing conditional text anonymization via llm-based private attribute randomization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RgqajywZa5": {
    "title": "XL$^2$Bench: A Benchmark for Extremely Long Context Understanding with Long-range Dependencies",
    "volume": "review",
    "abstract": "Recently, various efforts have been proposed to expand the context window size of large language models (LLMs). Meanwhile, building high-quality benchmarks with much longer text lengths and more demanding tasks to provide comprehensive evaluations is of immense practical interest to facilitate long context understanding research of LLMs. However, prior benchmarks create datasets that ostensibly cater to long-text comprehension by expanding the input of traditional tasks, which falls short to exhibit the unique characteristics of long-text understanding, including long dependency tasks and longer text length compatible with modern LLMs' context window size. In this paper, we introduce a benchmark for extremely long context understanding with long-range dependencies, XL$^2$Bench, which includes three scenarios—Fiction Reading, Paper Reading, and Law Reading—and four tasks of increasing complexity: Memory Retrieval, Detailed Understanding, Overall Understanding, and Open-ended Generation, covering 27 subtasks in English and Chinese. It has an average length of 100K+ words (English) and 200K+ characters (Chinese). Evaluating seven leading LLMs on XL$^2$Bench, we find that their performance significantly lags behind human levels. Moreover, the observed decline in performance across both the original and enhanced datasets underscores the efficacy of our approach to mitigating data contamination",
    "checked": true,
    "id": "d9db8114b3c79f96ee27a9f16e83430448ad3e68",
    "semantic_title": "xl$^2$bench: a benchmark for extremely long context understanding with long-range dependencies",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=DdGqSrG3oI": {
    "title": "Communicating with Speakers and Listeners of Different Pragmatic Levels",
    "volume": "review",
    "abstract": "This paper explores the impact of variable pragmatic competence on communicative success through simulating language learning and conversing between speakers and listeners with different levels of reasoning abilities. Through studying this interaction, we hypothesize that matching levels of reasoning between communication partners would create a more beneficial environment for communicative success and language learning. Our research findings indicate that learning from more explicit, literal language is advantageous, irrespective of the learner's level of pragmatic competence. Furthermore, we find that integrating pragmatic reasoning during language learning, not just during evaluation, significantly enhances overall communication performance. This paper provides key insights into the importance of aligning reasoning levels and incorporating pragmatic reasoning in optimizing communicative interactions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4OaaSHmdVM": {
    "title": "Memorize Step by Step: Efficient Long-Context Prefilling with Incremental Memory and Decremental Chunk",
    "volume": "review",
    "abstract": "The evolution of Large Language Models (LLMs) has led to significant advancements, with models like Claude and Gemini capable of processing contexts up to 1 million tokens. However, efficiently handling long sequences remains challenging, particularly during the prefilling stage when input lengths exceed GPU memory capacity. Traditional methods often segment sequence into chunks and compress them iteratively with fixed-size memory. However, our empirical analysis shows that the fixed-size memory results in wasted computational and GPU memory resources. Therefore, we introduces Incremental Memory (IM), a method that starts with a small memory size and gradually increases it, optimizing computational efficiency. Additionally, we propose Decremental Chunk based on Incremental Memory (IMDC), which reduces chunk size while increasing memory size, ensuring stable and lower GPU memory usage. Our experiments demonstrate that IMDC is consistently faster (1.45x) and reduces GPU memory consumption by 23.3\\% compared to fixed-size memory, achieving comparable performance on the LongBench Benchmark",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fJk1Iv91zQ": {
    "title": "Mining Word Boundaries from Speech for Cross-domain Chinese Word Segmentation",
    "volume": "review",
    "abstract": "Inspired by early research on exploring naturally annotated data for Chinese Word Segmentation (CWS), and also by recent research on integration of speech and text processing, this work for the first time proposes to explicitly mine word boundaries from parallel speech-text data. We employ the Montreal Forced Aligner (MFA) toolkit to perform character-level alignment on speech-text data, giving pauses as candidate word boundaries. Based on detailed analysis of collected pauses, we propose an effective probability-based strategy for filtering unreliable word boundaries. To more effectively utilize word boundaries as extra training data, we also propose a robust complete-then-train (CTT) strategy. We conduct cross-domain CWS experiments on two target domains, i.e., ZX and AISHELL2. We have also annotated about 900 sentences as the evaluation data of AISHELL2. Experiments demonstrate the effectiveness of our proposed approach",
    "checked": false,
    "id": "827adfd441ed4df68ada97b89638cb002e593835",
    "semantic_title": "mining word boundaries in speech as naturally annotated word segmentation data",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sl5MjsXQnB": {
    "title": "Can LLMs Patch Security Issues?",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) have shown impressive proficiency in code generation. Unfortunately, these models share a weakness with their human counterparts: producing code that inadvertently has security vulnerabilities. These vulnerabilities could allow unauthorized attackers to access sensitive data or systems, which is unacceptable for safety-critical applications. %In this paper, we evaluate LLMs' ability to generate vulnerable code on existing datasets and approaches, discuss the limitations, and propose a new dataset and novel approach to address these limitations. We propose Feedback-Driven Security Patching (FDSP), where LLMs automatically refine generated, vulnerable code. Our approach leverages automatic static code analysis to empower the LLM to generate and implement potential solutions to address vulnerabilities. We address the research community's needs for safe code generation by introducing a large-scale dataset, PythonSecurityEval, covering the diversity of real-world applications, including databases, websites and operating systems. We empirically validate that FDSP outperforms prior work that uses self-feedback from LLMs by up to 17.6\\% through our procedure that injects targeted, external feedback. Code and data are attached",
    "checked": true,
    "id": "f1c93c2f2e0fad83f323db5a6b6ac1aec9dbd830",
    "semantic_title": "can llms patch security issues?",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=CXcaPRwKYz": {
    "title": "What Makes Two Language Models Think Alike?",
    "volume": "review",
    "abstract": "Do architectural differences significantly affect the way models represent and process language? We propose a new approach, based on metric-learning encoding models (MLEMs), as a first step to answer this question. The approach provides a feature-based comparison of how any two layers of any two models represent linguistic information. We apply the method to BERT, GPT-2 and Mamba. Unlike previous methods, MLEMs offer a transparent comparison, by identifying the specific linguistic features responsible for similarities and differences. More generally, the method uses formal, symbolic descriptions of a domain, and use these to compare neural representations. As such, the approach can straightforwardly be extended to other domains, such as speech and vision, and to other neural systems, including human brains",
    "checked": true,
    "id": "5c889532c401e719beabc45d2df5bcea1367839f",
    "semantic_title": "what makes two language models think alike?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B5BlmsErGE": {
    "title": "DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature",
    "volume": "review",
    "abstract": "Recent advancements in large language models (LLMs) have achieved promising performances across various applications. Nonetheless, the ongoing challenge of integrating long-tail knowledge continues to impede the seamless adoption of LLMs in specialized domains. In this work, we introduce DALK, a.k.a. Dynamic Co-Augmentation of LLMs and KG, to address this limitation and demonstrate its ability on studying Alzheimer's Disease (AD), a specialized sub-field in biomedicine and a global health priority. With a synergized framework of LLM and KG mutually enhancing each other, we first leverage LLM to construct an evolving AD-specific knowledge graph (KG) sourced from AD-related scientific literature, and then we utilize a coarse-to-fine sampling method with a novel self-aware knowledge retrieval approach to select appropriate knowledge from the KG to augment LLM inference capabilities. The experimental results, conducted on our constructed AD question answering (ADQA) benchmark, underscore the efficacy of DALK. Additionally, we perform a series of detailed analyses that can offer valuable insights and guidelines for the emerging topic of mutually enhancing KG and LLM",
    "checked": true,
    "id": "f0a3cc74df84803589b8e8850fa3434d06e0c8eb",
    "semantic_title": "dalk: dynamic co-augmentation of llms and kg to answer alzheimer's disease questions with scientific literature",
    "citation_count": 7,
    "authors": []
  },
  "https://openreview.net/forum?id=buHxwAaG2x": {
    "title": "TokenVerse: Unifying Speech and NLP Tasks via Transducer-based ASR",
    "volume": "review",
    "abstract": "In traditional conversational intelligence from speech, a cascaded pipeline is used, involving tasks such as voice activity detection, diarization, transcription, and subsequent processing with different NLP models for tasks like semantic endpointing and named entity recognition (NER). Our paper introduces TokenVerse, a single Transducer-based model designed to handle multiple tasks. This is achieved by integrating task-specific tokens into the reference text during ASR model training, streamlining the inference and eliminating the need for separate NLP models. In addition to ASR, we conduct experiments on 3 different tasks: speaker change detection, endpointing, and NER. Our experiments on a public and a private dataset show that the proposed method improves ASR by up to 7.7% in relative WER while outperforming the cascaded pipeline approach in individual task performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hdZYHlDMez": {
    "title": "Self-Enhanced Reasoning Training: Activating Latent Reasoning in Small Models for Effective Knowledge Distillation",
    "volume": "review",
    "abstract": "The deployment of large language models (LLMs) in resource-constrained environments is hindered by their high computational demands. Traditional knowledge distillation methods struggle with significant distributional mismatches between the reasoning outputs of large teacher models and smaller student models. This study introduces Self-Enhanced Reasoning Training (SERT), a novel approach that activates the latent reasoning capabilities of small models prior to distillation. By leveraging inherent reasoning paths, SERT prepares these models for more effective knowledge transfer. Empirical results show that SERT not only narrows the generation gap between large and small models but also improves their reasoning performance significantly. SERT-activated models produce outputs with greater format consistency and reduced repetition, achieving higher accuracy than those trained via direct distillation methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9ISCsjScVW": {
    "title": "What Makes Cryptic Crosswords Challenging for LLMs?",
    "volume": "review",
    "abstract": "Cryptic crosswords are puzzles that rely on general knowledge and the solver's ability to manipulate language on different levels, dealing with various types of wordplay. Previous research suggests that solving such puzzles is a challenge even for modern NLP models. However, the abilities of large language models (LLMs) have not yet been tested on this task. In this paper, we establish the benchmark results for two popular LLMs: {\\tt LLaMA3} and {\\tt ChatGPT}, showing that their performance on this task is still far from that of humans. We also investigate why the models struggle to achieve superior performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=57q5tBHu6X": {
    "title": "Counter Turing Test ($CT^2$): Investigating AI-Generated Text Detection for Hindi - Ranking LLMs based on Hindi AI Detectability Index ($ADI_{hi}$)",
    "volume": "review",
    "abstract": "The widespread adoption of large language models (LLMs) and awareness around multilingual LLMs have raised concerns regarding the potential risks and repercussions linked to the misapplication of AI-generated text, necessitating increased vigilance. While these models are primarily trained for English, their extensive training on vast datasets covering almost the entire web, equips them with capabilities to perform well in numerous other languages. AI-Generated Text Detection (AGTD) has emerged as a topic that has already received immediate attention in research, with some initial methods having been proposed, soon followed by the emergence of techniques to bypass detection. In this paper, we report our investigation on AGTD for an indic language Hindi. Our major contributions are in four folds: i) examined 26 LLMs to evaluate their proficiency in generating Hindi text, ii) introducing the AI-generated news article in Hindi (AG\\textsubscript{hi}) dataset, iii) evaluated the effectiveness of five recently proposed AGTD techniques: ConDA, J-Guard, RADAR, RAIDAR and Intrinsic Dimension Estimation for detecting AI-generated Hindi text, iv) proposed Hindi AI Detectability Index ($ADI_{hi}$) which shows a spectrum to understand the evolving landscape of eloquence of AI-generated text in Hindi. To encourage further research in this field, we will be making the models and datasets available. The code and dataset can be found \\href{https://anonymous.4open.science/r/AGTD_Hindi-BC43/}{here}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FqHlUgDir4": {
    "title": "DeconICA: Deconfounding the Dataset Bias for Domain Generalization",
    "volume": "review",
    "abstract": "Domain generalization provides a research spot for enhancing the generalization capability of the machine learning model. We focus on a causal perspective for the domain generalization task. In causal theory, a confounder is a factor that affects both the cause and the effect. The confounder is often hidden, which causes problems in correctly performing the intervention. The Deconfounder approach indicates that a factorized multiple causes could be considered a substitute confounder. We choose a non-linear ICA method to factorize the data features to represent the confounder. The confounder is considered to represent the background, and domain biases. Empirical results on text and image classification domain generalization validate the proposed methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MBfnmeBFlC": {
    "title": "Representational Isomorphism and Alignment of Multilingual Large Language Models",
    "volume": "review",
    "abstract": "In this paper, we investigate the capability of large language models (LLMs) to represent texts in multilingual contexts. Our findings reveal that sentence representations derived from LLMs exhibit a high degree of isomorphism across languages. This existing isomorphism facilitates representational alignments in few-shot or even zero-shot settings. Specifically, by applying a contrastive objective at the representation level with only a small number (e.g., 100) of translation pairs, we significantly improve models' performance on Semantic Textual Similarity (STS) tasks across languages. This representation-level approach proves to be more efficient and effective for semantic alignment than continued pretraining or instruction tuning. Interestingly, we also observe substantial STS improvements within individual languages, even without a monolingual objective specifically designed for this purpose",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3wCpk0bnFU": {
    "title": "Leveraging Domain Knowledge for Efficient Reward Modeling in RLHF: A Case-Study in E-Commerce Opinion Summarization",
    "volume": "review",
    "abstract": "E-Commerce Opinion Summarization is the task of summarizing users' opinions expressed on a product (such as laptop, book, etc.). Prior approaches have failed to impart the human-desirable properties within an opinion summary. Recently, Reinforcement Learning from Human Feedback (RLHF) has become a dominant strategy in aligning Language Models (LMs) with human values. This motivates us to leverage RLHF for our task. The key to the strategy is learning a reward model ($\\varphi$), which can reflect the latent reward model of humans. The training process for $\\varphi$ requires sizeable human preference data, usually in the order of tens of thousands. However, human goals are subjective, and vary from task-to-task, hindering us from using a general purpose off-the-shelf reward model. This necessitates a large-scale preference annotation for our task, which is expensive and time-consuming. To address this challenge and still leverage RLHF, we propose a novel approach to infuse domain knowledge into $\\varphi$, which reduces the amount of preference annotation required ($21\\times$), while advancing SOTA ($\\sim4$-point \\rouge{L} improvement, $68\\%$ of times preferred by humans over SOTA). Our technique also omits Alignment Tax and provides some interpretability. We release our code: [anon.4open.science/efficient-rlhf](https://anonymous.4open.science/r/reward-approx-social-choice-opp-summ-B380)",
    "checked": false,
    "id": "c14b58a49667fb0990759905ea3b874d50a983d1",
    "semantic_title": "leveraging domain knowledge for efficient reward modelling in rlhf: a case-study in e-commerce opinion summarization",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F0hrLeNX6d": {
    "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
    "volume": "review",
    "abstract": "Recently, very large language models (LLMs) have shown exceptional performance on several English NLP tasks with just in-context learning (ICL), but their utility in other languages is still underexplored. We investigate their effectiveness for NLP tasks in low-resource languages (LRLs), especially in the setting of *zero-labelled* cross-lingual transfer (0-CLT), where no labelled training data for the target language is available -- however training data from one or more related medium-resource languages (MRLs) is utilized, alongside the available unlabeled test data for a target language. We introduce Self-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT setting. SSP is based on the key observation that LLMs output more accurate labels if in-context exemplars are from the target language (even if their labels are slightly noisy). To operationalize this, since target language training data is not available in 0-CLT, SSP operates in two stages. In Stage I, using source MRL training data, target language's test data is noisily labeled. In Stage II, these noisy test data points are used as exemplars in ICL for further improved labelling. Additionally, our implementation of SSP uses a novel Integer Linear Programming (ILP)-based exemplar selection that balances similarity, prediction confidence (when available) and label coverage. Experiments on three tasks and eleven LRLs (from three regions) demonstrate that SSP strongly outperforms existing SOTA fine-tuned and prompting-based baselines in 0-CLT setup",
    "checked": true,
    "id": "4e298242fd18904c09c67729d8f417546b0d02d0",
    "semantic_title": "ssp: self-supervised prompting for cross-lingual transfer to low-resource languages using large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jQKR6UQd9u": {
    "title": "Subjective Topic meets LLMs: Unleashing Comprehensive, Reflective and Creative Thinking through the Negation of Negation",
    "volume": "review",
    "abstract": "Large language models (LLMs) exhibit powerful reasoning capacity, as evidenced by prior studies focusing on objective topics that with unique standard answers such as arithmetic and commonsense reasoning. However, the reasoning to definite answers emphasizes more on logical thinking, and falls short in effectively reflecting the comprehensive, reflective, and creative thinking that is also critical for the overall reasoning prowess of LLMs. In light of this, we build a dataset SJTP comprising diverse SubJective ToPics with free responses, as well as three evaluation indicators to fully explore LLM's reasoning ability. We observe that a sole emphasis on logical thinking falls short in effectively tackling subjective challenges. Therefore, we introduce a framework grounded in the principle of the Negation of Negation (NeoN) to unleash the potential comprehensive, reflective, and creative thinking abilities of LLMs.Comprehensive experiments on SJTP demonstrate the efficacy of NeoN, and the enhanced performance on various objective reasoning tasks unequivocally underscores the benefits024 of stimulating LLM's subjective thinking in augmenting overall reasoning capabilities",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qQoWZ0C3ML": {
    "title": "TRACE: TRansformer-based Attribution using Contrastive Embeddings in LLMs",
    "volume": "review",
    "abstract": "The rapid evolution of large language models (LLMs) represents a substantial leap forward in natural language understanding and generation. However, alongside these advancements come significant challenges related to the accountability and transparency of LLM outputs. Reliable source attribution is essential to adhering to stringent legal and regulatory standards, including those set forth by the General Data Protection Regulation. Despite the well-established methods in source attribution within the computer vision domain, the application of robust attribution frameworks to natural language processing remains underexplored. To bridge this gap, we propose a novel and versatile TRansformer-based Attribution framework using Contrastive Embeddings called TRACE that, in particular, exploits contrastive learning for source attribution. We perform an extensive empirical evaluation to demonstrate the performance and efficiency of TRACE in various settings and show that TRACE significantly improves the ability to attribute sources accurately, making it a valuable tool for enhancing the reliability and trustworthiness of LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DLhsUyK4F5": {
    "title": "Formality Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge",
    "volume": "review",
    "abstract": "Having been trained on massive pretraining data, large language models have shown excellent performance on many knowledge-intensive tasks. However, pretraining data tends to contain misleading and even conflicting information, and it is intriguing to understand how LLMs handle these noisy data during training. In this study, we systematically analyze LLMs' learning preferences for data with conflicting knowledge. We find that pretrained LLMs establish learning preferences similar to humans, i.e., preferences towards formal texts and texts with fewer spelling errors, resulting in faster learning and more favorable treatment of knowledge in data with such features when facing conflicts. This finding is generalizable across models and languages and is more evident in larger models. An in-depth analysis reveals that LLMs tend to trust data with features that signify consistency with the majority of data, and it is possible to instill new preferences and erase old ones by manipulating the degree of consistency with the majority data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MdydT5NSmq": {
    "title": "Non-Asymptotic Convergence Bounds for Cross-Entropy Estimation between Neural Auto-Regressive Language Models: Theoretical Analysis",
    "volume": "review",
    "abstract": "Cross-entropy (CE) represents a central metric in evaluating the performance and other characteristics of Neural Auto-Regressive Language Models (NARLMs). Despite its importance, the convergence properties of its estimation remain relatively underexplored from a theoretical perspective, primarily due to the complex structure of modern language model architectures. This article aims at investigating this issue by providing a formal theoretical analysis of the covergence properties of the CE estimation between different families of NARLMs. When the test distribution is modeled by a LSTM/GRU, we will show that CE estimation exhibits a non-vacuous convergence rate, which depends linearly on the norm of the output matrix of the test model and logarithmically on the alphabet size. Additionaly, we provide a variance-based convergence bound applicable to large families of NARLM, including Decoder-only Transformer-based models and LSTMs/GRUs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e0aS6qUefY": {
    "title": "Handling the Follow-up Question: Conversational Explanations for Image Classification",
    "volume": "review",
    "abstract": "Explainable AI (XAI) aims to provide insights into decisions made by deep neural networks. To date, most XAI approaches provide only one-time, static explanations, which cannot cater to users' diverse knowledge levels and information needs. Conversational explanations have been proposed as an effective method to customize XAI explanations. However, building conversational explanation systems is hindered by the scarcity of training data. Training with synthetic data faces two main challenges: lack of data diversity and hallucination in the generated data. To alleviate these issues, we introduce a repetition penalty to promote data diversity and exploit a hallucination detector to filter out untruthful synthetic conversation turns. The proposed system, fEw-shot Multi-round ConvErsational Explanation (EMCEE), achieves relative improvements of 81.6\\% in BLEU and 80.5\\% in ROUGE compared to the baselines. EMCEE also mitigates the degeneration of data quality caused by training on synthetic data. In human evaluations, EMCEE outperforms baseline models in improving users' comprehension, acceptance, trust, and collaboration with static explanations by large margins. To the best of our knowledge, this is the first conversational explanation method that can answer arbitrary user questions that follow from static explanations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HMg3RmxR96": {
    "title": "CKBP v2: Better Annotation and Reasoning for Commonsense Knowledge Base Population",
    "volume": "review",
    "abstract": "Commonsense Knowledge Bases (CSKB) Population, which aims at automatically expanding knowledge in CSKBs with external resources, is an important yet hard task in NLP. Fang et al. (2021a) proposed a CSKB Population (CKBP) framework with an evaluation set CKBP v1. However, CKBP v1 relies on crowdsourced annotations that suffer from a considerable number of mislabeled answers, and the evaluation set lacks alignment with the external knowledge source due to random sampling. In this paper, we introduce CKBP v2, a new high-quality CSKB Population evaluation set that addresses the two aforementioned issues by employing domain experts as annotators and incorporating diversified adversarial samples to make the evaluation data more representative. We show that CKBP v2 serves as a challenging and representative evaluation dataset for the CSKB Population task, while its development set aids in selecting a population model that leads to improved knowledge acquisition for downstream commonsense reasoning. A better population model can also help acquire more informative commonsense knowledge as additional supervision signals for both generative commonsense inference and zero-shot commonsense question answering. Specifically, the question-answering model based on DeBERTa-v3-large (He et al., 2023b) even outperforms powerful large language models in a zero-shot setting, including ChatGPT and GPT-3.5",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=27scPv7iSP": {
    "title": "Synthetic Data Generation with Large Language Models for Personalized Community Question Answering",
    "volume": "review",
    "abstract": "Personalization in Information Retrieval (IR) is a topic studied by the community for a long time. However, the collection and curation of high-quality training data requires significant costs and time investment, especially for collecting user-related information. In this paper we explore the usefulness of Large Language Models (LLMs) in generating synthetic documents tailored to user's personal interests using user-related information. We introduce a new dataset, Sy-SE-PQA, to study the effectiveness of models fine-tuned on LLM-generated data and study how the complexity of personalization impacts model performances. We build Sy-SE-PQA based on an existing dataset, SE-PQA, which consists of questions and answers posted on the popular StackExchange communities. Starting from questions in SE-PQA, we generate synthetic answers using different prompt techniques and LLMs. Our findings suggest that LLMs have high potential in generating training data, tailored to user's needs, for neural retrieval models and it can be used to replace training data. The code is publicly available",
    "checked": false,
    "id": "b9194cf73bfa63aabe69532af6a58cee9e541872",
    "semantic_title": "ua-llm: advancing context-based question answering in ukrainian through large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cEZBq67YOz": {
    "title": "Towards Explainable Chinese Native Learner Essay Fluency Assessment: Dataset, Tasks, and Method",
    "volume": "review",
    "abstract": "Grammatical Error Correction (GEC) is a crucial technique in Automated Essay Scoring (AES) for evaluating the fluency of essays. However, in Chinese, existing GEC datasets often fail to consider the importance of specific grammatical error types within compositional scenarios, lack research on data collected from native Chinese speakers, and largely overlook cross-sentence grammatical errors. Furthermore, the measurement of the overall fluency of an essay is often overlooked. To address these issues, we present CEFA (Chinese Essay Fluency Assessment), an extensive corpus that is derived from essays authored by native Chinese-speaking primary and secondary students and encapsulates essay fluency scores along with both coarse and fine-grained grammatical error types and corrections. Experiments employing various benchmark models on CEFA substantiate the challenging nature of our dataset. Our findings further highlight the significance of fine-grained annotations in fluency assessment and the mutually beneficial relationship between error types and corrections. We will make the corpus and related codes available for research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XOK0jVBlok": {
    "title": "States Hidden in Hidden States: LLMs Emerge Discrete State Representations Implicitly",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) exhibit various emergent abilities. Among these abilities, some might reveal the internal working mechanisms of models. In this paper, we uncover a novel emergent capability in models: the intrinsic ability to perform extended sequences of calculations without relying on chain-of-thought step-by-step solutions. Remarkably, the most advanced models are capable of directly outputting the results of two-digit number additions with lengths extending up to 15 addends. We hypothesize that the model emerges discrete representations of symbols within its hidden states and performs symbolic calculations internally. To test this hypothesis, we design a sequence of experiments that look into the hidden states. Specifically, we first confirm that Implicit Discrete State Representations (IDSRs) exist. Then, we provide interesting observations about the formation of IDSRs from layer, digit, and sequence perspectives. Finally, we confirm that models indeed use IDSRs to produce the final answers. However, we also discover that the state representations are far from lossless in current open-sourced models, leading to inaccuracies in final performance. Our work presents a novel exploration of LLMs' symbolic calculation abilities and the underlying mechanisms",
    "checked": true,
    "id": "504f3713a74c66d61a46fe658988861302eb088d",
    "semantic_title": "states hidden in hidden states: llms emerge discrete state representations implicitly",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BSWRClgew8": {
    "title": "Can Tool-augmented Large Language Models be Aware of Incomplete Conditions?",
    "volume": "review",
    "abstract": "Recent advancements in integrating large language models (LLMs) with tools have allowed the models to interact with real-world environments. However, these tool-augmented LLMs often encounter incomplete scenarios when users provide partial information or the necessary tools are unavailable. Recognizing and managing such scenarios is crucial for LLMs to ensure their reliability, but this exploration remains understudied. This study examines whether LLMs can identify incomplete conditions and appropriately determine when to refrain from using tools. To this end, we address a dataset by manipulating instances from two datasets by removing necessary tools or essential information for tool invocation. We confirm that most LLMs are challenged to identify the additional information required to utilize specific tools and the absence of appropriate tools. Our research can contribute to advancing reliable LLMs by addressing scenarios that commonly arise during interactions between humans and LLMs. Our code and dataset will be made publicly available",
    "checked": true,
    "id": "7b31f2d677677afb401773f2660581c1ec5c650d",
    "semantic_title": "can tool-augmented large language models be aware of incomplete conditions?",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cdLL7qJN0T": {
    "title": "Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language Models",
    "volume": "review",
    "abstract": "Pretrained language models memorize vast amounts of information, including private and copyrighted data, raising significant safety concerns. Retraining these models after excluding sensitive data is prohibitively expensive, making machine unlearning a viable, cost-effective alternative. Previous research has focused on machine unlearning for monolingual models, but we find that unlearning in one language does not necessarily transfer to others. This vulnerability makes models susceptible to low-resource language attacks, where sensitive information remains accessible in less dominant languages. This paper presents a pioneering approach to machine unlearning for multilingual language models, selectively erasing information across different languages while maintaining overall performance. Specifically, our method employs an adaptive unlearning scheme that assigns language-dependent weights to address different language performances of multilingual language models. Empirical results demonstrate the effectiveness of our framework compared to existing unlearning baselines, setting a new standard for secure and adaptable multilingual language models",
    "checked": true,
    "id": "04da681a5cd508826c134f0a65c5c12acd0edd46",
    "semantic_title": "cross-lingual unlearning of selective knowledge in multilingual language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BCC3EfGzyw": {
    "title": "Bridging Law and Data: Augmenting Reasoning via a Semi-Structured Dataset with IRAC methodology",
    "volume": "review",
    "abstract": "The effectiveness of Large Language Models (LLMs) in legal reasoning is often limited due to the unique legal terminologies and the necessity for highly specialized knowledge. These limitations highlight the need for high-quality data tailored for complex legal reasoning tasks. This paper introduces LEGALSEMI, a benchmark specifically curated for legal scenario analysis. LEGALSEMI comprises 54 legal scenarios, each rigorously annotated by legal experts, based on the comprehensive IRAC (Issue, Rule, Application, Conclusion) framework. In addition, LEGALSEMI is accompanied by a structured knowledge graph (SKG). A series of experiments were conducted to assess the usefulness of LEGALSEMI for IRAC analysis. The experimental results demonstrate the effectiveness of incorporating the SKG for issue identification, rule retrieval, application and conclusion generation using four different LLMs. LEGALSEMI will be publicly available upon acceptance of this paper",
    "checked": true,
    "id": "1c6c7162e8a87b0b5814beec36911bb998cbc89f",
    "semantic_title": "bridging law and data: augmenting reasoning via a semi-structured dataset with irac methodology",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m56BGyFBB2": {
    "title": "StorySpark: Expert-Annotated QA Pairs with Real-World Knowledge for Children Storytelling",
    "volume": "review",
    "abstract": "Interactive storytelling between parents and children is a common activity in the real world, in which parents expect to teach children both language skills and real-world knowledge beyond the story narratives. While increasing AI-assisted storytelling systems have been developed and used in children's story-based interaction and learning scenarios, existing systems often fall short of generating real-world knowledge infused conversation to meet parents' practical expectation of interactive storytelling, with the foremost reason of existing question-answering (QA) datasets these systems build on focusing mainly on the knowledge answerable within the story content. To bridge this gap, we designed an annotation framework empowered by real-world knowledge graph to facilitate experts' annotations while collecting their mental procedures. Further, we leveraged this annotation framework to build StorySpark, a dataset of 5,868 expert-annotated QA pairs with real-world knowledge beyond story context. A comprehensive benchmarking experiment, including both automated and human expert evaluation within various QA pair generation (QAG) settings, demonstrates the usability of our StorySpark on the story-based knowledgeable QAG task. Worth mentioning that a traditional compact model fine-tuned on StorySpark can reliably outperform robust LLMs. This further highlights the complexity of such real-world tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FhBWQJGlDW": {
    "title": "UBENCH: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions",
    "volume": "review",
    "abstract": "The rapid development of large language models (LLMs) has shown promising practical results. However, their low interpretability often leads to errors in unforeseen circumstances, limiting their utility. Many works have focused on creating comprehensive evaluation systems, but previous benchmarks have primarily assessed problem-solving abilities while neglecting the response's uncertainty, which may result in unreliability. Recent methods for measuring LLM reliability are resource-intensive and unable to test black-box models. To address this, we propose UBENCH, a comprehensive benchmark for evaluating LLM reliability. UBENCH includes 3,978 multiple-choice questions covering knowledge, language, understanding, and reasoning abilities. Experimental results show that UBENCH has achieved state-of-the-art performance, while its single-sampling method significantly saves computational resources compared to baseline methods that require multiple samplings. Additionally, based on UBENCH, we evaluate the reliability of 15 popular LLMs, finding GLM4 to be the most outstanding, closely followed by GPT-4. We also explore the impact of Chain-of-Thought prompts, role-playing prompts, option order, and temperature on LLM reliability, analyzing the varying effects on different LLMs. Our implementation available at https://anonymous.4open.science/r/UBench",
    "checked": true,
    "id": "c14963a444405a9caca3c3c3aa5b16d1f5e1fb54",
    "semantic_title": "ubench: benchmarking uncertainty in large language models with multiple choice questions",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=QKsn2QE1Sw": {
    "title": "LeanQuant: Accurate Large Language Model Quantization with Loss-Error-Aware Grid",
    "volume": "review",
    "abstract": "Large language models (LLMs) have numerous applications across various domains, but their high computational and memory demands pose significant deployment challenges. Weight quantization is an effective technique for reducing the decoding latency and memory requirements of LLMs. Existing approaches primarily aim to maintain the quality of quantized models by preserving outliers in input features, but they still suffer significant quality loss at lower bit widths. Our approach builds on Optimal Brain Quantization (OBQ), an iterative weight-update-based quantization framework. We identify a key limitation of OBQ, specifically that its uniform quantization grid is suboptimal for maintaining model quality, as it introduces large errors to the task loss. To address this, we propose LeanQuant, which learns a loss-error-aware quantization grid by leveraging the inverse diagonal Hessian. Extensive experimental results demonstrate that our method compares favorably against competitive baselines and effectively accelerates LLM inference",
    "checked": true,
    "id": "9c580c162f028c20ad0516c220bbca32d9f8edf9",
    "semantic_title": "leanquant: accurate large language model quantization with loss-error-aware grid",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0N9nj2a0MH": {
    "title": "Can Few-shot Work in Long-Context? Recycling the Context to Generate Demonstrations",
    "volume": "review",
    "abstract": "Despite recent advancements in Large Language Models (LLMs), their performance on tasks involving long contexts remains sub-optimal. In-Context Learning (ICL) with few-shot examples may be an appealing solution to enhance LLM performance in this scenario too. However, na\\\"ively adding ICL examples with long context faces challenges, including domain shifts between demonstrations and the target query and substantial token overhead added for each example. In this work, we propose to automatically generate few-shot examples for long context QA tasks by recycling contexts. Specifically, given a long input context (1-3k tokens) and a query, we generate additional query-output pairs from the given context as few-shot examples. This ensures that the demonstrations come from the same domain as the target query and only add a small number of tokens to the prompt. Furthermore, we enhance each demonstration example by instructing the model to \\textit{explicitly} identify the relevant paragraphs before the answer. This approach acts as a structured Chain of Thought and provides fine-grained attribution to the answer. We apply our method on multiple models and obtain a substantial improvement on various QA datasets with long context, especially when the answer lies within the middle of the text. Surprisingly, despite introducing only single-passage ICL examples, LLMs successfully generalize to multi-hop long-context QA using our approach",
    "checked": true,
    "id": "48a00907faea2ccb56ee45495aaef8953ccf6535",
    "semantic_title": "can few-shot work in long-context? recycling the context to generate demonstrations",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=55pXzoTgFS": {
    "title": "Towards Truthful Multilingual Large Language Models: Benchmarking and Alignment Strategies",
    "volume": "review",
    "abstract": "In the era of large language models (LLMs), building multilingual large language models (MLLMs) that can serve users worldwide holds great significance. However, existing research seldom focuses on the truthfulness of MLLMs. Meanwhile, contemporary multilingual aligning technologies struggle to balance massive languages and often exhibit serious truthfulness gaps across different languages, especially those that differ greatly from English. In our work, we construct a benchmark for truthfulness evaluation in multilingual scenarios and explore the ways to align facts across languages to enhance the truthfulness of MLLMs. Furthermore, we propose *Fact-aware Multilingual Selective Synergy* (FaMSS) to optimize the data allocation across a large number of languages and different data types. Experimental results demonstrate that our approach can effectively reduce the multilingual representation disparity and enhance the multilingual capabilities of LLMs",
    "checked": true,
    "id": "90f780915df90786428f9a76db3eb61b99177b35",
    "semantic_title": "towards truthful multilingual large language models: benchmarking and alignment strategies",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vYXgey0drZ": {
    "title": "Match, Compare, or Select? An Investigation of Large Language Models for Entity Matching",
    "volume": "review",
    "abstract": "Entity matching (EM) is a critical step in entity resolution. Recently, entity matching based on large language models (LLMs) has shown great promise. However, current LLM-based entity matching approaches typically follow a binary matching paradigm that ignores the global consistency between record relationships. In this paper, we investigate various methodologies for LLM-based entity matching that incorporate record interactions from different perspectives. Specifically, we comprehensively compare three representative strategies: matching, comparing, and selecting, and analyze their respective advantages and challenges in diverse scenarios. Based on our findings, we further design a compound entity matching framework (ComEM) that leverages the composition of multiple strategies and LLMs. ComEM benefits from the advantages of different sides and achieves improvements in both effectiveness and efficiency. Experimental results verify that ComEM not only achieves significant performance gains on various datasets, but also reduces the cost of LLM-based entity matching for practical applications",
    "checked": true,
    "id": "3042f56baf64b06ba5f236f8237ec10174ba6ae2",
    "semantic_title": "match, compare, or select? an investigation of large language models for entity matching",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Umrjf5EVkl": {
    "title": "CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages",
    "volume": "review",
    "abstract": "Neural dependency parsing has achieved remarkable performance for low resource morphologically rich languages. It has also been well-studied that morphologically rich languages exhibit relatively free word order. This prompts a fundamental investigation: *Is there a way to enhance dependency parsing performance, making the model robust to word order variations utilizing the relatively free word order nature of morphologically rich languages?* In this work, we examine the robustness of graph-based parsing architectures on 7 relatively free word order languages. We focus on scrutinizing essential modifications such as data augmentation and the removal of position encoding required to adapt these architectures accordingly. To this end, we propose a contrastive self-supervised learning method to make the model robust to word order variations. Furthermore, our proposed modification demonstrates a substantial average gain of 3.03/2.95 points in 7 relatively free word order languages, as measured by the UAS/LAS Score metric when compared to the best performing baseline",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PYCkzS8WJr": {
    "title": "Leveraging Multimodal Fusion for Advanced Fake News Detection",
    "volume": "review",
    "abstract": "Detecting multimodal fake news is imperative for maintaining social media security and safeguarding community well-being. Existing detection approaches often fall short in adequately considering the nuanced context of social media and fail to fully utilize various modalities such as metadata, resulting in a significant gap. In this paper, we propose a novel and efficient model that integrates both textual global features and local features. This model captures semantic relationships within the text and utilizes a global corpus representation to align with the complex context of social media. We further enhance feature connectivity by employing a multilevel fusion technique that integrates visual and metadata information. Extensive experiments demonstrate that our method achieves state-of-the-art performance across all classification tasks using Fakeddit, the largest multimodal fake news dataset, underscoring its effectiveness",
    "checked": false,
    "id": "2efc32cb1ba8a49dee41e4f2f4ca6850ff57a7f7",
    "semantic_title": "a mutual attention based multimodal fusion for fake news detection on social network",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=xyswzRGYu1": {
    "title": "Towards Tool Use Alignment of Large Language Models",
    "volume": "review",
    "abstract": "Recently, tool use with LLMs has become one of the primary research topics as it can help LLM generate truthful and helpful responses. Existing studies on tool use with LLMs primarily focus on enhancing the tool-calling ability of LLMs. In practice, like chat assistants, LLMs are also required to align with human values in the context of tool use. Specifically, LLMs should refuse to answer unsafe tool use relevant instructions and insecure tool responses to ensure their reliability and harmlessness. At the same time, LLMs should demonstrate autonomy in tool use to reduce the costs associated with tool calling. To tackle this issue, we first introduce the principle that LLMs should follow in tool use scenarios: H2A. The goal of H2A is to align LLMs with $\\textbf{helpfulness}$, $\\textbf{harmlessness}$, and $\\textbf{autonomy}$. In addition, we propose ToolAlign, a dataset comprising instruction-tuning data and preference data to align LLMs with the H2A principle for tool use. Based on ToolAlign, we develop LLMs by supervised fine-tuning and preference learning, and experimental results demonstrate that the LLMs exhibit remarkable tool-calling capabilities, while also refusing to engage with harmful content, and displaying a high degree of autonomy in tool utilization. The code and datasets are avaliable at: https://anonymous.4open.science/r/ToolAlign",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=crEmQ7Gfuy": {
    "title": "Turn Waste into Worth: Rectifying Top-$k$ Router of MoE",
    "volume": "review",
    "abstract": "Sparse Mixture of Experts (MoE) models are popular for training large language models due to their computational efficiency. However, the commonly used top-$k$ routing mechanism suffers from redundancy computation and memory costs due to the unbalanced routing. Some experts are overflow, where the exceeding tokens are dropped. While some experts are empty, which are padded with zeros, negatively impacting model performance. To address the dropped tokens and padding, we propose the Rectify-Router, comprising the Intra-GPU Rectification and the Fill-in Rectification. The Intra-GPU Rectification handles dropped tokens, efficiently routing them to experts within the GPU where they are located to avoid inter-GPU communication. The Fill-in Rectification addresses padding by replacing padding tokens with the tokens that have high routing scores. Our experimental results demonstrate that the Intra-GPU Rectification and the Fill-in Rectification effectively handle dropped tokens and padding, respectively. Furthermore, the combination of them achieves superior performance, surpassing the accuracy of the vanilla top-1 router by 4.7\\%",
    "checked": false,
    "id": "656f4a76bcbc1a3a032ef5cf284909ef1bb58156",
    "semantic_title": "turn waste into worth: rectifying top-k router of moe",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=SH2sMWCLSe": {
    "title": "Thoughts to Target: Enhance Planning for Target-driven Conversation",
    "volume": "review",
    "abstract": "In conversational AI, large-scale models excel in various tasks but struggle with target-driven conversation planning. Current methods, such as chain-of-thought reasoning and tree-search policy learning techniques, either neglect plan rationality or require extensive human simulation procedures. Addressing this, we propose a novel two-stage framework, named EnPL, to improve the LLMs' capability in planning conversations towards designated targets, including (1) distilling natural language plans from target-driven conversation corpus and (2) generating new plans with demonstration-guided in-context learning. Specifically, we first propose a filter approach to distill a high-quality plan dataset, ConvPlan(Resources of this paper can be found at https://anonymous.4open.science/r/ConvPlan-2023). With the aid of corresponding conversational data and support from relevant knowledge bases, we validate the quality and rationality of these plans. Then, these plans are leveraged to help guide LLMs to further plan for new targets. Empirical results demonstrate that our method significantly improves the planning ability of LLMs, especially in target-driven conversations. Furthermore, EnPL is demonstrated to be quite effective in creating large-scale target-driven conversation datasets, paving the way for constructing extensive target-driven conversational models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xEYAiRmKMc": {
    "title": "Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues",
    "volume": "review",
    "abstract": "We develop assistive agents based on Large Language Models (LLMs) that aid interlocutors in business negotiations. Specifically, we simulate business negotiations by letting two LLM-based agents engage in role play. A third LLM acts as a remediator agent to rewrite utterances violating norms for improving negotiation outcomes. We introduce a simple tuning-free and label-free In-Context Learning (ICL) method to identify high-quality ICL examples for the remediator, where we propose a novel select criteria, called \\textit{value impact}, to measure the quality of the negotiation outcomes. We provide rich empirical evidence to demonstrate its effectiveness in negotiations across three different negotiation topics. The source code and the generated dataset will be publicly available upon acceptance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zp1BNUJnMM": {
    "title": "MuPT: A Generative Symbolic Music Pretrained Transformer",
    "volume": "review",
    "abstract": "In this paper, we explore the application of Large Language Models (LLMs) to the pre-training of music. While the prevalent use of MIDI in music modeling is well-established, our findings suggest that LLMs are inherently more compatible with ABC Notation, which aligns more closely with their design and strengths, thereby enhancing the model's performance in musical composition. To address the challenges associated with misaligned measures from different tracks during generation, we propose the development of a $\\underline{S}$ynchronized $\\underline{M}$ulti-$\\underline{T}$rack ABC Notation ($\\textbf{SMT-ABC Notation}$), which aims to preserve coherence across multiple musical tracks. Our contributions include a series of models capable of handling up to 8192 tokens, covering 90% of the symbolic music data in our training set. Furthermore, we explore the implications of the $\\underline{S}$ymbolic $\\underline{M}$usic $\\underline{S}$caling Law ($\\textbf{SMS Law}$) on model performance. The results indicate a promising direction for future research in music generation, offering extensive resources for community-led research through our open-source contributions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IUbIseO8rW": {
    "title": "OfficeBench: Benchmarking Language Agents across Multiple Applications for Office Automation",
    "volume": "review",
    "abstract": "Office automation significantly enhances human productivity by automatically finishing routine tasks in the workflow. Beyond the basic information extraction studied in much of the prior document AI literature, the office automation research should be extended to more realistic office tasks which require to integrate various information sources in the office system and produce outputs through a series of decision-making processes. We introduce OfficeBench, one of the first office automation benchmarks for evaluating current LLM agents' capability to address the office tasks in realistic office workflows. OfficeBench requires LLM agents to perform feasible long-horizon planning, proficiently switch between applications in a timely manner, and accurately ground their actions within a large combined action space, based on the contextual demands of the workflow. Applying our customized evaluation methods on each task, we find that GPT-4 Omni achieves the highest pass rate of 47.00%, demonstrating a decent performance in handling office tasks. However, this is still far below the human performance and accuracy standards required by real-world office workflows. We further observe that most issues are related to operation redundancy and hallucinations, as well as limitations in switching between multiple applications, which may provide valuable insights for developing effective agent frameworks for office automation. Code and data will be released upon acceptance",
    "checked": true,
    "id": "09710b95adf178e6db154d1a54212d4b111b7a6a",
    "semantic_title": "officebench: benchmarking language agents across multiple applications for office automation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AbuBYZw0Tk": {
    "title": "LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments",
    "volume": "review",
    "abstract": "The rapid obsolescence of information in Large Language Models (LLMs) has driven the development of various techniques to incorporate new facts. However, existing methods for knowledge editing still face difficulties with multi-hop questions that require accurate fact identification and sequential logical reasoning, particularly among numerous fact updates. To tackle these challenges, this paper introduces Graph Memory-based Editing for Large Language Models (GMeLLo), a straitforward and effective method that merges the explicit knowledge representation of Knowledge Graphs (KGs) with the linguistic flexibility of LLMs. Beyond merely leveraging LLMs for question answering, GMeLLo employs these models to convert free-form language into structured queries and fact triples, facilitating seamless interaction with KGs for rapid updates and precise multi-hop reasoning. Our results show that GMeLLo significantly surpasses current state-of-the-art knowledge editing methods in the multi-hop question answering benchmark, MQuAKE, especially in scenarios with extensive knowledge edits",
    "checked": false,
    "id": "4308208fac24626e0c927ee728038aadc4e87266",
    "semantic_title": "hipporag: neurobiologically inspired long-term memory for large language models",
    "citation_count": 2,
    "authors": []
  },
  "https://openreview.net/forum?id=ByUlikMupd": {
    "title": "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets",
    "volume": "review",
    "abstract": "Large language models (LLMs) can now generate and recognize text in a wide range of styles and genres, including highly specialized, creative genres like poetry. Poetry is a lightning rod for the marketing and popular imagination of LLM capabilities because it is a signifier of human creativity and complexity, as well as a popular and culturally significant art form. But what do LLMs really know about poetry? What can they know about poetry? We develop a task to evaluate how well LLMs recognize one aspect of English-language poetry, poetic form, which captures many different poetic features, including rhyme scheme, meter, and word or line repetition. We use this task to reflect on LLMs' current poetic capabilities, as well as the challenges and pitfalls of creating NLP benchmarks for poetry and for other creative tasks. In particular, we use this task to audit and reflect on the poems included in popular pretraining datasets. Our findings have implications for NLP researchers interested in model evaluation, digital humanities and cultural analytics research, and cultural heritage collections",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CbjKOrrQxO": {
    "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
    "volume": "review",
    "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not in their weights, to perform tasks on the web, and even to control robots. However, most ontologies and surveys of tool-use have assumed the core challenge for LLMs is choosing the tool. Instead, we introduce a framework for tools more broadly which guides us to explore a model's ability to detect \"silent\" tool errors, and reflect on how to plan. This more directly aligns with the increasingly popular use of models as tools. We provide an initial approach to failure recovery with promising results both on a controlled calculator setting and embodied agent planning",
    "checked": true,
    "id": "491e129c10bca2f9e50c9c4859b3cb825d217d37",
    "semantic_title": "tools fail: detecting silent errors in faulty tools",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hi5jqzoqpI": {
    "title": "Enhancing Controllable Generation with Improved Control Module Representations",
    "volume": "review",
    "abstract": "Controllable generation (CG) has been widely used in large language models (LLMs) for a wide range of language tasks, such as multi-task learning and human preference alignment. For example, prompt-based CG uses curated prompts as inputs (such as system prompts) to control LLMs behaviors. Finetuning-based CG is widely adopted when training data is available; it trains control modules and controls LLM behaviors by plugging these modules into LLMs (e.g., trainable prompts or LoRA weights). Finetuning-based CG can freeze LLMs and only train control modules for efficiency or train LLMs together with control models for effectiveness. We argue that fine-tuning control modules together with LLMs directly is not the optimal optimization strategy since their representations are often initialized irrelevantly to LLMs' representations, which adds more difficulty for optimization. A better optimization should first align control modules with the LLM's representation space and then optimize them together. To this end, we propose a simple yet effective Two-step Freezing-then-Tuning framework (TFT) to achieve better optimization results for finetuning-based CG. Concretely, we first freeze LLMs and only optimize control modules to align their representations with LLMs, and then optimize control modules together with LLMs to ensure performance. Experiment results on two popular human preference alignment datasets and one multi-task learning dataset show that our approach significantly improves the controllable generation qualities compared with one-step optimization widely used in related works, and achieves better or on-par performance compared with other kinds of baselines, such as direct preference optimization",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FxYoajVJnW": {
    "title": "KeyInst: Keyword Instruction for Improving SQL Formulation in Text-to-SQL",
    "volume": "review",
    "abstract": "Text-to-SQL parsing involves the translation of natural language queries (NLQs) into their corresponding SQL commands. A principal challenge within this domain is the formulation of SQL queries that are not only syntactically correct but also semantically aligned with the natural language input. However, the intrinsic disparity between the NLQ and the SQL poses a significant challenge. In this research, we introduce Keyword Instruction (KeyInst), a novel method designed to enhance SQL formulation by Large Language Models (LLMs). KeyInst essentially provides guidance on pivotal SQL keywords likely to be part of the final query, thus facilitates a smoother SQL query formulation process. We explore two strategies for integrating KeyInst into Text-to-SQL parsing: a pipeline strategy and a single-pass strategy. The former first generates KeyInst for question, which are then used to prompt LLMs. The latter employs a fine-tuned model to concurrently generate KeyInst and SQL in one step. We developed StrucQL, a benchmark specifically designed for the evaluation of SQL formulation. Extensive experiments on StrucQL and other benchmarks demonstrate that KeyInst significantly improves upon the existing Text-to-SQL prompting techniques",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=si4RqKfaBS": {
    "title": "DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models",
    "volume": "review",
    "abstract": "The performance of Large Language Models (LLMs) is substantially influenced by the pretraining corpus, which consists of vast quantities of unsupervised data processed by the models. Despite its critical role in model performance, ensuring the quality of this data is challenging due to its sheer volume and the absence of sample-level quality annotations and enhancements. In this paper, we introduce DecorateLM, a data engineering method designed to refine the pretraining corpus through data rating, tagging and editing. Specifically, DecorateLM rates texts against quality criteria, tags texts with hierarchical labels, and edits texts into a more formalized format. Due to the massive size of the pretraining corpus, adopting an LLM for decorating the entire corpus is less efficient. Therefore, to balance performance with efficiency, we curate a meticulously annotated training corpus for DecorateLM using a large language model and distill data engineering expertise into a compact 1.2 billion parameter small language model (SLM). We then apply DecorateLM to enhance 100B billion tokens of the training corpus, selecting 45 billion tokens that exemplify high quality and diversity for the further training of another 1.2 billion parameter LLM. Our results demonstrate that employing such high-quality data can significantly boost model performance, showcasing a powerful approach to enhance the quality of the pretraining corpus",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HzYw72kdn4": {
    "title": "On Demonstration Selection for Language Model Fairness in Decision-Making",
    "volume": "review",
    "abstract": "Recently, there has been a surge in deploying Large Language Models (LLMs) for decision-making tasks, such as income prediction and crime risk assessments. Due to bias in the pre-training data, LLMs generally present unfairness and discrimination against underprivileged groups. However, traditional fairness enhancement methods are generally impractical for LLMs due to the computational cost of fine-tuning and the black-box nature of powerful LLMs. To deal with this, In-Context Learning (ICL) offers a promising strategy for enhancing LLM fairness through input-output pairs, without the need for extensive retraining. Nevertheless, the efficacy of ICL is hindered by the inherent bias in both data and the LLM itself, leading to the potential exaggeration of existing societal disparities. In this study, we investigate the unfairness problem in LLMs and propose a novel demonstration selection strategy to address data and model biases when applying ICL. Extensive experiments on various tasks and datasets validate the superiority of our strategy",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P8URqRlQD0": {
    "title": "AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories",
    "volume": "review",
    "abstract": "Fine-tuning on agent-environment interaction trajectory data holds significant promise for surfacing generalized agent capabilities in open-source large language models (LLMs). In this work, we introduce AgentBank, by far the largest trajectory tuning data collection featuring more than 50k diverse high-quality interaction trajectories which comprises 16 tasks covering five distinct agent skill dimensions. Leveraging a novel annotation pipeline, we are able to scale the annotated trajectories and generate a trajectory dataset with minimized difficulty bias. Furthermore, we fine-tune LLMs on AgentBank to get a series of agent models, Samoyed. Our comparative experiments demonstrate the effectiveness of scaling the interaction trajectory data to acquire generalized agent capabilities. Additional studies also reveal some key observations regarding trajectory tuning and agent skill generalization",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ol4QiyoFbq": {
    "title": "Iterative or Innovative? A Problem-Oriented Perspective for Code Optimization",
    "volume": "review",
    "abstract": "Large language models (LLMs) have demonstrated strong capabilities in solving a wide range of programming tasks. However, LLMs have rarely been explored for code optimization. In this paper, we explore code optimization with a focus on performance enhancement, specifically aiming to optimize code for minimal execution time. The recently proposed first PIE dataset for performance optimization constructs program optimization pairs based on iterative submissions from the same programmer for the same problem. However, this approach restricts LLMs to local performance improvements, neglecting global algorithmic innovation. Therefore, we adopt a completely different perspective by reconstructing the optimization pairs into a problem-oriented approach. This allows for the integration of various ingenious ideas from different programmers tackling the same problem. Experimental results demonstrate that adapting LLMs to problem-oriented optimization pairs significantly enhances their optimization capabilities. Meanwhile, we identified performance bottlenecks within the problem-oriented perspective. By employing model merge, we further overcame bottlenecks and ultimately elevated the program optimization ratio (51.76\\% $\\rightarrow$ 76.65\\%) and speedup ($2.65\\times\\rightarrow5.09\\times$) to new levels",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JYjhTl4LSK": {
    "title": "Rethinking Jailbreaking through the Lens of Representation Engineering",
    "volume": "review",
    "abstract": "The recent surge in jailbreaking methods has revealed the vulnerability of Large Language Models (LLMs) to malicious inputs. While earlier research has primarily concentrated on increasing the success rates of jailbreaking attacks, the underlying mechanism for safeguarding LLMs remains underexplored. This study investigates the vulnerability of safety-aligned LLMs by uncovering specific activity patterns within the representation space generated by LLMs. We propose a novel approach to identify such \"safety patterns'\" using only a few pairs of contrastive queries. Surprisingly, these safety patterns function as \"keys'' (used as a metaphor for security defense capability) that can be used to open or lock Pandora's Box of LLMs. Extensive experiments demonstrate that the robustness of LLMs against jailbreaking can be lessened or augmented by attenuating or strengthening the identified safety patterns. These findings deepen our understanding of jailbreaking phenomena and call for the LLM community to address the potential misuse of open-source LLMs",
    "checked": true,
    "id": "90538881baa3ff6461ab6edc756832337219f9b4",
    "semantic_title": "rethinking jailbreaking through the lens of representation engineering",
    "citation_count": 14,
    "authors": []
  },
  "https://openreview.net/forum?id=iIWujvj8Kg": {
    "title": "Is long context helpful for dialog response generation?",
    "volume": "review",
    "abstract": "Personalization has been a key challenge in building engaging conversational agents, necessitating models to effectively utilize long-range context to maintain coherence and consistency over extended interactions. In this work, we investigate the potential of large language models (LLMs) to generate coherent and personalized responses in long-term human-human conversations. We experiment with $\\textit{fixed context}$ and $\\textit{retrieval-based}$ approaches to use the dialogue history between two speakers. We evaluate our methods and perform analysis on four long-term conversational datasets. Our results indicate that including only a few preceding utterances is generally sufficient for response generation. Retrieval or more extended contexts from past dialogues provide minimal benefits for personalizing model responses. Further analysis of instances that benefited most from retrieval reveals that these cases typically involve either explicit references to previously shared information or scenarios requiring stylistic consistency, such as farewell messages",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CrF1t2Qqyi": {
    "title": "Mitigating Hallucination in Fictional Character Role-Play",
    "volume": "review",
    "abstract": "Role-playing has wide-ranging applications in customer support, embodied agents, computational social science, etc. The influence of parametric world knowledge of large language models (LLMs) often causes role-playing characters to act out of character and hallucinate about things outside the scope of their knowledge. In this work, we focus on the evaluation and mitigation of hallucination in fictional character role-play. We introduce a dataset with more than 2,000 characters and 72,000 interviews, including 18,000 adversarial questions. We propose RoleFact, a role-playing method that mitigates hallucination by modulating the influence of parametric knowledge using a pre-calibrated confidence threshold. Experiments show that the proposed method improves the factual precision of generated responses by 18% for adversarial questions with a 44% reduction in temporal hallucination for time-sensitive interviews. We will make the dataset and code publicly available for the research community upon acceptance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=z9Ux2V9lWR": {
    "title": "Skip-Layer Attention: Bridging Abstract and Detailed Dependencies in Transformers",
    "volume": "review",
    "abstract": "The Transformer architecture has significantly advanced deep learning, particularly in natural language processing, by effectively managing long-range dependencies. However, as the demand for understanding complex relationships grows, refining the Transformer's architecture becomes critical. This paper introduces Skip-Layer Attention (SLA) to enhance Transformer models by enabling direct attention between non-adjacent layers. This method improves the model's ability to capture dependencies between high-level abstract features and low-level details. By facilitating direct attention between these diverse feature levels, our approach overcomes the limitations of current Transformers, which often rely on suboptimal intra-layer attention. Our implementation extends the Transformer's functionality by enabling queries in a given layer to interact with keys and values from both the current layer and one preceding layer, thus enhancing the diversity of multi-head attention without additional computational burden. Extensive experiments demonstrate that our enhanced Transformer model achieves superior performance in language modeling tasks, highlighting the effectiveness of our skip-layer attention mechanism",
    "checked": true,
    "id": "937a377d5ac0f6a835b843615c5e94e71a34176e",
    "semantic_title": "skip-layer attention: bridging abstract and detailed dependencies in transformers",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Wg0PkjMWkx": {
    "title": "InstructMol: Multi-Modal Integration for Building a Versatile and Reliable Molecular Assistant in Drug Discovery",
    "volume": "review",
    "abstract": "The rapid evolution of artificial intelligence in drug discovery encounters challenges with generalization and extensive training, yet Large Language Models (LLMs) offer promise in reshaping interactions with complex molecular data. Our novel contribution, InstructMol, a multi-modal LLM, effectively aligns molecular structures with natural language via an instruction-tuning approach, utilizing a two-stage training strategy that adeptly combines limited domain-specific data with molecular and textual information. InstructMol showcases substantial performance improvements in drug discovery-related molecular tasks, surpassing leading LLMs and significantly reducing the gap with specialists, thereby establishing a robust foundation for a versatile and dependable drug discovery assistant",
    "checked": true,
    "id": "2b3554a8fea6f123fc04bd3e120f2293f227e1b2",
    "semantic_title": "instructmol: multi-modal integration for building a versatile and reliable molecular assistant in drug discovery",
    "citation_count": 29,
    "authors": []
  },
  "https://openreview.net/forum?id=eqdRlangte": {
    "title": "Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning",
    "volume": "review",
    "abstract": "Natural language is a powerful complementary modality of communication for data visualizations, such as bar and line charts. To facilitate chart-based reasoning using natural language, various downstream tasks have been introduced recently such as chart question answering, chart summarization, and fact-checking with charts. These tasks pose a unique challenge, demanding both vision-language reasoning and a nuanced understanding of chart data tables, visual encodings, and natural language instructions. Despite the recent success of Large Language Models (LLMs) across diverse NLP tasks, their abilities and limitations in the realm of data visualization remain under-explored, possibly due to their lack of multi-modal capabilities. To bridge the gap, this paper presents one of the first comprehensive evaluations of the recently developed large vision language models (LVLMs) for chart understanding and reasoning tasks. Our evaluation includes a comprehensive assessment of both closed and open-sourced LVLMs across five major chart reasoning tasks. Furthermore, we perform a qualitative evaluation of LVLMs' performance on a diverse range of charts, aiming to provide a thorough analysis. Our findings reveal that while LVLMs demonstrate impressive abilities in generating fluent texts covering high-level data insights, they also encounter common problems like hallucinations, factual errors, and data bias. We highlight the key strengths and limitations of LVLMs in chart comprehension tasks, offering insights for future research\\footnote{We will make all our prompts as well as LVLMs' responses open source for future research",
    "checked": false,
    "id": "97ec0d508265f43d3d011a09ffbf599df9ea2b0d",
    "semantic_title": "are large vision language models up to the challenge of chart comprehension and reasoning? an extensive investigation into the capabilities and limitations of lvlms",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=WTCDeps5ym": {
    "title": "Automatic Detection of Parental Interference Behaviors during Bilingual Child Language Assessment",
    "volume": "review",
    "abstract": "Recent clinical research has developed novel protocols that enable children to participate in bilingual language assessment remotely with parents to assist in this process. However, since parents are not trained clinicians, they often perform interference behaviors---actions that could compromise the validity of the assessment (e.g., providing hints). In this paper, we study whether language models can help automate the detection and categorization of parental interference behaviors during bilingual English-Mandarin child language assessment. Such a system would reduce the burden on clinicians, who must otherwise rely on transcribing video recordings and checking them manually for signs of interference. We release a new, expert-annotated dataset for this task, and evaluate multiple state-of-the-art large language models. While these models achieve non-trivial accuracy, they currently lag far behind human annotators. We find that understanding Mandarin and code-mixed text are key challenges these models need to overcome. We hope that our new dataset inspires modeling advances that could improve the practice of bilingual child language assessment",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X6kcA8rIKX": {
    "title": "I Never Said That\": A dataset, taxonomy and baselines on response clarity classification",
    "volume": "review",
    "abstract": "Equivocation and ambiguity in public speech are well-studied discourse phenomena, especially in political science and analysis of political interviews. Inspired by the well-grounded theory on equivocation, we aim to resolve the closely related problem of response clarity in questions extracted from political interviews, leveraging the capabilities of Large Language Models (LLMs) and human expertise. To this end, we introduce a novel taxonomy that frames the task of detecting and classifying response clarity and a corresponding clarity classification dataset which consists of question-answer (QA) pairs drawn from political interviews and annotated accordingly. Our proposed two-level taxonomy addresses the clarity of a response in terms of the information provided for a given question (high-level) and also provides a fine-grained taxonomy of evasion techniques that relate to unclear, ambiguous responses (lower-level). We combine ChatGPT and human annotators to collect, validate and annotate discrete QA pairs from political interviews, to be used for our newly introduced response clarity task. We provide a detailed analysis and conduct several experiments with different model architectures, sizes and adaptation methods to gain insights and establish new baselines over the proposed dataset and task",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HgJy3CLtRe": {
    "title": "Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment",
    "volume": "review",
    "abstract": "As the capabilities of large language models (LLMs) have expanded dramatically, aligning these models with human values presents a significant challenge. Traditional alignment strategies rely heavily on human intervention, such as Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF), or on the self-alignment capacities of LLMs, which usually require a strong LLM's emergent ability to improve its original bad answer. To address these challenges, we propose a novel self-alignment method that utilizes a Chain of Thought (CoT) approach, termed AlignCoT. This method encompasses stages of Question Analysis, Answer Guidance, and Safe Answer production. It is designed to enable LLMs to generate high-quality, safe responses throughout various stages of their development. Furthermore, we introduce the Mixture of insighTful Experts (MoTE) architecture, which applies mixture of experts to enhance each component of the AlignCoT process, markedly increasing alignment efficiency. The MoTE approach not only outperforms existing methods in aligning LLMs with human values but also highlights the benefits of using self-generated data, revealing the dual benefits of improved alignment and training efficiency",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OVGk9vvWf1": {
    "title": "MatchTime: Towards Automatic Soccer Game Commentary Generation",
    "volume": "review",
    "abstract": "Soccer is a globally popular sport with a vast audience, in this paper, we consider to construct an automatic soccer game commentary model to improve the audiences' viewing experience. In general, we make the following contributions: *First*, observing the prevalent video-text misalignment in existing datasets, we manually annotate timestamps for 49 matches, establishing a more robust benchmark for soccer game commentary generation, termed as ***SN-Caption-test-align***; *Second*, we propose a multimodal temporal alignment pipeline to automatically correct and filter the existing dataset at scale, creating a higher-quality soccer game commentary dataset for training, denoted as ***MatchTime***; *Third*, based on our curated dataset, we train an automatic commentary generation model, named ***MatchVoice***. Extensive experiments and ablation studies have demonstrated the effectiveness of our alignment pipeline, and training model on the curated datasets achieves state-of-the-art performance for commentary generation, showcasing that better alignment can lead to significant performance improvements in downstream tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aFhDuLzqc9": {
    "title": "XLLaMA2: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages",
    "volume": "review",
    "abstract": "Large Language Models (LLMs) demonstrate remarkable translation capabilities in high-resource language tasks, yet their performance in low-resource languages is hindered by insufficient multilingual data during pre-training. To mitigate this, we continued pre-train LLaMA2-7B to support translation across more than 100 languages. Following a thorough analysis of training strategies, including vocabulary expansion and data augmentation, we apply extensive multilingual continued pre-training to the LLaMA series model, resulting in XLLaMA2. Without loss of the generality ability, the translation performance of XLLaMA2 significantly surpassed existing LLMs and is on par with that of a specialized translation model (M2M-100-12B) on the Flores-101 benchmark. Specifically, XLLaMA2 achieves an average spBLEU score improvement of over 10 points compared to the original LLaMA2 model. Further testing XLLaMA2 on Flores-200, XLLaMA2 exhibited notable performance gains even for languages not included in the training set. We will make the code and model publicly available",
    "checked": false,
    "id": "d3ad0931e5c6e0e7152485eb103a7301836b57cf",
    "semantic_title": "llamax: scaling linguistic horizons of llm by enhancing translation capabilities beyond 100 languages",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=aYcIUbchin": {
    "title": "Language Models in Dialogue: Conversational Maxims for Human-AI Interactions",
    "volume": "review",
    "abstract": "Modern language models, while sophisticated, exhibit some inherent shortcomings, particularly in conversational settings. We claim that many of the observed shortcomings can be attributed to violation of one or more conversational principles. By drawing upon extensive research from both the social science and AI communities, we propose a set of maxims -- quantity, quality, relevance, manner, benevolence, and transparency -- for describing effective human-AI conversation. We first justify the applicability of the first four maxims (from Grice) in the context of human-AI interactions. We then argue that two new maxims, benevolence (concerning the generation of, and engagement with, harmful content) and transparency (concerning recognition of one's knowledge boundaries, operational constraints, and intents), are necessary for addressing behavior unique to modern human-AI interactions. We evaluate the degree to which various language models are able to understand these maxims and find that models possess an internal prioritization of principles that can significantly impact accurate interpretability of the maxims",
    "checked": true,
    "id": "5dcc26649414295ec3d1d9a274d41b2759e53f8e",
    "semantic_title": "language models in dialogue: conversational maxims for human-ai interactions",
    "citation_count": 3,
    "authors": []
  },
  "https://openreview.net/forum?id=JGtxrFQ2pg": {
    "title": "Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication",
    "volume": "review",
    "abstract": "In this paper, we study how culture leads to differences in common ground and how this influences communication. During communication, cultural differences in common ground during communication may result in pragmatic failure and misunderstandings. We develop our method Rational Speech Acts for Cross-Cultural Communication (RSA+C3) to resolve cross-cultural differences in common ground. To measure the success of our method, we study RSA+C3 in the collaborative referential game of Codenames Duet and show that our method successfully improves collaboration between simulated players of different cultures. Our contributions are threefold: (1) creating Codenames players using contrastive learning of an embedding space and LLM prompting that are aligned with human patterns of play, (2) studying culturally induced differences in common ground reflected in our trained models, and (3) demonstrating that our method RSA+C3 can ease cross-cultural communication in gameplay by inferring sociocultural context from interaction",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yaNXERza7h": {
    "title": "A Survey on Natural Language Counterfactual Generation",
    "volume": "review",
    "abstract": "Natural Language Counterfactual generation aims to minimally modify a given text such that the modified text belongs to a different class. The generated counterfactuals provide insights into the reasoning behind a model's predictions by highlighting which words significantly influence the outcomes. Additionally, they can be used to detect model fairness issues or augment the training data to enhance the model's robustness. A substantial amount of research has been conducted to generate counterfactuals for various NLP tasks, employing different models and methodologies. With the rapid growth of studies in this field, a systematic review is crucial to guide future researchers and developers. To bridge this gap, this survey comprehensively overview textual counterfactual generation methods, particularly including those based on Large Language Models. We propose a new taxonomy that categorizes the generation methods into four groups and systematically summarize the metrics for evaluating the generation quality. Finally, we discuss ongoing research challenges and outline promising directions for future work",
    "checked": true,
    "id": "8d0bcbbc3c3505e7e7d9399fac404c14b6a17cb1",
    "semantic_title": "a survey on natural language counterfactual generation",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sTxK9Ne4uY": {
    "title": "Amuro and Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models",
    "volume": "review",
    "abstract": "The development of large language models leads to the formation of a pre-train-then-align paradigm, in which the model is typically pre-trained on a large text corpus and undergoes a tuning stage to align the model with human preference or downstream tasks. In this work, we investigate the relationship between pre-training and fine-tuning by fine-tuning multiple intermediate pre-trained model checkpoints, we find that i) continual pre-training improves the model in a latent way that unveils after fine-tuning; ii) with extra fine-tuning, the datasets that the model does not demonstrate capability gain much more than those that the model performs well during the pre-training stage; iii) although model benefits significantly through supervised fine-tuning, it may forget previously known domain knowledge and the tasks that are not seen during fine-tuning; iv) the supervised fine-tuned model resembles high sensitivity to few-shot evaluation prompts, but this sensitivity can be alleviated by more pre-training",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NnCI2HLTAz": {
    "title": "Securing Multi-turn Conversational Language Models Against Distributed Backdoor Triggers",
    "volume": "review",
    "abstract": "The security of multi-turn conversational large language models (LLMs) is understudied despite it being one of the most popular LLM utilization. Specifically, LLMs are vulnerable to data poisoning backdoor attacks, where an adversary manipulates the training data to cause the model to output malicious responses to predefined triggers. Specific to the multi-turn dialogue setting, LLMs are at the risk of even more harmful and stealthy backdoor attacks where the backdoor triggers may span across multiple utterances, giving lee-way to context-driven attacks. In this paper, we explore a novel distributed backdoor trigger attack that serves to be an extra tool in an adversary's toolbox that can interface with other single-turn attack strategies in a plug and play manner. Results on two representative defense mechanisms indicate that distributed backdoor triggers are robust against existing defense strategies which are designed for single-turn user-model interactions, motivating us to propose a new defense strategy for the multi-turn dialogue setting that is more challenging. To this end, we also explore a novel contrastive decoding based defense that is able to mitigate the backdoor with a low computational tradeoff",
    "checked": true,
    "id": "a9e3d4d0ce275564387a5a0265dcc1f1d75ca341",
    "semantic_title": "securing multi-turn conversational language models against distributed backdoor triggers",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=GCkhHWFdDW": {
    "title": "EPT: Explosive Prompt Tuning For Parameter-Efficient with Large Norm Prompt",
    "volume": "review",
    "abstract": "Prompt tuning introduces additional learnable tokens, known as $\\textit{soft prompts}$, to frozen pre-trained language models for parameter-efficient tuning. Unlike fine-tuning, only these soft prompts are trained on downstream tasks rather than all model parameters. While recent prompt tuning approaches that introduce a reparameterization network have shown comparable performance to fine-tuning, they still require a large number of parameters for the soft prompts. In this paper, we empirically show the characteristics of the recent prompt tuning methods, such as the large norm of trained soft prompts and their significant similarity to each other. Inspired by these observations, we propose simple yet effective modifications to the reparameterization network for efficient prompt tuning, which involves inducing large norm, replacing overparameterization with under-parameterization, and focusing on a single prompt. This approach preserves the advantageous characteristics of the soft prompts while significantly reducing the number of parameters. Our comprehensive experiments across 21 diverse NLP datasets show that our method called EPT: Explosive Prompt Tuning, significantly outperforms prompt Tuning and achieves comparable performance full fine-tuning or other parameter-efficient tuning, with only 2.3K parameters during training on T5-base",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1lMN0xV5tg": {
    "title": "InternalInspector $I^2$: Robust Confidence Estimation in LLMs through Internal States",
    "volume": "review",
    "abstract": "Despite their vast capabilities, Large Language Models (LLMs) often struggle with generating reliable outputs, frequently producing high-confidence inaccuracies known as hallucinations. Addressing this challenge, our research introduces InternalInspector, a novel framework designed to enhance confidence estimation in LLMs by leveraging contrastive learning on internal states including attention states, feed-forward states, and activation states of all layers. Unlike existing methods that primarily focus on the final activation state, InternalInspector conducts a comprehensive analysis across all internal states of every layer to accurately identify both correct and incorrect prediction processes. By benchmarking InternalInspector against existing confidence estimation methods across various natural language understanding and generation tasks, including factual question answering, commonsense reasoning, and reading comprehension, InternalInspector achieves significantly higher accuracy in aligning the estimated confidence scores with the correctness of the LLM's predictions and lower calibration error. Furthermore, InternalInspector excels at HaluEval, a hallucination detection benchmark, outperforming other internal-based confidence estimation methods in this task",
    "checked": false,
    "id": "2d5b8eed2fdf9f7ba237f986946c573d2b6aa258",
    "semantic_title": "internalinspector i2: robust confidence estimation in llms through internal states",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6gcX05a9aW": {
    "title": "ESC-Eval: Evaluating Emotion Support Conversations in Large Language Models",
    "volume": "review",
    "abstract": "Emotion Support Conversation (ESC) is a crucial application, which aims to reduce human stress, offer emotional guidance, and ultimately enhance human mental and physical well-being. With the advancement of Large Language Models (LLMs), many researchers have employed LLMs as the ESC models. However, the evaluation of these LLM-based ESCs remains uncertain. In detail, we first re-organize 2,801 role-playing cards from seven existing datasets to define the roles of the role-playing agent. Second, we train a specific role-playing model called ESC-Role which behaves more like a confused person than GPT-4. Third, through ESC-Role and organized role cards, we systematically conduct experiments using 14 LLMs as the ESC models, including general AI-assistant LLMs (e.g., ChatGPT) and ESC-oriented LLMs (e.g., ExTES-Llama). We conduct comprehensive human annotations on interactive multi-turn dialogues of different ESC models. The results show that ESC-oriented LLMs exhibit superior ESC abilities compared to general AI-assistant LLMs, but there is still a gap behind human performance. Moreover, to automate the scoring process for future ESC models, we developed ESC-RANK, which trained on the annotated data, achieving a scoring performance surpassing 35 points of GPT-4",
    "checked": true,
    "id": "202f3a1341a9e614c2611de4809dd12fe7850f36",
    "semantic_title": "esc-eval: evaluating emotion support conversations in large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AwD1id99dz": {
    "title": "Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM",
    "volume": "review",
    "abstract": "Large language models (LLMs) have achieved remarkable performance in various natural language processing tasks, especially in dialogue systems. However, LLM may also pose security and moral threats, especially in multi round conversations where large models are more easily guided by contextual content, resulting in harmful or biased responses.In this paper, we present a novel method to attack LLMs in multi-turn dialogues, called CoA (Chain of Attack). CoA is a semantic-driven contextual multi-turn attack method that adaptively adjusts the attack policy through contextual feedback and semantic relevance during multi-turn of dialogue with a large model, resulting in the model producing unreasonable or harmful content.We evaluate CoA on different LLMs and datasets, and show that it can effectively expose the vulnerabilities of LLMs, and outperform existing attack methods. Our work provides a new perspective and tool for attacking and defending LLMs, and contributes to the security and ethical assessment of dialogue systems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2skGwpaB4x": {
    "title": "Self–Boost: Boosting LLMs with Iterative Self-Generated Data",
    "volume": "review",
    "abstract": "Instruction finetuned large language models (LLMs) have shown impressive performance solving a diverse range of natural language processing (NLP) tasks involving classification and reasoning. However, this can be particularly challenging in low-data regimes. Recent methods have shown boosting via iterative full finetuning to be an effective method to augment the training data by using the incorrect examples to generate synthetic data using a teacher LLM. However, data generation at scale using a teacher LLM can be costly, and full finetuning can be computationally expensive. To address this, we introduce Self–Boost, an iterative data augmentation and instruction finetuning strategy that has no external dependence on any teacher models. Self–Boost uses parameter efficient finetuning (PEFT) with Llama 3 8B to instruction finetune a model using the seed data, uses the same model to generate examples similar to the misclassifications, and also the same model to verify and filter the generated examples. Our experiments show that performance on TREC, GSM8K, and CaseHOLD improves by 21.6\\%, 5.6\\% and 1.3\\% respectively, when compared to our baseline",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e7KRWhZJo7": {
    "title": "Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors",
    "volume": "review",
    "abstract": "Large language models have become increasingly prominent, also signaling a shift towards multimodality as the next frontier in artificial intelligence, where their embeddings are harnessed as prompts to generate textual content. Vision-language models (VLMs) stand at the forefront of this advancement, offering innovative ways to combine visual and textual data for enhanced understanding and interaction. However, this integration also enlarges the attack surface. Patch-based adversarial attack is considered the most realistic threat model in physical vision applications, as demonstrated in many existing literature. In this paper, we propose to address patched visual prompt injection, where adversaries exploit adversarial patches to generate target content in VLMs. Our investigation reveals that patched adversarial prompts exhibit sensitivity to pixel-wise randomization, a trait that remains robust even against adaptive attacks designed to counteract such defenses. Leveraging this insight, we introduce SmoothVLM, a defense mechanism rooted in smoothing techniques, specifically tailored to protect VLMs from the threat of patched visual prompt injectors. Our framework significantly lowers the attack success rate to a range between 0% and 5.0% on two leading VLMs, while achieving around 67.3% to 95.0% context recovery of the benign images, demonstrating a balance between security and usability",
    "checked": true,
    "id": "f41109b24c24ecccf26cda9ceacad9167d197028",
    "semantic_title": "safeguarding vision-language models against patched visual prompt injectors",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p7AOfQVfec": {
    "title": "Enhancing Legal Case Retrieval via Scaling High-quality Synthetic Query-Candidate Pairs",
    "volume": "review",
    "abstract": "Legal case retrieval (LCR) aims to provide similar cases as references for a given fact description. This task is crucial for promoting consistent judgments in similar cases, effectively enhancing judicial fairness and improving work efficiency for judges. However, existing works face two main challenges for real-world applications: existing works mainly focus on case-to-case retrieval using lengthy queries, which does not match real-world scenarios; and the limited data scale, with current datasets containing only hundreds of queries, is insufficient to satisfy the training requirements of existing data-hungry neural models. To address these issues, we introduce an automated method to construct synthetic query-candidate pairs and build the largest LCR dataset to date, LEAD, which is hundreds of times larger than existing datasets. This data construction method can provide ample training signals for LCR models. Experimental results demonstrate that model training with our constructed data can achieve state-of-the-art results on two widely-used LCR benchmarks. Besides, the construction method can also be applied to civil cases and achieve promising results. The code and dataset used in this paper will be released to promote the development of LCR",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KGcCDvchuY": {
    "title": "Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering",
    "volume": "review",
    "abstract": "To address the issues of insufficient knowledge and hallucination in Large Language Models (LLMs), numerous studies have explored integrating LLMs with Knowledge Graphs (KGs). However, these methods are typically evaluated on conventional Knowledge Graph Question Answering (KGQA) with complete KGs, where all factual triples required for each question are entirely covered by the given KG. In such cases, LLMs primarily act as an agent to find answer entities within the KG, rather than effectively integrating the internal knowledge of LLMs and external knowledge sources such as KGs. In fact, KGs are often incomplete to cover all the knowledge required to answer questions. To simulate these real-world scenarios and evaluate the ability of LLMs to integrate internal and external knowledge, we propose leveraging LLMs for QA under Incomplete Knowledge Graph (IKGQA), where the provided KG lacks some of the factual triples for each question, and construct corresponding datasets. To handle IKGQA, we propose a training-free method called Generate-on-Graph (GoG), which can generate new factual triples while exploring KGs. Specifically, GoG performs reasoning through a Thinking-Searching-Generating framework, which treats LLM as both Agent and KG in IKGQA. Experimental results on two datasets demonstrate that our GoG outperforms all previous methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YRjqvFpEwx": {
    "title": "Bayesian Example Selection Improves In-Context Learning for Speech, Text, and Visual Modalities",
    "volume": "review",
    "abstract": "Large language models (LLMs) can adapt to new tasks through in-context learning (ICL) based on a few examples presented in dialogue history without any model parameter update. Despite such convenience, the performance of ICL heavily depends on the quality of the in-context examples presented, which makes the in-context example selection approach a critical choice. This paper proposes a novel Bayesian in-Context example Selection method (ByCS) for ICL. Extending the inference probability conditioned on in-context examples based on Bayes' theorem, ByCS focuses on the inverse inference conditioned on test input. Following the assumption that accurate inverse inference probability (likelihood) will result in accurate inference probability (posterior), in-context examples are selected based on their inverse inference results. Diverse and extensive cross-tasking and cross-modality experiments are performed with speech, text, and image examples. Experimental results show the efficacy and robustness of our ByCS method on various models, tasks and modalities",
    "checked": true,
    "id": "729c6421c049d47350e04e32256a14d6fb74f9f1",
    "semantic_title": "bayesian example selection improves in-context learning for speech, text, and visual modalities",
    "citation_count": 1,
    "authors": []
  },
  "https://openreview.net/forum?id=6TMh1qcTAN": {
    "title": "On the Empirical Complexity of Reasoning and Planning in LLMs",
    "volume": "review",
    "abstract": "Chain-of-thought (CoT), tree-of-thought (ToT), and related techniques work surprisingly well in practice for some complex reasoning tasks with Large Language Models (LLMs), but why? This work seeks the underlying reasons by conducting experimental case studies and linking the performance benefits to well-established sample and computational complexity principles in machine learning. We experimented with 6 reasoning tasks, ranging from grade school math, air travel planning, $\\ldots$, to Blocksworld. The results suggest that (i) both CoT and ToT benefit significantly from task decomposition, which breaks a complex reasoning task into a sequence of steps with low sample and computational complexity and explicitly outlines the reasoning structure, and (ii) for computationally hard reasoning tasks, the more sophisticated tree structure of ToT outperforms the linear structure of CoT. These findings provide useful guidelines for the use of LLM in solving reasoning tasks in practice",
    "checked": true,
    "id": "cb4ce9d960c0c91aa72b23fdf4b4de27dc0bd1db",
    "semantic_title": "on the empirical complexity of reasoning and planning in llms",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cojHhAjzVy": {
    "title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning",
    "volume": "review",
    "abstract": "Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, use tools for scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs' abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Llama3-8B surpasses other LLMs with the comparable size by more than 8.0\\% in absolute accuracy. Furthermore, SciAgent-DeepMath-7B shows much superior performance than ChatGPT",
    "checked": true,
    "id": "60126292c0b31dfc8628d99001e057b9f8355000",
    "semantic_title": "sciagent: tool-augmented language models for scientific reasoning",
    "citation_count": 6,
    "authors": []
  },
  "https://openreview.net/forum?id=SqDrBaZVqn": {
    "title": "LONGAGENT: Achieving Question Answering for 128k-Token-Long Documents through Multi-Agent Collaboration",
    "volume": "review",
    "abstract": "Large language models (LLMs) have achieved tremendous success in understanding language and processing text. However, question-answering (QA) on lengthy documents faces challenges of resource constraints and a high propensity for errors, even for the most advanced models such as GPT-4 and Claude2. In this paper, we introduce \\textsc{LongAgent}, a multi-agent collaboration method that enables efficient and effective QA over $128k$-token-long documents. \\textsc{LongAgent} adopts a \\textit{divide-and-conquer} strategy, breaking down lengthy documents into shorter, more manageable text chunks. A leader agent comprehends the user's query and organizes the member agents to read their assigned chunks, reasoning a final answer through multiple rounds of discussion. Due to members' hallucinations, it's difficult to guarantee that every response provided by each member is accurate. To address this, we develop an \\textit{inter-member communication} mechanism that facilitates information sharing, allowing for the detection and mitigation of hallucinatory responses. Experimental results show that a LLaMA-2 7B driven by \\textsc{LongAgent} can effectively support QA over $128k$-token documents, achieving $16.42\\%$ and $1.63\\%$ accuracy gains over GPT-4 on single-hop and multi-hop QA settings, respectively",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ioC3T9FYAW": {
    "title": "Exploring Unified Training Framework for Multimodal User Profiling",
    "volume": "review",
    "abstract": "With the emergence of social media and e-commerce platforms, accurate \\emph{user profiling} has become increasingly vital for recommendation systems and personalized services. Recent studies have focused on generating detailed user profiles by extracting various aspects of user attributes from textual reviews. Nevertheless, these investigations have not fully exploited the potential of the abundant multimodal data at hand. In this study, we propose a novel task called \\emph{multimodal user profiling}. This task emphasizes the utilization of both review texts and their accompanying images to create comprehensive user profiles. By integrating textual and visual data, we leverage their complementary strengths, enabling the generation of more holistic user representations. Additionally, we explore a unified joint training framework with various multimodal training strategies that incorporate users' historical review texts and images for user profile generation. Our experimental results underscore the significance of multimodal data in enhancing user profile generation and demonstrate the effectiveness of the proposed unified joint training approach",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pwXH7ldmt3": {
    "title": "DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts",
    "volume": "review",
    "abstract": "Data-driven storytelling is a powerful method for conveying insights by combining narrative techniques with visualizations and text. These stories integrate visual aids, such as highlighted bars and lines in charts, along with textual annotations explaining insights. However, creating such stories requires a deep understanding of the data and meticulous narrative planning, often necessitating human intervention, which can be time-consuming and mentally taxing. While Large Language Models (LLMs) excel in various NLP tasks, their ability to generate coherent and comprehensive data stories remains underexplored. In this work, we introduce a novel task for data story generation and a benchmark containing 1,449 stories from diverse sources. To address the challenges of crafting coherent data stories, we propose a multi-agent framework employing two LLM agents designed to replicate the human storytelling process: one for understanding and describing the data (Reflection), generating the outline, and narration, and another for verification at each intermediary step. While our agentic framework generally outperforms non-agentic counterparts in both model-based and human evaluations, the results also reveal unique challenges in data story generation",
    "checked": true,
    "id": "bf746159ec6008fa8e4d4134c848f8611066d62d",
    "semantic_title": "datanarrative: automated data-driven storytelling with visualizations and texts",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kYT8fIcRtW": {
    "title": "CELM: A Dataset for Chinese Ethico-Legal Alignment in Large Language Models",
    "volume": "review",
    "abstract": "Existing Chinese datasets for aligning large language models (LLMs) with human preferences often reflect U.S.-centric values due to their annotation process, reducing their effectiveness for developing safe and culturally appropriate LLMs for China, one of the largest LLM markets in the world. In this work, we introduce ``CELM'', a comprehensive Chinese-centric dataset, for i) training LLMs with the Chinese module aligning with corresponding societal values and ii) assessing their safety in the Chinese context. This dataset includes 17 important scenarios, three of which are unique to China. It includes 1,337 instances innovatively annotated with Chinese legal and ethical norms for fine-tuning, and 46,633 instances judged according to the safety preference of native Chinese crowdworkers for reinforcement learning. It includes 2,111 evaluation examples produced using human-in-the-loop red teaming to rigorously examine the safety levels of LLMs in the Chinese cultural context. Our studies show that models trained on CELM produce safer and more culturally relevant responses for China than those trained on datasets biased towards U.S. norms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HBwy94oRhi": {
    "title": "Investigating Multilingual Instruction-Tuning: Do Polyglot Models Demand for Multilingual Instructions?",
    "volume": "review",
    "abstract": "The adaption of multilingual pre-trained LLMs into eloquent and helpful assistants is essential to facilitate their use across different language regions. In that spirit, we are the first to conduct an extensive study of the performance of multilingual models instruction-tuned on different language compositions on parallel instruction-tuning benchmarks across a selection of the most spoken Indo-European languages. We systematically examine the effects of language and instruction dataset size on a mid-sized and a large, multilingual LLMs by instruction-tuning them on parallel instruction-tuning datasets. Our results demonstrate that instruction-tuning on parallel instead of monolingual corpora benefits cross-lingual instruction following capabilities by up to 9.9%. Furthermore, we show that the Superficial Alignment Hypothesis does not hold in general, as the investigated multilingual 7B parameter model presents a counter-example requiring large-scale instruction-tuning datasets. Finally, we conduct a human annotation study to understand the alignment between human-based and GPT-4-based evaluation within multilingual chat scenarios",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=z4zVpx8OLs": {
    "title": "SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding",
    "volume": "review",
    "abstract": "As large language models (LLMs) become integral to advancing NLP tasks, their sequential decoding becomes a bottleneck to achieving more efficient inference. Multi-Draft Speculative Decoding (MDSD) emerges as a promising solution, where a small draft model produces a tree of tokens with each path as a draft predicting the target LLM's outputs, which is then verified by the target LLM in parallel. However, current methods rely on Recursive Rejection Sampling (RRS) and its variants, which suffer from low acceptance rates in proceeding drafts, diminishing the merits of multiple drafts. In this work, we investigate this critical inefficiency and sub-optimality through an optimal transport (OT) formulation that aims to maximize the acceptance rate by optimizing the joint distribution $\\pi(x_{1:k},y)$ of $k$-draft tokens $x_{1:k}$ and an accepted token $y$. We show that the OT can be greatly simplified to a much smaller Linear Programming (LP) focusing on a few probabilities in $\\pi(x_{1:k},y)$. Moreover, our analysis of different choices for the marginal distribution $Q(x_{1:k})$ reveals its importance to the sampling effectiveness and efficiency. Motivated by the new insight, we introduce SpecHub, which adopts a special design of $Q(x_{1:k})$ that significantly accelerates the LP and provably achieves a higher acceptance rate than existing strategies. SpecHub can be seamlessly integrated into existing MDSD frameworks, improving their acceptance rate while only incurring linear computational overhead. In extensive experiments, Spechub consistently generates 0.05-0.27 and 0.02-0.16 more tokens per step than RRS with and without replacement and achieves equivalent batch efficiency with half as much concurrency. We attach our code at \\url{anonymous.4open.science/r/SpecHub}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vPsA7QJWln": {
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "volume": "review",
    "abstract": "With the emergence of large language models (LLMs) and their ability to perform a variety of tasks, their application in recommender systems (RecSys) has shown promise. However, we are facing significant challenges when deploying LLMs into RecSys, such as limited prompt length, unstructured item information, and un-constrained generation of recommendations, leading to sub-optimal performance. To address these issues, we propose a novel method using a taxonomy dictionary. This method provides a systematic framework for categorizing and organizing items, improving the clarity and structure of item information. By incorporating the taxonomy dictionary into LLM prompts, we achieve efficient token utilization and controlled feature generation, leading to more accurate and contextually relevant recommendations. Our Taxonomy-guided Recommendation (TaxRec) approach features a two-step process: one-time taxonomy categorization and LLM-based recommendation, enabling zero-shot recommendations without the need for domain-specific fine-tuning. Experimental results demonstrate TaxRec significantly enhances recommendation quality compared to traditional zero-shot approaches, showcasing its efficacy as personal recommender with LLMs. Code is available at https://anonymous.4open.science/r/TaxRec",
    "checked": true,
    "id": "7a7da5e38c5b917b99c794436c8da58f4474cefe",
    "semantic_title": "taxonomy-guided zero-shot recommendations with llms",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9JFlJG9yZZ": {
    "title": "Thought2Text: Text Generation from EEG Brain Activities through Large Language Models",
    "volume": "review",
    "abstract": "Decoding and expressing brain activities in a comprehensible form is a challenging frontier in AI. This paper presents Thought2Text, which uses instruction-tuned LLMs fine-tuned with EEG data to achieve this goal. The approach involves three stages: (1) training an EEG encoder for visual feature extraction, (2) fine-tuning LLMs on image and text data, enabling multimodal description generation, and (3) further fine-tuning on EEG embeddings to generate text directly from EEG during inference. Experiments on a public EEG dataset collected for six subjects with image stimuli demonstrate the efficacy of multimodal LLMs (LLaMa-v3, Mistral-v0.3, Phi-v3) validated using BLEU, METEOR, ROUGE, BertScore, and GPT-4 based evaluations. This approach marks a significant advancement towards portable, low-cost \"thoughts-to-text\" technology, applicable to neuroscience and NLP",
    "checked": false,
    "id": "f9e5844a6bcff29f0e54374c345818331dae4d36",
    "semantic_title": "mindsemantix: deciphering brain visual experiences with a brain-language model",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nAqcuIOXr8": {
    "title": "Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models",
    "volume": "review",
    "abstract": "Vision-language models (VLMs) like CLIP have demonstrated remarkable applicability across a variety of downstream tasks, including zero-shot image classification. Recently, the use of prompts or adapters for efficient transfer learning (ETL) has gained significant attention for effectively adapting to downstream tasks. However, previous studies have overlooked the challenge of varying transfer difficulty of downstream tasks. In this paper, we empirically analyze how each ETL method behaves with respect to transfer difficulty. Our observations indicate that utilizing vision prompts and text adapters is crucial for adaptability and generalizability in domains with high difficulty. Also, by applying an adaptive ensemble approach that integrates task-adapted VLMs with pre-trained VLMs and strategically leverages more general knowledge in low-difficulty and less in high-difficulty domains, we consistently enhance performance across both types of domains. Based on these observations, we propose an adaptive ensemble method that combines visual prompts and text adapters with pre-trained VLMs, tailored by transfer difficulty, to achieve optimal performance for any target domain. Upon experimenting with extensive benchmarks, our method consistently outperforms all baselines, particularly on unseen tasks, demonstrating its effectiveness",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o9GRwNogsB": {
    "title": "A Collaborative Reasoning Framework Powered by Reinforcement Learning and Large Language Models for Complex Questions Answering over Knowledge Graph",
    "volume": "review",
    "abstract": "Knowledge Graph Question Answering (KGQA) aims to automatically answer natural language questions by reasoning across multiple triples in knowledge graphs (KGs). Reinforcement learning (RL)-based methods are introduced to enhance model interpretability. Nevertheless, when addressing complex questions requiring long-term reasoning, the RL agent is usually misled by aimless exploration, as it lacks common learning practices with prior knowledge. Recently, large language models (LLMs) have been proven to encode vast amounts of knowledge about the world and possess remarkable reasoning capabilities. However, they often encounter challenges with hallucination issues, failing to address complex questions that demand deep and deliberate reasoning. In this paper, we propose a collaborative reasoning framework (CRF) powered by RL and LLMs to answer complex questions based on the knowledge graph. Our approach leverages the common sense priors contained in LLMs while utilizing RL to provide learning from the environment, resulting in a hierarchical agent that uses LLMs to solve the complex KGQA task. By combining LLMs and the RL policy, the high-level agent accurately identifies constraints encountered during reasoning, while the low-level agent conducts efficient path reasoning by selecting the most promising relations in KG. Extensive experiments conducted on four benchmark datasets clearly demonstrate the effectiveness of the proposed model, which surpasses state-of-the-art approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Yr8UoBpmwM": {
    "title": "Dual-Space Knowledge Distillation for Large Language Models",
    "volume": "review",
    "abstract": "Knowledge distillation (KD) is known as a promising solution to compress large language models (LLMs) via transferring their knowledge to smaller models. During this process, white-box KD methods usually minimize the distance between the output distributions of the two models so that more knowledge can be transferred. However, in the current white-box KD framework, the output distributions are from the respective output spaces of the two models, using their own prediction heads. We argue that the space discrepancy will lead to low similarity between the teacher model and the student model on both representation and distribution levels. Furthermore, this discrepancy also hinders the KD process between models with different vocabularies, which is common for current LLMs. To address these issues, we propose a dual-space knowledge distillation (DSKD) framework that unifies the output spaces of the two models for KD. On the basis of DSKD, we further develop a cross-model attention mechanism, which can automatically align the representations of the two models with different vocabularies. Thus, our framework is not only compatible with various distance functions for KD (e.g., KL divergence) like the current framework, but also supports KD between any two LLMs regardless of their vocabularies. Experiments on task-agnostic instruction-following benchmarks show that DSKD significantly outperforms the current white-box KD framework with various distance functions, and also surpasses existing KD methods for LLMs with different vocabularies",
    "checked": true,
    "id": "84c567316b2eb804fb673871ae89748c3990a558",
    "semantic_title": "dual-space knowledge distillation for large language models",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xX0uhgvexQ": {
    "title": "Make Some Noise: Unlocking Language Model Parallel Inference Capability through Noisy Training",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aJdfCtCOlq": {
    "title": "Is Nomenclature Beneficial to Language Models for Chemistry?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cfMRTgLYSf": {
    "title": "TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A6JKBhc8aT": {
    "title": "Exploring the Diversity of Opinions on Affirmative Action Through Extended Stance Detection Among Reddit Users",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AYzd2W2ZEG": {
    "title": "MTChat: A Multimodal Time-Aware Dataset and Framework for Conversation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3PABAHvV6H": {
    "title": "Revisiting Automated Evaluation for Long-form Table Question Answering in the Era of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RifFJNhGFS": {
    "title": "DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lr5kxVrfqc": {
    "title": "Collaborative Tasks with Heterogenous LLM Students",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LA49aG7kLd": {
    "title": "SEAL: Entangled White-box Watermarks on Low-Rank Adaptation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=brG8gXxSNI": {
    "title": "SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Vu4d5PWRxb": {
    "title": "Unveiling the Flaws: Exploring Imperfections in Synthetic Data and Mitigation Strategies for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aReecSfloe": {
    "title": "MultiLogicNMR(er): A Benchmark and Neural-Symbolic Framework for Non-monotonic Reasoning Tasks with Multiple Extensions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OMhPSDMWFX": {
    "title": "Augment before You Try: Knowledge-Enhanced Table Question Answering via Table Expansion",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yGuJKNOJ1u": {
    "title": "Advancing Test-Time Adaptation in Wild Acoustic Test Settings",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JqC3JoeL3l": {
    "title": "Multimodal Customized Review Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ui6mIdPCLy": {
    "title": "A Little Leak Will Sink a Great Ship: Survey of Transparency for Large Language Models from Start to Finish",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hHHkx08YVV": {
    "title": "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2UlLGNpvwP": {
    "title": "Defending Jailbreak Attack in VLMs via Cross-modality Information Detector",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VhwKsW47FA": {
    "title": "medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CtHsalE9mx": {
    "title": "When Evolution Strategy Meets Language Models Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ezwl7hBpf2": {
    "title": "The Eyes Don't Lie: Text Transcriptions Can Hide Dementia Presentation that Gaze Reveals",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vkLeYVwzlQ": {
    "title": "Surgical-LLaVA: Toward Surgical Scenario Understanding via Large Language and Vision Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pU4Bzqr9oh": {
    "title": "CVLUE: A New Benchmark Dataset for Chinese Vision-Language Understanding Evaluation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fE6InnWvQS": {
    "title": "SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=34tVBCpUQM": {
    "title": "Mitigating Training Imbalance in LLM Fine-Tuning via Selective Parameter Merging",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rN1cAMNWIj": {
    "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ksK00x9MW4": {
    "title": "Bit-level BPE: Below the byte boundary",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=O6mNdNKhGy": {
    "title": "Understanding Faithfulness and Reasoning of Large Language Models on Plain Biomedical Summaries",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qXDppd1Xy3": {
    "title": "Trainable Attention-based Conditional Dependency for Uncertainty Quantification of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6FXotcWvO2": {
    "title": "A Nested Watermark for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uHlOvD1sTt": {
    "title": "Dual Stream Alignment with Hierarchical Bottleneck Fusion For Multimodal Sentiment Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jshsqUvXXB": {
    "title": "BaFair: Backdoored Fairness Attacks with Group-conditioned Triggers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WzyoaiSfWc": {
    "title": "LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F9p3fT9Wix": {
    "title": "Character is Destiny: Can Role-Playing Language Agents Make Persona-Driven Decisions?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J3LfXaS9Fa": {
    "title": "Task Oriented In-Domain Data Augmentation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q3oNU7aafv": {
    "title": "Inter-Batch Cross-Attention: See More to Forget Less",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l3FbLMvW3P": {
    "title": "Long Context Alignment with Short Instructions and Synthesized Positions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OildGoeWDP": {
    "title": "Preference Tuning For Toxicity Mitigation Generalizes Across Languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=laBa2cmS1N": {
    "title": "The Impact of Auxiliary Patient Data on Automated Chest X-Ray Report Generation and How to Incorporate It",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1qzSGLm6wI": {
    "title": "Unified Approach for more Generalizable Medical Language Understanding through Instruction Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9yeUsKoDe0": {
    "title": "Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LJ2mqF2xUd": {
    "title": "You Gotta be a Doctor, Lin\": An Investigation of Name-Based Bias of Large Language Models in Employment Recommendations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Zm5Cn6Yfcm": {
    "title": "Consecutive Batch Model Editing with HooK Layers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JRxfpIpb2W": {
    "title": "Multilingual Knowledge Editing with Language-Agnostic Factual Neurons",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ktws1BPlKg": {
    "title": "MMOE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4bRTAKd1zz": {
    "title": "Mitigating Bias in LLMs via EquiSync: A Multi-Objective Optimization Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8OrxBZI2zO": {
    "title": "LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xFOowEWHUJ": {
    "title": "AlignedCoT: Prompting Large Language Models via Native-Speaking Demonstrations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vYgIRMRn03": {
    "title": "On the In-context Generation of Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NkBPuFOyPe": {
    "title": "FlipGuard: Defending Preference Alignment against Update Regression with Constrained Optimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3zDPZm7YNY": {
    "title": "Multi-Modal and Multi-Agent Systems Meet Rationality: A Survey",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uZ4NJWOuwA": {
    "title": "BCoQA: Benchmark and Resources for Bangla Context-based Conversational Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VZ6IwTdiZV": {
    "title": "Fast Forwarding Low-Rank Training",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bixDcyuC3w": {
    "title": "Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4Ysv9j5nMw": {
    "title": "Sing it, Narrate it: Quality Musical Lyrics Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nIf4iC9dXR": {
    "title": "Grounding Language in Multi-Perspective Referential Communication",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fYEaVbm1VV": {
    "title": "Boosting Translation Capabilities of Large Language Models with Code-Switching Pretraining",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=daU3GzIQ58": {
    "title": "LLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KG93mcIsYv": {
    "title": "A Critical Survey on LLM Deployment Paradigms: Assessing Usability and Cognitive Behavioral Aspects",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kLwY5X4ovF": {
    "title": "Global Prefix-Tuning: Extremely Efficient Fine-Tuning for Shallow Alignment Using One Token",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IEB3MU0t3j": {
    "title": "ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PUBMcARDwJ": {
    "title": "PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5LL5TyTMfV": {
    "title": "SmellDetector: Multi-Label Code Smell Detection and Refactoring with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EvdrkuUbUg": {
    "title": "Studying Differential Mental Health Expressions in India",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=51faGPIG0o": {
    "title": "Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VnDTbu0WB0": {
    "title": "From Traits to Empathy: Personality-Aware Multimodal Empathetic Response Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3HMbUj3bo4": {
    "title": "Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3r04gGOnxd": {
    "title": "Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zCHTrb9c1B": {
    "title": "GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9J0gFCp8At": {
    "title": "The Generation Gap: Exploring Age Bias Underlying in the Value Systems of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YqSXeZfXCg": {
    "title": "Evaluating Fairness in Large Vision-Language Models Across Diverse Demographic Attributes and Prompts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fbhlQzY350": {
    "title": "Indic-MULAN: A Study of Fact Mutability in Language Models for Low-resource Indian languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EchbXYM0DN": {
    "title": "Multi-Granularity History and Entity Similarity Learning for Temporal Knowledge Graph Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K3cOWu0pVC": {
    "title": "Image-conditioned human language comprehension and psychometric benchmarking of visual language models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VmEFM6Jqtf": {
    "title": "Adapters Mixup: Mixing Parameter-Efficient Adapters to Enhance the Adversarial Robustness of Fine-tuned Pre-trained Text Classifiers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JGSh8i3LIr": {
    "title": "Discovering Meaningful Units with Visually Grounded Semantics from Image Captions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oTLbk834Ph": {
    "title": "LLM-powered Context Augmentation for Heterogeneous Citation Networks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ULjRcdsEiU": {
    "title": "LLMs as NLP Researchers: Paper (Meta-)Reviewing as a Testbed",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MHYcgeMGg9": {
    "title": "Beyond English-Centric Machine Translation by Multilingual Instruction Tuning Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=naLNksUMDd": {
    "title": "Is In-Context Learning a Type of Gradient-Based Learning? Evidence from the Inverse Frequency Effect in Structural Priming",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kWlUDTGCb9": {
    "title": "Cerberus: Efficient Inference with Adaptive Parallel Decoding and Sequential Knowledge Enhancement",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ECCTVtJCae": {
    "title": "PRDetect: Perturbation-Robust LLM-generated Text Detection Based on Syntax Tree",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oxYT7ztOt1": {
    "title": "PretextTrans: Investigating Medical Factual Knowledge Mastery of LLMs with Predicate-text Dual Transformation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5bHyRdZkZX": {
    "title": "Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=24CXJ2UEeB": {
    "title": "Reference (In-)Determinacy in Natural Language Inference",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qUKjgYIE05": {
    "title": "Behavioral Bias of Vision-Language Models: A Behavioral Finance View",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1XnMteXc8T": {
    "title": "Residualized Similarity Prediction for Maintaining Interpretability in Authorship Verification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JEHGDzuJLM": {
    "title": "Leveraging a Cognitive Model to Measure Subjective Similarity of Human and GPT-4 Written Content",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sYeakNu6Ll": {
    "title": "Unveiling and Mitigating Bias in Mental Health Analysis with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sVnBCIjMxr": {
    "title": "LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on Path Planning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H3QYUHI99M": {
    "title": "ARISE: Automatic Rule Induction and Filtering for Few-shot Text Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iyvA2me61E": {
    "title": "Eliminating Retrieval Knowledge Conflicts: Cross-Validated Re-ranking with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UlE0F3wfga": {
    "title": "Belief Revision: The Adaptability of Large Language Models Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0AKfifWzSK": {
    "title": "Generation with Dynamic Vocabulary",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b9jsMszNCi": {
    "title": "Do they mean us? Interpreting Referring Expressions in Intergroup Bias",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FEyvVBgOxy": {
    "title": "Extending Multilingual Machine Translation through Behavioral Cloning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M15yEj20uq": {
    "title": "Dependency Parsing with the Structuralized Prompt Template",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5loBBDD3c3": {
    "title": "Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P8PF2e5EXf": {
    "title": "Knowledge Conflicts for LLMs: A Survey",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GsEYwqRfgj": {
    "title": "Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ypkARmcboA": {
    "title": "Threshold-driven Pruning with Segmented Maximum Term Weights for Approximate Cluster-based Sparse Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xw3LPqLYKT": {
    "title": "Bridging Gaps with Multimodal Data: A Comprehensive Dataset for Pharmacovigilance Analysis in Ovarian Cancer",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k3ibnAmzKG": {
    "title": "RAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7UQUQudozb": {
    "title": "Two-level SVM model with language markers for (early) detection of Alzheimer's Disease",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1v26J8FMdi": {
    "title": "The Current State of the NLP in Sub-Saharan Africa - A Position Paper",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4MAACM0Hy6": {
    "title": "Avoiding Copyright Infringement via Machine Unlearning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sjMqvDwq6A": {
    "title": "Robust Claim Verification Through Fact Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aj7CqlDYeG": {
    "title": "Studying and Mitigating Biases in Sign Language Understanding Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4qHLzBY62c": {
    "title": "Images Speak Louder than Words: Understanding and Mitigating Bias in Vision-Language Model from a Causal Mediation Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qKa0jAOKyi": {
    "title": "UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NO2eAN3FQz": {
    "title": "Ask Optimal Questions: Aligning Large Language Models with Retriever's Preference in Conversational Search",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dinFs1ajvR": {
    "title": "SELECTLLM: A Framework for Quality Aware Cost Efficient LLM Usage",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Zr2pXxtEgn": {
    "title": "DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k21Zww3Oon": {
    "title": "RUPBench: Benchmarking Reasoning Under Perturbations for Robustness Evaluation in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=knQo5dGvc7": {
    "title": "Building a Multi-Platform, BERT Classifier for Detecting Connective Language",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cZKqp0etP6": {
    "title": "GovAIEc: A Lexical Complexity Corpus for Spanish in Ecuadorian public documents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1WvIFEPNG1": {
    "title": "OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aHGpeLFdL4": {
    "title": "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kRipwoUR6R": {
    "title": "Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Za1qX4ShsK": {
    "title": "From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vILFJ8fJrn": {
    "title": "Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HTK9Efk8rB": {
    "title": "Symbolic Working Memory Enhances Language Models for Complex Rule Application",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bhWiQWQOGc": {
    "title": "Securing Author Privacy using Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=a95JWLYbIi": {
    "title": "Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DA4XQ3VciF": {
    "title": "The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4LwI0Y646O": {
    "title": "Topic-XICL: Demonstration Selection with Topic Inference for Cross-lingual In-context Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SOWcC2cCMT": {
    "title": "LLM with Relation Classifier for Document-Level Relation Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1dA1DetuTk": {
    "title": "Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Tx7B7Gi52p": {
    "title": "Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q7BNj09ljG": {
    "title": "MVP-Bench: Can Large Vision-Language Models Conduct Multi-level Visual Perception Like Humans?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2MAlLcfx5p": {
    "title": "Guideline Compliance in Task-Oriented Dialogue: The Chained Prior Approach",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9gahhf20Xx": {
    "title": "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n5c4fpprwg": {
    "title": "DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s9y1iT2UFj": {
    "title": "Auditing Counterfire: Evaluating Advanced Counterargument Generation with Evidence and Style",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gVFrVw2z1R": {
    "title": "Voices Unheard: NLP Resources and Models for Yorùbá Regional Dialects",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FAUDgLi6RO": {
    "title": "RAG-Logic: Enhance Neuro-symbolic Approaches for Logical Reasoning with Retrieval-augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KqlSYhDbxe": {
    "title": "Learning to Correct for QA Reasoning with Black-box LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MiCF0g3E4u": {
    "title": "Attacks against Abstractive Text Summarization Models through Lead Bias and Influence Functions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DPCBUZqn1h": {
    "title": "Tune-n-Batch: Fine-Tuning LLMs for Batch Prompting",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=syE0kw1JSE": {
    "title": "Glue pizza and eat rocks\" - Exploiting Vulnerabilities in Retrieval-Augmented Generative Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oWbkowJg1W": {
    "title": "PERSONA: A Reproducible Testbed for Pluralistic Alignment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U3ssobFgDL": {
    "title": "MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WjlXdjwUYl": {
    "title": "Large Language Models Can Self-Correct with Minimal Effort",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3MzURC5YF4": {
    "title": "Multi-Modal Multi-Granularity Tokenizer for Chu Bamboo Slip Scripts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CpbflPKd0Z": {
    "title": "EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room Layout Editing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xtpwoThoBn": {
    "title": "OpenForecast: An Open-Domain and Large-Scale Dataset for LLM-Based Event Forecasting",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KdOvmXA1ba": {
    "title": "Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=njgRRuqJNn": {
    "title": "PATIENT-Ψ: Using Large Language Models to Simulate Patients for Training Mental Health Professionals",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DF9I6swsCa": {
    "title": "Training Task Experts through Retrieval Based Distillation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Acvvg21lst": {
    "title": "Adaptive Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LzHaRaTT71": {
    "title": "An Investigation on Group Query Hallucination Attacks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qlVi4p8zD1": {
    "title": "Can we teach language models to gloss endangered languages?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JD6fJzmFfm": {
    "title": "From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gVnZwOcIgE": {
    "title": "Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hnj2MNpOKr": {
    "title": "Learning How to Prompt with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TIi1hD7G5A": {
    "title": "Advancing Vision-Language Models with Adapter Ensemble Strategies",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ykAqmbjDOg": {
    "title": "A 3D-ResNet Combined with BRNN: Application in the Auxiliary Diagnosis of ADHD",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FnLMVYdXJe": {
    "title": "Detecting Online Community Practices with Large Language Models: A Case Study of Pro-Ukrainian Publics on Twitter",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UA3e4bVxU8": {
    "title": "Leveraging LEXICAL and GRAMMATICAL Errors: Extending ASR Error Measurements through NLP",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y5xrfZ47if": {
    "title": "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=O73iutFBl9": {
    "title": "Large Language Models are Biased to Detect Hallucination across Languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZgVD1BnR6f": {
    "title": "Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-checkers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x7fx4gVqrN": {
    "title": "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AyYIheGWkw": {
    "title": "Automatic Generation of In-Context Math Examples Using Multi-Modal Consistency",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5MAJGeFRIV": {
    "title": "LongWanjuan: Towards Systematic Measurement for Long Text Quality",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DHtyB3ZblF": {
    "title": "A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=T16jwd5e4T": {
    "title": "Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JUlTFCPMuJ": {
    "title": "SymBa: Symbolic Backward Chaining for Structured Natural Language Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3TIsPV9PO6": {
    "title": "Improving Zero-shot LLM Re-Ranker with Risk Minimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P7bxwEk8Xo": {
    "title": "FATH: Authentication-based Test-time Defense against Indirect Prompt Injection Attacks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XM7dMQnqCC": {
    "title": "VQ-TEGAN: Data Augmentation with Text Embeddings for Few-shot Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r6Eh3FbMZF": {
    "title": "UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B3Zv7qzEbX": {
    "title": "How Well Do LLMs Represent Values Across Cultures? Empirical Analysis of LLM Responses Based on Hofstede Cultural Dimensions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hXQy5jmVu6": {
    "title": "MM-MATH: Advancing Multimodal Math Evaluation with Process Evaluation and Fine-grained Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1w6HKalqgi": {
    "title": "Contrastive Classification via Linear Layer Extrapolation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZqHbcan6DG": {
    "title": "Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8LdqmNyP0H": {
    "title": "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jyirCJP6GV": {
    "title": "SoupLM: Model Integration in Large Language and Multi-Modal Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fpXjPbLxUH": {
    "title": "Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uDhgufpecX": {
    "title": "The Privileged Students: On the Value of Initialization in Multilingual Knowledge Distillation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w2Tkz8gKIQ": {
    "title": "UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rdh264rHhe": {
    "title": "Schema-Driven Information Extraction from Heterogeneous Tables",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QIzVVM3YOT": {
    "title": "Words Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5PmyXcU6Tp": {
    "title": "Large Language Models Can Plan Your Travels Rigorously with Formal Verification Tools",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AnCTnj6bR6": {
    "title": "Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KY21Lzjpbx": {
    "title": "CRQBench: A Benchmark of Code Reasoning Questions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IwKGTI5KTF": {
    "title": "Coverage-based Fairness in Multi-document Summarization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8adXCDiX8x": {
    "title": "LLMs Are Biased Towards Output Formats! Systematically Evaluating and Mitigating Output Format Bias of LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NFKWnxtTSH": {
    "title": "Mitigation and Evaluation for Gender Stereotype under Unfair Escape",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eqkyfdseNp": {
    "title": "EASIER: Relevance-Boosted Captioning and Structural Information Extraction for Zero-Shot Video-Text Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HpIX4JDFM8": {
    "title": "How to Leverage Digit Embeddings to Represent Numbers?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TPYhQQX0Ab": {
    "title": "AutoClean: LLMs Can Prepare Their Own Training Corpus",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WzL8o3g9hG": {
    "title": "SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zwkKn1v6J1": {
    "title": "ALPACA AGAINST VICUNA: Using LLMs to Uncover Memorization of LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DZhqSyXAgo": {
    "title": "Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting Framework",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jemQNMrpR0": {
    "title": "Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fWKgTz5sRL": {
    "title": "Pretrained Soft Prompt for Few-shot Unlearning via Relearning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rOvr0w1R7J": {
    "title": "Step-Back Profiling: Distilling User Interactions for Personalized Scientific Writing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HRiAT7jaLB": {
    "title": "Pay Attention to Real World Perturbations! Natural Robustness Evaluation in Machine Reading Comprehension",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TeRPGOGWRb": {
    "title": "Leveraging Passage Embeddings for Efficient Listwise Reranking with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=R2b1gSEbaN": {
    "title": "A Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5CBIuoWLol": {
    "title": "$R^3$: \"This is My SQL, Are You With Me?\" A Consensus-Based Multi-Agent System for Text-to-SQL Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I6oClTK5xq": {
    "title": "Eagle: A Family of Advanced Arabic Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MT4WEGzP5J": {
    "title": "Evaluating Concurrent Robustness of Language Models Across Diverse Challenge Sets",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IICFsvKyW6": {
    "title": "Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uvc1SDMdZK": {
    "title": "Low-rank Subspace for Binding in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9p8CI3cdqr": {
    "title": "The Ultimate Cookbook for Invisible Poison: Crafting Subtle Clean-Label Text Backdoors with Style Attributes",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g0zsQyXNhQ": {
    "title": "GOME: Grounding-based Metaphor Binding With Conceptual Elaboration For Figurative Language Illustration",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NHtScfaITd": {
    "title": "CEAMC: Corpus and Empirical Study of Argument Analysis in Education via LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mAegiwQYJ5": {
    "title": "Exploring Non-Autoregressive Image Captioning: Patterns and Semantics",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OPf78dMVFf": {
    "title": "MantisScore: A Reliable Fine-grained Metric for Video Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MydOaViluf": {
    "title": "KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FzEMhmC8jZ": {
    "title": "Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q4Funv6xB8": {
    "title": "GEM-VPC: A dual Graph-Enhanced Multimodal integration for Video Paragraph Captioning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1zJrDjKTWg": {
    "title": "SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RQeImTmSMI": {
    "title": "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UE5P9b4oBj": {
    "title": "LLMs are Turning a Blind Eye to Context: Insights from a Contrastive Dataset for Idiomaticity",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SvkOAxZdgv": {
    "title": "Nova: Generative Language Models for Assembly Code with Hierarchical Attention and Contrastive Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=y5gbFhQUbU": {
    "title": "SCA: Selective Compression Attention for Efficiently Extending the Context Window of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BKrYt5WEKN": {
    "title": "Incubating Text Classifiers Following User Instruction with Nothing but LLM",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TJUvajnLE1": {
    "title": "IDEAL: Leveraging Infinite and Dynamic Characterizations of Large Language Models for Query-focused summarization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NvNcOt9Jtq": {
    "title": "Learning to Rank Salient Content for Query-focused Summarization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kiHlEOJ1ID": {
    "title": "LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E6gQDgDVBc": {
    "title": "Where Am I From? Identifying Origin of LLM-generated Content",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EKlispzX65": {
    "title": "EBGCG: Effective White-Box Jailbreak Attack Against Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lY26YCmzo4": {
    "title": "LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HM55vfxtIs": {
    "title": "Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MZVrFEqVm7": {
    "title": "Exploring Rollback Inference for Aspect-based Sentiment Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EmDtezabqo": {
    "title": "AI-LieDar : Examine the Trade-off Between Utility and Truthfulness in LLM Agents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CGaEMnkzdR": {
    "title": "EmoKnob: Enhance Voice Cloning with Fine-Grained Emotion Control",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jYBjseMMSQ": {
    "title": "You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lcSHjDf6A6": {
    "title": "What Matters in Learning Facts in Language Models? Multifaceted Knowledge Probing with Diverse Multi-Prompt Datasets",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3CrvafYU3I": {
    "title": "Self-Adapted Entity-Centric Data Augmentation for Discontinuous Named Entity Recognition",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kWSpDKbHqS": {
    "title": "How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g6e9jgEobl": {
    "title": "VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E3VS45jxPR": {
    "title": "Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GpMzZcHHXm": {
    "title": "To Know What User Concerns: Conceptual Knowledge Reasoning for Task-oriented Dialogue Quality Estimation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g3jAdDEzSa": {
    "title": "Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6EUixqUlYS": {
    "title": "UKoSpeech: A Universal Korean ASR System for Diverse Domains",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0P1mkOvFIs": {
    "title": "Do LLMs Believe in Themselves? A Benchmark for LLM Robustness against External Counterfactual Knowledge",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OjRuBvZ8TO": {
    "title": "PUMGPT: A Large Vision-Language Model for Product Understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rrzw1t7LHc": {
    "title": "How Trustworthy is AI? A Deep Dive into the Bias in LLM-Based Recommendations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NmsQxtveeD": {
    "title": "Employing Glyphic Information for Chinese Event Extraction with Vision-Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Aqp3VzWHus": {
    "title": "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qXPJfQ9EWB": {
    "title": "CacheFormer: High Attention-based Segment Caching",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4nYcouJ6cI": {
    "title": "A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZUjqTc3dtz": {
    "title": "Improving the Factual Consistency of Abstractive Summarization: Model Self-Improvement Contrastive Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m9TuxlYIUL": {
    "title": "NormAd: A Benchmark for Measuring the Cultural Adaptability of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NUnoxv5Wr0": {
    "title": "MM-ChatAlign: A Novel Multimodal Reasoning Framework based on Large Language Models for Entity Alignment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IKK3v4uJz3": {
    "title": "ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8adI1JF8is": {
    "title": "Self-Improving Mathematical Reasoning of Large Language Models with a Code-Centric Paradigm",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DmirBUDJIy": {
    "title": "RAR: Retrieval Augmented Retrieval for Code Generation in Low Resource Languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s0kOGjxYyS": {
    "title": "A Survey on Open Information Extraction from Rule-based Model to Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jBLs05nDDH": {
    "title": "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UCreMNQzMU": {
    "title": "Learning to Refine with Fine-Grained Natural Language Feedback",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B0wvJYPT7M": {
    "title": "Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4SudP0Fuiz": {
    "title": "Grounding GPT-based Dialogue Agents with Knowledge Graphs for Consistent Personality",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Yxotd46V0U": {
    "title": "Question-Based Retrieval using Atomic Units for Enterprise RAG",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wtd6kWpB2V": {
    "title": "CAMELoT: Towards Large Language Models with Training-Free Consolidated Associative Memory",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=58Y5SMJ39R": {
    "title": "Birdie: Advancing State Space Models with a Minimalist Architecture and Novel Pre-training Objectives",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jr5I4gtkF6": {
    "title": "Shortcomings of LLMs for Low-Resource Translation: Retrieval and Understanding are Both the Problem",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LTz44KTb0X": {
    "title": "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CHkYtgbp6T": {
    "title": "EXCGEC: A Benchmark of Edit-wise Explainable Chinese Grammatical Error Correction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XehjPcp9la": {
    "title": "Intermediate Adapter: Efficient Alignment of Text in Diffusion Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kpDfxMzqck": {
    "title": "A New Competency Tagging Method through Semantic Matching with Fine-tuned LLM",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yGbc8D9fpv": {
    "title": "Swan: A Family of Arabic-Centric Cross-Lingual Embedding Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0hTlMm1im6": {
    "title": "Personalized LLM Response Generation with Parameterized User Memory Injection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nliOFWYlq8": {
    "title": "The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fpSUK1rbQs": {
    "title": "Language Modeling with Editable External Knowledge",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UCiDbOtHUb": {
    "title": "OT-Class: Optimal Transport-Enhanced Multi-label Text Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FyGJs8nhhU": {
    "title": "Pattern-Aware Chain-of-Thought Prompting in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CvrzffhXSg": {
    "title": "When ``A Helpful Assistant'' Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4AzksYndtz": {
    "title": "Seeing the Big through the Small\": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sgpUbD2okH": {
    "title": "Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V0I9AyRoV1": {
    "title": "Regression (and Scoring) Aware Inference with LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TnIUaq2d5y": {
    "title": "The Association Between Training Data and Success Ratios in Text-to-Image Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s4OukoHwnz": {
    "title": "Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LfDjUznLUv": {
    "title": "ChatGPT Doesn't Trust LA Chargers Fans: Guardrail Sensitivity in Context",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sSkTGRZMBj": {
    "title": "Annotator-Centric Active Learning for Subjective NLP Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mjjTKZZPlY": {
    "title": "Can We Instruct LLMs to Compensate for Position Bias?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UzIpiYHEoU": {
    "title": "War and Peace (WarAgent): LLM-based Multi-Agent Simulation of World Wars",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4NxcIoCcDH": {
    "title": "Aligning Language Models Using Multi-Objective Deep Reinforcement Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gmcHqlRC4n": {
    "title": "VALUE-Bench: A Comprehensive Benchmark for Evaluating Large Vision-Language Models on Multimodal Ethical Understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Km7sEBdyzh": {
    "title": "Retrieval and Reasoning on KGs: Integrate Knowledge Graphs into Large Language Models for Complex Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EQYtmyOrql": {
    "title": "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zymMBdfyDw": {
    "title": "Large Language Models are In-context Teachers for Knowledge Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GWZ0SYS3Bl": {
    "title": "Soft Prompting for Unlearning in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1Wz5w6rVSa": {
    "title": "Assessing the Role of Lexical Semantics in Cross-lingual Transfer through Controlled Manipulations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xMQ79IsvJL": {
    "title": "Improving Translation Faithfulness of Large Language Models via Augmenting Instructions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x2Ay4agzz2": {
    "title": "From Intentions to Techniques: A Comprehensive Taxonomy and Challenges in Text Watermarking for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ouUtjTa8vO": {
    "title": "Large Language Models for Data Annotation: Methods, Applications, and Challenges",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dSl8Cy3ID6": {
    "title": "Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CteqUe86mH": {
    "title": "Aligning with Whom? Large Language Models Have Gender and Racial Biases in Subjective NLP Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LvfghCNzyT": {
    "title": "Enhancing Reinforcement Learning with Intrinsic Rewards from Language Model Critique",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7NtfIYIqvk": {
    "title": "A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UP2apLrRO3": {
    "title": "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SIBusKukhe": {
    "title": "Crafting a Good Prompt or Providing Exemplary Dialogues? A Study of In-Context Learning for Persona-based Dialogue Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LVzKm1nvsd": {
    "title": "An image speaks a thousand words, but can everyone listen? On image transcreation for cultural relevance",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HIJOhOLUh4": {
    "title": "Rethinking Pruning for Vision-Language Models: Strategies for Effective Sparsity and Performance Restoration",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Z5DXkGyHCc": {
    "title": "Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kVVyhb1kwu": {
    "title": "Do Not Design, Learn: A Trainable Scoring Function for Uncertainty Estimation in Generative LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P2J2C5c8e3": {
    "title": "Neuro-symbolic Training for Reasoning over Spatial Language",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=APMnhbnk4B": {
    "title": "Improving Temporal Reasoning of Language Models via Recounted Narratives",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ONJ1sfOqGV": {
    "title": "Modeling Bilingual Sentence Processing: Evaluating RNN and Transformer Architectures for Cross-Language Structural Priming",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jOddQtCjdQ": {
    "title": "Encourage or Inhibit Monosemanticity? Revisit Monosemanticity from a Feature Decorrelation Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=syTkSPx0KU": {
    "title": "Transformers Can Model Human Hyperprediction in Buzzer Quiz",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J1JJ6qz9ZU": {
    "title": "LOCR: Location-Guided Transformer for Optical Character Recognition",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u2IWQn4OUq": {
    "title": "Lessons from using PLMs for Human Cognitive Modeling",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yxAhdDI2yN": {
    "title": "SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I1MrRb2K8l": {
    "title": "Understanding Translationese Effects in Multilingual Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VFmjzSCZgI": {
    "title": "Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=a81VIUxbgL": {
    "title": "Identifying Factual Inconsistencies in Summaries: Grounding Model Inference via Task Taxonomy",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YP8QNMaAhq": {
    "title": "ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=y6DKvWOTxB": {
    "title": "Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MFIYTecQ9Z": {
    "title": "Analyzing the Capabilities of Large Language Models in Annotating Substance Use Behavior from Clinical Notes",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JuSCbH0Snw": {
    "title": "$\\texttt{ModSCAN}$: Measuring Stereotypical Bias in Large Vision-Language Models from Vision and Language Modalities",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KIMkNwkxHX": {
    "title": "DocEditAgent: Document Structure Editing Via Multimodal LLM Grounding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UVYrFofLPk": {
    "title": "StateAct: State Tracking and Reasoning for Acting and Planning with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hWxipcH3t9": {
    "title": "Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4MneeeHGuL": {
    "title": "To Err Is Human, but Llamas Can Learn It Too",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h66QOiHyaZ": {
    "title": "Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K1VIvCN4gz": {
    "title": "Semantic Token Reweighting for Interpretable and Controllable Text Embeddings in CLIP",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hD04BoVVNR": {
    "title": "Evaluating Language Model Character Traits",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wo7FcGvM8r": {
    "title": "Evaluating Diversity in Automatic Poetry Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q9kPg2ndg2": {
    "title": "ALLaM: A Series of Large Language Models for Arabic and English",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Hx4iYqZV5J": {
    "title": "Automated Clinical Data Extraction with Knowledge Conditioned LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dVTHEGwn3j": {
    "title": "Skills-in-Context: Unlocking Compositionality in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YeeUN3tj6s": {
    "title": "Attribute Diversity Determines the Systematicity Gap in VQA",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ziKFVuk373": {
    "title": "Mitigating the Impact of Reference Quality on Evaluation of Summarization Systems with Reference-Free Metrics",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CjmPCi8Gfg": {
    "title": "Leveraging Parameter-Efficient Transfer Learning for Multi-Lingual Text-to-Speech Adaptation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sOrUfhfo8n": {
    "title": "Triple Preference Optimization: Achieving Better Alignment with Less Data in a Single Step Optimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=i5804xg6cE": {
    "title": "Many-Turn Jailbreaking",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VGNQEZfxKJ": {
    "title": "Direct-Inverse Prompting: Analyzing LLMs' Discriminative Capacity in Self-Improving Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VWPanc8u1g": {
    "title": "CliniDial: A Naturally Emerged Multimodal Dialogue Dataset for Team Reflection During Clinical Operation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Qt7yYNYiHL": {
    "title": "What's the most important value? INVP: INvestigating the Value Priorities of LLMs through Decision-making in Social Scenarios",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JixLyKI26g": {
    "title": "Data, Data Everywhere: A Guide for Pretraining Dataset Construction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aBeDyLkDyq": {
    "title": "Explanations explained. Influence of free-text explanations on LLMs and the role of implicit knowledge",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ie7bTfSllb": {
    "title": "Situational Evaluation for Social Intelligence of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nyGYCmtZqb": {
    "title": "Unlocking Continual Learning Abilities in Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZSfjY9piYg": {
    "title": "PatentEdits: A Patent Dataset Built for Predicting Revisions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Nw42MFuiKi": {
    "title": "Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pTbU2eKEPh": {
    "title": "MetaKP: On-Demand Keyphrase Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XgDfgnelgD": {
    "title": "Aligners: Decoupling LLMs and Alignment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mfgcxMm5aa": {
    "title": "One-to-Many Communication and Compositionality in Emergent Communication",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LepnjkXd08": {
    "title": "Carrot and Stick: Inducing Self-Motivation with Positive & Negative Feedback",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P0XxzFvTdJ": {
    "title": "EEG2Text: Open Vocabulary EEG-to-Text Decoding with EEG Pre-Training and Multi-View Transformer",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=27BrXMjq0h": {
    "title": "GE2PE: Persian End-to-End Grapheme-to-Phoneme Conversion",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qd3tzSnUN6": {
    "title": "Estimating Knowledge in Large Language Models Without Generating a Single Token",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cJ2GJm6tvr": {
    "title": "MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uue5KxPxY2": {
    "title": "A Unified Framework for Model Editing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t3RXpmeITf": {
    "title": "MANDALA: Multi-Agent Network for Backdoor Detection using AST Parsing and Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cA06EOIC3P": {
    "title": "Reuse, Don't Retrain: A Recipe for Continued Pretraining of Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hjSHtAEm0j": {
    "title": "VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models with Leaky Visual Conversations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tuAmmObUvK": {
    "title": "DistiLRR: Transferring Code Repair for Low-Resource Programming Languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rrIkAMZEPS": {
    "title": "Rethinking Text Generation Evaluation: A Unified Evaluation Theory for Reflective and Open-Ended Generation Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WhGw4tm9cZ": {
    "title": "The Role of Language Imbalance in Cross-lingual Generalisation: Insights from Cloned Language Experiments",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NXYVm3AjG2": {
    "title": "TabMeta: Table Metadata Generation with LLM-Curated Dataset and LLM-Judges",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kgFXSF1Jra": {
    "title": "SQFT: Low-cost Model Adaptation in Low-precision Sparse Foundation Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A9miw3n6A5": {
    "title": "Waste-Bench: A Comprehensive Benchmark for Evaluating VLLMs in Cluttered Environments",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=W7QCm2qjIh": {
    "title": "PromptAug: Data Augmentation for Fine Grained Conflict Identification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K9zCZHfj6J": {
    "title": "Paraphrase Generation Evaluation Powered by LLM: A Semantic Metric, Not a Lexical One",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uZORaRP9DX": {
    "title": "Evidence Retrieval for Fact Verification using Multi-stage Reranking",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f5q2g4PDFj": {
    "title": "Exploring Large Language Models for Low-resource Reference-less Evaluation of Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=75IAHKH1wX": {
    "title": "BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qxCUqxR5hG": {
    "title": "Weighted Grouped Query Attention in Transformers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BxrgkvGusd": {
    "title": "Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RzyM8nR2MH": {
    "title": "Eliciting human preferences with language models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8j0DgspBJH": {
    "title": "An Investigation into the Privacy Flow of Large Language Models in Interactive Contextual Settings",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Dq8VpnQ4M6": {
    "title": "PETapter: Leveraging PET-style classification heads for modular few-shot parameter-efficient fine-tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ATZoN90B7g": {
    "title": "NewsEdits 2.0: Learning the Intentions Behind Updating News",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k5g7GkSf9y": {
    "title": "Exploring Quantization for Efficient Pre-Training of Transformer Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Vjsgqtmx0G": {
    "title": "Evaluating large language-vision models on geographic language understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PIt90fv6W4": {
    "title": "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MJEaWaxC6B": {
    "title": "Biaffine Modal Dependency Parsing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jxc8TbxweK": {
    "title": "Authorship Style Transfer with Policy Optimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xFFyvJcqaq": {
    "title": "InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=duOsmTMvnu": {
    "title": "ApiQ: Finetuning of 2-Bit Quantized Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dsXatBeZV6": {
    "title": "Morphology of Chinese Characters: Evaluating LLMs and VLMs on Visual Features and Radical Prompting for NLP Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mrjLTbCcHi": {
    "title": "StoC-TOT: Stochastic Tree-of-Thought with Constrained Decoding for Complex Reasoning in Multi-Hop Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yEttrbXR4X": {
    "title": "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UCr1wOgr8c": {
    "title": "What Does Infect Mean to Cardio? Investigating the Role of Clinical Specialty Instructions in Medical LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JMrPaXEKru": {
    "title": "Towards Region-aware Bias Evaluation Metrics",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QpHBzKfNd3": {
    "title": "Enhancing Alzheimer's Disease Diagnosis Records with Large Language Models: A Pipeline for Multimodal and Longitudinal EHRs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DmhkhcXa2q": {
    "title": "LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MhDEbTtQPf": {
    "title": "A Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h2dAggXjXo": {
    "title": "As easy as PIE: understanding when pruning causes language models to disagree",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xsfPGxrBOr": {
    "title": "Driving Chinese Spelling Correction from a Fine-Grained Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zuS0YC7rpC": {
    "title": "MEANT: Multimodal Encoder for Antecedent Information",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AZ781CuNLk": {
    "title": "Follow the Beaten Path: The Role of Route Patterns on Vision-Language Navigation Agents Generalization Abilities",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TNfYsLINzx": {
    "title": "A Novel Dual of Shannon Information and Weighting Scheme",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RWYxCEbMvy": {
    "title": "Reviewer2: Optimizing Review Generation Through Prompt Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FkbcreYFJW": {
    "title": "LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qcH80ZZGXa": {
    "title": "Unifying Demonstration Selection and Compression for In-Context Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gxQAPMDX6y": {
    "title": "Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bI93TNG81x": {
    "title": "Investigating Continual Pretraining in Large Language Models: Insights and Implications",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f7ODMHHcln": {
    "title": "Large Language Models Often Say One Thing and Do Another",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LBw0Yyo97R": {
    "title": "FarsInstruct: Empowering Large Language Models for Persian Instruction Understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sCYZZBXk7z": {
    "title": "Demographically Blind Models Can be Unfair: Fairness through Awareness",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1IKZ876fWt": {
    "title": "Generating Demonstrations for In-Context Compositional Generalization in Grounded Language Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YqwQgLVMI7": {
    "title": "Analyzing Context Utilization of LLMs in Document-Level Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ww64cfDsTv": {
    "title": "Evaluating Linguistic Capabilities of Multimodal LLMs in the Lens of Few-Shot Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x3RxLiMLr0": {
    "title": "From Insights to Actions: The Impact of Interpretability and Analysis Research on NLP",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mG5jikbsaJ": {
    "title": "LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cI06Zq5z4P": {
    "title": "ProtocoLLM: Automatic Evaluation Framework of LLMs on Domain-Specific Scientific Protocol Formulation Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RFo4zsNRkP": {
    "title": "Evaluating Large Language Models along Dimensions of Language Variation: A Systematik Invesdigatiom uv Cross-lingual Generalization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1oebeZzs6T": {
    "title": "Learn and Unlearn in Multilingual LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cnrLITgaJN": {
    "title": "Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6lKk4WY58T": {
    "title": "TABLE CALL: A New Paradigm for Table Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=x1b7n8r9vE": {
    "title": "More \"Clever\" than \"Hans\": Probing and Adversarial Training in Translationese Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XOEUN7FggX": {
    "title": "How Susceptible are Large Language Models to Ideological Manipulation?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZgByAYBMLX": {
    "title": "FOOL ME IF YOU CAN! An Adversarial Dataset to Investigate the Robustness of LMs in Word Sense Disambiguation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q3zEMBprem": {
    "title": "PairDistill: Pairwise Relevance Distillation for Dense Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iAIuEQKDa3": {
    "title": "One-to-Many Testing for Code Generation from (Just) Natural Language",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jihnOw3uSC": {
    "title": "Improving Causal Event Attribution in LLMs using Cross-Questions to Validate Causal Inference Assumptions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mUcrxZje0K": {
    "title": "SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r8qiZ0UQQd": {
    "title": "Balancing the Scales: Reinforcement Learning for Fair Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8LeNxDkH3A": {
    "title": "Comparing Hallucination Detection Methods for Multilingual Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6bjKMg61kc": {
    "title": "HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rH5IIN5FX4": {
    "title": "IotaCode: A Small Code Model Can Be Reinforced to Beat the Bigger One",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4Xkyy48UOK": {
    "title": "Chain of Second Thoughts: Augmenting Chain-of-Thought Prompting with General Purpose Verifiers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ShkBlFFoFT": {
    "title": "Toward an Unsupervised Method for Assessing Semantic Specificity",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wEwg3Ff37d": {
    "title": "How Does Quantization Affect Multilingual LLMs?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=njKEUmn81R": {
    "title": "Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U7LlVdChPU": {
    "title": "Long Input Benchmark for Russian Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dgbnkK0Dz8": {
    "title": "Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sgFCrAgFnH": {
    "title": "GSR-BENCH: A Benchmark for Grounded Spatial Reasoning Evaluation via Multimodal LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=N06hbHULIP": {
    "title": "EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Jtsk15wzv4": {
    "title": "Benchmarking Public Large Language Models in Low-resource Languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gJGKsTG9xd": {
    "title": "Scaling laws for post-training quantized large language models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GTnzkwBoxO": {
    "title": "An Empirical Study of Validating Synthetic Data for Formula Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8ed7ZGhBGJ": {
    "title": "From Generation to Selection Findings of Converting Analogical Problem-Solving into Multiple-Choice Questions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RGclruEFoK": {
    "title": "LLMRank: Enhancing Large Language Models for Unsupervised Keyphrase Extraction with a Candidate Graph Approach",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pexlcefYkj": {
    "title": "Multi-Hop Table Retrieval for Open-Domain Text-to-SQL",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kEScimnD9Y": {
    "title": "A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EYkQFEc2MG": {
    "title": "Hypothesis Generation with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BvFyvkzs41": {
    "title": "Improving Linguistic Diversity of Large Language Models with Possibility Exploration Fine-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=221GeR7I7i": {
    "title": "Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural Knowledge",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2OwDyu9xR3": {
    "title": "Relation Extraction with Instance-Adapted Predicate Descriptions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MHknR4bWrz": {
    "title": "MKT: A Multi-Stage Knowledge Transfer Framework to Mitigate Catastrophic Forgetting in Multi-Domain Chinese Spelling Correction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q2K8ijV4bY": {
    "title": "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aCGxn1jpFe": {
    "title": "GPT makes a poor AMR parser",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LCBMGy3qjc": {
    "title": "Future Events as Backdoor Triggers: Investigating Temporal Vulnerabilities in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tA08E8bKoH": {
    "title": "Protecting Privacy in Classifiers by Token Manipulation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5pKv0gNLBz": {
    "title": "Explicit Inductive Inference using Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OykupORtFB": {
    "title": "Detecting Synthetic Lyrics with Few-Shot Inference",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PzOLpU6ofN": {
    "title": "Towards Textless Multilingual Audio Question Answering (TM-AQA) System Using Audio-MAMBA",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Mv3Ix4srg3": {
    "title": "Post Training Quantization of Large Language Models with Microscaling Formats",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=etw0Iseq0r": {
    "title": "On the Relationship between Truth and Political Bias in Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AJJZfN6jdv": {
    "title": "CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dxTO4dYbrS": {
    "title": "Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MmHSjAKH4U": {
    "title": "Measuring Psychological Depth in Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SCttYXtNIa": {
    "title": "RecLLMSim: A Comprehensive Task-based Recommendation Conversation Dataset Generated by Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=azYizvxfLh": {
    "title": "Benchmarking LLMs on the Semantic Overlap Summarization Task",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XJEmvFwrkT": {
    "title": "ILENS: Iterative Logical Enhancement via Neurosymbolic Computation and Common Sense",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5vjZJ56miF": {
    "title": "Benchmarking Language Models for Offensive Sentences Classification in Offensive Nepali Roman Multi-Label Dataset",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zS9v4KyNFZ": {
    "title": "Using Linguistic Synchrony to Evaluate Large Language Models for Cognitive Behavioral Therapy",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tkbzXpY4hD": {
    "title": "Learning Personalized Alignment for Evaluating Open-ended Text Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DVuo4r9ATq": {
    "title": "The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced By Them Instead?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HlXuNuHRf4": {
    "title": "HaloRAG: Towards Mitigating LLM Hallucinations with Low-Cost Real-Time Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OJoXQOKsJK": {
    "title": "Optimizing Class-Level Code Generation: Enhancing In-Context Learning in Large Language Models with Pruning Techniques",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k88OiuUp2j": {
    "title": "A Survey on Misinformation Prevention and Detection methods in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jlrqe4XQ6S": {
    "title": "Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6altEjJnVK": {
    "title": "Automated Evaluation of Large Vision-Language Models on Self-driving Corner Cases",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tAr6Kso5hm": {
    "title": "Prompt4LJP: Prompt Learning for Legal Judgement Prediction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dTdoZql621": {
    "title": "Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w4Z0xj0hzG": {
    "title": "Temporal Cognitive Tree: A Hierarchical Modeling Approach for Event Temporal Relation Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ct8iMUwc9m": {
    "title": "Explain then Rank: Scale Calibration of Neural Rankers Using Natural Language Explanations from LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pv1T9sgbeF": {
    "title": "GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XNobSD0MI9": {
    "title": "Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mjWhyqmABo": {
    "title": "Gender Bias in Nepali-English Machine Translation: A Comparison of LLMs and Existing MT Systems",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZSvYMHFgbL": {
    "title": "``Let's Argue Both Sides'': Argument Generation Can Force Models to Utilize Previously Inaccessible Reasoning Capabilities",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1p3h7Y7BeD": {
    "title": "Document-Level Event Extraction Based on Multi-instance Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=scXinOTZio": {
    "title": "Multimodal Large Language Models \"Foresee\" Objects Based on Verb Information But Not Gender",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2oS2kmTWZt": {
    "title": "Socially Aware Language Technologies: Perspectives and Practices",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FOQTQPBzPY": {
    "title": "A Context-Aware Approach for Enhancing Data Imputation with Pre-trained Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=thTaXZDeJC": {
    "title": "Are Large Language Models All You Need for Temporal Knowledge Graph Forecasting?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cSX19q9Jne": {
    "title": "Unifying Multimodal Retrieval via Document Screenshot Embedding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v5YGQK1qCP": {
    "title": "Improving Referring Ability for Biomedical Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o7GOyn0QJe": {
    "title": "An Efficient Approach for Studying Cross-Lingual Transfer in Multilingual Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IcPpNETR2y": {
    "title": "TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1cW5OIJFhT": {
    "title": "Low-Resource Machine Translation through the Lens of Personalized Federated Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CXsrhCqnKI": {
    "title": "Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ddlMkvyErA": {
    "title": "FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YWGUisSIMz": {
    "title": "Dynamic Few-Shot Learning for Knowledge Graph Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rxnhpYt6i1": {
    "title": "GraphLSS: Integrating Lexical, Structural, and Semantic Features for Long Document Extractive Summarization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QHGaAX9OOH": {
    "title": "SaSR-Net: Source-Aware Semantic Representation Network for Enhancing Audio-Visual Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4gS6YvnXXN": {
    "title": "Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k44TLajHss": {
    "title": "MemAgent: A cache inspired framework for augmenting conversational Web Agents with task-specific information",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2UOqOvaLUn": {
    "title": "Are Large Language Models (LLMs) Good Social Predictors?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=weLpjmdAFt": {
    "title": "Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=buKTXCa0aT": {
    "title": "PclGPT: A Large Language Model for Patronizing and Condescending Language Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IxNM13HBVJ": {
    "title": "Extending Cognitive Reframing Therapy: Multimodal Support and Multi-hop Psychotherapeutic Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=y2eUPuHQ2C": {
    "title": "A Chain-of-Task Framework for Instruction Tuning of LLMs Based on Chinese Grammatical Error Correction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=355wzFydL4": {
    "title": "Good Idea or Not, Representation of LLM Could Tell",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Di4SpgOszX": {
    "title": "Dual Diffusion Learning for Knowledge-Grounded Dialogue Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6nIFhDa5Ma": {
    "title": "CoverICL: Selective Annotation for In-Context Learning via Active Graph Coverage",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=db1WNQ79wx": {
    "title": "Concept Bottleneck Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H8vXUkIlVk": {
    "title": "Argument Mining with LLaMA 8B",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VOdZlvtlJz": {
    "title": "MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZJFgdmfAfT": {
    "title": "ClauseQA: Enhancing Customized Clause Extraction in Large Language Models via Instruction Following",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JF4qyxaAJo": {
    "title": "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ny51IA44q8": {
    "title": "Leveraging Large Models for Evaluating Novel Content: A Case Study on Advertisement Creativity",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OWiyyvMc0e": {
    "title": "Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1wEUzefTW3": {
    "title": "A Notion of Complexity for Theory of Mind via Discrete World Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9tjO2SoXAf": {
    "title": "WavLLM: Towards Robust and Adaptive Speech Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6T8qeXK7PN": {
    "title": "The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fbgGzJ0Uu9": {
    "title": "Advancing Translation Preference Modeling with RLHF: A Step Towards Cost-Effective Solution",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zSwnz6BsDa": {
    "title": "SHADES: Towards a Multilingual Assessment of Stereotypes in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gRpRRhTEJr": {
    "title": "How Facility is the Small-Scale Abstractive Summarization Model: A Quantitative Study of Semantics and Syntax",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dKODiqIfRY": {
    "title": "Granular Entity Mapper: Advancing Fine-grained Multimodal Named Entity Recognition and Grounding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NNFIu4KZpZ": {
    "title": "The Need for a Leaderboard: A Survey of LLM as a Judge in NLP",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pywu9bFaHl": {
    "title": "Re-Examine Distantly Supervised NER: A New Benchmark and a Simple Approach",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fXsHY6NdiB": {
    "title": "NALA: an Effective and Interpretable Entity Alignment Method",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k5cBrtuElA": {
    "title": "An Empirical Study of Iterative Refinements for Non-autoregressive Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ks89hD05cu": {
    "title": "Can We Verify Step by Step for Incorrect Answer Detection?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BeglmPVIVe": {
    "title": "Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GDQ2us7g3Y": {
    "title": "Data Contamination Can Cross Language Barriers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YHTR7Trkep": {
    "title": "Multi-view Content-aware Indexing for Long Document Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=afj2KQYzzj": {
    "title": "RE-RAG: Improving Open-Domain QA Performance and Interpretability with Relevance Estimator in Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sNJQMrM9rb": {
    "title": "Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GKNUTvkal9": {
    "title": "DIRAS: Efficient LLM-Assisted Annotation of Document Relevance in Retrieval Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZfIB7yUgAS": {
    "title": "Teaching Large Language Models to Express Knowledge Boundary from Their Own Signals",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u6QfNfk4Gf": {
    "title": "First Multi-Dimensional Evaluation of Flowchart Comprehension for Multimodal Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gil6KUTqvm": {
    "title": "An Exam for Anyone on Anything: LLM-Based Textbook Data Transformation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=smP90p65Sn": {
    "title": "Revealing The Intrinsic Ability of Generative Text Summarizers for Irrelevant Document Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9IVeNxXFV4": {
    "title": "World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X6MllOyg2y": {
    "title": "Evaluate, Scale, and Credit: A Comprehensive Study on Multi-Agent Collaboration of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xKGlpYvv9K": {
    "title": "Textless Speech-to-Speech Translation With Limited Parallel Data",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=W045tMwo4l": {
    "title": "Weakly-supervised Argument Mining with Boundary Refinement and Relation Denoising",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tULtVDdu8D": {
    "title": "Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mzOyE5wBMO": {
    "title": "AdaMoE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fqBBwIh238": {
    "title": "AdaCQR: Enhancing Query Reformulation for Conversational Search via Sparse and Dense Retrieval Alignment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=efksXXZa6k": {
    "title": "Large Language Models in Real-World Table Task Workflows: A Survey",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Knvy5pqhoo": {
    "title": "CLEME2.0: Towards More Interpretable Evaluation by Disentangling Edits for Grammatical Error Correction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q1hoMgzfw3": {
    "title": "EmbodiedBERT: Cognitively Informed Metaphor Detection Incorporating Sensorimotor Information",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Qw5KhoZOtA": {
    "title": "Benchmarking Vision Language Models for Cultural Understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KMD13Pdmit": {
    "title": "Multiple-Choice Questions are Efficient and Robust LLM Evaluators",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D2iN1eaFey": {
    "title": "Where does meaning live? Investigating the synthetic-analytic distinction in LLMs using gender as a case study",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NBeUgOpyWK": {
    "title": "Aligning Language Models to Explicitly Handle Ambiguity",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v3x1Pf4Y3r": {
    "title": "Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=a3rIzsawoF": {
    "title": "MoreHopQA: More Than Multi-hop Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PMa5ef9wxC": {
    "title": "Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BiY9SjM4OW": {
    "title": "Assessing and Post-Processing Black Box Large Language Models for Knowledge Editing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5mhCK0g5gw": {
    "title": "Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lTe2TqV6Iw": {
    "title": "MuAP: Multi-step Adaptive Prompt Learning for Vision-Language Model with Missing Modality",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5j1dGzpxr4": {
    "title": "Rater Cohesion and Quality from a Vicarious Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YdMiRnaU55": {
    "title": "On the Effects of Fine-tuning Language Models for Text-Based Reinforcement Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rTIU50bCtN": {
    "title": "QCRD: Quality-guided Contrastive Rationale Distillation for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fJ5ks1PLqS": {
    "title": "Efficient Unicode-Compatible Grammar-Constrained Decoding via String Homomorphism",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t8MJG2Nav6": {
    "title": "Progressive Multimodal Chain-of-Thought Tuning for Vision-Indispensable Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ul3AZUhMxO": {
    "title": "Opinion Units: Concise and Contextualized Representations for Aspect-Based Sentiment Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OaBqHlz3vP": {
    "title": "Organic Data-Driven Approach for Turkish Grammatical Error Correction and LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d8pBs6OQZ4": {
    "title": "Prosody Detection improves Pretrained Automatic Speech Recognition",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q3hhdoJo5v": {
    "title": "A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rzkx5AGJ3N": {
    "title": "Data Management For Training Large Language Models: A Survey",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CRtPOGbNOd": {
    "title": "Cross-Lingual Multi-Hop Knowledge Editing -- Benchmarks, Analysis and a Simple Contrastive Learning based Approach",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vqD0wLCRli": {
    "title": "Streamlining Knowledge Discovery in Scientific Literature: A Comprehensive End-to-End System for Research Artifact Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uy39I0axE8": {
    "title": "Step-level Value Preference Optimization for Mathematical Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u0GQVamcdA": {
    "title": "P-Distill: Efficient and Effective Prompt Tuning using Knowledge Distillation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pet6Wynw5y": {
    "title": "Scoring Assessment Center Exercises with LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aVx6Fo86G5": {
    "title": "ACE: A LLM-based Negotiation Coaching System",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JdVkgTAXi4": {
    "title": "KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pkTPPfBryJ": {
    "title": "Rethinking Code Refinement: Learning to Judge Code Efficiency",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=W4bEjhSPtI": {
    "title": "Uncovering the Intention Behind Equations in Mathematical Problems",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5uweK9D3dN": {
    "title": "Aspect Information Enhanced Contrastive Learning for Aspect-based Sentiment Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wVyceGU0CC": {
    "title": "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VHujO38XX5": {
    "title": "Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o7AIK7ieho": {
    "title": "Native Design Bias: Studying the Impact of English Nativeness on Language Model Performance",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s7FF2HPft0": {
    "title": "Span-Based Semantic Role Labeling with Contrastive Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qhvLPnO3Ou": {
    "title": "Self-training Large Language Models through Knowledge Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3rGbu05VwO": {
    "title": "Sharing Matters: Analysing Neurons Across Languages and Tasks in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3gqcH4Gkp0": {
    "title": "Source Attribution for Large Language Model-Generated Data",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=R5YLhou5PX": {
    "title": "TriageAgent: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pl8gvW3nJn": {
    "title": "Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XHjrLKVsrO": {
    "title": "Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M977txkdXs": {
    "title": "Representative Chain-of-Reasoning for Aspect Sentiment Quad Prediction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3RTAjD5cZB": {
    "title": "Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bLFEhvNYU8": {
    "title": "Vernacular? I Barely Know Her: Challenges with Style Control and Stereotyping",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IALYg2CH5c": {
    "title": "ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=T2VCRZTVeI": {
    "title": "People will agree what I think: Investigating LLM's False Consensus Effect",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LbQCMP2GOR": {
    "title": "Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ApSBYVzkFj": {
    "title": "Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8CLfC6V2Jb": {
    "title": "ProductAgent: Benchmarking Conversational Product Search Agent with Asking Clarification Questions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DY063SQ2Cy": {
    "title": "Limited Out-of-Context Knowledge Reasoning in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dgv6ZX2kNp": {
    "title": "Exploring the Memory Ability of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DVtTMQ7CJj": {
    "title": "DragFT: Adapting Large Language Models with Dictionary and Retrieval Augmented Fine-Tuning for Domain-specific Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qpiH4K3qcr": {
    "title": "Hijacking Large Language Models via Adversarial In-Context Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=a08QLmtYEi": {
    "title": "Learning to Extract Structured Entities Using Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PtC74QYtva": {
    "title": "Adapt Language Agent to Different Task via Automatic Mechanism Activation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=usICOeTMCQ": {
    "title": "Parameter-Efficient Instruction Tuning Code Large Language Models: A Comprehensive Study on OctoCoder Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UCE2Q4XLbN": {
    "title": "RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zsVdXouyPK": {
    "title": "Twice is Nice! Improving MEMIT for Knowledge Editing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4UDIBUIkwv": {
    "title": "Improving Language Transfer Capability of Decoder-only Architecture in Multilingual Neural Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Slu4Bvqu41": {
    "title": "Can LLM be a Personalized Judge",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7td0k31obl": {
    "title": "AnyTrans: Translate AnyText in the Image with Large Scale Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jVggyXpdeF": {
    "title": "GeNRe: a French Gender-Neutral Rewriting System Using Collective Nouns",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yr9iwPBl12": {
    "title": "S-Agent: an Agent Collaborative Framework \\Inspired by the Scientific Methodology",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9G9f1PGW7B": {
    "title": "RAEmoLLM: Retrieval Augmented LLMs for Cross-Domain Misinformation Detection Using In-Context Learning based on Emotional Information",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=50ZaXUDwb0": {
    "title": "Exploring Cultural Bias in Language Models Through Word Grouping Games",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZGsGFmUrm6": {
    "title": "ALiiCE: Evaluating Positional Fine-grained Citation Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xXN16BtjnL": {
    "title": "Exploring Intrinsic Language-specific Subspaces in Fine-tuning Multilingual Neural Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BLe8rV3VBH": {
    "title": "Safely Learning with Private Data: A Federated Learning Framework for Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5tzlr1IWRN": {
    "title": "Shiksha: A Technical Domain focused Translation Dataset and Model for Indian Languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PlldFUpUFD": {
    "title": "Quantum-Inspired Sentence Representation: Rethinking Word-Based Density Matrices",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BAxkfTaM7D": {
    "title": "SecCoder: Towards Generalizable and Robust Secure Code Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B4VnDh8nuj": {
    "title": "A framework for annotating and modelling intentions behind metaphor use",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6Mm2be80em": {
    "title": "Handling Dialog Dependencies to Reformulate Requests in Human-Agent Interaction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uckixscoGy": {
    "title": "PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B4lN0hYgXO": {
    "title": "What Kinds of Tokens Benefit from Distant Text? An Analysis on Long Context Language Modeling",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PbRlwcqaFO": {
    "title": "Is Synthetic Data Sufficient for Extractive Spoken Question Answering?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kpxjgjJBM8": {
    "title": "Automated Concept Map Extraction from Text",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZZcdkHEKD2": {
    "title": "Adaptive Retrieval-Augmented Generation for Conversational Systems",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wLo8Hnyfvs": {
    "title": "Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DuEesONIfZ": {
    "title": "DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9oZB6Nqs2q": {
    "title": "SeeD: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D8QOKkS43N": {
    "title": "Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JmNvS3Z4RF": {
    "title": "Balanced Watermark: A Simple High-Imperceptibility Watermark for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bWooXcoxCZ": {
    "title": "Zero-shot Commonsense Reasoning over Machine Imagination",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UXeNNfKWGj": {
    "title": "LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VANqfQbDZN": {
    "title": "A LLM-based Framework for Biomedical Terminology Normalization via Multi-Agent Collaboration",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V2eacwEW7H": {
    "title": "EditTrans: Speedy Edit-based Detailed Transformation of Academic Documents into Markup",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=O4rVJEcwi3": {
    "title": "MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ykwLBnTxGO": {
    "title": "Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oVly870Uac": {
    "title": "Explanations for explainability: towards an annotated corpus",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=O0p5wleHcd": {
    "title": "Random Label Forests: An Ensemble Method with Label Subsampling For Extreme Multi-Label Problems",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ui4IdCvESt": {
    "title": "In-Context Former: Lightning-fast Compressing Context for Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IASLoR2XfZ": {
    "title": "MQM-Chat: Multidimensional Quality Metrics for Chat Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8D1e3k2UDe": {
    "title": "Rational Sensibility: LLM Enhanced Empathetic Response Generation Guided by Self-presentation Theory",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NdWzQIeqe8": {
    "title": "Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CG90d084Ns": {
    "title": "ProcessChat: A Business Process Grounded Dialogue Dataset",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EntRkZ6vaP": {
    "title": "SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6v0aNxTXuG": {
    "title": "V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sZ2Q4FkVDq": {
    "title": "Detecting Machine-Generated Long-Form Content with Latent-Space Variables",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tUv6h1FOv5": {
    "title": "NAP^2: A Benchmark for Naturalness and Privacy-Preserving Text Rewriting by Learning from Human",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=whRJT6j4EM": {
    "title": "Large Language Models are Students at Various Levels: Zero-shot Question Difficulty Estimation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TXIW34StZn": {
    "title": "Text Clustering as Classification with LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b9P2cei6ZP": {
    "title": "Sequential API Function Calling Using GraphQL Schema",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3jmColxURv": {
    "title": "Grammatical Error Correction for Low-Resource Languages: The Case of Zarma",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g328uOSM2B": {
    "title": "Revisiting Supervised Contrastive Learning for Microblog Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7nIUWNewmT": {
    "title": "Event-level Knowledge Editing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=npcw2oz2yG": {
    "title": "Unveiling the Invisible: Captioning Videos with Metaphors",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sWBUs6gFXR": {
    "title": "Enhancing Cross-Prompt Transferability in Vision-Language Models through Contextual Injection of Target Tokens",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=obhgH4gzuW": {
    "title": "A Survey on In-context Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MkabNxaq7R": {
    "title": "Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3xwJjQXnKN": {
    "title": "Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph Embedding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oFsyz1OdFW": {
    "title": "Do Large Language Models Exhibit Cognitive Dissonance? Studying the Difference Between Revealed Beliefs and Stated Answers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gSpxHMoJAA": {
    "title": "Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PmI4x9roMz": {
    "title": "Collaborative Performance Prediction for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r9BWCloj54": {
    "title": "EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vpyboJVuwN": {
    "title": "MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zhQFVs9Q6L": {
    "title": "When is the consistent prediction likely to be a correct prediction?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lcqbEZkz26": {
    "title": "LongHeads: Multi-Head Attention is Secretly a Long Context Processor",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GnMHN9N0GY": {
    "title": "PDF-to-Tree: Parsing PDF Text Blocks into a Tree",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lSFEkeIrFd": {
    "title": "Beyond Instruction Following: Evaluating Rule Following of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Zxvjkk0aAI": {
    "title": "Active Instruction Tuning for Large Language Models with Reference-Free Instruction Selection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I98JkUN6es": {
    "title": "Do Pre-Trained Language Models Truly Focus on the Content They Are Expected to?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sb4cHMf8OV": {
    "title": "Large Language Models Can Better Understand Knowledge Graphs Than We Thought",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gEzRRrWDan": {
    "title": "Recurrent Alignment with Hard Attention for Hierarchical Text Rating",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Oyp66J0uW7": {
    "title": "ESAN: An Efficient Semantic Attention Network for Remote Sensing Image Change Captioning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NzVVWsokkg": {
    "title": "Calibrating the Confidence of Large Language Models by Eliciting Fidelity",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RAeYWAPpty": {
    "title": "Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4FdgKIYnJk": {
    "title": "Source Code Data Augmentation for Deep Learning: A Survey",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jaZXnb8yeF": {
    "title": "LLM4Decompile: Decompiling Binary Code with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XG9Nrgf6Pf": {
    "title": "Improving Proactive Dialogue Strategy Planning with Interactive Environment and Goal-oriented Reward",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EHlAE1bnxq": {
    "title": "Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Hpk9n92O6I": {
    "title": "Hidden Vulnerabilities: The Knowledge Degradation in Fine-Tuned Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3AEEkGPiM1": {
    "title": "Leveraging Language Models for Summarizing Mental State Examinations: A Comprehensive Evaluation and Dataset Release",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VgRaJ78ytQ": {
    "title": "Difficulty-Based Training Strategy with MLLMs for Multimodal Sarcasm Explanation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lGlmaoUfW8": {
    "title": "Does Reinforcement Learning from Human Feedback Framework Still Work for Task-Oriented Dialogue Systems?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=47Jkgzr9HO": {
    "title": "Probing zero shot VLMs for hate meme detection: Opportunities, risks and interpretations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zozQq4UWN3": {
    "title": "TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yuBVl3SRrU": {
    "title": "How Do Llamas Process Multilingual Text? A Latent Exploration through Patchscopes",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aw5grkur0F": {
    "title": "Knowledge Graph Enhanced Large Language Model Editing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=thRA7Tlg89": {
    "title": "Efficient Overshadowed Entity Disambiguation by Mitigating Shortcut Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H63IXdjesp": {
    "title": "R^2AG: Incorporating Retrieval Information into Retrieval Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k7xjAa2X22": {
    "title": "Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pjITMVzArC": {
    "title": "Intermediate Distillation: Data-Efficient Distillation from Black-Box LLMs for Information Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jyd1wQ5Mhh": {
    "title": "TopViewRS: Vision-Language Models as Top-View Spatial Reasoners",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LHfAyDyHcE": {
    "title": "Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cGV6c2lXEj": {
    "title": "Self-Evolved Diverse Data Sampling for Efficient Instruction Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VZSRlvGyZt": {
    "title": "Towards Measuring and Modeling \"Culture\" in LLMs: A Survey",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EYXS82MS9s": {
    "title": "LoraMap: Harnessing the Power of LoRA Connections",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZIu3i6bV5N": {
    "title": "Automatic sentence segmentation of clinical record narratives in real-world data",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5w0ghjY2Ct": {
    "title": "Can Deception Detection Go Deeper? Dataset, Evaluation, and Benchmark for Deception Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5q5JbJqh5d": {
    "title": "Mixed Distillation Helps Smaller Language Models Reason Better",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X2LNm1SCjs": {
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RqlRBySXu0": {
    "title": "Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iWXp19Qh6s": {
    "title": "Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aI9MESYatf": {
    "title": "LongAlign: A Recipe for Long Context Alignment of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YeuRO2UdvZ": {
    "title": "DA 3 : A Distribution-Aware Adversarial Attack against Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CGx4w1YOrH": {
    "title": "Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gLcpCzxoiM": {
    "title": "The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EduhNteyC9": {
    "title": "DECOR: Improving Coherence in L2 English Writing with a Novel Benchmark for Incoherence Detection, Reasoning, and Rewriting",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Sm71zywX66": {
    "title": "Understanding Performance of Long-Document Ranking Models through Comprehensive Evaluation and Leaderboarding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NM26AdIWdY": {
    "title": "In-Memory Learning: A Declarative Learning Framework for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EF0bkisSQX": {
    "title": "Comparative Study of Named Entity Recognition Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q8SncUWGSZ": {
    "title": "Evaluating Computational Metrics for Predicting N400 Amplitude during Reading Comprehension",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ml6a8y161S": {
    "title": "Multilingual evaluation of image captioning: How far can we get with CLIP models?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1EPBE4ynAy": {
    "title": "LINKAGE: Listwise Ranking among Varied-Quality References for Non-Factoid QA Evaluation via LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sVBRqSO9Ad": {
    "title": "A Cognitive-grounded Computational Model for Emotional Alignment During Conversations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dw3rqkELFQ": {
    "title": "Literacy is g -eneral for a Small Language: Evaluating GLLMs in Danish",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0oUnTvaPgG": {
    "title": "Knowledge Editing of Large Language Models in the Wild",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BqooRAZN3T": {
    "title": "Amphista: Accelerate LLM Inference with Bi-directional Multiple Drafting Heads in a Non-autoregressive Style",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XpWOKaxfCE": {
    "title": "Detecting Machine-Generated Text: Not just \"AI vs Humans\" and Explainability is Complicated",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QRoSeqTJLa": {
    "title": "RA2FD: Distilling Faithfulness into Efficient Dialogue Systems",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Z3GKTf6h6t": {
    "title": "Is Child-Directed Speech Effective Training Data for Language Models?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FbpCKiIvmC": {
    "title": "Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SRATnNcHDK": {
    "title": "Token-based Decision Criteria Are Suboptimal in In-context Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UBTcvaGl21": {
    "title": "FactGenius: Combining Zero-Shot Prompting and Fuzzy Relation Mining to Improve Fact Verification with Knowledge Graphs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DqSBGhmQXb": {
    "title": "Correct after Answer: Enhancing Multi-Span Question Answering with Post-Processing Method",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8ywPAiYbQb": {
    "title": "Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dNecVbFZVX": {
    "title": "How Well Do Multi-modal LLMs Interpret CT Scans? An Auto-Evaluation Framework for Analyses",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Rfn0euSgbX": {
    "title": "Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WzG1rQVkPP": {
    "title": "Orchestrating Human and AI Feedback: PCUI-DPO for Human-Aligned LLM Responses",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BNp3NLZbTc": {
    "title": "LLM-Assisted Content Conditional Debiasing for Fair Text Embedding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8AaByYdbod": {
    "title": "Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=10KaRLc3zD": {
    "title": "Visual Expression for Referring Expression Segmentation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U4jKMqdW9N": {
    "title": "Entity Retrieval for Answering Entity-Centric Questions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=labT01N7sb": {
    "title": "MultiCAT: Multimodal Communication Annotations for Teams",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nS839JhspA": {
    "title": "TOOLVERIFIER: Generalization to New Tools via Self-Verification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rGAi3RUlgl": {
    "title": "Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mtao3Gj7Mh": {
    "title": "Evaluating Knowledge-based Cross-lingual Inconsistency in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bo1XPDF2ob": {
    "title": "SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DHKEQCBP9f": {
    "title": "Video-LLaVA: Learning United Visual Representation by Alignment Before Projection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VAXwQqkp5e": {
    "title": "MalayMMLU: A Multitask Benchmark for the Low-Resource Malay Language",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2OB76SHUGU": {
    "title": "Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s7OZoZCOJd": {
    "title": "BASES: Large-scale Web Search User Simulation with Large Language Model based Agents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IRJZADcLM0": {
    "title": "A Dataset for Evaluating LLM-based Evaluation Functions for Research Question Extraction Task",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oYQ8la668U": {
    "title": "Towards Situated Bias Evaluations in LLM Alignment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lbP0VhiK94": {
    "title": "Vision Language Model-based Caption Evaluation Method Leveraging Visual Context Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GJYZPcVnGe": {
    "title": "Refiner : Restructure Retrieved Content Efficiently to Advance Question-Answering Capabilities",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QYiZAYbDtE": {
    "title": "Dynamic Planning for LLM-based Graphical User Interface Automation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FOP5TCrZ4S": {
    "title": "MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2ScFDlBwgn": {
    "title": "Beneath the tip of the melting iceberg: uncovering deep narrative structures in climate change news",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U5kVVgcSif": {
    "title": "CharacterQA: A Corpus for Multimodal Character Conversational Movie Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NyMYyFRq6j": {
    "title": "Iterative Utility Judgment Framework via LLMs Inspired by Relevance in Philosophy",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oHJ2Kh6hkR": {
    "title": "Quest: Query-centric Data Synthesis Approach for Long-context Scaling of Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dVmoLDLHL6": {
    "title": "Towards Efficient Large Language Models for Science: A Review",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EBGBMf1PkF": {
    "title": "Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f3jw8jn039": {
    "title": "Learning to Write Rationally: How Information Is Distributed in Non-native Speakers' Essays",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7yXmHHAQZp": {
    "title": "Memory Sharing for Large Language Model based Agents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ec7guJsZpQ": {
    "title": "Probing API Name Knowledge in Pre-trained Code Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IeofzBIx62": {
    "title": "Reusing Transferable Weight Increments for Low-resource Style Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qizgdzpc8m": {
    "title": "A Survey on Detection of LLMs-Generated Content",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6qPs9Y75iT": {
    "title": "VITS-Based Data Augmentation for Improved ASR Performance and Domain Adaptation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ilFPS7BOpe": {
    "title": "MLKV: Multi-Layer Key-Value Heads for Memory Efficient Transformer Decoding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NWXn9iPZ7r": {
    "title": "Knowledge-Centric Templatic Views of Documents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LXKPEUUdkL": {
    "title": "Bridging Local Details and Global Context in Text-Attributed Graphs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hFoLMcsCml": {
    "title": "First Heuristic Then Rational: Dynamic Use of Heuristics in Language Model Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mbUHHpmdm4": {
    "title": "Multiple Sources are Better Than One: Incorporating External Knowledge in Low-Resource Glossing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Glu9bfQxN6": {
    "title": "Scaling Sentence Embeddings with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fOMfNIF334": {
    "title": "MOYU: Massive Over-activation Yielded Uplifts in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MQ78Fhhqs3": {
    "title": "QGEval: Benchmarking Multi-dimensional Evaluation for Question Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8Fr2uyKwFD": {
    "title": "Enhancing Advanced Visual Reasoning Ability of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UPLoeVTPGj": {
    "title": "Revealing the Parallel Multilingual Learning within Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gRg1JeLte2": {
    "title": "Implicit Visual Knowledge Enhanced Training-free Image Captioning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sNYOeqiBTH": {
    "title": "From RAG to Riches: Retrieval Interlaced with Sequence Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G4vlza2ZaC": {
    "title": "Exploring Annotation-free Image Captioning with Retrieval-augmented Pseudo Sentence Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2ZsYbEWdXo": {
    "title": "Style Transfer with Multi-iteration Preference Optimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AUvmWdE9hs": {
    "title": "Rethink to Check: Mitigating Confirmation Bias for End-to-End Multimodal Fact-Checking",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BA2XusS6GP": {
    "title": "Detecting Subtle Differences between Human and Model Languages Using Spectrum of Relative Likelihood",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hufOctxUan": {
    "title": "A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cJGT47VFhM": {
    "title": "BPO: Supercharging Online Preference Learning by Adhering to the Proximity of Behavior LLM",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=70yPFGRERi": {
    "title": "Database-Augmented Query Representation for Information Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=REEohcwnOJ": {
    "title": "Utilizing Everything in History: Modeling Relation Inference Path and Entity Structure for Temporal Knowledge Graph Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NgWSakw55z": {
    "title": "Evaluating n -Gram Novelty of Language Models Using Rusty-DAWG",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SKDJBY6NvD": {
    "title": "TuringQ: Benchmarking AI Comprehension in Theory of Computation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r1QCjU78j9": {
    "title": "Factual Dialogue Summarization via Learning from Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FrjPJxP0lO": {
    "title": "LEGO: Language Model Building Blocks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NZPDERBlMU": {
    "title": "When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nos1wF3ekA": {
    "title": "Are Large Language Models Capable of Generating Human-Level Narratives?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eM0CGTmWlM": {
    "title": "Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dmrEeQRfsF": {
    "title": "Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Np69McMZKo": {
    "title": "HyQE: Ranking Contexts with Hypothetical Query Embeddings",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZcDSae49pR": {
    "title": "PediaBench: A Comprehensive Chinese Pediatric Dataset for Benchmarking Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jEBT890By0": {
    "title": "MDCR: A Dataset for Multi-Document Conditional Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d2HtyiNZfz": {
    "title": "Ask-before-Plan: Proactive Language Agents for Real-World Planning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k32hz3fO7P": {
    "title": "Can Generic LLMs Help Analyze Child-Adult Interactions Involving Children with Autism in Clinical Observation?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u5ggNGb6U5": {
    "title": "Reference-based Metrics Disprove Themselves in Question Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D2F4Kz6Tmr": {
    "title": "ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to Identify Likely Toxic Prompts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eDRSI97wbs": {
    "title": "Iterative Introspection based Refinement: Boosting Multi-Document Scientific Summarization with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JlgyYVBaqN": {
    "title": "HMamba: Towards Multifaceted Computer-assisted Pronunciation Training Leveraging Hierarchical Selective State Space Model and Decoupled Cross-entropy Loss",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GlFzqCNXiG": {
    "title": "FastLexRank: Efficient Lexical Ranking for Structuring Social Media Posts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kS41AMEm5l": {
    "title": "ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w0ZtUXRARU": {
    "title": "PuzzleGPT: Emulating Human Puzzle-Solving Ability for Time and Location Prediction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Zd2cMHHoGe": {
    "title": "Is Compound Aspect-Based Sentiment Analysis Addressed by ChatGPT?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gn8Ex8hMnV": {
    "title": "Identifying and Resolving Ambiguous Intents in Coding Instructions using Discourse Frameworks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=j5HU5PKnJk": {
    "title": "LawInstruct: A Resource for Studying Language Model Adaptation to the Legal Domain",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EeZUl6RVBF": {
    "title": "ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n94TkRInd3": {
    "title": "Human-AI Collaborative Essay Scoring: A Dual-Process Framework with LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YwYm5lq6DA": {
    "title": "Exploring Group and Symmetry Principles in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5o9QLeoLY2": {
    "title": "Detecting Temporal Ambiguity in Questions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cTte4olXJz": {
    "title": "Contextual Moral Value Alignment Through Context-Based Aggregation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LE1w3S7YNE": {
    "title": "Exploring Forgetting in Large Language Model Pre-Training",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=usqKwDx9lA": {
    "title": "Predicting Compact Phrasal Rewrites with Large Language Models forAutomatic Speech Recognition Post Editing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mlXlLyFFvs": {
    "title": "Gold Panning in Vocabulary: An Adaptive Method for Vocabulary Expansion of Domain-Specific LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ELcDNqOooA": {
    "title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f8z18xDC1Z": {
    "title": "Robust Hate Speech Detection Without Predefined Spurious Words",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eubxEnxOfp": {
    "title": "My LLM might Mimic AAE - But When Should it?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dpGK4B0mLR": {
    "title": "Enhancing Incremental Summarization with Structured Representations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BuU8aUGior": {
    "title": "Paraphrase Identification Datasets: Usage Survey and Generalization Patterns",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=soKmlpSh32": {
    "title": "AAPM: Large Language Model Agent-based Asset Pricing Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=STzJudM9cp": {
    "title": "Improving Minimum Bayes Risk Decoding with Multi-Prompt",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cKFNUTzU3I": {
    "title": "Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TtZHqD4lHD": {
    "title": "Beyond Turing Test: Can GPT-4 Sway Experts' Decisions?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2RLqASVf5x": {
    "title": "Locate&Edit: Energy-based Text Editing for Efficient, Flexible, and Faithful Controlled Text Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IvN1xqMe9X": {
    "title": "Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZwfaHjBmPP": {
    "title": "Can Textual Unlearning Solve Cross-Modality Safety Alignment?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6OZb1bG0di": {
    "title": "PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1PwOSwgVdg": {
    "title": "CluMo: Cluster-based Modality Fusion Prompt for Continual Learning in Visual Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4riSN1vVfc": {
    "title": "HiGenQA: Exploring Hint Generation Approaches for Open Domain Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9xrPOEDwk3": {
    "title": "Open-world Multi-label Text Classification with Extremely Weak Supervision",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hkc719CMqd": {
    "title": "Are Human Conversations Special? A Large Language Model Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G3EuSXKA4n": {
    "title": "A Simple yet Effective Training-free Prompt-free Approach to Chinese Spelling Correction Based on Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f12k6JxhQ9": {
    "title": "DiffuseDef: Improved Robustness to Adversarial Attacks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6IJXQ5Iobe": {
    "title": "Goal-Oriented Dialogue Grounding over Structured Lists",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2mUNv2hCRV": {
    "title": "Evaluating Human Alignment and Model Faithfulness of LLM Rationale",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lsjhpI3oi7": {
    "title": "Understanding \"Democratization\" in NLP and ML Research",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wOQahax16Q": {
    "title": "The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WbQLQDQF71": {
    "title": "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TwHDAvQvhn": {
    "title": "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PeaBxTtvCG": {
    "title": "Does Vec2Text Pose a New Corpus Poisoning Threat?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZORfB3FK7V": {
    "title": "Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6fxBvEwIzX": {
    "title": "Beyond Sentiment: Evaluating Gendered Language Using Zero-Shot Text Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tT61qT0bzF": {
    "title": "JobFair: A Framework for Benchmarking Gender Hiring Bias in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yQ6Jk7muDr": {
    "title": "Using Similarity to Evaluate Factual Consistency in Summaries",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EKXcrktzuk": {
    "title": "Language Fusion for Parameter-Efficient Cross-lingual Transfer",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oxQHbJN7iZ": {
    "title": "CovScore: Evaluation of Multi-Document Abstractive Title Set Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vYNjVgpixS": {
    "title": "If I understand the context, I will act accordingly: Combining Complementary Information with Generative Visual Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=riTHLxuZWR": {
    "title": "Fine-grained Controllable Text Generation through In-context Learning with Feedback",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RUwW2Up9PK": {
    "title": "Learning from Natural Language Explanations for Generalizable Entity Matching",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q2eC52ql9O": {
    "title": "Outcome-Constrained Large Language Models for Countering Hate Speech",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=13FvsnmPve": {
    "title": "Analyzing Key Neurons in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IQaynoIdrT": {
    "title": "GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XIa0ZHgHeJ": {
    "title": "Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bHCbpRKIBX": {
    "title": "Split and Merge: Aligning Position Biases in LLM-based Evaluators",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WmEb3dKg1t": {
    "title": "Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Wg7WJPKhJU": {
    "title": "Cascading Large Language Models for Salient Event Graph Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=O68Cpu6KHE": {
    "title": "CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r7GkDVkruw": {
    "title": "ASRank: Zero-Shot Re-Ranking with Answer Scent for Document Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VAzkX8j7pd": {
    "title": "LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6v8ehjE0Jn": {
    "title": "NativQA: Multilingual Culturally-Aligned Natural Query for LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XuazKRDuAS": {
    "title": "MOSEL: Inference Serving Using Dynamic Modality Selection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rZ5IcL2i4d": {
    "title": "Learning Peer Support Interactions via Bi-LSTM Graph Neural Networks for Suicide Risk Prediction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cv8VnWNjmS": {
    "title": "RepMatch: Quantifying Cross-Instance Similarities in Representation Space",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gliHPIEo87": {
    "title": "Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E5RaPdrGz7": {
    "title": "RETHiNK: Simulate Human Decision-making via Multi-LLM Debates in Cognitive Reframing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ReH45Ha5Em": {
    "title": "Latent Concept-based Explanation of NLP Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jCXIj8HPWX": {
    "title": "An Efficient Rehearsal Scheme for Catastrophic Forgetting Mitigation during Multi-stage Fine-tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q78OATOGjv": {
    "title": "Evaluating LLMs for Detecting Climate Misinformation: How Aligned are LLMs with Expert Classification of False or Misleading Claims about Climate Change on Social Media?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vTQeBcMhvq": {
    "title": "Evaluating Transparency of Machine Generated Fact Checking Explanations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I7KZoCV50T": {
    "title": "Dx-LLM: Two-layer Retrieval-Augmented Multilingual Diagnosis System",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gsxK1vWUR6": {
    "title": "Generating and Evaluating Synthetic Data for Privacy Preservation in High-Stakes Domains",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WVaWlamdYt": {
    "title": "On the token distance modeling ability of higher RoPE attention dimension",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GbXKiJyt1w": {
    "title": "MoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ONmOTVvY8Y": {
    "title": "Faithfulness and Content Selection in Long-Input Multi-Document Summarisation of U.S. Civil Rights Litigation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xcpHu030aY": {
    "title": "Empowering Multi-step Reasoning across Languages via Program-Aided Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PtkLLWQeRe": {
    "title": "Better Call SAUL: Fluent and Consistent Language Model Editing with Generation Regularization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=obzgclkKYQ": {
    "title": "Consistent Autoformalization for Constructing Mathematical Libraries",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3UnUxUYR6A": {
    "title": "Exploring Human-AI Perception Alignment in Sensory Experiences: Do LLMs Understand Textile Hand?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ddmw1vaOd1": {
    "title": "Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AJTtDe96tS": {
    "title": "xTower: A Multilingual LLM for Explaining and Correcting Translation Errors",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qoK5NRj9Ae": {
    "title": "Fact or Fiction? Exploring Diverse Approaches to Fact Verification with Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TC7nGHC1rb": {
    "title": "Generative evaluation for contextual machine translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6AjeDjlg3d": {
    "title": "Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r6ZV4ufZXO": {
    "title": "Do Language Differences Lead to Ethical Bias in LLMs? Exploring Dilemmas with the MSQAD and Statistical Hypothesis Tests",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lL3I8I70fM": {
    "title": "Socratic Human Feedback (SoHF): Understanding Socratic Feedback Based Steering Strategies Used by Expert Programmers for Code-generation with LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6WtzwfinXv": {
    "title": "Reflective Human-Machine Co-adaptation for Enhanced Text-to-Image Generation Dialogue System",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jhEgpbkK5D": {
    "title": "TF-Attack: Transferable and Fast Adversarial Attacks on Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FedLpkdOjf": {
    "title": "CMMaTH: A Chinese Multi-modal Math Skill Evaluation Benchmark for Foundation Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AFzzIOwQ6B": {
    "title": "Shortened LLaMA: Depth Pruning for Large Language Models with Comparison of Retraining Methods",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5LEGB38tqn": {
    "title": "Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6nVnX7fpQa": {
    "title": "Enhancing Data Privacy in Large Language Models through Private Association Editing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hE7DgtEia2": {
    "title": "aCAT: Automatically Choosing Anchor Tokens in prompt for Natural Language Understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qg0E3gI8lD": {
    "title": "Aligning Large Language Models with Diverse Political Viewpoints",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GlZpVV2KgN": {
    "title": "DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5pk7CflVsb": {
    "title": "Are Large Language Models More Empathetic than Humans?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H4faeJKJAo": {
    "title": "Can LLMs provide Recommendations to support Policy Making and Agency Operations?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TOIIhbQmUL": {
    "title": "Learning to Rewrite: Generalized LLM-Generated Text Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YRCAvXNP0v": {
    "title": "Neuron Specialization: Leveraging Intrinsic Task Modularity for Multilingual Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=67tSTNPecz": {
    "title": "Code-Optimise: Self-Generated Preference Data for Correctness and Efficiency",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U1m6MpRSVj": {
    "title": "In-Dialogues We Learn\": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iINAtDdgqW": {
    "title": "Quantifying the Capabilities of LLMs across Scale and Precision",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C3MbT9xzxj": {
    "title": "Counting-Stars: A Multi-evidence, Position-aware, and Scalable Benchmark for Evaluating Long-Context Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1g7NgXbIDO": {
    "title": "SeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IKKMRm2zwh": {
    "title": "MTEB-French: Resources for French Sentence Embedding Evaluation and Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zJCAR3nWz2": {
    "title": "Leveraging Web-Crawled Data for High-Quality Fine-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=syAo91pgm1": {
    "title": "Wavelet and Optical Features Sparkling NLP",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GOFMsrWoxh": {
    "title": "Self-MoE: Self Mixture of Experts in between decoder layers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vANmnQOqTf": {
    "title": "PsyPlay: Personality-Infused Role-Playing Conversational Agents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kLpqgBip9x": {
    "title": "Evaluating Transformers for OCR Post-Correction in Early Modern Dutch Comedies and Farces",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B1Yn4VnETJ": {
    "title": "MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dt0WRSK6cL": {
    "title": "Mitigating Hallucinations of Large Language Models in Medical Domain via Contrastive Decoding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3bcFeZRxVY": {
    "title": "Knowledge Introspection: A Self-reflection Method for Reliable and Helpful Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5nT79lhAsl": {
    "title": "On the Importance of Nuanced Taxonomies for LLM-Based Understanding of Harmful Events: A Case Study on Antisemitism",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oUMKv7Nlav": {
    "title": "GEGA: Graph Convolutional Networks and Evidence Retrieval Guided Attention for Enhanced Document-level Relation Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZSEioFIrzX": {
    "title": "Enhancing Intent Understanding for Ambiguous Prompt: A Human-Machine Co-Adaption Strategy",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d7KsesYb6E": {
    "title": "GAT-Edge: Graph Attention Neural Network with Adjacent Edge Features",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VEAxwRogmP": {
    "title": "Defending Against Social Engineering Attacks in the Age of LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TwJ2q0W0OH": {
    "title": "BERTrend: Neural Topic Modeling for Emerging Trends Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=izSknHt9Vn": {
    "title": "Irrelevant Alternatives Bias Large Language Model Hiring Decisions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SoPeTS9GVn": {
    "title": "PDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FmUS9qVnut": {
    "title": "Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vCscszwihl": {
    "title": "Think-in-Memory: Metacognition-Augmented LLM with Long-Term Memory",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8jXsWBMAYH": {
    "title": "Exploiting Reversible Semantic Parsing and Text Generation for Error Correction with Pre-trained LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CoSkl4iUQr": {
    "title": "PG-Story: Taxonomy, Dataset, and Evaluation for Ensuring Child-Safe Content for Story Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DciVFiTW31": {
    "title": "Social Bias Probing: Fairness Benchmarking for Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5pQ6NVzNfK": {
    "title": "Can LLMs Learn Macroeconomic Narratives from Social Media?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LBiqQJH0cr": {
    "title": "Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pGAaIC7wYt": {
    "title": "Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sfyL4tX6bc": {
    "title": "Referenceless evaluation of machine translation models by ranking performance in Romaninan to English translate-train settings",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bKvGjVZNUk": {
    "title": "Applying Intrinsic Debiasing on Downstream Tasks: Challenges and Considerations for Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=srJFNkOUVt": {
    "title": "CPO-SQL: Boosting Small LLMs for Text-to-SQL via Efficient In-Context Learning and Preference Optimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NaFtZu3c5f": {
    "title": "A Multilingual Exploration of Jailbreak Attacks in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ve74z0s17e": {
    "title": "Evaluating Short-Term Temporal Fluctuations of Social Biases in Social Media Data and Masked Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r8cbhMMORU": {
    "title": "ExcluIR: Exclusionary Neural Information Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gKHIT7BuRD": {
    "title": "DocCHA: Towards LLM-Augmented Interactive Online diagnosis System",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YSCNip4RDB": {
    "title": "Leveraging In-Context Learning for Political Bias Testing of LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BqjdRZhe5K": {
    "title": "Datasets for Multilingual Answer Sentence Selection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VzVEKmElJT": {
    "title": "Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UOxaepuMFy": {
    "title": "Measuring and Benchmarking Large Language Models' Capabilities to Generate Persuasive Language",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rXtGiySLBP": {
    "title": "CTL-Prompt: Contrastive Topic-Length Prompt Learning for Dialogue Summarization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vRHUZt3f07": {
    "title": "On the Robustness of Editing Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uXgGbezEoJ": {
    "title": "RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7LJsNxtnCJ": {
    "title": "MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1esqcgwDzI": {
    "title": "Using LLMs to simulate students' responses to exam questions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cvgxTh4WHi": {
    "title": "IAO prompting: Forcing Large Language Models to Show their Reasoning through an Input-Action-Output Template",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RV4s4JI6lu": {
    "title": "Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NuCvSx6t6V": {
    "title": "Multi-Target Cross-Lingual Summarization: a novel task and a language-neutral approach",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oXMTMJY7Li": {
    "title": "Imitation Game is Not Optimal: Alleviating Autoregressive Bias in Non-Autoregressive Transformers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FaatIWMJ0r": {
    "title": "Harnessing Instruction-Tuned Large Language Model for Guiding End-to-End Speech Recognition",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kCKirFfXdW": {
    "title": "Transformer-CTP: Current Token Prediction Using Cross-Attention of Queries with Current Position Information",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ke9x4M7Aw2": {
    "title": "DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=efHQ3cTXWs": {
    "title": "Precise Length Control for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PHAVxHKRZc": {
    "title": "Predicting generalization performance with correctness discriminators",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pBHePq1B6e": {
    "title": "Chain of LoRA: Efficient Fine-tuning of Language Models via Residual Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rWzECppYr4": {
    "title": "Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jouW22PVUo": {
    "title": "AlignSum: Data Pyramid Hierarchical Fine-tuning for Aligning with Human Summarization Preference",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MpoeoSmpiK": {
    "title": "How Effective are State Space Models for Machine Translation?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Mrc2ilbeUw": {
    "title": "A Split-and-Privatize Framework for Large Language Model Fine-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G7tDvnp4hV": {
    "title": "Evaluating Automatic Metrics with Incremental Machine Translation Systems",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wlZdXyB5tI": {
    "title": "Dialog2Flow: Pre-training Action-Driven Soft Contrastive Learning Embeddings for Automatic Dialog Flow Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PrrIxDCML5": {
    "title": "Do Language Models Understand Human Needs on Text Summarization?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xaSLpHVQPH": {
    "title": "Retrieval-Augmented Text-Only Training for Image Captioning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ab89SCgRad": {
    "title": "Learning Dynamic Multi-attribute Interest for Personalized Product Search",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yaevypXikZ": {
    "title": "On Leakage of Code Generation Evaluation Datasets",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lj3uI1XUQl": {
    "title": "Scope-enhanced Compositional Semantic Parsing for DRT",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cs5PeRshZ1": {
    "title": "AlanaVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AUK1LfrOfX": {
    "title": "Raker: A Relation-aware Knowledge Reasoning Model for Inductive Relation Prediction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vRkKEWpfsZ": {
    "title": "Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=33HI0UVKtJ": {
    "title": "Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=T61vy7JML8": {
    "title": "ABSEval: An Agent-based Framework for Script Evaluation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SMMUERMSlW": {
    "title": "Interpreting and Auditing Biases between Bengali Cultural Dialects in Large Language Models with Evaluation and Mitigation Strategies",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H1PreUjdgE": {
    "title": "Beyond \"Using Their Own Words\": Abstractivity Characterization in Summarization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RIDEuxMvhj": {
    "title": "Impact of LLM on Reinforcement Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NV2jzRDy6u": {
    "title": "STARD: A Chinese Statute Retrieval Dataset Derived from Real-life Queries by Non-professionals",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M588ckNRIT": {
    "title": "More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8xBMLAOZxq": {
    "title": "Obliviate: Neutralizing Task-agnostic Backdoors within the Parameter-efficient Fine-tuning Paradigm",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jqsVAg2vhe": {
    "title": "Large Language Models Can Not Perform Well in Understanding and Manipulating Natural Language at Both Character and Word Levels?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nrHm7qGxc5": {
    "title": "Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V3rHjGUZll": {
    "title": "Semantic Ontology for Paraphrase Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5kbAvWJVtv": {
    "title": "Evaluating Object Hallucination in LVLMs: Can They Still See Removed Objects?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7SoHEUxKMr": {
    "title": "D2A2: Enhancing LLM Knowledge Distillation Efficiency and Performance with Difficulty-Aware and Adaptive Distillation Framework",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WAcRc6xNeu": {
    "title": "RoleCraft introduces a framework aimed at enhancing role-playing experiences in large language models by focusing on authentic and non-celebrity characters and emotional depth",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qi80RWAEvg": {
    "title": "Efficient Aspect-Based Summarization with Small Language Models: A Use-Case on Climate Change Reports",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=29wc2HNSau": {
    "title": "DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=laASr36eUG": {
    "title": "Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TLgsPw0Kay": {
    "title": "Weak Reward Model Transforms Generative Models into Robust Causal Event Extraction Systems",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qJ6vPHLGWK": {
    "title": "From Evidence to Belief: A Bayesian Epistemology Approach to Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XHybQ6JNLd": {
    "title": "A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KmHs3XZwJw": {
    "title": "Noise, Novels, Numbers. A Framework for Detecting and Categorizing Noise in Danish and Norwegian Literature",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aumwGAptJW": {
    "title": "More Bang for your Context: Virtual Documents for Question Answering over Long Documents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LQfxWLdBBI": {
    "title": "LowREm: A Repository of Word Embeddings for 87 Low-Resource Languages Enhanced with Multilingual Graph Knowledge",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3MaDUX0SXc": {
    "title": "PFME: A Modular Approach for Fine-grained Hallucination Detection and Editing of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DCpapNkSPo": {
    "title": "Unified Active Retrieval for Retrieval Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qerJguRqHn": {
    "title": "A Novel Computational Modeling Foundation for Automatic Coherence Assessment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3CNNb3wtvT": {
    "title": "Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hOOFKKDzVB": {
    "title": "Regulation vs. Performance: Interpretable Language Models Help Quantify a Trade-Off",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DHV2xqsxgw": {
    "title": "Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uVbEkOnocR": {
    "title": "Analyzing Key Factors Influencing Emotion Prediction Performance of VLLMs in Conversational Contexts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eekAOta5Vx": {
    "title": "SignCLIP: Connecting Text and Sign Language by Contrastive Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lnsHDSuppb": {
    "title": "Underneath the Numbers: Quantitative and Qualitative Gender Fairness in LLMs for Depression Prediction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8myqhHFvo7": {
    "title": "Pcc-tuning: Breaking the Contrastive Learning Ceiling in Semantic Textual Similarity",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gp1UcGxe2E": {
    "title": "SELF: Self-Evolution with Language Feedback",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hzyRchjVAW": {
    "title": "Leveraging LLMs for Formal Grammar Generation in Programming Contest Testing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GwdQcEvDvJ": {
    "title": "Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CusvHZy1Rl": {
    "title": "Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Bx2QhrerpE": {
    "title": "PSC: Extending Context Window of Large Language Models via Phase Shift Calibration",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mOPCBf4ncP": {
    "title": "Quantifying Multilingual Performance of Large Language Models Across Languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fzDxIosyWu": {
    "title": "Uni-ETOD: User-Need-Driven Chain of Thought Framework for Fully End-to-end Task-oriented Dialogue System",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o3SAmsK48q": {
    "title": "Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tiJcC6JEwQ": {
    "title": "Breaking the Script Barrier in Multilingual Pre-Trained Language Models with Transliteration-Based Post-Training Alignment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fiQucCdsUe": {
    "title": "ICON: Improving Inter-Report Consistency in Radiology Report Generation via Lesion-aware Mixup Augmentation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ciPpzGFrfW": {
    "title": "MedThink: Inducing Medical Large-scale Visual Languange Models to Hallucinate Less by Thinking More",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eH4LZbCNGP": {
    "title": "Explaining Mixtures of Sources in News Articles",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ooolIMhWik": {
    "title": "A Two-dimensional Zero-shot Dialogue State Tracking Evaluation Method using GPT-4",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yoVy1YCU7w": {
    "title": "Retrieval-Augmented Generation Inspired Long Document Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pyUoHWYDUR": {
    "title": "CAST: Sparse Fine-Tuning with Counterfactual Data Augmentation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wfO5v4Lw4V": {
    "title": "MAC-SQL: A Multi-Agent Collaborative Framework for Text-to-SQL",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Gz7KSEIg5g": {
    "title": "Language Versatilists vs. Specialists: An Empirical Revisiting on Multilingual Transfer Ability",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9EhsUgBH9T": {
    "title": "Harnessing Dimension-level Contrastive Learning and Information Compensation Mechanism for Sentence Embedding Enhancement",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rNWRnVGfBC": {
    "title": "Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g0ywZtoLXu": {
    "title": "Watch Every Step! LLM Agent Learning via Iterative Step-level Process Refinement",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xw65urw8WG": {
    "title": "BlockPruner: Fine-grained Pruning for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GXCX9Wshwv": {
    "title": "PaCoST: Paired Confidence Significance Testing for Benchmark Contamination Detection in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gpjAnHSlRf": {
    "title": "Automated Compliance Checking for Chinese Privacy Policy: A New Task and Dataset",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jlMEPzyWIm": {
    "title": "Emosical: An Emotion Annotated Musical Theatre Dataset",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PBjQ9tOJhz": {
    "title": "In-Context Learning with Iterative Demonstration Selection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2ebvGUqmiz": {
    "title": "Stable Knowledge Editing in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r2wFLsujJQ": {
    "title": "Book2QA: A Framework for Integrating LLMs to Generate High-quality QA Data from Textbooks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k0JpEnpxT9": {
    "title": "Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qMv9xh8CqJ": {
    "title": "Unlocking Varied Perspectives: A Persona-Based Multi-Agent Framework with Debate-Driven Text Planning for Argument Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FXLzg6Ch4W": {
    "title": "Comparison of Cross-encoder and Bi-encoder Approaches for Arabic question answering task",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2SwOTnpH04": {
    "title": "Mixture-of-Skills: Learning to Optimize Data Usage for Fine-Tuning Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rDbFH8P82r": {
    "title": "Plug-and-Play Grounding of Reasoning in Multimodal Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ORSrbuU16k": {
    "title": "Emotionally Aligned Responses through Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bMU3OhBpci": {
    "title": "TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bgbXQRZpKG": {
    "title": "Interleaved Vision-and-Language Generation via Generative Vokens",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nMiRVN1KhG": {
    "title": "Dreaming with ChatGPT: Unraveling the Challenges of LLMs Dream Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EwXpapJLO5": {
    "title": "Adapting Large Language Models for Document-Level Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=c3VFBB2zga": {
    "title": "NeuroTrialNER: An Annotated Corpus for Neurological Diseases and Therapies in Clinical Trial Registries",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=asQAaWqNjs": {
    "title": "Virtual Personas for Language Models via an Anthology of Backstories",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WuH6XWNbeJ": {
    "title": "A good pun is its own reword\": Can Large Language Models Understand Puns?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FWoXTaEtIj": {
    "title": "Self-evolving Agents with reflective and memory-augmented abilities",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KmhVC7FKXN": {
    "title": "Rethinking Word Similarity: Semantic Similarity through Classification Confusion",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3hgsBxuGfQ": {
    "title": "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rUDrnBi6kH": {
    "title": "LanguaShrink:Reducing Token Overhead with Psycholinguistics",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OAUGyrzOEM": {
    "title": "Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uaE6jlngr4": {
    "title": "An Empirical Study on Robustness of Language Models via Decoupling Representation and Classifier",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U4N7erk6Bf": {
    "title": "LLMs Are Prone to Fallacies in Causal Inference",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eVEAO0MHP4": {
    "title": "Improving Factual Consistency of News Summarization by Contrastive Preference Optimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1gNwBkOYsQ": {
    "title": "DemoRank: Selecting Effective Demonstrations for Large Language Models in Ranking Task",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8xiyaVa25h": {
    "title": "Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qOmQ6AruXm": {
    "title": "SYNTHEMPATHY: A Scalable Empathy Corpus Generated Using LLMs Without Any Crowdsourcing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nAwG5AhMio": {
    "title": "From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H2dvPXvfDy": {
    "title": "Stark: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Hb8OFtXOcT": {
    "title": "M5 -- A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5hWKVerHWj": {
    "title": "DiPT: Enhancing LLM Reasoning through Diversified Perspective-Taking",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X3r0wOuuI3": {
    "title": "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Hx2XnVfK55": {
    "title": "Optimizing Language Model's Reasoning Abilities with Weak Supervision",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8aFlHbNALV": {
    "title": "Re-ReST: Reflection-Reinforced Self-Training for Language Agents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yDGJBh17WQ": {
    "title": "Zero and Few-Shot Learning Techniques for Cross-lingual Classification Tasks on Arabic and Code-Switched Data",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FpG7ye7Gvg": {
    "title": "Contextual Metric Meta-Evaluation by Measuring Local Metric Accuracy",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4BpEfStZBD": {
    "title": "Devil's Advocate: Anticipatory Reflection for LLM Agents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WKOZROjPqP": {
    "title": "MetaIE: Distilling a Meta Model from LLM for All Kinds of Information Extraction Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yodDLcGqXv": {
    "title": "Analyzing Context Contributions in LLM-based Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lrYnqFLCYr": {
    "title": "Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3mU0QS3G44": {
    "title": "LlamaTurk: Adapting Open-Source Generative Large Language Models for Low-Resource Language",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CwQ7ajvO9i": {
    "title": "Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jnpCEDhgY6": {
    "title": "All Context Aware Reservoir Transformer",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=108NglI3z0": {
    "title": "FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=36LzMpUNFg": {
    "title": "Understanding and Improving Limitations of Multilingual AI Text Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=witGLrCMjz": {
    "title": "M2QA: Multi-domain Multilingual Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H42VbGGYvY": {
    "title": "CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VFKhPYVzBm": {
    "title": "Model-based Preference Optimization in Abstractive Summarization without Human Feedback",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xeMHWnfo7R": {
    "title": "Community-Cross-Instruct: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zyHy5ELF2d": {
    "title": "Contrastive Perplexity for Controlled Generation: An Application in LLM Alignment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fhcvqpLdU7": {
    "title": "Entangled Relations: Leveraging NLI and Meta-analysis to Enhance Biomedical Relation Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C28tkD1ogp": {
    "title": "ViFactCheck: A New Benchmark Dataset and Methods for Multi-domain News Fact-Checking in Vietnamese",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FZihRKWnze": {
    "title": "Efficient Fine-Tuning Approaches on HuBERT for Speech Emotion Recognition on Multiple Labels",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9dkTWqRy5S": {
    "title": "A Simple Baseline for Zero-shot Visual Question Answering via Synthetic Data Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MObsTppWtK": {
    "title": "FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese Food Culture",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=roMLbP6cGl": {
    "title": "Semantic Change Characterization with LLMs using Rhetorics",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6mI6tcvP7u": {
    "title": "Break the Chain: Large Language Models Can be Shortcut Reasoners",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LkLpG2mnpz": {
    "title": "MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ovFbnJWJmM": {
    "title": "Swap or Skip? Challenging Step Type Identification in Instructional Manuals",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qQbFpi1XzX": {
    "title": "BLSP-Emo: Towards Empathetic Large Speech-Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NPU7VzgU6N": {
    "title": "Exploring Spatial Understanding Capability in Large Language Models: Proficiency in Layout Generation sans Visual Perception",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3EmwxoK54w": {
    "title": "Self-Evolution Fine-Tuning for Policy Optimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CnnsDrNJ8s": {
    "title": "From Language to Action: Employing Foundation Models in Autonomous Robots",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xryoosZiX6": {
    "title": "Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WJ09vSBYBR": {
    "title": "Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LbegsBNyAs": {
    "title": "ITER: Iterative Transformer-based Entity Recognition and Relation Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y6EQiLYGVT": {
    "title": "1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6YjJklAAQ9": {
    "title": "Towards Event-intensive Long Video Understanding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nxUL97tGWT": {
    "title": "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IjVIorgJJQ": {
    "title": "Are Large Language Models Good Classifiers? A Study on Edit Intent Classification in Scientific Document Revisions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qZSETTmoh4": {
    "title": "Are there identifiable structural parts in the sentence embedding whole?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vkgc46fBBA": {
    "title": "Exploring the Impact of Occupational Personas on Domain-Specific QA",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HjPBlQ6fGu": {
    "title": "Script-Agnostic Language Identification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4xDpUOKDP5": {
    "title": "How does a text preprocessing pipeline affect ontology matching?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BAVawpQw7Q": {
    "title": "Make Large Language Model a Better Ranker",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VLzLj7dU9b": {
    "title": "AudioAgent: Enhancing Task Performance through Modality-Driven Prompt Optimization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SVlkUHepTy": {
    "title": "Claim-Guided Textual Backdoor Attack for Practical Applications",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3OC7RHTkGa": {
    "title": "TEVLA: Text-oriented Enhancement for Vision-Language Alignment in Infomation Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZSkzlh1BSG": {
    "title": "RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PRkzXIy5ew": {
    "title": "Efficient Active Learning with Adapters",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UHAFkcfNdL": {
    "title": "HiRA: Parameter-Efficient Hadamard High-Rank Adaptation for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3cigyj14Dx": {
    "title": "Continual Test-time Adaptation for End-to-end Speech Recognition on Noisy Speech",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=S0McroVcou": {
    "title": "Imagination Augmented Generation: Learning to Imagine Richer Context for Question Answering over Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I0gypxeQte": {
    "title": "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o1bTN9apZU": {
    "title": "Evaluating LLMs Adversarially with Word Guessing Game",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Bl5ZIQlqxo": {
    "title": "One-Vs-Rest Neural Network English Grapheme Segmentation: A Linguistic Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=swyMHo2daP": {
    "title": "Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CRcpdEluzC": {
    "title": "Cross-Subject Data Splitting for Brain-to-Text Decoding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fNy3FcdkX8": {
    "title": "Short Video is not only Video: Multimodal Unified Social Hypergraph Contrastive Enhancement for Fake News Video Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hzQf1lIVpI": {
    "title": "ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sdPeC6Oohf": {
    "title": "Data Augmentation for Text-based Person Retrieval Using Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CytotQoqNs": {
    "title": "Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zRZdBI7ORQ": {
    "title": "TransMI: A Framework to Create Strong Baselines from Multilingual Pretrained Language Models for Transliterated Data",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dq9pIKiZYR": {
    "title": "Enhancing Emotion Recognition in Incomplete Data: A Novel Cross-Modal Alignment, Reconstruction, and Refinement Framework",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SnQOZc2az1": {
    "title": "Salience-aware Dialogue Summarization via Parallel Original-Extracted Streams",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zPKjzqfXhM": {
    "title": "PIRLS Category-specific Question Generation for Reading Comprehension",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MFsR2r0Ejq": {
    "title": "VE-KD: Vocabulary-Expansion Knowledge-Distillation for Training Smaller Domain-Specific Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=My6R2q5mWz": {
    "title": "Late Inception Prompt Tuning: Improving Prompt Tuning with Inception Reparameterization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lIbEoTudsZ": {
    "title": "Self-Prompt Tuning: Enable Autonomous Role-Playing in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Z4Z3pqrLMw": {
    "title": "Dynamic Tuning and Multi-Task Learning Based Model for Multimodal Sentiment Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qGewKcofxZ": {
    "title": "Eliciting In-Context Learning in Vision-Language Models for Videos Through Curated Data Distributional Properties",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U3SmiXUxAq": {
    "title": "Smaug: A Chat Model with Agent-Generated Data for Conversational Recommendations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=irYBP6Rx57": {
    "title": "Zero-Shot Chain-of-Thought Reasoning Guided by Swarm Intelligence Algorithms in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U15vRrs5lw": {
    "title": "EVER: Mitigating Hallucination in Large Language Models through Generation-Time Verification and Rectification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WpdSAan8Tx": {
    "title": "Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining for Clinical LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wgKhZvPojL": {
    "title": "Enhancing Byzantine-Resistant Aggregations with Client Embedding",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Sy2Z0pSGLi": {
    "title": "Supplemental Enhancement of Action Segments: A Retrieval Optimization for Large Language Models in the Legal Domain",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oEd61a1EpR": {
    "title": "TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DuWc8GEqnB": {
    "title": "Identification of depression and PTSD among Twitter users using pre-trained language model",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B0dAudLu9K": {
    "title": "Integrating Spoken and Signed Languages for Inclusive and Modality-Independent Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rct6Kqy6Pb": {
    "title": "MoSLD: A Extremely Parameter-Efficient Mixture-of-Shared LoRAs for Multi-Task Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uPZkAUa2ng": {
    "title": "Large Language Models as a Normalizer for Transliteration and Dialectal Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wnZ5gINYfO": {
    "title": "Entropy Guided Extrapolative Decoding to Improve Factuality in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zdDwzNKOtx": {
    "title": "MICL: Improving In-Context Learning through Multiple-Label Words in Demonstration",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bHx9ahTdYO": {
    "title": "RevOrder: A Novel Equation Format for Arithmetic Operations in Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rYmiEvm3f0": {
    "title": "An Analysis and Mitigation of the Reversal Curse",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wG0Xf7DJ2H": {
    "title": "Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=16Fvyqty0u": {
    "title": "Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=o7GvuFzM0n": {
    "title": "Mitigating Biases to Embracing Diversity: A Comprehensive Annotation Benchmark for Toxic Language",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RFCuycKKcv": {
    "title": "Orchestrating Heterogeneous Architecture for Fast Inference of Mixture-of-Experts Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=c0VhbnktWV": {
    "title": "Cross-cultural Inspiration Detection and Analysis in Real and LLM-generated Social Media Data",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WmxAerGaoi": {
    "title": "First-Step Advantage: Importance of Starting Right in Multi-Step Math Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZDq0AKvpT5": {
    "title": "Misinformation detection with learning from spatial-temporal propagation features and information content on Twitter",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qzaH3k7zUz": {
    "title": "A Recipe of Parallel Corpora Exploitation for Multilingual Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JBWO7EClx4": {
    "title": "Beyond Accuracy Optimization: Computer Vision Losses for Large Language Model Fine-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8wI82giPJZ": {
    "title": "XAMPLER: Learning to Retrieve Cross-Lingual In-Context Examples",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Oax3R1Qmrh": {
    "title": "Evaluating D-MERIT of Partial-annotation on Information Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Uft84Ru4rD": {
    "title": "MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel Reviews",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w0vkg53vsV": {
    "title": "MixGR : Enhancing Retriever Generalization for Scientific Domain through Complementary Granularity",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bxSFccJHUO": {
    "title": "MATE: Meet At The Embedding - Connecting Images with Long Texts",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ULYnBYISqy": {
    "title": "Extrinsic Evaluation of Cultural Competence in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CLVEal3sUI": {
    "title": "Recent Trends in Linear Text Segmentation: A Survey",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vnq8vVuLPR": {
    "title": "CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2iY6CsW5Yp": {
    "title": "Fine-grained Hallucination Detection and Mitigation in Long-form Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HK4sgNcXUp": {
    "title": "EMS-SD: Efficient Multi-sample Speculative Decoding for Accelerating Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lPoMt9Pwo5": {
    "title": "Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yb5YhwKWJ4": {
    "title": "Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XupJ7lhMLA": {
    "title": "Investigating the translation capabilities of Large Language Models trained on parallel data only",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iIMmumK7bz": {
    "title": "Measuring Progress in Second Language Pronunciation Learning using Automated Assessment Metrics",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=58UxkFKQvN": {
    "title": "Comparative Analysis of Acoustic Perception Models in Simulation of Teacher-Learner Interaction in L2 Pronunciation Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mPwBL4NkW0": {
    "title": "RWKV-CLIP: A Robust Vision-Language Representation Learner",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3lpjXd4vMz": {
    "title": "AI-Assisted Human Evaluation of Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dWdpnlnAum": {
    "title": "CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lyCG5ZfQPO": {
    "title": "Leveraging Explicit Reasoning for Inference Integration in Commonsense-Augmented Dialogue Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ya1c3iGogR": {
    "title": "Bi-DCA: Bi-directional Dual Contrastive Adapting for Alleviating Hallucination in Multimodal Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0Ark9UioAe": {
    "title": "Revisiting the Othello World Model Hypothesis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gNZ3tMPqx2": {
    "title": "African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H9Weg7vLqE": {
    "title": "Evaluating AI-driven Psychotherapy: Insights from Large Language Models and Human Expert Comparisons",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WhGYuOGU2G": {
    "title": "VHASR: A Multimodal Speech Recognition System With Vision Hotwords",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LJqrfGM1f4": {
    "title": "Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tjGbJmdRM7": {
    "title": "AdvisorQA: Towards Helpful and Harmless Advice-seeking Question Answering with Collective Intelligence",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5uy1NxgTwj": {
    "title": "Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating Video-based Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e9TrT7LGnK": {
    "title": "Can Automatic Metrics Assess High-Quality Translations?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WRXiff8Vw3": {
    "title": "By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IHLwnwSzhl": {
    "title": "Attribute or Abstain: Large Language Models as Long Document Assistants",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6LvWYaSzK0": {
    "title": "Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JskM2kZANS": {
    "title": "Leave the Bias in Bias: Mitigating the Label Noise Effects in Continual Visual Instruction Fine-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0AcjNkohUl": {
    "title": "Multi-modal Knowledge Graphs: Evolution, Methods, and Opportunities",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jsE0gw4zub": {
    "title": "InferAct: Inferring Safe Actions for LLMs-Based Agents Through Preemptive Evaluation and Human Feedback",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xC8KTvexaJ": {
    "title": "Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=950A7ddNc9": {
    "title": "Unveiling the Misuse Potential of Base Large Language Models via In-Context Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8K6BkGtMB3": {
    "title": "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EvI9K24ttS": {
    "title": "CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4jLDSb8BMs": {
    "title": "Fine Irony: Training Transformers with Ordinal Likelihood Labels",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vsRU4v83B0": {
    "title": "SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DgZWp1VqPN": {
    "title": "Word Alignment as Preference for Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Sy4brfxJvO": {
    "title": "PE: A Poincare Explanation Method for Fast Text Hierarchy Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vSx6PPm3wG": {
    "title": "A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns Well with The Key Tokens",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1gclnHeyN8": {
    "title": "CW3NE:A Genre-oriented Corpus for Nested Named Entity Recognition in Chinese Web Novels",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gzBXGu5wHf": {
    "title": "Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qofNwM4E0w": {
    "title": "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JJi9Zns9c6": {
    "title": "Self-VEQA Agent Self-Verification Enhanced Question Answering Agent",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9SkMEG7I6V": {
    "title": "Dynamic Entity Alignment with Attribute Integration",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VQ2aOIolZh": {
    "title": "A Survey of Large Language Models Attribution",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZtVl0jCbnL": {
    "title": "VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NhMGDXTDwH": {
    "title": "ShareLoRA: Parameter Efficient and Robust Large Language Model Fine-tuning via Shared Low-Rank Adaptation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=y6Ene4t5Tx": {
    "title": "Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gEMLMMG0m9": {
    "title": "Eliminating Positional Bias in LLMs via Attention Weight Averaging",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=17a5MFji8L": {
    "title": "Making Task-Oriented Dialogue Datasets More Natural by Synthetically Generating Indirect User Requests",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HccN11PPRB": {
    "title": "ManiTweet: A New Benchmark for Identifying Manipulation of News on Social Media",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PPh5KtX8If": {
    "title": "Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EDCOgqo4dK": {
    "title": "AUTOHALLUSION: Automatic Generation of Hallucination Benchmarks for Vision-Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G8PyRFzTEt": {
    "title": "Assessing the Role of Imagery in Multimodal Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TmsQjrlMjH": {
    "title": "Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=s1dOBTeFDM": {
    "title": "ThatiAR: Subjectivity Detection in Arabic News Sentences",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fcJZkcfA8E": {
    "title": "DRE: Generating Recommendation Explanations by Aligning Large Language Models at Data-level",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZkZ2erwY0w": {
    "title": "PS-Radar: A High-Precision Geoparsing Solution for Real-Time Location Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rCk4ARcI1k": {
    "title": "Dual Modalities of Text: Visual and Textual Generative Pre-Training",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xotWo7JKM9": {
    "title": "DVD: Dynamic Contrastive Decoding for Knowledge Amplification in Multi-Document Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WKqBCqgeBk": {
    "title": "Improving Minimum Bayes Risk Decoding with Weight Uncertainty",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qjdoPUVmnG": {
    "title": "Cross-Domain Classification of Education Talk-Turns",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kpEvU0MD2x": {
    "title": "Input Conditioned Graph Generation for Language Agents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=T4ZysPbfW4": {
    "title": "R&R: A Role-playing Model Enhanced by Retrieving and Reflecting",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DYqbooTruk": {
    "title": "MobileQuant: Mobile-friendly Quantization for On-device Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7wKlIsJHLa": {
    "title": "Beyond Hate Speech: NLP's Challenges and Opportunities in Uncovering Dehumanizing Language",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VHMKPhzEwr": {
    "title": "An Automatic and Cost-Efficient Peer-Review Framework for Language Generation Evaluation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RBkEqV9yME": {
    "title": "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bO26RZUUOu": {
    "title": "Retrieved Sequence Augmentation for Protein Representation Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HgYIajh9fN": {
    "title": "Reconfidencing LLMs from the Grouping Loss Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E6aEhSlwHw": {
    "title": "Humanity in AI: Detecting the Personality of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ATk82ymOUv": {
    "title": "CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oGvgcmJDww": {
    "title": "A Road for LLM SQL Bug-Fixing Enhancing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dj6WcAjMH7": {
    "title": "Can we employ LLM to meta-evaluate LLM-based evaluators? A Preliminary Study",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DrE7KAzwyU": {
    "title": "Enhancing Zero-Shot Relation Triplet Extraction through Staged Interaction with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=a5En3TZwii": {
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MJQNbYYt1d": {
    "title": "DRaMI: Dialogue Relation-aware Multi-task with In-context Learning for Emotion Recognition in Multi-party Conversations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u0nVUnFhfM": {
    "title": "Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KMUUgLfJst": {
    "title": "Noise-powered Multi-modal Knowledge Graph Representation Framework",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=38K5miAAbL": {
    "title": "How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U0myZcZ30d": {
    "title": "SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b9bHwbxILh": {
    "title": "Unsupervised Morphological Tree Tokenizer",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HCkNgkS5H8": {
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F4B2dGGgVm": {
    "title": "DRMR: An Immersing Oriented Role-Playing Framework with Duplex Relationship Modeling",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wEOwKX6j4f": {
    "title": "High-Dimension Human Value Representation in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pVqoJiEKue": {
    "title": "Necessary and Sufficient Watermark for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3I8bhxI6H8": {
    "title": "Robust Utility-Preserving Text Anonymization Based on Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jcxniCckdf": {
    "title": "Quantifying the Gap Between Machine Translation and Native Language in Training for Multimodal, Multilingual Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MThh08klxQ": {
    "title": "Bidirectional Transformer Representations of (Spanish) Ambiguous Words in Context: A New Lexical Resource and Empirical Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xPvbFLG1fV": {
    "title": "Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=noWl1ifTk6": {
    "title": "Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine Translation and Language Modeling",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3E4Gv5kQS4": {
    "title": "Show Less, Instruct More: Enriching Prompts with Definitions and Guidelines for Zero-Shot NER",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LhiA7mjznI": {
    "title": "The effects of distance on NPI illusive effects in BERT",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6FQBTdgSXZ": {
    "title": "Personas as a Way to Model Truthfulness in Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KqPPLy9RXc": {
    "title": "External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=btfCvWz5vO": {
    "title": "Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4v4F8N7nvJ": {
    "title": "Contribution of Linguistic Typology to Universal Dependency Parsing: An Empirical Investigation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5zZBGBO1ET": {
    "title": "Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BF7r9c7HRJ": {
    "title": "The Fall of ROME: Understanding the Collapse of LLMs in Model Editing",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kWHsiOMhdb": {
    "title": "Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CyNw3aWuRl": {
    "title": "A Radiology-Aware Model-Based Evaluation Metric for Report Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KyXTjn6s7p": {
    "title": "Answer When Needed, Forget When Not: Language Models Pretend to Forget via In-Context Knowledge Unlearning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bJkx9uvzcg": {
    "title": "Eliminating Language Bias in Visual Question Answering with Potential Causality Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wWiPr1syai": {
    "title": "DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Oiep7TST71": {
    "title": "Mitigating Language Biases In Visual Question Answering Through The Forgotten Attention Algorithm",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OGut4W9k0p": {
    "title": "PropTest: Automatic Property Testing for Improved Visual Programming",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mornWjoqQy": {
    "title": "Is Self-knowledge and Action Consistent or Not: Investigating Large Language Model's Personality",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6pDG2o41m6": {
    "title": "TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hbPCNXh05e": {
    "title": "A Study of Implicit Ranking Unfairness in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AHS2ZfTv4w": {
    "title": "Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gAcieeAmB6": {
    "title": "From Answers to Questions: A Study on Backward Reasoning in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QvOAQehQEZ": {
    "title": "COOL: Comprehensive Knowledge Enhanced Prompt Learning for Domain Adaptive Few-shot Fake News Detection",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=L4ZuKt44U8": {
    "title": "Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2zpjKw7vvG": {
    "title": "A Survey of Keyphrase Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aUmtVlaPRD": {
    "title": "AgentReview: Exploring Peer Review Dynamics with LLM Agents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y851NvWAi9": {
    "title": "FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BBDOc0TB7i": {
    "title": "Can ChatGPT understand the implicit meaning of language? Discussion of ChatGPT's ability to generate metaphorical samples",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=galuhSN7am": {
    "title": "FIHA: Fine-grained Hallucinations Evaluations in Large Vision Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E1USRd80QC": {
    "title": "A Simple Angle-based Approach for Contrastive Learning of Unsupervised Sentence Representation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Trn5nysipv": {
    "title": "ArMeme: Propagandistic Content in Arabic Memes",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xg2qWLEpJ7": {
    "title": "FGAIF: Aligning Large Vision-Language Models with Fine-grained AI Feedback",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mMB3iPeN6d": {
    "title": "FaithScore: Fine-grained Evaluations of Hallucinations in Large Vision-Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cw3c4TcGLA": {
    "title": "Partisan Opinions, but Common Language: Similarities in Topic Use by Appellate Judges",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xUxU1YUKbz": {
    "title": "BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5UKVBsEOWa": {
    "title": "Language Models Know the Value of Numbers",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zpjZl6wSQO": {
    "title": "Red Teaming Language Models for Processing Contradictory Dialogues",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FM6xTzjGtA": {
    "title": "NutePrune: Efficient Progressive Pruning with Numerous Teachers for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bvKg3wNxkY": {
    "title": "Language Model Can Do Knowledge Tracing: Simple but Effective Method to Integrate Language Model and Knowledge Tracing Task",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=erbUEhQbtl": {
    "title": "InstructERC: Reforming Emotion Recognition in Conversation with a Multi-task Retrieval-based LLMs Framework",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yGmTaA8aWu": {
    "title": "Humans or LLMs as the Judge? A Study on Judgement Bias",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5DcsbWHY0O": {
    "title": "CoT-Planner: Chain-of-Thoughts as the Content Planner for Few-shot Table-to-Text Generation Reduces the Hallucinations from LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1V9iGRN8hk": {
    "title": "Novel-WD: Exploring acquisition of Novel World Knowledge in LLMs Using Prefix-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Jlaa645kLo": {
    "title": "BAPO: Base-Anchored Preference Optimization for Personalized Alignment in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aJVwhHwH3G": {
    "title": "FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs Only",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4y4EBySL3E": {
    "title": "On Unsupervised Comparisons of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ymjVhUuZFU": {
    "title": "GRASS: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sa20JogM3C": {
    "title": "Enhanced Hallucination Detection in Neural Machine Translation through Simple Detector Aggregation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RZIWfoI5dj": {
    "title": "Scenarios and Approaches for Situated Natural Language Explanations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5Cj5OXD4kK": {
    "title": "Towards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4ko0TkYZuu": {
    "title": "What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PHgyifqXoT": {
    "title": "Pre-trained Semantic Interaction based Inductive Graph Neural Networks for Text Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P8k99b1Nus": {
    "title": "Advancing Semantic Textual Similarity Modeling: A Regression Framework with Translated ReLU and Smooth K2 Loss",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UvDdkmg14w": {
    "title": "A Thorough Examination of Decoding Methods in the Era of LLMs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MpXSpER30w": {
    "title": "EM-LoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Nw7pRpYvNH": {
    "title": "Towards Uncovering How Large Language Models Work: An Interpretability Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AyqtlIFwrx": {
    "title": "Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jaszo5zZM8": {
    "title": "Contextual Compression in Retrieval-Augmented Generation for Large Language Models: A Survey",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wzYBwxGBSI": {
    "title": "S3D: A Simple and Cost-Effective Self-Speculative Decoding Scheme for Low-Memory GPUs",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zBh9qLz1f6": {
    "title": "Formal Semantic Geometry over Transformer-based Variational AutoEncoder",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5FdJBSMLo3": {
    "title": "LLMs Cannot (Yet) Match the Specificity and Simplicity of Online Communities in Long Form Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mSgN1QQUBr": {
    "title": "Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=i2TboPArOr": {
    "title": "UFO: a Unified and Flexible Framework for Evaluating Factuality of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7roOZvDii6": {
    "title": "Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gFrVsxAEO4": {
    "title": "Scaling Large-Language-Model-based Multi-Agent Collaboration",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nNdq8GG9Zs": {
    "title": "Semantic Steganography: A Framework for Robust and High-Capacity Information Hiding using Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HOwjJyqRai": {
    "title": "Komodo: A Linguistic Expedition into Indonesia's Regional Languages",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YwKcOll596": {
    "title": "A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jDMvwI9IEh": {
    "title": "Knowledge Graphs for Multi-modal Learning: Survey and Perspective",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KvTH7eUxsY": {
    "title": "Preview Tools before Using: Enhancing Tool Documentation with Multi-Tool Exploration",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jmLKEtZsxN": {
    "title": "Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6G4V3COOvt": {
    "title": "Integrating Emotional and Linguistic Models for Ethical Compliance in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=umVwLUlhcQ": {
    "title": "SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AH1DvHxvzt": {
    "title": "Large Language Models Can Be Contextual Privacy Protection Learners",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oSETxofkqf": {
    "title": "UniTabNet: Bridging Vision and Language Models for Enhanced Table Structure Recognition",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fLbF0lwrYr": {
    "title": "Evolution without Large Models: Training Language Model with Task Principles",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=iY9LArskAF": {
    "title": "KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tO7XlLK8dN": {
    "title": "Nash CoT: Multi-Path Inference with Preference Equilibrium",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K1vNb5SH2o": {
    "title": "Measuring and Modifying the Readability of English Texts with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Hh3e3n0oiv": {
    "title": "Evaluating Creativity in Large Language Models through Creative Problem-Solving: A New Dataset and Benchmark",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Boa0GnqTqh": {
    "title": "UNICORN: A Unified Causal Video-Oriented Language-Modeling Framework for Temporal Video-Language Tasks",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qAXUZFU6Q9": {
    "title": "Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JT5TRr6obB": {
    "title": "Pushing The Limit of LLM Capacity for Text Classification",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DYgpiWI2fp": {
    "title": "Learning to Use Tools via Cooperative and Interactive Agents",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GCxvf6qxeW": {
    "title": "OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WDZ9kRZxNb": {
    "title": "Making AI Think Lean: Sparse Concept Bottleneck Models for Interpretable Decisions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pY82iRwlOD": {
    "title": "Implicit and Indirect: Computational Identification of Ambiguous Conversational Actions in Asynchronous Crisis-Related Conversations",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZCCydvipRt": {
    "title": "Generating Long-form Story Using Dynamic Hierarchical Outlining with Memory-Enhancement",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RDjYDGvtcx": {
    "title": "Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving Vision-Linguistic Compositionality",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BlKQRqqSvf": {
    "title": "Fewer is More: Boosting Math Reasoning with Reinforced Context Pruning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bCTqtcEySo": {
    "title": "Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xNa0lDqdTl": {
    "title": "UP4LS: User Profile Constructed by Multiple Attributes for Enhancing Linguistic Steganalysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D1rx4J6AEe": {
    "title": "Automated Tone Transcription and Clustering with Tone2Vec",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VvrZGNHg1e": {
    "title": "Text Fluoroscopy: Detecting LLM-Generated Text through Intrinsic Features",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CN9EUevAqC": {
    "title": "Bridging the Writing Manner Gap in Visual Instruction Tuning by Creating LLM-aligned Instructions",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LfhhTLTpE4": {
    "title": "Cross-Domain Audio Deepfake Detection: Dataset and Analysis",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7aCcfbp6N5": {
    "title": "Creative and Context-Aware Translation of East Asian Idioms with GPT-4",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=W4CLqPq1xF": {
    "title": "Entropy Variation and Information Competence: Enhancing Predictive Accuracy of Collaborative Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ui7aRCFuuu": {
    "title": "How do Large Language Models Learn In-Context? Query and Key Matrices of In-Context Heads are Two Towers for Metric Learning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HaaPCU2LvE": {
    "title": "Neuron-Level Knowledge Attribution in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Oc8Cteojey": {
    "title": "Code Less, Align More: Efficient LLM Fine-tuning for Code Generation with Data Pruning",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JRe8v0lUgU": {
    "title": "Impact of Stickers on Multimodal Chat Sentiment Analysis and Intent Recognition: A New Task, Dataset and Baseline",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3lgVTTzVSM": {
    "title": "BMIL: Self and Cooperative Bias Mitigation in-the-loop in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=m2JUBJuKQD": {
    "title": "Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented Document-Grounded Dialogues",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rb380J8pcE": {
    "title": "Cultural Value Differences of LLMs: Prompt, Language, and Model Size",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NtJJASK4ey": {
    "title": "StableSynthNet: Disentangled HyperNetworks for Enhanced On-device Multi-modal Model Generalization",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YPlIAcmfmR": {
    "title": "Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons",
    "volume": "review",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SYEi6o4D1F": {
    "title": "CogLoop: Bridging Planning and Control for Robot Manipulation by Embodied Feedback",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QUmZIx3boG": {
    "title": "Insights into using temporal coordinated behaviour to explore connections between social media posts and influence",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7YEsiDoHdt": {
    "title": "Transfer-Prompting: Enhancing Language Models with Objective-Transferable Prompting",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AqAF5MI0Lw": {
    "title": "Better Mathematical Reasoners by Bootstrapping from LLM Answers",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1SNTgwOsyg": {
    "title": "Active Reading Agent through Reading Controller",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=A7eAWirXMD": {
    "title": "WEPO: Web Element Preference Optimization for Enhanced Autonomous Web Navigation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9upwOJYJAr": {
    "title": "HalLoc: Token-level Localization of Hallucinations in Large Vision Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9AQBVqeJ8K": {
    "title": "LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs from the Programming Language",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Hyng2buyYm": {
    "title": "Gender-specific Machine Translation with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4d5ljoYgII": {
    "title": "HyPost: A Dataset for Hypothesis-based Post-Processing of ASR Transcripts using LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EnvMeHoyrj": {
    "title": "Large Language Model Can Continue Evolving From Mistakes",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K1gkAIWkwu": {
    "title": "An Effective Data Refinement Strategy Using Annotation Agreements and Model Predictions for Implicit Hate Speech Detection",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=syuip9BKM8": {
    "title": "Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3whj1NCfB5": {
    "title": "CORM: Coarse-to-fine-grained Offloading for SMoE LLM Inference on Consumer-grade GPU",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l1YOKJeavf": {
    "title": "Benchmarking Large Language Models in E-commerce Leveraging Knowledge Graph",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qH8bArdz9R": {
    "title": "FACTOID: FACtual enTailment fOr hallucInation Detection",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xANK99Zro7": {
    "title": "Are LLMs Rational Investors?\\\\A Study on Detecting and Reducing the Financial Bias in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CHcUtUkt4u": {
    "title": "This Suits You the Best\": Query Focused Product Comparison Summary",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1FFOFvYItY": {
    "title": "Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Q7AzOSiatW": {
    "title": "Save It All: Enabling Full Parameter Tuning for Federated Large Language Models via Bicycle Black Gradient Descent",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7vP8ybn81d": {
    "title": "GCFCE: The Evaluation of the Security Vulnerability-Fixing Capabilities of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=quwlR4TI0q": {
    "title": "PrivTextBench: a Unified Benchmark for Text-to-Text Privatization",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1jcPbFBHKZ": {
    "title": "i-SRT: Aligning Large Multimodal Models for Videos by Iterative Self-Retrospective Judgment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8C3Iy2D1Rz": {
    "title": "SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qmZWGs0lQO": {
    "title": "Neuro-Symbolic Commonsense Reasoning: A First-Order Logic and Sub-Symbolic Embeddings Framework",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DVxsnjiXYQ": {
    "title": "Benchmarking Semantic Sensitive Information in LLMs Outputs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yjut3ol0Zb": {
    "title": "SymbolicThought: Integrating Language Models and Symbolic Reasoning for Consistent and Interpretable Human Relationship Understanding",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BdypeVSMNt": {
    "title": "Survival of the Safest: Multi-Objective Pareto Optimization of AI Prompts through Evolutionary Methods",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Nz2CpFM9PH": {
    "title": "Thought-Path Contrastive Learning via Premise-Oriented Data Augmentation for Logical Reading Comprehension",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zcFbcwrx7O": {
    "title": "Mitigating Hallucinations in Large Language Model Agent Communication with Uncertainty Estimations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zY9ZqspbW5": {
    "title": "MindShift: Analyzing Language Models' Reactions to Psychological Prompts",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mGocca4jea": {
    "title": "Annotated Dataset of Human Rights Violations in the Russia-Ukraine Conflict: A Comparative Analysis of Human and ChatGPT Annotations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zE6okqoT0N": {
    "title": "Synergistic Multi-Agent Framework with Trajectory Learning for Knowledge-Intensive Tasks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3IMINODsts": {
    "title": "Make Every Penny Count: Difficulty-Adaptive Self-Consistency for Cost-Efficient Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dITC0cxUFG": {
    "title": "Jailbreak Paradox: The Achilles' Heel of LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b2HTD5Q3YK": {
    "title": "DiaCBT: A Fine-Grained Dialogue Benchmark with Cognitive Behavioral Therapy for Psychological Counseling",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MpH54T6uSM": {
    "title": "Cognitive Map for language models: Optimal Planning via Verbal Representation of World Model",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lBPk1LEq0b": {
    "title": "Reward Steering with Evolutionary Heuristics for Decoding-time Alignment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YnNNcteDmT": {
    "title": "A Generative Framework for Continual Named Entity Recognition",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EvF6gyqN0Z": {
    "title": "Persona Dynamics : Unveiling the Impact of Persona Traits on Agents in Text-Based Games",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1T99z4CsMi": {
    "title": "Kunpeng: A Large Language Model, Instruction Data and Evaluation Benchmark for Web Novel Translation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ugKvWZHe42": {
    "title": "On the Decision-Making Abilities in Role-Playing using Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TTQmSmYbwh": {
    "title": "Towards Vision Enhancing LLMs: Empowering Multimodal Knowledge Storage and Sharing in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NZ8VsHx1ls": {
    "title": "MINGLE: Multi-level Integration via Language Guided Learning\\\\for Comprehensive Visual Understanding",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2FeactcFrW": {
    "title": "From Unknown to Known: An AI Coaching Problem in Open-World Environments",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Sme3gqbIeq": {
    "title": "You Comprehended the Whole Paper: Academic Reviews Enhance LLM Long-Context Capabilities",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0JhjzHfC7a": {
    "title": "SentiXRL: An advanced large language Model Framework for Multilingual Fine-Grained Emotion Classification in Complex Text Environment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MpMZujJXgs": {
    "title": "Could Large Language Models (LLMs) serve as an alternative to manual evaluation for Detoxification?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6GTC05KX9L": {
    "title": "Psy-Insight: Mental Health Oriented Interpretable Multi-turn Bilingual Counseling Dataset for Large Language Model Finetuning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BBVAk7PXjB": {
    "title": "Language Agents for Detecting Implicit Stereotypes in Text-to-image Models at Scale",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xiv0VhiEdv": {
    "title": "Enhancing Fine-Grained Image Classifications via Cascaded Vision Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UXDcqflTMx": {
    "title": "Text-Vision Interacted and Auxiliary Sample Generation for Document Layout Analysis",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pxTWKPVg2x": {
    "title": "ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Cr7pVMsj9o": {
    "title": "DynDST: A Dynamic Dialogue State Tracking Dataset for Assessing the Conversational Adaptability of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uwsbtGMM9j": {
    "title": "How to Classify Extremely Long Texts: Age Rating Classification of Movie Scripts Using RAG Pipeline",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u0vN077uKa": {
    "title": "Assessing the Robustness of Retrieval-Augmented Generation Systems in K-12 Educational Question Answering with Knowledge Discrepancies",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QHi4PFXh9a": {
    "title": "CASK: Causal Knowledge Representations for Question-Answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XjCuwJm49E": {
    "title": "Gradient-Mask Tuning Elevates the Upper Limits of LLM Performance",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p5yIVJ5lj2": {
    "title": "Human-Interpretable Adversarial Prompt Attack on Large Language Models with Situational Context",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wXiG0ojb6W": {
    "title": "CodeChameleon: Personalized Encryption Framework for Jailbreaking Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vcQLCwm22f": {
    "title": "Towards a Robust Multimodal Framework for Hate Detection: A Study on Video vs. Image-based Content",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=u4xfPr409C": {
    "title": "Not All Bias Bad: Balancing Rational Deviations and Cognitive Biases in Large Language Models Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jZeuVLt9Bs": {
    "title": "DocDoc: a general framework for open-ended long text generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jb1oi5Vtj7": {
    "title": "Less is More: A Simple yet Effective Token Reduction Method for Efficient Multi-modal LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ne5dt45ofU": {
    "title": "Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GA2yx9sf5z": {
    "title": "A Structured Approach to Re-Encoding Short-Term Memory of Large Language Models in Conversations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G3FVqp9WzB": {
    "title": "Inducing Vulnerable Code Generation in LLM Coding Assistants",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8ftqjYE7rq": {
    "title": "Intelli-Planner: Towards Participatory and Customized Urban Planning via Large Language Model Empowered Reinforcement Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KbjaGPBT2L": {
    "title": "LLM Safety for Children",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JnMekh6L0Q": {
    "title": "PhyBench: A Physical Commonsense Benchmark for Evaluating Text-to-Image Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VS3rq3tnaG": {
    "title": "Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FDyzPHBW4Q": {
    "title": "ObjVariantEnsemble:Advancing Point Cloud LLM Evaluation in Challenging Scenes with Subtly Distinguished Object",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=i0FOif69oW": {
    "title": "Don't Say No: Jailbreaking LLM by Suppressing Refusal",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P0xzgCm3Oy": {
    "title": "TEaR: Improving LLM-based Machine Translation with Systematic Self-Refinement",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EYOx0GeRTp": {
    "title": "On the Effect of Steering Latent Representation for Large Language Model Unlearning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P3uy9Sarza": {
    "title": "BDA: Bangla Text Data Augmentation Framework",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5zDgrgQSuz": {
    "title": "GraphEdit: Large Language Models for Graph Structure Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0TMCh60MyP": {
    "title": "PyBench: Evaluating LLM Agent on various real-world coding tasks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yFhdCD3clp": {
    "title": "Language-based Valence and Arousal Expressions between the United States and China: a Cross-Cultural Examination",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VWekQGYNTr": {
    "title": "Scoping Matters: Assessing Multimodal Model Editing via Dynamic Evaluation of Vision Questions Answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BPDV18lgBX": {
    "title": "A Comprehensive Study of Multimodal Large Models on Knowledge-Intensive Visual Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vmcGwh6NAP": {
    "title": "Enhancing Large Language Models for Document-Level Translation Post-Editing Using Monolingual Data",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uwKkozdTYt": {
    "title": "When does In-context Learning Fall Short and Why? A Study on Specification-Heavy Tasks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J6CX3N2ups": {
    "title": "REPANA: A Reasoning Path Navigation Framework for Large Language Models to Universally Reason over Heterogeneous Data",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OwlLLuQvzy": {
    "title": "DSGram: Dynamic Weighting Sub-Metrics for Grammatical Error Correction in the Era of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NwoMm6kLno": {
    "title": "ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible and Expressive Speech Synthesis",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SYoLl01otv": {
    "title": "Huatuo-26M, a Large-scale Chinese Medical QA Dataset",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XFoxWzolL1": {
    "title": "Adaptive Reinforcement Learning Planning: Harnessing Large Language Models for Complex Information Extraction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mMJndR6tAF": {
    "title": "Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f82fmg18fx": {
    "title": "ClinTexTS: Improving Patient-centered Care through Text Simplification of Clinical Narratives with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=stJoFiTlnc": {
    "title": "Confidence Breeds Success: Improving Fake News Video Detection via LVLM-Assisted Inference",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n08YuP2nZ3": {
    "title": "Edge-free but Structure-aware: Prototype-Guided Knowledge Distillation from GNNs to MLPs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wu7bTonPfG": {
    "title": "Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kRWOrobYxC": {
    "title": "On Context-aware Detection of Cherry-picking in News Reporting",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NevSyaNyx5": {
    "title": "Federated Recommendation with Differentially-Private and Multi-Agent Conversations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TdJsprtZem": {
    "title": "Tuning Language Models by Mixture-of-Depths Ensemble",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ljJBBhMcON": {
    "title": "Sports Intelligence: Assessing the Sports Understanding Capabilities of Language Models through Question Answering from Text to Video",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ewQzNGOs3l": {
    "title": "Push the Limit of Multi-modal Emotion Recognition by Prompting LLMs with Receptive-Field-Aware Attention Weighting",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=D4argRUaYh": {
    "title": "Adversarial Noisy Instruction Tuning for Enhancing NLU in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=47u8eyuOr5": {
    "title": "SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NbWt58tRox": {
    "title": "Large Language Models are Good Annotators for Type-aware Data Augmentation in Grammatical Error Correction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EvX52YynDr": {
    "title": "Language and Multimodal Models in Sports: A Survey of Datasets and Applications",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V602Oqu718": {
    "title": "Is Generative Communication between Embodied Agents Good for Zero-Shot ObjectNav?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CrojreecOG": {
    "title": "CLERC: A Dataset for Legal Citation Retrieval and Retrieval-Augmented Analysis Generation (which happen to be really really long)",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FKuvYtt4TQ": {
    "title": "Investigating How LLM-generated Data Affects the Evaluation of Foundation Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wH7oNs7pqk": {
    "title": "Direct Prompt Optimization with Continuous Representations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zWlRgVHIfJ": {
    "title": "LLMs Meet Long Video: Advancing Long Video Question Answering with An Interactive Visual Adapter in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ktkn0qzLYM": {
    "title": "Self-Verification for Computer-aided Design Code Generation with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GYkyOZR7a5": {
    "title": "Latent Dialogue Policy Planning without Policy Annotation and Dynamic Interaction for Effective Proactive Dialogues",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qkOaKOWy5E": {
    "title": "SR-FoT: A Syllogistic-reasoning Framework of Thought for Large Language Models Tackling Knowledge-based Reasoning Tasks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4TFlX5Ps3u": {
    "title": "News Without Borders: Domain Adaptation of Multilingual Sentence Embeddings for Cross-lingual News Recommendation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1x8S05HUOh": {
    "title": "G2RG: Grounding Prompt Guided Framework for Report Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aRDOYsu51E": {
    "title": "Balanced Multi-Objective Optimization as a Multi-Arm Bandit Problem",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d5ZQE0SotN": {
    "title": "SciQAG: A Framework for Auto-Generated Science Question Answering Dataset with Fine-grained Evaluation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lF8FmsMByO": {
    "title": "Unc-TTP: A Method for Classifying LLM Uncertainty to Improve In-Context Example Selection",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9i8z3sC6Fe": {
    "title": "LoFTI: Localization and Factuality Transfer to Indian Locales",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LBWttx1WAF": {
    "title": "GAIfE: Using GenAI to Improve Literacy in Low-resourced Settings",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BxyFGHeYLY": {
    "title": "Healing Powers of BERT: How Task-Specific Fine-Tuning Recovers Corrupted Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=R38o8dLQnw": {
    "title": "Efficient and Responsible Adaptation of Large Language Models for Robust Top-k Recommendations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cpkLFypIMO": {
    "title": "From English to Second Language Mastery: Enhancing LLMs with Cross-Lingual Continuation Instruction Tuning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IiLvT3ofe6": {
    "title": "Fact Decomposition is More Effective: A Post-hoc Retrieval Approach to Attributed Question Answering with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IaDLZdBEuo": {
    "title": "Unlock the Power of Frozen LLMs in Knowledge Graph Completion",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zZuSwZTPAY": {
    "title": "Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aTL8DXlRnd": {
    "title": "MULTIVERSE: Exposing Large Language Model Alignment Problems in Diverse Worlds",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eGn3TYJJbP": {
    "title": "Interactive Evaluation for Medical LLMs via Task-oriented Dialogue System",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UfYfnjrN6e": {
    "title": "No effort is ever wasted\": Learning to Detect AI-generated Text from Unseen LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LQwMOkuVzp": {
    "title": "Valley: Video Assistant with Large Language Model Enhanced Ability",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nuvYQHD8q2": {
    "title": "RRP: Boosting Text-to-SQL Generation by Ranking Reward Policy based on Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5zUh4VA9IO": {
    "title": "TinyLLM: Learning a Small Student from Multiple Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=022O6nI10X": {
    "title": "Beyond sentiment analysis for FOMC stock return prediction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FcBeG1O1aT": {
    "title": "Detection and Pinyin Improved Language Model for Chinese Grammatical Error Correction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NKirbMrl9Z": {
    "title": "Phonetization Improves Lexical Retrieval in Agglutinative Languages",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vGbXNYo9JH": {
    "title": "Large Language Models as Event Forecasters",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pulNBMA5uH": {
    "title": "Fine-Grained Knowledge Unlearning in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kQDxNPcDSk": {
    "title": "Graph-Score: A Graph-grounded Metric for Audio Captioning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=plD0EtdQfP": {
    "title": "Exploiting the Vulnerability of Large Language Models via Defense-Aware Architectural Backdoor",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nrh06BSQks": {
    "title": "JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning and Professional Question Answering Capability",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XvZfglYQ3S": {
    "title": "Hierarchical ReAct Ensembles for Human-Level Forecasting",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4hlrz5DzdB": {
    "title": "ExDDI: Explainable Drug-Drug Interaction Prediction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E8pk1i7ntF": {
    "title": "Graph Reasoning Task: A Step-by-Step Executable Benchmark for Mathematical Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5NErohfcHa": {
    "title": "Quantitative Framework for Word-Color Association and Application to 20th Century Anglo-American Poetry",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DCZ8841uBV": {
    "title": "Bridging Vision and Action for Navigation in Continuous Environments",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=g53qiV0h1Y": {
    "title": "Full-ECE: A Metric For Token-level Calibration on Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=W62WwI6FVl": {
    "title": "Palo: A Polyglot Large Multimodal Model for 5B People",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lewe4NJY4Z": {
    "title": "HerculesBench: Gradual Steps Towards AGI with a Bilingual Multi-discipline Hierarchical and Multimodal Benchmark",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=scAOC14MmM": {
    "title": "Examining Language Model Self-Play Beyond Zero-Sum Games",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0i2JfLjXbO": {
    "title": "QMixTuner: Learning to Optimize Mixed-Precision Quantization",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jsFzILeYGH": {
    "title": "Dual Grained Quantization: efficient fine-grained quantization for LLM",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Pl01EmqWY8": {
    "title": "Words Matter: Can Proprietary Large Language Models Handle Word-Substitutions?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=AJxlZCS03G": {
    "title": "Rethinking Sentence Embedding with Mean Pooling: Is it Reasonable to Summarize a Point Cloud with a Single Vector?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ijg2oF9wfg": {
    "title": "Inter-Lingual Semantic Map: Dictionaries that Visualizes Inter-Lingual Semantic Network/Space",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nG1iy3lBGc": {
    "title": "Non-instructional Fine-tuning: Enabling Instruction-Following Capabilities in Pre-trained Language Models without Instruction-Following Data",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FAIFJP1cIF": {
    "title": "CA-TriNet: Digging Image-to-Text Essence by Adaptive Co-Attention Head Distribution and Triple-LSTM Module for Medical Report Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NDjhJ2Tx16": {
    "title": "Harnessing GNN-LLM Synergy for Predicting and Explaining Restaurant Survival",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lox79lYSZB": {
    "title": "Exploring the Jungle of Bias: Political Bias Attribution in Language Models via Dependency Analysis",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XXpJeNX204": {
    "title": "TIFG: Text-Informed Feature Generation with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Y4ZGqwJ3D6": {
    "title": "A Deep Learning based Approach for Sindhi Poet Classification using Couplets",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Xj1uMpSLPy": {
    "title": "Hierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mckNboN9dh": {
    "title": "Promises, Outlooks and Challenges of Diffusion Language Modeling",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w2ZSoSzg8v": {
    "title": "Collaborative Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YNEgYGc9GT": {
    "title": "LLM Internal States Reveal Hallucination Risk Faced With a Query",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=czbSpuJgke": {
    "title": "Controlling Summarization Length Through EOS Token Weighting",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GzCrJiUi2R": {
    "title": "Detecting ChatGPT Modification in Global Education Research: A Case Study Across Translated and Open Access Contexts",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pBCa0xjkeD": {
    "title": "MovieLLM: Enhancing Long Video Understanding with AI-Generated Movies",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jV244jQuBT": {
    "title": "Hypothetical-Deductive Reasoning for Event Causality Identification",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PZvuzagvmZ": {
    "title": "Investigating Human Values in Online Communities",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4xC9tgBCzR": {
    "title": "Advancing Self-Enhancement of Reasoning via Historical Data Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=y9JEBCbhjz": {
    "title": "Social Norms in Cinema: A Cross-Cultural Analysis of Shame, Pride and Prejudice",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Wy5BTAnp4l": {
    "title": "Poetry2Image: An Iterative Correction Framework for Images Generated from Chinese Classical Poetry",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TG5rILd5Z0": {
    "title": "Learning to Poison Large Language Models During Instruction Tuning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RaUZeM5tAA": {
    "title": "ARTICLE: Annotator Reliability Through In-Context Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5sqHCFffWo": {
    "title": "Qibo: A Large Language Model for Traditional Chinese Medicine",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nHzMOOr9r4": {
    "title": "NAT3DSound: 3D Spatial Sound Field Synthesis with Multi-Modal Non-Autoregressive Transformer",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7KxqpQpz1z": {
    "title": "Auto-ICL: In-Context Learning without Human Supervision",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oyIyllLNSu": {
    "title": "Fully Inductive Link Prediction on N-ary Relational Facts via Semantic Hypergraph Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FgdcKodbeF": {
    "title": "Two Heads Are Better Than One: Distilling Task-Identify-and-Solve Rationales from Multiple LLM Teachers to Improve Student Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mZag77mJpU": {
    "title": "Multi-Document Grounded Synthetic Dialog Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ojDTdaNvjJ": {
    "title": "All that glitters\": Quality Evaluations with Unreliable Model and Human Annotations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vcs1WkxXi2": {
    "title": "Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h8wWjJ2gBK": {
    "title": "Multi-modal Multi-agent Debate-based Dialectical Knowledge Transfer Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GuQXNxCM2M": {
    "title": "Bi-LLMs: Bi-directional Large Language Models for Information Extraction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eajmBArdwI": {
    "title": "Generative Annotation for ASR Name Entity Correction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w81ziXFCLT": {
    "title": "On the Consistency of Prompt Preference across LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LqfcQQHHuu": {
    "title": "MemLong: Memory-Augmented Retrieval for Long Text Modeling",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7hZyeQxd6n": {
    "title": "Recording for Eyes, Not Echoing to Ears: Contextualized Spoken-to-Written Conversion of ASR Transcripts",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lXcxte1ZuA": {
    "title": "Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eznmHBknuD": {
    "title": "Enhancing the Multi-Attribute Fairness of LLM-based Recommenders: A Mixure-of-Experts Contrastive Learning Approach",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0ZP2JcGHIn": {
    "title": "CMed-Eval: A Systematic Chinese Medical Benchmark for Evaluating Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=62EtEWPTsB": {
    "title": "KARLM: Enhancing LLM-based Recommendation Systems with Knowledge Bases",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ulI036LMiw": {
    "title": "DParT: Transferring knowledge between languages changing a few weights",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HjgXnYmwtb": {
    "title": "Fake News Detection: It's All in the Data!",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Qdrl0n6cMa": {
    "title": "Can LLMs Recognize Toxicity? Definition-Based Toxicity Metric",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=a69IHVYumi": {
    "title": "Is It Live Streaming?\": Examining the Streamer's Understanding of \"Liveness\" From a Semi-Experimental Conversation Analytic Approach",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4YI6uh91Jg": {
    "title": "Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fi9ZUF8A4j": {
    "title": "Enhancing Knowledge Distillation of Large Language Models through Efficient Multi-Modal Distribution Alignment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CqR5Fx47Mc": {
    "title": "CHEW: A Dataset of CHanging Events in Wikipedia",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DuwmovyYuw": {
    "title": "FlexAlign: A Plug-and-Play Method for Language Models Target Domain Alignment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qDZKKFxY4t": {
    "title": "KGPA: Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=H2uKPyyLS3": {
    "title": "Similarity is Not All You Need: Endowing Retrieval-Augmented Generation with Multi–layered Thoughts",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p9HJFnByOX": {
    "title": "On Incorporating Prior Knowledge Extracted from Pre-trained Language Models into Causal Discovery",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eZ4leTW30G": {
    "title": "Enhancing Job Matching: BERT-Based Occupation, Skill and Qualification Entity Linking with the ESCO and EQF taxonomies",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rr8PfzoZ4v": {
    "title": "Towards Expert-Level Chinese Tax Consultancy: Enhancing Large Language Models for Accurate and Contextualized Advice",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yYSA1Zgamr": {
    "title": "The Male CEO and the Female Assistant: Gender Biases in Text-To-Image Generation of Dual Subjects",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oG9K4r1aeJ": {
    "title": "CLAIM: Mitigating Catastrophic Forgetting in Continual Instruction Fine-tuning Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NhAXmO4aPy": {
    "title": "LLM Analyst: What stocks do you recommend today?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uVjSlJ7bi1": {
    "title": "Language Models Can Think Faster: Compressing Chain-of-Thought without Compromising Effectiveness",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pwAwwu4Fh6": {
    "title": "eMART: An Efficient Multi-Agent System with LLM Specialized MCTS",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xIrqznJOfj": {
    "title": "Thought-Like-Pro: Enhancing Reasoning of Large Language Models through Self-Driven Prolog-based Chain-of-Though",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=atkEnV4LiY": {
    "title": "When natural language is not enough: The limits of in-context learning demonstrations in multilingual reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ubzPGpYA1V": {
    "title": "Securing Large Language Models: Effective Refusal Pattern Alignment through Self and Cross-Model Distillation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YXeL6szLv2": {
    "title": "Causally Interpretable Offline Reinforcement Learning for Task-oriented Dialogue Policy",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f0M9ODfKoR": {
    "title": "LLMs Know What They Need: Leveraging a Missing Information Guided Framework to Empower Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nuG8MEfqAF": {
    "title": "Tuning-Free Accountable Intervention for LLM Deployment - A Metacognitive Approach",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ALXFQN4KeJ": {
    "title": "Fairness at Every Intersection: Uncovering and Mitigating Intersectional Biases in Multimodal Clinical Predictions",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YiSLhqKoDM": {
    "title": "EnriCo: Enriched Representation and Globally Constrained Inference for Entity and Relation Extraction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gfe0nh7XCf": {
    "title": "Semantic Side-Channels to Jailbreak Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2FWE8zZIPm": {
    "title": "Transformers at the Edge: Challenges and Recipes for Productizing Neural Machine Translation for Regular Languages",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oMJ0fAlM3y": {
    "title": "Capabilities of LLMs on Casual Inference",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=geJTmUEUcW": {
    "title": "Evaluating Gender Bias in the Translation of Gender-Neutral Educational Professions from English to Gendered Languages",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=KTD6M7VkqP": {
    "title": "Argumentative Large Language Models for Explainable and Contestable Claim Verification",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LV66I3Jtey": {
    "title": "LOLAMEME: LOGIC, LANGUAGE, MEMORY, MECH- ANISTIC FRAMEWORK",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pvsLtjDXpA": {
    "title": "RLDF: Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vZUIHtG7kX": {
    "title": "LoRA 2 : Multi-Scale Low-Rank Approximations for Fine-Tuning Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Fu4sLIRHF0": {
    "title": "A Hopfieldian View-based Interpretation for Chain-of-Thought Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mi1kBh3Brp": {
    "title": "GlossGPT: GPT for Word Sense Disambiguation using Few-shot Chain-of-Thought Prompting",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YhX7bb0MYO": {
    "title": "From PEFT to DEFT: Parameter Efficient Finetuning for Reducing Activation Density in Transformers",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fEt1TDEIYj": {
    "title": "LightDefense: A Lightweight Uncertainty-Driven Defense against Jailbreaks via Shifted Token Distribution",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QDXr4VBPgZ": {
    "title": "BiLD: Bi-directional Logits Difference Loss for Large Language Model Distillation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VYT433CufJ": {
    "title": "Learning to Instruct with Implicit Harmfulness: Transferable Black-Box Jailbreak on Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eqj5L7H39n": {
    "title": "Keyword-Centric Prompting for One-Shot Event Detection with Self-Generated Rationale Enhancements",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kWs0B73KAG": {
    "title": "MoESD: Mixture of Experts Stable Diffusion to Mitigate Gender Bias",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E4JmTsdXhr": {
    "title": "Recurrent Context Compression: Efficiently Expanding the Context Window of LLM",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0ozHZzzH58": {
    "title": "MedCalc: Bridging Medical Calculator and LLM Agent with Nested Tool Calling",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VHwnKMtC0k": {
    "title": "FinDABench: Benchmarking Financial Data Analysis Ability of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RUW4vDDfnS": {
    "title": "ProSwitch: Knowledge-Guided Instruction Tuning to Switch Between Professional and Non-Professional Text Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Yk2mYu4ojN": {
    "title": "From WRIME to WRIME-TC: Enhancing Emotional Analysis of Writers and Readers with Temporal Context",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JtpLNNfQ5T": {
    "title": "Semantic Information: A difference that makes a difference",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B5hkYIa11V": {
    "title": "SimsChat: A Customisable Persona-Driven Role-Playing Agent",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JwVj4izv4c": {
    "title": "Enhancing Relation Extraction via Supervised Rationale Verification and Feedback",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vbUm0UmVXF": {
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vb37Py4936": {
    "title": "E2TP: Element to Tuple Prompting Improves Aspect Sentiment Tuple Prediction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SuCdnvyjkl": {
    "title": "Large Language Models are Multi-Task Chain-of-Thought Prompting Optimizers",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=b5LdTQCTuP": {
    "title": "Improving Visual Q/A in Autonomous Driving Scenerio's Using LLM",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PdU1ujmDyp": {
    "title": "AutoDCM: A Novel Framework for Automatic Relation Extraction Dataset Construction via Distant Supervision and Large Language Models for Low-Resource Tasks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8nphDi6E0l": {
    "title": "ObscurePrompt: Jailbreaking Large Language Models via Obscure Input",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LmnvN0C01K": {
    "title": "mGDTP: An End-to-End Framework for Long Document Modeling with mix-Granularity Dynamic Token Pruning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=40vd76KUoi": {
    "title": "The More Moral an LLM is, the Smarter It Becomes: Analyzing the Impact of Moral Development on General Problem-Solving in LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RHo8XFlMcA": {
    "title": "All Against Some: Efficient Integration of Large Language Models for Message Passing in Graph Neural Networks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZdT1OYeVjP": {
    "title": "Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5Oj1rUxbmh": {
    "title": "Who speaks for the autistic community? An NLP-driven investigation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XacdHuNC1L": {
    "title": "MergeNet: Knowledge Migration across Heterogeneous Models, Tasks, and Modalities",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=egYY7YpRFQ": {
    "title": "Integrating information from evolving layers to reduce hallucinations through Contrastive Decoding",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oNiskX6jWP": {
    "title": "Investigating Recurrent Transformers with Dynamic Halt",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RcoX5hqhS4": {
    "title": "Importance Weighting Can Help Large Language Models Self-Improve",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lMAGEzipXK": {
    "title": "Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bb9BBq2oCp": {
    "title": "Text-Conditioned Multimodal Alignment and Consistency Modeling for Fake News Video Detection",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=21SAZbReVg": {
    "title": "Learning to Check: Enhancing Self-Correction Capabilities in Large Language Models for Reasoning Tasks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h1AlJPngXy": {
    "title": "Empowering Empathetic Dialogue Generation in Large Language Models via Sensible and Visionary Commonsense Inference",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oJzEHBKc0I": {
    "title": "Explanatory Prompt Injection for Pre-trained Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BOXzslNx1B": {
    "title": "GenC: Generative Contrastive Learning for Passage Retrieval with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yMGbN5t2ja": {
    "title": "RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9TK0IGc0Xy": {
    "title": "Towards Collaborative Intelligence: Propagating Intentions and Reasoning for Multi-Agent Coordination with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NpErfKmepm": {
    "title": "TreeEval: Benchmark-Free Evaluation of Large Language Models through Tree Planning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mHCYjukiWe": {
    "title": "LLaMA-MoT: A Cost-Effective Framework for Visual-Linguistic Instruction Tuning Based on Multi-Head Adapters and Chain-of-Thought",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w4MnON8YtC": {
    "title": "PREMISE: Matching-based Prediction for Accurate Review Recommendation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rHb99ToADK": {
    "title": "CrossIn: An Efficient Instruction Tuning Approach for Cross-Lingual Knowledge Alignment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M8x89u5ZsO": {
    "title": "Computational Sentence-level Metrics for Predicting Comprehension of Entire Sentence by Humans",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oYYbxu6EgF": {
    "title": "A Survey on Effective Invocation Methods of Massive LLM Services",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IV0KyxFQ9h": {
    "title": "PROMPT-SAW: Leveraging Relation-Aware Graphs for Textual Prompt Compression",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V0LoeM0udJ": {
    "title": "Highlighting the Safety Concerns of Deploying LLMs/VLMs in Robotics",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OwGmX2Fv7Y": {
    "title": "PreAct: Prediction Enhances Agent's Planning Ability",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LAAgkc5kNb": {
    "title": "Trigger 3 : Refining Query Correction via Adaptive Model Selector",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FwQkprR53P": {
    "title": "FPTQ: Fine-grained Post-Training Quantization for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YQTUpp9NNi": {
    "title": "sDPO: Don't Use Your Data All at Once",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xa9hawIeIr": {
    "title": "SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical Reasoning in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SrfbyH3wgh": {
    "title": "Enhancing Continual Learning in Speech-Referring Video Object Segmentation with Mutual Information Maximization",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w4PXp9MiFM": {
    "title": "IMPROVED CONTENT UNDERSTANDING WITH EFFECTIVE USE OF MULTI-TASK CONTRASTIVE LEARNING",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oSwW0fhk2c": {
    "title": "InstructionCP: A Simple yet Effective Approach for Transferring Large Language Models to Target Languages",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QuTMQUaxMs": {
    "title": "Probability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F2uPrHJ4iB": {
    "title": "A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jbjKZ0lNZm": {
    "title": "Sentence-level Aggregation of Lexical Metrics Correlate Stronger with Human Judgements than Corpus-level Aggregation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PESflaYU8v": {
    "title": "Enhance the Robustness in Text-Centric Multimodal Alignments",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=inOBXcvmlz": {
    "title": "Enhancing Trustworthiness in Multimodal Large Language Models via Penalization of Language Priors",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e5ZYHZEQye": {
    "title": "diffusion models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rQ7w4VhdRQ": {
    "title": "Adapting Large Language Models for Content Moderation: Pitfalls in Data Engineering and Supervised Fine-tuning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mzZRdeJNv1": {
    "title": "PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=c2UQ6x3t0w": {
    "title": "Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=y68B76sbaR": {
    "title": "Advancing African-Accented English Speech Recognition: Epistemic Uncertainty-Driven Data Selection for Generalizable ASR Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0OhL0VmPvO": {
    "title": "MindStar: Enhancing Math Reasoning in Pre-trained LLMs at Inference Time",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FSALVvACFQ": {
    "title": "Improving Fuzzy Match Augmented Neural Machine Translation through Synthetic Data",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xCur5qLNln": {
    "title": "Can Large Language Models Create New Knowledge for Spatial Reasoning Tasks?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M9obtJdqgr": {
    "title": "Applying ESGBert to Detect Climate-Related Passages from German Financial Reports",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xVSJ4e9thv": {
    "title": "Cracking Factual Knowledge: A Comprehensive Analysis of Degenerate Knowledge Neurons in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9L4McQnj6J": {
    "title": "Increasing Trust in Language Models through the Reuse of Verified Circuits",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aKusABh8ZS": {
    "title": "Towards a Client-Centered Assessment of LLM Therapists by Client Simulation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7oPGJi0mdr": {
    "title": "How Well Can Multimodal LLMs Write Code as Vision-Enabled Agents?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zSdCoyjHa8": {
    "title": "Grimoire is All You Need for Enhancing Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rMLNzLRl1s": {
    "title": "Intention Analysis Makes LLMs A Good Jailbreak Defender",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8NgaPnk1J3": {
    "title": "UPO: Unpaired Preference Optimization for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MPmZO69Hr1": {
    "title": "ConceptPsy: A Benchmark Suite with Conceptual Comprehensiveness in Psychology",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PRMvw2rKf2": {
    "title": "Xrphonetic: Akshara-based Phonetic String Similarity",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F8tk4TEyQg": {
    "title": "From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TgOpyPW8Li": {
    "title": "The Generation Gap: Exploring Age Bias Underlying in the Value Systems of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=J92FmsN5Az": {
    "title": "Find Before you Fine-Tune (FiT): How to Identify Small-Scale LLM Suitable for Cybersecurity Question-Answering Tasks?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pDv2FMBBvc": {
    "title": "A Systematic Literature Review of Adapter-based Approaches to Knowledge-enhanced Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=v9lPQp0Dyi": {
    "title": "LinguAlchemy: Fusing Typological and Geographical Elements for Unseen Language Generalization",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qpZWYVxMQ6": {
    "title": "BiMediX: Bilingual Medical Mixture of Experts LLM",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=py5HlgQkQR": {
    "title": "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2NHJM9R2kP": {
    "title": "Data-Scarce Event Argument Extraction: A Dynamic Modular Prompt Tuning Model Based on Slot Transfer",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=snXfD8ecVK": {
    "title": "Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JYOsj0hy39": {
    "title": "What Is Missing in Multilingual Visual Reasoning and How to Fix It",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B1qWIPsXFH": {
    "title": "TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pGEu03b58f": {
    "title": "People will agree what I think: Investigating LLM's False Consensus Effect",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=vpM0pfm7C5": {
    "title": "Rethinking the Role of Proxy Rewards in Language Model Alignment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Zeo4HMnPtt": {
    "title": "EASY: Enhanced Analysis Approach for Implicit Hate Speech Yield – Bridging Human Insight and Algorithmic Precision in Social Media Discourse",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4OkWwjsJfp": {
    "title": "Generation with Dynamic Vocabulary",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0w1lzBv26x": {
    "title": "MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XfOFYVZtRx": {
    "title": "ANALOBENCH: Benchmarking the Identification of Abstract and Long-context Analogies",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mpRckjTbtb": {
    "title": "Can Large Language Models Unlock Novel Scientific Research Idea?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MskMzRfTsS": {
    "title": "Interaction Matters: An Evaluation Framework for Interactive Dialogue Assessment on English Second Language Conversations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=h7PEBMI7eX": {
    "title": "Facts-and-Feelings: Capturing both Objectivity and Subjectivity in Table-to-Text Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=32ojYK2xFE": {
    "title": "Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9r6TZATiMF": {
    "title": "DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Oiyyllbzra": {
    "title": "PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VqqNoSuxSa": {
    "title": "Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mHgNzfiApQ": {
    "title": "ReWIRED: Instructional Explanations in Teacher-Student Dialogues",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PF8Autw1kU": {
    "title": "MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7DhygCqaCL": {
    "title": "A ∧ B ⇔ B ∧ A: Evaluating and Improving Logical Reasoning Ability of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=f16qBlCJFN": {
    "title": "Pattern-Aware Chain-of-Thought Prompting in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HEjqNfHCCH": {
    "title": "LAiW: A Chinese Legal Large Language Models Benchmark",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wuTIy79GKB": {
    "title": "LLM-based Multi-hop Question Answering with Knowledge Graph Integration in Evolving Environments",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LMSYvl0hCq": {
    "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=grW9pYNjTC": {
    "title": "Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2UVtn2SRaN": {
    "title": "Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CIFvYGsSof": {
    "title": "BELIEFs: Bias-resilient, Multifaceted Evaluation of Language Models in Factual Knowledge Understanding",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SKLpAU2yGh": {
    "title": "Understanding ''Democratization'' in NLP Research",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OXE4qq1X30": {
    "title": "A Simple yet Effective Training-free Prompt-free Approach to Chinese Spelling Correction Based on Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0piiZz7bFE": {
    "title": "Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pXERcyY4Ht": {
    "title": "LLM with Relation Classifier for Document-Level Relation Extraction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8aYitCuR6l": {
    "title": "Evaluating Task-Oriented Dialogue Consistency through Constraint Satisfaction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=X5czq3asqL": {
    "title": "Puzzle Solving using Reasoning of Large Language Models: A Survey",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MHDQWs2NvV": {
    "title": "Towards Effective Counter-Responses: Aligning Human Preferences with Strategies to Combat Online Trolling",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=U3mt8vi0PB": {
    "title": "Smurfs: Leveraging Multiple Proficiency Agents with Context-Efficiency for Tool Planning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=fQjPKAiNbF": {
    "title": "Bridging the Gap: Integrating Knowledge Graphs into Large Language Models for Complex Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qwD7a6QgsU": {
    "title": "Code-Optimise: Optimising Code Language Models for Functional Correctness and Efficiency",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qU6F1OC2CE": {
    "title": "PEMCAMP: Parameter Efficient Model with Continuous Attentive Multimodal Prompt for Few-Shot Multimodal Sarcasm Detection",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hTBD3LYoqd": {
    "title": "The Art of Data Selection: A Survey on Data Selection for Fine-Tuning Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bziyNACv4B": {
    "title": "We Care: Multimodal Depression Detection and Knowledge Infused Mental Health Therapeutic Response Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oary7aJrfK": {
    "title": "On the Robustness of Editing Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pLQskC8sjI": {
    "title": "Dissecting similarities in self-consistency: An analysis on impact of semantic consistency on language model reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E8UWqLxg7z": {
    "title": "Source Attribution for Large Language Model-Generated Data",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hi5k4PDnX7": {
    "title": "ADELIE: Aligning Large Language Models on Information Extraction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kkvbBhUDo1": {
    "title": "Gotta Catch'em All!: Multi-Generator and Multi-Lingual Benchmark for Detecting LLM-Generated Code Snippets",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0aF93512B4": {
    "title": "MotionBoost: Bootstrapping Image-Language Models with Motion Awareness for Efficient Video Understanding",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=adHtqD9UDn": {
    "title": "FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e7IQBIXPQc": {
    "title": "GeNeRTe: Generating Neural Representations from Text for Classification",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=njZo800gEi": {
    "title": "Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical question answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=P82OfKIgNw": {
    "title": "IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Large Language Models in E-commerce",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4crBgTTCEB": {
    "title": "CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zMpZ2HQsOZ": {
    "title": "Measuring the Robustness of NLP Models to Domain Shifts",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8DQyyumKg8": {
    "title": "Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UKJWJXaHhz": {
    "title": "Cross-lingual Transfer for Automatic Question Generation by Learning Interrogative Structures in Target Languages",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=5oM6aIY0Zm": {
    "title": "Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F2SRTowQ2n": {
    "title": "Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HGtxNj2fG9": {
    "title": "Leveraging Domain Knowledge for Efficient Reward Modeling in RLHF: A Case-Study in E-Commerce Opinion Summarization",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Qn7WNRJvO9": {
    "title": "Aligning Language Models to Explicitly Handle Ambiguity",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=i7nGaiDz7H": {
    "title": "A Narrative Framework for Analyzing Partisan Perspectives in Event Discourse",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lf61bKz8L5": {
    "title": "Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kfmjnnblfL": {
    "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Dzr7iv0ZMQ": {
    "title": "Exploring Fine-Grained Human Motion Video Captioning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K3PODOXQqL": {
    "title": "Rethinking the Instruction Quality: LIFT is What You Need",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MiW7qui4HY": {
    "title": "Generating Zero-shot Abstractive Explanations for Rumour Verification",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RKoxfZuMIO": {
    "title": "MentalGPT: Harnessing AI for Compassionate Mental Health Support",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HGVQy9ZJQc": {
    "title": "Explaining Mixtures of Sources in News Articles",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HvjlLJy1Xg": {
    "title": "Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Iucj0JFblr": {
    "title": "Approximate Cluster-Based Sparse Document Retrieval with Segmented Maximum Term Weights",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gWPYS4u4sn": {
    "title": "Beyond English-Centric Machine Translation by Multilingual Instruction Tuning Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=C9k27kKMKj": {
    "title": "Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments Through Templates and Slot-filling",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Jw6rhpycTu": {
    "title": "Exploring Large Language Models for Knowledge Graph Completion",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=2EYu8T9C50": {
    "title": "Alleviate Prompt Forgetting of RNN-based Language Models Through Prompt Synthetic Gradients",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=47hULeg4nf": {
    "title": "PerLTQA: A Personal Long-Term Memory Dataset for Memory Classification, Retrieval, and Fusion in Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jIEmj2V87d": {
    "title": "Large Language Model-based Human-Agent Collaboration for Complex Task Solving",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k3dzpooeQL": {
    "title": "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n1L1KT05dQ": {
    "title": "Breaking Boundaries: Neural Approaches to Interlinear Translation of Classic Texts",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WDJ259NPAI": {
    "title": "DPPA: Pruning Method for Large Language Model to Model Merging",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mEWKp64fvf": {
    "title": "M2QA: Multi-domain Multilingual Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VFzYmcKhLM": {
    "title": "Driving Chinese Spelling Correction from a Fine-Grained Perspective",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=20E6oVPztC": {
    "title": "We Demand Justice!\": Towards Social Context Grounding of Political Texts",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IMNnyrC0Ky": {
    "title": "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1LHT5IsOXB": {
    "title": "Robust Claim Verification Through Fact Detection",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bGi69H0atI": {
    "title": "Knowledge Verification to Nip Hallucination in the Bud",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YNoloCgtWT": {
    "title": "Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FlXweLwQk5": {
    "title": "Large Language Models Can Plan Your Travels Rigorously with Formal Verification Tools",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4noo5lXUIJ": {
    "title": "DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bOy7jAyDyc": {
    "title": "Gotcha! Don't trick me with unanswerable questions! Self-aligning Large Language Models for Proactively Responding to Unknown Questions",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4QxIV9nQIf": {
    "title": "Automatic Evaluation for Mental Health Counseling using LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6B0D6VwC0R": {
    "title": "LLMs Know What They Need: Leveraging a Missing Information Guided Framework to Empower Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QVq6Fheh0b": {
    "title": "Claim Check-Worthiness Detection: How Well do LLMs Grasp Annotation Guidelines?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NgcsbiImqL": {
    "title": "More than Just Printing \"Hijacked!\": Automatic and Universal Prompt Injection Attacks against Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Dkli9LbLKh": {
    "title": "Exploring Multilingual Concepts of Human Values in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0OaINsyHhh": {
    "title": "API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9esVkGJLYv": {
    "title": "Evaluating Large Language Models in Olympic-Level Physics Problems: A Benchmark Dataset",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V2NlbQJbds": {
    "title": "SToRI: Semantic Token Reweighting for Interpretable and Controllable Text Embeddings in Vision-Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wUi43kk7iX": {
    "title": "REASONS: A benchmark for REtrieval and Automated citationS Of scieNtific Sentences using Public and Proprietary LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YhkZzwHMxX": {
    "title": "Which questions should I answer? Salience Prediction of Inquisitive Questions",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oj8LMcHWi5": {
    "title": "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Preference Alignment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=3DoU4C8ZWb": {
    "title": "Do Large Language Models Speak All Languages Equally? A Comparative Study in Low-Resource Settings",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G3Tmyh8IpM": {
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specifc Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FDOlg6MBp7": {
    "title": "Revisiting the Iterative Non-Autoregressive Transformer",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r7lSTDCO6y": {
    "title": "Learning to Extract Structured Entities Using Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mACk3ZVHoU": {
    "title": "Designing Draft Models for Speculative Decoding",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=OvZa5b4fdr": {
    "title": "STARD: A Statute Retrieval Dataset for Layperson Queries",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lfiY2bIcfD": {
    "title": "JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning and Professional Question Answering Capability",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=oXPPBAn45s": {
    "title": "Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=awzqNHY7hC": {
    "title": "From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LnAw7ecjpl": {
    "title": "AutoCrawler : A Progressive Understanding Web Agent for Web Crawler Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WKdcBbuzjv": {
    "title": "nbDescribe: A Dataset for Text Description Generation from Tables and Code in Jupyter Notebooks with Guidelines",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9IUfu0F50J": {
    "title": "On Demonstration Selection for Improving Language Model Fairness",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=eCATrqi1FC": {
    "title": "I Could've Asked That: Reformulating Unanswerable Questions",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=sfCZV7T41n": {
    "title": "Spatial-Aware Visual Program Reasoning for Complex Visual Questions Answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hR4uTiXz6C": {
    "title": "Assessing and Post-Processing Black Box Large Language Models for Knowledge Editing",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JnAHWgKeSt": {
    "title": "AILQA: Evaluating AI-Driven Legal Question Answering Systems for the Indian Legal System",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ycrYUUStqy": {
    "title": "GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LJWIALJlNQ": {
    "title": "Reformatted Alignment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rb0AjPCAm2": {
    "title": "Data Augmentation for Less Resourced Summarization",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PlrPx39xo5": {
    "title": "Development of Cognitive Intelligence in Pre-trained Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cd525xu7OM": {
    "title": "Automated Data Curation for Robust Language Model Fine-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=q5WTq5dDs7": {
    "title": "A Survey on Open Information Extraction from Rule-based Model to Large Language Model",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=GnGXbekH7M": {
    "title": "Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UsdoZJddRo": {
    "title": "SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LB8bER1JBS": {
    "title": "Text2Model: Text-based Model Induction for Zero-shot Image Classification",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6SnNOOkkVb": {
    "title": "Automatic Instruction Evolving for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=BR97WPMeEF": {
    "title": "DeAL: Decoding-time Alignment Framework for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TQZFKvu02A": {
    "title": "MedReadMe: A Systematic Study for Fine-grained Sentence Readability in Medical Domain",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0zJ3ApCz5W": {
    "title": "Radical Prompting: Enhancing Chinese Language Models with Character Visual Analysis",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=DDqiER1toi": {
    "title": "Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM Framework for Detecting Factual Errors",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=VIS6nCehyD": {
    "title": "Evaluating Character Understanding of Large Language Models via Character Profiling From Fictional Works",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mqrylyUmZ3": {
    "title": "NewsEdits 2.0: Learning the Intentions Behind Updating News",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8xfJKMzvrm": {
    "title": "A good pun is its own reword\": Can Large Language Models Understand Puns?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=K7TlD3mVGN": {
    "title": "On Diversified Preferences of Large Language Model Alignment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Bhzd8kJhNC": {
    "title": "Assessing and Verifying Task Utility in LLM-Powered Applications",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Su7OLRmo3r": {
    "title": "Translation of Multifaceted Data without Re-Training of Machine Translation System",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zHOtAkQulQ": {
    "title": "Leveraging Large Language Models for Adversarial Attacks on Information Retrieval Systems",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=CteryEsG7E": {
    "title": "A Unified Framework for Model Editing",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wyWkUe13dW": {
    "title": "Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SMK34VBntD": {
    "title": "GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=e1bM1YofLh": {
    "title": "Automated Evaluation of the Linguistic Difficulty of Conversational Texts for LLM Applications",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ek4XVXc9vj": {
    "title": "Exploring Large Language Models for Hate Speech Detection in Rioplatense Spanish",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aa2Nf8v6L9": {
    "title": "Defense Against Syntactic Textual Backdoor Attacks with Token Substitution",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Hn7tT46INc": {
    "title": "Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qhHxRsN7oG": {
    "title": "Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification For ICD Coding",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HEvdEjvKSQ": {
    "title": "D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rEIZUkGlbM": {
    "title": "Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7DicksqbxB": {
    "title": "WordPlay: An Agent Framework for Language Learning Games",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=n2J2vmPJzH": {
    "title": "KnowTuning: Knowledge-aware Fine-tuning for Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=nha1mwiGdM": {
    "title": "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7Sa4uZjKHL": {
    "title": "Cause and Effect: Can Large Language Models Truly Understand Causality?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ilHAWjNfFh": {
    "title": "Explaining the Hardest Errors of Contextual Embedding Based Classifiers",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PYUgeLtn4F": {
    "title": "Updating CLIP to Prefer Descriptions Over Captions",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jlUUoerguq": {
    "title": "Enhancing Reinforcement Learning with Intrinsic Rewards from Language Model Critique",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hzO9G2XayB": {
    "title": "Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6OZm8mkwrp": {
    "title": "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bR7tto04wx": {
    "title": "Learning to Poison Large Language Models During Instruction Tuning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IFdjMXAEnk": {
    "title": "Annotator-Centric Active Learning for Subjective NLP Tasks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0sqP6XHFku": {
    "title": "LLM Task Interference: An Initial Study on the Impact of Task-Switch in Conversational History",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MjhcZO9Nsp": {
    "title": "Assessing the Role of Lexical Semantics in Cross-lingual Transfer through Controlled Manipulations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7WfuEoGfrT": {
    "title": "A Data-Driven Approach to Idiomaticity in Russian MWEs Based on Experts' Criteria in Theoretical Linguistics",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UEXqI6KSLl": {
    "title": "Scaling Properties of Speech Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qJWA4kLueV": {
    "title": "Unifying Demonstration Selection and Compression for In-Context Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rWn9hGiHMa": {
    "title": "Hijacking Large Language Models via Adversarial In-Context Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tkbIJpb6tO": {
    "title": "Multilingual Performance Analysis of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0HdVkWv5p8": {
    "title": "XC-Cache: Cross-Attending to Cached Context for Efficient LLM Inference",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XWLnASxlIu": {
    "title": "Decomposed Prompting: Probing Multilingual Linguistic Structure Knowledge in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RylDUZzJOy": {
    "title": "Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=SStY2rV16I": {
    "title": "GREEN: Generative Radiology Report Evaluation and Error Notation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=aLNSiCw4pc": {
    "title": "Argumentative Large Language Models for Explainable and Contestable Decision-Making",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=gR6RbmZSwu": {
    "title": "CUTE: Measuring LLMs' Understanding of Their Tokens",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rlBYJyZdwi": {
    "title": "Progressive Knowledge Graph Completion",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TNekcamOfv": {
    "title": "SEAVER: Attention Reallocation for Mitigating Distractions in Language Models for Conditional Semantic Textual Similarity Measurement",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=43UQJyD4jU": {
    "title": "PiT: Prompt Injection Tuning for Pre-trained Lanaguage Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=uSf5QvBC6j": {
    "title": "Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mlY0Un1mm3": {
    "title": "When Emotional Stimuli meet Prompt Designing: An Auto-Prompt Graphical Paradigm",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Qt3MGkkXC3": {
    "title": "Dynamic Planning for LLM-based Graphical User Interface Automation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=W4KRfyiBzm": {
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=k9KuNVnkeR": {
    "title": "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=T0pqsBEQRD": {
    "title": "Retrieval-Augmented Generation: Is Dense Passage Retrieval Retrieving?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=wPPcMxVOsV": {
    "title": "Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-checkers",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=M7YYzGmH5h": {
    "title": "Enhancing Confidence Expression in Large Language Models Through Learning from Past Experience",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Ag1PL4eDCO": {
    "title": "SNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=255EPHrB2q": {
    "title": "Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E71T5czNBb": {
    "title": "Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yGcW7Os1op": {
    "title": "Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ATSA2LhP2W": {
    "title": "Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I1ZR1DLYTE": {
    "title": "LUQ: Long-text Uncertainty Quantification for LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=TzrsefUVx8": {
    "title": "Learning to Paraphrase for Alignment with Model Preference",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0bcts3XUrB": {
    "title": "Neuron Specialization: Leveraging Intrinsic Task Modularity for Multilingual Machine Translation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=7YlEPNFSp3": {
    "title": "Humans or LLMs as the Judge? A Study on Judgement Bias",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=POvqE9wKlg": {
    "title": "Consecutive Model Editing with Batch alongside HooK Layers",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8t844SNkXx": {
    "title": "Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MirhzDaV8Y": {
    "title": "Controlled Cloze-test Question Generation with Surrogate Models for IRT Assessment",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=pd2EVKoU6c": {
    "title": "Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=qMqUFxTJ2l": {
    "title": "TRoTR: A Framework for Evaluating the Recontextualization of Text",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WXtTdv5O5e": {
    "title": "Understanding Token Probability Encoding in Output Embeddings",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=veHK4vbnpY": {
    "title": "Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dKm4jLXZVr": {
    "title": "QUIK: Towards End-to-end 4-Bit Inference on Generative Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r270rFSQDa": {
    "title": "Parameter-Efficient Tuning with Information Carrier and Partially Unfrozen Component",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=V6Jd4TUnKO": {
    "title": "ChatCRS: Incorporating External Knowledge and Goal Guidance for LLM-based Conversational Recommender Systems",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=i35MCC7VHt": {
    "title": "Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=HeISnPQMET": {
    "title": "ProSwitch: Knowledge-Guided Instruction Tuning to Generate Professional and Non-Professional Styled Text",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=EbzqjIy5Hl": {
    "title": "Large Language Models Are Unconscious of Unreasonability in Math Problems",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WItPPXAgAR": {
    "title": "From Answers to Questions: A Study on Backward Reasoning in Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cFHfla6OYq": {
    "title": "Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=r1zEPBcx1V": {
    "title": "DetectBench: Can LLMs Piece Together Implicit Evidence for Long-Context Multi-Hop Reasoning?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=hTr8s95SYA": {
    "title": "Improving Minimum Bayes Risk Decoding with Multi-Prompt",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=6vnAOGZkmy": {
    "title": "Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IWns0d4P9M": {
    "title": "Optimizing Machine Translation through Paraphrasing Ranking",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=y5COK6zo2Z": {
    "title": "Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QV9Gt2tEpm": {
    "title": "Navigating the Nuances: A Fine-grained Evaluation of Vision-Language Navigation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kAUJaVppSA": {
    "title": "Towards Uncovering How Large Language Model Works: An Explainability Perspective",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d3CqANZj9F": {
    "title": "Cost-Efficient Subjective Task Annotation and Modeling through Few-Shot Annotator Adaptation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=B6LCAfbB4f": {
    "title": "The Impact of Reasoning Methods across Languages",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=tXMcWTbVlJ": {
    "title": "Entity6K: A Large Open-Domain Evaluation Dataset for Real-World Entity Recognition",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ZKEXuZ5ksI": {
    "title": "The Program Testing Ability of Large Language Models for Code",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=d98xvzlf8l": {
    "title": "Is there really a Citation Age Bias in NLP?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E6uTejGgth": {
    "title": "FaithScore: Fine-grained Evaluations of Hallucinations in Large Vision-Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1Mikiy7Fzo": {
    "title": "MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=JAzg4CtkXq": {
    "title": "Systematic Biases in LLM Simulations of Debates",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=4wzxMJGbx4": {
    "title": "David vs. Goliath: Can small models leverage LLMs for summarization?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=WZkT6h6Kbt": {
    "title": "ChOiRe: Characterizing and Predicting Human Opinions with Chain of Opinion Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=cM1QDYKKVm": {
    "title": "LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zc4WaM7WZ0": {
    "title": "Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1NfXdBBVcY": {
    "title": "SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=G6XAUVZFur": {
    "title": "TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IqcSNVLu3y": {
    "title": "Mitigating Open-Vocabulary Caption Hallucinations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xvD1zoieJF": {
    "title": "KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=E6Mh36I6a0": {
    "title": "How Can Metaphor not Handle Anomaly? Metaphor Detection with Anomalous Text",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YAeHOnzrMo": {
    "title": "LongAlign: A Recipe for Long Context Alignment of Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UrYL85oZuL": {
    "title": "Reconsidering Token Embeddings with the Definitions for Pre-trained Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=jZEIsYKslm": {
    "title": "CoT-Planner: Chain-of-Thoughts as the Content Planner for Few-shot Table-to-Text Generation Reduces the Hallucinations from LLMs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=kxMFQVpfQu": {
    "title": "Positive Text Reframing under Multi-strategy Optimization",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=RRYyr5EmHA": {
    "title": "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=l0v8xOuKDR": {
    "title": "Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=mtmFt7zu1K": {
    "title": "\\textit{Dial BeInfo for Faithfulness}: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=QC2bQjm6Lt": {
    "title": "Fine-grained and Explanable Factuality Evaluation for Multimodal Summarization",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=IbpxiUULD8": {
    "title": "ManiTweet: A New Benchmark for Identifying Manipulation of News on Social Media",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MTVGbju4N4": {
    "title": "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Yp7LkttZ2Q": {
    "title": "Reversing the NLP Pipeline: What Do LMs Have to Offer Linguistics?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=8Ey54SZGVn": {
    "title": "Is ChatGPT a Smart Data Generation Tool? Exploring ChatGPT for Generating Metaphorical Data",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=zVI3qVofDk": {
    "title": "RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=w4PInrVSYU": {
    "title": "Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=p0N0RYl7i5": {
    "title": "Incubating Text Classifiers Following User Instruction with Nothing but LLM",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=0qns6fSiZK": {
    "title": "Making Task-Oriented Dialogue Datasets More Natural by Synthetically Generating Indirect User Requests",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=XibKBU8y6a": {
    "title": "In-Context Learning with Iterative Demonstration Selection",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=FF1ksRdveR": {
    "title": "Towards Robustness of Text-to-Visualization Translation against Lexical and Phrasal Variability",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=NVATnmPk8v": {
    "title": "How to Insert an Additional Layer Between the Middle Layer of the Pre-trained Model",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=niCsgzEGAY": {
    "title": "Improving LLM-based Unified Event Relation Extraction via Multiple Answer Questions",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=PBb2NolNfS": {
    "title": "Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=lBc3MXcGqZ": {
    "title": "NL2FOL: Translating Natural Language to First-Order Logic for Logical Fallacy Detection",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=YenLE2PvO7": {
    "title": "Exploring the Jungle of Bias: Political Bias Attribution in Language Models via Dependency Analysis",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=t0dpw7nrkK": {
    "title": "Experimental Contexts Can Facilitate Robust Semantic Property Inference in Language Models, but Inconsistently",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=dElj4nJt9X": {
    "title": "Improving Small and Large Language Models Alignment on Chain-of-Thought Reasoning using Curriculum Learning",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=I0oWWdH7cS": {
    "title": "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=F3tAkdqhIV": {
    "title": "Transition-based Opinion Generation for Aspect-based Sentiment Analysis",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=UvDNTDBAqE": {
    "title": "Large Language Models are Better Logical Fallacy Reasoners with Counterargument, Goal, and Explanation-aware Prompt Formulation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=yb1o4Tj68X": {
    "title": "Tuning-Free Accountable Intervention for LLM Deployment - A Metacognitive Approach",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=Bg2P0xImjY": {
    "title": "Unlocking Multi-View Insights in Knowledge-Dense Retrieval-Augmented Generation",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=guSIWloCNz": {
    "title": "Multi-Event Temporal Ordering by Event Order Ranking",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=85FdcTyMxU": {
    "title": "FrCoLA: a French Corpus of Linguistic Acceptability Judgments",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=i4Gm9K7mm1": {
    "title": "Uncertainty in Language Models: Assessment through Rank-Calibration",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xm6vXYVH3i": {
    "title": "Beyond the Turn-Based Game: Duplex Models Enable Real-Time Conversations",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=9mSUtXbxVw": {
    "title": "Mitigating Prototype Shift: Few-Shot Nested Named Entity Recognition with Prototype-Attention",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=MOoZjnA8S8": {
    "title": "Salience-aware Dialogue Summarization via Parallel Original-Extracted Streams",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=rEQU0BjJOz": {
    "title": "Imagination Augmented Generation: Learning to Imagine Richer Context for Question Answering over Large Language Models",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=bVWOCdBAKM": {
    "title": "ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=T4o5BVsIdI": {
    "title": "Personality Profiling: How informative are social media profiles in predicting personal information?",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=1OcsjG37jy": {
    "title": "Can't Remember Details in Long Documents? You Need Some R&R",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ha1S5Plcee": {
    "title": "Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=ie9T6S9g4S": {
    "title": "70B-parameter large language models in Japanese medical question-answering",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=LZpK1N1naV": {
    "title": "MMoE: Robust Spoiler Detection with Multi-modal Information and Domain-aware Mixture-of-Experts",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  },
  "https://openreview.net/forum?id=xbk1WGTP8y": {
    "title": "ChatLog: Carefully Evaluating the Evolution of ChatGPT Across Time",
    "volume": "review",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": []
  }
}