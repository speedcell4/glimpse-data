{
  "https://openreview.net/forum?id=giw2vcAhiH": {
    "title": "Spectral learning of Bernoulli linear dynamical systems models for decision-making",
    "abstract": "Latent linear dynamical systems with Bernoulli observations provide a powerful modeling framework for identifying the temporal dynamics underlying binary time series data, which arise in a variety of contexts such as binary decision-making and discrete stochastic processes\nsuch as binned neural spike trains. Here we develop a spectral learning method for fast, efficient fitting of probit-Bernoulli latent linear dynamical system (LDS) models. Our approach extends traditional subspace identification methods to the Bernoulli setting via a transformation of the first and second sample moments. This results in a robust, fixed-cost estimator that avoids the hazards of local optima and the long computation time of iterative fitting procedures like the expectation-maximization (EM) algorithm. In regimes where data is limited or assumptions about the statistical structure of the data are not met, we demonstrate that the spectral estimate provides a good initialization for Laplace-EM fitting. Finally, we show that the estimator provides substantial benefits to real world settings by analyzing data from mice performing a sensory decision-making task",
    "volume": "main",
    "checked": true,
    "id": "29154bbd6c07960fb40259288dd96a7509fa9b01",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=bnBeNFB27b": {
    "title": "Self-Supervision is All You Need for Solving Rubikâs Cube",
    "abstract": "Existing combinatorial search methods are often complex and require some level of expertise. This work introduces a simple and efficient deep learning method for solving combinatorial problems with a predefined goal, represented by Rubik's Cube. We demonstrate that, for such problems, training a deep neural network on random scrambles branching from the goal state is sufficient to achieve near-optimal solutions. When tested on Rubik's Cube, 15 Puzzle, and 7$\\times$7 Lights Out, our method outperformed the previous state-of-the-art method DeepCubeA, improving the trade-off between solution optimality and computational cost, despite significantly less training data. Furthermore, we investigate the scaling law of our Rubik's Cube solver with respect to model size and training data volume",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://openreview.net/forum?id=EYjfLeJL4l": {
    "title": "Towards Better Generalization with Flexible Representation of Multi-Module Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have become compelling models designed to perform learning and inference on graph-structured data. However, little work has been done to understand the fundamental limitations of GNNs for scaling to larger graphs and generalizing to out-of-distribution (OOD) inputs. In this paper, we use a random graph generator to systematically investigate how the graph size and structural properties affect the predictive performance of GNNs. We present specific evidence that the average node degree is a key feature in determining whether GNNs can generalize to unseen graphs, and that the use of multiple node update functions can improve the generalization performance of GNNs when dealing with graphs of multimodal degree distributions. Accordingly, we propose a multi-module GNN framework that allows the network to adapt flexibly to new graphs by generalizing a single canonical nonlinear transformation over aggregated inputs. Our results show that the multi-module GNNs improve the OOD generalization on a variety of inference tasks in the direction of diverse structural features",
    "volume": "main",
    "checked": true,
    "id": "36dd723251d11fe1142a9cc9d783f2adc8af3233",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=5rq8iRzHAQ": {
    "title": "Assisting Human Decisions in Document Matching",
    "abstract": "Many practical applications, ranging from paper-reviewer assignment in peer review to job-applicant matching for hiring, require human decision makers to identify relevant matches by combining their expertise with predictions from machine learning models. In many such model-assisted document matching tasks, the decision makers have stressed the need for assistive information about the model outputs (or the data) to facilitate their decisions. In this paper, we devise a proxy matching task that allows us to evaluate which kinds of assistive information improve decision makers’ performance (in terms of accuracy and time). Through a crowdsourced (N = 271 participants) study, we find that providing black-box model explanations reduces users’ accuracy on the matching task, contrary to the commonly-held belief that they can be helpful by allowing better understanding of the model. On the other hand, custom methods that are designed to closely attend to some task-specific desiderata are found to be effective in improving user performance. Surprisingly, we also find that the users’ perceived utility of assistive information is misaligned with their objective utility (measured through their task performance)",
    "volume": "main",
    "checked": true,
    "id": "92f9859569cf60f841911960af13efeec095882e",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=T5sXdAO3EQ": {
    "title": "Bayesian Quadrature for Neural Ensemble Search",
    "abstract": "Ensembling can improve the performance of Neural Networks, but existing approaches struggle when the architecture likelihood surface has dispersed, narrow peaks. Furthermore, existing methods construct equally weighted ensembles, and this is likely to be vulnerable to the failure modes of the weaker architectures. By viewing ensembling as approximately marginalising over architectures we construct ensembles using the tools of Bayesian Quadrature -- tools which are well suited to the exploration of likelihood surfaces with dispersed, narrow peaks. Additionally, the resulting ensembles consist of architectures weighted commensurate with their performance. We show empirically -- in terms of test likelihood, accuracy, and expected calibration error -- that our method outperforms state-of-the-art baselines, and verify via ablation studies that its components do so independently",
    "volume": "main",
    "checked": true,
    "id": "ac698e49c4ff0a56ec6349bfd7ff28a019fbba0c",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=MMsyqXIJuk": {
    "title": "JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games",
    "abstract": "This paper presents an empirical exploration of non-transitivity in perfect-information games, specifically focusing on Xiangqi, a traditional Chinese board game comparable in game-tree complexity to chess and shogi. By analyzing over 10,000 records of human Xiangqi play, we highlight the existence of both transitive and non-transitive elements within the game’s strategic structure. To address non-transitivity, we introduce the JiangJun algorithm, an innovative combination of Monte-Carlo Tree Search (MCTS) and Policy Space Response Oracles (PSRO) designed to approximate a Nash equilibrium. We evaluate the algorithm empirically using a WeChat mini program and achieve a Master level with a 99.41% win rate against human players. The algorithm’s effectiveness in overcoming non-transitivity is confirmed by a plethora of metrics, such as relative population performance and visualization results. Our project site is available at https://sites.google.com/view/jiangjun-site/",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://openreview.net/forum?id=f39UIDkwwc": {
    "title": "Contrastive Attraction and Contrastive Repulsion for Representation Learning",
    "abstract": "Contrastive learning (CL) methods effectively learn data representations in a self-supervision manner, where the encoder contrasts each positive sample over multiple negative samples via a one-vs-many softmax cross-entropy loss. By leveraging large amounts of unlabeled image data, recent CL methods have achieved promising results when pretrained on large-scale datasets, such as ImageNet. However, most of them consider the augmented views from the same instance are positive pairs, while views from other instances are negative ones. Such binary partition insufficiently considers the relation between samples and tends to yield worse performance when generalized on images in the wild. In this paper, to further improve the performance of CL and enhance its robustness on various datasets, we propose a doubly CL strategy that contrasts positive samples and negative ones within themselves separately. We realize this strategy with contrastive attraction and contrastive repulsion (CACR), which makes the query not only exert a greater force to attract more distant positive samples but also do so to repel closer negative samples. Theoretical analysis reveals that CACR generalizes CL's behavior by positive attraction and negative repulsion. It further considers the intra-contrastive relation within the positive and negative pairs to narrow the gap between the sampled and true distribution, which is important when datasets are less curated. Extensive large-scale experiments on standard vision tasks show that CACR not only consistently outperforms existing CL methods on benchmark datasets, but also shows better robustness when generalized on imbalanced image datasets",
    "volume": "main",
    "checked": true,
    "id": "e0669fcf8d388ad640d42e014930540d85794eb7",
    "citation_count": 5
  },
  "https://openreview.net/forum?id=HyzCuCV1jH": {
    "title": "Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success",
    "abstract": "Self-supervised learning (SSL) has emerged as a promising alternative to create supervisory signals to real-world problems, avoiding the extensive cost of manual labeling. SSL is particularly attractive for unsupervised tasks such as anomaly detection (AD), where labeled anomalies are rare or often nonexistent. A large catalog of augmentation functions has been used for SSL-based AD (SSAD) on image data, and recent works have reported that the type of augmentation has a significant impact on accuracy. Motivated by those, this work sets out to put image-based SSAD under a larger lens and investigate the role of data augmentation in SSAD. Through extensive experiments on 3 different detector models and across 420 AD tasks, we provide comprehensive numerical and visual evidences that the alignment between data augmentation and anomaly-generating mechanism is the key to the success of SSAD, and in the lack thereof, SSL may even impair accuracy. To the best of our knowledge, this is the first meta-analysis on the role of data augmentation in SSAD",
    "volume": "main",
    "checked": true,
    "id": "18e6802b19bb5bc4bd64dc9bf495ef0a95ccc21b",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=Wcui061fxr": {
    "title": "Conditional Generative Models are Provably Robust: Pointwise Guarantees for Bayesian Inverse Problems",
    "abstract": "Conditional generative models became a very powerful tool to sample from Bayesian inverse problem posteriors. It is well-known in classical Bayesian literature that posterior measures are quite robust with respect to perturbations of both the prior measure and the negative log-likelihood, which includes perturbations of the observations. However, to the best of our knowledge, the robustness of conditional generative models with respect to perturbations of the observations has not been investigated yet. In this paper, we prove for the first time that appropriately learned conditional generative models provide robust results for single observations",
    "volume": "main",
    "checked": true,
    "id": "29fcb5ccd0e82cea08cd744d96967be12d3e63ef",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=eLX5XrajXh": {
    "title": "A Characteristic Function for Shapley-Value-Based Attribution of Anomaly Scores",
    "abstract": "In anomaly detection, the degree of irregularity is often summarized as a real-valued anomaly score. We address the problem of attributing such anomaly scores to input features for interpreting the results of anomaly detection. We particularly investigate the use of the Shapley value for attributing anomaly scores of semi-supervised detection methods. We propose a characteristic function specifically designed for attributing anomaly scores. The idea is to approximate the absence of some features by locally minimizing the anomaly score with regard to the to-be-absent features. We examine the applicability of the proposed characteristic function and other general approaches for interpreting anomaly scores on multiple datasets and multiple anomaly detection methods. The results indicate the potential utility of the attribution methods including the proposed one",
    "volume": "main",
    "checked": true,
    "id": "55aef92de7709c0f9c2a70db10a2f32fa8db7b61",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=QBMyDZsPMd": {
    "title": "The Open MatSci ML Toolkit: A Flexible Framework for Machine Learning in Materials Science",
    "abstract": "We present the Open MatSci ML Toolkit: a flexible, self-contained, and scalable Python-based framework to apply deep learning models and methods on scientific data with a specific focus on materials science and the OpenCatalyst Dataset. Our toolkit provides: 1. A scalable machine learning workflow for materials science leveraging PyTorch Lightning, which enables seamless scaling across different computation capabilities (laptop, server, cluster) and hardware platforms (CPU, GPU, XPU). 2. Deep Graph Library (DGL) support for rapid graph neural network prototyping and development. By publishing and sharing this toolkit with the research community via open-source release, we hope to: 1. Lower the entry barrier for new machine learning researchers and practitioners that want to get started with the OpenCatalyst dataset, which presently comprises the largest computational materials science dataset. 2. Enable the scientific community to apply advanced machine learning tools to high-impact scientific challenges, such as modeling of materials behavior for clean energy applications. We demonstrate the capabilities of our framework by enabling three new equivariant neural network models for multiple OpenCatalyst tasks and arrive at promising results for compute scaling and model performance. The code of the framework and experiments presented in this is paper are publicly available at https://github.com/IntelLabs/matsciml",
    "volume": "main",
    "checked": true,
    "id": "21f9ddb6f39b2678bf9266d63895cdf71906784e",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=mXfkKtu5JA": {
    "title": "Differentiable Logic Machines",
    "abstract": "The integration of reasoning, learning, and decision-making is key to build more general artificial intelligence systems. As a step in this direction, we propose a novel neural-logic architecture, called differentiable logic machine (DLM), that can solve both inductive logic programming (ILP) and reinforcement learning (RL) problems, where the solution can be interpreted as a first-order logic program. Our proposition includes several innovations. Firstly, our architecture defines a restricted but expressive continuous relaxation of the space of first-order logic programs by assigning weights to predicates instead of rules, in contrast to most previous neural-logic approaches. Secondly, with this differentiable architecture, we propose several (supervised and RL) training procedures, based on gradient descent, which can recover a fully-interpretable solution (i.e., logic formula). Thirdly, to accelerate RL training, we also design a novel critic architecture that enables actor-critic algorithms. Fourthly, to solve hard problems, we propose an incremental training procedure that can learn a logic program progressively. Compared to state-of-the-art (SOTA) differentiable ILP methods, DLM successfully solves all the considered ILP problems with a higher percentage of successful seeds (up to 3.5x). On RL problems, without requiring an interpretable solution, DLM outperforms other non-interpretable neural-logic RL approaches in terms of rewards (up to 3.9%). When enforcing interpretability, DLM can solve harder RL problems (e.g., Sorting, Path) than other interpretable RL methods. Moreover, we show that deep logic programs can be learned via incremental supervised training. In addition to this excellent performance, DLM can scale well in terms of memory and computational time, especially during the testing phase where it can deal with much more constants (>2x) than SOTA",
    "volume": "main",
    "checked": true,
    "id": "411356eb1c5f006c0f6f89d1c59bbcc0acba8d8d",
    "citation_count": 9
  },
  "https://openreview.net/forum?id=kdPcLdJbt1": {
    "title": "Vulnerability-Aware Instance Reweighting For Adversarial Training",
    "abstract": "Adversarial Training (AT) has been found to substantially improve the robustness of deep learning classifiers against adversarial attacks. AT involves obtaining robustness by including adversarial examples in training a classifier. Most variants of AT algorithms treat every training example equally. However, recent works have shown that better performance is achievable by treating them unequally. In addition, it has been observed that AT exerts an uneven influence on different classes in a training set and unfairly hurts examples corresponding to classes that are inherently harder to classify. Consequently, various reweighting schemes have been proposed that assign unequal weights to robust losses of individual examples in a training set. In this work, we propose a novel instance-wise reweighting scheme. It considers the vulnerability of each natural example and the resulting information loss on its adversarial counterpart occasioned by adversarial attacks. Through extensive experiments, we show that our proposed method significantly improves over existing reweighting schemes, especially against strong white and black-box attacks",
    "volume": "main",
    "checked": true,
    "id": "544a68888a72406b86732d84447b00b769994509",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=V7tahqGrOq": {
    "title": "Lifelong Reinforcement Learning with Modulating Masks",
    "abstract": "Lifelong learning aims to create AI systems that continuously and incrementally learn during a lifetime, similar to biological learning. Attempts so far have met problems, including catastrophic forgetting, interference among tasks, and the inability to exploit previous knowledge. While considerable research has focused on learning multiple supervised classification tasks that involve changes in the input distribution, lifelong reinforcement learning (LRL) must deal with variations in the state and transition distributions, and in the reward functions. Modulating masks with a fixed backbone network, recently developed for classification, are particularly suitable to deal with such a large spectrum of task variations. In this paper, we adapted modulating masks to work with deep LRL, specifically PPO and IMPALA agents. The comparison with LRL baselines in both discrete and continuous RL tasks shows superior performance. We further investigated the use of a linear combination of previously learned masks to exploit previous knowledge when learning new tasks: not only is learning  faster, the algorithm solves tasks that we could not otherwise solve from scratch due to extremely sparse rewards. The results suggest that RL with modulating masks is a promising approach to lifelong learning, to the composition of knowledge to learn increasingly complex tasks, and to knowledge reuse for efficient and faster learning",
    "volume": "main",
    "checked": true,
    "id": "c0a41fbf0abc2f5c05cdbdd59a2ea9814f28e81b",
    "citation_count": 6
  },
  "https://openreview.net/forum?id=ILNqQhGbLx": {
    "title": "Semantic Self-adaptation: Enhancing Generalization with a Single Sample",
    "abstract": "The lack of out-of-domain generalization is a critical weakness of deep networks for semantic segmentation. Previous studies relied on the assumption of a static model, i. e., once the training process is complete, model parameters remain fixed at test time. In this work, we challenge this premise with a self-adaptive approach for semantic segmentation that adjusts the inference process to each input sample. Self-adaptation operates on two levels. First, it fine-tunes the parameters of convolutional layers to the input image using consistency regularization. Second, in Batch Normalization layers, self-adaptation interpolates between the training and the reference distribution derived from a single test sample. Despite both techniques being well known in the literature, their combination sets new state-of-the-art accuracy on synthetic-to-real generalization benchmarks. Our empirical study suggests that self-adaptation may complement the established practice of model regularization at training time for improving deep network generalization to out-of-domain data. Our code and pre-trained models are available at https://github.com/visinf/self-adaptive",
    "volume": "main",
    "checked": true,
    "id": "352a368136359bc8031bca42a835d1da7b6b010d",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=MyQ1e1VQQ3": {
    "title": "Fair Kernel Regression through Cross-Covariance Operators",
    "abstract": "Ensuring fairness in machine learning models is a difficult problem from both a formulation and implementation perspective. One sensible criterion for achieving fairness is Equalised Odds, which requires that subjects in protected and unprotected groups have equal true and false positive rates. However, practical implementation is challenging. This work proposes two ways to address this issue through the conditional independence operator. First, given the output values, it is used as a fairness measure of independence between model predictions and sensitive variables. Second, it is used as a regularisation term in the problem formulation, which seeks optimal models that balance performance and fairness concerning the sensitive variables. To illustrate the potential of our approach, we consider different scenarios. First, we use the Gaussian model to provide new insights into the problem formulation and numerical results on its convergence. Second, we present the formulation using the conditional cross-covariance operator. We anticipate that a closed-form solution is possible in the general problem formulation, including in the case of a kernel formulation setting. Third, we introduce a normalised criterion of the conditional independence operator. All formulations are posed under the risk minimisation principle, which leads to theoretical results on the performance.\nAdditionally, insights are provided into using these operators under a Gaussian Process setting. Our methods are compared to state-of-the-art methods in terms of performance and fairness metrics on a representative set of real problems. The results obtained with our proposed methodology show promising performance-fairness curves. Furthermore, we discuss the usefulness of linear weights in the fair model to describe the behaviour of the features when enforcing fairness over a particular set of input features",
    "volume": "main",
    "checked": false,
    "id": "64226b9fa39fb24e8ad5fe594151867bb198ab8f",
    "citation_count": 21
  },
  "https://openreview.net/forum?id=dpGSNLUCzu": {
    "title": "The Score-Difference Flow for Implicit Generative Modeling",
    "abstract": "Implicit generative modeling (IGM) aims to produce samples of synthetic data matching the characteristics of a target data distribution.  Recent work (e.g. score-matching networks, diffusion models) has approached the IGM problem from the perspective of pushing synthetic source data toward the target distribution via dynamical perturbations or flows in the ambient space.  In this direction, we present the score difference (SD) between arbitrary target and source distributions as a flow that optimally reduces the Kullback-Leibler divergence between them while also solving the Schrödinger bridge problem.  We apply the SD flow to convenient proxy distributions, which are aligned if and only if the original distributions are aligned.  We demonstrate the formal equivalence of this formulation to denoising diffusion models under certain conditions.  We also show that the training of generative adversarial networks includes a hidden data-optimization sub-problem, which induces the SD flow under certain choices of loss function when the discriminator is optimal. As a result, the SD flow provides a theoretical link between model classes that individually address the three challenges of the \"generative modeling trilemma\"—high sample quality, mode coverage, and fast sampling—thereby setting the stage for a unified approach",
    "volume": "main",
    "checked": true,
    "id": "19717d2dfa9387d9ebe5c2b3d7f9dc7f42b3e4d2",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=tLBjsX4tjs": {
    "title": "A Unified Perspective on Natural Gradient Variational Inference with Gaussian Mixture Models",
    "abstract": "Variational inference with Gaussian mixture models (GMMs) enables learning of highly tractable yet multi-modal approximations of intractable target distributions with up to a few hundred dimensions. The two currently most effective methods for GMM-based variational inference, VIPS and iBayes-GMM, both employ independent natural gradient updates for the individual components and their weights. We show for the first time, that their derived updates are equivalent, although their practical implementations and theoretical guarantees differ. We identify several design choices that distinguish both approaches, namely with respect to sample selection, natural gradient estimation, stepsize adaptation, and whether trust regions are enforced or the number of components adapted. We argue that for both approaches, the quality of the learned approximations can heavily suffer from the respective design choices: By updating the individual components using samples from the mixture model, iBayes-GMM often fails to produce meaningful updates to low-weight components, and by using a zero-order method for estimating the natural gradient, VIPS scales badly to higher-dimensional problems. Furthermore, we show that information-geometric trust-regions (used by VIPS) are effective even when using first-order natural gradient estimates, and often outperform the improved Bayesian learning rule (iBLR) update used by iBayes-GMM. We systematically evaluate the effects of design choices and show that a hybrid approach significantly outperforms both prior works. Along with this work, we publish our highly modular and efficient implementation for natural gradient variational inference with Gaussian mixture models, which supports $432$ different combinations of design choices, facilitates the reproduction of all our experiments, and may prove valuable for the practitioner",
    "volume": "main",
    "checked": true,
    "id": "a45bb667e33e75af9dda50108a543faf6344ab86",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=FbztvhdCX9": {
    "title": "On the Gradient Formula for learning Generative Models with Regularized Optimal Transport Costs",
    "abstract": "Learning a Wasserstein Generative Adversarial Networks (WGAN) requires the differentiation of the optimal transport cost with respect to the parameters of the generative model. In this work, we provide sufficient conditions for the  existence of a gradient formula in two different frameworks: the case of semi-discrete optimal transport (i.e. with a discrete target distribution) and the case of regularized optimal transport (i.e. with an entropic penalty). In both cases the gradient formula involves a solution of the semi-dual formulation of the optimal transport cost. Our study makes a connection between the gradient of the WGAN loss function and the Laguerre diagrams associated to semi-discrete transport maps. The learning problem is addressed with an alternating algorithm, which is in general not convergent. However, in most cases, it stabilizes close to a relevant  solution for the generative learning problem. We also show that entropic regularization can improve the convergence speed but noticeably changes the shape of the learned generative model",
    "volume": "main",
    "checked": true,
    "id": "a95b8fa116e60976e8256d124780c6cce17b8acc",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=HP7Qpui5YE": {
    "title": "Understanding Self-Supervised Pretraining with Part-Aware Representation Learning",
    "abstract": "In this paper, we are interested in understanding self-supervised pretraining through studying the capability that self-supervised methods learn part-aware representations. The study is mainly motivated by that random views, used in contrastive learning, and random masked (visible) patches, used in masked image modeling, are often about object parts. \n\nWe explain that contrastive learning is a part-to-whole task: the projection layer hallucinates the whole object representation from the object part representation learned from the encoder, and that masked image modeling is a part-to-part task: the masked patches of the object are hallucinated from the visible patches. The explanation suggests that the self-supervised pretrained encoder leans toward understanding the object part. We empirically compare the off-the-shelf encoders pretrained with several representative methods on object-level recognition and part-level recognition. The results show that the fully-supervised model outperforms self-supervised models for object-level recognition, and most self-supervised contrastive learning and masked image modeling methods outperform the fully-supervised method for part-level recognition. It is observed that the combination of contrastive learning and masked image modeling further improves the performance",
    "volume": "main",
    "checked": true,
    "id": "fb28002574cf7e6f08a10e3fb39b8f05bc4bad7b",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=SaVEXFuozg": {
    "title": "DSpar: An Embarrassingly Simple Strategy for Efficient GNN training and inference via Degree-based Sparsification",
    "abstract": "Running Graph Neural Networks (GNNs) on large graphs suffers from notoriously inefficiency.  This is attributed to the sparse graph-based operations, which is hard to be accelerated by community hardware, e.g., GPUs and CPUs. One potential solution is to  ``sketch'' the original graph by removing unimportant edges, then both the training and inference process are executed on the sparsified graph with improved efficiency. Traditional graph sparsification work calculates the edge importance score, i.e., effective resistance, from graph topology with theoretical guarantee. However, estimating effective resistance is even more expensive than training GNNs itself. Later, learning-based sparsification methods propose to learn the edge importance from data, but with significant overhead due to the extra learning process. Thus, both of them introduce significant ahead-of-training overhead. In this paper, we experimentally and theoretically prove that effective resistance can be approximated using only the node degree information and achieve similar node presentations on graph with/without sparsification. Based on this finding, we propose DSpar, to sparsify the graph once before training based on only the node degree information with negligible ahead-of-training overhead. In practice, for the training phase, DSpar achieves up to $5.9\\times$ faster than baseline with almost no accuracy drop. For the inference phase, DSpar reduces up to $90\\%$ latency",
    "volume": "main",
    "checked": false,
    "id": "809e2aedcbc3703ab6fbf31450b6c115fe00efca",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=1QqIfGZOWu": {
    "title": "Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations",
    "abstract": "Offline reinforcement learning has shown great promise in leveraging large pre-collected datasets for policy learning, allowing agents to forgo often-expensive online data collection. However, offline reinforcement learning from visual observations with continuous action spaces remains under-explored, with a limited understanding of the key challenges in this complex domain. In this paper, we establish simple baselines for continuous control in the visual domain and introduce a suite of benchmarking tasks for offline reinforcement learning from visual observations designed to better represent the data distributions present in real-world offline RL problems and guided by a set of desiderata for offline RL from visual observations, including robustness to visual distractions and visually identifiable changes in dynamics. Using this suite of benchmarking tasks, we show that simple modifications to two popular vision-based online reinforcement learning algorithms, DreamerV2 and DrQ-v2, suffice to outperform existing offline RL methods and establish competitive baselines for continuous control in the visual domain. We rigorously evaluate these algorithms and perform an empirical evaluation of the differences between state-of-the-art model-based and model-free offline RL methods for continuous control from visual observations. All code and data used in this evaluation are open-sourced to facilitate progress in this domain",
    "volume": "main",
    "checked": true,
    "id": "fb61b640944044b92e093b4622c8dbed6ebdd8e8",
    "citation_count": 21
  },
  "https://openreview.net/forum?id=LEVbhNrLEL": {
    "title": "Mind the Gap: Mitigating the Distribution Gap in Graph Few-shot Learning",
    "abstract": "Prevailing supervised deep graph learning models often suffer from the issue of label scarcity, leading to performance degradation in the face of limited annotated data. Although numerous graph few-shot learning (GFL) methods have been developed to mitigate this problem, they tend to rely excessively on labeled data. This over-reliance on labeled data can result in impaired generalization ability in the test phase due to the existence of a distribution gap. Moreover, existing GFL methods lack a general purpose as their designs are coupled with task or data-specific characteristics. To address these shortcomings, we propose a novel Self-Distilled Graph Few-shot Learning framework (SDGFL) that is both general and effective. SDGFL leverages a self-distilled contrastive learning procedure to boost GFL. Specifically, our model first pre-trains a graph encoder with contrastive learning using unlabeled data. Later, the trained encoder is frozen as a teacher model to distill a student model with a contrastive loss. The distilled model is then fed to GFL. By learning data representation in a self-supervised manner, SDGFL effectively mitigates the distribution gap and enhances generalization ability. Furthermore, our proposed framework is task and data-independent, making it a versatile tool for general graph mining purposes. To evaluate the effectiveness of our proposed framework, we introduce an information-based measurement that quantifies its capability. Through comprehensive experiments, we demonstrate that SDGFL outperforms state-of-the-art baselines on various graph mining tasks across multiple datasets in the few-shot scenario. We also provide a quantitative measurement of SDGFL’s superior performance in comparison to existing methods",
    "volume": "main",
    "checked": true,
    "id": "8c945d9ebce699687fe10ed9d6f2a3c4721842ba",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=HqIuAzBxbh": {
    "title": "Consistent Collaborative Filtering via Tensor Decomposition",
    "abstract": "Collaborative filtering is the de facto standard for analyzing users’ activities and building recommendation systems for items. In this work we develop Sliced Anti-symmetric Decomposition (SAD), a new model for collaborative filtering based on implicit feedback. In contrast to traditional techniques where a latent representation of users (user vectors) and items (item vectors) are estimated, SAD introduces one additional latent vector to each item, using a novel three-way tensor view of user-item interactions. This new vector extends user-item preferences calculated by standard dot products to general inner products, producing interactions between items when evaluating their relative preferences. SAD reduces to state-of-the-art (SOTA) collaborative filtering models when the vector collapses to 1, while in this paper we allow its value to be estimated from data. Allowing the values of the new item vector to be different from 1 has profound implications. It suggests users may have nonlinear mental models when evaluating items, allowing the existence of cycles in pairwise comparisons. We demonstrate the efficiency of SAD in both simulated and real world datasets containing over 1M user-item interactions. By comparing with seven SOTA collaborative filtering models with implicit feedbacks, SAD produces the most consistent personalized preferences, in the meanwhile maintaining top-level of accuracy in personalized recommendations. We release the model and inference algorithms in a Python library https://github.com/apple/ml-sad",
    "volume": "main",
    "checked": true,
    "id": "0dccc06f3f05b7174be9756142a795579f6c6eb5",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=jkTqJJOGMS": {
    "title": "Provably Convergent Policy Optimization via Metric-aware Trust Region Methods",
    "abstract": "Trust-region methods based on Kullback-Leibler divergence are pervasively used to stabilize policy optimization in reinforcement learning. In this paper, we exploit more flexible metrics and examine two natural extensions of policy optimization with Wasserstein and Sinkhorn trust regions, namely Wasserstein policy optimization (WPO) and Sinkhorn policy optimization (SPO). Instead of restricting the policy to a parametric distribution class, we directly optimize the policy distribution and derive their close-form policy updates based on the Lagrangian duality. Theoretically, we show that WPO guarantees a monotonic performance improvement, and SPO provably converges to WPO as the entropic regularizer diminishes. Moreover, we prove that with a decaying Lagrangian multiplier to the trust region constraint, both methods converge to global optimality. Experiments across tabular domains, robotic locomotion, and continuous control tasks further demonstrate the performance improvement of both approaches, more robustness of WPO to sample insufficiency, and faster convergence of SPO, over state-of-art policy gradient methods",
    "volume": "main",
    "checked": true,
    "id": "2732028656ffa7c240932d38a7e134747c2aefeb",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=P6NcRPb13w": {
    "title": "Adjusting Machine Learning Decisions for Equal Opportunity and Counterfactual Fairness",
    "abstract": "Machine learning (ML) methods have the potential to automate\nhigh-stakes decisions, such as bail admissions or credit lending, by\nanalyzing and learning from historical data. But these algorithmic\ndecisions may be unfair: in learning from historical data, they may\nreplicate discriminatory practices from the past.  In this paper, we\npropose two algorithms that adjust fitted ML predictors to produce\ndecisions that are fair.  Our methods provide post-hoc adjustments to\nthe predictors, without requiring that they be retrained.  We consider\na causal model of the ML decisions, define fairness through\ncounterfactual decisions within the model, and then form algorithmic\ndecisions that capture the historical data as well as possible but\nare provably fair.  In particular, we consider two definitions of\nfairness.  The first is ``equal counterfactual opportunity,'' where\nthe counterfactual distribution of the decision is the same regardless\nof the protected attribute; the second is counterfactual fairness.  We\nevaluate the algorithms, and the trade-off between accuracy and\nfairness, on datasets about admissions, income, credit, and\nrecidivism",
    "volume": "main",
    "checked": true,
    "id": "cb39129d23d427b397d930bca1079a7b8d0176c6",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=JJrKbq35l4": {
    "title": "On Average-Case Error Bounds for Kernel-Based Bayesian Quadrature",
    "abstract": "In this paper, we study error bounds for Bayesian quadrature (BQ), with an emphasis on noisy settings, randomized algorithms, and average-case performance measures.  We seek to approximate the integral of functions in a Reproducing Kernel Hilbert Space (RKHS), particularly focusing on the Mat\\'ern-$\\nu$ and squared exponential (SE) kernels, with samples from the function potentially being corrupted by Gaussian noise.  We provide a two-step meta-algorithm that serves as a general tool for relating the average-case quadrature error with the $L^2$-function approximation error. When specialized to the Mat\\'ern kernel, we recover an existing near-optimal error rate while avoiding the existing method of repeatedly sampling points.  When specialized to other settings, we obtain new average-case results for settings including the SE kernel with noise and the Mat\\'ern kernel with misspecification.  Finally, we present algorithm-independent lower bounds that have greater generality and/or give distinct proofs compared to existing ones",
    "volume": "main",
    "checked": true,
    "id": "013e187dbf20d5153198b74cef2382b8d47b5413",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=ThhMzfrd6r": {
    "title": "Self-Supervised Graph Representation Learning for Neuronal Morphologies",
    "abstract": "Unsupervised graph representation learning has recently gained interest in several application domains such as neuroscience, where modeling the diverse morphology of cell types in the brain is one of the key challenges. It is currently unknown how many excitatory cortical cell types exist and what their defining morphological features are. Here we present GraphDINO, a purely data-driven approach to learn low-dimensional representations of 3D neuronal morphologies from unlabeled large-scale datasets. GraphDINO is a novel transformer-based representation learning method for spatially-embedded graphs. To enable self-supervised learning on transformers, we (1) developed data augmentation strategies for spatially-embedded graphs, (2) adapted the positional encoding and (3) introduced a novel attention mechanism, AC-Attention, which combines attention-based global interaction between nodes and classic graph convolutional processing. We show, in two different species and across multiple brain areas, that this method yields morphological cell type clusterings that are on par with manual feature-based classification by experts, but without using prior knowledge about the structural features of neurons. Moreover, it outperforms previous approaches on quantitative benchmarks predicting expert labels. Our method could potentially enable data-driven discovery of novel morphological features and cell types in large-scale datasets. It is applicable beyond neuroscience in settings where samples in a dataset are graphs and graph-level embeddings are desired",
    "volume": "main",
    "checked": true,
    "id": "804f1bff8f76488c13657f492b5c9d2523ad3a45",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=VV4zJwLwI7": {
    "title": "Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling",
    "abstract": "Trying to capture the sample-label relationship, conditional generative models often end up inheriting the spurious correlation in the training dataset, giving label-conditional distributions that are severely imbalanced in another latent attribute. To mitigate such undesirable correlations engraved into generative models, which we call spurious causality, we propose a general two-step strategy. (a) Fairness Intervention (FI): Emphasize the minority samples that are hard to be generated due to the spurious correlation in the training dataset. (b) Corrective Sampling (CS): Filter the generated samples explicitly to follow the desired label-conditional latent attribute distribution. We design the fairness intervention for various degrees of supervision on the spurious attribute, including unsupervised, weakly-supervised, and semi-supervised scenarios. Our experimental results show that the proposed FICS can successfully resolve the spurious correlation in generated samples on various datasets",
    "volume": "main",
    "checked": true,
    "id": "a7cf8f52c7797f2015ab9600cfb4f2993379acb9",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=VpaXrBFYZ9": {
    "title": "Stochastic Constrained DRO with a Complexity Independent of Sample Size",
    "abstract": "Distributionally Robust Optimization (DRO), as a popular method to train robust models against distribution shift between training and test sets, has received tremendous attention in recent years. In this paper, we propose and analyze stochastic algorithms that apply to both non-convex and convex losses for solving Kullback–Leibler divergence constrained DRO problem. Compared with existing methods solving this problem, our stochastic algorithms not only enjoy competitive if not better complexity independent of sample size but also just require a constant batch size at every iteration, which is more practical for broad applications. We establish a nearly optimal complexity bound for finding an $\\epsilon$-stationary solution for non-convex losses and an optimal complexity for finding an $\\epsilon$-optimal solution for convex losses. Empirical studies demonstrate the effectiveness of the proposed algorithms for solving non-convex and convex constrained DRO problems",
    "volume": "main",
    "checked": true,
    "id": "8fdd4a57c62be9a3d1306b2dad56efc4c5adf08a",
    "citation_count": 5
  },
  "https://openreview.net/forum?id=nddEHTSnqg": {
    "title": "Neural Networks beyond explainability: Selective inference for sequence motifs",
    "abstract": "Over the past decade, neural networks have been successful at making predictions from biological sequences, especially in the context of regulatory genomics. As in other fields of deep learning, tools have been devised to extract features such as sequence motifs that can explain the predictions made by a trained network. Here we intend to go beyond explainable machine learning and introduce SEISM, a selective inference procedure to test the association between these extracted features and the predicted phenotype. In particular, we discuss how training a one-layer convolutional network is formally equivalent to selecting motifs maximizing some association score. We adapt existing sampling-based selective inference procedures by quantizing this selection over an infinite set to a large but finite grid. Finally,we show that sampling under a specific choice of parameters is sufficient to characterize the composite null hypothesis typically used for selective inference - a result that goes well beyond our particular framework. We illustrate the behavior of our method in terms of calibration, power and speed and discuss its power/speed trade-off with a simpler data-split strategy. SEISM paves the way to an easier analysis of neural networks used in regulatory genomics, and to more powerful methods for genome wide association studies (GWAS)",
    "volume": "main",
    "checked": true,
    "id": "206b19e38788b5bb0ea8bedac2a1a8fd43f6375f",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=w36pqfaJ4t": {
    "title": "Dynamics Adapted Imitation Learning",
    "abstract": "We consider Imitation Learning with dynamics variation between the expert demonstration (source domain) and the environment (target domain). Based on the popular framework of Adversarial Imitation Learning, we propose a novel algorithm – Dynamics Adapted Imitation Learning (DYNAIL), which incorporates the dynamics variation into the state-action occupancy measure matching as a regularization term. The dynamics variation is modeled by a pair of classifiers to distinguish between source dynamics and target dynamics. Theoretically, we provide an upper bound on the divergence between the learned policy and expert demonstrations in the source domain. Our error bound only depends on the expectation of the discrepancy between the source and target dynamics for the optimal policy in the target domain. The experiment evaluation validates that our method achieves superior results on high dimensional continuous control tasks, compared to existing imitation learning methods",
    "volume": "main",
    "checked": true,
    "id": "e436df13213f288a3f398482b2a540f1c0602eb9",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=CkXOwlhf27": {
    "title": "A Proximal Algorithm for Sampling",
    "abstract": "We study sampling problems associated with potentials that lack smoothness. The potentials can be either convex or non-convex. Departing from the standard smooth setting, the potentials are only assumed to be weakly smooth or non-smooth, or the summation of multiple such functions. We develop a sampling algorithm that resembles proximal algorithms in optimization for this challenging sampling task. Our algorithm is based on a special case of Gibbs sampling known as the alternating sampling framework (ASF). The key contribution of this work is a practical realization of the ASF based on rejection sampling for both non-convex and convex potentials that are not necessarily smooth. In almost all the cases of sampling considered in this work, our proximal sampling algorithm achieves a better\ncomplexity than all existing methods",
    "volume": "main",
    "checked": true,
    "id": "be5a49e6dc47608a36cf8ac8f4ec80088e133023",
    "citation_count": 7
  },
  "https://openreview.net/forum?id=j3FK00HyfU": {
    "title": "The Meta-Evaluation Problem in Explainable AI: Identifying Reliable Estimators with MetaQuantus",
    "abstract": "One of the unsolved challenges in the field of Explainable AI (XAI) is determining how to most reliably estimate the quality of an explanation method in the absence of ground truth explanation labels. Resolving this issue is of utmost importance as the evaluation outcomes generated by competing evaluation methods (or ``quality estimators''), which aim at measuring the same property of an explanation method, frequently present conflicting rankings. Such disagreements can be challenging for practitioners to interpret, thereby complicating their ability to select the best-performing explanation method. We address this problem through a meta-evaluation of different quality estimators in XAI, which we define as ``the process of evaluating the evaluation method''. Our novel framework, MetaQuantus, analyses two complementary performance characteristics of a quality estimator: its resilience to noise and reactivity to randomness, thus circumventing the need for ground truth labels. We demonstrate the effectiveness of our framework through a series of experiments, targeting various open questions in XAI such as the selection and hyperparameter optimisation of quality estimators. Our work is released under an open-source license (https://github.com/annahedstroem/MetaQuantus) to serve as a development tool for XAI- and Machine Learning (ML) practitioners to verify and benchmark newly constructed quality estimators in a given explainability context. With this work, we provide the community with clear and theoretically-grounded guidance for identifying reliable evaluation methods, thus facilitating reproducibility in the field",
    "volume": "main",
    "checked": true,
    "id": "b90f732d484babfbdbe47d765c1f25ee3507451f",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=LdSP6cvTS4": {
    "title": "Calibrating and Improving Graph Contrastive Learning",
    "abstract": "Graph contrastive learning algorithms have demonstrated remarkable success in various applications such as node classification, link prediction, and graph clustering. However, in unsupervised graph contrastive learning, some contrastive pairs may contradict the truths in downstream tasks and thus the decrease of losses on these pairs undesirably harms the performance in the downstream tasks. To assess the discrepancy between the prediction and the ground-truth in the downstream tasks for these contrastive pairs, we adapt expected calibration error (ECE) to graph contrastive learning. The analysis of ECE motivates us to propose a novel regularization method, Contrast-Reg, to ensure that decreasing the contrastive loss leads to better performance in the downstream tasks. As a plug-in regularizer, Contrast-Reg effectively improves the performance of existing graph contrastive learning algorithms. We provide both theoretical and empirical results to demonstrate the effectiveness of Contrast-Reg in enhancing the generalizability of the Graph Neural Network (GNN) model and improving the performance of graph contrastive algorithms with different similarity definitions and encoder backbones across various downstream tasks",
    "volume": "main",
    "checked": true,
    "id": "5436fdb817e7d6a494af26fff8a28c5714f22f8f",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=oqOBTo5uWD": {
    "title": "Supervised Knowledge May Hurt Novel Class Discovery Performance",
    "abstract": "Novel class discovery (NCD) aims to infer novel categories in an unlabeled dataset by leveraging prior knowledge of a labeled set comprising disjoint but related classes. Given that most existing literature focuses primarily on utilizing supervised knowledge from a labeled set at the methodology level, this paper considers the question: Is supervised knowledge always helpful at different levels of semantic relevance? To proceed, we first establish a novel metric, so-called transfer leakage, to measure the semantic similarity between labeled/unlabeled datasets. To show the validity of the proposed metric, we build up a large-scale benchmark with various degrees of semantic similarities between labeled/unlabeled datasets on ImageNet by leveraging its hierarachical class structure. The results based on the proposed benchmark show that the proposed transfer leakage is in line with the hierarachical class structure; and that NCD performance is consistent with the semantic similarities (measured by the proposed metric). Next, by using the proposed transfer leakage, we conduct various empirical experiments with different levels of semantic similarity, yielding that supervised knowledge may hurt NCD performance. Specifically, using supervised information from a low-similarity labeled set may lead to a suboptimal result as compared to using pure self-supervised knowledge. These results reveal the inadequacy of the existing NCD literature which usually assumes that supervised knowledge is beneficial. Finally, we develop a pseudo-version of the transfer leakage as a practical reference to decide if supervised knowledge should be used in NCD. Its effectiveness is supported by our empirical studies, which show that the pseudo transfer leakage (with or without supervised knowledge) is consistent with the corresponding accuracy based on various datasets",
    "volume": "main",
    "checked": true,
    "id": "45035ac3ca5f5f89a07f66f848d364e3e10681d6",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=nfYwRIezvg": {
    "title": "DORA: Exploring Outlier Representations in Deep Neural Networks",
    "abstract": "Deep Neural Networks (DNNs) excel at learning complex abstractions within their internal representations. However, the concepts they learn remain opaque, a problem that becomes particularly acute when models unintentionally learn spurious correlations. In this work, we present DORA (Data-agnOstic Representation Analysis), the first data-agnostic framework for analyzing the representational space of DNNs. Central to our framework is the proposed Extreme-Activation (EA) distance measure, which assesses similarities between representations by analyzing their activation patterns on data points that cause the highest level of activation. As spurious correlations often manifest in features of data that are anomalous to the desired task, such as watermarks or artifacts, we demonstrate that internal representations capable of detecting such artifactual concepts can be found by analyzing relationships within neural representations. We validate the EA metric quantitatively, demonstrating its effectiveness both in controlled scenarios and real-world applications. Finally, we provide practical examples from popular Computer Vision models to illustrate that representations identified as outliers using the EA metric often correspond to undesired and spurious concepts",
    "volume": "main",
    "checked": true,
    "id": "93f691020a216dc3a6079ef04b422d8f3a215da0",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=g97OHbQyk1": {
    "title": "The Vendi Score: A Diversity Evaluation Metric for Machine Learning",
    "abstract": "Diversity is an important criterion for many areas of machine learning (ML), including generative modeling and dataset curation. However, existing metrics for measuring diversity are often domain-specific and limited in flexibility. In this paper we address the diversity evaluation problem by proposing the Vendi Score, which connects and extends ideas from ecology and quantum statistical mechanics to ml. The Vendi Score is defined as the exponential of the Shannon entropy of the eigenvalues of a similarity matrix. This matrix is induced by a user-defined similarity function applied to the sample to be evaluated for diversity. In taking a similarity function as input, the Vendi Score enables its user to specify any desired form of diversity. Importantly, unlike many existing metrics in ML, the Vendi Score does not require a reference dataset or distribution over samples or labels, it is therefore general and applicable to any generative model, decoding algorithm, and dataset from any domain where similarity can be defined. We showcase the Vendi Score on molecular generative modeling where we found it addresses shortcomings of the current diversity metric of choice in that domain. We also applied the Vendi Score to generative models of images and decoding algorithms of text where we found it confirms known results about diversity in those domains. Furthermore, we used the Vendi Score to measure mode collapse, a known shortcoming of generative adversarial networks (GANs). In particular, the Vendi Score revealed that even GANs that capture all the modes of a labelled dataset can be less diverse than the original dataset. Finally, the interpretability of the Vendi Score allowed us to diagnose several benchmark ML datasets for diversity, opening the door for diversity-informed data augmentation",
    "volume": "main",
    "checked": true,
    "id": "b03c078303326ff022f525fccdf028b73ccb1cb4",
    "citation_count": 5
  },
  "https://openreview.net/forum?id=OqbGu3hdQb": {
    "title": "Contextual Combinatorial Multi-output GP Bandits with Group Constraints",
    "abstract": "In federated multi-armed bandit problems, maximizing global reward while satisfying minimum privacy requirements to protect clients is the main goal. To formulate such problems, we consider a combinatorial contextual bandit setting with groups and changing action sets, where similar base arms arrive in groups and a set of base arms, called a super arm, must be chosen in each round to maximize super arm reward while satisfying the constraints of the rewards of groups from which base arms were chosen. To allow for greater flexibility, we let each base arm have two outcomes, modeled as the output of a two-output Gaussian process (GP), where one outcome is used to compute super arm reward and the other for group reward. We then propose a novel double-UCB GP-bandit algorithm, called Thresholded Combinatorial Gaussian Process Upper Confidence Bounds (TCGP-UCB), which balances between maximizing cumulative super arm reward and satisfying group reward constraints and can be tuned to prefer one over the other. We also define a new notion of regret that combines super arm regret with group reward constraint satisfaction and prove that TCGP-UCB incurs $\\tilde{O}(\\sqrt{KT\\overline{\\gamma}_{T}} )$ regret with high probability, where $\\overline{\\gamma}_{T}$ is the maximum information gain associated with the set of base arm contexts that appeared in the first $T$ rounds and $K$ is the maximum super arm cardinality over all rounds. We lastly show in experiments using synthetic and real-world data and based on a federated learning setup as well as a content-recommendation one that our algorithm performs better then the current non-GP state-of-the-art combinatorial bandit algorithm, while satisfying group constraints",
    "volume": "main",
    "checked": true,
    "id": "e514ef53e5e44559cb403bf3cb6a7cad57e0938e",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=Gbu1bHQhEL": {
    "title": "Active Acquisition for Multimodal Temporal Data: A Challenging Decision-Making Task",
    "abstract": "We introduce a challenging decision-making task that we call active acquisition for multimodal temporal data (A2MT). In many real-world scenarios, input features are not readily available at test time and must instead be acquired at significant cost. With A2MT, we aim to learn agents that actively select which modalities of an input to acquire, trading off acquisition cost and predictive performance. A2MT extends a previous task called active feature acquisition to temporal decision making about high-dimensional inputs. We propose a method based on the Perceiver IO architecture to address A2MT in practice. Our agents are able to solve a novel synthetic scenario requiring practically relevant cross-modal reasoning skills. On two large-scale, real-world datasets, Kinetics-700 and AudioSet, our agents successfully learn cost-reactive acquisition behavior. However, an ablation reveals they are unable to learn adaptive acquisition strategies, emphasizing the difficulty of the task even for state-of-the-art models. Applications of A2MT may be impactful in domains like medicine, robotics, or finance, where modalities differ in acquisition cost and informativeness",
    "volume": "main",
    "checked": true,
    "id": "56b35f7bca65566543469e79b04497e3d7436637",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=gwRwHUZUgz": {
    "title": "Learning Symbolic Rules for Reasoning in Quasi-Natural Language",
    "abstract": "Symbolic reasoning, rule-based symbol manipulation, is a hallmark of human intelligence. However, rule-based systems have had limited success competing with learning-based systems outside formalized domains such as automated theorem proving. We hypothesize that this is due to the manual construction of rules in past attempts. In this work, we take initial steps towards rule-based systems that can reason with natural language but without manually constructing rules. We propose MetaQNL, a \"Quasi-Natural Language\" that can express both formal logic and natural language sentences, and MetaInduce, a learning algorithm that induces MetaQNL rules from training data consisting of questions and answers, with or without intermediate reasoning steps. In addition, we introduce soft matching—a flexible mechanism for applying rules without rigid matching, overcoming a typical source of brittleness in symbolic reasoning. Our approach achieves state-of-the-art accuracies on multiple reasoning benchmarks; it learns compact models with much less data and produces not only answers but also checkable proofs. Further, experiments on two simple real-world datasets demonstrate the possibility for our method to handle noise and ambiguity",
    "volume": "main",
    "checked": true,
    "id": "2cffec40f1d7cfc81d498b8939493243bbcadebe",
    "citation_count": 10
  },
  "https://openreview.net/forum?id=XJIg4kQbkv": {
    "title": "CoCoFL: Communication- and Computation-Aware Federated Learning via Partial NN Freezing and Quantization",
    "abstract": "Devices participating in federated learning (FL) typically have heterogeneous communication, computation, and memory resources. However, in synchronous FL, all devices need to finish training by the same deadline dictated by the server. Our results show that training a smaller subset of the neural network (NN) at constrained devices, i.e., dropping neurons/filters as proposed by state of the art, is inefficient, preventing these devices to make an effective contribution to the model. This causes unfairness w.r.t the achievable accuracies of constrained devices, especially in cases with a skewed distribution of class labels across devices. We present a novel FL technique, CoCoFL, which maintains the full NN structure on all devices. To adapt to the devices’ heterogeneous resources, CoCoFL freezes and quantizes selected layers, reducing communication, computation, and memory requirements, whereas other layers are still trained in full precision, enabling to reach a high accuracy. Thereby, CoCoFL efficiently utilizes the available resources on devices and allows constrained devices to make a significant contribution to the FL system, preserving fairness among participants (accuracy parity) and significantly improving final accuracy",
    "volume": "main",
    "checked": false,
    "id": "518747257702484d80d0d106185eec67c39a57ab",
    "citation_count": 3
  },
  "https://openreview.net/forum?id=TdzQtbLeVw": {
    "title": "Online Min-max Problems with Non-convexity and Non-stationarity",
    "abstract": "Online min-max optimization has recently gained considerable interest due to its rich applications to game theory, multi-agent reinforcement learning, online robust learning, etc. Theoretical understanding in this field has been mainly focused on convex-concave settings. Online min-max optimization with nonconvex geometries, which captures various online deep learning problems, has yet been studied so far. In this paper, we make the first effort and investigate online nonconvex-strongly-concave min-max optimization in the nonstationary environment. We first introduce a natural notion of  local Nash equilibrium (NE)-regret, and then propose a novel algorithm coined TSODA to achieve the optimal regret. We further generalize our study to the setting with stochastic first-order feedback, and show that a variation of TSODA can also achieve the same optimal regret in expectation. Our theoretical results and the superior performance of the proposed method are further validated by empirical experiments. To our best knowledge, this is the first exploration of efficient online nonconvex min-max optimization",
    "volume": "main",
    "checked": false,
    "id": "0cc96b88549fb81e161e446da8a067cedeb814f4",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=LKz5SqIXPJ": {
    "title": "On the Robustness of Dataset Inference",
    "abstract": "Machine learning (ML) models are costly to train as they can require a significant amount of data, computational resources and technical expertise. Thus, they constitute valuable intellectual property that needs protection from adversaries wanting to steal them. Ownership verification techniques allow the victims of model stealing attacks to demonstrate that a suspect model was in fact stolen from theirs. Although a number of ownership verification techniques based on watermarking or fingerprinting have been proposed, most of them fall short either in terms of security guarantees (well-equipped adversaries can evade verification)  or computational cost. A fingerprinting technique, Dataset Inference (DI) has been shown to offer better robustness and efficiency than prior methods. The authors of DI provided a correctness proof for linear (suspect) models. However, in a subspace of the same setting, we prove that DI suffers from high false positives (FPs) -- it can incorrectly identify an independent model trained with non-overlapping data from the same distribution as stolen. We further prove that DI also triggers FPs in realistic, non-linear suspect models. We then confirm empirically that DI in the black-box setting leads to FPs, with high confidence. Second, we show that DI also suffers from false negatives (FNs) -- an adversary can fool DI by regularising a stolen model's decision boundaries using adversarial training, thereby leading to an FN. To this end, we demonstrate that black-box DI fails to identify a model adversarially trained from a stolen dataset -- the setting where DI is the hardest to evade. Finally, we discuss the implications of our findings, the viability of fingerprinting-based ownership verification in general, and suggest directions for future work",
    "volume": "main",
    "checked": true,
    "id": "a46d1f8e5ed6182df8c864e72160372cf2a14b13",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=sY35BAiIf4": {
    "title": "Improving Differentially Private SGD via Randomly Sparsified Gradients",
    "abstract": "Differentially private stochastic gradient descent (DP-SGD) has been widely adopted in deep learning to provide rigorously defined privacy, which requires gradient clipping to bound the maximum norm of individual gradients and additive isotropic Gaussian noise. With analysis of the convergence rate of DP-SGD in a non-convex setting, we identify that randomly sparsifying gradients before clipping and noisification adjusts a trade-off between internal components of the convergence bound and leads to a smaller upper bound when the noise is dominant. Additionally, our theoretical analysis and empirical evaluations show that the trade-off is not trivial but possibly a unique property of DP-SGD, as either canceling noisification or gradient clipping eliminates the trade-off in the bound. This observation is indicative, as it implies DP-SGD has special inherent room for (even simply random) gradient compression. To verify the observation an utilize it, we propose an efficient and lightweight extension using random sparsification (RS) to strengthen DP-SGD.  Experiments with various DP-SGD frameworks show that RS can improve performance. Additionally, the produced sparse gradients of RS exhibit advantages in reducing communication cost and strengthening privacy against reconstruction attacks, which are also key problems in private machine learning",
    "volume": "main",
    "checked": true,
    "id": "ba5b71313ab921d4c79626e537563c6e0614446f",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=p28wv4G65d": {
    "title": "SC2 Benchmark: Supervised Compression for Split Computing",
    "abstract": "With the increasing demand for deep learning models on mobile devices, splitting neural network computation between the device and a more powerful edge server has become an attractive solution. However, existing split computing approaches often underperform compared to a naive baseline of remote computation on compressed data. Recent studies propose learning compressed representations that contain more relevant information for supervised downstream tasks, showing improved tradeoffs between compressed data size and supervised performance. However, existing evaluation metrics only provide an incomplete picture of split computing. This study introduces supervised compression for split computing (SC2) and proposes new evaluation criteria: minimizing computation on the mobile device, minimizing transmitted data size, and maximizing model accuracy. We conduct a comprehensive benchmark study using 10 baseline methods, three computer vision tasks, and over 180 trained models, and discuss various aspects of SC2. We also release our code and sc2bench, a Python package for future research on SC2. Our proposed metrics and package will help researchers better understand the tradeoffs of supervised compression in split computing",
    "volume": "main",
    "checked": true,
    "id": "5592106cb23e8958920a10b211921a96afe65199",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=izL3B8dPx1": {
    "title": "Inherent Limits on Topology-Based Link Prediction",
    "abstract": "Link prediction systems (e.g. recommender systems) typically use graph topology as one of their main sources of information. However,  automorphisms and related properties of graphs beget inherent limits in predictability. We calculate hard upper bounds on how well graph topology alone enables link prediction for a wide variety of real-world graphs. We find that in the sparsest of these graphs the upper bounds are surprisingly low, thereby demonstrating that prediction systems on sparse graph data are inherently limited and require information in addition to the graph topology",
    "volume": "main",
    "checked": true,
    "id": "bb9ed292b35bd82a2ac84fc542b8303b709d7fdd",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=uv32JOdQuh": {
    "title": "Invariant Feature Coding using Tensor Product Representation",
    "abstract": "In this study, a novel feature coding method that exploits invariance for transformations represented by a finite group of orthogonal matrices is proposed. We prove that the group-invariant feature vector contains sufficient discriminative information when learning a linear classifier using convex loss minimization. Based on this result, a novel feature model that explicitly considers group action is proposed for principal component analysis and k-means clustering, which are commonly used in most feature coding methods, and global feature functions. Although the global feature functions are in general complex nonlinear functions, the group action on this space can be easily calculated by constructing these functions as tensor-product representations of basic representations, resulting in an explicit form of invariant feature functions. The effectiveness of our method is demonstrated on several image datasets",
    "volume": "main",
    "checked": true,
    "id": "c595f64229647e03be95502885b3391ff1a1d7c3",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=wk8oXR0kFA": {
    "title": "Releasing Graph Neural Networks with Differential Privacy Guarantees",
    "abstract": "With the increasing popularity of graph neural networks (GNNs) in several sensitive applications like healthcare and medicine, concerns have been raised over the privacy aspects of trained GNNs. More notably, GNNs are vulnerable to privacy attacks, such as membership inference attacks, even if only black-box access to the trained model is granted. We propose PRIVGNN, a privacy-preserving framework for releasing GNN models in a centralized setting. Assuming an access to a public unlabeled graph, PRIVGNN provides a framework to release GNN models trained explicitly on public data along with knowledge obtained from the private data in a privacy preserving manner. PRIVGNN combines the knowledge-distillation framework with the two noise mechanisms, random subsampling, and noisy labeling, to ensure rigorous privacy guarantees. We theoretically analyze our approach in the Rènyi differential privacy framework. Besides, we show the solid experimental performance of our method compared to several baselines adapted for graph-structured data. Our code is\navailable at https://github.com/iyempissy/privGnn",
    "volume": "main",
    "checked": true,
    "id": "44fb93ce9016fbc1deb3fe0c5098e8707c0ca77d",
    "citation_count": 18
  },
  "https://openreview.net/forum?id=ERqGqZzSu5": {
    "title": "Sequential Query Encoding for Complex Query Answering on Knowledge Graphs",
    "abstract": "Complex Query Answering (CQA) is an important and fundamental task for knowledge graph (KG) reasoning.\nQuery encoding (QE) is proposed as a fast and robust solution to CQA. \nIn the encoding process, most existing QE methods first parse the logical query into an executable computational direct-acyclic graph (DAG), then use neural networks to parameterize the operators,\nand finally, recursively execute these neuralized operators. \nHowever, the parameterization-and-execution paradigm may be potentially over-complicated, as it can be structurally simplified by a single neural network encoder.\nMeanwhile, sequence encoders, like LSTM and Transformer, proved to be effective for encoding semantic graphs in related tasks.\nMotivated by this, we propose sequential query encoding (SQE) as an alternative to encode queries for CQA. \nInstead of parameterizing and executing the computational graph, SQE first uses a search-based algorithm to linearize the computational graph to a sequence of tokens and then uses a sequence encoder to compute its vector representation.\nThen this vector representation is used as a query embedding to retrieve answers from the embedding space according to similarity scores.\nDespite its simplicity, SQE demonstrates state-of-the-art neural query encoding performance on FB15k, FB15k-237, and NELL on an extended benchmark including twenty-nine types of in-distribution queries. \nFurther experiment shows that SQE also demonstrates comparable knowledge inference capability on out-of-distribution queries, whose query types are not observed during the training process",
    "volume": "main",
    "checked": true,
    "id": "b45ea6ddc9d964116addaf1dafd0641d78a6228e",
    "citation_count": 4
  },
  "https://openreview.net/forum?id=sFk3aBNb81": {
    "title": "TransFool: An Adversarial Attack against Neural Machine Translation Models",
    "abstract": "Deep neural networks have been shown to be vulnerable to small perturbations of their inputs, known as adversarial attacks. In this paper, we investigate the vulnerability of Neural Machine Translation (NMT) models to adversarial attacks and propose a new attack algorithm called TransFool. To fool NMT models, TransFool builds on a multi-term optimization problem and a gradient projection step. By integrating the embedding representation of a language model, we generate fluent adversarial examples in the source language that maintain a high level of semantic similarity with the clean samples. Experimental results demonstrate that, for different translation tasks and NMT architectures, our white-box attack can severely degrade the translation quality while the semantic similarity between the original and the adversarial sentences stays high. Moreover, we show that TransFool is transferable to unknown target models. Finally, based on automatic and human evaluations, TransFool leads to improvement in terms of success rate, semantic similarity, and fluency compared to the existing attacks both in white-box and black-box settings. Thus, TransFool permits us to better characterize the vulnerability of NMT models and outlines the necessity to design strong defense mechanisms and more robust NMT systems for real-life applications",
    "volume": "main",
    "checked": true,
    "id": "c5e9fdb1b81edf470141843c44264a5eb1ff0cc1",
    "citation_count": 3
  },
  "https://openreview.net/forum?id=9pWjgQ3y85": {
    "title": "An Explicit Expansion of the Kullback-Leibler Divergence along its Fisher-Rao Gradient Flow",
    "abstract": "Let $V_* : \\mathbb{R}^d \\to \\mathbb{R}$ be some (possibly non-convex) potential function, and consider the probability measure $\\pi \\propto e^{-V_*}$. When $\\pi$ exhibits multiple modes, it is known that sampling techniques based on Wasserstein gradient flows of the Kullback-Leibler (KL) divergence (e.g. Langevin Monte Carlo) suffer poorly in the rate of convergence, where the dynamics are unable to easily traverse between modes. In stark contrast, the work of Lu et al. (2019; 2022) has shown that the gradient flow of the KL with respect to the Fisher-Rao (FR) geometry exhibits a convergence rate to $\\pi$ is that \\textit{independent} of the potential function. In this short note, we complement these existing results in the literature by providing an explicit expansion of $\\text{KL}(\\rho_t^{\\text{FR}}\\|\\pi)$ in terms of $e^{-t}$, where $(\\rho_t^{\\text{FR}})_{t\\geq 0}$ is the FR gradient flow of the KL divergence. In turn, we are able to provide a clean asymptotic convergence rate, where the burn-in time is guaranteed to be finite. Our proof is based on observing a similarity between FR gradient flows and simulated annealing with linear scaling, and facts about cumulant generating functions. We conclude with simple synthetic experiments that demonstrate our theoretical findings are indeed tight. Based on our numerical findings, we conjecture that the asymptotic rates of convergence for Wasserstein-Fisher-Rao gradient flows are possibly related to this expansion in some cases",
    "volume": "main",
    "checked": true,
    "id": "8570695c0ee3574f1a0829f0fe4672de634acb1b",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=ZoXi7n54OB": {
    "title": "Training with Mixed-Precision Floating-Point Assignments",
    "abstract": "When training deep neural networks, keeping all tensors in high precision (e.g., 32-bit or even 16-bit floats) is often wasteful. However, keeping all tensors in low precision (e.g., 8-bit floats) can lead to unacceptable accuracy loss. Hence, it is important to use a precision assignment—a mapping from all tensors (arising in training) to precision levels (high or low)—that keeps most of the tensors in low precision and leads to sufficiently accurate models. We provide a technique that explores this memory-accuracy tradeoff by generating precision assignments for convolutional neural networks that (i) use less memory and (ii) lead to more accurate convolutional networks at the same time, compared to the precision assignments considered by prior work in low-precision floating-point training. We evaluate our technique on image classiﬁcation tasks by training convolutional networks on CIFAR-10, CIFAR-100, and ImageNet. Our method typically provides > 2× memory reduction over a baseline precision assignment while preserving training accuracy, and gives further reductions by trading off accuracy. Compared to other baselines which sometimes cause training to diverge, our method provides similar or better memory reduction while avoiding divergence",
    "volume": "main",
    "checked": true,
    "id": "6d06cd10665360739317c288ca25c68699611926",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=A1N2qp4yAq": {
    "title": "Bandwidth Enables Generalization in Quantum Kernel Models",
    "abstract": "Quantum computers are known to provide speedups over classical state-of-the-art machine learning methods in some specialized settings. For example, quantum kernel methods have been shown to provide an exponential speedup on a learning version of the discrete logarithm problem. Understanding the generalization of quantum models is essential to realizing similar speedups on problems of practical interest. Recent results demonstrate that generalization is hindered by the exponential size of the quantum feature space. Although these results suggest that quantum models cannot generalize when the number of qubits is large, in this paper we show that these results rely on overly restrictive assumptions. We consider a wider class of models by varying a hyperparameter that we call quantum kernel bandwidth. We analyze the large-qubit limit and provide explicit formulas for the generalization of a quantum model that can be solved in closed form. Specifically, we show that changing the value of the bandwidth can take a model from provably not being able to generalize to any target function to good generalization for well-aligned targets. Our analysis shows how the bandwidth controls the spectrum of the kernel integral operator and thereby the inductive bias of the model. We demonstrate empirically that our theory correctly predicts how varying the bandwidth affects generalization of quantum models on challenging datasets, including those far outside our theoretical assumptions. We discuss the implications of our results for quantum advantage in machine learning",
    "volume": "main",
    "checked": true,
    "id": "67557d52497b2805a840083564ee2596ef609042",
    "citation_count": 14
  },
  "https://openreview.net/forum?id=vTsfup5ll6": {
    "title": "Privacy-Preserving Energy-Based Generative Models for Marginal Distribution Protection",
    "abstract": "We consider learning generative models for sensitive financial and healthcare data. While previous work incorporates Differential Privacy (DP) into GAN training to protect the privacy of individual training instances, we consider a different privacy context where the primary objective is protecting the privacy of sensitive marginal distributions of the true generative process. We propose and motivate a new notion of privacy: \\emph{$\\alpha$-Level Marginal Distribution Privacy} ($\\alpha$-LMDP), which provides a statistical guarantee that the sensitive generative marginal distributions are different from the observed real data. We then propose \\emph{Privacy-Preserving Energy Models (PPEMs)}, a novel energy-based generative model formulation where the representations for these attributes are isolated from other attributes. This structured formulation motivates a learning procedure where a penalty based on a statistical goodness of fit test, the \\emph{Kernel Stein Discrepancy}, can be applied to only the attributes requiring privacy so that $\\alpha$-LMDP may be satisfied without affecting the other attributes. We evaluate this approach using financial and healthcare datasets and demonstrate that the resulting learnt generative models produce high fidelity synthetic data while preserving privacy. We also show that PPEMs can incorporate both $\\alpha$-LMDP \\emph{and} DP in contexts where both forms of privacy are required",
    "volume": "main",
    "checked": true,
    "id": "c27a01ff464bcc72124b6901ab3b5e2c0f517d98",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=B7PFZtm8DA": {
    "title": "Unsupervised Discovery and Composition of Object Light Fields",
    "abstract": "Neural scene representations, both continuous and discrete, have recently emerged as a powerful new paradigm for 3D scene understanding. Recent efforts have tackled unsupervised discovery of object-centric neural scene representations. However, the high cost of ray-marching, exacerbated by the fact that each object representation has to be ray-marched separately, leads to insufficiently sampled radiance fields and thus, noisy renderings, poor framerates, and high memory and time complexity during training and rendering. Here, we propose to represent objects in an object-centric, compositional scene representation as light fields. We propose a novel light field compositor module that enables reconstructing the global light field from a set of object-centric light fields. Dubbed Compositional Object Light Fields (COLF), our method enables unsupervised learning of object-centric neural scene representations, state-of-the-art reconstruction and novel view synthesis performance on standard datasets, and rendering and training speeds at orders of magnitude faster than existing 3D approaches",
    "volume": "main",
    "checked": true,
    "id": "4fa77b26bffc65a1baad55248fd7df06e46bc58e",
    "citation_count": 13
  },
  "https://openreview.net/forum?id=dXnccpSSYF": {
    "title": "Pareto Optimization for Active Learning under Out-of-Distribution Data Scenarios",
    "abstract": "Pool-based Active Learning (AL) has proven successful in minimizing labeling costs by sequentially selecting the most informative unlabeled data from large pool and querying their labels from an oracle or annotators.  However, existing AL sampling schemes may not perform well in out-of-distribution (OOD) data scenarios, where the unlabeled data pool contains samples that do not belong to the pre-defined categories of the target task. Achieving strong AL performance under OOD data scenarios presents a challenge due to the inherent conflict between AL sampling strategies and OOD data detection. For instance, both more informative in-distribution (ID) data and OOD data in an unlabeled data pool would be assigned high informativeness scores (e.g., high entropy) during AL processes. To address this dilemma, we propose a Monte-Carlo Pareto Optimization for Active Learning (POAL) sampling scheme, which selects optimal subsets of unlabeled samples with fixed batch size from the unlabeled data pool. We formulate the AL sampling task as a multi-objective optimization problem and employ Pareto optimization based on two conflicting objectives: (1) the conventional AL sampling scheme (e.g., maximum entropy) and (2) the confidence of excluding OOD data samples. Experimental results demonstrate the effectiveness of our POAL approach on classical Machine Learning (ML) and Deep Learning (DL) tasks",
    "volume": "main",
    "checked": true,
    "id": "e702416f7a9f62bf275c35a58a08839d65211733",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=jYkWdJzTwn": {
    "title": "Predicting Out-of-Domain Generalization with Neighborhood Invariance",
    "abstract": "Developing and deploying machine learning models safely depends on the ability to char- acterize and compare their abilities to generalize to new environments. Although recent work has proposed a variety of methods that can directly predict or theoretically bound the generalization capacity of a model, they rely on strong assumptions such as matching train/test distributions and access to model gradients. In order to characterize generalization when these assumptions are not satisfied, we propose neighborhood invariance, a measure of a classifier’s output invariance in a local transformation neighborhood. Specifically, we sample a set of transformations and given an input test point, calculate the invariance as the largest fraction of transformed points classified into the same class. Crucially, our measure is simple to calculate, does not depend on the test point’s true label, makes no assumptions about the data distribution or model, and can be applied even in out-of-domain (OOD) settings where existing methods cannot, requiring only selecting a set of appropriate data transformations. In experiments on robustness benchmarks in image classification, sentiment analysis, and natural language inference, we demonstrate a strong and robust correlation between our neighborhood invariance measure and actual OOD generalization on over 4,600 models evaluated on over 100 train/test domain pairs",
    "volume": "main",
    "checked": true,
    "id": "d59deb443bdf1858fcb2d43d455aa147ecf652d9",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=ipe0IMglFF": {
    "title": "Empirical Study on Optimizer Selection for Out-of-Distribution Generalization",
    "abstract": "Modern deep learning systems do not generalize well when the test data distribution is slightly different to the training data distribution. While much promising work has been accomplished to address this fragility, a systematic study of the role of optimizers and their out-of-distribution generalization performance has not been undertaken. In this study, we examine the performance of popular first-order optimizers for different classes of distributional shift under empirical risk minimization and invariant risk minimization. We address this question for image and text classification using DomainBed, WILDS, and Backgrounds Challenge as testbeds for studying different types of shifts---namely correlation and diversity shift. We search over a wide range of hyperparameters and examine classification accuracy (in-distribution and out-of-distribution) for over 20,000 models. We arrive at the following findings, which we expect to be helpful for practitioners: i) adaptive optimizers (e.g., Adam) perform worse than non-adaptive optimizers (e.g., SGD, momentum SGD) on out-of-distribution performance. In particular, even though there is no significant difference in in-distribution performance, we show a measurable difference in out-of-distribution performance. ii) in-distribution performance and out-of-distribution performance exhibit three types of behavior depending on the dataset---linear returns, increasing returns, and diminishing returns. For example, in the training of natural language data using Adam, fine-tuning the performance of in-distribution performance does not significantly contribute to the out-of-distribution generalization performance",
    "volume": "main",
    "checked": true,
    "id": "9d99e651212de629568de2f2dcaa0856fe4c0bbe",
    "citation_count": 3
  },
  "https://openreview.net/forum?id=FDbQGCAViI": {
    "title": "The Eigenlearning Framework: A Conservation Law Perspective on Kernel Ridge Regression and Wide Neural Networks",
    "abstract": "We derive simple closed-form estimates for the test risk and other generalization metrics of kernel ridge regression (KRR). Relative to prior work, our derivations are greatly simplified and our final expressions are more readily interpreted. In particular, we show that KRR can be interpreted as an explicit competition among kernel eigenmodes for a fixed supply of a quantity we term \"learnability.'' These improvements are enabled by a sharp conservation law which limits the ability of KRR to learn any orthonormal basis of functions. Test risk and other objects of interest are expressed transparently in terms of our conserved quantity evaluated in the kernel eigenbasis. We use our improved framework to:\n   i) provide a theoretical explanation for the \"deep bootstrap\" of Nakkiran et al (2020),\n   ii) generalize a previous result regarding the hardness of the classic parity problem,\n   iii) fashion a theoretical tool for the study of adversarial robustness, and\n   iv) draw a tight analogy between KRR and a well-studied system in statistical physics",
    "volume": "main",
    "checked": false,
    "id": "79f95d13d8430b2e31cb8a8104c0455c6995a259",
    "citation_count": 8
  },
  "https://openreview.net/forum?id=kiPsMct7vL": {
    "title": "Unsupervised Domain Adaptation via Minimized Joint Error",
    "abstract": "Unsupervised domain adaptation transfers knowledge from a fully labeled source domain to a different target domain, where no labeled data are available. Some researchers have proposed upper bounds for the target error when transferring knowledge. For example, Ben-David et al. (2010) established a theory based on minimizing the source error and distance between marginal distributions simultaneously. However, in most research, the joint error is ignored because of its intractability. In this research, we argue that joint errors are essential for domain adaptation problems, particularly when the domain gap is large. To address this problem, we propose a novel objective related to the upper bound of the joint error. Moreover, we adopt a source/pseudo-target label-induced hypothesis space that can reduce the search space to further tighten this bound. To measure the dissimilarity between hypotheses, we define a novel cross-margin discrepancy to alleviate instability during adversarial learning. In addition, we present extensive empirical evidence showing that the proposed method boosts the performance of image classification accuracy on standard domain adaptation benchmarks",
    "volume": "main",
    "checked": true,
    "id": "d8fcfb51844125476ebcaf2ffe53352e06d5dd89",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=r6oHDYOZ6p": {
    "title": "Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification",
    "abstract": "While a broad range of techniques have been proposed to tackle distribution shift, the simple baseline of training on an undersampled balanced dataset often achieves close to state-of-the-art-accuracy across several popular benchmarks. This is rather surprising, since undersampling algorithms discard excess majority group data. To understand this phenomenon, we ask if learning is fundamentally constrained by a lack of minority group samples. We prove that this is indeed the case in the setting of nonparametric binary classification. Our results show that in the worst case, an algorithm cannot outperform undersampling unless there is a high degree of overlap between the train and test distributions (which is unlikely to be the case in real-world datasets), or if the algorithm leverages additional structure about the distribution shift. In particular, in the case of label shift we show that there is always an undersampling algorithm that is minimax optimal. In the case of group-covariate shift we show that there is an undersampling algorithm that is minimax optimal when the overlap between the group distributions is small. We also perform an experimental case study on a label shift dataset and find that in line with our theory, the test accuracy of robust neural network classifiers is constrained by the number of minority samples",
    "volume": "main",
    "checked": true,
    "id": "598fe230576ff15e637be2dc5bf420ecba5d8688",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=K0CAGgjYS1": {
    "title": "On the Convergence and Calibration of Deep Learning with Differential Privacy",
    "abstract": "Differentially private (DP) training preserves the data privacy usually at the cost of slower convergence (and thus lower accuracy), as well as more severe mis-calibration than its non-private counterpart. To analyze the convergence of DP training, we formulate a continuous time analysis through the lens of neural tangent kernel (NTK), which characterizes the per-sample gradient clipping and the noise addition in DP training, for arbitrary network architectures and loss functions. Interestingly, we show that the noise addition only affects the privacy risk but not the convergence or calibration, whereas the per-sample gradient clipping (under both flat and layerwise clipping styles) only affects the convergence and calibration.\n\nFurthermore, we observe that while DP models trained with small clipping norm usually achieve the best accurate, but are poorly calibrated and thus unreliable. In sharp contrast, DP models trained with large clipping norm enjoy the same privacy guarantee and similar accuracy, but are significantly more \\textit{calibrated}. Our code can be found at https://github.com/woodyx218/opacus_global_clipping",
    "volume": "main",
    "checked": true,
    "id": "a7d7db2320436a90dac4fb10a50dc0500952e7a6",
    "citation_count": 13
  },
  "https://openreview.net/forum?id=XcVzIBXeRn": {
    "title": "A Reproducible and Realistic Evaluation of Partial Domain Adaptation Methods",
    "abstract": "Unsupervised Domain Adaptation (UDA) aims at classifying unlabeled target images leveraging source labeled ones. In the case of an extreme label shift scenario between the source and target domains, where we have extra source classes not present in the target domain, the UDA problem becomes a harder problem called Partial Domain Adaptation (PDA). While different methods have been developed to solve the PDA problem, most successful algorithms use model selection strategies that rely on target labels to find the best hyper-parameters and/or models along training. These strategies violate the main assumption in PDA: only unlabeled target domain samples are available. In addition, there are also experimental inconsistencies between developed methods - different architectures, hyper-parameter tuning, number of runs - yielding unfair comparisons. The main goal of this work is to provide a realistic evaluation of PDA methods under different model selection strategies and a consistent evaluation protocol. We evaluate 6 state-of-the-art PDA algorithms on 2 different real-world datasets using 7 different model selection strategies. Our two main findings are: (i) without target labels for model selection, the accuracy of the methods decreases up to 30 percentage points; (ii) only one method and model selection pair performs well on both datasets. Experiments were performed with our PyTorch framework, BenchmarkPDA, which we open source",
    "volume": "main",
    "checked": true,
    "id": "ee931b89b8828582db08fc7ff8b5f02580b4d7c9",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=B0WYWvVA2r": {
    "title": "Attentional-Biased Stochastic Gradient Descent",
    "abstract": "In this paper, we present a simple yet effective provable method (named ABSGD) for addressing the data imbalance or label noise problem in deep learning. Our method is a simple modification to momentum SGD where we assign an individual importance weight to each sample in the mini-batch. The individual-level weight of a sampled data is systematically proportional to the exponential of a scaled loss value of the data, where the scaling factor is interpreted as the regularization parameter in the framework of distributionally robust optimization (DRO). Depending on whether the scaling factor is positive or negative, ABSGD is guaranteed to converge to a stationary point of an information-regularized min-max or min-min  DRO problem, respectively. Compared with existing class-level weighting schemes, our method can capture the diversity between individual examples within each class. Compared with existing individual-level weighting methods using meta-learning that require three backward propagations for computing mini-batch stochastic gradients, our method is more efficient with only one backward propagation at each iteration as in standard deep learning methods.  ABSGD is flexible enough to combine with other robust losses without any additional cost. Our empirical studies on several benchmark datasets demonstrate the effectiveness of the proposed method",
    "volume": "main",
    "checked": true,
    "id": "8ede6030db284d6eedc1a667416a2224aff62863",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=G2GKiicaJI": {
    "title": "Reinforcement Teaching",
    "abstract": "Machine learning algorithms learn to solve a task, but are unable to improve their ability to learn.\nMeta-learning methods learn about machine learning algorithms and improve them so that they learn more quickly. However, existing meta-learning methods are either hand-crafted to improve one specific component of an algorithm or only work with differentiable algorithms. \nWe develop a unifying meta-learning framework, called \\textit{Reinforcement Teaching}, to improve the learning process of \\emph{any} algorithm. Under Reinforcement Teaching, a teaching policy is learned, through reinforcement, to improve a student's learning algorithm. To learn an effective teaching policy, we introduce the \\textit{parametric-behavior embedder} that learns a representation of the student's learnable parameters from its input/output behavior. We further use \\textit{learning progress} to shape the teacher's reward, allowing it to more quickly maximize the student's performance. To demonstrate the generality of Reinforcement Teaching, we conduct experiments in which a teacher learns to significantly improve both reinforcement and supervised learning algorithms. Reinforcement Teaching outperforms previous work using heuristic reward functions and state representations, as well as other parameter representations",
    "volume": "main",
    "checked": true,
    "id": "fa71320d3ef00075f4ddd6df0d328d00016377b0",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=zshemTAa6U": {
    "title": "Test-Time Adaptation for Visual Document Understanding",
    "abstract": "For visual document understanding (VDU), self-supervised pretraining has been shown to successfully generate transferable representations, yet, effective adaptation of such representations to distribution shifts at test-time remains to be an unexplored area. We propose DocTTA, a novel test-time adaptation method for documents, that does source-free domain adaptation using unlabeled target document data. DocTTA leverages cross-modality self-supervised learning via masked visual language modeling, as well as pseudo labeling to adapt models learned on a \\textit{source} domain to an unlabeled \\textit{target} domain at test time. We introduce new benchmarks using existing public datasets for various VDU tasks, including entity recognition, key-value extraction, and document visual question answering. DocTTA shows significant improvements on these compared to the source model performance, up to 1.89\\% in (F1 score), 3.43\\% (F1 score), and 17.68\\%  (ANLS score), respectively",
    "volume": "main",
    "checked": true,
    "id": "acf1c8e5e57a7b96fda3ac5f71ed9b94f286dfd4",
    "citation_count": 3
  },
  "https://openreview.net/forum?id=W98AEKQ38Y": {
    "title": "Learning to Incentivize Improvements from Strategic Agents",
    "abstract": "Machine learning systems are often used in settings where individuals adapt their features to obtain a desired outcome. \nIn such settings, strategic behavior leads to a sharp loss in model performance in deployment. In this work, we aim to address this problem by learning classifiers that encourage decision subjects to change their features in a way that leads to improvement in both predicted and true outcome. We frame the dynamics of prediction and adaptation as a two-stage game, and characterize optimal strategies for the model designer and its decision subjects. In benchmarks on simulated and real-world datasets, we find that classifiers trained using our method maintain the accuracy of existing approaches while inducing higher levels of improvement and less manipulation",
    "volume": "main",
    "checked": true,
    "id": "a2a0667a08b3c043b2e480786321b8f6039f1084",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=TSy0vuwQFN": {
    "title": "Finding Competence Regions in Domain Generalization",
    "abstract": "We investigate a \"learning to reject\" framework to address the problem of silent failures in Domain Generalization (DG), where the test distribution differs from the training distribution. Assuming a mild distribution shift, we wish to accept out-of-distribution (OOD) data from a new domain whenever a model's estimated competence foresees trustworthy responses, instead of rejecting OOD data outright. Trustworthiness is then predicted via a proxy incompetence score that is tightly linked to the performance of a classifier. We present a comprehensive experimental evaluation of existing proxy scores as incompetence scores for classification and highlight the resulting trade-offs between rejection rate and accuracy gain. For comparability with prior work, we focus on standard DG benchmarks and consider the effect of measuring incompetence via different learned representations in a closed versus an open world setting. Our results suggest that increasing incompetence scores are indeed predictive of reduced accuracy, leading to significant improvements of the average accuracy below a suitable incompetence threshold. However, the scores are not yet good enough to allow for a favorable accuracy/rejection trade-off in all tested domains. Surprisingly, our results also indicate that classifiers optimized for DG robustness do not outperform a naive Empirical Risk Minimization (ERM) baseline in the competence region, that is, where test samples elicit low incompetence scores",
    "volume": "main",
    "checked": true,
    "id": "376fd16949012d585fa4482540cbcdae8cf6ad5d",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=r7imkFEAQb": {
    "title": "Noise-robust Graph Learning by Estimating and Leveraging Pairwise Interactions",
    "abstract": "Teaching Graph Neural Networks (GNNs) to accurately classify nodes under severely noisy labels is an important problem in real-world graph learning applications, but is currently underexplored. Although pairwise training methods have demonstrated promise in supervised metric learning and unsupervised contrastive learning, they remain less studied on noisy graphs, where the structural pairwise interactions (PI) between nodes are abundant and thus might benefit label noise learning rather than the pointwise methods. This paper bridges the gap by proposing a pairwise framework for noisy node classification on graphs, which relies on the PI as a primary learning proxy in addition to the pointwise learning from the noisy node class labels. Our proposed framework PI-GNN contributes two novel components: (1) a confidence-aware PI estimation model that adaptively estimates the PI labels, which are defined as whether the two nodes share the same node labels, and (2) a decoupled training approach that leverages the estimated PI labels to regularize a node classification model for robust node classification. Extensive experiments on different datasets and GNN architectures demonstrate the effectiveness of PI-GNN, yielding a promising improvement over the state-of-the-art methods. Code is publicly available at https://github.com/TianBian95/pi-gnn",
    "volume": "main",
    "checked": true,
    "id": "564bd41471fdfd371d11bbc83b7c4b97fccaf429",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=SwlfyDq6B3": {
    "title": "3D-Aware Video Generation",
    "abstract": "Generative models have emerged as an essential building block for many image synthesis and editing tasks. Recent advances in this field have also enabled high-quality 3D or video content to be generated that exhibits either multi-view or temporal consistency. With our work, we explore 4D generative adversarial networks (GANs) that learn unconditional generation of 3D-aware videos. By combining neural implicit representations with time-aware discriminator, we develop a GAN framework that synthesizes 3D video supervised only with monocular videos. We show that our method learns a rich embedding of decomposable 3D structures and motions that enables new visual effects of spatio-temporal renderings while producing imagery with quality comparable to that of existing 3D or video GANs",
    "volume": "main",
    "checked": true,
    "id": "aa7dda2f65691e2ada225c66c2d8fa0047448b02",
    "citation_count": 10
  },
  "https://openreview.net/forum?id=sixOD8YVvM": {
    "title": "Bounded Space Differentially Private Quantiles",
    "abstract": "Estimating the quantiles of a large dataset is a fundamental problem in both the streaming algorithms literature and the differential privacy literature. However, all existing private mechanisms for distribution-independent quantile computation require space at least linear in the input size $n$. In this work, we devise a differentially private algorithm for the quantile estimation problem, with strongly sublinear space complexity, in the one-shot and continual observation settings. Our basic mechanism estimates any $\\alpha$-approximate quantile of a length-$n$ stream over a data universe $\\mathcal{X}$ with probability $1-\\beta$ using $O\\left( \\frac{\\log (|\\mathcal{X}|/\\beta) \\log (\\alpha \\epsilon n)}{\\alpha \\epsilon} \\right)$ space while satisfying $\\epsilon$-differential privacy at a single time point. Our approach builds upon deterministic streaming algorithms for non-private quantile estimation instantiating the exponential mechanism using a utility function defined on sketch items, while (privately) sampling from intervals defined by the sketch. We also present another algorithm based on histograms that is especially well-suited to the multiple quantiles case. We implement our algorithms and experimentally evaluate them on synthetic and real-world datasets",
    "volume": "main",
    "checked": true,
    "id": "3ef96d9ee132ca2edc5fdb5e76f4c4cf538e4ece",
    "citation_count": 12
  },
  "https://openreview.net/forum?id=pxpbTdUEpD": {
    "title": "The Stack: 3 TB of permissively licensed source code",
    "abstract": "Large Language Models (LLMs) play an ever-increasing role in the field of Artificial Intelligence (AI)--not only for natural language processing but also for code understanding and generation. To stimulate open and responsible research on LLMs for code, we introduce The Stack, a 3.1 TB dataset consisting of permissively licensed source code in 30 programming languages. We describe how we collect the full dataset, construct a permissively licensed subset, present a data governance plan, discuss limitations, and show promising results on text2code benchmarks by training 350M-parameter decoders on different Python subsets. We find that (1) near-deduplicating the data significantly boosts performance across all experiments, and (2) it is possible to match previously reported HumanEval and MBPP performance using only permissively licensed data. We make the dataset available at https://hf.co/BigCode, provide a tool called \"Am I in The Stack\" for developers to search The Stack for copies of their code (https://hf.co/spaces/bigcode/in-the-stack), and provide a process for code to be removed from the dataset",
    "volume": "main",
    "checked": true,
    "id": "f3a6115e5fb2237df938976e005468f0b18da797",
    "citation_count": 23
  },
  "https://openreview.net/forum?id=sWQJfb2GSk": {
    "title": "Exploring the Approximation Capabilities of Multiplicative Neural Networks for Smooth Functions",
    "abstract": "Multiplication layers are a key component in various influential neural network modules, including self-attention and hypernetwork layers. In this paper, we investigate the approximation capabilities of deep neural networks with intermediate neurons connected by simple multiplication operations. We consider two classes of target functions: generalized bandlimited functions, which are frequently used to model real-world signals with finite bandwidth, and Sobolev-Type balls, which are embedded in the Sobolev Space $\\mathcal{W}^{r,2}$. Our results demonstrate that multiplicative neural networks can approximate these functions with significantly fewer layers and neurons compared to standard ReLU neural networks, with respect to both input dimension and approximation error. These findings suggest that multiplicative gates can outperform standard feed-forward layers and have potential for improving neural network design",
    "volume": "main",
    "checked": true,
    "id": "c27bbdd8968c11513a68383145f7935293a57c25",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=na5sHG69rI": {
    "title": "Assuming Locally Equal Calibration Errors for Non-Parametric Multiclass Calibration",
    "abstract": "A probabilistic classifier is considered calibrated if it outputs probabilities equal to the expected class distribution given the classifier's output. Calibration is essential in safety-critical tasks where small deviations between the predicted probabilities and the actually observed class proportions can incur high costs. A common approach to improve the calibration of a classifier is to use a hold-out data set and a post-hoc calibration method to learn a correcting transformation for the classifier's output. This work explores the field of post-hoc calibration methods for multi-class classifiers and formulates two assumptions about the probability simplex which have been used by many existing non-parametric calibration methods, but despite this, have never been explicitly stated: assuming locally equal label distributions or assuming locally equal calibration errors. Based on the latter assumption, an intuitive non-parametric post-hoc calibration method is proposed, which is shown to offer improvements to the state-of-the-art according to the expected calibration error metric on CIFAR-10 and CIFAR-100 data sets",
    "volume": "main",
    "checked": true,
    "id": "98a59cf71e7f2623625cfae4772b12388a723751",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=OILbP0WErR": {
    "title": "Learning Graph Structure from Convolutional Mixtures",
    "abstract": "Machine learning frameworks such as graph neural networks typically rely on a given, fixed graph to exploit relational inductive biases and thus effectively learn from network data. However, when said graphs are (partially) unobserved, noisy, or dynamic, the problem of inferring graph structure from data becomes relevant. In this paper, we postulate a graph convolutional relationship between the observed and latent graphs, and formulate the graph structure learning task as a network inverse (deconvolution) problem. In lieu of eigendecomposition-based spectral methods or iterative optimization solutions, we unroll and truncate proximal gradient iterations to arrive at a parameterized neural network architecture that we call a Graph Deconvolution Network (GDN). GDNs can learn a distribution of graphs in a supervised fashion, perform link prediction or edge-weight regression tasks by adapting the loss function, and they are inherently inductive as well as node permutation equivariant. We corroborate GDN's superior graph learning performance and its generalization to larger graphs using synthetic data in supervised settings. Moreover, we demonstrate the robustness and representation power of GDNs on real world neuroimaging and social network datasets",
    "volume": "main",
    "checked": true,
    "id": "064a66238196f14b5815dc5bed72a5499bef2e5b",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=NrfSRtTpN5": {
    "title": "Learning Object-Centric Neural Scattering Functions for Free-viewpoint Relighting and Scene Composition",
    "abstract": "Photorealistic object appearance modeling from 2D images is a constant topic in vision and graphics. While neural implicit methods (such as Neural Radiance Fields) have shown high-fidelity view synthesis results, they cannot relight the captured objects. More recent neural inverse rendering approaches have enabled object relighting, but they represent surface properties as simple BRDFs, and therefore cannot handle translucent objects. We propose Object-Centric Neural Scattering Functions (OSFs) for learning to reconstruct object appearance from only images. OSFs not only support free-viewpoint object relighting, but also can model both opaque and translucent objects. While accurately modeling subsurface light transport for translucent objects can be highly complex and even intractable for neural methods, OSFs learn to approximate the radiance transfer from a distant light to an outgoing direction at any spatial location. This approximation avoids explicitly modeling complex subsurface scattering, making learning a neural implicit model tractable. Experiments on real and synthetic data show that OSFs accurately reconstruct appearances for both opaque and translucent objects, allowing faithful free-viewpoint relighting as well as scene composition. In our supplementary material, we include a video for an overview. Project website with video results: https://kovenyu.com/OSF/",
    "volume": "main",
    "checked": true,
    "id": "0c597d8f2e782e1d8036197d440d967b89fb015e",
    "citation_count": 3
  },
  "https://openreview.net/forum?id=Y42xVBQusn": {
    "title": "Contextualize Me â The Case for Context in Reinforcement Learning",
    "abstract": "While Reinforcement Learning ( RL) has made great strides towards solving increasingly\ncomplicated problems, many algorithms are still brittle to even slight environmental changes.\nContextual Reinforcement Learning (cRL) provides a framework to model such changes in\na principled manner, thereby enabling flexible, precise and interpretable task specification\nand generation. Our goal is to show how the framework of cRL contributes to improving\nzero-shot generalization in RL through meaningful benchmarks and structured reasoning\nabout generalization tasks. We confirm the insight that optimal behavior in cRL requires\ncontext information, as in other related areas of partial observability. To empirically validate\nthis in the cRL framework, we provide various context-extended versions of common RL\nenvironments. They are part of the first benchmark library, CARL, designed for generalization\nbased on cRL extensions of popular benchmarks, which we propose as a testbed to further\nstudy general agents. We show that in the contextual setting, even simple RL environments\nbecome challenging - and that naive solutions are not enough to generalize across complex\ncontext spaces",
    "volume": "main",
    "checked": false,
    "id": "df8e5f2e19b696fc5ed4bec9b61835943c8e8a8f",
    "citation_count": 6
  },
  "https://openreview.net/forum?id=KxBQPz7HKh": {
    "title": "Multi-dimensional concept discovery (MCD): A unifying framework with completeness guarantees",
    "abstract": "The completeness axiom renders the explanation of a post-hoc eXplainable AI (XAI) method only locally faithful to the model, i.e. for a single decision. For the trustworthy application of XAI, in particular for high-stake decisions, a more global model understanding is required. To this end, concept-based methods have been proposed, which are however not guaranteed to be bound to the actual model reasoning. To circumvent this problem, we propose Multi-dimensional Concept Discovery (MCD) as an extension of previous approaches that fulfills a completeness relation on the level of concepts. Our method starts from general linear subspaces as concepts and does neither require reinforcing concept interpretability nor re-training of model parts. We propose sparse subspace clustering to discover improved concepts and fully leverage the potential of multi-dimensional subspaces. MCD offers two complementary analysis tools for concepts in input space: (1) concept activation maps, that show where a concept is expressed within a sample, allowing for concept characterization through prototypical samples, and (2) concept relevance heatmaps, that decompose the model decision into concept contributions. Both tools together enable a detailed global understanding of the model reasoning, which is guaranteed to relate to the model via a completeness relation. Thus, MCD paves the way towards more trustworthy concept-based XAI. We empirically demonstrate the superiority of MCD against more constrained concept definitions",
    "volume": "main",
    "checked": true,
    "id": "e695a6a6d8a677f528add0118effc7736da35709",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=TyBd56VK7z": {
    "title": "Dr-Fairness: Dynamic Data Ratio Adjustment for Fair Training on Real and Generated Data",
    "abstract": "Fair visual recognition has become critical for preventing demographic disparity. A major cause of model unfairness is the imbalanced representation of different groups in training data. Recently, several works aim to alleviate this issue using generated data. However, these approaches often use generated data to obtain similar amounts of data across groups, which is not optimal for achieving high fairness due to different learning difficulties and generated data qualities across groups. To address this issue, we propose a novel adaptive sampling approach that leverages both real and generated data for fairness. We design a bilevel optimization that finds the optimal data sampling ratios among groups and between real and generated data while training a model. The ratios are dynamically adjusted considering both the model's accuracy as well as its fairness. To efficiently solve our non-convex bilevel optimization, we propose a simple approximation to the solution given by the implicit function theorem. Extensive experiments show that our framework achieves state-of-the-art fairness and accuracy on the CelebA and ImageNet People Subtree datasets. We also observe that our method adaptively relies less on the generated data when it has poor quality. Our work shows the importance of using generated data together with real data for improving model fairness",
    "volume": "main",
    "checked": true,
    "id": "37aa9f75ac8b983470e89989a533e277e00c0ef8",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=N7lCDaeNiS": {
    "title": "Federated Learning under Covariate Shifts with Generalization Guarantees",
    "abstract": "This paper addresses intra-client and inter-client covariate shifts in federated learning (FL) with a focus on the overall generalization performance. To handle covariate shifts, we formulate a new global model training paradigm and propose  Federated Importance-Weighted Empirical Risk Minimization (FTW-ERM) along with improving density ratio matching methods without requiring perfect knowledge of the supremum over true ratios. We also propose the communication-efficient variant FITW-ERM with the same level of privacy guarantees as those of classical ERM in FL. We theoretically show that FTW-ERM achieves smaller generalization error than classical ERM under certain settings. Experimental results demonstrate the superiority of FTW-ERM over existing FL baselines in challenging imbalanced federated settings in terms of data distribution shifts across clients",
    "volume": "main",
    "checked": true,
    "id": "537ede99556e763aaeb1ccaa1a34801d276daee4",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=pbs22kJmEO": {
    "title": "When Does Uncertainty Matter?: Understanding the Impact of Predictive Uncertainty in ML Assisted Decision Making",
    "abstract": "As machine learning (ML) models are increasingly being employed to assist human decision makers, it becomes critical to provide these decision makers with relevant inputs which can help them decide if and how to incorporate model predictions into their decision making. For instance, communicating the uncertainty associated with model predictions could potentially be helpful in this regard. In this work, we carry out user studies (1,330 responses from 190 participants) to systematically assess how people with differing levels of expertise respond to different types of predictive uncertainty (i.e., posterior predictive distributions with different shapes and variances) in the context of ML assisted decision making for predicting apartment rental prices. We found that showing posterior predictive distributions led to smaller disagreements with the ML model's predictions, regardless of the shapes and variances of the posterior predictive distributions we considered, and that these effects may be sensitive to expertise in both ML and the domain. This suggests that posterior predictive distributions can potentially serve as useful decision aids which should be used with caution and take into account the type of distribution and the expertise of the human",
    "volume": "main",
    "checked": true,
    "id": "9aa0143243847eaa2b3fb66c8b3d5c42e39613e9",
    "citation_count": 15
  },
  "https://openreview.net/forum?id=QhHLwn3D0Y": {
    "title": "The Robustness Limits of SoTA Vision Models to Natural Variation",
    "abstract": "Recent state-of-the-art vision models have introduced new architectures, learning\nparadigms, and larger pretraining data, leading to impressive performance on tasks\nsuch as classification. While previous generations of vision models were shown to\nlack robustness to factors such as pose, the extent to which this next generation\nof models are more robust remains unclear. To study this question, we develop a\ndataset of more than 7 million images with controlled changes in pose, position\nbackground, lighting color, and size. We study not only how robust recent state-of-\nthe-art models are, but also the extent to which models can generalize to variation in\neach of these factors. We consider a catalog of recent vision models, including vision\ntransformers (ViT), self-supervised models such as masked autoencoders (MAE),\nand models trained on larger datasets such as CLIP. We find that even today’s best\nmodels are not robust to common changes in pose, size, and background. When\nsome samples varied during training, we found models required a significant portion\nof instances seen varying to generalize—though eventually robustness did improve.\nWhen variability is only witnessed for some classes however, we found that models\ndid not generalize to other classes unless the classes were very similar to those seen\nvarying during training. We hope our work will shed further light on the blind\nspots of SoTA models and spur the development of more robust vision models",
    "volume": "main",
    "checked": true,
    "id": "8b1aa3a20638363be3a6d941e907df704c738dfc",
    "citation_count": 4
  },
  "https://openreview.net/forum?id=CqTkapZ6H9": {
    "title": "Robust Multi-Agent Reinforcement Learning with State Uncertainty",
    "abstract": "In real-world multi-agent reinforcement learning (MARL) applications, agents may not have perfect state information (e.g., due to inaccurate measurement or malicious attacks), which challenges the robustness of agents' policies. Though robustness is getting important in MARL deployment, little prior work has studied state uncertainties in MARL, neither in problem formulation nor algorithm design. Motivated by this robustness issue and the lack of corresponding studies, we study the problem of MARL with state uncertainty in this work. We provide the first attempt to the theoretical and empirical analysis of this challenging problem. We first model the problem as a Markov Game with state perturbation adversaries (MG-SPA) by introducing a set of state perturbation adversaries into a Markov Game. We then introduce robust equilibrium (RE) as the solution concept of an MG-SPA. We conduct a fundamental analysis regarding MG-SPA such as giving conditions under which such a robust equilibrium exists. Then we propose a robust multi-agent Q-learning (RMAQ) algorithm to find such an equilibrium, with convergence guarantees. To handle high-dimensional state-action space, we design a robust multi-agent actor-critic (RMAAC) algorithm based on an analytical expression of the policy gradient derived in the paper. Our experiments show that the proposed RMAQ algorithm converges to the optimal value function; our RMAAC algorithm outperforms several MARL and robust MARL methods in multiple multi-agent environments when state uncertainty is present. The source code is public on https://github.com/sihongho/robust_marl_with_state_uncertainty",
    "volume": "main",
    "checked": true,
    "id": "b1dd351bab053ea1acac9c1822034480fa3a201e",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=ClIcmwdlxn": {
    "title": "Optimum-statistical Collaboration Towards General and Efficient Black-box Optimization",
    "abstract": "In this paper, we make the key delineation on the roles of resolution and statistical uncertainty in hierarchical bandits-based black-box optimization algorithms, guiding a more general analysis and a more efficient algorithm design. We introduce the optimum-statistical\ncollaboration, an algorithm framework of managing the interaction between optimization error flux and statistical error flux evolving in the optimization process. We provide a general analysis of this framework without specifying the forms of statistical error and uncertainty quantifier. Our framework and its analysis, due to their generality, can be applied to a large family of functions and partitions that satisfy different local smoothness assumptions and have different numbers of local optimums, which is much richer than the class of functions studied in prior works. Our framework also inspires us to propose a better measure of the statistical uncertainty and consequently a variance-adaptive algorithm VHCT. In theory, we prove the algorithm enjoys rate-optimal regret bounds under different local smoothness assumptions; in experiments, we show the algorithm outperforms prior efforts in different settings",
    "volume": "main",
    "checked": true,
    "id": "c3a62d14244c5c7fea01c161e32685c0c6e2f043",
    "citation_count": 4
  },
  "https://openreview.net/forum?id=KBhSyBBeeO": {
    "title": "An Adaptive Half-Space Projection Method for Stochastic Optimization Problems with Group Sparse Regularization",
    "abstract": "Optimization problems with group sparse regularization are ubiquitous in various popular downstream applications, such as feature selection and compression for Deep Neural Networks (DNNs). Nonetheless, the existing methods in the literature do not perform particularly well when such regularization is used in combination with a stochastic loss function. In particular, it is challenging to design a computationally efficient algorithm with a convergence guarantee and can compute group-sparse solutions. Recently, a half-space stochastic projected gradient (HSPG)  method was proposed that partly addressed these challenges. This paper presents a substantially enhanced version of HSPG that we call AdaHSPG+ that makes two noticeable advances. First, AdaHSPG+ is shown to have a stronger convergence result under significantly looser assumptions than those required by HSPG. This improvement in convergence is achieved by integrating variance reduction techniques with a new adaptive strategy for iteratively predicting the support of a solution. Second, AdaHSPG+ requires significantly less parameter tuning compared to HSPG, thus making it more practical and user-friendly. This advance is achieved by designing automatic and adaptive strategies for choosing the type of step employed at each iteration and for updating key hyperparameters. The numerical effectiveness of our proposed AdaHSPG+ algorithm is demonstrated on both convex and non-convex benchmark problems. The source code is available at https://github.com/tianyic/adahspg",
    "volume": "main",
    "checked": true,
    "id": "6826fe9e5d593cb63129039d35e19d7c0f482790",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=iDNMZgjJuJ": {
    "title": "Causally-guided Regularization of Graph Attention Improves Generalizability",
    "abstract": "Graph attention networks estimate the relational importance of node neighbors to aggregate relevant information over local neighborhoods for a prediction task. However, the inferred attentions are vulnerable to spurious correlations and connectivity in the training data, hampering the generalizability of models. We introduce CAR, a general-purpose regularization framework for graph attention networks. Embodying a causal inference approach based on invariance prediction, CAR aligns the attention mechanism with the causal effects of active interventions on graph connectivity in a scalable manner. CAR is compatible with a variety of graph attention architectures, and we show that it systematically improves generalizability on various node classification tasks. Our ablation studies indicate that CAR hones in on the aspects of graph structure most pertinent to the prediction (e.g., homophily), and does so more effectively than alternative approaches. Finally, we also show that \\methodname enhances interpretability of attention coefficients by accentuating node-neighbor relations that point to causal hypotheses",
    "volume": "main",
    "checked": true,
    "id": "5a7c11c952e51497d92bec310e15b1947bf460bf",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=nEX2q5B2RQ": {
    "title": "Analyzing Deep PAC-Bayesian Learning with Neural Tangent Kernel: Convergence, Analytic Generalization Bound, and Efficient Hyperparameter Selection",
    "abstract": "PAC-Bayes is a well-established framework for analyzing generalization performance in machine learning models. This framework provides a bound on the expected population error by considering the sum of training error and the divergence between posterior and prior distributions. In addition to being a successful generalization bound analysis tool, the PAC-Bayesian bound can also be incorporated into an objective function for training probabilistic neural networks, which we refer to simply as {\\it Deep PAC-Bayesian Learning}. Deep PAC-Bayesian learning has been shown to achieve competitive expected test set error and provide a tight generalization bound in practice at the same time through gradient descent training. Despite its empirical success, theoretical analysis of deep PAC-Bayesian learning for neural networks is rarely explored. To this end, this paper proposes a theoretical convergence and generalization analysis for Deep PAC-Bayesian learning. For a deep and wide probabilistic neural network, our analysis shows that PAC-Bayesian learning corresponds to solving a kernel ridge regression when the probabilistic neural tangent kernel (PNTK) is used as the kernel. We utilize this outcome in conjunction with the PAC-Bayes $\\mathcal{C}$-bound, enabling us to derive an analytical and guaranteed PAC-Bayesian generalization bound for the first time. Finally, drawing insight from our theoretical results, we propose a proxy measure for efficient hyperparameter selection, which is proven to be time-saving on various benchmarks. Our work not only provides a better understanding of the theoretical underpinnings of Deep PAC-Bayesian learning, but also offers practical tools for improving the training and generalization performance of these models",
    "volume": "main",
    "checked": true,
    "id": "8dab53b0cc7358b36a0fc7e5ff09f5c9a492b1c8",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=ttzypy3kT7": {
    "title": "High-Modality Multimodal Transformer: Quantifying Modality & Interaction Heterogeneity for High-Modality Representation Learning",
    "abstract": "Many real-world problems are inherently multimodal, from the communicative modalities humans use to express social and emotional states such as spoken language, gestures, and paralinguistics to the force, proprioception, and visual sensors ubiquitous on robots. While there has been an explosion of interest in multimodal representation learning, these methods are still largely focused on a small set of modalities, primarily in the language, vision, and audio space. In order to accelerate generalization towards diverse and understudied modalities, this paper studies efficient representation learning for high-modality scenarios involving a large set of diverse modalities. Since adding new models for every new modality or task becomes prohibitively expensive, a critical technical challenge is heterogeneity quantification: how can we measure which modalities encode similar information and interactions in order to permit parameter sharing with previous modalities? This paper proposes two new information theoretic metrics for heterogeneity quantification: (1) modality heterogeneity studies how similar $2$ modalities $\\{X_1,X_2\\}$ are by measuring how much information can be transferred from $X_1$ to $X_2$, while (2) interaction heterogeneity studies how similarly pairs of modalities $\\{X_1,X_2\\}, \\{X_3,X_4\\}$ interact by measuring how much interaction information can be transferred from $\\{X_1,X_2\\}$ to $\\{X_3,X_4\\}$. We show the importance of these $2$ proposed metrics in high-modality scenarios as a way to automatically prioritize the fusion of modalities that contain unique information or unique interactions. The result is a single model, HighMMT, that scales up to $10$ modalities (text, image, audio, video, sensors, proprioception, speech, time-series, sets, and tables) and $15$ tasks from $5$ different research areas. Not only does HighMMT outperform prior methods on the tradeoff between performance and efficiency, it also demonstrates a crucial scaling behavior: performance continues to improve with each modality added, and it transfers to entirely new modalities and tasks during fine-tuning. We release our code and benchmarks, which we hope will present a unified platform for subsequent theoretical and empirical analysis",
    "volume": "main",
    "checked": false,
    "id": "3f6aeb7b5c3e3c0a1a6d2ac1d737d36365709da1",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=TH6YrEcbth": {
    "title": "Learning Interpolations between Boltzmann Densities",
    "abstract": "We introduce a training objective for  continuous normalizing flows that can be used in the absence of samples but in the presence of an energy function. Our method relies on either a prescribed or a learnt  interpolation $f_t$ of energy functions between the target energy $f_1$ and the energy function of a generalized Gaussian  $f_0(x) = ||x/\\sigma||_p^p$. The interpolation of energy functions induces an interpolation of Boltzmann densities $p_t \\propto e^{-f_t}$ and we aim to find a time-dependent vector field $V_t$ that transports samples along the family $p_t$ of densities. The condition of transporting samples along the family $p_t$ is equivalent to satisfying the continuity equation with $V_t$ and $p_t = Z_t^{-1}e^{-f_t}$. Consequently, we optimize $V_t$ and $f_t$ to satisfy this partial differential equation. We experimentally compare the proposed training objective to the reverse KL-divergence on Gaussian mixtures and on the Boltzmann density of a quantum mechanical particle in a double-well potential",
    "volume": "main",
    "checked": true,
    "id": "6404636ef49ceef284c09ed6aaa32641b6723cde",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=LjDFIWWVVa": {
    "title": "Retiring $\\Delta \\text{DP}$: New Distribution-Level Metrics for Demographic Parity",
    "abstract": "Demographic parity is the most widely recognized measure of group fairness in machine learning, which ensures equal treatment of different demographic groups. Numerous works aim to achieve demographic parity by pursuing the commonly used metric $\\Delta DP$. Unfortunately, in this paper, we reveal that the fairness metric $\\Delta DP$ can not precisely measure the violation of demographic parity, because it inherently has the following drawbacks: i) zero-value $\\Delta DP$ does not guarantee zero violation of demographic parity, ii)  $\\Delta DP$ values can vary with different classification thresholds. To this end, we propose two new fairness metrics, Area Between Probability density function Curves (ABPC) and Area Between Cumulative density function Curves (ABCC), to precisely measure the violation of demographic parity at the distribution level. The new fairness metrics directly measure the difference between the distributions of the prediction probability for different demographic groups. Thus our proposed new metrics enjoy: i) zero-value ABCC/ABPC guarantees zero violation of demographic parity; ii) ABCC/ABPC guarantees demographic parity while the classification thresholds are adjusted. We further re-evaluate the existing fair models with our proposed fairness metrics and observe different fairness behaviors of those models under the new metrics",
    "volume": "main",
    "checked": false,
    "id": "8dc4f76559e3d603412d4ba7b3af118233942b05",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=2f81Q622ww": {
    "title": "Generating Adversarial Examples with Task Oriented Multi-Objective Optimization",
    "abstract": "Deep learning models, even the-state-of-the-art ones, are highly vulnerable to adversarial examples. Adversarial training is one of the most efficient methods to improve the model's robustness. The key factor for the success of adversarial training is the capability to generate \nqualified and divergent adversarial examples which satisfy some objectives/goals (e.g., finding adversarial examples that maximize the model losses for simultaneously attacking multiple models). Therefore, multi-objective optimization (MOO) is a natural tool for adversarial example generation to achieve multiple objectives/goals simultaneously. However, we observe that a naive application of MOO tends to maximize all objectives/goals equally, without caring if an objective/goal has been achieved yet. This leads to useless effort to further improve the goal-achieved tasks, while putting less focus on the goal-unachieved tasks. In this paper, we propose \\emph{Task Oriented MOO} to address this issue, in the context where we can explicitly define the goal achievement for a task. Our principle is to only maintain the goal-achieved tasks, while letting the optimizer spend more effort on improving the goal-unachieved tasks. We conduct comprehensive experiments for our Task Oriented MOO on various adversarial example generation schemes. The experimental results firmly demonstrate the merit of our proposed approach",
    "volume": "main",
    "checked": true,
    "id": "8836eebd5420c337565937a9623156a193623444",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=D45gGvUZp2": {
    "title": "Denise: Deep Robust Principal Component Analysis for Positive Semidefinite Matrices",
    "abstract": "The robust PCA of covariance matrices plays an essential role when isolating key explanatory features.  The currently available methods for performing such a low-rank plus sparse decomposition are matrix specific, meaning, those algorithms must re-run for every new matrix.  Since these algorithms are computationally expensive, it is preferable to learn and store a function that nearly instantaneously performs this decomposition when evaluated.  Therefore, we introduce Denise, a deep learning-based algorithm for robust PCA of covariance matrices, or more generally, of symmetric positive semidefinite matrices, which learns precisely such a function.  Theoretical guarantees for Denise are provided.  These include a novel universal approximation theorem adapted to our geometric deep learning problem and convergence to an optimal solution to the learning problem.  Our experiments show that Denise matches state-of-the-art performance in terms of decomposition quality, while being approximately $2000\\times$ faster than the state-of-the-art, principal component pursuit (PCP), and $200 \\times$ faster than the current speed-optimized method, fast PCP",
    "volume": "main",
    "checked": true,
    "id": "8c7a4439b039cacce6066625d2b751347c56135a",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=ZME2nZMTvY": {
    "title": "Mean-Field Control based Approximation of Multi-Agent Reinforcement Learning in Presence of a Non-decomposable Shared Global State",
    "abstract": "Mean Field Control (MFC) is a powerful approximation tool to solve large-scale Multi-Agent Reinforcement Learning (MARL) problems. However, the success of MFC  relies on the presumption that given the local states and actions of all the agents, the next (local) states of the agents evolve conditionally independent of each other. Here we demonstrate that even in a MARL setting where agents share a common global state in addition to their local states evolving conditionally independently (thus introducing a correlation between the state transition processes of individual agents), the MFC can still be applied as a good approximation tool. The global state is assumed to be non-decomposable i.e., it cannot be expressed as a collection of local states of the agents. We compute the approximation error as $\\mathcal{O}(e)$ where $e=\\frac{1}{\\sqrt{N}}\\left[\\sqrt{|\\mathcal{X}|} +\\sqrt{|\\mathcal{U}|}\\right]$.  The size of the agent population is denoted by the term $N$, and $|\\mathcal{X}|, |\\mathcal{U}|$ respectively indicate the sizes of (local) state and action spaces of individual agents. The approximation error is found to be independent of the size of the shared global state space. We further demonstrate that in a special case if the reward and state transition functions are independent of the action distribution of the population, then the error can be improved to $e=\\frac{\\sqrt{|\\mathcal{X}|}}{\\sqrt{N}}$. Finally, we devise a Natural Policy Gradient based algorithm that solves the MFC problem with $\\mathcal{O}(\\epsilon^{-3})$ sample complexity and obtains a policy that is within $\\mathcal{O}(\\max\\{e,\\epsilon\\})$ error of the optimal MARL policy for any $\\epsilon>0$",
    "volume": "main",
    "checked": true,
    "id": "715daa423edae09c6213f0ff43f6c759384a8906",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=DdZoPUPm0a": {
    "title": "Interpretable Mixture of Experts",
    "abstract": "The need for reliable model explanations is prominent for many machine learning applications, particularly for tabular and time-series data as their use cases often involve high-stakes decision making.  Towards this goal, we introduce a novel interpretable modeling framework, Interpretable Mixture of Experts (IME), that yields high accuracy, comparable to `black-box' Deep Neural Networks (DNNs) in many cases, along with useful interpretability capabilities. IME consists of an assignment module and a mixture of experts, with each sample being assigned to a single expert for prediction. We introduce multiple options for IME based on the assignment and experts being interpretable. When the experts are chosen to be interpretable such as linear models, IME yields an inherently-interpretable architecture where the explanations produced by IME are the exact descriptions of how the prediction is computed. In addition to constituting a standalone inherently-interpretable architecture, IME has the premise of being integrated with existing DNNs to offer interpretability to a subset of samples while maintaining the accuracy of the DNNs. Through extensive experiments on 15 tabular and time-series datasets, IME is demonstrated to be more accurate than single interpretable models and perform comparably with existing state-of-the-art DNNs in accuracy. On most datasets, IME even outperforms DNNs, while providing faithful explanations.  Lastly, IME's explanations are compared to commonly-used post-hoc explanations methods through a user study -- participants are able to better predict the model behavior when given IME explanations, while finding IME's explanations more faithful and trustworthy",
    "volume": "main",
    "checked": false,
    "id": "68e64acad9ff92952f4fe1fb9edd1b70d6bf842b",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=162TqkUNPO": {
    "title": "Comparative Generalization Bounds for Deep Neural Networks",
    "abstract": "In this work, we investigate the generalization capabilities of deep neural networks. We introduce a novel measure of the effective depth of neural networks, defined as the first layer at which sample embeddings are separable using the nearest-class center classifier. Our empirical results demonstrate that, in standard classification settings, neural networks trained using Stochastic Gradient Descent (SGD) tend to have small effective depths. We also explore the relationship between effective depth, the complexity of the training dataset, and generalization. For instance, we find that the effective depth of a trained neural network increases as the proportion of random labels in the data rises. Finally, we derive a generalization bound by comparing the effective depth of a network with the minimal depth required to fit the same dataset with partially corrupted labels. This bound provides non-vacuous predictions of test performance and is found to be empirically independent of the actual depth of the network",
    "volume": "main",
    "checked": true,
    "id": "70425b0964fcff792cba8b82e8571f7047008ab2",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=wNBARGxoJn": {
    "title": "Learning to correct spectral methods for simulating turbulent flows",
    "abstract": "Despite their ubiquity throughout science and engineering, only a handful of partial differential equations (PDEs) have analytical, or closed-form solutions. This motivates a vast amount of classical work on numerical simulation of PDEs and more recently, a whirlwind of research into data-driven techniques leveraging machine learning (ML). A recent line of work indicates that a hybrid of classical numerical techniques and machine learning can offer significant improvements over either approach alone. In this work, we show that the choice of the numerical scheme is crucial when incorporating physics-based priors. We build upon Fourier-based spectral methods, which are known to be more efficient than other numerical schemes for simulating PDEs with smooth and periodic solutions. Specifically, we develop ML-augmented spectral solvers for three common PDEs of fluid dynamics. Our models are more accurate (2-4x) than standard spectral solvers at the same resolution but have longer overall runtimes (~2x), due to the additional runtime cost of the neural network component. We also demonstrate a handful of key design principles for combining machine learning and numerical methods for solving PDEs",
    "volume": "main",
    "checked": true,
    "id": "e6e0222b93b6531833fc2d4ff8f6fc35588b5b2b",
    "citation_count": 10
  },
  "https://openreview.net/forum?id=xzCDD9i4IZ": {
    "title": "Cox-Hawkes: doubly stochastic spatiotemporal Poisson processes",
    "abstract": "Hawkes processes are point process models that have been used to capture self-excitatory\nbehaviour in social interactions, neural activity, earthquakes and viral epidemics. They can\nmodel the occurrence of the times and locations of events. Here we develop a new class of\nspatiotemporal Hawkes processes that can capture both triggering and clustering behaviour\nand we provide an efficient method for performing inference. We use a log-Gaussian Cox\nprocess (LGCP) as prior for the background rate of the Hawkes process which gives arbitrary\nflexibility to capture a wide range of underlying background effects (for infectious diseases\nthese are called endemic effects). The Hawkes process and LGCP are computationally\nexpensive due to the former having a likelihood with quadratic complexity in the number\nof observations and the latter involving inversion of the precision matrix which is cubic\nin observations. Here we propose a novel approach to perform MCMC sampling for our\nHawkes process with LGCP background, using pre-trained Gaussian Process generators\nwhich provide direct and cheap access to samples during inference. We show the efficacy\nand flexibility of our approach in experiments on simulated data and use our methods to\nuncover the trends in a dataset of reported crimes in the US",
    "volume": "main",
    "checked": true,
    "id": "f89396d31e0d0f35ac7a99de4a73707f00b9cd04",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=ilHM31lXC4": {
    "title": "Personalized Federated Learning: A Unified Framework and Universal Optimization Techniques",
    "abstract": "We investigate the optimization aspects of personalized Federated Learning (FL). We propose general optimizers that can be applied to numerous existing personalized FL objectives, specifically a tailored variant of Local SGD and variants of accelerated coordinate descent/accelerated SVRCD. By examining a general personalized objective capable of recovering many existing personalized FL objectives as special cases, we develop a comprehensive optimization theory applicable to a wide range of strongly convex personalized FL models in the literature. We showcase the practicality and/or optimality of our methods in terms of communication and local computation. Remarkably, our general optimization solvers and theory can recover the best-known communication and computation guarantees for addressing specific personalized FL objectives. Consequently, our proposed methods can serve as universal optimizers, rendering the design of task-specific optimizers unnecessary in many instances",
    "volume": "main",
    "checked": true,
    "id": "44fa4438b1319f0ca97af13fe1a361f01e16aab6",
    "citation_count": 29
  },
  "https://openreview.net/forum?id=l5BzfQhROl": {
    "title": "Generating Teammates for Training Robust Ad Hoc Teamwork Agents via Best-Response Diversity",
    "abstract": "Ad hoc teamwork (AHT) is the challenge of designing a robust learner agent that effectively collaborates with unknown teammates without prior coordination mechanisms. Early approaches address the AHT challenge by training the learner with a diverse set of handcrafted teammate policies, usually designed based on an expert's domain knowledge about the policies the learner may encounter. However, implementing teammate policies for training based on domain knowledge is not always feasible. In such cases, recent approaches attempted to improve the robustness of the learner by training it with teammate policies generated by optimising information-theoretic diversity metrics. The problem with optimising existing information-theoretic diversity metrics for teammate policy generation is the emergence of superficially different teammates. When used for AHT training, superficially different teammate behaviours may not improve a learner's robustness during collaboration with unknown teammates. In this paper, we present an automated teammate policy generation method optimising the Best-Response Diversity (BRDiv) metric, which measures diversity based on the compatibility of teammate policies in terms of returns. We evaluate our approach in environments with multiple valid coordination strategies, comparing against methods optimising information-theoretic diversity metrics and an ablation not optimising any diversity metric. Our experiments indicate that optimising BRDiv yields a diverse set of training teammate policies that improve the learner's performance relative to previous teammate generation approaches when collaborating with near-optimal previously unseen teammate policies",
    "volume": "main",
    "checked": true,
    "id": "ede53ce63a31e7398b657463415e7429399a6bb0",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=ZgXfXSz51n": {
    "title": "Guillotine Regularization: Why removing layers is needed to improve generalization in Self-Supervised Learning",
    "abstract": "One unexpected technique that emerged in recent years consists in training a Deep Network (DN) with a Self-Supervised Learning (SSL) method, and using this network on downstream tasks but with its last few layers entirely removed. This usually skimmed-over trick of throwing away the entire projector is actually critical for SSL methods to display competitive performances. For example, on ImageNet classification, more than 30 points of percentage can be gained that way. This is a little vexing, as one would hope that the network layer at which invariance is explicitly enforced by the SSL criterion during training (the last layer) should be the one to use for best generalization performance downstream. But it seems not to be, and this study sheds some light on why.\nThis trick, which we name Guillotine Regularization (GR), is in fact a generically applicable method that has been used to improve generalization performance in transfer learning scenarios. In this work, we identify the underlying reasons behind its success and challenge the preconceived idea that we should through away the entire projector in SSL. In fact, the optimal layer to use might change significantly depending on the training setup, the data or the downstream task. Lastly, we give some insights on how to reduce the need for a projector in SSL by aligning the pretext SSL task and the downstream task",
    "volume": "main",
    "checked": true,
    "id": "3f60e8735f735cc84febde2340cb735e33fa1a76",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=MTFf1rDDEI": {
    "title": "Successor Feature Representations",
    "abstract": "Transfer in Reinforcement Learning aims to improve learning performance on target tasks using knowledge from experienced source tasks. Successor Representations (SR) and their extension Successor Features (SF) are prominent transfer mechanisms in domains where reward functions change between tasks. They reevaluate the expected return of previously learned policies in a new target task to transfer their knowledge. The SF framework extended SR by linearly decomposing rewards into successor features and a reward weight vector allowing their application in high-dimensional tasks. But this came with the cost of having a linear relationship between reward functions and successor features, limiting its application to tasks where such a linear relationship exists. We propose a novel formulation of SR based on learning the cumulative discounted probability of successor features, called Successor Feature Representations (SFR). Crucially, SFR allows to reevaluate the expected return of policies for general reward functions. We introduce different SFR variations, prove its convergence, and provide a guarantee on its transfer performance. Experimental evaluations based on SFR with function approximation demonstrate its advantage over SF not only for general reward functions, but also in the case of linearly decomposable reward functions",
    "volume": "main",
    "checked": true,
    "id": "977369cc594796a2d5af2b5e8e968641b569d533",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=Jjl2c8kWUc": {
    "title": "Lightweight Learner for Shared Knowledge Lifelong Learning",
    "abstract": "In Lifelong Learning (LL), agents continually learn as they encounter new conditions and tasks. Most current LL is limited to a single agent that learns tasks sequentially. Dedicated LL machinery is then deployed to mitigate the forgetting of old tasks as new tasks are learned. This is inherently slow. We propose a new Shared Knowledge Lifelong Learning (SKILL) challenge, which deploys a decentralized population of LL agents that each sequentially learn different tasks, with all agents operating independently and in parallel. After learning their respective tasks, agents share and consolidate their knowledge over a decentralized communication network, so that, in the end, all agents can master all tasks. We present one solution to SKILL which uses Lightweight Lifelong Learning (LLL) agents, where the goal is to facilitate efficient sharing by minimizing the fraction of the agent that is specialized for any given task. Each LLL agent thus consists of a common task-agnostic immutable part, where most parameters are, and individual task-specific modules that contain fewer parameters but are adapted to each task. Agents share their task-specific modules, plus summary information (\"task anchors\") representing their tasks in the common task-agnostic latent space of all agents. Receiving agents register each received task-specific module using the corresponding anchor. Thus, every agent improves its ability to solve new tasks each time new task-specific modules and anchors are received. If all agents can communicate with all others, eventually all agents become identical and can solve all tasks. On a new, very challenging SKILL-102 dataset with 102 image classification tasks (5,033 classes in total, 2,041,225 training, 243,464 validation, and 243,464 test images), we achieve much higher (and SOTA) accuracy over 8 LL baselines, while also achieving near perfect parallelization. Code and data can be found at https://github.com/gyhandy/Shared-Knowledge-Lifelong-Learning",
    "volume": "main",
    "checked": true,
    "id": "beed9a33fe65602bf10e3dd283206f1e1fcdf9c3",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=6rbcq0qacA": {
    "title": "Deep Plug-and-Play Clustering with Unknown Number of Clusters",
    "abstract": "Clustering is an essential task for the purpose that data points can be classified in an unsupervised manner. Most deep clustering algorithms are very effective when given the number of clusters K. However, when K is unknown, finding the appropriate K for these algorithms can be computationally expensive via model-selection criteria, and applying algorithms with an inaccurate K can hardly achieve the state-of-the-art performance. This paper proposes a plug-and-play clustering module to automatically adjust the number of clusters, which can be easily embedded into existing deep parametric clustering methods. By analyzing the goal of clustering, a split-and-merge framework is introduced to reduce the intra-class diversity and increase the inter-class difference, which leverages the entropy between different clusters. Specifically, given an initial clustering number, clusters can be split into sub-clusters or merged into super-clusters and converge to a stable number of K clusters at the end of training. Experiments on benchmark datasets demonstrate that the proposed method can achieve comparable performance with the state-of-the-art works without requiring the number of clusters",
    "volume": "main",
    "checked": true,
    "id": "5c83672a68e1aa8bcc7db8a6bc77607cdb102751",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=v73h3bYE2Z": {
    "title": "When to Trust Aggregated Gradients: Addressing Negative Client Sampling in Federated Learning",
    "abstract": "Federated Learning has become a widely-used framework which allows learning a global model on decentralized local datasets under the condition of protecting local data privacy. However, federated learning faces severe optimization difficulty when training samples are not independently and identically distributed (non-i.i.d.). In this paper, we point out that the client sampling practice plays a decisive role in the aforementioned optimization difficulty. We find that the negative client sampling will cause the merged data distribution of currently sampled clients heavily inconsistent with that of all available clients, and further make the aggregated gradient unreliable. To address this issue, we propose a novel learning rate adaptation mechanism to adaptively adjust the server learning rate for the aggregated gradient in each round, according to the consistency between the merged data distribution of currently sampled clients and that of all available clients. Specifically, we make theoretical deductions to find a meaningful and robust indicator that is positively related to the optimal server learning rate, which is supposed to minimize the Euclidean distance between the aggregated gradient given currently sampled clients and that if all clients could participate in the current round. We show that our proposed indicator can effectively reflect the merged data distribution of sampled clients, thus we utilize it for the server learning rate adaptation. Extensive experiments on multiple image and text classification tasks validate the great effectiveness of our method in various settings. Our code is available at https://github.com/lancopku/FedGLAD",
    "volume": "main",
    "checked": true,
    "id": "90bf8112b28e6daf397873ba744f59ce8a5c3cbb",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=R8TU3pfzFr": {
    "title": "A Measure of the Complexity of Neural Representations based on Partial Information Decomposition",
    "abstract": "In neural networks, task-relevant information is represented jointly by groups of neurons. However, the specific way in which this mutual information about the classification label is distributed among the individual neurons is not well understood: While parts of it may only be obtainable from specific single neurons, other parts are carried redundantly or synergistically by multiple neurons. We show how Partial Information Decomposition (PID), a recent extension of information theory, can disentangle these different contributions. From this, we introduce the measure of ``Representational Complexity'', which quantifies the difficulty of accessing information spread across multiple neurons. We show how this complexity is directly computable for smaller layers. For larger layers, we propose subsampling and coarse-graining procedures and prove corresponding bounds on the latter. Empirically, for quantized deep neural networks solving the MNIST and CIFAR10 tasks, we observe that representational complexity decreases both through successive hidden layers and over training, and compare the results to related measures. Overall, we propose representational complexity as a principled and interpretable summary statistic for analyzing the structure and evolution of neural representations and complex systems in general",
    "volume": "main",
    "checked": true,
    "id": "42b41c171e6c11443cbb5f4b1b1783d77b036917",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=MR4glug5GU": {
    "title": "Trip-ROMA: Self-Supervised Learning with Triplets and Random Mappings",
    "abstract": "Contrastive self-supervised learning (SSL) methods, such as MoCo and SimCLR, have achieved great success in unsupervised visual representation learning. They rely on a large number of negative pairs and thus require either large memory banks or large batches. Some recent non-contrastive SSL methods, such as BYOL and SimSiam, attempt to discard negative pairs and have also shown remarkable performance. To avoid collapsed solutions caused by not using negative pairs, these methods require non-trivial asymmetry designs. However, in small data regimes, we can not obtain a sufficient number of negative pairs or effectively avoid the over-fitting problem when negatives are not used at all. To address this situation, we argue that negative pairs are still important but one is generally sufficient for each positive pair. We show that a simple Triplet-based loss (Trip) can achieve surprisingly good performance without requiring large batches or asymmetry designs. Moreover, to alleviate the over-fitting problem in small data regimes and further enhance the effect of Trip, we propose a simple plug-and-play RandOm MApping (ROMA) strategy by randomly mapping samples into other spaces and requiring these randomly projected samples to satisfy the same relationship indicated by the triplets. Integrating the triplet-based loss with random mapping, we obtain the proposed method Trip-ROMA. Extensive experiments, including unsupervised representation learning and unsupervised few-shot learning, have been conducted on ImageNet-1K and seven small datasets. They successfully demonstrate the effectiveness of Trip-ROMA and consistently show that ROMA can further effectively boost other SSL methods. Code is available at https://github.com/WenbinLee/Trip-ROMA",
    "volume": "main",
    "checked": true,
    "id": "08090f7a9d271e2c00f9bc75a4789d25befa01a4",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=DUsgPi3oCC": {
    "title": "Conditional Permutation Invariant Flows",
    "abstract": "We present a conditional generative probabilistic model of set-valued data with a tractable log density.  This model is a continuous normalizing flow governed by permutation equivariant dynamics. These dynamics are driven by a learnable per-set-element term and pairwise interactions, both parametrized by deep neural networks.  We illustrate the utility of this model via applications including (1) complex traffic scene generation conditioned on visually specified map information, and (2) object bounding box generation conditioned directly on images.  We train our model by maximizing the expected likelihood of labeled conditional data under our flow, with the aid of a penalty that ensures the dynamics are smooth and hence efficiently solvable. Our method significantly outperforms non-permutation invariant baselines in terms of log likelihood and domain-specific metrics (offroad, collision, and combined infractions), yielding realistic samples that are difficult to distinguish from data",
    "volume": "main",
    "checked": true,
    "id": "635ba79662d9becdd2331ab7a3d1336bbb8ed39c",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=XejzjAjKjv": {
    "title": "Event Tables for Efficient Experience Replay",
    "abstract": "Experience replay (ER) is a crucial component of many deep reinforcement learning (RL) systems.\nHowever, uniform sampling from an ER buffer can lead to slow convergence and unstable asymptotic\nbehaviors. This paper introduces Stratified Sampling from Event Tables (SSET), which partitions\nan ER buffer into Event Tables, each capturing important subsequences of optimal behavior. We\nprove a theoretical advantage over the traditional monolithic buffer approach and combine SSET with\nan existing prioritized sampling strategy to further improve learning speed and stability. Empirical\nresults in challenging MiniGrid domains, benchmark RL environments, and a high-fidelity car racing\nsimulator demonstrate the advantages and versatility of SSET over existing ER buffer sampling",
    "volume": "main",
    "checked": true,
    "id": "a2756a25accb20111ddb2e385b7a2a0b7df11870",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=RLYkyucU6k": {
    "title": "Agent-State Construction with Auxiliary Inputs",
    "abstract": "In many, if not every realistic sequential decision-making task, the decision-making agent is not able to model the full complexity of the world. The environment is often much larger and more complex than the agent, a setting also known as partial observability. In such settings, the agent must leverage more than just the current sensory inputs; it must construct an agent state that summarizes previous interactions with the world. Currently, a popular approach for tackling this problem is to learn the agent-state function via a recurrent network from the agent's sensory stream as input. Many impressive reinforcement learning applications have instead relied on environment-specific functions to aid the agent's inputs for history summarization. These augmentations are done in multiple ways, from simple approaches like concatenating observations to more complex ones such as uncertainty estimates. Although ubiquitous in the field, these additional inputs, which we term auxiliary inputs, are rarely emphasized, and it is not clear what their role or impact is. In this work we explore this idea further, and relate these auxiliary inputs to prior classic approaches to state construction. We present a series of examples illustrating the different ways of using auxiliary inputs for reinforcement learning. We show that these auxiliary inputs can be used to discriminate between observations that would otherwise be aliased, leading to more expressive features that smoothly interpolate between different states. Finally, we show that this approach is complementary to state-of-the-art methods such as recurrent neural networks and truncated back-propagation through time, and acts as a heuristic that facilitates longer temporal credit assignment, leading to better performance",
    "volume": "main",
    "checked": true,
    "id": "a04611387661acfc81266260fa443803062953d0",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=9KoBOlstTq": {
    "title": "Modelling sequential branching dynamics with a multivariate branching Gaussian process",
    "abstract": "The Branching Gaussian Process (BGP) model is a modification of the Overlapping Mixture\nof Gaussian Processes (OMGP) where latent functions branch in time. The BGP model\nwas introduced as a method to model bifurcations in single-cell gene expression data and\norder genes by inferring their branching time parameter. A limitation of the current BGP\nmodel is that the assignment of observations to latent functions is inferred independently\nfor each output dimension (gene). This leads to inconsistent assignments across outputs\nand reduces the accuracy of branching time inference. Here, we propose a multivariate\nbranching Gaussian process (MBGP) model to perform joint branch assignment inference\nacross multiple output dimensions. This ensures that branch assignments are consistent and\nleverages more data for branching time inference. Model inference is more challenging than\nfor the original BGP or OMGP models because assignment labels can switch from trunk to\nbranch lineages as branching times change during inference. To scale up inference to large\ndatasets we use sparse variational Bayesian inference. We examine the effectiveness of our\napproach on synthetic data and a single-cell RNA-Seq dataset from mouse haematopoietic\nstem cells (HSCs). Our approach ensures assignment consistency by design and achieves\nimproved accuracy in branching time inference and assignment accuracy",
    "volume": "main",
    "checked": true,
    "id": "d1d330bf943ce3fe103970e755064de18398e0a8",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=j3oQF9coJd": {
    "title": "U-NO: U-shaped Neural Operators",
    "abstract": "Neural operators generalize classical neural networks to maps between infinite-dimensional spaces, e.g., function spaces. Prior works on neural operators proposed a series of novel methods to learn such maps and demonstrated unprecedented success in learning solution operators of partial differential equations. Due to their close proximity to fully connected architectures, these models mainly suffer from high memory usage and are generally limited to shallow deep learning models. In this paper, we propose U-shaped Neural Operator (U-NO), a U-shaped memory enhanced architecture that allows for deeper neural operators. U-NOs exploit the problem structures in function predictions and demonstrate fast training, data efficiency, and robustness with respect to hyperparameters choices. We study the performance of U-NO on PDE benchmarks, namely, Darcy’s flow law and the Navier-Stokes equations. We show that U-NO results in an average of 26% and 44% prediction improvement on Darcy’s flow and turbulent Navier-Stokes equations, respectively, over the state of the art. On Navier-Stokes 3D spatiotemporal operator learning task, we show U-NO provides 37% improvement over the state of art methods",
    "volume": "main",
    "checked": true,
    "id": "d7ec7ddcbba6a702991a5c66c7c36c168e384dfc",
    "citation_count": 19
  },
  "https://openreview.net/forum?id=uyTL5Bvosj": {
    "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models",
    "abstract": "Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models.\nTo address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG- bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood develop- ment, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google- internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit \"breakthrough\" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting",
    "volume": "main",
    "checked": true,
    "id": "34503c0b6a615124eaf82cb0e4a1dab2866e8980",
    "citation_count": 399
  },
  "https://openreview.net/forum?id=nOk4XEB7Ke": {
    "title": "Fast&Fair: Training Acceleration and Bias Mitigation for GNNs",
    "abstract": "Graph neural networks (GNNs) have been demonstrated to achieve state-of-the-art performance for a number of graph-based learning tasks, which leads to a rise in their employment in various domains. However, it has been shown that GNNs may inherit and even amplify bias within training data, which leads to unfair results towards certain sensitive groups. Meanwhile, training of GNNs introduces additional challenges, such as slow convergence and possible instability. Faced with these limitations, this work proposes FairNorm, a unified normalization-based framework that reduces the bias in GNN-based learning while also providing provably faster convergence. Specifically, FairNorm presents individual normalization operators over different sensitive groups and introduces fairness regularizers on the learnable parameters of normalization layers to reduce the bias in GNNs. The design of the proposed regularizers is built upon analyses that illuminate the sources of bias in graph-based learning. Experiments on node classification over real-world networks demonstrate the efficiency of the proposed scheme in improving fairness in terms of statistical parity and equal opportunity compared to fairness-aware baselines. In addition, it is empirically shown that the proposed framework leads to faster convergence compared to the naive baseline where no normalization is employed",
    "volume": "main",
    "checked": true,
    "id": "59a3e8b8586e497c39e227a7c4399d87314f90f1",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=IqJsyulDUX": {
    "title": "Ensembles for Uncertainty Estimation: Benefits of Prior Functions and Bootstrapping",
    "abstract": "In machine learning, an agent needs to estimate uncertainty to efficiently explore and adapt and to make effective decisions. A common approach to uncertainty estimation maintains an ensemble of models. In recent years, several approaches have been proposed for training ensembles, and conflicting views prevail with regards to the importance of various ingredients of these approaches. In this paper, we aim to address the benefits of two ingredients -- prior functions and bootstrapping -- which have come into question. We show that prior functions can significantly improve an ensemble agent's joint predictions across inputs and that bootstrapping affords additional benefits if the signal-to-noise ratio varies across inputs.  Our claims are justified by both theoretical and experimental results",
    "volume": "main",
    "checked": true,
    "id": "f030e634f1b20b23f5d6ea5bf4472426244d66d5",
    "citation_count": 5
  },
  "https://openreview.net/forum?id=W98rebBxlQ": {
    "title": "Soft Diffusion: Score Matching with General Corruptions",
    "abstract": "We define a broader family of corruption processes that generalizes previously known diffusion models. To reverse these general diffusions, we propose a new objective called Soft Score Matching. Soft Score Matching incorporates the degradation process in the network and provably learns the score function for any linear corruption process. Our new loss trains the model to predict a clean image, that after corruption, matches the diffused observation. This objective learns the gradient of the likelihood under suitable regularity conditions for the family of linear corruption processes. We further develop an algorithm to select the corruption levels for general diffusion processes and a novel sampling method that we call Momentum Sampler. We show experimentally that our framework works for general linear corruption processes, such as Gaussian blur and masking. Our method outperforms all linear diffusion models on CelebA-64 achieving FID score 1.85. We also show computational benefits compared to vanilla denoising diffusion",
    "volume": "main",
    "checked": false,
    "id": "43b75b59a75d618596abe69579b7cb2b9c69ef9c",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=mySiFHCeAl": {
    "title": "Spectral Regularization Allows Data-frugal Learning over Combinatorial Spaces",
    "abstract": "Data-driven machine learning models are being increasingly employed in several important inference problems in biology, chemistry, and physics, which require learning over combinatorial spaces. Recent empirical evidence (see, e.g., ~\\cite{tseng2020fourier,aghazadeh2021epistatic,ha2021adaptive}) suggests that regularizing the spectral representation of such models improves their generalization power when labeled data is scarce. However, despite these empirical studies, the theoretical underpinning of when and how spectral regularization enables improved generalization is poorly understood. In this paper, we focus on learning pseudo-Boolean functions and demonstrate that regularizing the empirical mean squared error by the $L_1$ norm of the spectral transform of the learned function reshapes the loss landscape and allows for data-frugal learning under a restricted secant condition on the learner's empirical error measured against the ground truth function. Under a weaker quadratic growth condition, we show that stationary points, which also approximately interpolate the training data points achieve statistically optimal generalization performance. Complementing our theory, we empirically demonstrate that running gradient descent on the regularized loss results in a better generalization performance compared to baseline algorithms in several data-scarce real-world problems",
    "volume": "main",
    "checked": true,
    "id": "a902afd1e45a9409c3b6209fe2f634232cd7cf11",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=jVMMdg31De": {
    "title": "A Cubic Regularization Approach for Finding Local Minimax Points in Nonconvex Minimax Optimization",
    "abstract": "Gradient descent-ascent (GDA) is a widely used algorithm for minimax optimization. However, GDA has been proved to converge to stationary points for nonconvex minimax optimization, which are suboptimal compared with local minimax points. In this work, we develop cubic regularization (CR) type algorithms that globally converge to local minimax points in nonconvex-strongly-concave minimax optimization. We first show that local minimax points are equivalent to second-order stationary points of a certain envelope function. Then, inspired by the classic cubic regularization algorithm, we propose an algorithm named Cubic-LocalMinimax for finding local minimax points, and provide a comprehensive convergence analysis by leveraging its intrinsic potential function. Specifically, we establish the global convergence of Cubic-LocalMinimax to a local minimax point at a sublinear convergence rate and characterize its iteration complexity. Also, we propose a GDA-based solver for solving the cubic subproblem involved in Cubic-LocalMinimax up to certain pre-defined accuracy, and analyze the overall gradient and Hessian-vector product computation complexities of such an inexact Cubic-LocalMinimax algorithm. Moreover, we propose a stochastic variant of Cubic-LocalMinimax for large-scale minimax optimization, and characterize its sample complexity under stochastic sub-sampling. Experimental results demonstrate faster or comparable convergence speed of our stochastic Cubic-LocalMinimax than the state-of-the-art algorithms such as GDA and Minimax Cubic-Newton. In particular, our stochastic Cubic-LocalMinimax was also faster as compared to several other algorithms for minimax optimization on a particular adversarial loss for training a convolutional neural network on MNIST",
    "volume": "main",
    "checked": true,
    "id": "010ccf4ee5abc99cbba51ae62deeb458e35d7ad1",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=SEDWlhcFWA": {
    "title": "Assisted Learning for Organizations with Limited Imbalanced Data",
    "abstract": "In the era of big data, many big organizations are integrating machine learning into their work pipelines to facilitate data analysis. However, the performance of their trained models is often restricted by limited and imbalanced data available to them. In this work, we develop an assisted learning framework for assisting organizations to improve their learning performance. The organizations have sufficient computation resources but are subject to stringent data-sharing and collaboration policies. Their limited imbalanced data often cause biased inference and sub-optimal decision-making. In assisted learning, an organizational learner purchases assistance service from an external service provider and aims to enhance its model performance within only a few assistance rounds. We develop effective stochastic training algorithms for both assisted deep learning and assisted reinforcement learning. Different from existing distributed algorithms that need to frequently transmit gradients or models, our framework allows the learner to only occasionally share information with the service provider, but still obtain a model that achieves near-oracle performance as if all the data were centralized",
    "volume": "main",
    "checked": true,
    "id": "199d7a655e51e7f48bbc4d0c7c548b110b62b045",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=EPPqt3uERT": {
    "title": "Transformer for Partial Differential Equationsâ Operator Learning",
    "abstract": "Data-driven learning of partial differential equations' solution operators has recently emerged as a promising paradigm for approximating the underlying solutions. The solution operators are usually parameterized by deep learning models that are built upon problem-specific inductive biases. An example is a convolutional or a graph neural network that exploits the local grid structure where functions' values are sampled. The attention mechanism, on the other hand, provides a flexible way to implicitly exploit the patterns within inputs, and furthermore, relationship between arbitrary query locations and inputs. In this work, we present an attention-based framework for data-driven operator learning, which we term Operator Transformer (OFormer). Our framework is built upon self-attention, cross-attention, and a set of point-wise multilayer perceptrons (MLPs), and thus it makes few assumptions on the sampling pattern of the input function or query locations. We show that the proposed framework is competitive on standard PDE benchmark problems and can flexibly be adapted to different types of grids",
    "volume": "main",
    "checked": false,
    "id": "179070d3d43e97d1ce4d12127a3dc63581328809",
    "citation_count": 18
  },
  "https://openreview.net/forum?id=gvcDSDYUZx": {
    "title": "Efficient Model-Based Multi-Agent Mean-Field Reinforcement Learning",
    "abstract": "Learning in multi-agent systems is highly challenging due to several factors including the non-stationarity introduced by agents' interactions and the combinatorial nature of their state and action spaces.\nIn particular, we consider the Mean-Field Control (MFC) problem which assumes an asymptotically infinite population of identical agents that aim to collaboratively maximize the collective reward. In many cases, solutions of an MFC problem are good approximations for large systems, hence, efficient learning for MFC is valuable for the analogous discrete agent setting with many agents.\nSpecifically, we focus on the case of unknown system dynamics where the goal is to simultaneously optimize for the rewards and learn from experience. We propose an efficient model-based reinforcement learning algorithm, $\\text{M}^3$--UCRL, that runs in episodes, balances between exploration and exploitation during policy learning, and provably solves this problem. Our main theoretical contributions are the first general regret bounds for model-based reinforcement learning for MFC, obtained via a novel mean-field type analysis. To learn the system’s dynamics, $\\text{M}^3$--UCRL can be instantiated with various statistical models, e.g., neural networks or Gaussian Processes. Moreover, we provide a practical parametrization of the core optimization problem that facilitates gradient-based optimization techniques when combined with differentiable dynamics approximation methods such as neural networks",
    "volume": "main",
    "checked": true,
    "id": "88b80affbaeacc42da08831a86a874d825f28555",
    "citation_count": 21
  },
  "https://openreview.net/forum?id=y4CGF1A8VG": {
    "title": "Machine Explanations and Human Understanding",
    "abstract": "Explanations are hypothesized to improve human understanding of machine learning models and achieve a variety of desirable outcomes, ranging from model debugging to enhancing human decision making. However, empirical studies have found mixed and even negative results. An open question, therefore, is under what conditions explanations can improve human understanding and in what way. To address this question, we first identify three core concepts that cover most existing quantitative measures of understanding: task decision boundary, model decision boundary, and model error. Using adapted causal diagrams, we provide a formal characterization of the relationship between these concepts and human approximations (i.e., understanding) of them. The relationship varies by the level of human intuition in different task types, such as emulation and discovery, which are often ignored when building or evaluating explanation methods. Our key result is that human intuitions are necessary for generating and evaluating machine explanations in human-AI decision making: without assumptions about human intuitions, explanations may improve human understanding of model decision boundary, but cannot improve human understanding of task decision boundary or model error. To validate our theoretical claims, we conduct human subject studies to show the importance of human intuitions. Together with our theoretical contributions, we provide a new paradigm for designing behavioral studies towards a rigorous view of the role of machine explanations across different tasks of human-AI decision making",
    "volume": "main",
    "checked": true,
    "id": "101309da0732648e72929a5327341d325fca57fa",
    "citation_count": 11
  },
  "https://openreview.net/forum?id=9aXKUJEKwV": {
    "title": "Learning to Look by Self-Prediction",
    "abstract": "We present a method for learning active vision skills, to move the camera to observe a robot's sensors from informative points of view, without external rewards or labels. We do this by jointly training a visual predictor network, which predicts future returns of the sensors using pixels, and a camera control agent, which we reward using the negative error of the predictor. The agent thus moves the camera to points of view that are most predictive for a chosen sensor, which we select using a conditioning input to the agent. We observe that despite this noisy learned reward function, the learned policies a exhibit competence by reliably framing the sensor in a specific location in the view, an emergent location which we call a behavioral fovea. We find that replacing the conventional camera with a foveal camera further increases the policies' precision",
    "volume": "main",
    "checked": true,
    "id": "496349bd33b2793f66b151eda9266e856bc1e9ab",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=slsAQHpS7n": {
    "title": "Computationally-efficient initialisation of GPs: The generalised variogram method",
    "abstract": "We present a computationally-efficient strategy to initialise the hyperparameters of a Gaussian process (GP) avoiding the computation of the likelihood function. Our strategy can be used as a pretraining stage to find initial conditions for maximum-likelihood (ML) training, or as a standalone method to compute hyperparameters values to be plugged in directly into the GP model. Motivated by the fact that training a GP via  ML is equivalent (on average) to minimising the KL-divergence between the true and learnt model, we set to explore different metrics/divergences among GPs that are computationally inexpensive and provide hyperparameter values that are close to those found via ML. In practice, we identify the GP hyperparameters by projecting the empirical covariance or (Fourier) power spectrum onto a parametric family, thus proposing and studying various measures of discrepancy operating on the temporal and frequency domains. Our contribution extends the variogram method developed by the geostatistics literature and, accordingly, it is referred to as the generalised variogram method (GVM). In addition to the theoretical presentation of GVM, we provide experimental validation in terms of accuracy, consistency with ML and computational complexity for different kernels using synthetic and real-world data",
    "volume": "main",
    "checked": true,
    "id": "1047c86bdd1a18ea12b2191afece931e6b15cf77",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=f4VyYhkRvi": {
    "title": "Fairness via In-Processing in the Over-parameterized Regime: A Cautionary Tale with MinDiff Loss",
    "abstract": "Prior work has observed that the test error of state-of-the-art deep neural networks often continues to decrease with increasing over-parameterization, a phenomenon referred to as double descent. This allows deep learning engineers to instantiate large models without having to worry about over-fitting. Despite its benefits, however, prior work has shown that over-parameterization can exacerbate bias against minority subgroups. Several fairness-constrained DNN training methods have been proposed to address this concern. Here, we critically examine MinDiff, a fairness-constrained training procedure implemented within TensorFlow's Responsible AI Toolkit, that aims to achieve Equality of Opportunity. We show that although MinDiff improves fairness for under-parameterized models, it is likely to be ineffective in the over-parameterized regime. This is because an overfit model with zero training loss is trivially group-wise fair on training data, creating an “illusion of fairness,” thus turning off the MinDiff optimization (this will apply to any disparity-based measures which care about errors or accuracy; while it won’t apply to demographic parity). We find that within specified fairness constraints, under-parameterized MinDiff models can even have lower error compared to their over-parameterized counterparts (despite baseline over-parameterized models having lower error compared to their under-parameterized counterparts). We further show that MinDiff optimization is very sensitive to choice of batch size in the under-parameterized regime. Thus, fair model training using MinDiff requires time-consuming hyper-parameter searches. Finally, we suggest using previously proposed regularization techniques, viz. L2, early stopping and flooding in conjunction with MinDiff to train fair over-parameterized models. In our results, over-parameterized models trained using MinDiff+regularization with standard batch sizes are fairer than their under-parameterized counterparts, suggesting that at the very least, regularizers should be integrated into fair deep learning flows, like MinDiff",
    "volume": "main",
    "checked": false,
    "id": "20fcf4d635036d16db881c503c1fcaf52695188b",
    "citation_count": 2
  },
  "https://openreview.net/forum?id=Oq5XKRVYpQ": {
    "title": "Graph-based Multi-ODE Neural Networks for Spatio-Temporal Traffic Forecasting",
    "abstract": "There is a recent surge in the development of spatio-temporal forecasting models in the transportation domain. Long-range traffic forecasting, however,  remains a challenging task due to the intricate and extensive spatio-temporal correlations observed in traffic networks. \nCurrent works primarily rely on road networks with graph structures and learn representations using graph neural networks (GNNs), but this approach suffers from over-smoothing problem in deep architectures. To tackle this problem, recent methods introduced the combination of GNNs with residual connections or neural ordinary differential equations (ODE). However, current graph ODE models face two key limitations in feature extraction: (1) they lean towards global temporal patterns, overlooking local patterns that are important for unexpected events; and (2) they lack dynamic semantic edges in their architectural design. In this paper, we propose a novel architecture called Graph-based Multi-ODE Neural Networks (GRAM-ODE) which is designed with multiple connective ODE-GNN modules to learn better representations by capturing different views of complex local and global dynamic spatio-temporal dependencies. We also add some techniques like shared weights and divergence constraints into the intermediate layers of distinct ODE-GNN modules to further improve their communication towards the forecasting task. Our extensive set of experiments conducted on six real-world datasets demonstrate the superior performance of GRAM-ODE compared with state-of-the-art baselines as well as the contribution of different components to the overall performance",
    "volume": "main",
    "checked": true,
    "id": "295b40b0e734987aa6fa41d18a0673bf6eb51d03",
    "citation_count": 0
  },
  "https://openreview.net/forum?id=iMmsCI0JsS": {
    "title": "TimeSeAD: Benchmarking Deep Multivariate Time-Series Anomaly Detection",
    "abstract": "Developing new methods for detecting anomalies in time series is of great practical significance, but progress is hindered by the difficulty of assessing the benefit of new methods, for the following reasons. (1) Public benchmarks are flawed (e.g., due to potentially erroneous anomaly labels), (2) there is no widely accepted standard evaluation metric, and (3) evaluation protocols are mostly inconsistent. In this work, we address all three issues: (1) We critically analyze several of the most widely-used multivariate datasets, identify a number of significant issues, and select the best candidates for evaluation. (2) We introduce a new evaluation metric for time-series anomaly detection, which—in contrast to previous metrics—is recall consistent and takes temporal correlations into account. (3) We analyze and overhaul existing evaluation protocols and provide the largest benchmark of deep multivariate time-series anomaly detection methods to date. We focus on deep-learning based methods and multivariate data, a common setting in modern anomaly detection. We provide all implementations and analysis tools in a new comprehensive library for Time Series Anomaly Detection, called TimeSeAD",
    "volume": "main",
    "checked": true,
    "id": "4c151732cfc97c2cdceed47728ff5ded4f2050c9",
    "citation_count": 1
  },
  "https://openreview.net/forum?id=I4IkGmgFJz": {
    "title": "Data Models for Dataset Drift Controls in Machine Learning With Optical Images",
    "abstract": "Camera images are ubiquitous in machine learning research. They also play a central role in the delivery of important public services spanning medicine or environmental surveying. However, the application of machine learning models in these domains has been limited because of robustness concerns. A primary failure mode are performance drops due to differences between the training and deployment data. While there are methods to prospectively validate the robustness of machine learning models to such dataset drifts, existing approaches do not account for explicit models of machine learning's primary object of interest: the data. This limits our ability to study and understand the relationship between data generation and downstream machine learning model performance in a physically accurate manner. In this study, we demonstrate how to overcome this limitation by pairing traditional machine learning with physical optics to obtain explicit and differentiable data models. We demonstrate how such data models can be constructed for image data and used to control downstream machine learning model performance related to dataset drift. The findings are distilled into three applications. First, drift synthesis enables the controlled generation of physically faithful drift test cases to power model selection and targeted generalization. Second, the gradient connection between machine learning task model and data model allows advanced, precise tolerancing of task model sensitivity to changes in the data generation. These drift forensics can be used to precisely specify the acceptable data environments in which a task model may be run. Third, drift optimization opens up the possibility to create drifts that can help the task model learn better faster, effectively optimizing the data generating process itself to support the downstream machine vision task. This is an interesting upgrade to existing imaging pipelines which traditionally have been optimized to be consumed by human users but not machine learning models. Alongside the data model code we release two datasets to the public that we collected as part of this work. In total, the two datasets, Raw-Microscopy and Raw-Drone, comprise 1,488 scientifically calibrated reference raw sensor measurements, 8,928 raw intensity variations as well as 17,856 images processed through twelve data models with different configurations. A guide to access the open code and datasets is available at https://github.com/aiaudit-org/raw2logit",
    "volume": "main",
    "checked": true,
    "id": "74009c57ded629bf5cae2021805fbdd0f693f331",
    "citation_count": 2
  }
}