{
  "https://openreview.net/forum?id=YVPb6tyRJu": {
    "title": "FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction",
    "volume": "main",
    "abstract": "A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (Yang et al., 2021). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Telepov",
      "Artem Tsypin",
      "Kuzma Khrabrov",
      "Sergey Yakukhnov",
      "Pavel Strashnov",
      "Petr Zhilyaev",
      "Egor Rumiantsev",
      "Daniel Ezhov",
      "Manvel Avetisian",
      "Olga Popova",
      "Artur Kadurin"
    ]
  },
  "https://openreview.net/forum?id=Ls1E16bTj8": {
    "title": "In search of projectively equivariant networks",
    "volume": "main",
    "abstract": "Equivariance of linear neural network layers is well studied. In this work, we relax the equivariance condition to only be true in a projective sense. Hereby, we introduce the topic of projective equivariance to the machine learning audience. We theoretically study the relation of projectively and linearly equivariant linear layers. We find that in some important cases, surprisingly, the two types of layers coincide. We also propose a way to construct a projectively equivariant neural network, which boils down to building a standard equivariant network where the linear group representations acting on each intermediate feature space are lifts of projective group representations. Projective equivariance is showcased in two simple experiments. Code for the experiments is provided in the supplementary material",
    "checked": true,
    "id": "87e4e0723dea55ad3779ffe9a047f495990ddd1c",
    "semantic_title": "in search of projectively equivariant networks",
    "citation_count": 0,
    "authors": [
      "Georg Bökman",
      "Axel Flinth",
      "Fredrik Kahl"
    ]
  },
  "https://openreview.net/forum?id=2wecNCpZ7Y": {
    "title": "Improving Native CNN Robustness with Filter Frequency Regularization",
    "volume": "main",
    "abstract": "Neural networks tend to overfit the training distribution and perform poorly on out-of-distribution data. A conceptually simple solution lies in adversarial training, which introduces worst-case perturbations into the training data and thus improves model generalization to some extent. However, it is only one ingredient towards generally more robust models and requires knowledge about the potential attacks or inference time data corruptions during model training. This paper focuses on the native robustness of models that can learn robust behavior directly from conventional training data without out-of-distribution examples. To this end, we study the frequencies in learned convolution filters. Clean-trained models often prioritize high-frequency information, whereas adversarial training enforces models to shift the focus to low-frequency details during training. By mimicking this behavior through frequency regularization in learned convolution weights, we achieve improved native robustness to adversarial attacks, common corruptions, and other out-of-distribution tests. Additionally, this method leads to more favorable shifts in decision-making towards low-frequency information, such as shapes, which inherently aligns more closely with human vision",
    "checked": true,
    "id": "f2b15de1db12bfaeab8365202e03f364caa1dee2",
    "semantic_title": "improving native cnn robustness with filter frequency regularization",
    "citation_count": 10,
    "authors": [
      "Jovita Lukasik",
      "Paul Gavrikov",
      "Janis Keuper",
      "Margret Keuper"
    ]
  },
  "https://openreview.net/forum?id=wzzrs5QH5k": {
    "title": "Resmax: An Alternative Soft-Greedy Operator for Reinforcement Learning",
    "volume": "main",
    "abstract": "Soft-greedy operators, namely $\\varepsilon$-greedy and softmax, remain a common choice to induce a basic level of exploration for action-value methods in reinforcement learning. These operators, however, have a few critical limitations. In this work, we investigate a simple soft-greedy operator, which we call resmax, that takes actions proportionally to their max action gap: the residual to the estimated maximal value. It is simple to use and ensures coverage of the state-space like $\\varepsilon$-greedy, but focuses exploration more on potentially promising actions like softmax. Further, it does not concentrate probability as quickly as softmax, and so better avoids overemphasizing sub-optimal actions that appear high-valued during learning. Additionally, we prove it is a non-expansion for any fixed exploration hyperparameter, unlike the softmax policy which requires a state-action specific temperature to obtain a non-expansion (called mellowmax). We empirically validate that resmax is comparable to or outperforms $\\varepsilon$-greedy and softmax across a variety of environments in tabular and deep RL",
    "checked": true,
    "id": "8321641f955713efa53caba33b6d7cbf87964f38",
    "semantic_title": "resmax: an alternative soft-greedy operator for reinforcement learning",
    "citation_count": 2,
    "authors": [
      "Erfan Miahi",
      "Revan MacQueen",
      "Alex Ayoub",
      "Abbas Masoumzadeh",
      "Martha White"
    ]
  },
  "https://openreview.net/forum?id=SnPEhMyuYX": {
    "title": "Privacy Budget Tailoring in Private Data Analysis",
    "volume": "main",
    "abstract": "We consider the problem of learning differentially private linear and logistic regression models that do not exhibit disparate performance for minority groups in the data. Small-sized datasets pose a challenging regime for differential privacy; that is, satisfying differential privacy while learning models from data can lead to models with worse accuracy for minority---in size---subgroups. To address this challenge, inspired by Abowd & Schmutte (2018), we propose: (i) to systematically tailor the privacy budget to the different groups, (ii) use linear optimization oracles in a grid to optimize Lagrangian objectives that correspond to fair learning and optimization. We present efficient differentially private algorithms for linear and logistic regression subject to fairness constraints (e.g., bounded group loss) that allocate the privacy budget based on the private standard error of each subgroup in the data. Consequently, the formulation reduces the amount of noise added to these groups, which leads to more accurate models for such groups. We validate the proposed, group-aware budget allocation, method on synthetic and real-world datasets where we show significant reductions in prediction error for the smallest groups, while still preserving sufficient privacy to protect the minority group from re-identification attacks. In addition, we provide sample complexity lower bounds for our problem formulation",
    "checked": true,
    "id": "90934943ff80ffa3e36efaddd23b222f523bf318",
    "semantic_title": "privacy budget tailoring in private data analysis",
    "citation_count": 1,
    "authors": [
      "Daniel Alabi",
      "Chris Wiggins"
    ]
  },
  "https://openreview.net/forum?id=CviCLt44Em": {
    "title": "Smoothed Differential Privacy",
    "volume": "main",
    "abstract": "Differential privacy (DP) is a widely-accepted and widely-applied notion of privacy based on worst-case analysis. Often, DP classifies most mechanisms without additive noise as non-private (Dwork et al., 2014). Thus, additive noises are added to improve privacy (to achieve DP). However, in many real-world applications, adding additive noise is undesirable (Bagdasaryan et al., 2019) and sometimes prohibited (Liu et al., 2020). In this paper, we propose a natural extension of DP following the worst average-case idea behind the celebrated smoothed analysis (Spielman & Teng, May 2004). Our notion, smoothed DP, can effectively measure the privacy leakage of mechanisms without additive noises under realistic settings. We prove that any discrete mechanism with sampling procedures is more private than what DP predicts, while many continuous mechanisms with sampling procedures are still non-private under smoothed DP. In addition, we prove several desirable properties of smoothed DP, including composition, robustness to post-processing, and distribution reduction. Based on those properties, we propose an efficient algorithm to calculate the privacy parameters for smoothed DP. Experimentally, we verify that, according to smoothed DP, the discrete sampling mechanisms are private in real-world elections, and some discrete neural networks can be private without adding any additive noise. We believe that these results contribute to the theoretical foundation of realistic privacy measures beyond worst-case analysis",
    "checked": true,
    "id": "a2beb939daba8c6a835accb98afe1d79990e7aae",
    "semantic_title": "smoothed differential privacy",
    "citation_count": 0,
    "authors": [
      "Ao Liu",
      "Yu-Xiang Wang",
      "Lirong Xia"
    ]
  },
  "https://openreview.net/forum?id=sY75NqDRk1": {
    "title": "Distributed Architecture Search Over Heterogeneous Distributions",
    "volume": "main",
    "abstract": "Federated learning (FL) is an efficient learning framework that assists distributed machine learning when data cannot be shared with a centralized server. Recent advancements in FL use predefined architecture-based learning for all clients. However, given that clients' data are invisible to the server and data distributions are non-identical across clients, a predefined architecture discovered in a centralized setting may not be an optimal solution for all the clients in FL. Motivated by this challenge, we introduce SPIDER, an algorithmic framework that aims to Search PersonalIzed neural architecture for feDERated learning. SPIDER is designed based on two unique features: (1) alternately optimizing one architecture-homogeneous global model in a generic FL manner and architecture-heterogeneous local models that are connected to the global model by weight-sharing-based regularization, (2) achieving architecture-heterogeneous local models by a perturbation-based neural architecture search method. Experimental results demonstrate superior prediction performance compared with other state-of-the-art personalization methods",
    "checked": true,
    "id": "e3d4c7af9fe350ec99e77aff9c1e729da6363c04",
    "semantic_title": "distributed architecture search over heterogeneous distributions",
    "citation_count": 0,
    "authors": [
      "Erum Mushtaq",
      "Chaoyang He",
      "Jie Ding",
      "Salman Avestimehr"
    ]
  },
  "https://openreview.net/forum?id=P9haooN9v2": {
    "title": "DreamEdit: Subject-driven Image Editing",
    "volume": "main",
    "abstract": "Subject-driven image generation aims at generating images containing customized subjects, which has recently drawn enormous attention from the research community. Nevertheless, the previous works cannot precisely control the background and position of the target subject. In this work, we aspire to fill the void of the existing subject-driven generation tasks. To this end, we propose two novel subject-driven editing sub-tasks, i.e., Subject Replacement and Subject Addition. The new tasks are challenging in multiple aspects: replacing a subject with a customized one can totally change its shape, texture, and color, while adding a target subject to a designated position in a provided scene necessitates a rational context-aware posture of the subject. To conquer these two novel tasks, we first manually curate a new dataset called DreamEditBench containing 22 different types of subjects, and 440 source images, which cover diverse scenarios with different difficulty levels. We plan to host DreamEditBench as a platform and hire trained evaluators for standardized human evaluation. We also devise an innovative method DreamEditor to resolve these tasks by performing iterative generation, which enables a smooth adaptation to the customized subject. In this project, we conduct automatic and human evaluations to understand the performance of our DreamEditor and baselines on DreamEditBench. We found that the new tasks are challenging for the existing models. For Subject Replacement, we found that the existing models are particularly sensitive to the shape and color of the original subject. When the original subject and the customized subject are highly different, the model failure rate will dramatically increase. For Subject Addition, we found that the existing models cannot easily blend the customized subjects into the background smoothly, which causes noticeable artifacts in the generated image. We hope that DreamEditBench can become a standardized platform to enable future investigations towards building more controllable subject-driven image editing. Our project and benchmark homepage is https://dreameditbenchteam.github.io/",
    "checked": true,
    "id": "2cf1de499a91aaef4695c716f37bbad9868ecec5",
    "semantic_title": "dreamedit: subject-driven image editing",
    "citation_count": 31,
    "authors": [
      "Tianle Li",
      "Max Ku",
      "Cong Wei",
      "Wenhu Chen"
    ]
  },
  "https://openreview.net/forum?id=4uflhObpcp": {
    "title": "UnIVAL: Unified Model for Image, Video, Audio and Language Tasks",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) have made the ambitious quest for generalist agents significantly far from being a fantasy. A key hurdle for building such general models is the diversity and heterogeneity of tasks and modalities. A promising solution is unification, allowing the support of a myriad of tasks and modalities within one unified framework. While few large models (e.g., Flamingo (Alayrac et al. 2022)), trained on massive datasets, can support more than two modalities, current small to mid-scale unified models are still limited to 2 modalities, usually image-text or video-text. The question that we ask is: is it possible to build efficiently a unified model that can support all modalities? To answer this, we propose UnIVAL, a step further towards this ambitious goal. Without relying on fancy datasets sizes or models with billions of parameters, the ~ 0.25B parameter UnIVAL model goes beyond two modalities and unifies text, images, video, and audio into a single model. Our model is efficiently pretrained on many tasks, based on task balancing and multimodal curriculum learning. UnIVAL shows competitive performance to existing state-of-the-art approaches, across image and video-text tasks. The feature representations learned from image and video-text modalities, allows the model to achieve competitive performance when finetuned on audio-text tasks, despite not being pretrained on audio. Thanks to the unified model, we propose a novel study on multimodal model merging via weight interpolation of models trained on different multimodal tasks, showing their benefits in particular for out-of-distribution generalization. Finally, we motivate unification by showing the synergy between tasks. The model weights and code are available at: https://github.com/mshukor/UnIVAL",
    "checked": false,
    "id": "0fe88452660cb8a0e37f54bcd44f3cd6504354b5",
    "semantic_title": "unified model for image, video, audio and language tasks",
    "citation_count": 48,
    "authors": [
      "Mustafa Shukor",
      "Corentin Dancette",
      "Alexandre Rame",
      "Matthieu Cord"
    ]
  },
  "https://openreview.net/forum?id=vfT4YuzAYA": {
    "title": "IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages",
    "volume": "main",
    "abstract": "India has a rich linguistic landscape, with languages from 4 major language families spoken by over a billion people. 22 of these languages listed in the Constitution of India (referred to as scheduled languages) are the focus of this work. Given the linguistic diversity, high-quality and accessible Machine Translation (MT) systems are essential in a country like India. Before this work, there was (i) no parallel training data spanning all 22 languages, (ii) no robust benchmarks covering all these languages and containing content relevant to India, and (iii) no existing translation models that support all 22 scheduled languages of India. In this work, we aim to address this gap by focusing on the missing pieces required for enabling wide, easy, and open access to good machine translation systems for all 22 scheduled Indian languages. We identify four key areas of improvement: curating and creating larger training datasets, creating diverse and high-quality benchmarks, training multilingual models, and releasing models with open access. Our first contribution is the release of the Bharat Parallel Corpus Collection (BPCC), the largest publicly available parallel corpora for Indic languages. BPCC contains a total of 230M bitext pairs, of which a total of 126M were newly added, including 644K manually translated sentence pairs created as part of this work. Our second contribution is the release of the first $n$-way parallel benchmark covering all 22 Indian languages, featuring diverse domains, Indian-origin content, and conversational test sets. Next, we present IndicTrans2, the first translation model to support all 22 languages, surpassing existing models in performance on multiple existing and new benchmarks created as a part of this work. Lastly, to promote accessibility and collaboration, we release our models and associated data with permissive licenses at https://github.com/AI4Bharat/IndicTrans2",
    "checked": true,
    "id": "59919e80ede70e82a70e8f76f533360c22f37275",
    "semantic_title": "indictrans2: towards high-quality and accessible machine translation models for all 22 scheduled indian languages",
    "citation_count": 147,
    "authors": [
      "Jay Gala",
      "Pranjal A Chitale",
      "A K Raghavan",
      "Varun Gumma",
      "Sumanth Doddapaneni",
      "Aswanth Kumar M",
      "Janki Atul Nawale",
      "Anupama Sujatha",
      "Ratish Puduppully",
      "Vivek Raghavan",
      "Pratyush Kumar",
      "Mitesh M Khapra",
      "Raj Dabre",
      "Anoop Kunchukuttan"
    ]
  },
  "https://openreview.net/forum?id=4Hq816XDDG": {
    "title": "Towards Optimization-Friendly Binary Neural Network",
    "volume": "main",
    "abstract": "Binary neural networks (BNNs) are a promising approach for compressing and accelerating deep learning models, especially in resource-constrained environments. However, the optimization gap between BNNs and their full-precision counterparts has long been an open problem limiting their performance. In this work, we propose a novel optimization pipeline to enhance the performance of BNNs. The main approach includes three key components: (1) BNext, a strong binary baseline based on an optimization-friendly basic block design, (2) knowledge complexity, a simple yet effective teacher-selection metric taking the capacity gap between teachers and binary students under consideration, (3) consecutive knowledge distillation (CKD), a novel multi-round optimization technique to transfer high-confidence knowledge from strong teachers to low-capacity BNNs. We empirically validate the superiority of the method on several vision classification tasks CIFAR-10/100 & ImageNet. For instance, the BNext family outperforms previous BNNs under different capacity levels and contributes the first binary neural network to reach the state-of-the-art 80.57\\% Top-1 accuracy on ImageNet with 0.82 GOPS, which verifies the potential of BNNs and already contributes a strong baseline for future research on high-accuracy BNNs. The code will be publicly available at (blind URL, see supplementary material)",
    "checked": true,
    "id": "7f9e7c1497e87e6b584046bb94009da92fe0d90a",
    "semantic_title": "towards optimization-friendly binary neural network",
    "citation_count": 3,
    "authors": [
      "Nianhui Guo",
      "Joseph Bethge",
      "Hong Guo",
      "Christoph Meinel",
      "Haojin Yang"
    ]
  },
  "https://openreview.net/forum?id=ExbGarTbLE": {
    "title": "Equivariant MuZero",
    "volume": "main",
    "abstract": "Deep reinforcement learning has shown lots of success in closed, well-defined domains such as games (Chess, Go, StarCraft). The next frontier is real-world scenarios, where setups are numerous and varied. For this, agents need to learn the underlying environment dynamics, so as to robustly generalise to conditions that differ from those they were trained on. Model-based reinforcement learning algorithms, such as MuZero or Dreamer, aim to accomplish this by learning a world model. However, leveraging a world model has not yet consistently shown greater generalisation capabilities compared to model-free alternatives. In this work, we propose improving the data efficiency and generalisation capabilities of MuZero by explicitly incorporating the \\emph{symmetries} of the environment in its world-model architecture. We prove that, so long as the neural networks used by MuZero are equivariant to a particular symmetry group acting on the environment, the entirety of MuZero's action-selection algorithm will also be equivariant to that group. As such, Equivariant MuZero is guaranteed to behave symmetrically in symmetrically-transformed states, and will hence be more data-efficient when learning its world models. We evaluate Equivariant MuZero on procedurally-generated MiniPacman and on Chaser from the ProcGen suite: training on a set of mazes, and then testing on unseen rotated versions, demonstrating the benefits of equivariance. We verify that our improvements hold even when only some of the components of Equivariant MuZero obey strict equivariance, which highlights the robustness of our construction",
    "checked": true,
    "id": "2e8355d05976a96018757af12177a78f1911e912",
    "semantic_title": "equivariant muzero",
    "citation_count": 4,
    "authors": [
      "Andreea Deac",
      "Theophane Weber",
      "George Papamakarios"
    ]
  },
  "https://openreview.net/forum?id=hFsr59Imzm": {
    "title": "On the Efficacy of Differentially Private Few-shot Image Classification",
    "volume": "main",
    "abstract": "There has been significant recent progress in training differentially private (DP) models which achieve accuracy that approaches the best non-private models. These DP models are typically pretrained on large public datasets and then fine-tuned on private downstream datasets that are relatively large and similar in distribution to the pretraining data. However, in many applications including personalization and federated learning, it is crucial to perform well (i) in the few-shot setting, as obtaining large amounts of labeled data may be problematic; and (ii) on datasets from a wide variety of domains for use in various specialist settings. To understand under which conditions few-shot DP can be effective, we perform an exhaustive set of experiments that reveals how the accuracy and vulnerability to attack of few-shot DP image classification models are affected as the number of shots per class, privacy level, model architecture, downstream dataset, and subset of learnable parameters in the model vary. We show that to achieve DP accuracy on par with non-private models, the shots per class must be increased as the privacy level increases. We also show that learning parameter-efficient FiLM adapters under DP is competitive with learning just the final classifier layer or learning all of the network parameters. Finally, we evaluate DP federated learning systems and establish state-of-the-art performance on the challenging FLAIR benchmark",
    "checked": true,
    "id": "947cf0610c58fb87e9b4d09d3e4e99311d3a7a05",
    "semantic_title": "on the efficacy of differentially private few-shot image classification",
    "citation_count": 12,
    "authors": [
      "Marlon Tobaben",
      "Aliaksandra Shysheya",
      "John F Bronskill",
      "Andrew Paverd",
      "Shruti Tople",
      "Santiago Zanella-Beguelin",
      "Richard E Turner",
      "Antti Honkela"
    ]
  },
  "https://openreview.net/forum?id=sbkZKBVC31": {
    "title": "Mixture of Dynamical Variational Autoencoders for Multi-Source Trajectory Modeling and Separation",
    "volume": "main",
    "abstract": "In this paper, we propose a latent-variable generative model called mixture of dynamical variational autoencoders (MixDVAE) to model the dynamics of a system composed of multiple moving sources. A DVAE model is pre-trained on a single-source dataset to capture the source dynamics. Then, multiple instances of the pre-trained DVAE model are integrated into a multi-source mixture model with a discrete observation-to-source assignment latent variable. The posterior distributions of both the discrete observation-to-source assignment variable and the continuous DVAE variables representing the sources content/position are estimated using the variational expectation-maximization algorithm, leading to multi-source trajectories estimation. We illustrate the versatility of the proposed MixDVAE model on two tasks: a computer vision task, namely multi-object tracking, and an audio processing task, namely single-channel audio source separation. Experimental results show that the proposed method works well on these two tasks, and outperforms several baseline methods",
    "checked": true,
    "id": "b0218ce7d6f38137ba8523b1d268e688052519f2",
    "semantic_title": "mixture of dynamical variational autoencoders for multi-source trajectory modeling and separation",
    "citation_count": 2,
    "authors": [
      "Xiaoyu Lin",
      "Laurent Girin",
      "Xavier Alameda-Pineda"
    ]
  },
  "https://openreview.net/forum?id=f7a8XCRtUu": {
    "title": "Fast Slate Policy Optimization: Going Beyond Plackett-Luce",
    "volume": "main",
    "abstract": "An increasingly important building block of large scale machine learning systems is based on returning slates; an ordered lists of items given a query. Applications of this technology include: search, information retrieval and recommender systems. When the action space is large, decision systems are restricted to a particular structure to complete online queries quickly. This paper addresses the optimization of these large scale decision systems given an arbitrary reward function. We cast this learning problem in a policy optimization framework and propose a new class of policies, born from a novel relaxation of decision functions. This results in a simple, yet efficient learning algorithm that scales to massive action spaces. We compare our method to the commonly adopted Plackett-Luce policy class and demonstrate the effectiveness of our approach on problems with action space sizes in the order of millions",
    "checked": true,
    "id": "583eec43ce04e3b7c58247832d766c4e257fb98a",
    "semantic_title": "fast slate policy optimization: going beyond plackett-luce",
    "citation_count": 4,
    "authors": [
      "Otmane Sakhi",
      "David Rohde",
      "Nicolas Chopin"
    ]
  },
  "https://openreview.net/forum?id=QCjMJfSnYk": {
    "title": "Error bounds and dynamics of bootstrapping in actor-critic reinforcement learning",
    "volume": "main",
    "abstract": "Actor-critic algorithms such as DDPG, TD3, and SAC, which are built on Silver's deterministic policy gradient theorem, are among the most successful reinforcement-learning methods, but their mathematical basis is not entirely clear. In particular, the critic networks in these algorithms learn to estimate action-value functions by a \"bootstrapping\" technique based on Bellman error, and it is unclear why this approach works so well in practice, given that Bellman error is only very loosely related to value error, i.e. to the inaccuracy of the action-value estimate. Here we show that policy training in this class of actor-critic methods depends not on the accuracy of the critic's action-value estimate but on how well the critic estimates the gradient of the action-value, which is better assessed using what we call difference error. We show that this difference error is closely related to the Bellman error — a finding which helps to explain why Bellman-based bootstrapping leads to good policies. Further, we show that value error and difference error show different dynamics along on-policy trajectories through state-action space: value error is a low-pass anticausal (i.e., backward-in-time) filter of Bellman error, and therefore accumulates along trajectories, whereas difference error is a high-pass filter of Bellman error. It follows that techniques which reduce the high-frequency Fourier components of the Bellman error may improve policy training even if they increase the actual size of the Bellman errors. These findings help to explain certain aspects of actor-critic methods that are otherwise theoretically puzzling, such as the use of policy (as distinct from exploratory) noise, and they suggest other measures that may improve these methods",
    "checked": true,
    "id": "d4c92347bff3a51245f2c9f5e2af861cf264d94b",
    "semantic_title": "error bounds and dynamics of bootstrapping in actor-critic reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Ahmed J Zerouali",
      "Douglas Blair Tweed"
    ]
  },
  "https://openreview.net/forum?id=NnUmg1chLL": {
    "title": "Federated Minimax Optimization with Client Heterogeneity",
    "volume": "main",
    "abstract": "Minimax optimization has seen a surge in interest with the advent of modern applications such as GANs, and it is inherently more challenging than simple minimization. The difficulty is exacerbated by the training data residing at multiple edge devices or \\textit{clients}, especially when these clients can have heterogeneous datasets and heterogeneous local computation capabilities. We propose a general federated minimax optimization framework that subsumes such settings and several existing methods like Local SGDA. We show that naive aggregation of model updates made by clients running unequal number of local steps can result in optimizing a mismatched objective function -- a phenomenon previously observed in standard federated minimization. To fix this problem, we propose normalizing the client updates by the number of local steps. We analyze the convergence of the proposed algorithm for classes of nonconvex-concave and nonconvex-nonconcave functions and characterize the impact of heterogeneous client data, partial client participation, and heterogeneous local computations. For all the function classes considered, we significantly improve the existing computation and communication complexity results. Experimental results support our theoretical claims",
    "checked": true,
    "id": "410dc1db47548691bb5a1de2db247bae81324098",
    "semantic_title": "federated minimax optimization with client heterogeneity",
    "citation_count": 10,
    "authors": [
      "Pranay Sharma",
      "Rohan Panda",
      "Gauri Joshi"
    ]
  },
  "https://openreview.net/forum?id=Uj6MRfR1P5": {
    "title": "Towards Fair Video Summarization",
    "volume": "main",
    "abstract": "Automated video summarization is a vision task that aims to generate concise summaries of lengthy videos. Recent advancements in deep learning have led to highly performant video summarization models; however, there has been a lack of attention given to fairness and unbiased representation in the generated summaries. To bridge this gap, we introduce and analytically define the fair video summarization problem, and demonstrate its connections to the well-established problem of fair clustering. To facilitate fair model development, we also introduce the FairVidSum dataset, which is similar in design to state-of-the-art video summarization datasets such as TVSum and SumMe, but also includes annotations for sensitive attributes and individuals alongside frame importance scores. Finally, we propose the SumBal metric for quantifying the fairness of an outputted video summary. We conduct extensive experiments to benchmark the fairness of various state-of-the-art video summarization models. Our results highlight the need for better models that balance accuracy and fairness to ensure equitable representation and inclusion in summaries. For completeness, we also provide a novel fair-only baseline, FVS-LP, to showcase the fairness-utility gap models can improve upon",
    "checked": true,
    "id": "a0786692ef0768176bf1f59489d95dab69f43d28",
    "semantic_title": "towards fair video summarization",
    "citation_count": 3,
    "authors": [
      "Anshuman Chhabra",
      "Kartik Patwari",
      "Chandana Kuntala",
      "Sristi",
      "Deepak Kumar Sharma",
      "Prasant Mohapatra"
    ]
  },
  "https://openreview.net/forum?id=FWyabz82fH": {
    "title": "Uncertainty Estimation for Computed Tomography with a Linearised Deep Image Prior",
    "volume": "main",
    "abstract": "Existing deep-learning based tomographic image reconstruction methods do not provide accurate uncertainty estimates of their reconstructions, hindering their real-world deployment. This paper develops a method, termed as linearised deep image prior (DIP), to estimate the uncertainty associated with reconstructions produced by the DIP with total variation (TV) regularisation. We endow the DIP with conjugate Gaussian-linear model type error-bars computed from a local linearisation of the neural network around its optimised parameters. To preserve conjugacy, we approximate the TV regulariser with a Gaussian surrogate. This approach provides pixel-wise uncertainty estimates and a marginal likelihood objective for hyperparameter optimisation. We demonstrate the method on synthetic data and real-measured high-resolution 2D $\\mu$CT data, and show that it provides superior calibration of uncertainty estimates relative to previous probabilistic formulations of the~DIP. Our code is available at https://github.com/educating-dip/bayes_dip",
    "checked": true,
    "id": "2eec71f84d06d4f554a4243874fe3d1780ba90c2",
    "semantic_title": "uncertainty estimation for computed tomography with a linearised deep image prior",
    "citation_count": 10,
    "authors": [
      "Javier Antoran",
      "Riccardo Barbano",
      "Johannes Leuschner",
      "José Miguel Hernández-Lobato",
      "Bangti Jin"
    ]
  },
  "https://openreview.net/forum?id=231ZzrLC8X": {
    "title": "Early Stopping for Deep Image Prior",
    "volume": "main",
    "abstract": "Deep image prior (DIP) and its variants have shown remarkable potential to solve inverse problems in computational imaging (CI), needing no separate training data. Practical DIP models are often substantially overparameterized. During the learning process, these models first learn the desired visual content and then pick up potential modeling and observational noise, i.e., performing early learning then overfitting. Thus, the practicality of DIP hinges on early stopping (ES) that can capture the transition period. In this regard, most previous DIP works for CI tasks only demonstrate the potential of the models, reporting the peak performance against the ground truth but providing no clue about how to operationally obtain near-peak performance without access to the ground truth. In this paper, we set to break this practicality barrier of DIP, and propose an effective ES strategy that consistently detects near-peak performance across several CI tasks and DIP variants. Simply based on the running variance of DIP intermediate reconstructions, our ES method not only outpaces the existing ones---which only work in very narrow regimes, but also remains effective when combined with methods that try to mitigate overfitting",
    "checked": true,
    "id": "1f82c4a2962a3e6fb0800661ae7239092037bd08",
    "semantic_title": "early stopping for deep image prior",
    "citation_count": 67,
    "authors": [
      "Hengkang Wang",
      "Taihui Li",
      "Zhong Zhuang",
      "Tiancong Chen",
      "Hengyue Liang",
      "Ju Sun"
    ]
  },
  "https://openreview.net/forum?id=xflYdGZMpv": {
    "title": "Image retrieval outperforms diffusion models on data augmentation",
    "volume": "main",
    "abstract": "Many approaches have been proposed to use diffusion models to augment training datasets for downstream tasks, such as classification. However, diffusion models are themselves trained on large datasets, often with noisy annotations, and it remains an open question to which extent these models contribute to downstream classification performance. In particular, it remains unclear if they generalize enough to improve over directly using the additional data of their pre-training process for augmentation. We systematically evaluate a range of existing methods to generate images from diffusion models and study new extensions to assess their benefit for data augmentation. Personalizing diffusion models towards the target data outperforms simpler prompting strategies. However, using the pre-training data of the diffusion model alone, via a simple nearest-neighbor retrieval procedure, leads to even stronger downstream performance. Our study explores the potential of diffusion models in generating new training data, and surprisingly finds that these sophisticated models are not yet able to beat a simple and strong image retrieval baseline on simple downstream vision tasks",
    "checked": true,
    "id": "c22dfd7dd7364d96e03e47998819cc188a53d3f4",
    "semantic_title": "image retrieval outperforms diffusion models on data augmentation",
    "citation_count": 17,
    "authors": [
      "Max F Burg",
      "Florian Wenzel",
      "Dominik Zietlow",
      "Max Horn",
      "Osama Makansi",
      "Francesco Locatello",
      "Chris Russell"
    ]
  },
  "https://openreview.net/forum?id=Mbc58EzF5q": {
    "title": "Transport with Support: Data-Conditional Diffusion Bridges",
    "volume": "main",
    "abstract": "The dynamic Schrödinger bridge problem provides an appealing setting for solving constrained time-series data generation tasks posed as optimal transport problems. It consists of learning non-linear diffusion processes using efficient iterative solvers. Recent works have demonstrated state-of-the-art results (eg., in modelling single-cell embryo RNA sequences or sampling from complex posteriors) but are limited to learning bridges with only initial and terminal constraints. Our work extends this paradigm by proposing the Iterative Smoothing Bridge (ISB). We integrate Bayesian filtering and optimal control into learning the diffusion process, enabling the generation of constrained stochastic processes governed by sparse observations at intermediate stages and terminal constraints. We assess the effectiveness of our method on synthetic and real-world data generation tasks and we show that the ISB generalises well to high-dimensional data, is computationally efficient, and provides accurate estimates of the marginals at intermediate and terminal times",
    "checked": true,
    "id": "8d61874776bf54ced20fffe3b2258da85090d7b8",
    "semantic_title": "transport with support: data-conditional diffusion bridges",
    "citation_count": 7,
    "authors": [
      "Ella Tamir",
      "Martin Trapp",
      "Arno Solin"
    ]
  },
  "https://openreview.net/forum?id=w4MoQ39zmc": {
    "title": "Local Function Complexity for Active Learning via Mixture of Gaussian Processes",
    "volume": "main",
    "abstract": "Inhomogeneities in real-world data, e.g., due to changes in the observation noise level or variations in the structural complexity of the source function, pose a unique set of challenges for statistical inference. Accounting for them can greatly improve predictive power when physical resources or computation time is limited. In this paper, we draw on recent theoretical results on the estimation of local function complexity (LFC), derived from the domain of local polynomial smoothing (LPS), to establish a notion of local structural complexity, which is used to develop a model-agnostic active learning (AL) framework. Due to its reliance on pointwise estimates, the LPS model class is not robust and scalable concerning large input space dimensions that typically come along with real-world problems. Here, we derive and estimate the Gaussian process regression (GPR)-based analog of the LPS-based LFC and use it as a substitute in the above framework to make it robust and scalable. We assess the effectiveness of our LFC estimate in an AL application on a prototypical low-dimensional synthetic dataset, before taking on the challenging real-world task of reconstructing a quantum chemical force field for a small organic molecule and demonstrating state-of-the-art performance with a significantly reduced training demand",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Danny Panknin",
      "Stefan Chmiela",
      "Klaus Robert Muller",
      "Shinichi Nakajima"
    ]
  },
  "https://openreview.net/forum?id=vJcTm2v9Ku": {
    "title": "Towards a General Transfer Approach for Policy-Value Networks",
    "volume": "main",
    "abstract": "Transferring trained policies and value functions from one task to another, such as one game to another with a different board size, board shape, or more substantial rule changes, is a challenging problem. Popular benchmarks for reinforcement learning (RL), such as Atari games and ProcGen, have limited variety especially in terms of action spaces. Due to a focus on such benchmarks, the development of transfer methods that can also handle changes in action spaces has received relatively little attention. Furthermore, we argue that progress towards more general methods should include benchmarks where new problem instances can be described by domain experts, rather than machine learning experts, using convenient, high-level domain specific languages (DSLs). In addition to enabling end users to more easily describe their problems, user-friendly DSLs also contain relevant task information which can be leveraged to make effective zero-shot transfer plausibly achievable. As an example, we use the Ludii general game system, which includes a highly varied set of over 1000 distinct games described in such a language. We propose a simple baseline approach for transferring fully convolutional policy-value networks, which are used to guide search agents similar to AlphaZero, between any pair of games modelled in this system. Extensive results---including various cases of highly successful zero-shot transfer---are provided for a wide variety of source and target games",
    "checked": true,
    "id": "80453413e567db49cb355520d9c7aa063138b85b",
    "semantic_title": "towards a general transfer approach for policy-value networks",
    "citation_count": 5,
    "authors": [
      "Dennis J. N. J. Soemers",
      "Vegard Mella",
      "Eric Piette",
      "Matthew Stephenson",
      "Cameron Browne",
      "Olivier Teytaud"
    ]
  },
  "https://openreview.net/forum?id=Id10mlBjcx": {
    "title": "ProtoCaps: A Fast and Non-Iterative Capsule Network Routing Method",
    "volume": "main",
    "abstract": "Capsule Networks have emerged as a powerful class of deep learning architectures, known for robust performance with relatively few parameters compared to Convolutional Neural Networks (CNNs). However, their inherent efficiency is often overshadowed by their slow, iterative routing mechanisms which establish connections between Capsule layers, posing computational challenges resulting in an inability to scale. In this paper, we introduce a novel, non-iterative routing mechanism, inspired by trainable prototype clustering. This innovative approach aims to mitigate computational complexity, while retaining, if not enhancing, performance efficacy. Furthermore, we harness a shared Capsule subspace, negating the need to project each lower-level Capsule to each higher-level Capsule, thereby significantly reducing memory requisites during training. Our approach demonstrates superior results compared to the current best non-iterative Capsule Network and tests on the Imagewoof dataset, which is too computationally demanding to handle efficiently by iterative approaches. Our findings underscore the potential of our proposed methodology in enhancing the operational efficiency and performance of Capsule Networks, paving the way for their application in increasingly complex computational scenarios. Code is available at https://github.com/mileseverett/ProtoCaps",
    "checked": true,
    "id": "3f870b61566940acdb565e88bd4f5c0183c03827",
    "semantic_title": "protocaps: a fast and non-iterative capsule network routing method",
    "citation_count": 4,
    "authors": [
      "Miles Everett",
      "Mingjun Zhong",
      "Georgios Leontidis"
    ]
  },
  "https://openreview.net/forum?id=t4p612DftO": {
    "title": "Detecting danger in gridworlds using Gromov's Link Condition",
    "volume": "main",
    "abstract": "Gridworlds have been long-utilised in AI research, particularly in reinforcement learning, as they provide simple yet scalable models for many real-world applications such as robot navigation, emergent behaviour, and operations research. We initiate a study of gridworlds using the mathematical framework of reconfigurable systems and state complexes due to Abrams, Ghrist & Peterson. State complexes, a higher-dimensional analogue of state graphs, represent all possible configurations of a system as a single geometric space, thus making them conducive to study using geometric, topological, or combinatorial methods. The main contribution of this work is a modification to the original Abrams, Ghrist & Peterson setup which we introduce to capture agent braiding and thereby more naturally represent the topology of gridworlds. With this modification, the state complexes may exhibit geometric defects (failure of Gromov's Link Condition). Serendipitously, we discover these failures for agent-only cases occur exactly where undesirable or dangerous states appear in the gridworld. Our results therefore provide a novel method for seeking guaranteed safety limitations in discrete task environments with single or multiple agents, and offer useful safety information (in geometric and topological forms) for incorporation in or analysis of machine learning systems. More broadly, our work introduces tools from geometric group theory and combinatorics to the AI community and demonstrates a proof-of-concept for this geometric viewpoint of the task domain through the example of simple environments",
    "checked": true,
    "id": "7d2d1e91f66790aaeefa123304be153297c8a82b",
    "semantic_title": "detecting danger in gridworlds using gromov's link condition",
    "citation_count": 2,
    "authors": [
      "Thomas F Burns",
      "Robert Tang"
    ]
  },
  "https://openreview.net/forum?id=75CcopPxIr": {
    "title": "Partial Optimal Transport for Support Subset Selection",
    "volume": "main",
    "abstract": "In probabilistic terms, optimal transport aims to find a joint distribution that couples two distributions and minimizes the cost of transforming one distribution to another. Any feasible coupling necessarily maintains the support of both distributions. However, maintaining the entire support is not ideal when only a subset of one of the distributions, namely the source, is assumed to align with the other target distribution. For these cases, which are common in machine learning applications, we study the semi-relaxed partial optimal transport problem that relaxes the constraints on the joint distribution allowing it to under-represent a subset of the source by over-representing other subsets of the source by a constant factor. In the discrete distribution case, such as in the case of two samples from continuous random variables, optimal transport with the relaxed constraints is a linear program. When sufficiently relaxed, the solution has a source marginal with only a subset of its original support. We investigate the scaling path of solutions, specifically the relaxed marginal distribution for the source, across different relaxations and show that it is distinct from the solutions from penalty-based semi-relaxed unbalanced optimal transport problems and fully-relaxed partial optimal transport, which have previously been explored. We demonstrate the usefulness of this support subset selection in applications such as color transfer, partial point cloud alignment, and semi-supervised machine learning, where a part of data is curated to have reliable labels and another part is unlabeled or has unreliable labels. Our experiments show that optimal transport under the relaxed constraint can improve the performance of these applications by allowing for more flexible alignment between distributions",
    "checked": true,
    "id": "7d2880a2eea9196780d33e7173699d2b9d80e5b6",
    "semantic_title": "partial optimal transport for support subset selection",
    "citation_count": 2,
    "authors": [
      "Bilal Riaz",
      "Yuksel Karahan",
      "Austin J. Brockmeier"
    ]
  },
  "https://openreview.net/forum?id=KrequDpWzt": {
    "title": "Wrapped $\\beta$-Gaussians with compact support for exact probabilistic modeling on manifolds",
    "volume": "main",
    "abstract": "We introduce wrapped $\\beta$-Gaussians, a family of wrapped distributions on Riemannian manifolds, supporting efficient reparametrized sampling, as well as exact density estimation, effortlessly supporting high dimensions and anisotropic scale parameters. We extend Fenchel-Young losses for geometry-aware learning with wrapped $\\beta$-Gaussians, and demonstrate the efficacy of our proposed family in a suite of experiments on hypersphere and rotation manifolds: data fitting, hierarchy encoding, generative modeling with variational autoencoders, and multilingual word embedding alignment",
    "checked": false,
    "id": "1ece7fca5488633dda8fd9b16305caabc82f6810",
    "semantic_title": "wrapped β-gaussians with compact support for exact probabilistic modeling on manifolds",
    "citation_count": 1,
    "authors": [
      "Sergey Troshin",
      "Vlad Niculae"
    ]
  },
  "https://openreview.net/forum?id=0WKTmrVkd2": {
    "title": "GIT-Net: Generalized Integral Transform for Operator Learning",
    "volume": "main",
    "abstract": "This article introduces GIT-Net, a deep neural network architecture for approximating Partial Differential Equation (PDE) operators, inspired by integral transform operators. GIT-NET harnesses the fact that common differential operators commonly used for defining PDEs can often be represented parsimoniously when expressed in specialized functional bases (e.g., Fourier basis). Unlike rigid integral transforms, GIT-Net parametrizes adaptive generalized integral transforms with deep neural networks. When compared to several recently proposed alternatives, GIT-Net's computational and memory requirements scale gracefully with mesh discretizations, facilitating its application to PDE problems on complex geometries. Numerical experiments demonstrate that GIT-Net is a competitive neural network operator, exhibiting small test errors and low evaluations across a range of PDE problems. This stands in contrast to existing neural network operators, which typically excel in just one of these areas",
    "checked": true,
    "id": "ef45194c431ebddf869fc8191ab91c105389e01b",
    "semantic_title": "git-net: generalized integral transform for operator learning",
    "citation_count": 0,
    "authors": [
      "Chao Wang",
      "Alexandre H. Thiery"
    ]
  },
  "https://openreview.net/forum?id=sUlbRfLijj": {
    "title": "Semi-Supervised Single Domain Generalization with Label-Free Adversarial Data Augmentation",
    "volume": "main",
    "abstract": "Domain generalization (DG) has attracted increasing attention recently, as it seeks to improve the generalization ability of visual recognition models to unseen target domains. DG leverages multiple source domains for model training, while single domain generalization (SDG) further restricts such setting by exploiting only a single source domain. Nevertheless, both DG and SDG assume that the source domains are fully labeled, which might not be practical in many real world scenarios. In this paper, we present a new problem, i.e., semi-supervised single domain generalization (SS-SDG), which aims to train a model with a partially labeled single source domain to generalize to multiple unseen testing domains. We propose an effective framework to address this problem. In particular, we design a label-free adversarial data augmentation strategy to diversify the source domain, and propose a novel multi-pair FixMatch loss to generalize classifiers to unseen testing domains. Extensive experiments on OfficeHome, PACS and DomainNet20 datasets show that our method surpasses the latest SDG and semi-supervised methods. Moreover, on PACS and DomainNet20, our method approaches the fully supervised ERM upper bound within $5\\%$ gap, but only uses less than $8\\%$ of the labels",
    "checked": true,
    "id": "8fb4eda80a0fe08b32e3c016ad6ed96131568ac4",
    "semantic_title": "semi-supervised single domain generalization with label-free adversarial data augmentation",
    "citation_count": 2,
    "authors": [
      "Ronghang Zhu",
      "Xiang Yu",
      "Sheng Li"
    ]
  },
  "https://openreview.net/forum?id=jpZmhiIys1": {
    "title": "Beyond Boundaries: A Novel Data-Augmentation Discourse for Open Domain Generalization",
    "volume": "main",
    "abstract": "The problem of Open Domain Generalization (ODG) is multifaceted, encompassing shifts in domains and labels across all source and target domains. Existing approaches have encountered challenges such as style bias towards training domains, insufficient feature-space disentanglement to highlight semantic features, and discriminativeness of the latent space. Additionally, they rely on a confidence-based target outlier detection approach, which can lead to misclassifications when target open samples visually align with the source domain data. In response to these challenges, we present a solution named \\textsc{ODG-Net}. We aim to create a direct open-set classifier within a \\textit{discriminative}, \\textit{unbiased}, and \\textit{disentangled} semantic embedding space. To enrich data density and diversity, we introduce a generative augmentation framework that produces \\textit{style-interpolated} novel domains for closed-set images and novel pseudo-open images by \\textit{interpolating the contents of paired training images}. Our augmentation strategy skillfully utilizes \\textit{disentangled style and content information} to synthesize images effectively. Furthermore, we tackle the issue of style bias by representing all images in relation to all source domain properties, which effectively accentuates complementary visual features. Consequently, we train a multi-class semantic object classifier, incorporating both closed and open class classification capabilities, along with a style classifier to identify style primitives. The joint use of style and semantic classifiers facilitates the disentanglement of the latent space, thereby enhancing the generalization performance of the semantic classifier. To ensure discriminativeness in both closed and open spaces, we optimize the semantic feature space using novel metric losses. The experimental results on six benchmark datasets convincingly demonstrate that \\textsc{ODG-Net} surpasses the state-of-the-art by an impressive margin of $1-4\\%$ in both open and closed-set DG scenarios",
    "checked": true,
    "id": "af5dea08a858c96c2311e5de6a41e8fbf2ad0dcc",
    "semantic_title": "beyond boundaries: a novel data-augmentation discourse for open domain generalization",
    "citation_count": 5,
    "authors": [
      "Shirsha Bose",
      "Ankit Jha",
      "Hitesh Kandala",
      "Biplab Banerjee"
    ]
  },
  "https://openreview.net/forum?id=T55dLSgsEf": {
    "title": "Accelerating Batch Active Learning Using Continual Learning Techniques",
    "volume": "main",
    "abstract": "A major problem with Active Learning (AL) is high training costs since models are typically retrained from scratch after every query round. We start by demonstrating that standard AL on neural networks with warm starting fails, both to accelerate training and to avoid catastrophic forgetting when using fine-tuning over AL query rounds. We then develop a new class of techniques, circumventing this problem, by biasing further training towards previously labeled sets. We accomplish this by employing existing, and developing novel, replay-based Continual Learning (CL) algorithms that are effective at quickly learning the new without forgetting the old, especially when data comes from an evolving distribution. We call this paradigm \\textit{\"Continual Active Learning\" (CAL)}. We show CAL achieves significant speedups using a plethora of replay schemes that use model distillation and that select diverse/uncertain points from the history. We conduct experiments across many data domains, including natural language, vision, medical imaging, and computational biology, each with different neural architectures and dataset sizes. CAL consistently provides a $\\sim$3x reduction in training time, while retaining performance and out-of-distribution robustness, showing its wide applicability",
    "checked": true,
    "id": "ef120748f38e47adfa7f4f95dc161f414389f498",
    "semantic_title": "accelerating batch active learning using continual learning techniques",
    "citation_count": 10,
    "authors": [
      "Arnav Mohanty Das",
      "Gantavya Bhatt",
      "Megh Manoj Bhalerao",
      "Vianne R. Gao",
      "Rui Yang",
      "Jeff Bilmes"
    ]
  },
  "https://openreview.net/forum?id=lXBEwFfxpA": {
    "title": "Revisiting Topic-Guided Language Models",
    "volume": "main",
    "abstract": "A recent line of work in natural language processing has aimed to combine language models and topic models. These \\textit{topic-guided language models} augment neural language models with topic models, unsupervised learning methods that can discover document-level patterns of word use. This paper compares the effectiveness of these methods in a standardized setting. We study four topic-guided language models and two baselines, evaluating the held-out predictive performance of each model on four corpora. Surprisingly, we find that \\textit{none of these methods outperform a standard LSTM language model baseline}, and most fail to learn good topics. Further, we train a probe of the neural language model that shows that the baseline's hidden states already encode topic information. We make public all code used for this study",
    "checked": true,
    "id": "2ccb7e10e1f5bebe7e203a2e99a23c4998287e4d",
    "semantic_title": "revisiting topic-guided language models",
    "citation_count": 1,
    "authors": [
      "Carolina Zheng",
      "Keyon Vafa",
      "David Blei"
    ]
  },
  "https://openreview.net/forum?id=LfQ6uAVAEo": {
    "title": "Two-Level Actor-Critic Using Multiple Teachers",
    "volume": "main",
    "abstract": "Deep reinforcement learning has successfully allowed agents to learn complex behaviors for many tasks. However, a key limitation of current learning approaches is the sample-inefficiency problem, which limits performance of the learning agent. This paper considers how agents can benefit from improved learning via teachers' advice. In particular, we consider the setting with multiple sub-optimal teachers, as opposed to having a single near-optimal teacher. We propose a flexible two-level actor-critic algorithm where the high-level network learns to choose the best teacher in the current situation while the low-level network learns the control policy",
    "checked": true,
    "id": "ce7be018cc30bd2bb195e7f97849ef004fdc33e9",
    "semantic_title": "two-level actor-critic using multiple teachers",
    "citation_count": 0,
    "authors": [
      "Su Zhang",
      "Srijita Das",
      "Sriram Ganapathi Subramanian",
      "Matthew E. Taylor"
    ]
  },
  "https://openreview.net/forum?id=UxmvCwuTMG": {
    "title": "ECG Representation Learning with Multi-Modal EHR Data",
    "volume": "main",
    "abstract": "Electronic Health Records (EHRs) provide a rich source of medical information across different modalities such as electrocardiograms (ECG), structured EHRs (sEHR), and unstructured EHRs (text). Inspired by the fact that many cardiac and non-cardiac diseases influence the behavior of the ECG, we leverage structured EHRs and unstructured EHRs from multiple sources by pairing with ECGs and propose a set of three new multi-modal contrastive learning models that combine ECG, sEHR, and text modalities. The performance of these models is compared against different baseline models such as supervised learning models trained from scratch with random weights initialization, and self-supervised learning models trained only on ECGs. We pre-train the models on a large proprietary dataset of about 9 $million$ ECGs from around 2.4 $million$ patients and evaluate the pre-trained models on various downstream tasks such as classification, zero-shot retrieval, and out-of-distribution detection involving the prediction of various heart conditions using ECG waveforms as input, and demonstrate that the models presented in this work show significant improvements compared to all baseline modes",
    "checked": true,
    "id": "15a7b048c5ad3f3b37844426a94fb66c3074e568",
    "semantic_title": "ecg representation learning with multi-modal ehr data",
    "citation_count": 10,
    "authors": [
      "Sravan Kumar Lalam",
      "Hari Krishna Kunderu",
      "Shayan Ghosh",
      "Harish Kumar A",
      "Samir Awasthi",
      "Ashim Prasad",
      "Francisco Lopez-Jimenez",
      "Zachi I Attia",
      "Samuel Asirvatham",
      "Paul Friedman",
      "Rakesh Barve",
      "Melwin Babu"
    ]
  },
  "https://openreview.net/forum?id=V9tQKYYNK1": {
    "title": "Variational Causal Dynamics: Discovering Modular World Models from Interventions",
    "volume": "main",
    "abstract": "Latent world models allow agents to reason about complex environments with high-dimensional observations. However, adapting to new environments and effectively leveraging previous knowledge remain significant challenges. We present Variational Causal Dynamics (VCD), a structured world model that exploits the invariance of causal mechanisms across environments to achieve fast and modular adaptation. By causally factorising a transition model, VCD is able to identify reusable components across different environments. This is achieved by combining causal discovery and variational inference to learn a latent representation and transition model jointly in an unsupervised manner. Specifically, we optimise the evidence lower bound jointly over a representation model and a transition model structured as a causal graphical model. In evaluations on simulated environments with state and image observations, we show that VCD is able to successfully identify causal variables, and to discover consistent causal structures across different environments. Moreover, given a small number of observations in a previously unseen, intervened environment, VCD is able to identify the sparse changes in the dynamics and to adapt efficiently. In doing so, VCD significantly extends the capabilities of the current state-of-the-art in latent world models while also comparing favourably in terms of prediction accuracy",
    "checked": true,
    "id": "73f959402b39929dbad93610436ca078262c0fbf",
    "semantic_title": "variational causal dynamics: discovering modular world models from interventions",
    "citation_count": 9,
    "authors": [
      "Anson Lei",
      "Bernhard Schölkopf",
      "Ingmar Posner"
    ]
  },
  "https://openreview.net/forum?id=F74ZZk5hPa": {
    "title": "RCT Rejection Sampling for Causal Estimation Evaluation",
    "volume": "main",
    "abstract": "Confounding is a significant obstacle to unbiased estimation of causal effects from observational data. For settings with high-dimensional covariates---such as text data, genomics, or the behavioral social sciences---researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited. In this work, we build on a promising empirical evaluation strategy that simplifies evaluation design and uses real data: subsampling randomized controlled trials (RCTs) to create confounded observational datasets while using the average causal effects from the RCTs as ground-truth. We contribute a new sampling algorithm, which we call RCT rejection sampling, and provide theoretical guarantees that causal identification holds in the observational data to allow for valid comparisons to the ground-truth RCT. Using synthetic data, we show our algorithm indeed results in low bias when oracle estimators are evaluated on the confounded samples, which is not always the case for a previously proposed algorithm. In addition to this identification result, we highlight several finite data considerations for evaluation designers who plan to use RCT rejection sampling on their own datasets. As a proof of concept, we implement an example evaluation pipeline and walk through these finite data considerations with a novel, real-world RCT---which we release publicly---consisting of approximately 70k observations and text data as high-dimensional covariates. Together, these contributions build towards a broader agenda of improved empirical evaluation for causal estimation",
    "checked": true,
    "id": "f2410b3da60ba080031d50b6e2217003173c0eb0",
    "semantic_title": "rct rejection sampling for causal estimation evaluation",
    "citation_count": 9,
    "authors": [
      "Katherine A. Keith",
      "Sergey Feldman",
      "David Jurgens",
      "Jonathan Bragg",
      "Rohit Bhattacharya"
    ]
  },
  "https://openreview.net/forum?id=qM7JPBYROr": {
    "title": "Tight conditions for when the NTK approximation is valid",
    "volume": "main",
    "abstract": "We study when the neural tangent kernel (NTK) approximation is valid for training a model with the square loss. In the lazy training setting of Chizat et al. 2019, we show that rescaling the model by a factor of $\\alpha = O(T)$ suffices for the NTK approximation to be valid until training time $T$. Our bound is tight and improves on the previous bound of Chizat et al. 2019, which required a larger rescaling factor of $\\alpha = O(T^2)$",
    "checked": true,
    "id": "3a9185c60a36d48fc301188d32df361d9f0d865f",
    "semantic_title": "tight conditions for when the ntk approximation is valid",
    "citation_count": 0,
    "authors": [
      "Enric Boix-Adserà",
      "Etai Littwin"
    ]
  },
  "https://openreview.net/forum?id=ORMlg4g3mG": {
    "title": "Data-Free Diversity-Based Ensemble Selection for One-Shot Federated Learning",
    "volume": "main",
    "abstract": "The emerging availability of various machine learning models creates a great demand to harness the collective intelligence of many independently well-trained models to improve overall performance. Considering the privacy concern and non-negligible communication costs, one-shot federated learning and ensemble learning in a data-free manner attract significant attention. However, conventional ensemble selection approaches are neither training efficient nor applicable to federated learning due to the risk of privacy leakage from local clients; meanwhile, the \"many could be better than all\" principle under data-free constraints makes it even more challenging. Therefore, it becomes crucial to design an effective ensemble selection strategy to find a good subset of the base models as the ensemble team for the federated learning scenario. In this paper, we propose a novel data-free diversity-based framework, DeDES, to address the ensemble selection problem with diversity consideration for models under the one-shot federated learning setting. Experimental results show that our method can achieve both better performance and higher efficiency over 5 datasets, 4 different model structures, and both homogeneous and heterogeneous model groups under four different data-partition strategies",
    "checked": true,
    "id": "23234175cbdb8664bfbca42a28e37bf39ccff4ec",
    "semantic_title": "data-free diversity-based ensemble selection for one-shot federated learning",
    "citation_count": 5,
    "authors": [
      "Naibo Wang",
      "Wenjie Feng",
      "yuchen deng",
      "Moming Duan",
      "Fusheng Liu",
      "See-Kiong Ng"
    ]
  },
  "https://openreview.net/forum?id=wzRE5kTnl3": {
    "title": "Universal Graph Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a38346d888a632b9fca2dd0c2947d5620b7b4117",
    "semantic_title": "universal graph continual learning",
    "citation_count": 5,
    "authors": [
      "Thanh Duc Hoang",
      "Do Viet Tung",
      "Duy-Hung Nguyen",
      "Bao-Sinh Nguyen",
      "Huy Hoang Nguyen",
      "Hung Le"
    ]
  },
  "https://openreview.net/forum?id=gY04GX8R5k": {
    "title": "Cross-client Label Propagation for Transductive and Semi-Supervised Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cbf044732c521a8ee3b2fcf3abc8d98d587f49ec",
    "semantic_title": "cross-client label propagation for transductive and semi-supervised federated learning",
    "citation_count": 0,
    "authors": [
      "Jonathan Scott",
      "Michelle Yeo",
      "Christoph H Lampert"
    ]
  },
  "https://openreview.net/forum?id=H5VRvCXCzf": {
    "title": "MERMAIDE: Learning to Align Learners using Model-Based Meta-Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2226ab21e8059a2e154655e0c8d19779f0fc30fb",
    "semantic_title": "mermaide: learning to align learners using model-based meta-learning",
    "citation_count": 1,
    "authors": [
      "Arundhati Banerjee",
      "Soham Rajesh Phade",
      "Stefano Ermon",
      "Stephan Zheng"
    ]
  },
  "https://openreview.net/forum?id=8tnrh56P5W": {
    "title": "Meta Continual Learning on Graphs with Experience Replay",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "65894534b1fb06a4bfa80d409d29048572ca7a73",
    "semantic_title": "meta continual learning on graphs with experience replay",
    "citation_count": 3,
    "authors": [
      "Altay Unal",
      "Abdullah Akgül",
      "Melih Kandemir",
      "Gozde Unal"
    ]
  },
  "https://openreview.net/forum?id=0ck7hJ8EVC": {
    "title": "Improved identification accuracy in equation learning via comprehensive $\\boldsymbol{R^2}$-elimination and Bayesian model selection",
    "volume": "main",
    "abstract": "In the field of equation learning, exhaustively considering all possible combinations derived from a basis function dictionary is infeasible. Sparse regression and greedy algorithms have emerged as popular approaches to tackle this challenge. However, the presence of strong collinearities poses difficulties for sparse regression techniques, and greedy steps may inadvertently exclude important components of the true equation, leading to reduced identification accuracy. In this article, we present a novel algorithm that strikes a balance between comprehensiveness and efficiency in equation learning. Inspired by stepwise regression, our approach combines the coefficient of determination, $R^2$, and the Bayesian model evidence, $p(y|\\mathcal{M})$, in a novel way. Through three extensive numerical experiments involving random polynomials and dynamical systems, we compare our method against two standard approaches, four state-of-the-art methods, and bidirectional stepwise regression incorporating $p(y|\\mathcal{M})$. The results demonstrate that our less greedy algorithm surpasses all other methods in terms of identification accuracy. Furthermore, we discover a heuristic approach to mitigate the overfitting penalty associated with $R^2$ and propose an equation learning procedure solely based on $R^2$, which achieves high rates of exact equation recovery",
    "checked": false,
    "id": "0684e51641821819f73f47679d4d67a0725186f4",
    "semantic_title": "improved identification accuracy in equation learning via comprehensive r2-elimination and bayesian model selection",
    "citation_count": 0,
    "authors": [
      "Daniel Nickelsen",
      "Bubacarr Bah"
    ]
  },
  "https://openreview.net/forum?id=dN9YICB6hN": {
    "title": "Reliable Active Learning via Influence Functions",
    "volume": "main",
    "abstract": "Due to the high cost and time-consuming nature of collecting labeled data, having insufficient labeled data is a common challenge that can negatively impact the performance of deep learning models when applied to real-world applications. Active learning (AL) aims to reduce the cost and time required for obtaining labeled data by selecting valuable samples during model training. However, recent works have pointed out the performance unreliability of existing AL algorithms for deep learning (DL) architectures under different scenarios, which manifests as their performance being comparable (or worse) to that of basic random selection. This behavior compromises the applicability of these approaches. We address this problem by proposing a theoretically motivated AL framework for DL architectures. We demonstrate that the most valuable samples for the model are those that, unsurprisingly, improve its performance on the entire dataset, most of which is unlabeled, and present a framework to efficiently estimate such performance (or loss) via influence functions, pseudo labels and diversity selection. Experimental results show that the proposed reliable active learning via influence functions (RALIF) can consistently outperform the random selection baseline as well as other existing and state-of-the art active learning approaches",
    "checked": true,
    "id": "55736f19cdd0a6bd0946041f806335995190893c",
    "semantic_title": "reliable active learning via influence functions",
    "citation_count": 0,
    "authors": [
      "Meng Xia",
      "Ricardo Henao"
    ]
  },
  "https://openreview.net/forum?id=dZugyhbNFY": {
    "title": "Personalized Federated Learning with Communication Compression",
    "volume": "main",
    "abstract": "In contrast to training traditional machine learning~(ML) models in data centers, federated learning~(FL) trains ML models over local datasets contained on resource-constrained heterogeneous edge devices. Existing FL algorithms aim to learn a single global model for all participating devices, which may not be helpful to all devices participating in the training due to the heterogeneity of the data across the devices. Recently, Hanzely and Richt\\'{a}rik (2020) proposed a new formulation for training personalized FL models aimed at balancing the trade-off between the traditional global model and the local models that could be trained by individual devices using their private data only. They derived a new algorithm, called {\\em loopless gradient descent}~(L2GD), to solve it and showed that this algorithms leads to improved communication complexity guarantees in regimes when more personalization is required. In this paper, we equip their L2GD algorithm with a {\\em bidirectional} compression mechanism to further reduce the communication bottleneck between the local devices and the server. Unlike other compression-based algorithms used in the FL-setting, our compressed L2GD algorithm operates on a probabilistic communication protocol, where communication does not happen on a fixed schedule. Moreover, our compressed L2GD algorithm maintains a similar convergence rate as vanilla SGD without compression. To empirically validate the efficiency of our algorithm, we perform diverse numerical experiments on both convex and non-convex problems and using various compression techniques",
    "checked": true,
    "id": "9849705c3afaa6a147cc0c4d95d97130132e3199",
    "semantic_title": "personalized federated learning with communication compression",
    "citation_count": 10,
    "authors": [
      "El houcine Bergou",
      "Konstantin Pavlovich Burlachenko",
      "Aritra Dutta",
      "Peter Richtárik"
    ]
  },
  "https://openreview.net/forum?id=LT4DXqUJTD": {
    "title": "Uncovering Unique Concept Vectors through Latent Space Decomposition",
    "volume": "main",
    "abstract": "Interpreting the inner workings of deep learning models is crucial for establishing trust and ensuring model safety. Concept-based explanations have emerged as a superior approach that is more interpretable than feature attribution estimates such as pixel saliency. However, defining the concepts for the interpretability analysis biases the explanations by the user's expectations on the concepts. To address this, we propose a novel post-hoc unsupervised method that automatically uncovers the concepts learned by deep models during training. By decomposing the latent space of a layer in singular vectors and refining them by unsupervised clustering, we uncover concept vectors aligned with directions of high variance that are relevant to the model prediction, and that point to semantically distinct concepts. Our extensive experiments reveal that the majority of our concepts are readily understandable to humans, exhibit coherency, and bear relevance to the task at hand. Moreover, we showcase the practical utility of our method in dataset exploration, where our concept vectors successfully identify outlier training samples affected by various confounding factors. This novel exploration technique has remarkable versatility to data types and model architectures and it will facilitate the identification of biases and the discovery of sources of error within training data",
    "checked": true,
    "id": "a0f7ebe4c978c8c9e42e4e5004b968d58a9e901e",
    "semantic_title": "uncovering unique concept vectors through latent space decomposition",
    "citation_count": 5,
    "authors": [
      "Mara Graziani",
      "Laura O'Mahony",
      "An-phi Nguyen",
      "Henning Müller",
      "Vincent Andrearczyk"
    ]
  },
  "https://openreview.net/forum?id=V7guVYzvE4": {
    "title": "SANTA: Source Anchoring Network and Target Alignment for Continual Test Time Adaptation",
    "volume": "main",
    "abstract": "Adapting a trained model to perform satisfactorily on continually changing test environments is an important and challenging task. In this work, we propose a novel framework, SANTA, which aims to satisfy the following characteristics required for online adaptation: 1) can work effectively for different (even small) batch sizes; 2) should continue to work well on the source domain; 3) should have minimal tunable hyperparameters and storage requirements. Given a pre-trained network trained on source domain data, the proposed framework modifies the affine parameters of the batch normalization layers using source anchoring based self-distillation. This ensures that the model incorporates knowledge from the newly encountered domains, without catastrophically forgetting the previously seen domains. We also propose a source-prototype driven contrastive alignment to ensure natural grouping of the target samples, while maintaining the already learnt semantic information. Extensive evaluation on three benchmark datasets under challenging settings justify the effectiveness of SANTA for real-world applications. Code here: https://github.com/goirik-chakrabarty/SANTA",
    "checked": true,
    "id": "a08f8b9355eff9135970c378bddc3252ecf61236",
    "semantic_title": "santa: source anchoring network and target alignment for continual test time adaptation",
    "citation_count": 9,
    "authors": [
      "Goirik Chakrabarty",
      "Manogna Sreenivas",
      "Soma Biswas"
    ]
  },
  "https://openreview.net/forum?id=gvqzvUVPiQ": {
    "title": "The Analysis of the Expected Change in the Classification Probability of the Predicted Label",
    "volume": "main",
    "abstract": "We present a formalism for estimating the expected change in the probability distribution of the predicted label of an object, with respect to all small perturbations to the object. We first derive analytically an estimate of the expected probability change as a function of the input noise. We then conduct three empirical studies: in the first study, experimental results on image classification show that the proposed measure can be used to distinguish the not-robust label predictions from those that are robust, even when they are all predicted with high confidence. The second study shows that the proposed robustness measure is almost always higher for the predictions on the corrupted images, compared to the predictions on the original versions of them. The final study shows that the proposed measure is lower for models when they are trained using adversarial training approaches",
    "checked": true,
    "id": "17f3ca0e7489faf6b3f53cfa327c7bca2d936e30",
    "semantic_title": "the analysis of the expected change in the classification probability of the predicted label",
    "citation_count": 0,
    "authors": [
      "Ruo Yang",
      "Ping Liu",
      "Mustafa Bilgic"
    ]
  },
  "https://openreview.net/forum?id=NE2xXWo0LF": {
    "title": "Latent State Models of Training Dynamics",
    "volume": "main",
    "abstract": "The impact of randomness on model training is poorly understood. How do differences in data order and initialization actually manifest in the model, such that some training runs outperform others or converge faster? Furthermore, how can we interpret the resulting training dynamics and the phase transitions that characterize different trajectories? To understand the effect of randomness on the dynamics and outcomes of neural network training, we train models multiple times with different random seeds and compute a variety of metrics throughout training, such as the $L_2$ norm, mean, and variance of the neural network's weights. We then fit a hidden Markov model (HMM) over the resulting sequences of metrics. The HMM represents training as a stochastic process of transitions between latent states, providing an intuitive overview of significant changes during training. Using our method, we produce a low-dimensional, discrete representation of training dynamics on grokking tasks, image classification, and masked language modeling. We use the HMM representation to study phase transitions and identify latent \"detour\" states that slow down convergence",
    "checked": true,
    "id": "01bc697a530bf5b15ec0f20b6419947d66af4d83",
    "semantic_title": "latent state models of training dynamics",
    "citation_count": 8,
    "authors": [
      "Michael Y. Hu",
      "Angelica Chen",
      "Naomi Saphra",
      "Kyunghyun Cho"
    ]
  },
  "https://openreview.net/forum?id=o8VgRNYh6n": {
    "title": "Differentially Private Optimizers Can Learn Adversarially Robust Models",
    "volume": "main",
    "abstract": "Machine learning models have shone in a variety of domains and attracted increasing attention from both the security and the privacy communities. One important yet worrying question is: Will training models under the differential privacy (DP) constraint have an unfavorable impact on their adversarial robustness? While previous works have postulated that privacy comes at the cost of worse robustness, we give the first theoretical analysis to show that DP models can indeed be robust and accurate, even sometimes more robust than their naturally-trained non-private counterparts. We observe three key factors that influence the privacy-robustness-accuracy tradeoff: (1) hyper-parameters for DP optimizers are critical; (2) pre-training on public data significantly mitigates the accuracy and robustness drop; (3) choice of DP optimizers makes a difference. With these factors set properly, we achieve 90\\% natural accuracy, 72\\% robust accuracy ($+9\\%$ than the non-private model) under $l_2(0.5)$ attack, and 69\\% robust accuracy ($+16\\%$ than the non-private model) with pre-trained SimCLRv2 model under $l_\\infty(4/255)$ attack on CIFAR10 with $\\epsilon=2$. In fact, we show both theoretically and empirically that DP models are Pareto optimal on the accuracy-robustness tradeoff. Empirically, the robustness of DP models is consistently observed across various datasets and models. We believe our encouraging results are a significant step towards training models that are private as well as robust",
    "checked": true,
    "id": "19c8fee47f4a88fae01042f907d8030bf73f9bb0",
    "semantic_title": "differentially private optimizers can learn adversarially robust models",
    "citation_count": 4,
    "authors": [
      "Zhiqi Bu",
      "Yuan Zhang"
    ]
  },
  "https://openreview.net/forum?id=oyfRWeoUJY": {
    "title": "Addressing caveats of neural persistence with deep graph persistence",
    "volume": "main",
    "abstract": "Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning. In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence. Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights. Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers. Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix. This yields our deep graph persistence measure, which implicitly incorporates persistent paths through the network and alleviates variance-related issues through standardisation. Code is available at https://github.com/ExplainableML/Deep-Graph-Persistence",
    "checked": true,
    "id": "926070acfff1ba430944f0773dd41a3d56e15cb3",
    "semantic_title": "addressing caveats of neural persistence with deep graph persistence",
    "citation_count": 1,
    "authors": [
      "Leander Girrbach",
      "Anders Christensen",
      "Ole Winther",
      "Zeynep Akata",
      "A. Sophia Koepke"
    ]
  },
  "https://openreview.net/forum?id=91hfMEUukm": {
    "title": "Replay-enhanced Continual Reinforcement Learning",
    "volume": "main",
    "abstract": "Replaying past experiences has proven to be a highly effective approach for averting catastrophic forgetting in supervised continual learning. However, some crucial factors are still largely ignored, making it vulnerable to serious failure, when used as a solution to forgetting in continual reinforcement learning, even in the context of perfect memory where all data of previous tasks are accessible in the current task. On the one hand, since most reinforcement learning algorithms are not invariant to the reward scale, the previously well-learned tasks (with high rewards) may appear to be more salient to the current learning process than the current task (with small initial rewards). This causes the agent to concentrate on those salient tasks at the expense of generality on the current task. On the other hand, offline learning on replayed tasks while learning a new task may induce a distributional shift between the dataset and the learned policy on old tasks, resulting in forgetting. In this paper, we introduce RECALL, a replay-enhanced method that greatly improves the plasticity of existing replay-based methods on new tasks while effectively avoiding the recurrence of catastrophic forgetting in continual reinforcement learning. RECALL leverages adaptive normalization on approximate targets and policy distillation on old tasks to enhance generality and stability, respectively. Extensive experiments on the Continual World benchmark show that RECALL performs significantly better than purely perfect memory replay, and achieves comparable or better overall performance against state-of-the-art continual learning methods",
    "checked": true,
    "id": "f5bbd862df67bc681957e8c1bc64159c5ac38020",
    "semantic_title": "replay-enhanced continual reinforcement learning",
    "citation_count": 7,
    "authors": [
      "Tiantian Zhang",
      "Kevin Zehua Shen",
      "Zichuan Lin",
      "Bo Yuan",
      "Xueqian Wang",
      "Xiu Li",
      "Deheng Ye"
    ]
  },
  "https://openreview.net/forum?id=JllRdycmLk": {
    "title": "The (Un)Scalability of Informed Heuristic Function Estimation in NP-Hard Search Problems",
    "volume": "main",
    "abstract": "The A* algorithm is commonly used to solve NP-hard combinatorial optimization problems. When provided with a completely informed heuristic function, A* can solve such problems in time complexity that is polynomial in the solution cost and branching factor. In light of this fact, we examine a line of recent publications that propose fitting deep neural networks to the completely informed heuristic function. We assert that these works suffer from inherent scalability limitations since --- under the assumption of NP $\\not \\subseteq$ P/poly --- such approaches result in either (a) network sizes that scale super-polynomially in the instance sizes or (b) the accuracy of the fitted deep neural networks scales inversely with the instance sizes. Complementing our theoretical claims, we provide experimental results for three representative NP-hard search problems. The results suggest that fitting deep neural networks to informed heuristic functions requires network sizes that grow quickly with the problem instance size. We conclude by suggesting that the research community should focus on scalable methods for integrating heuristic search with machine learning, as opposed to methods relying on informed heuristic estimation",
    "checked": true,
    "id": "394bcb1ed8b7ad8d4580ab7e78cfc40ea528d78a",
    "semantic_title": "the (un)scalability of informed heuristic function estimation in np-hard search problems",
    "citation_count": 1,
    "authors": [
      "Sumedh Pendurkar",
      "Taoan Huang",
      "Brendan Juba",
      "Jiapeng Zhang",
      "Sven Koenig",
      "Guni Sharon"
    ]
  },
  "https://openreview.net/forum?id=ndw90pkNM9": {
    "title": "A Combinatorial Semi-Bandit Approach to Charging Station Selection for Electric Vehicles",
    "volume": "main",
    "abstract": "In this work, we address the problem of long-distance navigation for battery electric vehicles (BEVs), where one or more charging sessions are required to reach the intended destination. We consider the availability and performance of the charging stations to be unknown and stochastic, and develop a combinatorial semi-bandit framework for exploring the road network to learn the parameters of the queue time and charging power distributions. Within this framework, we first outline a method for transforming the road network graph into a graph of feasible paths between charging stations to handle the constrained combinatorial optimization problem in an efficient way. Then, for the feasibility graph, we use a Bayesian approach to model the stochastic edge weights, utilizing conjugate priors for the one-parameter exponential and two-parameter gamma distributions, the latter of which is novel to multi-armed bandit literature. Finally, we apply combinatorial versions of Thompson Sampling, BayesUCB and Epsilon-greedy to the problem. We demonstrate the performance of our framework on long-distance navigation problem instances in large-scale country-sized road networks, with simulation experiments in Norway, Sweden and Finland",
    "checked": true,
    "id": "969676d0f6002d57b487d220ba400ee6d90b8e5b",
    "semantic_title": "a combinatorial semi-bandit approach to charging station selection for electric vehicles",
    "citation_count": 0,
    "authors": [
      "Niklas Åkerblom",
      "Morteza Haghir Chehreghani"
    ]
  },
  "https://openreview.net/forum?id=4rkKN4tM63": {
    "title": "Invertible Hierarchical Generative Model for Images",
    "volume": "main",
    "abstract": "Normalizing flows (NFs) as generative models enjoy desirable properties such as exact invertibility and exact likelihood evaluation, while being efficient to sample from. These properties, however, come at the cost of heavy restrictions on the architecture. Due to these limitations, modeling multi-modal probability distributions can yield poor results even with low-dimensional data. Additionally, typical flow architectures employed on real image datasets produce samples with visible aliasing artifacts and limited variation. The latent decomposition of flow-models also falls short on that of competing methods, with uneven contribution to a decoded image. In this work we build an invertible generative model using conditional normalizing flows in a hierarchical fashion to circumvent the aforementioned limitations. We show that we can achieve superior sample quality among flow-based models with fewer parameters compared to the state of the art. We demonstrate ability to control individual levels of detail via the latent decomposition of our model",
    "checked": true,
    "id": "781fde26e007ba48b2759169fb2321a8671344f1",
    "semantic_title": "invertible hierarchical generative model for images",
    "citation_count": 0,
    "authors": [
      "Heikki Timonen",
      "Miika Aittala",
      "Jaakko Lehtinen"
    ]
  },
  "https://openreview.net/forum?id=BxdrpnRHNh": {
    "title": "Using Representation Expressiveness and Learnability to Evaluate Self-Supervised Learning Methods",
    "volume": "main",
    "abstract": "We address the problem of evaluating the quality of self-supervised learning (SSL) models without access to supervised labels, while being agnostic to the architecture, learning algorithm or data manipulation used during training. We argue that representations can be evaluated through the lens of expressiveness and learnability. We propose to use the Intrinsic Dimension (ID) to assess expressiveness and introduce Cluster Learnability (CL) to assess learnability. CL is measured in terms of the performance of a KNN classifier trained to predict labels obtained by clustering the representations with K-means. We thus combine CL and ID into a single predictor – CLID. Through a large-scale empirical study with a diverse family of SSL algorithms, we find that CLID better correlates with in-distribution model performance than other competing recent evaluation schemes. We also benchmark CLID on out-of-domain generalization, where CLID serves as a predictor of the transfer performance of SSL models on several visual classification tasks, yielding improvements with respect to the competing baselines",
    "checked": true,
    "id": "f3f3cacc5e36ab98e719b896c99ca757fee592a8",
    "semantic_title": "using representation expressiveness and learnability to evaluate self-supervised learning methods",
    "citation_count": 0,
    "authors": [
      "Yuchen Lu",
      "Zhen Liu",
      "Aristide Baratin",
      "Romain Laroche",
      "Aaron Courville",
      "Alessandro Sordoni"
    ]
  },
  "https://openreview.net/forum?id=SQnPE63jtA": {
    "title": "Learning Multiscale Non-stationary Causal Structures",
    "volume": "main",
    "abstract": "This paper addresses a gap in the current state of the art by providing a solution for modeling causal relationships that evolve over time and occur at different time scales. Specifically, we introduce the multiscale non-stationary directed acyclic graph (MN-DAG), a framework for modeling multivariate time series data. Our contribution is twofold. Firstly, we expose a probabilistic generative model by leveraging results from spectral and causality theories. Our model allows sampling an MN-DAG according to user-specified priors on the time-dependence and multiscale properties of the causal graph. Secondly, we devise a Bayesian method named Multiscale Non-stationary Causal Structure Learner (MN-CASTLE) that uses stochastic variational inference to estimate MN-DAGs. The method also exploits information from the local partial correlation between time series over different time resolutions. The data generated from an MN-DAG reproduces well-known features of time series in different domains, such as volatility clustering and serial correlation. Additionally, we show the superior performance of MN-CASTLE on synthetic data with different multiscale and non-stationary properties compared to baseline models. Finally, we apply MN-CASTLE to identify the drivers of the natural gas prices in the US market. Causal relationships have strengthened during the COVID-19 outbreak and the Russian invasion of Ukraine, a fact that baseline methods fail to capture. MN-CASTLE identifies the causal impact of critical economic drivers on natural gas prices, such as seasonal factors, economic uncertainty, oil prices, and gas storage deviations",
    "checked": true,
    "id": "7706ef7e213cbb099dfeb1861dae82971de50780",
    "semantic_title": "learning multiscale non-stationary causal structures",
    "citation_count": 4,
    "authors": [
      "Gabriele D'Acunto",
      "Gianmarco De Francisci Morales",
      "Paolo Bajardi",
      "Francesco Bonchi"
    ]
  },
  "https://openreview.net/forum?id=r06xREo3QG": {
    "title": "Bag of Image Patch Embedding Behind the Success of Self-Supervised Learning",
    "volume": "main",
    "abstract": "Self-supervised learning (SSL) has recently achieved tremendous empirical advancements in learning image representation. However, our understanding of the principle behind learning such a representation is still limited. This work shows that joint-embedding SSL approaches learn a representation of image patches, which reflects their co-occurrence. Such a connection to co-occurrence modeling can be established formally, and it supplements the prevailing invariance perspective. We empirically show that learning a representation for fixed-scale patches and aggregating local patch representations as the image representation achieves similar or even better results than the baseline methods. We denote this process as {\\it BagSSL}. Even with $32\\times 32$ patch representation, BagSSL achieves $62\\%$ top-1 linear probing accuracy on ImageNet. On the other hand, with a multi-scale pretrained model, we show that the whole image embedding is approximately the average of local patch embeddings. While the SSL representation is relatively invariant at the global scale, we show that locality is preserved when we zoom into local patch-level representation. Further, we show that patch representation aggregation can improve various SOTA baseline methods by a large margin. The patch representation is considerably easier to understand, and this work makes a step to demystify self-supervised representation learning",
    "checked": true,
    "id": "0bbb60fd0fe2e0ffefacb16fc2c527cb2f01a71e",
    "semantic_title": "bag of image patch embedding behind the success of self-supervised learning",
    "citation_count": 7,
    "authors": [
      "Yubei Chen",
      "Adrien Bardes",
      "ZENGYI LI",
      "Yann LeCun"
    ]
  },
  "https://openreview.net/forum?id=8HQCOMRa7g": {
    "title": "One-Round Active Learning through Data Utility Learning and Proxy Models",
    "volume": "main",
    "abstract": "While active learning (AL) techniques have demonstrated the potential to produce high-performance models with fewer labeled data, their application remains limited due to the necessity for multiple rounds of interaction with annotators. This paper studies the problem of one-round AL, which aims at selecting a subset of unlabeled points and querying their labels \\emph{all at once}. A fundamental challenge is how to measure the utility of different choices of labeling queries for learning a target model. Our key idea is to learn such a utility metric from a small initial labeled set. We demonstrate that our approach leads to state-of-the-art performance on various AL benchmarks and is more robust to the lack of initial labeled data. In addition to algorithmic development and evaluation, we introduce a novel metric for quantifying `\\emph{utility transferability}' -- the degree of correlation between the performance changes of two learning algorithms due to variations in training data selection. Previous studies have often observed a notable utility transferability between models, even those with differing complexities. Such transferability enabled our approach, as well as other techniques such as coresets, hyperparameter tuning, and data valuation, to scale up to more sophisticated target models by substituting them with smaller proxy models. Nevertheless, utility transferability has not yet been rigorously defined within a formal mathematical framework, a gap that our work addresses innovatively. We further propose two Monte Carlo-based methods for efficiently comparing utility transferability for different proxy models, thereby facilitating a more informed selection of proxy models",
    "checked": true,
    "id": "89ffeb90dcdf7823844fbc0dd3a8bb3a60d48b0f",
    "semantic_title": "one-round active learning through data utility learning and proxy models",
    "citation_count": 1,
    "authors": [
      "Jiachen T. Wang",
      "Si Chen",
      "Ruoxi Jia"
    ]
  },
  "https://openreview.net/forum?id=J3veZdVpts": {
    "title": "Bridging the Gap Between Offline and Online Reinforcement Learning Evaluation Methodologies",
    "volume": "main",
    "abstract": "Reinforcement learning (RL) has shown great promise with algorithms learning in environments with large state and action spaces purely from scalar reward signals. A crucial challenge for current deep RL algorithms is that they require a tremendous amount of environment interactions for learning. This can be infeasible in situations where such interactions are expensive, such as in robotics. Offline RL algorithms try to address this issue by bootstrapping the learning process from existing logged data without needing to interact with the environment from the very beginning. While online RL algorithms are typically evaluated as a function of the number of environment interactions, there isn't a single established protocol for evaluating offline RL methods. In this paper, we propose a sequential approach to evaluate offline RL algorithms as a function of the training set size and thus by their data efficiency. Sequential evaluation provides valuable insights into the data efficiency of the learning process and the robustness of algorithms to distribution changes in the dataset while also harmonizing the visualization of the offline and online learning phases. Our approach is generally applicable and easy to implement. We compare several existing offline RL algorithms using this approach and present insights from a variety of tasks and offline datasets",
    "checked": true,
    "id": "0f1947fe9ae67eccd2c09057ab00553ebf8c318b",
    "semantic_title": "bridging the gap between offline and online reinforcement learning evaluation methodologies",
    "citation_count": 2,
    "authors": [
      "Shivakanth Sujit",
      "Pedro Braga",
      "Jorg Bornschein",
      "Samira Ebrahimi Kahou"
    ]
  },
  "https://openreview.net/forum?id=hjYmsV6nXZ": {
    "title": "RLTF: Reinforcement Learning from Unit Test Feedback",
    "volume": "main",
    "abstract": "The goal of program synthesis, or code generation, is to generate executable code based on given descriptions. Recently, there has been an increasing number of studies employing reinforcement learning (RL) to improve the performance of large language models (LLMs) for code. However, some of the current representative RL methods have only used offline frameworks, limiting the exploration of new sample spaces. Additionally, the utilization of unit test signals is limited, not accounting for specific error locations within the code. To address these issues, we proposed RLTF, i.e., Reinforcement Learning from Unit Test Feedback, a novel online RL framework with unit test feedback of multi-granularity for refining code LLMs. Our approach generates data in real-time during training and simultaneously utilizes fine-grained feedback signals to guide the model towards producing higher-quality code. Extensive experiments show that RLTF achieves state-of-the-art performance on the APPS and the MBPP benchmarks. Our code is available at: \\url{https://github.com/Zyq-scut/RLTF}",
    "checked": true,
    "id": "a669ea57529f4db630043c8c75d8f840c485d24d",
    "semantic_title": "rltf: reinforcement learning from unit test feedback",
    "citation_count": 70,
    "authors": [
      "Jiate Liu",
      "Yiqin Zhu",
      "Kaiwen Xiao",
      "QIANG FU",
      "Xiao Han",
      "Yang Wei",
      "Deheng Ye"
    ]
  },
  "https://openreview.net/forum?id=ZSxvyWrX6k": {
    "title": "Visualizing the Diversity of Representations Learned by Bayesian Neural Networks",
    "volume": "main",
    "abstract": "Explainable Artificial Intelligence (XAI) aims to make learning machines less opaque, and offers researchers and practitioners various tools to reveal the decision-making strategies of neural networks. In this work, we investigate how XAI methods can be used for exploring and visualizing the diversity of feature representations learned by Bayesian Neural Networks (BNNs). Our goal is to provide a global understanding of BNNs by making their decision-making strategies a) visible and tangible through feature visualizations and b) quantitatively measurable with a distance measure learned by contrastive learning. Our work provides new insights into the posterior distribution in terms of human-understandable feature information with regard to the underlying decision-making strategies. The main findings of our work are the following: 1) global XAI methods can be applied to explain the diversity of decision-making strategies of BNN instances, 2) Monte Carlo dropout with commonly used Dropout rates exhibit increased diversity in feature representations compared to the multimodal posterior approximation of MultiSWAG, 3) the diversity of learned feature representations highly correlates with the uncertainty estimate for the output and 4) the inter-mode diversity of the multimodal posterior decreases as the network width increases, while the intra-mode diversity increases. These findings are consistent with the recent Deep Neural Networks theory, providing additional intuitions about what the theory implies in terms of humanly understandable concepts",
    "checked": true,
    "id": "bd1486c78d5a16b544e6d9d014d96681fc7dd56b",
    "semantic_title": "visualizing the diversity of representations learned by bayesian neural networks",
    "citation_count": 5,
    "authors": [
      "Dennis Grinwald",
      "Kirill Bykov",
      "Shinichi Nakajima",
      "Marina MC Höhne"
    ]
  },
  "https://openreview.net/forum?id=cdRYoTyHZh": {
    "title": "Automated Detection of Causal Inference Opportunities: Regression Discontinuity Subgroup Discovery",
    "volume": "main",
    "abstract": "The gold standard for the identification of causal effects are randomized controlled trials (RCT), but RCTs may not always be feasible to conduct. When treatments depend on a threshold however, such as the blood sugar threshold for diabetes diagnosis, we can still sometimes estimate causal effects with regression discontinuities (RDs). RDs are valid when units just above and below the threshold have the same distribution of covariates and thus no confounding in the presence of noise, establishing an as-if randomization. In practice however, implementing RD studies can be difficult as identifying treatment thresholds require considerable domain expertise -- furthermore, the thresholds may differ across subgroups (e.g., the blood sugar threshold for diabetes may differ across demographics), and ignoring these differences can lower statistical power. Finding the thresholds and to whom they apply is an important problem currently solved manually by domain experts, and data-driven approaches are needed when domain expertise is not sufficient. Here, we introduce Regression Discontinuity SubGroup Discovery (RDSGD), a machine-learning method that identifies statistically powerful and interpretable subgroups for RD thresholds. Using a medical claims dataset with over 60 million patients, we apply RDSGD to multiple clinical contexts and identify subgroups with increased compliance to treatment assignment thresholds. As treatment thresholds matter for many diseases and policy decisions, RDSGD can be a powerful tool for discovering new avenues for causal estimation",
    "checked": true,
    "id": "64e1ed0941ed89fcf8a02d5a7d0a3935495c2dfb",
    "semantic_title": "automated detection of causal inference opportunities: regression discontinuity subgroup discovery",
    "citation_count": 0,
    "authors": [
      "Tony Liu",
      "Patrick Lawlor",
      "Lyle Ungar",
      "Konrad Kording",
      "Rahul Ladhania"
    ]
  },
  "https://openreview.net/forum?id=A9yn7KTwsK": {
    "title": "Invariant Structure Learning for Better Generalization and Causal Explainability",
    "volume": "main",
    "abstract": "Learning the causal structure behind data is invaluable for improving generalization and ob- taining high-quality explanations. Towards this end, we propose a novel framework, Invariant Structure Learning (ISL), that is designed to improve causal structure discovery by utilizing generalization as an indication in the process. ISL splits the data into different environments, and learns a structure that is invariant to the target across different environments by imposing a consistency constraint. The proposed aggregation mechanism then selects the classifier based on a graph structure that reflects the causal mechanisms in the data more accurately compared to the structures learnt from individual environments. Furthermore, we extend ISL to a self-supervised learning setting, where accurate causal structure discovery does not rely on any labels. Self-supervised ISL utilizes proposals for invariant causality, by iteratively setting different nodes as targets. On synthetic and real-world datasets, we demonstrate that ISL accurately discovers the causal structure, outperforms alternative methods, and yields superior generalization for datasets with significant distribution shifts",
    "checked": true,
    "id": "edc07047cd45e90aff0556ab10b16740a8110e61",
    "semantic_title": "invariant structure learning for better generalization and causal explainability",
    "citation_count": 2,
    "authors": [
      "Yunhao Ge",
      "Sercan O Arik",
      "Jinsung Yoon",
      "Ao Xu",
      "Laurent Itti",
      "Tomas Pfister"
    ]
  },
  "https://openreview.net/forum?id=iRTL4pDavo": {
    "title": "Data pruning and neural scaling laws: fundamental limitations of score-based algorithms",
    "volume": "main",
    "abstract": "Data pruning algorithms are commonly used to reduce the memory and computational cost of the optimization process. Recent empirical results (Guo, B. Zhao, and Bai, 2022) reveal that random data pruning remains a strong baseline and outperforms most existing data pruning methods in the high compression regime, i.e., where a fraction of 30% or less of the data is kept. This regime has recently attracted a lot of interest as a result of the role of data pruning in improving the so-called neural scaling laws; see (Sorscher et al., 2022), where the authors showed the need for high-quality data pruning algorithms in order to beat the sample power law. In this work, we focus on score-based data pruning algorithms and show theoretically and empirically why such algorithms fail in the high compression regime. We demonstrate \"No Free Lunch\" theorems for data pruning and discuss potential solutions to these limitations",
    "checked": true,
    "id": "bb4721b1a806ac00308bfb174edf3c36b6f0b620",
    "semantic_title": "data pruning and neural scaling laws: fundamental limitations of score-based algorithms",
    "citation_count": 11,
    "authors": [
      "Fadhel Ayed",
      "Soufiane Hayou"
    ]
  },
  "https://openreview.net/forum?id=AfXq3x3X16": {
    "title": "Offline Reinforcement Learning with Additional Covering Distributions",
    "volume": "main",
    "abstract": "We study learning optimal policies from a logged dataset, i.e., offline RL, with function general approximation. Despite the efforts devoted, existing algorithms with theoretic finite-sample guarantees typically assume exploratory data coverage or strong realizable function classes (e.g., Bellman-completeness), which is hard to be satisfied in reality. While there are recent works that successfully tackle these strong assumptions, they either require the gap assumptions that could only be satisfied by part of MDPs or use the behavior regularization that makes the optimality of learned policy even intractable. To solve this challenge, we provide finite-sample guarantees for a simple algorithm based on marginalized importance sampling (MIS), showing that sample-efficient offline RL for general MDPs is possible with only a partial coverage dataset (instead of assuming a dataset covering all possible policies) and weak realizable function classes (assuming function classes containing simply one function) given additional side information of a covering distribution. We demonstrate that the covering distribution trades off prior knowledge of the optimal trajectories against the coverage requirement of the dataset, revealing the effect of this inductive bias in the learning processes. Furthermore, when considering the exploratory dataset, our analysis shows that only realizable function classes are enough for learning near-optimal policies, even with no side information on the additional coverage distributions",
    "checked": true,
    "id": "3f1302446ae40cceea8a804efc9fc2dba1d056d0",
    "semantic_title": "offline reinforcement learning with additional covering distributions",
    "citation_count": 0,
    "authors": [
      "Chenjie Mao"
    ]
  },
  "https://openreview.net/forum?id=23WZFQBUh5": {
    "title": "Online model selection by learning how compositional kernels evolve",
    "volume": "main",
    "abstract": "Motivated by the need for efficient, personalized learning in health, we investigate the problem of online compositional kernel selection for multi-task Gaussian Process regression. Existing composition selection methods do not satisfy our strict criteria in health; selection must occur quickly, and the selected kernels must maintain the appropriate level of complexity, sparsity, and stability as data arrives online. We introduce the Kernel Evolution Model (KEM), a generative process on how to evolve kernel compositions in a way that manages the bias--variance trade-off as we observe more data about a user. Using pilot data, we learn a set of kernel evolutions that can be used to quickly select kernels for new test users. KEM reliably selects high-performing kernels for a range of synthetic and real data sets, including two health data sets",
    "checked": true,
    "id": "cf03f313f861c567d5f6076702835cbc3691f771",
    "semantic_title": "online model selection by learning how compositional kernels evolve",
    "citation_count": 3,
    "authors": [
      "Eura Shin",
      "Predrag Klasnja",
      "Susan Murphy",
      "Finale Doshi-Velez"
    ]
  },
  "https://openreview.net/forum?id=EjqopDxLbG": {
    "title": "NOFLITE: Learning to Predict Individual Treatment Effect Distributions",
    "volume": "main",
    "abstract": "Estimating the effect of a treatment on an individual's outcome of interest is an important challenge in various fields, such as healthcare, economics, marketing, and education. Previous work in machine learning has focused on estimating the expected value of the treatment effect. However, effective personalized decision-making requires more than just the treatment expected effect; it requires knowing the entire treatment effect distribution. Knowing this distribution allows analyzing the treatment's expected utility or quantifying the uncertainty regarding a treatment's effect. This information is essential for prescribing optimal treatments. The ability of a model to predict accurate individual treatment effect distributions is captured by its likelihood. In light of this, we propose a novel neural architecture, NOFLITE, that uses normalizing flows to directly optimize this likelihood, while simultaneously learning flexible estimates of the individual treatment effect distribution. Experiments on various semi-synthetic data sets show that NOFLITE outperforms existing methods in terms of loglikelihood. Moreover, we illustrate how the predicted distributions can enable an in-depth analysis of the treatment effect and more accurate decision-making",
    "checked": true,
    "id": "3e5b2797577be2bcb1d7af3ff848703727b22efe",
    "semantic_title": "noflite: learning to predict individual treatment effect distributions",
    "citation_count": 4,
    "authors": [
      "Toon Vanderschueren",
      "Jeroen Berrevoets",
      "Wouter Verbeke"
    ]
  },
  "https://openreview.net/forum?id=28bQiPWxHl": {
    "title": "Stochastic Mirror Descent: Convergence Analysis and Adaptive Variants via the Mirror Stochastic Polyak Stepsize",
    "volume": "main",
    "abstract": "We investigate the convergence of stochastic mirror descent (SMD) under interpolation in relatively smooth and smooth convex optimization. In relatively smooth convex optimization we provide new convergence guarantees for SMD with a constant stepsize. For smooth convex optimization we propose a new adaptive stepsize scheme --- the mirror stochastic Polyak stepsize (mSPS). Notably, our convergence results in both settings do not make bounded gradient assumptions or bounded variance assumptions, and we show convergence to a neighborhood that vanishes under interpolation. Consequently, these results correspond to the first convergence guarantees under interpolation for the exponentiated gradient algorithm for fixed or adaptive stepsizes. mSPS generalizes the recently proposed stochastic Polyak stepsize (SPS) (Loizou et al. 2021) to mirror descent and remains both practical and efficient for modern machine learning applications while inheriting the benefits of mirror descent. We complement our results with experiments across various supervised learning tasks and different instances of SMD, demonstrating the effectiveness of mSPS",
    "checked": true,
    "id": "f866b44965117173ced03178fe685fa8d26b2f67",
    "semantic_title": "stochastic mirror descent: convergence analysis and adaptive variants via the mirror stochastic polyak stepsize",
    "citation_count": 31,
    "authors": [
      "Ryan D'Orazio",
      "Nicolas Loizou",
      "Issam H. Laradji",
      "Ioannis Mitliagkas"
    ]
  },
  "https://openreview.net/forum?id=B0uBSSUy0G": {
    "title": "Provably Personalized and Robust Federated Learning",
    "volume": "main",
    "abstract": "Clustering clients with similar objectives and learning a model per cluster is an intuitive and interpretable approach to personalization in federated learning. However, doing so with provable and optimal guarantees has remained an open challenge. In this work, we formalize personalized federated learning as a stochastic optimization problem. We propose simple clustering-based algorithms which iteratively identify and train within clusters, using local client gradients. Our algorithms have optimal convergence rates which asymptotically match those obtained if we knew the true underlying clustering of the clients, and are provably robust in the Byzantine setting where some fraction of the clients are malicious",
    "checked": true,
    "id": "235f66ac870ee8ede8f131fb0da00472545febab",
    "semantic_title": "provably personalized and robust federated learning",
    "citation_count": 13,
    "authors": [
      "Mariel Werner",
      "Lie He",
      "Michael Jordan",
      "Martin Jaggi",
      "Sai Praneeth Karimireddy"
    ]
  },
  "https://openreview.net/forum?id=I5sJ6PU6JN": {
    "title": "Conditional Sampling of Variational Autoencoders via Iterated Approximate Ancestral Sampling",
    "volume": "main",
    "abstract": "Conditional sampling of variational autoencoders (VAEs) is needed in various applications, such as missing data imputation, but is computationally intractable. A principled choice for asymptotically exact conditional sampling is Metropolis-within-Gibbs (MWG). However, we observe that the tendency of VAEs to learn a structured latent space, a commonly desired property, can cause the MWG sampler to get \"stuck\" far from the target distribution. This paper mitigates the limitations of MWG: we systematically outline the pitfalls in the context of VAEs, propose two original methods that address these pitfalls, and demonstrate an improved performance of the proposed methods on a set of sampling tasks",
    "checked": true,
    "id": "eed436b929b954eab3e9aa856dde0a9428f9dbe5",
    "semantic_title": "conditional sampling of variational autoencoders via iterated approximate ancestral sampling",
    "citation_count": 4,
    "authors": [
      "Vaidotas Simkus",
      "Michael U. Gutmann"
    ]
  },
  "https://openreview.net/forum?id=dn3ZkqG2YV": {
    "title": "Rewiring with Positional Encodings for Graph Neural Networks",
    "volume": "main",
    "abstract": "Several recent works use positional encodings to extend the receptive fields of graph neural network (GNN) layers equipped with attention mechanisms. These techniques, however, extend receptive fields to the complete graph, at substantial computational cost and risking a change in the inductive biases of conventional GNNs, or require complex architecture adjustments. As a conservative alternative, we use positional encodings to expand receptive fields to r-hop neighborhoods. More specifically, our method augments the input graph with additional nodes/edges and uses positional encodings as node and/or edge features. We thus modify graphs before inputting them to a downstream GNN model, instead of modifying the model itself. This makes our method model-agnostic, i.e., compatible with any of the existing GNN architectures. We also provide examples of positional encodings that are lossless with a one-to-one map between the original and the modified graphs. We demonstrate that extending receptive fields via positional encodings and a virtual fully- connected node significantly improves GNN performance and alleviates over-squashing using small r. We obtain improvements on a variety of models and datasets and reach competitive performance using traditional GNNs or graph Transformers",
    "checked": true,
    "id": "002390988f7157b425ac7e5dc42f3d06eca6ede7",
    "semantic_title": "rewiring with positional encodings for graph neural networks",
    "citation_count": 36,
    "authors": [
      "Rickard Brüel Gabrielsson",
      "Mikhail Yurochkin",
      "Justin Solomon"
    ]
  },
  "https://openreview.net/forum?id=leqr0vQzeN": {
    "title": "A Robust Backpropagation-Free Framework for Images",
    "volume": "main",
    "abstract": "While current deep learning algorithms have been successful for a wide variety of artificial intelligence (AI) tasks, including those involving structured image data, they present deep neurophysiological conceptual issues due to their reliance on the gradients that are computed by backpropagation of errors (backprop). Gradients are required to obtain synaptic weight adjustments but require knowledge of feed forward activities in order to conduct backward propagation, a biologically implausible process. This is known as the \"weight transport problem''. Therefore, in this work, we present a more biologically plausible approach towards solving the weight transport problem for image data. This approach, which we name the error-kernel driven activation alignment (EKDAA) algorithm, accomplishes through the introduction of locally derived error transmission kernels and error maps. Like standard deep learning networks, EKDAA performs the standard forward process via weights and activation functions; however, its backward error computation involves adaptive error kernels that propagate local error signals through the network. The efficacy of EKDAA is demonstrated by performing visual-recognition tasks on the Fashion MNIST, CIFAR-10 and SVHN benchmarks, along with demonstrating its ability to extract visual features from natural color images. Furthermore, in order to demonstrate its non-reliance on gradient computations, results are presented for an EKDAA-trained CNN that employs a non-differentiable activation function",
    "checked": true,
    "id": "f191c831918b1616f734da071d54de2ddd745b89",
    "semantic_title": "a robust backpropagation-free framework for images",
    "citation_count": 1,
    "authors": [
      "Timothy Zee",
      "Alex Ororbia",
      "Ankur Mali",
      "Ifeoma Nwogu"
    ]
  },
  "https://openreview.net/forum?id=65AzNvY73Q": {
    "title": "Minorization-Maximization for Learning Determinantal Point Processes",
    "volume": "main",
    "abstract": "A determinantal point process (DPP) is a powerful probabilistic model that generates diverse random subsets from a ground set. Since a DPP is characterized by a positive definite kernel, a DPP on a finite ground set can be parameterized by a kernel matrix. Recently, DPPs have gained attention in the machine learning community and have been applied to various practical problems; however, there is still room for further research on the learning of DPPs. In this paper, we propose a simple learning rule for full-rank DPPs based on a minorization-maximization (MM) algorithm, which monotonically increases the likelihood in each iteration. We show that our minorizer of the MM algorithm provides a tighter lower-bound compared to an existing method locally. We also generalize the algorithm for further acceleration. In our experiments on both synthetic and real-world datasets, our method outperforms existing methods in most settings. Our code is available at https://github.com/ISMHinoLab/DPPMMEstimation",
    "checked": true,
    "id": "05272f41369a00407a5547140cb3a45ee53cc025",
    "semantic_title": "minorization-maximization for learning determinantal point processes",
    "citation_count": 2,
    "authors": [
      "Takahiro Kawashima",
      "Hideitsu Hino"
    ]
  },
  "https://openreview.net/forum?id=gKEbBKRUjA": {
    "title": "Understanding Curriculum Learning in Policy Optimization for Online Combinatorial Optimization",
    "volume": "main",
    "abstract": "Over the recent years, reinforcement learning (RL) starts to show promising results in tackling combinatorial optimization (CO) problems, in particular when coupled with curriculum learning to facilitate training. Despite emerging empirical evidence, theoretical study on why RL helps is still at its early stage. This paper presents the first systematic study on policy optimization methods for online CO problems. We show that online CO problems can be naturally formulated as latent Markov Decision Processes (LMDPs), and prove convergence bounds on natural policy gradient (NPG) for solving LMDPs. Furthermore, our theory explains the benefit of curriculum learning: it can find a strong sampling policy and reduce the distribution shift, a critical quantity that governs the convergence rate in our theorem. For a canonical online CO problem, the Best Choice Problem (BCP), we formally prove that distribution shift is reduced exponentially with curriculum learning even if the curriculum is a randomly generated BCP on a smaller scale. Our theory also shows we can simplify the curriculum learning scheme used in prior work from multi-step to single-step. Lastly, we provide extensive experiments on the Best Choice Problem, Online Knapsack, and AdWords to verify our findings",
    "checked": true,
    "id": "396e224a94202c253a6201d670724041f9cb33a3",
    "semantic_title": "understanding curriculum learning in policy optimization for online combinatorial optimization",
    "citation_count": 3,
    "authors": [
      "Runlong Zhou",
      "Zelin He",
      "Yuandong Tian",
      "Yi Wu",
      "Simon Shaolei Du"
    ]
  },
  "https://openreview.net/forum?id=BxjHMPwZIH": {
    "title": "Training DNNs Resilient to Adversarial and Random Bit-Flips by Learning Quantization Ranges",
    "volume": "main",
    "abstract": "Promoting robustness in deep neural networks (DNNs) is crucial for their reliable deployment in uncertain environments, such as low-power settings or in the presence of adversarial attacks. In particular, bit-flip weight perturbations in quantized networks can significantly degrade performance, underscoring the need to improve DNN resilience. In this paper, we introduce a training mechanism to learn the quantization range of different DNN layers to enhance DNN robustness against bit-flip errors on the model parameters. The proposed approach, called weight clipping-aware training (WCAT), minimizes the quantization range while preserving performance, striking a balance between the two. Our experimental results on different models and datasets showcase that DNNs trained with WCAT can tolerate a high amount of noise while keeping the accuracy close to the baseline model. Moreover, we show that our method significantly enhances DNN robustness against adversarial bit-flip attacks. Finally, when considering the energy-reliability trade-off inherent in on-chip SRAM memories, we observe that WCAT consistently improves the Pareto frontier of test accuracy and energy consumption across diverse models",
    "checked": true,
    "id": "17b6068b5552a5d8c15d3cb8f6cd6452aee29c29",
    "semantic_title": "training dnns resilient to adversarial and random bit-flips by learning quantization ranges",
    "citation_count": 3,
    "authors": [
      "Kamran Chitsaz",
      "Goncalo Mordido",
      "Jean-Pierre David",
      "François Leduc-Primeau"
    ]
  },
  "https://openreview.net/forum?id=j4y3gN7VtW": {
    "title": "Feature-Attending Recurrent Modules for Generalization in Reinforcement Learning",
    "volume": "main",
    "abstract": "Many important tasks are defined in terms of object. To generalize across these tasks, a reinforcement learning (RL) agent needs to exploit the structure that the objects induce. Prior work has either hard-coded object-centric features, used complex object-centric generative models, or updated state using local spatial features. However, these approaches have had limited success in enabling general RL agents. Motivated by this, we introduce \"Feature- Attending Recurrent Modules\" (FARM), an architecture for learning state representations that relies on simple, broadly applicable inductive biases for capturing spatial and temporal regularities. FARM learns a state representation that is distributed across multiple modules that each attend to spatiotemporal features with an expressive feature attention mechanism. We show that this improves an RL agent's ability to generalize across object-centric tasks. We study task suites in both 2D and 3D environments and find that FARM better generalizes compared to competing architectures that leverage attention or multiple modules",
    "checked": true,
    "id": "7365d4b97e38ca7fcd8ac3db194854b59def1d42",
    "semantic_title": "feature-attending recurrent modules for generalization in reinforcement learning",
    "citation_count": 7,
    "authors": [
      "Wilka Torrico Carvalho",
      "Andrew Kyle Lampinen",
      "Kyriacos Nikiforou",
      "Felix Hill",
      "Murray Shanahan"
    ]
  },
  "https://openreview.net/forum?id=5Y04GWvoJu": {
    "title": "Achieving Risk Control in Online Learning Settings",
    "volume": "main",
    "abstract": "To provide rigorous uncertainty quantification for online learning models, we develop a framework for constructing uncertainty sets that provably control risk---such as coverage of confidence intervals, false negative rate, or F1 score---in the online setting. This extends conformal prediction to apply to a larger class of online learning problems. Our method guarantees risk control at any user-specified level even when the underlying data distribution shifts drastically, even adversarially, over time in an unknown fashion. The technique we propose is highly flexible as it can be applied with any base online learning algorithm (e.g., a deep neural network trained online), requiring minimal implementation effort and essentially zero additional computational cost. We further extend our approach to control multiple risks simultaneously, so the prediction sets we generate are valid for all given risks. To demonstrate the utility of our method, we conduct experiments on real-world tabular time-series data sets showing that the proposed method rigorously controls various natural risks. Furthermore, we show how to construct valid intervals for an online image-depth estimation problem that previous sequential calibration schemes cannot handle",
    "checked": true,
    "id": "222e7926d07384f104016a7e2264978fedfcdeda",
    "semantic_title": "achieving risk control in online learning settings",
    "citation_count": 33,
    "authors": [
      "Shai Feldman",
      "Liran Ringel",
      "Stephen Bates",
      "Yaniv Romano"
    ]
  },
  "https://openreview.net/forum?id=1kl4YM2Q7P": {
    "title": "Exploring Transformer Backbones for Heterogeneous Treatment Effect Estimation",
    "volume": "main",
    "abstract": "Previous works on Treatment Effect Estimation (TEE) are not in widespread use because they are predominantly theoretical, where strong parametric assumptions are made but untractable for practical application. Recent works use Multilayer Perceptron (MLP) for modeling casual relationships, however, MLPs lag far behind recent advances in ML methodology, which limits their applicability and generalizability. To extend beyond the single domain formulation and towards more realistic learning scenarios, we explore model design spaces beyond MLPs, i.e., transformer backbones, which provide flexibility where attention layers govern interactions among treatments and covariates to exploit structural similarities of potential outcomes for confounding control. Through careful model design, Transformers as Treatment Effect Estimators (TransTEE) is proposed. We show empirically that TransTEE can: (1) serve as a general-purpose treatment effect estimator which significantly outperforms competitive baselines on a variety of challenging TEE problems (e.g., discrete, continuous, structured, or dosage-associated treatments.) and is applicable to both when covariates are tabular and when they consist of structural data (e.g., texts, graphs); (2) yield multiple advantages: compatibility with propensity score modeling, parameter efficiency, robustness to continuous treatment value distribution shifts, explainable in covariate adjustment, and real-world utility in auditing pre-trained language models",
    "checked": true,
    "id": "0109c662c101723aea99e561937e3aca58563537",
    "semantic_title": "exploring transformer backbones for heterogeneous treatment effect estimation",
    "citation_count": 30,
    "authors": [
      "YiFan Zhang",
      "Hanlin Zhang",
      "Zachary Chase Lipton",
      "Li Erran Li",
      "Eric Xing"
    ]
  },
  "https://openreview.net/forum?id=ok18jj7cam": {
    "title": "GraphPNAS: Learning Probabilistic Graph Generators for Neural Architecture Search",
    "volume": "main",
    "abstract": "Neural architectures can be naturally viewed as computational graphs. Motivated by this perspective, we, in this paper, study neural architecture search (NAS) through the lens of learning graph generative models. In contrast to existing NAS methods which largely focus on searching for a single best architecture, i.e, point estimation, we propose GraphPNAS a deep graph generative model that learns a distribution of well-performing architectures. Relying on graph neural networks (GNNs), our GraphPNAS can better capture topologies of good neural architectures and relations between operators therein. Moreover, our graph generator leads to a learnable probabilistic search method that is more flexible and efficient than the commonly used RNN generator and random search methods. Finally, we learn our generator via an efficient reinforcement learning formulation for NAS. To assess the effectiveness of our GraphPNAS, we conduct extensive experiments on four search spaces, including the challenging RandWire on TinyImageNet, ENAS on CIFAR10, and NAS-Bench-101/201. We show that our proposed graph generator consistently outperforms RNN-based one and achieves better or comparable performances than state-of-the-art NAS methods",
    "checked": true,
    "id": "33291bc4488b2a087bf50d8c1d58af3e7c535884",
    "semantic_title": "graphpnas: learning probabilistic graph generators for neural architecture search",
    "citation_count": 2,
    "authors": [
      "Muchen Li",
      "Jeffrey Yunfan Liu",
      "Leonid Sigal",
      "Renjie Liao"
    ]
  },
  "https://openreview.net/forum?id=jLJTqJXAG7": {
    "title": "Federated Learning under Partially Disjoint Data via Manifold Reshaping",
    "volume": "main",
    "abstract": "Statistical heterogeneity severely limits the performance of federated learning (FL), motivating several explorations e.g., FedProx, MOON and FedDyn, to alleviate this problem. Despite effectiveness, their considered scenario generally requires samples from almost all classes during the local training of each client, although some covariate shifts may exist among clients. In fact, the natural case of partially class-disjoint data (PCDD), where each client contributes a few classes (instead of all classes) of samples, is practical yet underexplored. Specifically, the unique collapse and invasion characteristics of PCDD can induce the biased optimization direction in local training, which prevents the efficiency of federated learning. To address this dilemma, we propose a manifold reshaping approach called FedMR to calibrate the feature space of local training. Our FedMR adds two interplaying losses to the vanilla federated learning: one is the intra-class loss to decorrelate feature dimensions for anti-collapse; and the other one is the inter-class loss to guarantee the proper margin among categories in the feature expansion. We conduct extensive experiments on a range of datasets to demonstrate that our FedMR achieves much higher accuracy and better communication efficiency",
    "checked": true,
    "id": "521bcc5bc7da0a52976551c1a2b8630d01e660b5",
    "semantic_title": "federated learning under partially disjoint data via manifold reshaping",
    "citation_count": 5,
    "authors": [
      "Ziqing Fan",
      "Jiangchao Yao",
      "Ruipeng Zhang",
      "Lingjuan Lyu",
      "Yanfeng Wang",
      "Ya Zhang"
    ]
  },
  "https://openreview.net/forum?id=DlRsoxjyPm": {
    "title": "Synthetic Data from Diffusion Models Improves ImageNet Classification",
    "volume": "main",
    "abstract": "Deep generative models are becoming increasingly powerful, now generating diverse, high fidelity, photo-realistic samples given text prompts. Nevertheless, samples from such models have not been shown to significantly improve model training for challenging and well-studied discriminative tasks like ImageNet classification. In this paper we show that augmenting the ImageNet training set with samples from a generative diffusion model can yield substantial improvements in ImageNet classification accuracy over strong ResNet and Vision Transformer baselines. To this end we explore the fine-tuning of large-scale text-to-image diffusion models, yielding class-conditional ImageNet models with state-of-the-art FID score (1.76 at 256×256 resolution) and Inception Score (239 at 256×256). The model also yields a new state-of-the-art in Classification Accuracy Scores, i.e., ImageNet test accuracy for a ResNet-50 architecture trained solely on synthetic data (64.96 top-1 accuracy for 256×256 samples, improving to 69.24 for 1024×1024 samples). Adding up to three times as many synthetic samples as real training samples consistently improves ImageNet classification accuracy across multiple architectures",
    "checked": true,
    "id": "4538e353dd98f396c8facc29ebb72e9b1ba5f7c2",
    "semantic_title": "synthetic data from diffusion models improves imagenet classification",
    "citation_count": 331,
    "authors": [
      "Shekoofeh Azizi",
      "Simon Kornblith",
      "Chitwan Saharia",
      "Mohammad Norouzi",
      "David J. Fleet"
    ]
  },
  "https://openreview.net/forum?id=f3JLnnZsAm": {
    "title": "ILPO-MP: Mode Priors Prevent Mode Collapse when Imitating Latent Policies from Observations",
    "volume": "main",
    "abstract": "Imitation learning from observations (IfO) constrains the classic imitation learning setting to cases where expert observations are easy to obtain, but no expert actions are available. Most existing IfO methods require access to task-specific cost functions or many interactions with the target environment. Learning a forward dynamics model in combination with a latent policy has been shown to solve these issues. However, the limited supervision in the IfO scenario can lead to mode collapse when learning the generative forward dynamics model and the corresponding latent policy. In this paper, we analyze the mode collapse problem in this setting and show that it is caused by a combination of deterministic expert data and bad initialization of the models. Under the assumption of piecewise continuous system dynamics, we propose ILPO-MP, a method to prevent the mode collapse using clustering of expert transitions to impose a mode prior on the generative model and the latent policy. We show that ILPO-MP prevents mode collapse and improves performance in a variety of environments",
    "checked": true,
    "id": "dc1a8e8f9624c4004ee4968b071db6f5aabd0760",
    "semantic_title": "ilpo-mp: mode priors prevent mode collapse when imitating latent policies from observations",
    "citation_count": 2,
    "authors": [
      "Oliver Struckmeier",
      "Ville Kyrki"
    ]
  },
  "https://openreview.net/forum?id=g1B4qgOw79": {
    "title": "Complementary Sparsity: Accelerating Sparse CNNs with High Accuracy on General-Purpose Computing Platforms",
    "volume": "main",
    "abstract": "Model sparsity is a promising approach to reducing parameters or FLOPs of convolutional neural networks (CNNs). Compared to unstructured or coarse-grained structured sparsity, fine-grained structured sparsity, e.g., N:M sparse pattern, can achieve a better balance between accuracy and efficiency on general computing platforms like CPUs and GPUs. In particular, the 2:4 sparsity can accelerate CNN inference by 2$\\times$ speed and with negligible accuracy drop. However, N:M sparsity needs to be supported by GPU within specific hardware circuits and hardly achieves significant speedups on common GPUs. To accelerate CNNs with general-purposed computing resources and simultaneously retain the model accuracy as much as possible, this paper proposes complementary sparsity (CS). CS denotes that only one weight can be retained for weights spaced at the same distance. On the one hand, CS features high mask flexibility, which is naturally favorable to high model accuracy. Moreover, we propose a CS-specific sparse training method to improve CS-based CNNs' accuracy under high parameter sparsities ($>$75\\%). On the other hand, CS itself is memory-access balanced and robust to pattern hyperparameters, which can be utilized to speedup CS-based convolution computation on CPUs and common GPUs. We thus propose a CS convolution parallel computing algorithm that adapts to common GPUs without sparse tensor cores. Experimental results show that compared to other sparsity patterns, the proposed CS can achieve the optimal trade-off in terms of accuracy and latency for CPUs and common GPUs, respectively. Codes will be available at https://gitee.com/mindspore/models/tree/master/research/cv/CS",
    "checked": true,
    "id": "e6592ed83ee30ba3bb651604b8cbc457834cf1c4",
    "semantic_title": "complementary sparsity: accelerating sparse cnns with high accuracy on general-purpose computing platforms",
    "citation_count": 0,
    "authors": [
      "Kang Zhao",
      "Yijun Tan",
      "Kai Han",
      "Ting Hu",
      "Hanting Chen",
      "Tao Yuan",
      "Yunhe Wang",
      "Jun Yao"
    ]
  },
  "https://openreview.net/forum?id=JYs1R9IMJr": {
    "title": "Finding Neurons in a Haystack: Case Studies with Sparse Probing",
    "volume": "main",
    "abstract": "Despite rapid adoption and deployment of large language models (LLMs), the internal computations of these models remain opaque and poorly understood. In this work, we seek to understand how high-level human-interpretable features are represented within the internal neuron activations of LLMs. We train $k$-sparse linear classifiers (probes) on these internal activations to predict the presence of features in the input; by varying the value of $k$ we study the sparsity of learned representations and how this varies with model scale. With $k=1$, we localize individual neurons that are highly relevant for a particular feature and perform a number of case studies to illustrate general properties of LLMs. In particular, we show that early layers make use of sparse combinations of neurons to represent many features in superposition, that middle layers have seemingly dedicated neurons to represent higher-level contextual features, and that increasing scale causes representational sparsity to increase on average, but there are multiple types of scaling dynamics. In all, we probe for over 100 unique features comprising 10 different categories in 7 different models spanning 70 million to 6.9 billion parameters",
    "checked": true,
    "id": "12910786da7a34c9ee26798fd81b0ed7b0e38789",
    "semantic_title": "finding neurons in a haystack: case studies with sparse probing",
    "citation_count": 230,
    "authors": [
      "Wes Gurnee",
      "Neel Nanda",
      "Matthew Pauly",
      "Katherine Harvey",
      "Dmitrii Troitskii",
      "Dimitris Bertsimas"
    ]
  },
  "https://openreview.net/forum?id=m8U9rSs6gU": {
    "title": "Inducing Meaningful Units from Character Sequences with Dynamic Capacity Slot Attention",
    "volume": "main",
    "abstract": "Characters do not convey meaning, but sequences of characters do. We propose an unsupervised distributional method to learn the abstract meaning-bearing units in a sequence of characters. Rather than segmenting the sequence, our Dynamic Capacity Slot Attention model discovers continuous representations of the objects in the sequence, extending an architecture for object discovery in images. We train our model on different languages and evaluate the quality of the obtained representations with forward and reverse probing classifiers. These experiments show that our model succeeds in discovering units which are similar to those proposed previously in form, content, and level of abstraction, and which show promise for capturing meaningful information at a higher level of abstraction",
    "checked": true,
    "id": "2dce73e4a3e19d71249fc7a53c2a9531daaff839",
    "semantic_title": "inducing meaningful units from character sequences with dynamic capacity slot attention",
    "citation_count": 1,
    "authors": [
      "Melika Behjati",
      "James Henderson"
    ]
  },
  "https://openreview.net/forum?id=YfZ4ZPt8zd": {
    "title": "Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks",
    "volume": "main",
    "abstract": "Recently, there has been significant progress in teaching language models to perform step-by-step reasoning to solve complex numerical reasoning tasks. Chain-of-thoughts prompting (CoT) is the state-of-art method for many of these tasks. CoT uses language models to produce text describing reasoning, and computation, and finally the answer to a question. Here we propose `Program of Thoughts' (PoT), which uses language models (mainly Codex) to generate text and programming language statements, and finally an answer. In PoT, the computation can be delegated to a program interpreter, which is used to execute the generated program, thus decoupling complex computation from reasoning and language understanding. We evaluate PoT on five math word problem datasets and three financial-QA datasets in both few-shot and zero-shot settings. We find that PoT has an average performance gain over CoT of around 12% across all datasets. By combining PoT with self-consistency decoding, we can achieve extremely strong performance on all the math datasets and financial datasets. All of our data and code will be released",
    "checked": true,
    "id": "6c943670dca38bfc7c8b477ae7c2d1fba1ad3691",
    "semantic_title": "program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks",
    "citation_count": 865,
    "authors": [
      "Wenhu Chen",
      "Xueguang Ma",
      "Xinyi Wang",
      "William W. Cohen"
    ]
  },
  "https://openreview.net/forum?id=GEcneTl9Mk": {
    "title": "DP-LFlow: Differentially Private Latent Flow for Scalable Sensitive Image Generation",
    "volume": "main",
    "abstract": "Privacy concerns grow with the success of modern deep learning models, especially when the training set contains sensitive data. Differentially private generative model (DPGM) can serve as a solution to circumvent such concerns by generating data that are distributionally similar to the original data yet with differential privacy (DP) guarantees. While GAN has attracted major attention, existing DPGMs based on flow generative models are limited and only developed on low-dimensional tabular datasets. The capability of exact density estimation makes the flow model exceptional when density estimation is of interest. In this work, we will first show that it is challenging (or even infeasible) to train a DP-flow via DP-SGD, i.e. the workhorse algorithm for private deep learning, on high-dimensional image sets with acceptable utility, and then we give an effective solution by reducing the generation from the pixel space to a lower dimensional latent space. We show the effectiveness and scalability of the proposed method via extensive experiments, where the proposed method achieves a significantly better privacy-utility trade-off compared to existing alternatives. Notably, our method is the first DPGM to scale to high-resolution image sets (up to 256 × 256). Our code is available at https://github.com/dihjiang/DP-LFlow",
    "checked": true,
    "id": "ff14a9be477cae258579fc11d0255b99fef81f70",
    "semantic_title": "dp-lflow: differentially private latent flow for scalable sensitive image generation",
    "citation_count": 1,
    "authors": [
      "Dihong Jiang",
      "Sun Sun"
    ]
  },
  "https://openreview.net/forum?id=uKCGOw9bGG": {
    "title": "Binary Classification under Local Label Differential Privacy Using Randomized Response Mechanisms",
    "volume": "main",
    "abstract": "Label differential privacy is a popular branch of $\\epsilon$-differential privacy for protecting labels in training datasets with non-private features. In this paper, we study the generalization performance of a binary classifier trained on a dataset privatized under the label differential privacy achieved by the randomized response mechanism. Particularly, we establish minimax lower bounds for the excess risks of the deep neural network plug-in classifier, theoretically quantifying how privacy guarantee $\\epsilon$ affects its generalization performance. Our theoretical result shows: (1) the randomized response mechanism slows down the convergence of excess risk by lessening the multiplicative constant term compared with the non-private case $(\\epsilon=\\infty)$; (2) as $\\epsilon$ decreases, the optimal structure of the neural network should be smaller for better generalization performance; (3) the convergence of its excess risk is guaranteed even if $\\epsilon$ is adaptive to the size of training sample $n$ at a rate slower than $O(n^{-1/2})$. Our theoretical results are validated by extensive simulated examples and two real applications",
    "checked": true,
    "id": "7d7e82810d60101189b1fbc2c0b2804b07bb667b",
    "semantic_title": "binary classification under local label differential privacy using randomized response mechanisms",
    "citation_count": 7,
    "authors": [
      "Shirong Xu",
      "Chendi Wang",
      "Will Wei Sun",
      "Guang Cheng"
    ]
  },
  "https://openreview.net/forum?id=Q4aAITDgdP": {
    "title": "Learn the Time to Learn: Replay Scheduling in Continual Learning",
    "volume": "main",
    "abstract": "Replay methods are known to be successful at mitigating catastrophic forgetting in continual learning scenarios despite having limited access to historical data. However, storing historical data is cheap in many real-world settings, yet replaying all historical data is often prohibited due to processing time constraints. In such settings, we propose that continual learning systems should learn the time to learn and schedule which tasks to replay at different time steps. We first demonstrate the benefits of our proposal by using Monte Carlo tree search to find a proper replay schedule, and show that the found replay schedules can outperform fixed scheduling policies when combined with various replay methods in different continual learning settings. Additionally, we propose a framework for learning replay scheduling policies with reinforcement learning. We show that the learned policies can generalize better in new continual learning scenarios compared to equally replaying all seen tasks, without added computational cost. Our study reveals the importance of learning the time to learn in continual learning, which brings current research closer to real-world needs",
    "checked": true,
    "id": "a1953404403f99a3d9c4ee33efecd2eb8f47a0c6",
    "semantic_title": "learn the time to learn: replay scheduling in continual learning",
    "citation_count": 9,
    "authors": [
      "Marcus Klasson",
      "Hedvig Kjellstrom",
      "Cheng Zhang"
    ]
  },
  "https://openreview.net/forum?id=vkiKzK5G3e": {
    "title": "Neighborhood Gradient Mean: An Efficient Decentralized Learning Method for Non-IID Data",
    "volume": "main",
    "abstract": "Decentralized learning algorithms enable the training of deep learning models over large distributed datasets, without the need for a central server. The current state-of-the-art decentralized algorithms mostly assume the data distributions to be Independent and Identically Distributed (IID). In practical scenarios, the distributed datasets can have significantly different data distributions across the agents. This paper focuses on improving decentralized learning on non-IID data with minimal compute and memory overheads. We propose Neighborhood Gradient Mean (NGM), a novel decentralized learning algorithm that modifies the local gradients of each agent using self- and cross-gradient information. In particular, the proposed method averages the local gradients with model-variant or data-variant cross-gradients based on the communication budget. Model-variant cross-gradients are derivatives of the received neighbors' model parameters with respect to the local dataset. Data-variant cross-gradient derivatives of the local model with respect to its neighbors' datasets. The data-variant cross-gradients are aggregated through an additional communication round. We theoretically analyze the convergence characteristics of NGM and demonstrate its efficiency on non-IID data sampled from various vision and language datasets. Our experiments demonstrate that the proposed method either remains competitive or outperforms (by 0-6%) the existing state-of-the-art (SoTA) decentralized learning algorithm on non-IID data with significantly less compute and memory requirements. Further, we show that the model-variant cross-gradient information available locally at each agent can improve the performance on non-IID data by 3-20% without additional communication costs",
    "checked": true,
    "id": "3b8e534931f42ad8d98fc31e00574ccf0be879e1",
    "semantic_title": "neighborhood gradient mean: an efficient decentralized learning method for non-iid data",
    "citation_count": 7,
    "authors": [
      "Sai Aparna Aketi",
      "Sangamesh Kodge",
      "Kaushik Roy"
    ]
  },
  "https://openreview.net/forum?id=140kSqm0uy": {
    "title": "Limitation of Characterizing Implicit Regularization by Data-independent Functions",
    "volume": "main",
    "abstract": "In recent years, understanding the implicit regularization of neural networks (NNs) has become a central task in deep learning theory. However, implicit regularization is itself not completely defined and well understood. In this work, we attempt to mathematically define and study implicit regularization. Importantly, we explore the limitations of a common approach to characterizing implicit regularization using data-independent functions. We propose two dynamical mechanisms, i.e., Two-point and One-point Overlapping mechanisms, based on which we provide two recipes for producing classes of one-hidden-neuron NNs that provably cannot be fully characterized by a type of or all data-independent functions. Following the previous works, our results further emphasize the profound data dependency of implicit regularization in general, inspiring us to study in detail the data dependency of NN implicit regularization in the future",
    "checked": true,
    "id": "e27217173cf86a6786ad5aaf3e48f3eeeee0fe77",
    "semantic_title": "limitation of characterizing implicit regularization by data-independent functions",
    "citation_count": 0,
    "authors": [
      "Leyang Zhang",
      "Zhi-Qin John Xu",
      "Tao Luo",
      "Yaoyu Zhang"
    ]
  },
  "https://openreview.net/forum?id=gQnJ7ODIAx": {
    "title": "Population-based Evaluation in Repeated Rock-Paper-Scissors as a Benchmark for Multiagent Reinforcement Learning",
    "volume": "main",
    "abstract": "Progress in fields of machine learning and adversarial planning has benefited significantly from benchmark domains, from checkers and the classic UCI data sets to Go and Diplomacy. In sequential decision-making, agent evaluation has largely been restricted to few interactions against experts, with the aim to reach some desired level of performance (e.g. beating a human professional player). We propose a benchmark for multiagent learning based on repeated play of the simple game Rock, Paper, Scissors along with a population of forty-three tournament entries, some of which are intentionally sub-optimal. We describe metrics to measure the quality of agents based both on average returns and exploitability. We then show that several RL, online learning, and language model approaches can learn good counter-strategies and generalize well, but ultimately lose to the top-performing bots, creating an opportunity for research in multiagent learning",
    "checked": true,
    "id": "524cdc83813740f4f7f4149896c2feabdf85ff18",
    "semantic_title": "population-based evaluation in repeated rock-paper-scissors as a benchmark for multiagent reinforcement learning",
    "citation_count": 4,
    "authors": [
      "Marc Lanctot",
      "John Schultz",
      "Neil Burch",
      "Max Olan Smith",
      "Daniel Hennes",
      "Thomas Anthony",
      "Julien Perolat"
    ]
  },
  "https://openreview.net/forum?id=aqqfB3p9ZA": {
    "title": "Convergence of SGD for Training Neural Networks with Sliced Wasserstein Losses",
    "volume": "main",
    "abstract": "Optimal Transport has sparked vivid interest in recent years, in particular thanks to the Wasserstein distance, which provides a geometrically sensible and intuitive way of comparing probability measures. For computational reasons, the Sliced Wasserstein (SW) distance was introduced as an alternative to the Wasserstein distance, and has seen uses for training generative Neural Networks (NNs). While convergence of Stochastic Gradient Descent (SGD) has been observed practically in such a setting, there is to our knowledge no theoretical guarantee for this observation. Leveraging recent works on convergence of SGD on non-smooth and non-convex functions by Bianchi et al. (2022), we aim to bridge that knowledge gap, and provide a realistic context under which fixed-step SGD trajectories for the SW loss on NN parameters converge. More precisely, we show that the trajectories approach the set of (sub)-gradient flow equations as the step decreases. Under stricter assumptions, we show a much stronger convergence result for noised and projected SGD schemes, namely that the long-run limits of the trajectories approach a set of generalised critical points of the loss function",
    "checked": true,
    "id": "13908d2c6f60e07a3e5eb7c85e23508ae46e81d1",
    "semantic_title": "convergence of sgd for training neural networks with sliced wasserstein losses",
    "citation_count": 6,
    "authors": [
      "Eloi Tanguy"
    ]
  },
  "https://openreview.net/forum?id=ySWQ6eXAKp": {
    "title": "Not All Causal Inference is the Same",
    "volume": "main",
    "abstract": "Neurally-parameterized Structural Causal Models in the Pearlian notion to causality, referred to as NCM, were recently introduced as a step towards next-generation learning systems. However, said NCM are only concerned with the learning aspect of causal inference and totally miss out on the architecture aspect. That is, actual causal inference within NCM is intractable in that the NCM won't return an answer to a query in polynomial time. This insight follows as corollary to the more general statement on the intractability of arbitrary structural causal model (SCM) parameterizations, which we prove in this work through classical 3-SAT reduction. Since future learning algorithms will be required to deal with both high dimensional data and highly complex mechanisms governing the data, we ultimately believe work on tractable inference for causality to be decisive. We also show that not all \"causal\" models are created equal. More specifically, there are models capable of answering causal queries that are not SCM, which we refer to as partially causal models (PCM). We provide a tabular taxonomy in terms of tractability properties for all of the different model families, namely correlation-based, PCM and SCM. To conclude our work, we also provide some initial ideas on how to overcome parts of the intractability of causal inference with SCM by showing an example of how parameterizing an SCM with SPN modules can at least allow for tractable mechanisms. With this work we hope that our insights can raise awareness for this novel research direction since achieving success with causality in real world downstream tasks will not only depend on learning correct models but also require having the practical ability to gain access to model inferences",
    "checked": true,
    "id": "33baffb40db3c605823944e7074552cff196b8d9",
    "semantic_title": "not all causal inference is the same",
    "citation_count": 1,
    "authors": [
      "Matej Zečević",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ]
  },
  "https://openreview.net/forum?id=tEKqQgbwbf": {
    "title": "Homomorphic Self-Supervised Learning",
    "volume": "main",
    "abstract": "Many state of the art self-supervised learning approaches fundamentally rely on transformations applied to the input in order to selectively extract task-relevant information. Recently, the field of equivariant deep learning has developed to introduce structure into the feature space of deep neural networks by designing them as homomorphisms with respect to input transformations. In this work, we observe that many existing self-supervised learning algorithms can be both unified and generalized when seen through the lens of equivariant representations. Specifically, we introduce a general framework we call Homomorphic Self-Supervised Learning, and theoretically show how it may subsume the use of input-augmentations provided an augmentation-homomorphic feature extractor. We validate this theory experimentally for simple augmentations, demonstrate the necessity of representational structure for feature-space SSL, and further empirically explore how the parameters of this framework relate to those of traditional augmentation-based self-supervised learning. We conclude with a discussion of the potential benefits afforded by this new perspective on self-supervised learning",
    "checked": true,
    "id": "64b8bf4c805699b084476b5dd7ffa8095be04e6e",
    "semantic_title": "homomorphic self-supervised learning",
    "citation_count": 2,
    "authors": [
      "T. Anderson Keller",
      "Xavier Suau",
      "Luca Zappella"
    ]
  },
  "https://openreview.net/forum?id=cXa6Xdm0v7": {
    "title": "Multimodal Language Learning for Object Retrieval in Low Data Regimes in the Face of Missing Modalities",
    "volume": "main",
    "abstract": "Our study is motivated by robotics, where when dealing with robots or other physical systems, we often need to balance competing concerns of relying on complex, multimodal data coming from a variety of sensors with a general lack of large representative datasets. Despite the complexity of modern robotic platforms and the need for multimodal interaction, there has been little research on integrating more than two modalities in a low data regime with the real-world constraint that sensors fail due to obstructions or adverse conditions. In this work, we consider a case in which natural language is used as a retrieval query against objects, represented across multiple modalities, in a physical environment. We introduce extended multimodal alignment (EMMA), a method that learns to select the appropriate object while jointly refining modality-specific embeddings through a geometric (distance-based) loss. In contrast to prior work, our approach is able to incorporate an arbitrary number of views (modalities) of a particular piece of data. We demonstrate the efficacy of our model on a grounded language object retrieval scenario. We show that our model outperforms state-of-the-art baselines when little training data is available. Our code is available at https://github.com/kasraprime/EMMA",
    "checked": true,
    "id": "1e3d96a9568b7c75f0e79c5069e499bdd3ebbabd",
    "semantic_title": "multimodal language learning for object retrieval in low data regimes in the face of missing modalities",
    "citation_count": 1,
    "authors": [
      "Kasra Darvish",
      "Edward Raff",
      "Francis Ferraro",
      "Cynthia Matuszek"
    ]
  },
  "https://openreview.net/forum?id=czev0exHXT": {
    "title": "Worst-case Feature Risk Minimization for Data-Efficient Learning",
    "volume": "main",
    "abstract": "Deep learning models typically require massive amounts of annotated data to train a strong model for a task of interest. However, data annotation is time-consuming and costly. How to use labeled data from a related but distinct domain, or just a few samples to train a satisfactory model are thus important questions. To achieve this goal, models should resist overfitting to the specifics of the training data in order to generalize well to new data. This paper proposes a novel Worst-case Feature Risk Minimization (WFRM) method that helps improve model generalization. Specifically, we tackle a minimax optimization problem in feature space at each training iteration. Given the input features, we seek the feature perturbation that maximizes the current training loss and then minimizes the training loss of the worst-case features. By incorporating our WFRM during training, we significantly improve model generalization under distributional shift – Domain Generalization (DG) and in the low-data regime – Few-shot Learning (FSL). We theoretically analyze WFRM and find the key reason why it works better than ERM – it induces an empirical risk-based semi-adaptive $L_{2}$ regularization of the classifier weights, enabling a better risk-complexity trade-off. We evaluate WFRM on two data-efficient learning tasks, including three standard DG benchmarks of PACS, VLCS, OfficeHome and the most challenging FSL benchmark Meta-Dataset. Despite the simplicity, our method consistently improves various DG and FSL methods, leading to the new state-of-the-art performances in all settings. Codes & models will be released at https://github.com/jslei/WFRM",
    "checked": true,
    "id": "638f2aaa05512b1cea4cb923b07cacfb2c336a9c",
    "semantic_title": "worst-case feature risk minimization for data-efficient learning",
    "citation_count": 0,
    "authors": [
      "Jingshi Lei",
      "Da Li",
      "Chengming Xu",
      "Liming Fang",
      "Timothy Hospedales",
      "Yanwei Fu"
    ]
  },
  "https://openreview.net/forum?id=CAd6V2qXxc": {
    "title": "Conformal prediction under ambiguous ground truth",
    "volume": "main",
    "abstract": "Conformal Prediction (CP) allows to perform rigorous uncertainty quantification by constructing a prediction set $C(X)$ satisfying $\\mathbb{P}(Y \\in C(X))\\geq 1-\\alpha$ for a user-chosen $\\alpha \\in [0,1]$ by relying on calibration data $(X_1,Y_1),...,(X_n,Y_n)$ from $\\mathbb{P}=\\mathbb{P}^{X} \\otimes \\mathbb{P}^{Y|X}$. It is typically implicitly assumed that $\\mathbb{P}^{Y|X}$ is the ``true'' posterior label distribution. However, in many real-world scenarios, the labels $Y_1,...,Y_n$ are obtained by aggregating expert opinions using a voting procedure, resulting in a one-hot distribution $\\mathbb{P}_{\\textup{vote}}^{Y|X}$. This is the case for most datasets, even well-known ones like ImageNet. For such ``voted'' labels, CP guarantees are thus w.r.t. $\\mathbb{P}_{\\textup{vote}}=\\mathbb{P}^X \\otimes \\mathbb{P}_{\\textup{vote}}^{Y|X}$ rather than the true distribution $\\mathbb{P}$. In cases with unambiguous ground truth labels, the distinction between $\\mathbb{P}_{\\textup{vote}}$ and $\\mathbb{P}$ is irrelevant. However, when experts do not agree because of ambiguous labels, approximating $\\mathbb{P}^{Y|X}$ with a one-hot distribution $\\mathbb{P}_{\\textup{vote}}^{Y|X}$ ignores this uncertainty. In this paper, we propose to leverage expert opinions to approximate $\\mathbb{P}^{Y|X}$ using a non-degenerate distribution $\\mathbb{P}_{\\textup{agg}}^{Y|X}$. We then develop \\emph{Monte Carlo CP} procedures which provide guarantees w.r.t. $\\mathbb{P}_{\\textup{agg}}=\\mathbb{P}^X \\otimes \\mathbb{P}_{\\textup{agg}}^{Y|X}$ by sampling multiple synthetic pseudo-labels from $\\mathbb{P}_{\\textup{agg}}^{Y|X}$ for each calibration example $X_1,...,X_n$. In a case study of skin condition classification with significant disagreement among expert annotators, we show that applying CP w.r.t. $\\mathbb{P}_{\\textup{vote}}$ under-covers expert annotations: calibrated for $72\\%$ coverage, it falls short by on average $10\\%$; our Monte Carlo CP closes this gap both empirically and theoretically. We also extend Monte Carlo CP to multi-label classification and CP with calibration examples enriched through data augmentation",
    "checked": true,
    "id": "7a65e919fa4b2e0d03273935a4ff413a993764f4",
    "semantic_title": "conformal prediction under ambiguous ground truth",
    "citation_count": 20,
    "authors": [
      "David Stutz",
      "Abhijit Guha Roy",
      "Tatiana Matejovicova",
      "Patricia Strachan",
      "Ali Taylan Cemgil",
      "Arnaud Doucet"
    ]
  },
  "https://openreview.net/forum?id=RFfUUtKYOG": {
    "title": "Towards Stability of Autoregressive Neural Operators",
    "volume": "main",
    "abstract": "Neural operators have proven to be a promising approach for modeling spatiotemporal systems in the physical sciences. However, training these models for large systems can be quite challenging as they incur significant computational and memory expense---these systems are often forced to rely on autoregressive time-stepping of the neural network to predict future temporal states. While this is effective in managing costs, it can lead to uncontrolled error growth over time and eventual instability. We analyze the sources of this autoregressive error growth using prototypical neural operator models for physical systems and explore ways to mitigate it. We introduce architectural and application-specific improvements that allow for careful control of instability-inducing operations within these models without inflating the compute/memory expense. We present results on several scientific systems that include Navier-Stokes fluid flow, rotating shallow water, and a high-resolution global weather forecasting system. We demonstrate that applying our design principles to neural operators leads to significantly lower errors for long-term forecasts as well as longer time horizons without qualitative signs of divergence compared to the original models for these systems. We open-source our code for reproducibility",
    "checked": true,
    "id": "b03dfd3500ed198ff5c42ecec3fcd07247baaae5",
    "semantic_title": "towards stability of autoregressive neural operators",
    "citation_count": 25,
    "authors": [
      "Michael McCabe",
      "Peter Harrington",
      "Shashank Subramanian",
      "Jed Brown"
    ]
  },
  "https://openreview.net/forum?id=ZD03VUZmRx": {
    "title": "$f$-MICL: Understanding and Generalizing InfoNCE-based Contrastive Learning",
    "volume": "main",
    "abstract": "In self-supervised contrastive learning, a widely-adopted objective function is InfoNCE, which uses the heuristic cosine similarity for the representation comparison, and is closely related to maximizing the Kullback-Leibler (KL)-based mutual information. In this paper, we aim at answering two intriguing questions: (1) Can we go beyond the KL-based objective? (2) Besides the popular cosine similarity, can we design a better similarity function? We provide answers to both questions by generalizing the KL-based mutual information to the $f$-Mutual Information in Contrastive Learning ($f$-MICL) using the $f$-divergences. To answer the first question, we provide a wide range of $f$-MICL objectives which share the nice properties of InfoNCE (e.g., alignment and uniformity), and meanwhile result in similar or even superior performance. For the second question, assuming that the joint feature distribution is proportional to the Gaussian kernel, we derive an $f$-Gaussian similarity with better interpretability and empirical performance. Finally, we identify close relationships between the $f$-MICL objective and several popular InfoNCE-based objectives. Using benchmark tasks from both vision and natural language, we empirically evaluate $f$-MICL with different $f$-divergences on various architectures (SimCLR, MoCo, and MoCo v3) and datasets. We observe that $f$-MICL generally outperforms the benchmarks and the best-performing $f$-divergence is task and dataset dependent",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwei Lu",
      "Guojun Zhang",
      "Sun Sun",
      "Hongyu Guo",
      "Yaoliang Yu"
    ]
  },
  "https://openreview.net/forum?id=fWIQ9Oaao0": {
    "title": "Non-Stationary Contextual Pricing with Safety Constraints",
    "volume": "main",
    "abstract": "In a contextual pricing problem, a seller aims at maximizing the revenue over a sequence of sales sessions (described by feature vectors) using binary-censored feedback of \"sold\" or \"not sold\". Existing methods often overlook two practical challenges (1) the best pricing strategy could change over time; (2) the prices and pricing policies must conform to hard constraints due to safety, ethical or legal restrictions. We address both challenges by solving a more general problem of \"universal dynamic regret\" minimization in proper online learning with exp-concave losses --- an open problem posed by Baby & Wang (2021) that we partially resolve in this paper, with attention restricted to loss functions coming from a generalized linear model. Here \"dynamic regret\" measures the performance relative to a non-stationary sequence of policies, and \"proper\" means that the learner must choose feasible strategies within a pre-defined convex set, which we use to model the safety constraints. In this work, we consider a linear noisy valuation model for the customers. In the case of a known strictly log-concave market noise, our algorithm achieves $\\tilde{O}(d^3T^{1/3}C_T^{2/3} \\vee d^3)$ dynamic regret in comparison with the optimal policy series, where $T$, $d$ and $C_T$ stand for the time horizon, the feature dimension and the total variation (characterizing non-stationarity) respectively. This regret is near-optimal with respect to $T$ (within $O(\\log T)$ gaps) and $C_T$, and our algorithm is adaptable to unknown $C_T$ and remains feasible throughout. However, the dependence on $d$ is suboptimal and the minimax rate is still open",
    "checked": true,
    "id": "cc5f481d38da0300b2780e35b9e895651e32894c",
    "semantic_title": "non-stationary contextual pricing with safety constraints",
    "citation_count": 4,
    "authors": [
      "Dheeraj Baby",
      "Jianyu Xu",
      "Yu-Xiang Wang"
    ]
  },
  "https://openreview.net/forum?id=Kt2VJrCKo4": {
    "title": "VoLTA: Vision-Language Transformer with Weakly-Supervised Local-Feature Alignment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0ee11b28a9ce49d3030cab11f1178fa5abae9c3b",
    "semantic_title": "volta: vision-language transformer with weakly-supervised local-feature alignment",
    "citation_count": 24,
    "authors": [
      "Shraman Pramanick",
      "Li Jing",
      "Sayan Nag",
      "Jiachen Zhu",
      "Hardik J Shah",
      "Yann LeCun",
      "Rama Chellappa"
    ]
  },
  "https://openreview.net/forum?id=YgeXqrH7gA": {
    "title": "Benefits of Max Pooling in Neural Networks: Theoretical and Experimental Evidence",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4f13e06f319373cb96e10857e1a940db92670e42",
    "semantic_title": "benefits of max pooling in neural networks: theoretical and experimental evidence",
    "citation_count": 0,
    "authors": [
      "Kyle Matoba",
      "Nikolaos Dimitriadis",
      "François Fleuret"
    ]
  },
  "https://openreview.net/forum?id=adpKzWQunW": {
    "title": "Local Advantage Networks for Multi-Agent Reinforcement Learning in Dec-POMDPs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "017cc5edbe203b9cb8b6876124b80ac4e4edcd66",
    "semantic_title": "local advantage networks for multi-agent reinforcement learning in dec-pomdps",
    "citation_count": 6,
    "authors": [
      "Raphaël Avalos",
      "Mathieu Reymond",
      "Ann Nowe",
      "Diederik M Roijers"
    ]
  },
  "https://openreview.net/forum?id=Tkvmt9nDmB": {
    "title": "Beyond Distribution Shift: Spurious Features Through the Lens of Training Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8c3ed2f05511ececa8cbe28bdd5dd5071ab934b5",
    "semantic_title": "beyond distribution shift: spurious features through the lens of training dynamics",
    "citation_count": 10,
    "authors": [
      "Nihal Murali",
      "Aahlad Manas Puli",
      "Ke Yu",
      "Rajesh Ranganath",
      "kayhan Batmanghelich"
    ]
  },
  "https://openreview.net/forum?id=3AzqYa18ah": {
    "title": "Pareto Actor-Critic for Equilibrium Selection in Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "This work focuses on equilibrium selection in no-conflict multi-agent games, where we specifically study the problem of selecting a Pareto-optimal Nash equilibrium among several existing equilibria. It has been shown that many state-of-the-art multi-agent reinforcement learning (MARL) algorithms are prone to converging to Pareto-dominated equilibria due to the uncertainty each agent has about the policy of the other agents during training. To address sub-optimal equilibrium selection, we propose Pareto Actor-Critic (Pareto-AC), which is an actor-critic algorithm that utilises a simple property of no-conflict games (a superset of cooperative games): the Pareto-optimal equilibrium in a no-conflict game maximises the returns of all agents and, therefore, is the preferred outcome for all agents. We evaluate Pareto-AC in a diverse set of multi-agent games and show that it converges to higher episodic returns compared to seven state-of-the-art MARL algorithms and that it successfully converges to a Pareto-optimal equilibrium in a range of matrix games. Finally, we propose PACDCG, a graph neural network extension of Pareto-AC, which is shown to efficiently scale in games with a large number of agents",
    "checked": true,
    "id": "975d272c3122891f8fcf69847d1ddc21ff134528",
    "semantic_title": "pareto actor-critic for equilibrium selection in multi-agent reinforcement learning",
    "citation_count": 5,
    "authors": [
      "Filippos Christianos",
      "Georgios Papoudakis",
      "Stefano V Albrecht"
    ]
  },
  "https://openreview.net/forum?id=lanGfX0M6C": {
    "title": "Bridging Imitation and Online Reinforcement Learning: An Optimistic Tale",
    "volume": "main",
    "abstract": "In this paper, we address the following problem: Given an offline demonstration dataset from an imperfect expert, what is the best way to leverage it to bootstrap online learning performance in MDPs. We first propose an Informed Posterior Sampling-based RL (iPSRL) algorithm that uses the offline dataset, and information about the expert's behavioral policy used to generate the offline dataset. Its cumulative Bayesian regret goes down to zero exponentially fast in $N$, the offline dataset size if the expert is competent enough. Since this algorithm is computationally impractical, we then propose the iRLSVI algorithm that can be seen as a combination of the RLSVI algorithm for online RL, and imitation learning. Our empirical results show that the proposed iRLSVI algorithm is able to achieve significant reduction in regret as compared to two baselines: no offline data, and offline dataset but used without suitably modeling the generative policy. Our algorithm can be seen as bridging online RL and imitation learning",
    "checked": true,
    "id": "5aeef5fc2533f8deeefb73688040279acad67e96",
    "semantic_title": "bridging imitation and online reinforcement learning: an optimistic tale",
    "citation_count": 4,
    "authors": [
      "Botao Hao",
      "Rahul Jain",
      "Dengwang Tang",
      "Zheng Wen"
    ]
  },
  "https://openreview.net/forum?id=REAyrhRYAo": {
    "title": "Gradient Masked Averaging for Federated Learning",
    "volume": "main",
    "abstract": "Federated learning (FL) is an emerging paradigm that permits a large number of clients with heterogeneous data to coordinate learning of a unified global model without the need to share data amongst each other. A major challenge in federated learning is the heterogeneity of data across client, which can degrade the performance of standard FL algorithms. Standard FL algorithms involve averaging of model parameters or gradient updates to approximate the global model at the server. However, we argue that in heterogeneous settings, averaging can result in information loss and lead to poor generalization due to the bias induced by dominant client gradients. We hypothesize that to generalize better across non-i.i.d datasets, the algorithms should focus on learning the invariant mechanism that is constant while ignoring spurious mechanisms that differ across clients. Inspired from recent works in Out-of-Distribution generalization, we propose a gradient masked averaging approach for FL as an alternative to the standard averaging of client updates. This aggregation technique for client updates can be adapted as a drop-in replacement in most existing federated algorithms. We perform extensive experiments on multiple FL algorithms with in-distribution, real-world, feature-skewed out-of-distribution, and quantity imbalanced datasets and show that it provides consistent improvements, particularly in the case of heterogeneous clients",
    "checked": true,
    "id": "3e583ea1e45c7772904131850add04d4ac8b8c91",
    "semantic_title": "gradient masked averaging for federated learning",
    "citation_count": 26,
    "authors": [
      "Irene Tenison",
      "Sai Aravind Sreeramadas",
      "Vaikkunth Mugunthan",
      "Edouard Oyallon",
      "Irina Rish",
      "Eugene Belilovsky"
    ]
  },
  "https://openreview.net/forum?id=xLnbSpozWS": {
    "title": "Training Vision-Language Transformers from Captions",
    "volume": "main",
    "abstract": "Vision-Language Transformers can be learned without low-level human labels (e.g. class labels, bounding boxes, etc). Existing work, whether explicitly utilizing bounding boxes (Chen et al., 2020b; Tan & Bansal, 2019; Lu et al., 2019) or patches (Kim et al., 2021), assumes that the visual backbone must first be trained on ImageNet (Russakovsky et al., 2015) class prediction before being integrated into a multimodal linguistic pipeline. We show that this is not necessary and introduce a new model Vision-Language from Captions (VLC) built on top of Masked Auto-Encoders (He et al., 2022) that does not require this supervision. We seek to provide general advice on multimodal pretraining by examining the roles of (a) unimodal initialization, (b) unimodal architectural components and (c) data annotation in the pretraining corpus. Our extensive and carefully controlled studies suggest that none of the above factors is absolutely important in achieving versatile vision-language representations. We conclude our analysis with suggestions on the choices of initialization, architectural components, and annotation formats targeting a better balance between data efficiency and representation quality",
    "checked": false,
    "id": "6ac02dee3372535d9f3fbb3f67b8ef881b50e2aa",
    "semantic_title": "training vision-language transformers from captions alone",
    "citation_count": 11,
    "authors": [
      "Liangke Gui",
      "Yingshan Chang",
      "Qiuyuan Huang",
      "Subhojit Som",
      "Alexander G Hauptmann",
      "Jianfeng Gao",
      "Yonatan Bisk"
    ]
  },
  "https://openreview.net/forum?id=3Ba6Hd3nZt": {
    "title": "Policy Gradient Algorithms Implicitly Optimize by Continuation",
    "volume": "main",
    "abstract": "Direct policy optimization in reinforcement learning is usually solved with policy-gradient algorithms, which optimize policy parameters via stochastic gradient ascent. This paper provides a new theoretical interpretation and justification of these algorithms. First, we formulate direct policy optimization in the optimization by continuation framework. The latter is a framework for optimizing nonconvex functions where a sequence of surrogate objective functions, called continuations, are locally optimized. Second, we show that optimizing affine Gaussian policies and performing entropy regularization can be interpreted as implicitly optimizing deterministic policies by continuation. Based on these theoretical results, we argue that exploration in policy-gradient algorithms consists in computing a continuation of the return of the policy at hand, and that the variance of policies should be history-dependent functions adapted to avoid local extrema rather than to maximize the return of the policy",
    "checked": true,
    "id": "b0affaa6b830ee25b93169202df23cf9fce621a0",
    "semantic_title": "policy gradient algorithms implicitly optimize by continuation",
    "citation_count": 3,
    "authors": [
      "Adrien Bolland",
      "Gilles Louppe",
      "Damien Ernst"
    ]
  },
  "https://openreview.net/forum?id=3dQCNqqv2d": {
    "title": "Self-Attention in Colors: Another Take on Encoding Graph Structure in Transformers",
    "volume": "main",
    "abstract": "We introduce a novel self-attention mechanism, which we call CSA (Chromatic Self-Attention), which extends the notion of attention scores to attention _filters_, independently modulating the feature channels. We showcase CSA in a fully-attentional graph Transformer CGT (Chromatic Graph Transformer) which integrates both graph structural information and edge features, completely bypassing the need for local message-passing components. Our method flexibly encodes graph structure through node-node interactions, by enriching the original edge features with a relative positional encoding scheme. We propose a new scheme based on random walks that encodes both structural and positional information, and show how to incorporate higher-order topological information, such as rings in molecular graphs. Our approach achieves state-of-the-art results on the ZINC benchmark dataset, while providing a flexible framework for encoding graph structure and incorporating higher-order topology",
    "checked": true,
    "id": "458c8a10ec37466a6a554202c472e8faea0834ad",
    "semantic_title": "self-attention in colors: another take on encoding graph structure in transformers",
    "citation_count": 7,
    "authors": [
      "Romain Menegaux",
      "Emmanuel Jehanno",
      "Margot Selosse",
      "Julien Mairal"
    ]
  },
  "https://openreview.net/forum?id=Q2Gi0TUAdS": {
    "title": "Identifying latent distances with Finslerian geometry",
    "volume": "main",
    "abstract": "Riemannian geometry provides us with powerful tools to explore the latent space of generative models while preserving the underlying structure of the data. The latent space can be equipped it with a Riemannian metric, pulled back from the data manifold. With this metric, we can systematically navigate the space relying on geodesics defined as the shortest curves between two points. Generative models are often stochastic, causing the data space, the Riemannian metric, and the geodesics, to be stochastic as well. Stochastic objects are at best impractical, and at worst impossible, to manipulate. A common solution is to approximate the stochastic pullback metric by its expectation. But the geodesics derived from this expected Riemannian metric do not correspond to the expected length-minimising curves. In this work, we propose another metric whose geodesics explicitly minimise the expected length of the pullback metric. We show this metric defines a Finsler metric, and we compare it with the expected Riemannian metric. In high dimensions, we prove that both metrics converge to each other at a rate of $\\mathcal{O}\\left(\\frac{1}{D}\\right)$. This convergence implies that the established expected Riemannian metric is an accurate approximation of the theoretically more grounded Finsler metric. This provides justification for using the expected Riemannian metric for practical implementations",
    "checked": true,
    "id": "0b1e512ac57a9ecd11635980605bae84888f65d9",
    "semantic_title": "identifying latent distances with finslerian geometry",
    "citation_count": 1,
    "authors": [
      "Alison Pouplin",
      "David Eklund",
      "Carl Henrik Ek",
      "Søren Hauberg"
    ]
  },
  "https://openreview.net/forum?id=CpYBAqDgmz": {
    "title": "Discretization Invariant Networks for Learning Maps between Neural Fields",
    "volume": "main",
    "abstract": "With the emergence of powerful representations of continuous data in the form of neural fields, there is a need for discretization invariant learning: an approach for learning maps between functions on continuous domains without being sensitive to how the function is sampled. We present a new framework for understanding and designing discretization invariant neural networks (DI-Nets), which generalizes many discrete networks such as convolutional neural networks as well as continuous networks such as neural operators. Our analysis establishes upper bounds on the deviation in model outputs under different finite discretizations, and highlights the central role of point set discrepancy in characterizing such bounds. This insight leads to the design of a family of neural networks driven by numerical integration via quasi-Monte Carlo sampling with discretizations of low discrepancy. We prove by construction that DI-Nets universally approximate a large class of maps between integrable function spaces, and show that discretization invariance also describes backpropagation through such models. Applied to neural fields, convolutional DI-Nets can learn to classify and segment visual data under various discretizations, and sometimes generalize to new types of discretizations at test time",
    "checked": true,
    "id": "2d77ada902e568071cc476898cc9f13e03e7f722",
    "semantic_title": "discretization invariant networks for learning maps between neural fields",
    "citation_count": 1,
    "authors": [
      "Clinton Wang",
      "Polina Golland"
    ]
  },
  "https://openreview.net/forum?id=QfyVqvpg7u": {
    "title": "Physics informed neural networks for elliptic equations with oscillatory differential operators",
    "volume": "main",
    "abstract": "Physics informed neural network (PINN) based solution methods for differential equations have recently shown success in a variety of scientific computing applications. Several authors have reported difficulties, however, when using PINNs to solve equations with multiscale features. The objective of the present work is to illustrate and explain the difficulty of using standard PINNs for the particular case of divergence-form elliptic partial differential equations (PDEs) with oscillatory coefficients present in the differential operator. We show that if the coefficient in the elliptic operator $a^{\\epsilon}(x)$ is of the form $a(x/\\epsilon)$ for a 1-periodic coercive function $a(\\cdot)$, then the Frobenius norm of the neural tangent kernel (NTK) matrix associated to the loss function grows as $1/\\epsilon^2$. This implies that as the separation of scales in the problem increases, training the neural network with gradient descent based methods to achieve an accurate approximation of the solution to the PDE becomes increasingly difficult. Numerical examples illustrate the stiffness of the optimization problem",
    "checked": true,
    "id": "8fbb03cb338f27f99f768d2f1d170fe8234b4391",
    "semantic_title": "physics informed neural networks for elliptic equations with oscillatory differential operators",
    "citation_count": 1,
    "authors": [
      "Arnav Gangal",
      "Luis Kim",
      "Sean Patrick Carney"
    ]
  },
  "https://openreview.net/forum?id=djD8IbSvgm": {
    "title": "Greedier is Better: Selecting Multiple Neighbors per Iteration for Sparse Subspace Clustering",
    "volume": "main",
    "abstract": "Sparse subspace clustering (SSC) using greedy-based neighbor selection, such as orthogonal matching pursuit (OMP), has been known as a popular computationally-efficient alternative to the standard $\\ell_1$-minimization based methods. However, existing stopping rules of OMP to halt neighbor search needs additional offline work to estimate some ground truths, e.g., subspace dimension and/or noise strength. This paper proposes a new SSC scheme using generalized OMP (GOMP), a soup-up of OMP whereby multiple, say $p(\\geq1)$, neighbors are identified per iteration to further speed up neighbor acquisition, along with a new stopping rule requiring nothing more than a knowledge of the ambient signal dimension and the number $p$ of identified neighbors in each iteration. Compared to conventional OMP (i.e., $p=1$), the proposed GOMP method involves fewer iterations, thereby enjoying lower algorithmic complexity. Under the semi-random model, analytic performance guarantees are provided. It is shown that, with a high probability, (i) GOMP can retrieve more true neighbors than OMP, consequently yielding higher data clustering accuracy, and (ii) the proposed stopping rule terminates neighbor search once the number of recovered neighbors is close to the subspace dimension. Issues about selecting $p$ for practical implementation are also discussed. Computer simulations using both synthetic and real data are provided to demonstrate the effectiveness of the proposed approach and validate our analytic study",
    "checked": true,
    "id": "ae114bf870d7d110892f8bd9d89bd4a62aeb3216",
    "semantic_title": "greedier is better: selecting multiple neighbors per iteration for sparse subspace clustering",
    "citation_count": 0,
    "authors": [
      "Jwo-Yuh Wu",
      "Liang-Chi Huang",
      "Wen Hsuan Li",
      "Chun-Hung Liu",
      "Rung-Hung Gau"
    ]
  },
  "https://openreview.net/forum?id=NekBTCKJ1H": {
    "title": "Distributed Newton-Type Methods with Communication Compression and Bernoulli Aggregation",
    "volume": "main",
    "abstract": "Despite their high computation and communication costs, Newton-type methods remain an appealing option for distributed training due to their robustness against ill-conditioned convex problems. In this work, we study communication compression and aggregation mechanisms for curvature information in order to reduce these costs while preserving theoretically superior local convergence guarantees. We prove that the recently developed class of three point compressors (3PC) of [Richtarik et al., 2022] for gradient communication can be generalized to Hessian communication as well. This result opens up a wide variety of communication strategies, such as contractive compression and lazy aggregation, available to our disposal to compress prohibitively costly curvature information. Moreover, we discovered several new 3PC mechanisms, such as adaptive thresholding and Bernoulli aggregation, which require reduced communication and occasional Hessian computations. Furthermore, we extend and analyze our approach to bidirectional communication compression and partial device participation setups to cater to the practical considerations of applications in federated learning. For all our methods, we derive fast condition-number-independent local linear and/or superlinear convergence rates. Finally, with extensive numerical evaluations on convex optimization problems, we illustrate that our designed schemes achieve state-of-the-art communication complexity compared to several key baselines using second-order information",
    "checked": true,
    "id": "b28d2e268e19e0585a9a39405cf21c08423107b0",
    "semantic_title": "distributed newton-type methods with communication compression and bernoulli aggregation",
    "citation_count": 17,
    "authors": [
      "Rustem Islamov",
      "Xun Qian",
      "Slavomir Hanzely",
      "Mher Safaryan",
      "Peter Richtárik"
    ]
  },
  "https://openreview.net/forum?id=LWotmCKC6Y": {
    "title": "Fourier Features in Reinforcement Learning with Neural Networks",
    "volume": "main",
    "abstract": "In classic Reinforcement Learning (RL), the performance of algorithms depends critically on data representation, i.e., the way the states of the system are represented as features. Choosing appropriate features for a task is an important way of adding prior domain knowledge since cleverly distributing information into states facilitates appropriate generalization. For linear function approximations, the representation is usually hand-designed according to the task at hand and projected into a higher-dimensional space to facilitate linear separation. Among the feature encodings used in RL for linear function approximation, we can mention in a non-exhaustive way Polynomial Features or Tile Coding. However, the main bottleneck of such feature encodings is that they do not scale to high-dimensional inputs as they grow exponentially in size with the input dimension",
    "checked": true,
    "id": "fddebe1b1ed229db667b2406041e7859148e71d3",
    "semantic_title": "fourier features in reinforcement learning with neural networks",
    "citation_count": 5,
    "authors": [
      "David Brellmann",
      "David Filliat",
      "Goran Frehse"
    ]
  },
  "https://openreview.net/forum?id=Ulf3QZG9DC": {
    "title": "Diagnostic Tool for Out-of-Sample Model Evaluation",
    "volume": "main",
    "abstract": "Assessment of model fitness is a key part of machine learning. The standard paradigm of model evaluation is analysis of the average loss over future data. This is often explicit in model fitting, where we select models that minimize the average loss over training data as a surrogate, but comes with limited theoretical guarantees. In this paper, we consider the problem of characterizing a batch of out-of-sample losses of a model using a calibration data set. We provide finite-sample limits on the out-of-sample losses that are statistically valid under quite general conditions and propose a diagonistic tool that is simple to compute and interpret. Several numerical experiments are presented to show how the proposed method quantifies the impact of distribution shifts, aids the analysis of regression, and enables model selection as well as hyperparameter tuning",
    "checked": true,
    "id": "619851652c4bf8ab97da75f4374f05ba55a06ff5",
    "semantic_title": "diagnostic tool for out-of-sample model evaluation",
    "citation_count": 1,
    "authors": [
      "Ludvig Hult",
      "Dave Zachariah",
      "Peter Stoica"
    ]
  },
  "https://openreview.net/forum?id=gxEpUFxIgz": {
    "title": "Straggler-Resilient Personalized Federated Learning",
    "volume": "main",
    "abstract": "Federated Learning is an emerging learning paradigm that allows training models from samples distributed across a large network of clients while respecting privacy and communication restrictions. Despite its success, federated learning faces several challenges related to its decentralized nature. In this work, we develop a novel algorithmic procedure with theoretical speedup guarantees that simultaneously handles two of these hurdles, namely (i) data heterogeneity, i.e., data distributions can vary substantially across clients, and (ii) system heterogeneity, i.e., the computational power of the clients could differ significantly. By leveraging previous works in the realm of representation learning (Collins et al., 2021; Liang et al., 2020), our method constructs a global common representation utilizing the data from all clients. Additionally, it learns a user-specific set of parameters resulting in a personalized solution for each individual client. Furthermore, it mitigates the effects of stragglers by adaptively selecting clients based on their computational characteristics, thus achieving for the first time near optimal sample complexity and provable logarithmic speedup. Experimental results support our theoretical findings showing the superiority of our method over alternative personalized federated schemes in system and data heterogeneous environments",
    "checked": true,
    "id": "e2525b1e37226359274092e95e6988194855d75c",
    "semantic_title": "straggler-resilient personalized federated learning",
    "citation_count": 10,
    "authors": [
      "Isidoros Tziotis",
      "Zebang Shen",
      "Ramtin Pedarsani",
      "Hamed Hassani",
      "Aryan Mokhtari"
    ]
  },
  "https://openreview.net/forum?id=izFnURFG3f": {
    "title": "Self-supervised Learning for Segmentation and Quantification of Dopamine Neurons in Parkinson's Disease",
    "volume": "main",
    "abstract": "Parkinson's Disease (PD) is the second most common neurodegenerative disease in humans. PD is characterized by the gradual loss of dopaminergic neurons in the Substantia Nigra (SN, a part of the mid-brain). Counting the number of dopaminergic neurons in the SN is one of the most important indexes in evaluating drug efficacy in PD animal models. Currently, analyzing and quantifying dopaminergic neurons is conducted manually by experts through analysis of digital pathology images which is laborious, time-consuming, and highly subjective. As such, a reliable and unbiased automated system is demanded for the quantification of dopaminergic neurons in digital pathology images. Recent years have seen a surge in adopting deep learning solutions in medical image processing. However, developing high-performing deep learning models hinges on the availability of large-scale, high-quality annotated data, which can be expensive to acquire, especially in applications like digital pathology image analysis. To this end, we propose an end-to-end deep learning framework based on self-supervised learning for the segmentation and quantification of dopaminergic neurons in PD animal models. To the best of our knowledge, this is the first deep learning model that detects the cell body of dopaminergic neurons, counts the number of dopaminergic neurons, and provides characteristics of individual dopaminergic neurons as a numerical output. Extensive experiments demonstrate the effectiveness of our model in quantifying neurons with high precision, which can provide a faster turnaround for drug efficacy studies,better understanding of dopaminergic neuronal health status, and unbiased results in PD pre-clinical research. As part of our contributions, we also provide the first publicly available dataset of histology digital images along with expert annotations for the segmentation of TH-positive DA neuronal soma",
    "checked": true,
    "id": "357d7cc1a703a988b26d7cfa6d29a9a25e0a93bc",
    "semantic_title": "self-supervised learning for segmentation and quantification of dopamine neurons in parkinson's disease",
    "citation_count": 2,
    "authors": [
      "Fatemeh Haghighi",
      "soumitra ghosh",
      "Sarah Chu",
      "Hai Ngu",
      "Mohsen Hejrati",
      "Han Hui Lin",
      "Baris Bingol",
      "Somaye Hashemifar"
    ]
  },
  "https://openreview.net/forum?id=xgYgDEof29": {
    "title": "Analysis of Convolutions, Non-linearity and Depth in Graph Neural Networks using Neural Tangent Kernel",
    "volume": "main",
    "abstract": "The fundamental principle of Graph Neural Networks (GNNs) is to exploit the structural information of the data by aggregating the neighboring nodes using a `graph convolution' in conjunction with a suitable choice for the network architecture, such as depth and activation functions. Therefore, understanding the influence of each of the design choice on the network performance is crucial. Convolutions based on graph Laplacian have emerged as the dominant choice with the symmetric normalization of the adjacency matrix as the most widely adopted one. However, some empirical studies show that row normalization of the adjacency matrix outperforms it in node classification. Despite the widespread use of GNNs, there is no rigorous theoretical study on the representation power of these convolutions, that could explain this behavior. Similarly, the empirical observation of the linear GNNs performance being on par with non-linear ReLU GNNs lacks rigorous theory. In this work, we theoretically analyze the influence of different aspects of the GNN architecture using the Graph Neural Tangent Kernel in a semi-supervised node classification setting. Under the population Degree Corrected Stochastic Block Model, we prove that: (i) linear networks capture the class information as good as ReLU networks; (ii) row normalization preserves the underlying class structure better than other convolutions; (iii) performance degrades with network depth due to over-smoothing, but the loss in class information is the slowest in row normalization; (iv) skip connections retain the class information even at infinite depth, thereby eliminating over-smoothing. We finally validate our theoretical findings numerically and on real datasets such as Cora and Citeseer",
    "checked": true,
    "id": "8df003baa77649a80cc44ba548e1351909bcf116",
    "semantic_title": "analysis of convolutions, non-linearity and depth in graph neural networks using neural tangent kernel",
    "citation_count": 2,
    "authors": [
      "Mahalakshmi Sabanayagam",
      "Pascal Esser",
      "Debarghya Ghoshdastidar"
    ]
  },
  "https://openreview.net/forum?id=8wGXnjRLSy": {
    "title": "Zero-shot Node Classification with Graph Contrastive Embedding Network",
    "volume": "main",
    "abstract": "This paper studies zero-shot node classification, which aims to predict new classes (i.e., unseen classes) of nodes in a graph. This problem is challenging yet promising in a variety of real-world applications such as social analysis and bioinformatics. The key of zero-shot node classification is to enable the knowledge transfer of nodes from training classes to unseen classes. However, existing methods typically ignore the dependencies between nodes and classes, and fail to be organically integrated in a united way. In this paper, we present a novel framework called the Graph Contrastive Embedding Network (GraphCEN) for zero-shot node classification. Specifically, GraphCEN first constructs an affinity graph to model the relations between the classes. Then the node- and class-level contrastive learning (CL) are proposed to jointly learn node embeddings and class assignments in an end-to-end manner. The two-level CL can be optimized to mutually enhance each other. Extensive experiments indicate that our GraphCEN significantly outperforms the state-of-the-art approaches on multiple challenging benchmark datasets",
    "checked": true,
    "id": "4b31bd0ebbf4fcba2a538b17250277dedf3cf5e8",
    "semantic_title": "zero-shot node classification with graph contrastive embedding network",
    "citation_count": 21,
    "authors": [
      "Wei Ju",
      "Yifang Qin",
      "Siyu Yi",
      "Zhengyang Mao",
      "Kangjie Zheng",
      "Luchen Liu",
      "Xiao Luo",
      "Ming Zhang"
    ]
  },
  "https://openreview.net/forum?id=zKgJ6TWAFE": {
    "title": "Sharper Rates and Flexible Framework for Nonconvex SGD with Client and Data Sampling",
    "volume": "main",
    "abstract": "We revisit the classical problem of finding an approximately stationary point of the average of $n$ smooth and possibly nonconvex functions. The optimal complexity of stochastic first-order methods in terms of the number of gradient evaluations of individual functions is $\\mathcal{O}\\left(n + n^{1/2}\\varepsilon^{-1}\\right)$, attained by the optimal SGD methods SPIDER (Fang et al., 2018) and PAGE (Li et al., 2021), for example, where $\\varepsilon$ is the error tolerance. However, i) the big-$\\mathcal{O}$ notation hides crucial dependencies on the smoothness constants associated with the functions, and ii) the rates and theory in these methods assume simplistic sampling mechanisms that do not offer any flexibility. In this work we remedy the situation. First, we generalize the PAGE (Li et al., 2021) algorithm so that it can provably work with virtually any (unbiased) sampling mechanism. This is particularly useful in federated learning, as it allows us to construct and better understand the impact of various combinations of client and data sampling strategies. Second, our analysis is sharper as we make explicit use of certain novel inequalities that capture the intricate interplay between the smoothness constants and the sampling procedure. Indeed, our analysis is better even for the simple sampling procedure analyzed in the PAGE (Li et al., 2021) paper. However, this already improved bound can be further sharpened by a different sampling scheme which we propose. In summary, we provide the most general and most accurate analysis of optimal SGD in the smooth nonconvex regime. Finally, our theoretical findings are supposed with carefully designed experiments",
    "checked": true,
    "id": "a8df569f41c2a04df16e5dd8c6dd73b6476bc42e",
    "semantic_title": "sharper rates and flexible framework for nonconvex sgd with client and data sampling",
    "citation_count": 8,
    "authors": [
      "Alexander Tyurin",
      "Lukang Sun",
      "Konstantin Pavlovich Burlachenko",
      "Peter Richtárik"
    ]
  },
  "https://openreview.net/forum?id=YQWOzzSMPp": {
    "title": "An Analysis of Model-Based Reinforcement Learning From Abstracted Observations",
    "volume": "main",
    "abstract": "Many methods for Model-based Reinforcement learning (MBRL) in Markov decision processes (MDPs) provide guarantees for both the accuracy of the model they can deliver and the learning efficiency. At the same time, state abstraction techniques allow for a reduction of the size of an MDP while maintaining a bounded loss with respect to the original problem. Therefore, it may come as a surprise that no such guarantees are available when combining both techniques, i.e., where MBRL merely observes abstract states. Our theoretical analysis shows that abstraction can introduce a dependence between samples collected online (e.g., in the real world). That means that, without taking this dependence into account, results for MBRL do not directly extend to this setting. Our result shows that we can use concentration inequalities for martingales to overcome this problem. This result makes it possible to extend the guarantees of existing MBRL algorithms to the setting with abstraction. We illustrate this by combining R-MAX, a prototypical MBRL algorithm, with abstraction, thus producing the first performance guarantees for model-based ‘RL from Abstracted Observations': model-based reinforcement learning with an abstract model",
    "checked": true,
    "id": "40bda2294008695ffa48b0ef24d5d0952cb83065",
    "semantic_title": "an analysis of model-based reinforcement learning from abstracted observations",
    "citation_count": 3,
    "authors": [
      "Rolf A. N. Starre",
      "Marco Loog",
      "Elena Congeduti",
      "Frans A Oliehoek"
    ]
  },
  "https://openreview.net/forum?id=6OEcDKZj5j": {
    "title": "The Kernel Density Integral Transformation",
    "volume": "main",
    "abstract": "Feature preprocessing continues to play a critical role when applying machine learning and statistical methods to tabular data. In this paper, we propose the use of the kernel density integral transformation as a feature preprocessing step. Our approach subsumes the two leading feature preprocessing methods as limiting cases: linear min-max scaling and quantile transformation. We demonstrate that, without hyperparameter tuning, the kernel density integral transformation can be used as a simple drop-in replacement for either method, offering robustness to the weaknesses of each. Alternatively, with tuning of a single continuous hyperparameter, we frequently outperform both of these methods. Finally, we show that the kernel density transformation can be profitably applied to statistical data analysis, particularly in correlation analysis and univariate clustering",
    "checked": true,
    "id": "47150b772a11789bed763d4d425ae2539279aa96",
    "semantic_title": "the kernel density integral transformation",
    "citation_count": 4,
    "authors": [
      "Calvin McCarter"
    ]
  },
  "https://openreview.net/forum?id=lx1WnkL9fk": {
    "title": "Overcoming Resource Constraints in Federated Learning: Large Models Can Be Trained with only Weak Clients",
    "volume": "main",
    "abstract": "Federated Learning (FL) is emerging as a popular, promising decentralized learning framework that enables collaborative training among clients, with no need to share private data between them or to a centralized server. However, considering many edge clients do not have sufficient computing, memory, or communication capabilities, federated learning of large models still faces significant bottlenecks. To keep such weak but crucial clients in the loop, prior works either consider a heterogeneous-client setting where clients train models with different sizes; or offload training to the server. However, the heterogeneous-client setting requires some clients to train full model, which is not aligned with the resource-constrained setting; while the latter ones break privacy promises in FL when sharing intermediate representations or labels with the server. To overcome these limitations, in this work, we formulate a realistic, but much less explored, cross-device FL setting in which no client can train a full large model nor is willing to share any intermediate information with the remote server. Under such a formulation, we develop a principal sub-model (PriSM) training methodology to collaboratively train a full large model, while assigning each client a small sub-model that is a probabilistic low-rank approximation to the full server model. When creating sub-models, PriSM first performs a principal kernel analysis in the orthogonal kernel space to obtain importance of each kernel. Then, PriSM adopts a novel importance-aware sampling process to select a subset of kernels (i.e., a kernel with high importance is assigned with a higher sampling probability). This sampling process ensures each sub-model is still a low-rank approximation to the full model, while all sub-models together achieve nearly full coverage on the principal kernels. To further improve memory efficiency while still preserving accuracy, PriSM also exploits low-rank structure in intermediate representations and allows each sub-model to learn only a subset of them. Our evaluations on various datasets and models (CNNs, LSTMs, Transformers) under different resource-constrained settings demonstrate that PriSM yields an accuracy improvement of up to $10\\%$ compared to existing works. More importantly, PriSM does not incur significant accuracy degradation compared to full-model training (e.g., only $\\sim 2\\%$ accuracy drops for ResNet-18/CIFAR-10 when clients train only $0.2\\times$ sub-models)",
    "checked": true,
    "id": "32388c03bf0f59a152bcd98b9cf0623e8b7f08a6",
    "semantic_title": "overcoming resource constraints in federated learning: large models can be trained with only weak clients",
    "citation_count": 3,
    "authors": [
      "Yue Niu",
      "Saurav Prakash",
      "Souvik Kundu",
      "Sunwoo Lee",
      "Salman Avestimehr"
    ]
  },
  "https://openreview.net/forum?id=FObkvLwNSo": {
    "title": "Projected Randomized Smoothing for Certified Adversarial Robustness",
    "volume": "main",
    "abstract": "Randomized smoothing is the current state-of-the-art method for producing provably robust classifiers. While randomized smoothing typically yields robust $\\ell_2$-ball certificates, recent research has generalized provable robustness to different norm balls as well as anisotropic regions. This work considers a classifier architecture that first projects onto a low-dimensional approximation of the data manifold and then applies a standard classifier. By performing randomized smoothing in the low-dimensional projected space, we characterize the certified region of our smoothed composite classifier back in the high-dimensional input space and prove a tractable lower bound on its volume. We show experimentally on CIFAR-10 and SVHN that classifiers without the initial projection are vulnerable to perturbations that are normal to the data manifold and yet are captured by the certified regions of our method. We compare the volume of our certified regions against various baselines and show that our method improves on the state-of-the-art by many orders of magnitude",
    "checked": true,
    "id": "efb6333deaf551f642f6f76af896c0a6adf26cd5",
    "semantic_title": "projected randomized smoothing for certified adversarial robustness",
    "citation_count": 16,
    "authors": [
      "Samuel Pfrommer",
      "Brendon G. Anderson",
      "Somayeh Sojoudi"
    ]
  },
  "https://openreview.net/forum?id=4UXJhNSbwd": {
    "title": "Multi-Domain Long-Tailed Learning by Augmenting Disentangled Representations",
    "volume": "main",
    "abstract": "There is an inescapable long-tailed class-imbalance issue in many real-world classification problems. Current methods for addressing this problem only consider scenarios where all examples come from the same distribution. However, in many cases, there are multiple domains with distinct class imbalance. We study this multi-domain long-tailed learning problem and aim to produce a model that generalizes well across all classes and domains. Towards that goal, we introduce TALLY, a method that addresses this multi-domain long-tailed learning problem. Built upon a proposed selective balanced sampling strategy, TALLY achieves this by mixing the semantic representation of one example with the domain-associated nuisances of another, producing a new representation for use as data augmentation. To improve the disentanglement of semantic representations, TALLY further utilizes a domain-invariant class prototype that averages out domain-specific effects. We evaluate TALLY on several benchmarks and real-world datasets and find that it consistently outperforms other state-of-the-art methods in both subpopulation and domain shift",
    "checked": true,
    "id": "eeec52cc464b50a560b50ef26b566ad243564849",
    "semantic_title": "multi-domain long-tailed learning by augmenting disentangled representations",
    "citation_count": 4,
    "authors": [
      "Xinyu Yang",
      "Huaxiu Yao",
      "Allan Zhou",
      "Chelsea Finn"
    ]
  },
  "https://openreview.net/forum?id=f36LaK7M0F": {
    "title": "CAE v2: Context Autoencoder with CLIP Latent Alignment",
    "volume": "main",
    "abstract": "Masked image modeling (MIM) learns visual representations by predicting the masked patches on a pre-defined target. Inspired by MVP(Wei et al., 2022b) that displays impressive gains with CLIP, in this work, we also employ the semantically rich CLIP latent as target and further tap its potential by introducing a new MIM pipeline, CAE v2, to learn a high-quality encoder and facilitate model convergence on the pre-training task. CAE v2 is an improved variant of CAE (Chen et al., 2023), applying the CLIP latent on two pretraining tasks, i.e., visible latent alignment and masked latent alignment. Visible latent alignment directly mimics the visible latent representations from the encoder to the corresponding CLIP latent, which is beneficial for facilitating model convergence and improving the representative ability of the encoder. Masked latent alignment predicts the representations of masked patches within the feature space of CLIP latent as standard MIM task does, effectively aligning the representations computed from the encoder and the regressor into the same domain. We pretrain CAE v2 on ImageNet-1K images and evaluate on various downstream vision tasks, including image classification, semantic segmentation, object detection and instance segmentation. Experiments show that our CAE v2 achieves competitive performance and even outperforms the CLIP vision encoder, demonstrating the effectiveness of our method. Code is available at https://github.com/Atten4Vis/CAE",
    "checked": true,
    "id": "6e966e5d3c15fbb162f19ba2e1cf448ff079c345",
    "semantic_title": "cae v2: context autoencoder with clip latent alignment",
    "citation_count": 7,
    "authors": [
      "Xinyu Zhang",
      "Jiahui Chen",
      "Junkun Yuan",
      "Qiang Chen",
      "Jian Wang",
      "Xiaodi Wang",
      "Shumin Han",
      "Xiaokang Chen",
      "Jimin Pi",
      "Kun Yao",
      "Junyu Han",
      "Errui Ding",
      "Jingdong Wang"
    ]
  },
  "https://openreview.net/forum?id=VgJhYu7FmQ": {
    "title": "Cross-validation for Geospatial Data: Estimating Generalization Performance in Geostatistical Problems",
    "volume": "main",
    "abstract": "Geostatistical learning problems are frequently characterized by spatial autocorrelation in the input features and/or the potential for covariate shift at test time. These realities violate the classical assumption of independent, identically distributed data, upon which most cross-validation algorithms rely in order to estimate the generalization performance of a model. In this paper, we present a theoretical criterion for unbiased cross-validation estimators in the geospatial setting. We also introduce a new cross-validation algorithm to evaluate models, inspired by the challenges of geospatial problems. We apply a framework for categorizing problems into different types of geospatial scenarios to help practitioners select an appropriate cross-validation strategy. Our empirical analyses compare cross-validation algorithms on both simulated and several real datasets to develop recommendations for a variety of geospatial settings. This paper aims to draw attention to some challenges that arise in model evaluation for geospatial problems and to provide guidance for users",
    "checked": true,
    "id": "4afd99f5d36a6687bf43724168a834d683c2ef67",
    "semantic_title": "cross-validation for geospatial data: estimating generalization performance in geostatistical problems",
    "citation_count": 3,
    "authors": [
      "Jing Wang",
      "Laurel Hopkins",
      "Tyler Hallman",
      "W. Douglas Robinson",
      "Rebecca Hutchinson"
    ]
  },
  "https://openreview.net/forum?id=LLKI5Lq2YN": {
    "title": "Adaptive Hyperparameter Selection for Differentially Private Gradient Descent",
    "volume": "main",
    "abstract": "We present an adaptive mechanism for hyperparameter selection in differentially private optimization that addresses the inherent trade-off between utility and privacy. The mechanism eliminates the often unstructured and time-consuming manual effort of selecting hyperparameters and avoids the additional privacy costs that hyperparameter selection otherwise incurs on top of that of the actual algorithm. We instantiate our mechanism for noisy gradient descent on non-convex, convex and strongly convex loss functions, respectively, to derive schedules for the noise variance and step size. These schedules account for the properties of the loss function and adapt to convergence metrics such as the gradient norm. When using these schedules, we show that noisy gradient descent converges at essentially the same rate as its noise-free counterpart. Numerical experiments show that the schedules consistently perform well across a range of datasets without manual tuning",
    "checked": true,
    "id": "883bdc74ba6df56bbee38f573170cce882900bd9",
    "semantic_title": "adaptive hyperparameter selection for differentially private gradient descent",
    "citation_count": 2,
    "authors": [
      "Dominik Fay",
      "Sindri Magnússon",
      "Jens Sjölund",
      "Mikael Johansson"
    ]
  },
  "https://openreview.net/forum?id=Ub6XILEF9x": {
    "title": "Multiscale Causal Structure Learning",
    "volume": "main",
    "abstract": "Causal structure learning methods are vital for unveiling causal relationships embedded into observed data. However, the state of the art suffers a major limitation: it assumes that causal interactions occur only at the frequency at which data is observed. To address this limitation, this paper proposes a method that allows structural learning of linear causal relationships occurring at different time scales. Specifically, we explicitly take into account instantaneous and lagged inter-relations between multiple time series, represented at different scales, hinging on wavelet transform. We cast the problem as the learning of a multiscale causal graph having sparse structure and dagness constraints, enforcing causality through directed and acyclic topology. To solve the resulting (non-convex) formulation, we propose an algorithm termed MS-CASTLE, which exhibits consistent performance across different noise distributions and wavelet choices. We also propose a single-scale version of our algorithm, SS-CASTLE, which outperforms existing methods in computational efficiency, performance, and robustness on synthetic data. Finally, we apply the proposed approach to learn the multiscale causal structure of the risk of 15 global equity markets, during covid-19 pandemic, illustrating the importance of multiscale analysis to reveal useful interactions at different time resolutions. Financial investors can leverage our approach to manage risk within equity portfolios from a causal perspective, tailored to their investment horizon",
    "checked": true,
    "id": "6b370dc7e28fb8dcd551153101114d56870e40cb",
    "semantic_title": "multiscale causal structure learning",
    "citation_count": 7,
    "authors": [
      "Gabriele D'Acunto",
      "Paolo Di Lorenzo",
      "Sergio Barbarossa"
    ]
  },
  "https://openreview.net/forum?id=xiQXHvL1eN": {
    "title": "Dynamic Regret Analysis of Safe Distributed Online Optimization for Convex and Non-convex Problems",
    "volume": "main",
    "abstract": "This paper addresses safe distributed online optimization over an unknown set of linear safety constraints. A network of agents aims at jointly minimizing a global, time-varying function, which is only partially observable to each individual agent. Therefore, agents must engage in local communications to generate a safe sequence of actions competitive with the best minimizer sequence in hindsight, and the gap between the two sequences is quantified via dynamic regret. We propose distributed safe online gradient descent (D-Safe-OGD) with an exploration phase, where all agents estimate the constraint parameters collaboratively to build estimated feasible sets, ensuring the action selection safety during the optimization phase. We prove that for convex functions, D-Safe-OGD achieves a dynamic regret bound of $O(T^{2/3} \\sqrt{\\log T} + T^{1/3}C_T^*)$, where $C_T^*$ denotes the path-length of the best minimizer sequence. We further prove a dynamic regret bound of $O(T^{2/3}{\\color{black} \\sqrt{\\log T}} + T^{2/3}C_T^*)$ for certain non-convex problems, which establishes the first dynamic regret bound for a safe distributed algorithm in the non-convex setting",
    "checked": true,
    "id": "e8c5928fe05de0b5f0d76d0ef7b6043b1ff8c388",
    "semantic_title": "dynamic regret analysis of safe distributed online optimization for convex and non-convex problems",
    "citation_count": 6,
    "authors": [
      "Ting-Jui Chang",
      "Sapana Chaudhary",
      "Dileep Kalathil",
      "Shahin Shahrampour"
    ]
  },
  "https://openreview.net/forum?id=2tdhQMLg36": {
    "title": "Revisiting Image Classifier Training for Improved Certified Robust Defense against Adversarial Patches",
    "volume": "main",
    "abstract": "Certifiably robust defenses against adversarial patches for image classifiers ensure correct prediction against any changes to a constrained neighborhood of pixels. PatchCleanser, the state-of-the-art certified defense, uses a double-masking strategy for robust classification. The success of this strategy relies heavily on the model's invariance to image pixel masking. In this paper, we take a closer look at model training schemes to improve this invariance. Instead of using Random Cutout augmentations like PatchCleanser, we introduce the notion of worst-case masking, i.e., selecting masked images which maximize classification loss. However, finding worst-case masks requires an exhaustive search, which might be prohibitively expensive to do on-the-fly during training. To solve this problem, we propose a two-round greedy masking strategy (Greedy Cutout) which finds an approximate worst-case mask location with much less compute. We show that the models trained with our Greedy Cutout improves certified robust accuracy over Random Cutout in PatchCleanser across a range of datasets and architectures. Certified robust accuracy on ImageNet with a ViT-B16-224 model increases from 58.1% to 62.3% against a 3% square patch applied anywhere on the image",
    "checked": true,
    "id": "4e4f5f1a72d665ff28e7028f9a483dd1900522d4",
    "semantic_title": "revisiting image classifier training for improved certified robust defense against adversarial patches",
    "citation_count": 4,
    "authors": [
      "Aniruddha Saha",
      "Shuhua Yu",
      "Mohammad Sadegh Norouzzadeh",
      "Wan-Yi Lin",
      "Chaithanya Kumar Mummadi"
    ]
  },
  "https://openreview.net/forum?id=61TKzU9B96": {
    "title": "An Optical Control Environment for Benchmarking Reinforcement Learning Algorithms",
    "volume": "main",
    "abstract": "Deep reinforcement learning has the potential to address various scientific problems. In this paper, we implement an optics simulation environment for reinforcement learning based controllers. The environment captures the essence of nonconvexity, nonlinearity, and time-dependent noise inherent in optical systems, offering a more realistic setting. Subsequently, we provide the benchmark results of several reinforcement learning algorithms on the proposed simulation environment. The experimental findings demonstrate the superiority of off-policy reinforcement learning approaches over traditional control algorithms in navigating the intricacies of complex optical control environments",
    "checked": true,
    "id": "535722991c93f214446b1bc36421b259b6b76f6e",
    "semantic_title": "an optical control environment for benchmarking reinforcement learning algorithms",
    "citation_count": 1,
    "authors": [
      "ABULIKEMU ABUDUWEILI",
      "Changliu Liu"
    ]
  },
  "https://openreview.net/forum?id=0pn3KnbH5F": {
    "title": "Learning-to-defer for sequential medical decision-making under uncertainty",
    "volume": "main",
    "abstract": "Learning-to-defer is a framework to automatically defer decision-making to a human expert when ML-based decisions are deemed unreliable. Existing learning-to-defer frameworks are not designed for sequential settings. That is, they defer at every instance independently, based on immediate predictions, while ignoring the potential long-term impact of these interventions. As a result, existing frameworks are myopic. Further, they do not defer adaptively, which is crucial when human interventions are costly. In this work, we propose Sequential Learning-to-Defer (SLTD), a framework for learning-to-defer to a domain expert in sequential decision-making settings. Contrary to existing literature, we pose the problem of learning-to-defer as model-based reinforcement learning (RL) to i) account for long-term consequences of ML-based actions using RL and ii) adaptively defer based on the dynamics (model-based). Our proposed framework determines whether to defer (at each time step) by quantifying whether a deferral now will improve the value compared to delaying deferral to the next time step. To quantify the improvement, we account for potential future deferrals. As a result, we learn a pre-emptive deferral policy (i.e. a policy that defers early if using the ML-based policy could worsen long-term outcomes). Our deferral policy is adaptive to the non-stationarity in the dynamics. We demonstrate that adaptive deferral via SLTD provides an improved trade-off between long-term outcomes and deferral frequency on synthetic, semi-synthetic, and real-world data with non-stationary dynamics. Finally, we interpret the deferral decision by decomposing the propagated (long-term) uncertainty around the outcome, to justify the deferral decision",
    "checked": true,
    "id": "793f242c80ab54c43aa7da3b628ad6bbf48c041e",
    "semantic_title": "learning-to-defer for sequential medical decision-making under uncertainty",
    "citation_count": 9,
    "authors": [
      "Shalmali Joshi",
      "Sonali Parbhoo",
      "Finale Doshi-Velez"
    ]
  },
  "https://openreview.net/forum?id=JFaZ94tT8M": {
    "title": "Learning domain-specific causal discovery from time series",
    "volume": "main",
    "abstract": "Causal discovery (CD) from time-varying data is important in neuroscience, medicine, and machine learning. Techniques for CD encompass randomized experiments, which are generally unbiased but expensive, and algorithms such as Granger causality, conditional-independence-based, structural-equation-based, and score-based methods that are only accurate under strong assumptions made by human designers. However, as demonstrated in other areas of machine learning, human expertise is often not entirely accurate and tends to be outperformed in domains with abundant data. In this study, we examine whether we can enhance domain-specific causal discovery for time series using a data-driven approach. Our findings indicate that this procedure significantly outperforms human-designed, domain-agnostic causal discovery methods, such as Mutual Information, VAR-LiNGAM, and Granger Causality on the MOS 6502 microprocessor, the NetSim fMRI dataset, and the Dream3 gene dataset. We argue that, when feasible, the causality field should consider a supervised approach in which domain-specific CD procedures are learned from extensive datasets with known causal relationships, rather than being designed by human specialists. Our findings promise a new approach toward improving CD in neural and medical data and for the broader machine learning community",
    "checked": true,
    "id": "78f33165d0a9250fc76edf1a6e831c68657d0a69",
    "semantic_title": "learning domain-specific causal discovery from time series",
    "citation_count": 1,
    "authors": [
      "Xinyue Wang",
      "Konrad Kording"
    ]
  },
  "https://openreview.net/forum?id=ThJl4d5JRg": {
    "title": "Dynamic Subgoal-based Exploration via Bayesian Optimization",
    "volume": "main",
    "abstract": "Reinforcement learning in sparse-reward navigation environments with expensive and limited interactions is challenging and poses a need for effective exploration. Motivated by complex navigation tasks that require real-world training (when cheap simulators are not available), we consider an agent that faces an unknown distribution of environments and must decide on an exploration strategy. It may leverage a series of training environments to improve its policy before it is evaluated in a test environment drawn from the same environment distribution. Most existing approaches focus on fixed exploration strategies, while the few that view exploration as a meta-optimization problem tend to ignore the need for _cost-efficient_ exploration. We propose a cost-aware Bayesian optimization approach that efficiently searches over a class of dynamic subgoal-based exploration strategies. The algorithm adjusts a variety of levers --- the locations of the subgoals, the length of each episode, and the number of replications per trial --- in order to overcome the challenges of sparse rewards, expensive interactions, and noise. An experimental evaluation demonstrates that the new approach outperforms existing baselines across a number of problem domains. We also provide a theoretical foundation and prove that the method asymptotically identifies a near-optimal subgoal design",
    "checked": false,
    "id": "b8dc2c6f9ca7c0d55b0379d5067f67b3e834ee80",
    "semantic_title": "model-based causal bayesian optimization",
    "citation_count": 25,
    "authors": [
      "Yijia Wang",
      "Matthias Poloczek",
      "Daniel R. Jiang"
    ]
  },
  "https://openreview.net/forum?id=V7BvYJyTmM": {
    "title": "Gated Domain Units for Multi-source Domain Generalization",
    "volume": "main",
    "abstract": "The phenomenon of distribution shift (DS) occurs when a dataset at test time differs from the dataset at training time, which can significantly impair the performance of a machine learning model in practical settings due to a lack of knowledge about the data's distribution at test time. To address this problem, we postulate that real-world distributions are composed of latent Invariant Elementary Distributions (I.E.D) across different domains. This assumption implies an invariant structure in the solution space that enables knowledge transfer to unseen domains. To exploit this property for domain generalization, we introduce a modular neural network layer consisting of Gated Domain Units (GDUs) that learn a representation for each latent elementary distribution. During inference, a weighted ensemble of learning machines can be created by comparing new observations with the representations of each elementary distribution. Our flexible framework also accommodates scenarios where explicit domain information is not present. Extensive experiments on image, text, and graph data show consistent performance improvement on out-of-training target domains. These findings support the practicality of the I.E.D assumption and the effectiveness of GDUs for domain generalisation",
    "checked": true,
    "id": "f26d1e49b28f3214e4307302e66f716c14ef129d",
    "semantic_title": "gated domain units for multi-source domain generalization",
    "citation_count": 4,
    "authors": [
      "Simon Föll",
      "Alina Dubatovka",
      "Eugen Ernst",
      "Siu Lun Chau",
      "Martin Maritsch",
      "Patrik Okanovic",
      "Gudrun Thaeter",
      "Joachim M. Buhmann",
      "Felix Wortmann",
      "Krikamol Muandet"
    ]
  },
  "https://openreview.net/forum?id=8L7Rh6FIXt": {
    "title": "IBIA: An Incremental Build-Infer-Approximate Framework for Approximate Inference of Partition Function",
    "volume": "main",
    "abstract": "Exact computation of the partition function is known to be intractable, necessitating approximate inference techniques. Existing methods for approximate inference are slow to converge for many benchmarks. The control of accuracy-complexity trade-off is also non-trivial in many of these methods. We propose a novel incremental build-infer-approximate (IBIA) framework for approximate inference that addresses these issues. In this framework, the probabilistic graphical model is converted into a sequence of clique tree forests (SCTF) with bounded clique sizes. We show that the SCTF can be used to efficiently compute the partition function. We propose two new algorithms which are used to construct the SCTF and prove the correctness of both. The first is an algorithm for incremental construction of CTFs that is guaranteed to give a valid CTF with bounded clique sizes and the second is an approximation algorithm that takes a calibrated CTF as input and yields a valid and calibrated CTF with reduced clique sizes as the output. We have evaluated our method using several benchmark sets from recent UAI competitions and our results show good accuracies with competitive runtimes",
    "checked": true,
    "id": "cd68083d1c3f37e85cdcbaa104c86d92edc43d2f",
    "semantic_title": "ibia: an incremental build-infer-approximate framework for approximate inference of partition function",
    "citation_count": 1,
    "authors": [
      "Shivani Bathla",
      "Vinita Vasudevan"
    ]
  },
  "https://openreview.net/forum?id=iHyhdpsnyi": {
    "title": "Revisiting Sparsity Hunting in Federated Learning: Why does Sparsity Consensus Matter?",
    "volume": "main",
    "abstract": "Edge devices can benefit remarkably from federated learning due to their distributed nature; however, their limited resource and computing power poses limitations in deployment. A possible solution to this problem is to utilize off-the-shelf sparse learning algorithms at the clients to meet their resource budget. However, such naive deployment in the clients causes significant accuracy degradation, especially for highly resource-constrained clients. In particular, our investigations reveal that the lack of consensus in the sparsity masks among the clients may potentially slow down the convergence of the global model and cause a substantial accuracy drop. With these observations, we present \\textit{federated lottery aware sparsity hunting} (FLASH), a unified sparse learning framework for training a sparse sub-model that maintains the performance under ultra-low parameter density while yielding proportional communication benefits. Moreover, given that different clients may have different resource budgets, we present \\textit{hetero-FLASH} where clients can take different density budgets based on their device resource limitations instead of supporting only one target parameter density. Experimental analysis on diverse models and datasets shows the superiority of FLASH in closing the gap with an unpruned baseline while yielding up to $\\mathord{\\sim}10.1\\%$ improved accuracy with $\\mathord{\\sim}10.26\\times$ fewer communication, compared to existing alternatives, at similar hyperparameter settings",
    "checked": true,
    "id": "f6209fcb71cafacf9379806d85109754c96e11b1",
    "semantic_title": "revisiting sparsity hunting in federated learning: why does sparsity consensus matter?",
    "citation_count": 12,
    "authors": [
      "Sara Babakniya",
      "Souvik Kundu",
      "Saurav Prakash",
      "Yue Niu",
      "Salman Avestimehr"
    ]
  },
  "https://openreview.net/forum?id=Y1eYplvxrE": {
    "title": "Relating graph auto-encoders to linear models",
    "volume": "main",
    "abstract": "Graph auto-encoders are widely used to construct graph representations in Euclidean vector spaces. However, it has already been pointed out empirically that linear models on many tasks can outperform graph auto-encoders. In our work, we prove that the solution space induced by graph auto-encoders is a subset of the solution space of a linear map. This demonstrates that linear embedding models have at least the representational power of graph auto-encoders based on graph convolutional networks. So why are we still using nonlinear graph auto-encoders? One reason could be that actively restricting the linear solution space might introduce an inductive bias that helps improve learning and generalization. While many researchers believe that the nonlinearity of the encoder is the critical ingredient towards this end, we instead identify the node features of the graph as a more powerful inductive bias. We give theoretical insights by introducing a corresponding bias in a linear model and analyzing the change in the solution space. Our experiments are aligned with other empirical work on this question and show that the linear encoder can outperform the nonlinear encoder when using feature information",
    "checked": true,
    "id": "1ea30fd85da438eb3f526307330380e0532c84b6",
    "semantic_title": "relating graph auto-encoders to linear models",
    "citation_count": 1,
    "authors": [
      "Solveig Klepper",
      "Ulrike von Luxburg"
    ]
  },
  "https://openreview.net/forum?id=zmBFzuT2DN": {
    "title": "Deep Operator Learning Lessens the Curse of Dimensionality for PDEs",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) have achieved remarkable success in numerous domains, and their application to PDE-related problems has been rapidly advancing. This paper provides an estimate for the generalization error of learning Lipschitz operators over Banach spaces using DNNs with applications to various PDE solution operators. The goal is to specify DNN width, depth, and the number of training samples needed to guarantee a certain testing error. Under mild assumptions on data distributions or operator structures, our analysis shows that deep operator learning can have a relaxed dependence on the discretization resolution of PDEs and, hence, lessen the curse of dimensionality in many PDE-related problems including elliptic equations, parabolic equations, and Burgers equations. Our results are also applied to give insights about discretization-invariant in operator learning",
    "checked": true,
    "id": "c39106c6d3ddcba512fe8f776a32c739e4e75375",
    "semantic_title": "deep operator learning lessens the curse of dimensionality for pdes",
    "citation_count": 14,
    "authors": [
      "Ke Chen",
      "Chunmei Wang",
      "Haizhao Yang"
    ]
  },
  "https://openreview.net/forum?id=3taIQG4C7H": {
    "title": "Label Noise-Robust Learning using a Confidence-Based Sieving Strategy",
    "volume": "main",
    "abstract": "In learning tasks with label noise, improving model robustness against overfitting is a pivotal challenge because the model eventually memorizes labels, including the noisy ones. Identifying the samples with noisy labels and preventing the model from learning them is a promising approach to address this challenge. When training with noisy labels, the per-class confidence scores of the model, represented by the class probabilities, can be reliable criteria for assessing whether the input label is the true label or the corrupted one. In this work, we exploit this observation and propose a novel discriminator metric called confidence error and a sieving strategy called CONFES to differentiate between the clean and noisy samples effectively. We provide theoretical guarantees on the probability of error for our proposed metric. Then, we experimentally illustrate the superior performance of our proposed approach compared to recent studies on various settings, such as synthetic and real-world label noise. Moreover, we show CONFES can be combined with other state-of-the-art approaches, such as Co-teaching and DivideMix to further improve model performance",
    "checked": true,
    "id": "ed32c5122d899da367270557cdb363fe5fab838b",
    "semantic_title": "label noise-robust learning using a confidence-based sieving strategy",
    "citation_count": 7,
    "authors": [
      "Reihaneh Torkzadehmahani",
      "Reza Nasirigerdeh",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ]
  },
  "https://openreview.net/forum?id=igDOV2KBwM": {
    "title": "On Perfect Clustering for Gaussian Processes",
    "volume": "main",
    "abstract": "In this paper, we propose a data based transformation for infinite-dimensional Gaussian processes and derive its limit theorem. For a clustering problem using mixture models, an appropriate modification of this transformation asymptotically leads to perfect separation of the populations under rather general conditions, except the scenario in which differences between clusters depend only on the locations; in which case our procedure is useless. Theoretical properties related to label consistency are studied for the k-means clustering algorithm when used on this transformed data. Good empirical performance of the proposed methodology is demonstrated using simulated as well as benchmark data sets, when compared with some popular parametric and nonparametric methods for such functional data",
    "checked": true,
    "id": "74dde6d496a4a4ec9b8e38f30079c719ae49c962",
    "semantic_title": "on perfect clustering for gaussian processes",
    "citation_count": 2,
    "authors": [
      "Juan Cuesta-Albertos",
      "Subhajit Dutta"
    ]
  },
  "https://openreview.net/forum?id=WJt2Pc3qtI": {
    "title": "How Reliable is Your Regression Model's Uncertainty Under Real-World Distribution Shifts?",
    "volume": "main",
    "abstract": "Many important computer vision applications are naturally formulated as regression problems. Within medical imaging, accurate regression models have the potential to automate various tasks, helping to lower costs and improve patient outcomes. Such safety-critical deployment does however require reliable estimation of model uncertainty, also under the wide variety of distribution shifts that might be encountered in practice. Motivated by this, we set out to investigate the reliability of regression uncertainty estimation methods under various real-world distribution shifts. To that end, we propose an extensive benchmark of 8 image-based regression datasets with different types of challenging distribution shifts. We then employ our benchmark to evaluate many of the most common uncertainty estimation methods, as well as two state-of-the-art uncertainty scores from the task of out-of-distribution detection. We find that while methods are well calibrated when there is no distribution shift, they all become highly overconfident on many of the benchmark datasets. This uncovers important limitations of current uncertainty estimation methods, and the proposed benchmark therefore serves as a challenge to the research community. We hope that our benchmark will spur more work on how to develop truly reliable regression uncertainty estimation methods",
    "checked": true,
    "id": "f01dfb620ae80f8ad56fc1a6f4d84eb52200fbf0",
    "semantic_title": "how reliable is your regression model's uncertainty under real-world distribution shifts?",
    "citation_count": 12,
    "authors": [
      "Fredrik K. Gustafsson",
      "Martin Danelljan",
      "Thomas B. Schön"
    ]
  },
  "https://openreview.net/forum?id=qcCE4mC2jI": {
    "title": "RIGNN: A Rationale Perspective for Semi-supervised Open-world Graph Classification",
    "volume": "main",
    "abstract": "Graph classification has gained growing attention in the graph machine learning community and a variety of semi-supervised methods have been developed to reduce the high cost of annotation. They usually combine graph neural networks (GNNs) and extensive semi-supervised techniques such as knowledge distillation. However, they adhere to the close-set assumption that unlabeled graphs all belong to known classes, limiting their applications in the real world. This paper goes further, investigating a practical problem of semi-supervised open-world graph classification where these unlabeled graph data could come from unseen classes. A novel approach named Rationale-Informed GNN (RIGNN) is proposed, which takes a rationale view to detect components containing the most information related to the label space and classify unlabeled graphs into a known class or an unseen class. In particular, RIGNN contains a relational detector and a feature extractor to produce effective rationale features, which maximize the mutual information with label information and exhibit sufficient disentanglement with non-rationale elements. Furthermore, we construct a graph-of-graph based on geometrical relationships, which gives instructions on enhancing rationale representations. In virtue of effective rationale representations, we can provide accurate and balanced predictions for unlabeled graphs. An extension is also made to accomplish effective open-set graph classification. We verify our proposed methods on four benchmark datasets in various settings and experimental results reveal the effectiveness of our proposed RIGNN compared with state-of-the-art methods",
    "checked": true,
    "id": "76b9d2931374d060ab55b220af51bffc10479432",
    "semantic_title": "rignn: a rationale perspective for semi-supervised open-world graph classification",
    "citation_count": 10,
    "authors": [
      "Xiao Luo",
      "Yusheng Zhao",
      "Zhengyang Mao",
      "Yifang Qin",
      "Wei Ju",
      "Ming Zhang",
      "Yizhou Sun"
    ]
  },
  "https://openreview.net/forum?id=JwGKVpRfVD": {
    "title": "SkillS: Adaptive Skill Sequencing for Efficient Temporally-Extended Exploration",
    "volume": "main",
    "abstract": "The ability to effectively reuse prior knowledge is a key requirement when building general and flexible Reinforcement Learning (RL) agents. Skill reuse is one of the most common approaches, but current methods have considerable limitations. For example, fine-tuning an existing policy frequently fails, as the policy can degrade rapidly early in training. In a similar vein, distillation of expert behavior can lead to poor results when given sub-optimal experts. We compare several common approaches for skill transfer on multiple domains including changes in task and system dynamics. We identify how existing methods fail and introduce an alternative approach to mitigate these problems. Our approach learns to sequence temporally-extended skills for exploration but learns the final policy directly from the raw experience. This conceptual split enables rapid adaptation and thus efficient data collection but without constraining the final solution. It significantly outperforms many classical methods across a suite of evaluation tasks and we use a broad set of ablations to highlight the importance of different components of our method",
    "checked": true,
    "id": "6a4c74430e9c9c165ef3321edf6b4e9bdc36dea9",
    "semantic_title": "skills: adaptive skill sequencing for efficient temporally-extended exploration",
    "citation_count": 6,
    "authors": [
      "Giulia Vezzani",
      "Dhruva Tirumala",
      "Markus Wulfmeier",
      "Dushyant Rao",
      "Abbas Abdolmaleki",
      "Ben Moran",
      "Tuomas Haarnoja",
      "Jan Humplik",
      "Roland Hafner",
      "Michael Neunert",
      "Claudio Fantacci",
      "Tim Hertweck",
      "Thomas Lampe",
      "Fereshteh Sadeghi",
      "Nicolas Heess",
      "Martin Riedmiller"
    ]
  },
  "https://openreview.net/forum?id=cJgHzw8Qhq": {
    "title": "Estimating Differential Equations from Temporal Point Processes",
    "volume": "main",
    "abstract": "Ordinary differential equations (ODEs) allow interpretation of phenomena in various scientific fields. They have mostly been applied to numerical data observed at regular intervals, but not to irregularly observed discrete events, also known as point processes. In this study, we introduce an ODE modeling of such events by combining ODEs with log-Gaussian Cox processes (Møller et al., 1998). In the experiments with different types of ODEs regarding infectious disease, predator-prey interaction, and competition among participants, our method outperformed existing baseline methods assuming regularly observed continuous data with respect to the accuracy of recovering the latent parameters of ODEs. Through both synthetic and actual examples, we also showed the ability of our method to extrapolate, model latent events that cannot be observed, and offer interpretability of phenomena from the viewpoint of the estimated parameters of ODE",
    "checked": true,
    "id": "65ce2d8059bbff71df6bf402d7b8df9fc8ffa9fa",
    "semantic_title": "estimating differential equations from temporal point processes",
    "citation_count": 0,
    "authors": [
      "Shuichi Miyazawa",
      "Daichi Mochihashi"
    ]
  },
  "https://openreview.net/forum?id=XuOE99cmST": {
    "title": "Turning a Curse into a Blessing: Enabling In-Distribution-Data-Free Backdoor Removal via Stabilized Model Inversion",
    "volume": "main",
    "abstract": "The effectiveness of many existing techniques for removing backdoors from machine learning models relies on access to clean in-distribution data. However, given that these models are often trained on proprietary datasets, it may not be practical to assume that in-distribution samples will always be available. On the other hand, model inversion techniques, which are typically viewed as privacy threats, can reconstruct realistic training samples from a given model, potentially eliminating the need for in-distribution data. To date, the only prior attempt to integrate backdoor removal and model inversion involves a simple combination that produced very limited results. This work represents a first step toward a more thorough understanding of how model inversion techniques could be leveraged for effective backdoor removal. Specifically, we seek to answer several key questions: What properties must reconstructed samples possess to enable successful defense? Is perceptual similarity to clean samples enough, or are additional characteristics necessary? Is it possible for reconstructed samples to contain backdoor triggers? We demonstrate that relying solely on perceptual similarity is insufficient for effective defenses. The stability of model predictions in response to input and parameter perturbations also plays a critical role. To address this, we propose a new bi-level optimization based framework for model inversion that promotes stability in addition to visual quality. Interestingly, we also find that reconstructed samples from a pre-trained generator's latent space do not contain backdoors, even when signals from a backdoored model are utilized for reconstruction. We provide a theoretical analysis to explain this observation. Our evaluation shows that our stabilized model inversion technique achieves state-of-the-art backdoor removal performance without requiring access to clean in-distribution data. Furthermore, its performance is on par with or even better than using the same amount of clean samples",
    "checked": true,
    "id": "f65c2209859b8de0bd7edbfeacbe62e263af6bd7",
    "semantic_title": "turning a curse into a blessing: enabling in-distribution-data-free backdoor removal via stabilized model inversion",
    "citation_count": 3,
    "authors": [
      "Si Chen",
      "Yi Zeng",
      "Won Park",
      "Jiachen T. Wang",
      "Xun Chen",
      "Lingjuan Lyu",
      "Zhuoqing Mao",
      "Ruoxi Jia"
    ]
  },
  "https://openreview.net/forum?id=8koy8QuTZD": {
    "title": "Momentum Tracking: Momentum Acceleration for Decentralized Deep Learning on Heterogeneous Data",
    "volume": "main",
    "abstract": "SGD with momentum is one of the key components for improving the performance of neural networks. For decentralized learning, a straightforward approach using momentum is Distributed SGD (DSGD) with momentum (DSGDm). However, DSGDm performs worse than DSGD when the data distributions are statistically heterogeneous. Recently, several studies have addressed this issue and proposed methods with momentum that are more robust to data heterogeneity than DSGDm, although their convergence rates remain dependent on data heterogeneity and deteriorate when the data distributions are heterogeneous. In this study, we propose Momentum Tracking, which is a method with momentum whose convergence rate is proven to be independent of data heterogeneity. More specifically, we analyze the convergence rate of Momentum Tracking in the setting where the objective function is non-convex and the stochastic gradient is used. Then, we identify that it is independent of data heterogeneity for any momentum coefficient $\\beta \\in [0, 1)$. Through experiments, we demonstrate that Momentum Tracking is more robust to data heterogeneity than the existing decentralized learning methods with momentum and can consistently outperform these existing methods when the data distributions are heterogeneous",
    "checked": true,
    "id": "fabf58a766313f3f7088e95c53233a1e3fd0ef6f",
    "semantic_title": "momentum tracking: momentum acceleration for decentralized deep learning on heterogeneous data",
    "citation_count": 20,
    "authors": [
      "Yuki Takezawa",
      "Han Bao",
      "Kenta Niwa",
      "Ryoma Sato",
      "Makoto Yamada"
    ]
  },
  "https://openreview.net/forum?id=KQ5jI19kF3": {
    "title": "Optimistic Optimization of Gaussian Process Samples",
    "volume": "main",
    "abstract": "Bayesian optimization is a popular formalism for global optimization, but its computational costs limit it to expensive-to-evaluate functions. A competing, computationally more effi- cient, global optimization framework is optimistic optimization, which exploits prior knowl- edge about the geometry of the search space in form of a dissimilarity function. We investi- gate to which degree the conceptual advantages of Bayesian Optimization can be combined with the computational efficiency of optimistic optimization. By mapping the kernel to a dissimilarity, we obtain an optimistic optimization algorithm for the Bayesian Optimization setting with a run-time of up to $O(N log N )$. As a high-level take-away we find that, when using stationary kernels on objectives of low evaluation cost, optimistic optimization can be preferable over Bayesian optimization, while for strongly coupled and parametric models, Bayesian optimization can perform much better, even at low evaluation cost. As a concep- tual takeaway, our results demonstrate that balancing exploration and exploitation under Gaussian process assumptions does not require computing a posterior",
    "checked": true,
    "id": "5d3af1d038b1057c319038e896a6fd96c40a764a",
    "semantic_title": "optimistic optimization of gaussian process samples",
    "citation_count": 0,
    "authors": [
      "Julia Grosse",
      "Cheng Zhang",
      "Philipp Hennig"
    ]
  },
  "https://openreview.net/forum?id=xoLyps2qWc": {
    "title": "Linearized Relative Positional Encoding",
    "volume": "main",
    "abstract": "Relative positional encoding is widely used in vanilla and linear transformers to represent positional information. However, existing encoding methods of a vanilla transformer are not always directly applicable to a linear transformer, because the latter requires a decomposition of the query and key representations into separate kernel functions. Nevertheless, principles for designing encoding methods suitable for linear transformers remain understudied. In this work, we put together a variety of existing linear relative positional encoding approaches under a canonical form and further propose a family of linear relative positional encoding algorithms via unitary transformation. Our formulation leads to a principled framework that can be used to develop new relative positional encoding methods that preserve linear space-time complexity. Equipped with different models, the proposed linearized relative positional encoding (LRPE) family derives effective encoding for various applications. Experiments show that compared with existing methods, LRPE achieves state-of-the-art performance in language modeling, text classification, and image classification. Meanwhile, it emphasizes a general paradigm for designing broadly more relative positional encoding methods that are applicable to linear transformers",
    "checked": true,
    "id": "8bc8b9ae855bc0aa19e7223899440ffbdc61f4d8",
    "semantic_title": "linearized relative positional encoding",
    "citation_count": 13,
    "authors": [
      "Zhen Qin",
      "Weixuan Sun",
      "Kaiyue Lu",
      "Hui Deng",
      "Dongxu Li",
      "Xiaodong Han",
      "Yuchao Dai",
      "Lingpeng Kong",
      "Yiran Zhong"
    ]
  },
  "https://openreview.net/forum?id=oud7Ny0KQy": {
    "title": "RIFLE: Imputation and Robust Inference from Low Order Marginals",
    "volume": "main",
    "abstract": "The ubiquity of missing values in real-world datasets poses a challenge for statistical inference and can prevent similar datasets from being analyzed in the same study, precluding many existing datasets from being used for new analyses. While an extensive collection of packages and algorithms have been developed for data imputation, the overwhelming majority perform poorly if there are many missing values and low sample sizes, which are unfortunately common characteristics in empirical data. Such low-accuracy estimations adversely affect the performance of downstream statistical models. We develop a statistical inference framework for predicting the target variable in the presence of missing data without imputation. Our framework, RIFLE (Robust InFerence via Low-order moment Estimations), estimates low-order moments of the underlying data distribution with corresponding confidence intervals to learn a distributionally robust model. We specialize our framework to linear regression and normal discriminant analysis, and we provide convergence and performance guarantees. This framework can also be adapted to impute missing data. We compare RIFLE with state-of-the-art approaches (including MICE, Amelia, MissForest, KNN-imputer, MIDA, and Mean Imputer) in numerical experiments. Our experiments demonstrate that RIFLE outperforms other benchmark algorithms when the percentage of missing values is high and/or when the number of data points is relatively small. RIFLE is publicly available",
    "checked": true,
    "id": "d0c854843e362856b46ace44c484310ab33616e2",
    "semantic_title": "rifle: imputation and robust inference from low order marginals",
    "citation_count": 5,
    "authors": [
      "Sina Baharlouei",
      "Sze-Chuan Suen",
      "Meisam Razaviyayn"
    ]
  },
  "https://openreview.net/forum?id=zkRCp4RmAF": {
    "title": "Offline Reinforcement Learning with Mixture of Deterministic Policies",
    "volume": "main",
    "abstract": "Offline reinforcement learning (RL) has recently attracted considerable attention as an approach for utilizing past experiences to learn a policy. Recent studies have reported the challenges of offline RL, such as estimating the values of actions that are outside the data distribution. To mitigate offline RL issues, we propose an algorithm that leverages a mixture of deterministic policies. When the data distribution is multimodal, fitting a policy modeled with a unimodal distribution, such as Gaussian distribution, may lead to interpolation between separate modes, thereby resulting in the value estimation of actions that are outside the data distribution. In our framework, the state-action space is divided by learning discrete latent variables, and the sub-policies corresponding to each region are trained. The proposed algorithm was derived by considering the variational lower bound of the offline RL objective function. We show empirically that the use of the proposed mixture policy can reduce the accumulation of the critic loss in offline RL, which was reported in previous studies. Experimental results also indicate that using a mixture of deterministic policies in offline RL improves the performance with the D4RL benchmarking datasets",
    "checked": true,
    "id": "7950a565d8fb5d26d0987a2e3ac336abd9f62581",
    "semantic_title": "offline reinforcement learning with mixture of deterministic policies",
    "citation_count": 5,
    "authors": [
      "Takayuki Osa",
      "Akinobu Hayashi",
      "Pranav Deo",
      "Naoki Morihira",
      "Takahide Yoshiike"
    ]
  },
  "https://openreview.net/forum?id=lvevdX6bxm": {
    "title": "Quantization Robust Federated Learning for Efficient Inference on Heterogeneous Devices",
    "volume": "main",
    "abstract": "Federated Learning (FL) is a machine learning paradigm to distributively learn machine learning models from decentralized data that remains on-device. Despite the success of standard Federated optimization methods, such as Federated Averaging (FedAvg) in FL, the energy demands and hardware induced constraints for on-device learning have not been considered sufficiently in the literature. Specifically, an essential demand for on-device learning is to enable trained models to be quantized to various bit-widths based on the energy needs and heterogeneous hardware designs across the federation. In this work, we introduce multiple variants of federated averaging algorithm that train neural networks robust to quantization. Such networks can be quantized to various bit-widths with only limited reduction in full precision model accuracy. We perform extensive experiments on standard FL benchmarks to evaluate our proposed FedAvg variants for quantization robustness and provide a convergence analysis for our Quantization-Aware variants in FL. Our results demonstrate that integrating quantization robustness results in FL models that are significantly more robust to different bit-widths during quantized on-device inference",
    "checked": true,
    "id": "b253022a77ebf30d4a5964d68087d9ff9860b4d4",
    "semantic_title": "quantization robust federated learning for efficient inference on heterogeneous devices",
    "citation_count": 17,
    "authors": [
      "Kartik Gupta",
      "Marios Fournarakis",
      "Matthias Reisser",
      "Christos Louizos",
      "Markus Nagel"
    ]
  },
  "https://openreview.net/forum?id=wRepWp1KC7": {
    "title": "Fair and Useful Cohort Selection",
    "volume": "main",
    "abstract": "A challenge in fair algorithm design is that, while there are compelling notions of individual fairness, these notions typically do not satisfy desirable composition properties, and downstream applications based on fair classifiers might not preserve fairness. To study fairness under composition, Dwork & Ilvento (2019) introduced an archetypal problem called fair-cohort-selection problem, where a single fair classifier is composed with itself to select a group of candidates of a given size, and proposed a solution to this problem. In this work we design algorithms for selecting cohorts that not only preserve fairness, but also maximize the utility of the selected cohort under two notions of utility that we introduce and motivate. We give optimal (or approximately optimal) polynomial-time algorithms for this problem in both an offline setting, and an online setting where candidates arrive one at a time and are classified as they arrive",
    "checked": false,
    "id": "a46b28076aee58e200cb7421b6f8af9991e293a5",
    "semantic_title": "enhancing students' engagement and learning through peer assessment in group projects",
    "citation_count": 2,
    "authors": [
      "Konstantina Bairaktari",
      "Paul Tsela Langton",
      "Huy Nguyen",
      "Niklas Smedemark-Margulies",
      "Jonathan Ullman"
    ]
  },
  "https://openreview.net/forum?id=vgXnEyeWVY": {
    "title": "Walking Out of the Weisfeiler Leman Hierarchy: Graph Learning Beyond Message Passing",
    "volume": "main",
    "abstract": "We propose CRaWl, a novel neural network architecture for graph learning. Like graph neural networks, CRaWl layers update node features on a graph and thus can freely be combined or interleaved with GNN layers. Yet CRaWl operates fundamentally different from message passing graph neural networks. CRaWl layers extract and aggregate information on subgraphs appearing along random walks through a graph using 1D Convolutions. Thereby it detects long range interactions and computes non-local features. As the theoretical basis for our approach, we prove a theorem stating that the expressiveness of CRaWl is incomparable with that of the Weisfeiler Leman algorithm and hence with graph neural networks. That is, there are functions expressible by CRaWl, but not by GNNs and vice versa. This result extends to higher levels of the Weisfeiler Leman hierarchy and thus to higher-order GNNs. Empirically, we show that CRaWl matches state-of-the-art GNN architectures across a multitude of benchmark datasets for classification and regression on graphs",
    "checked": true,
    "id": "ceb26d1f1a888a58190f8d2d33b2c2d0539a1523",
    "semantic_title": "walking out of the weisfeiler leman hierarchy: graph learning beyond message passing",
    "citation_count": 34,
    "authors": [
      "Jan Tönshoff",
      "Martin Ritzert",
      "Hinrikus Wolf",
      "Martin Grohe"
    ]
  },
  "https://openreview.net/forum?id=xWrtiJwJj5": {
    "title": "Global Contrastive Learning for Long-Tailed Classification",
    "volume": "main",
    "abstract": "We consider the long-tailed classification problem in which a few classes in the training data dominate the majority of the other classes. For concreteness, we focus on the visual domain in this paper. Most current methods employ contrastive learning to learn a representation for long-tailed data. In this paper, first, we investigate $k$-positive sampling, a popular baseline method widely used to build contrastive learning models for imbalanced data. Previous works show that $k$-positive learning, which only chooses $k$ positive samples (instead of all positive images) for each query image, suffers from inferior performance in long-tailed data. In this work, we further point out that k-positive learning limits the learning capability of both head and tail classes. Based on this perspective, we propose a novel contrastive learning framework that improves the limitation in k-positive learning by enlarging its positive selection space, so it can help the model learn more semantic discrimination features. Second, we analyze how the temperature (the hyperparameter used for tuning a concentration of samples on feature space) affects the gradients of each class in long-tailed learning, and propose a new method that can mitigate inadequate gradients between classes, which can help model learning easier. We name this framework as CoGloAT. Finally, we go on to introduce a new prototype learning framework namely ProCo based on coreset selection, which creates a global prototype for each cluster while keeping the computation cost within a reasonable time and show that combining CoGloAT with ProCo can further enhance the model learning ability on long-tailed data",
    "checked": true,
    "id": "684514104a254f08e41826edf5788c09a3004dff",
    "semantic_title": "global contrastive learning for long-tailed classification",
    "citation_count": 0,
    "authors": [
      "Thong Bach",
      "Anh Tong",
      "Truong Son Hy",
      "Vu Nguyen",
      "Thanh Nguyen-Tang"
    ]
  },
  "https://openreview.net/forum?id=KpElM2S9pw": {
    "title": "Approximating Naive Bayes on Unlabelled Categorical Data",
    "volume": "main",
    "abstract": "We address the question of binary classification when no labels are available and the input features are categorical. The lack of labels means supervised approaches can't be used, and the lack of a natural distance measure means that most unsupervised methods do poorly. For such problems, where the alternatives might be a) do nothing or b) heuristic rules-based approaches, we offer a third alternative: a classifier that approximates Naive Bayes. Our primary scenarios are those that involve distinguishing scripted, or bot, web traffic from that of legitimate users. Our main assumption is the existence of some attribute $x_*$ more prevalent in the benign than the scripted traffic; i.e., $P(x_*|\\overline{\\mbox{bot}}) = K \\cdot P(x_*|\\mbox{bot}),$ for $K>1.$ We show that any such disparity yields a lower bound on $P(\\mbox{bot}|x_{j})$ even when we have no prior estimates of $P(x_*|\\overline{\\mbox{bot}}),$ $P(x_*|\\mbox{bot})$ or $K$ (except that $K>1$). We show that when at least one bin of at least one feature receives no attack traffic then we under-estimate the actual conditional probability by a factor of $1-1/K.$ Thus, any attribute with a large disparity between prevalence in benign and abuse traffic (i.e., $K$ is large), allows good approximation of the Naive Bayes classifier without the benefit of labels. The approach is particularly suited to problems where $K$ is high and thus the approximation is very accurate. Example problems (and relevant attributes) might be: password-guessing, if login attempts from legitimate users succeed at a much higher rate than those from password-guessing attackers; Credit Card Verification Value (CVV) guessing, if an attacker exhaustively tries all possible 3 or 4-digit values and fails at a higher rate than legitimate users; account registration, if legitimate users use email addresses from services that do not allow fee anonymous accounts (e.g., {\\tt .edu}) at a much higher rate than attackers; click-fraud if legitimate users visit pages and services that contain no ads at a higher rate than click-fraud bots",
    "checked": true,
    "id": "2efeffd9aa3d78e64c7f9959646b967ed4edf6eb",
    "semantic_title": "approximating naive bayes on unlabelled categorical data",
    "citation_count": 0,
    "authors": [
      "Cormac Herley"
    ]
  },
  "https://openreview.net/forum?id=uaHyXxyp2r": {
    "title": "Weight-balancing fixes and flows for deep learning",
    "volume": "main",
    "abstract": "Feedforward neural networks with homogeneous activation functions possess an internal symmetry: the functions they compute do not change when the incoming and outgoing weights at any hidden unit are rescaled by reciprocal positive values. This paper makes two contributions to our understanding of these networks. The first is to describe a simple procedure, or {\\it fix}, for balancing the weights in these networks: this procedure computes multiplicative rescaling factors---one at each hidden unit---that rebalance the weights of these networks without changing the end-to-end functions that they compute. Specifically, given an initial network with arbitrary weights, the procedure determines the functionally equivalent network whose weight matrix is of minimal $\\ell_{p,q}$-norm; the weights at each hidden unit are said to be balanced when this norm is stationary with respect to rescaling transformations. The optimal rescaling factors are computed in an iterative fashion via simple multiplicative updates, and the updates are notable in that (a) they do not require the tuning of learning rates, (b) they operate in parallel on the rescaling factors at all hidden units, and (c) they converge monotonically to a global minimizer of the $\\ell_{p,q}$-norm. The paper's second contribution is to analyze the optimization landscape for learning in these networks. We suppose that the network's loss function consists of two terms---one that is invariant to rescaling transformations, measuring predictive accuracy, and another (a regularizer) that breaks this invariance, penalizing large weights. We show how to derive a weight-balancing {\\it flow} such that the regularizer remains minimal with respect to rescaling transformations as the weights descend in the loss function. These dynamics reduce to an ordinary gradient flow for $\\ell_2$-norm regularization, but not otherwise. In this way our analysis suggests a canonical pairing of alternative flows and regularizers",
    "checked": true,
    "id": "a78c53259ea22c0b49268dc72c6f5091811aed56",
    "semantic_title": "weight-balancing fixes and flows for deep learning",
    "citation_count": 6,
    "authors": [
      "Lawrence K. Saul"
    ]
  },
  "https://openreview.net/forum?id=lOegPKSu04": {
    "title": "$k$-Mixup Regularization for Deep Learning via Optimal Transport",
    "volume": "main",
    "abstract": "Mixup is a popular regularization technique for training deep neural networks that improves generalization and increases robustness to certain distribution shifts. It perturbs input training data in the direction of other randomly-chosen instances in the training set. To better leverage the structure of the data, we extend mixup in a simple, broadly applicable way to $k$-mixup, which perturbs $k$-batches of training points in the direction of other $k$-batches. The perturbation is done with displacement interpolation, i.e. interpolation under the Wasserstein metric. We demonstrate theoretically and in simulations that $k$-mixup preserves cluster and manifold structures, and we extend theory studying the efficacy of standard mixup to the $k$-mixup case. Our empirical results show that training with $k$-mixup further improves generalization and robustness across several network architectures and benchmark datasets of differing modalities. For the wide variety of real datasets considered, the performance gains of $k$-mixup over standard mixup are similar to or larger than the gains of mixup itself over standard ERM after hyperparameter optimization. In several instances, in fact, $k$-mixup achieves gains in settings where standard mixup has negligible to zero improvement over ERM",
    "checked": false,
    "id": "3c25c031c93ca1808fcb0923a7b6f89e78ed9a65",
    "semantic_title": "k-mixup regularization for deep learning via optimal transport",
    "citation_count": 19,
    "authors": [
      "Kristjan Greenewald",
      "Anming Gu",
      "Mikhail Yurochkin",
      "Justin Solomon",
      "Edward Chien"
    ]
  },
  "https://openreview.net/forum?id=0Xo9giEZWf": {
    "title": "HypUC: Hyperfine Uncertainty Calibration with Gradient- boosted Corrections for Reliable Regression on Imbalanced Electrocardiograms",
    "volume": "main",
    "abstract": "The automated analysis of medical time series, such as the electrocardiogram (ECG), electroencephalogram (EEG), pulse oximetry, etc, has the potential to serve as a valuable tool for diagnostic decisions, allowing for remote monitoring of patients and more efficient use of expensive and time-consuming medical procedures. Deep neural networks (DNNs) have been demonstrated to process such signals effectively. However, previous research has primarily focused on classifying medical time series rather than attempting to regress the continuous-valued physiological parameters central to diagnosis. One significant challenge in this regard is the imbalanced nature of the dataset, as a low prevalence of abnormal conditions can lead to heavily skewed data that results in inaccurate predictions and a lack of certainty in such predictions when deployed. To address these challenges, we propose HypUC, a framework for imbalanced probabilistic regression in medical time series, making several contributions. (i) We introduce a simple kernel density-based technique to tackle the imbalanced regression problem with medical time series. (ii) Moreover, we employ a probabilistic regression framework that allows uncertainty estimation for the predicted continuous values. (iii) We also present a new approach to calibrate the predicted uncertainty further. (iv) Finally, we demonstrate a technique to use calibrated uncertainty estimates to improve the predicted continuous value and show the efficacy of the calibrated uncertainty estimates to flag unreliable predictions. HypUC is evaluated on a large, diverse, real-world dataset of ECGs collected from millions of patients, outperforming several conventional baselines on various diagnostic tasks, suggesting potential use-case for the reliable clinical deployment of deep learning models and a prospective clinical trial. Consequently, a hyperkalemia diagnosis algorithm based on HypUC is going to be the subject of a real-world clinical prospective study",
    "checked": false,
    "id": "e2b4d10d0b8de66ba072b730b44fc3eb19081311",
    "semantic_title": "hypuc: hyperfine uncertainty calibration with gradient-boosted corrections for reliable regression on imbalanced electrocardiograms",
    "citation_count": 3,
    "authors": [
      "Uddeshya Upadhyay",
      "Sairam Bade",
      "Arjun Puranik",
      "Shahir Asfahan",
      "Melwin Babu",
      "Francisco Lopez-Jimenez",
      "Samuel Asirvatham",
      "Ashim Prasad",
      "Ajit Rajasekharan",
      "Samir Awasthi",
      "Rakesh Barve"
    ]
  },
  "https://openreview.net/forum?id=wbpxTuXgm0": {
    "title": "TSMixer: An All-MLP Architecture for Time Series Forecast-ing",
    "volume": "main",
    "abstract": "Real-world time-series datasets are often multivariate with complex dynamics. To capture this complexity, high capacity architectures like recurrent- or attention-based sequential deep learning models have become popular. However, recent work demonstrates that simple univariate linear models can outperform such deep learning models on several commonly used academic benchmarks. Extending them, in this paper, we investigate the capabilities of linear models for time-series forecasting and present Time-Series Mixer (TSMixer), a novel architecture designed by stacking multi-layer perceptrons (MLPs). TSMixer is based on mixing operations along both the time and feature dimensions to extract information efficiently. On popular academic benchmarks, the simple-to-implement TSMixer is comparable to specialized state-of-the-art models that leverage the inductive biases of specific benchmarks. On the challenging and large scale M5 benchmark, a real-world retail dataset, TSMixer demonstrates superior performance compared to the state-of-the-art alternatives. Our results underline the importance of efficiently utilizing cross-variate and auxiliary information for improving the performance of time series forecasting. We present various analyses to shed light into the capabilities of TSMixer. The design paradigms utilized in TSMixer are expected to open new horizons for deep learning-based time series forecasting",
    "checked": false,
    "id": "59694c8dce4f13db2f486eb8102459a3f7c23da6",
    "semantic_title": "tsmixer: an all-mlp architecture for time series forecasting",
    "citation_count": 208,
    "authors": [
      "Si-An Chen",
      "Chun-Liang Li",
      "Sercan O Arik",
      "Nathanael Christian Yoder",
      "Tomas Pfister"
    ]
  },
  "https://openreview.net/forum?id=ScrEUZLxPr": {
    "title": "Revisiting Hidden Representations in Transfer Learning for Medical Imaging",
    "volume": "main",
    "abstract": "While a key component to the success of deep learning is the availability of massive amounts of training data, medical image datasets are often limited in diversity and size. Transfer learning has the potential to bridge the gap between related yet different domains. For medical applications, however, it remains unclear whether it is more beneficial to pre-train on natural or medical images. We aim to shed light on this problem by comparing initialization on ImageNet and RadImageNet on seven medical classification tasks. Our work includes a replication study, which yields results contrary to previously published findings. In our experiments, ResNet50 models pre-trained on ImageNet tend to outperform those trained on RadImageNet. To gain further insights, we investigate the learned representations using Canonical Correlation Analysis (CCA) and compare the predictions of the different models. Our results indicate that, contrary to intuition, ImageNet and RadImageNet may converge to distinct intermediate representations, which appear to diverge further during fine-tuning. Despite these distinct representations, the predictions of the models remain similar. Our findings show that the similarity between networks before and after fine-tuning does not correlate with performance gains, suggesting that the advantages of transfer learning might not solely originate from the reuse of features in the early layers of a convolutional neural network",
    "checked": true,
    "id": "f10a7d49d67d292e03e8f8185310147b4e6fdebc",
    "semantic_title": "revisiting hidden representations in transfer learning for medical imaging",
    "citation_count": 1,
    "authors": [
      "Dovile Juodelyte",
      "Amelia Jiménez-Sánchez",
      "Veronika Cheplygina"
    ]
  },
  "https://openreview.net/forum?id=VrvGHDSzZ7": {
    "title": "The Geometry of Mixability",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5c13e876605fa2e46518ac5ebbd5f2d44d9b425e",
    "semantic_title": "the geometry of mixability",
    "citation_count": 3,
    "authors": [
      "Armando J Cabrera Pacheco",
      "Robert Williamson"
    ]
  },
  "https://openreview.net/forum?id=hjDYJUn9l1": {
    "title": "Evaluating Human-Language Model Interaction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a640cdafc10181517b7694ab589db515595b3490",
    "semantic_title": "evaluating human-language model interaction",
    "citation_count": 102,
    "authors": [
      "Mina Lee",
      "Megha Srivastava",
      "Amelia Hardy",
      "John Thickstun",
      "Esin Durmus",
      "Ashwin Paranjape",
      "Ines Gerard-Ursin",
      "Xiang Lisa Li",
      "Faisal Ladhak",
      "Frieda Rong",
      "Rose E Wang",
      "Minae Kwon",
      "Joon Sung Park",
      "Hancheng Cao",
      "Tony Lee",
      "Rishi Bommasani",
      "Michael S. Bernstein",
      "Percy Liang"
    ]
  },
  "https://openreview.net/forum?id=2uMnAwWnRy": {
    "title": "Benchmarking Continuous Time Models for Predicting Multiple Sclerosis Progression",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dc1ced0efc9bfee96b2e37580f5a17f4892acbda",
    "semantic_title": "benchmarking continuous time models for predicting multiple sclerosis progression",
    "citation_count": 2,
    "authors": [
      "Alexander Luke Ian Norcliffe",
      "Lev Proleev",
      "Diana Mincu",
      "F Lee Hartsell",
      "Katherine A Heller",
      "Subhrajit Roy"
    ]
  },
  "https://openreview.net/forum?id=ZPpQk7FJXF": {
    "title": "Differentially Private Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9dea2c15a044a3c83d0d66b9c3daa91d457d905f",
    "semantic_title": "differentially private diffusion models",
    "citation_count": 106,
    "authors": [
      "Tim Dockhorn",
      "Tianshi Cao",
      "Arash Vahdat",
      "Karsten Kreis"
    ]
  },
  "https://openreview.net/forum?id=JaNlH6dZYk": {
    "title": "On the special role of class-selective neurons in early training",
    "volume": "main",
    "abstract": "It is commonly observed that deep networks trained for classification exhibit class-selective neurons in their early and intermediate layers. Intriguingly, recent studies have shown that these class-selective neurons can be ablated without deteriorating network function. But if class-selective neurons are not necessary, why do they exist? We attempt to answer this question in a series of experiments on ResNet-50s trained on ImageNet. We first show that class-selective neurons emerge during the first few epochs of training, before receding rapidly but not completely; this suggests that class-selective neurons found in trained networks are in fact vestigial remains of early training. With single-neuron ablation experiments, we then show that class-selective neurons are important for network function in this early phase of training. We also observe that the network is close to a linear regime in this early phase; we thus speculate that class-selective neurons appear early in training as quasi-linear shortcut solutions to the classification task. Finally, in causal experiments where we regularize against class selectivity at different points in training, we show that the presence of class-selective neurons early in training is critical to the successful training of the network; in contrast, class-selective neurons can be suppressed later in training with little effect on final accuracy. It remains to be understood by which mechanism the presence of class-selective neurons in the early phase of training contributes to the successful training of networks",
    "checked": true,
    "id": "6fbbe8a5554a3fbc003f288c954c2e66ef4c854d",
    "semantic_title": "on the special role of class-selective neurons in early training",
    "citation_count": 3,
    "authors": [
      "Omkar Ranadive",
      "Nikhil Thakurdesai",
      "Ari S. Morcos",
      "Matthew L Leavitt",
      "Stephane Deny"
    ]
  },
  "https://openreview.net/forum?id=MgdoxzImlK": {
    "title": "Multi-annotator Deep Learning: A Probabilistic Framework for Classification",
    "volume": "main",
    "abstract": "Solving complex classification tasks using deep neural networks typically requires large amounts of annotated data. However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowdworkers. Training standard deep neural networks leads to subpar performances in such multi-annotator supervised learning settings. We address this issue by presenting a probabilistic training framework named multi-annotator deep learning (MaDL). A downstream ground truth and an annotator performance model are jointly trained in an end-to-end learning approach. The ground truth model learns to predict instances' true class labels, while the annotator performance model infers probabilistic estimates of annotators' performances. A modular network architecture enables us to make varying assumptions regarding annotators' performances, e.g., an optional class or instance dependency. Further, we learn annotator embeddings to estimate annotators' densities within a latent space as proxies of their potentially correlated annotations. Together with a weighted loss function, we improve the learning from correlated annotation patterns. In a comprehensive evaluation, we examine three research questions about multi-annotator supervised learning. Our findings show MaDL's state-of-the-art performance and robustness against many correlated, spamming annotators",
    "checked": true,
    "id": "a6f09f3e6fb8d07cc06876714afe2861c457edfa",
    "semantic_title": "multi-annotator deep learning: a probabilistic framework for classification",
    "citation_count": 11,
    "authors": [
      "Marek Herde",
      "Denis Huseljic",
      "Bernhard Sick"
    ]
  },
  "https://openreview.net/forum?id=Ns2X7Azudy": {
    "title": "Learning to Optimize Quasi-Newton Methods",
    "volume": "main",
    "abstract": "Fast gradient-based optimization algorithms have become increasingly essential for the computationally efficient training of machine learning models. One technique is to multiply the gradient by a preconditioner matrix to produce a step, but it is unclear what the best preconditioner matrix is. This paper introduces a novel machine learning optimizer called LODO, which tries to online meta-learn the best preconditioner during optimization. Specifically, our optimizer merges Learning to Optimize (L2O) techniques with quasi-Newton methods to learn preconditioners parameterized as neural networks; they are more flexible than preconditioners in other quasi-Newton methods. Unlike other L2O methods, LODO does not require any meta-training on a training task distribution, and instead learns to optimize on the fly while optimizing on the test task, adapting to the local characteristics of the loss landscape while traversing it. Theoretically, we show that our optimizer approximates the inverse Hessian in noisy loss landscapes and is capable of representing a wide range of inverse Hessians. We experimentally verify that our algorithm can optimize in noisy settings, and show that simpler alternatives for representing the inverse Hessians worsen performance. Lastly, we use our optimizer to train a semi-realistic deep neural network with 95k parameters at speeds comparable to those of standard neural network optimizers",
    "checked": true,
    "id": "17d5196926077fc4343bdb6bc1724ee65f945fe4",
    "semantic_title": "learning to optimize quasi-newton methods",
    "citation_count": 4,
    "authors": [
      "Isaac Liao",
      "Rumen Dangovski",
      "Jakob Nicolaus Foerster",
      "Marin Soljacic"
    ]
  },
  "https://openreview.net/forum?id=SSkTBUyJip": {
    "title": "Task Weighting in Meta-learning with Trajectory Optimisation",
    "volume": "main",
    "abstract": "Developing meta-learning algorithms that are un-biased toward a subset of training tasks often requires hand-designed criteria to weight tasks, potentially resulting in sub-optimal solutions. In this paper, we introduce a new principled and fully-automated task-weighting algorithm for meta-learning methods. By considering the weights of tasks within the same mini-batch as an action, and the meta-parameter of interest as the system state, we cast the task-weighting meta-learning problem to a trajectory optimisation and employ the iterative linear quadratic regulator to determine the optimal action or weights of tasks. We theoretically show that the proposed algorithm converges to an $\\epsilon_{0}$-stationary point, and empirically demonstrate that the proposed approach out-performs common hand-engineering weighting methods in two few-shot learning benchmarks",
    "checked": true,
    "id": "ce854cd64758ec023d34fe129eaf02f17e0d5108",
    "semantic_title": "task weighting in meta-learning with trajectory optimisation",
    "citation_count": 3,
    "authors": [
      "Cuong C. Nguyen",
      "Thanh-Toan Do",
      "Gustavo Carneiro"
    ]
  },
  "https://openreview.net/forum?id=lNB5EHx8uC": {
    "title": "Cyclic and Randomized Stepsizes Invoke Heavier Tails in SGD than Constant Stepsize",
    "volume": "main",
    "abstract": "Cyclic and randomized stepsizes are widely used in the deep learning practice and can often outperform standard stepsize choices such as constant stepsize in SGD. Despite their empirical success, not much is currently known about when and why they can theoretically improve the generalization performance. We consider a general class of Markovian stepsizes for learning, which contain i.i.d. random stepsize, cyclic stepsize as well as the constant stepsize as special cases, and motivated by the literature which shows that heaviness of the tails (measured by the so-called ``tail-index\") in the SGD iterates is correlated with generalization, we study tail-index and provide a number of theoretical results that demonstrate how the tail-index varies on the stepsize scheduling. Our results bring a new understanding of the benefits of cyclic and randomized stepsizes compared to constant stepsize in terms of the tail behavior. We illustrate our theory on linear regression experiments and show through deep learning experiments that Markovian stepsizes can achieve even a heavier tail and be a viable alternative to cyclic and i.i.d. randomized stepsize rules",
    "checked": false,
    "id": "c734607dfd1735d9d2657f37f9f3697117252019",
    "semantic_title": "cyclic and randomized stepsizes invoke heavier tails in sgd",
    "citation_count": 1,
    "authors": [
      "Mert Gurbuzbalaban",
      "Yuanhan Hu",
      "Umut Simsekli",
      "Lingjiong Zhu"
    ]
  },
  "https://openreview.net/forum?id=2TneniEIDB": {
    "title": "A probabilistic Taylor expansion with Gaussian processes",
    "volume": "main",
    "abstract": "We study a class of Gaussian processes for which the posterior mean, for a particular choice of data, replicates a truncated Taylor expansion of any order. The data consist of derivative evaluations at the expansion point and the prior covariance kernel belongs to the class of Taylor kernels, which can be written in a certain power series form. We discuss and prove some results on maximum likelihood estimation of parameters of Taylor kernels. The proposed framework is a special case of Gaussian process regression based on data that is orthogonal in the reproducing kernel Hilbert space of the covariance kernel",
    "checked": true,
    "id": "b8f0221d2bcf1b7aa71b5ecf724d8f63ee391a02",
    "semantic_title": "a probabilistic taylor expansion with gaussian processes",
    "citation_count": 1,
    "authors": [
      "Toni Karvonen",
      "Jon Cockayne",
      "Filip Tronarp",
      "Simo Särkkä"
    ]
  },
  "https://openreview.net/forum?id=BFvoemrmqX": {
    "title": "Bridging the Gap Between Target Networks and Functional Regularization",
    "volume": "main",
    "abstract": "Bootstrapping is behind much of the successes of deep Reinforcement Learning. However, learning the value function via bootstrapping often leads to unstable training due to fast-changing target values. Target Networks are employed to stabilize training by using an additional set of lagging parameters to estimate the target values. Despite the popularity of Target Networks, their effect on the optimization is still misunderstood. In this work, we show that they act as an implicit regularizer which can be beneficial in some cases, but also have disadvantages such as being inflexible and can result in instabilities, even when vanilla TD(0) converges. To overcome these issues, we propose an explicit Functional Regularization alternative that is flexible and a convex regularizer in function space and we theoretically study its convergence. We conducted an experimental study across a range of environments, discount factors, and off-policiness data collections to investigate the effectiveness of the regularization induced by Target Networks and Functional Regularization in terms of performance, accuracy, and stability. Our findings emphasize that Functional Regularization can be used as a drop-in replacement for Target Networks and result in performance improvement. Furthermore, adjusting both the regularization weight and the network update period in Functional Regularization can result in further performance improvements compared to solely adjusting the network update period as typically done with Target Networks. Our approach also enhances the ability to networks to recover accurate $Q$-values",
    "checked": true,
    "id": "187f444fd816f2c613f827464d9c2184288c1c3a",
    "semantic_title": "bridging the gap between target networks and functional regularization",
    "citation_count": 3,
    "authors": [
      "Alexandre Piché",
      "Valentin Thomas",
      "Joseph Marino",
      "Rafael Pardinas",
      "Gian Maria Marconi",
      "Christopher Pal",
      "Mohammad Emtiyaz Khan"
    ]
  },
  "https://openreview.net/forum?id=4ofFo7D5GL": {
    "title": "HERMES: Hybrid Error-corrector Model with inclusion of External Signals for nonstationary fashion time series",
    "volume": "main",
    "abstract": "Developing models and algorithms to predict nonstationary time series is a long standing statistical problem. It is crucial for many applications, in particular for fashion or retail industries, to make optimal inventory decisions and avoid massive wastes. By tracking thousands of fashion trends on social media with state-of-the-art computer vision approaches, we propose a new model for fashion time series forecasting. Our contribution is twofold. We first provide publicly a dataset gathering 10000 weekly fashion time series. As influence dynamics are the key of emerging trend detection, we associate with each time series an external weak signal representing behaviours of influencers. Secondly, to leverage such a dataset, we propose a new hybrid forecasting mode. Our approach combines per-time-series parametric models with seasonal components and a global recurrent neural network to include sporadic external signals. This hybrid model provides state-of-the-art results on the proposed fashion dataset, on the weekly time series of the M4 competition, and illustrates the benefit of the contribution of external weak signals",
    "checked": true,
    "id": "44a57c2226a876f1bccf7362d3eb8fd39821c5e6",
    "semantic_title": "hermes: hybrid error-corrector model with inclusion of external signals for nonstationary fashion time series",
    "citation_count": 2,
    "authors": [
      "Etienne David",
      "Jean Bellot",
      "Sylvain Le Corff"
    ]
  },
  "https://openreview.net/forum?id=QoRo9QmOAr": {
    "title": "Detecting incidental correlation in multimodal learning via latent variable modeling",
    "volume": "main",
    "abstract": "Multimodal neural networks often fail to utilize all modalities. They subsequently generalize worse than their unimodal counterparts, or make predictions that only depend on a subset of modalities. We refer to this problem as \\emph{modality underutilization}. Existing work has addressed this issue by ensuring that there are no systematic biases in dataset creation, or that our neural network architectures and optimization algorithms are capable of learning modality interactions. We demonstrate that even when these favorable conditions are met, modality underutilization can still occur in the small data regime. To explain this phenomenon, we put forth a concept that we call \\emph{incidental correlation}. It is a spurious correlation that emerges in small datasets, despite not being a part of the underlying data generating process (DGP). We develop our argument using a DGP under which multimodal neural networks must utilize all modalities, since all paths between the inputs and target are causal. This represents an idealized scenario that often fails to materialize. Instead, due to incidental correlation, small datasets sampled from this DGP have higher likelihood under an alternative DGP with spurious paths between the inputs and target. Multimodal neural networks that use these spurious paths for prediction fail to utilize all modalities. Given its harmful effects, we propose to detect incidental correlation via latent variable modeling. We specify an identifiable variational autoencoder such that the latent posterior encodes the spurious correlations between the inputs and target. This allows us to interpret the Kullback-Leibler divergence between the latent posterior and prior as the severity of incidental correlation. We use an ablation study to show that identifiability is important in this context, since we derive our conclusions from the latent posterior. Using experiments with synthetic data, as well as with VQA v2.0 and NLVR2, we demonstrate that incidental correlation emerges in the small data regime, and leads to modality underutilization. Practitioners of multimodal learning can use our method to detect whether incidental correlation is present in their datasets, and determine whether they should collect additional data",
    "checked": true,
    "id": "2e5a62dc622f67ff6adf8ebb4aecde812b6e4b28",
    "semantic_title": "detecting incidental correlation in multimodal learning via latent variable modeling",
    "citation_count": 4,
    "authors": [
      "Taro Makino",
      "Yixin Wang",
      "Krzysztof J. Geras",
      "Kyunghyun Cho"
    ]
  },
  "https://openreview.net/forum?id=ry2qgRqTOw": {
    "title": "Fast Kernel Methods for Generic Lipschitz Losses via $p$-Sparsified Sketches",
    "volume": "main",
    "abstract": "Kernel methods are learning algorithms that enjoy solid theoretical foundations while suffering from important computational limitations. Sketching, which consists in looking for solutions among a subspace of reduced dimension, is a well-studied approach to alleviate these computational burdens. However, statistically-accurate sketches, such as the Gaussian one, usually contain few null entries, such that their application to kernel methods and their non-sparse Gram matrices remains slow in practice. In this paper, we show that sparsified Gaussian (and Rademacher) sketches still produce theoretically-valid approximations while allowing for important time and space savings thanks to an efficient \\emph{decomposition trick}. To support our method, we derive excess risk bounds for both single and multiple output kernel problems, with generic Lipschitz losses, hereby providing new guarantees for a wide range of applications, from robust regression to multiple quantile regression. Our theoretical results are complemented with experiments showing the empirical superiority of our approach over state-of-the-art sketching methods",
    "checked": false,
    "id": "012fd55b8ad27f1c9998b977c8286a7ea2a452c5",
    "semantic_title": "fast kernel methods for generic lipschitz losses via p-sparsified sketches",
    "citation_count": 5,
    "authors": [
      "Tamim El Ahmad",
      "Pierre Laforgue",
      "Florence d'Alché-Buc"
    ]
  },
  "https://openreview.net/forum?id=244KePn09i": {
    "title": "Single-Pass Contrastive Learning Can Work for Both Homophilic and Heterophilic Graph",
    "volume": "main",
    "abstract": "Existing graph contrastive learning (GCL) techniques typically require two forward passes for a single instance to construct the contrastive loss, which is effective for capturing the low-frequency signals of node features. Such a dual-pass design has shown empirical success on homophilic graphs, but its effectiveness on heterophilic graphs, where directly connected nodes typically have different labels, is unknown. In addition, existing GCL approaches fail to provide strong performance guarantees. Coupled with the unpredictability of GCL approaches on heterophilic graphs, their applicability in real-world contexts is limited. Then, a natural question arises: Can we design a GCL method that works for both homophilic and heterophilic graphs with a performance guarantee? To answer this question, we theoretically study the concentration property of features obtained by neighborhood aggregation on homophilic and heterophilic graphs, introduce the single-pass graph contrastive learning loss based on the property, and provide performance guarantees for the minimizer of the loss on downstream tasks. As a direct consequence of our analysis, we implement the Single-Pass Graph Contrastive Learning method (SP-GCL). Empirically, on 14 benchmark datasets with varying degrees of homophily, the features learned by the SP-GCL can match or outperform existing strong baselines with significantly less computational overhead, which demonstrates the usefulness of our findings in real-world cases",
    "checked": true,
    "id": "98f54609e969ea01ee129148fb8b863c7f39a058",
    "semantic_title": "single-pass contrastive learning can work for both homophilic and heterophilic graph",
    "citation_count": 14,
    "authors": [
      "Haonan Wang",
      "Jieyu Zhang",
      "Qi Zhu",
      "Wei Huang",
      "Kenji Kawaguchi",
      "Xiaokui Xiao"
    ]
  },
  "https://openreview.net/forum?id=djN3TaqbdA": {
    "title": "Variational Elliptical Processes",
    "volume": "main",
    "abstract": "We present elliptical processes—a family of non-parametric probabilistic models that subsumes Gaussian processes and Student's t processes. This generalization includes a range of new heavy-tailed behaviors while retaining computational tractability. Elliptical processes are based on a representation of elliptical distributions as a continuous mixture of Gaussian distributions. We parameterize this mixture distribution as a spline normalizing flow, which we train using variational inference. The proposed form of the variational posterior enables a sparse variational elliptical process applicable to large-scale problems. We highlight advantages compared to Gaussian processes through regression and classification experiments. Elliptical processes can supersede Gaussian processes in several settings, including cases where the likelihood is non-Gaussian or when accurate tail modeling is essential",
    "checked": true,
    "id": "5724cd95dd02b0fde4a0a49f6b00cbcee7f4b151",
    "semantic_title": "variational elliptical processes",
    "citation_count": 1,
    "authors": [
      "Maria Margareta Bånkestad",
      "Jens Sjölund",
      "Jalil Taghia",
      "Thomas B. Schön"
    ]
  },
  "https://openreview.net/forum?id=PRrKOaDQtQ": {
    "title": "Mitigating Confirmation Bias in Semi-supervised Learning via Efficient Bayesian Model Averaging",
    "volume": "main",
    "abstract": "State-of-the-art (SOTA) semi-supervised learning (SSL) methods have been highly successful in leveraging a mix of labeled and unlabeled data, often via self-training or pseudo-labeling. During pseudo-labeling, the model's predictions on unlabeled data are used for training and may result in confirmation bias where the model reinforces its own mistakes. In this work, we show that SOTA SSL methods often suffer from confirmation bias and demonstrate that this is often a result of using a poorly calibrated classifier for pseudo labeling. We introduce BaM-SSL, an efficient Bayesian Model averaging technique that improves uncertainty quantification in SSL methods with limited computational or memory overhead. We demonstrate that BaM-SSL mitigates confirmation bias in SOTA SSL methods across standard vision benchmarks of CIFAR-10, CIFAR-100, giving up to 16% improvement in test accuracy on the CIFAR-100 with 400 labels benchmark. Furthermore, we also demonstrate their effectiveness in additional realistic and challenging problems, such as class-imbalanced datasets and in photonics science",
    "checked": true,
    "id": "7a8280a7cc11463dd7f98683018f328b64041a99",
    "semantic_title": "mitigating confirmation bias in semi-supervised learning via efficient bayesian model averaging",
    "citation_count": 2,
    "authors": [
      "Charlotte Loh",
      "Rumen Dangovski",
      "Shivchander Sudalairaj",
      "Seungwook Han",
      "Ligong Han",
      "Leonid Karlinsky",
      "Marin Soljacic",
      "Akash Srivastava"
    ]
  },
  "https://openreview.net/forum?id=l4Jcxs0fpC": {
    "title": "Individual Privacy Accounting for Differentially Private Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "Differentially private stochastic gradient descent (DP-SGD) is the workhorse algorithm for recent advances in private deep learning. It provides a single privacy guarantee to all datapoints in the dataset. We propose \\emph{output-specific} $(\\varepsilon,\\delta)$-DP to characterize privacy guarantees for individual examples when releasing models trained by DP-SGD. We also design an efficient algorithm to investigate individual privacy across a number of datasets. We find that most examples enjoy stronger privacy guarantees than the worst-case bound. We further discover that the training loss and the privacy parameter of an example are well-correlated. This implies groups that are underserved in terms of model utility simultaneously experience weaker privacy guarantees. For example, on CIFAR-10, the average $\\varepsilon$ of the class with the lowest test accuracy is 44.2\\% higher than that of the class with the highest accuracy",
    "checked": true,
    "id": "750331fa07beb042acb462283e18d05d756824e3",
    "semantic_title": "individual privacy accounting for differentially private stochastic gradient descent",
    "citation_count": 22,
    "authors": [
      "Da Yu",
      "Gautam Kamath",
      "Janardhan Kulkarni",
      "Tie-Yan Liu",
      "Jian Yin",
      "Huishuai Zhang"
    ]
  },
  "https://openreview.net/forum?id=VI2JjIfU37": {
    "title": "A DNN Optimizer that Improves over AdaBelief by Suppression of the Adaptive Stepsize Range",
    "volume": "main",
    "abstract": "We make contributions towards improving adaptive-optimizer performance. Our improvements are based on suppression of the range of adaptive stepsizes in the AdaBelief optimizer. Firstly, we show that the particular placement of the parameter $\\epsilon$ within the update expressions of AdaBelief reduces the range of the adaptive stepsizes, making AdaBelief closer to SGD with momentum. Secondly, we extend AdaBelief by further suppressing the range of the adaptive stepsizes. To achieve the above goal, we perform mutual layerwise vector projections between the gradient $\\boldsymbol{g}_t$ and its first momentum $\\boldsymbol{m}_t$ before using them to estimate the second momentum. The new optimization method is referred to as \\emph{Aida}. Thirdly, extensive experimental results show that Aida outperforms nine optimizers when training transformers and LSTMs for NLP, and VGG and ResNet for image classification over CIAF10 and CIFAR100 while matching the best performance of the nine methods when training WGAN-GP models for image generation tasks. Furthermore, Aida produces higher validation accuracies than AdaBelief for training ResNet18 over ImageNet",
    "checked": true,
    "id": "d1a029608df9d652418c776bf3dc6aa836216e7e",
    "semantic_title": "a dnn optimizer that improves over adabelief by suppression of the adaptive stepsize range",
    "citation_count": 2,
    "authors": [
      "Guoqiang Zhang",
      "Kenta Niwa",
      "W. Bastiaan Kleijn"
    ]
  },
  "https://openreview.net/forum?id=f0FSDAy1bU": {
    "title": "Faster Training of Neural ODEs Using Gauß–Legendre Quadrature",
    "volume": "main",
    "abstract": "Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gauß-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models",
    "checked": false,
    "id": "dde67a6ab628d08f693376a3e7e3332f1795a990",
    "semantic_title": "faster training of neural odes using gauß-legendre quadrature",
    "citation_count": 4,
    "authors": [
      "Alexander Luke Ian Norcliffe",
      "Marc Peter Deisenroth"
    ]
  },
  "https://openreview.net/forum?id=lAQQx7hlku": {
    "title": "Bridging the Sim2Real gap with CARE: Supervised Detection Adaptation with Conditional Alignment and Reweighting",
    "volume": "main",
    "abstract": "Sim2Real domain adaptation (DA) research focuses on the constrained setting of adapting from a labeled synthetic source domain to an unlabeled or sparsely labeled real target domain. However, for high-stakes applications (e.g. autonomous driving), it is common to have a modest amount of human-labeled real data in addition to plentiful auto-labeled source data (e.g. from a driving simulator). We study this setting of supervised sim2real DA applied to 2D object detection. We propose Domain Translation via Conditional Alignment and Reweighting (CARE) a novel algorithm that systematically exploits target labels to explicitly close the sim2real appearance and content gaps. We present an analytical justification of our algorithm and demonstrate strong gains over competing methods on standard benchmarks",
    "checked": true,
    "id": "4bfb08bce1f31cd20ee2c3e66ff8078f6501e4fe",
    "semantic_title": "bridging the sim2real gap with care: supervised detection adaptation with conditional alignment and reweighting",
    "citation_count": 13,
    "authors": [
      "Viraj Uday Prabhu",
      "David Acuna",
      "Rafid Mahmood",
      "Marc T. Law",
      "Yuan-Hong Liao",
      "Judy Hoffman",
      "Sanja Fidler",
      "James Lucas"
    ]
  },
  "https://openreview.net/forum?id=obB415rg8q": {
    "title": "Efficient Inference With Model Cascades",
    "volume": "main",
    "abstract": "State-of-the-art deep learning models are becoming ever larger. However, many practical applications are constrained by the cost of inference. Cascades of pretrained models with conditional execution address these requirements based on the intuition that some inputs are easy enough that they can be processed correctly by a smaller model allowing for an early exit. If the smaller model is not sufficiently confident in its prediction, the input is passed on to a larger model. The selection of the confidence threshold allows to trade off computational cost against accuracy. In this work we explore the effective design of model cascades, thoroughly evaluate the impact on the accuracy-efficiency trade-off, and provide a reproducible state-of-the-art baseline that is currently missing for related research. We demonstrate that model cascades dominate the ImageNet Pareto front already with 2-model cascades, achieving an average reduction in compute effort at equal accuracy of almost 3.1x above 86% and more than 1.9x between 80% and 86% top-1 accuracy, while 3-model cascades achieve 4.4x above 87% accuracy. We confirm wider applicability and effectiveness of the method on the GLUE benchmark. We release the code to reproduce our experiments in the supplementary material and use only publicly available pretrained models and datasets",
    "checked": true,
    "id": "be6e3a6dcd75f9f8c8ceb3f8ea97eb409aa14cb2",
    "semantic_title": "efficient inference with model cascades",
    "citation_count": 7,
    "authors": [
      "Luzian Lebovitz",
      "Lukas Cavigelli",
      "Michele Magno",
      "Lorenz K Muller"
    ]
  },
  "https://openreview.net/forum?id=EWPA9TZcUy": {
    "title": "Semantic Representations of Mathematical Expressions in a Continuous Vector Space",
    "volume": "main",
    "abstract": "Mathematical notation makes up a large portion of STEM literature, yet finding semantic representations for formulae remains a challenging problem. Because mathematical notation is precise, and its meaning changes significantly with small character shifts, the methods that work for natural text do not necessarily work well for mathematical expressions. This work describes an approach for representing mathematical expressions in a continuous vector space. We use the encoder of a sequence-to-sequence architecture, trained on visually different but mathematically equivalent expressions, to generate vector representations (or embeddings). We compare this approach with a structural approach that considers visual layout to embed an expression and show that our proposed approach is better at capturing mathematical semantics. Finally, to expedite future research, we publish a corpus of equivalent transcendental and algebraic expression pairs",
    "checked": true,
    "id": "ab080117bfdd1cb2ab7d913b45a904f78ee542be",
    "semantic_title": "semantic representations of mathematical expressions in a continuous vector space",
    "citation_count": 1,
    "authors": [
      "Neeraj Gangwar",
      "Nickvash Kani"
    ]
  },
  "https://openreview.net/forum?id=oFC2LAqS6Z": {
    "title": "Representations and Computations in Transformers that Support Generalization on Structured Tasks",
    "volume": "main",
    "abstract": "Transformers have shown remarkable success in natural language processing and computer vision, serving as the foundation of large language and multimodal models. These networks can capture nuanced context sensitivity across high-dimensional language tokens or image pixels, but it remains unclear how highly structured behavior and systematic generalization can arise in these systems. Here, we explore the solution process a causal transformer discovers as it learns to solve a set of algorithmic tasks involving copying, sorting, and hierarchical compositions of these operations. We search for the minimal layer and head configuration sufficient to solve these tasks and unpack the roles of the attention heads, as well as how token representations are reweighted across layers to complement these roles. Our results provide new insights into how attention layers in transformers support structured computation within and across tasks: 1) Replacing fixed position labels with labels sampled from a larger set enables strong length generalization and faster learning. The learnable embeddings of these labels develop different representations, capturing sequence order if necessary, depending on task demand. 2) Two-layer transformers can learn reliable solutions to the multi-level problems we explore. The first layer tends to transform the input representation to allow the second layer to share computation across repeated components within a task or across related tasks. 3) We introduce an analysis pipeline that quantifies how the representation space in a given layer prioritizes different aspects of each item. We show that these representations prioritize information needed to guide attention relative to information that only requires downstream readout",
    "checked": true,
    "id": "79dd9e62f0e3ba35ce54d98b32750933e91a972a",
    "semantic_title": "representations and computations in transformers that support generalization on structured tasks",
    "citation_count": 5,
    "authors": [
      "Yuxuan Li",
      "James McClelland"
    ]
  },
  "https://openreview.net/forum?id=tv46tCzs83": {
    "title": "Causal Parrots: Large Language Models May Talk Causality But Are Not Causal",
    "volume": "main",
    "abstract": "Some argue scale is all what is needed to achieve AI, covering even causal models. We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables. We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained. If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots",
    "checked": true,
    "id": "b9672ac98913c43fcb996b3def314789d1cc0cf4",
    "semantic_title": "causal parrots: large language models may talk causality but are not causal",
    "citation_count": 125,
    "authors": [
      "Matej Zečević",
      "Moritz Willig",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ]
  },
  "https://openreview.net/forum?id=VP9p4u9jAo": {
    "title": "An Option-Dependent Analysis of Regret Minimization Algorithms in Finite-Horizon Semi-MDP",
    "volume": "main",
    "abstract": "A large variety of real-world Reinforcement Learning (RL) tasks is characterized by a complex and heterogeneous structure that makes end-to-end (or flat) approaches hardly applicable or even infeasible. Hierarchical Reinforcement Learning (HRL) provides general solutions to address these problems thanks to a convenient multi-level decomposition of the tasks, making their solution accessible. Although often used in practice, few works provide theoretical guarantees to justify this outcome effectively. Thus, it is not yet clear when to prefer such approaches compared to standard flat ones. In this work, we provide an option-dependent upper bound to the regret suffered by regret minimization algorithms in finite-horizon problems. We illustrate that the performance improvement derives from the planning horizon reduction induced by the temporal abstraction enforced by the hierarchical structure. Then, focusing on a sub-setting of HRL approaches, the options framework, we highlight how the average duration of the available options affects the planning horizon and, consequently, the regret itself. Finally, we relax the assumption of having pre-trained options to show how, in particular situations, is still preferable a hierarchical approach over a standard one",
    "checked": false,
    "id": "3e45d02b763cb8197369ac0b3ef4a16f4726de85",
    "semantic_title": "an option-dependent analysis of regret minimization algorithms in finite-horizon semi-markov decision processes",
    "citation_count": 0,
    "authors": [
      "Gianluca Drappo",
      "Alberto Maria Metelli",
      "Marcello Restelli"
    ]
  },
  "https://openreview.net/forum?id=Hf95zFnQ7H": {
    "title": "On Adaptivity in Quantum Testing",
    "volume": "main",
    "abstract": "Can adaptive strategies outperform non-adaptive ones for quantum hypothesis selection? We exhibit problems where adaptive strategies provably reduce the number of required samples by a factor four in the worst case, and possibly more when the actual difficulty of the problem makes it possible. In addition, we exhibit specific hypotheses classes for which there is a provable polynomial separation between adaptive and non-adaptive strategies -- a specificity of the quantum framework that does not appear in classical testing",
    "checked": true,
    "id": "329438fe111495e37f45b91641504abee0f05916",
    "semantic_title": "on adaptivity in quantum testing",
    "citation_count": 3,
    "authors": [
      "Omar Fawzi",
      "Nicolas Flammarion",
      "Aurélien Garivier",
      "Aadil Oufkir"
    ]
  },
  "https://openreview.net/forum?id=d4Vr6E0jjm": {
    "title": "Teaching Smaller Language Models To Generalise To Unseen Compositional Questions",
    "volume": "main",
    "abstract": "We equip a smaller Language Model to generalise to answering challenging compositional questions that have not been seen in training. To do so we propose a combination of multitask supervised pretraining on up to 93 tasks designed to instill diverse reasoning abilities, and a dense retrieval system that aims to retrieve a set of evidential paragraph fragments. Recent progress in question-answering has been achieved either through prompting methods against very large pretrained Language Models in zero or few-shot fashion, or by fine-tuning smaller models, sometimes in conjunction with information retrieval. We focus on the less explored question of the extent to which zero-shot generalisation can be enabled in smaller models with retrieval against a corpus within which sufficient information to answer a particular question may not exist. We establish strong baselines in this setting for diverse evaluation datasets (StrategyQA, CommonsenseQA, IIRC, DROP, Musique and ARC-DA), and show that performance can be significantly improved by adding retrieval-augmented training datasets which are designed to expose our models to a variety of heuristic reasoning strategies such as weighing partial evidence or ignoring an irrelevant context",
    "checked": true,
    "id": "aea817017e18cc1cb34962ffd399f8a83ab7a076",
    "semantic_title": "teaching smaller language models to generalise to unseen compositional questions",
    "citation_count": 2,
    "authors": [
      "Tim Hartill",
      "Neset TAN",
      "Michael Witbrock",
      "Patricia J. Riddle"
    ]
  },
  "https://openreview.net/forum?id=3agxS3aDUs": {
    "title": "Subgraph Permutation Equivariant Networks",
    "volume": "main",
    "abstract": "In this work we develop a new method, named Sub-graph Permutation Equivariant Networks (SPEN), which provides a framework for building graph neural networks that operate on sub-graphs, while using a base update function that is permutation equivariant, that are equivariant to a novel choice of automorphism group. Message passing neural networks have been shown to be limited in their expressive power and recent approaches to over come this either lack scalability or require structural information to be encoded into the feature space. The general framework presented here overcomes the scalability issues associated with global permutation equivariance by operating more locally on sub-graphs. In addition, through operating on sub-graphs the expressive power of higher-dimensional global permutation equivariant networks is improved; this is due to fact that two non-distinguishable graphs often contain distinguishable sub-graphs. Furthermore, the proposed framework only requires a choice of $k$-hops for creating ego-network sub-graphs and a choice of representation space to be used for each layer, which makes the method easily applicable across a range of graph based domains. We experimentally validate the method on a range of graph benchmark classification tasks, demonstrating statistically indistinguishable results from the state-of-the-art on six out of seven benchmarks. Further, we demonstrate that the use of local update functions offers a significant improvement in GPU memory over global methods",
    "checked": true,
    "id": "d65a4acf7a846eb0fc4d9638ec052c6778a96110",
    "semantic_title": "subgraph permutation equivariant networks",
    "citation_count": 2,
    "authors": [
      "Joshua Mitton",
      "Roderick Murray-Smith"
    ]
  },
  "https://openreview.net/forum?id=uq29MIWvIV": {
    "title": "About the Cost of Central Privacy in Density Estimation",
    "volume": "main",
    "abstract": "We study non-parametric density estimation for densities in Lipschitz and Sobolev spaces, and under central privacy. In particular, we investigate regimes where the privacy budget is not supposed to be constant. We consider the classical definition of central differential privacy, but also the more recent notion of central concentrated differential privacy. We recover the result of Barber & Duchi (2014) stating that histogram estimators are optimal against Lipschitz distributions for the L2 risk and, under regular differential privacy, we extend it to other norms and notions of privacy. Then, we investigate higher degrees of smoothness, drawing two conclusions: First, and contrary to what happens with constant privacy budget (Wasserman & Zhou, 2010), there are regimes where imposing privacy degrades the regular minimax risk of estimation on Sobolev densities. Second, so-called projection estimators are near-optimal against the same classes of densities in this new setup with pure differential privacy, but contrary to the constant privacy budget case, it comes at the cost of relaxation. With zero concentrated differential privacy, there is no need for relaxation, and we prove that the estimation is optimal",
    "checked": true,
    "id": "9b0b28f48f828f399cda2801f1e43b6aa384a0b6",
    "semantic_title": "about the cost of central privacy in density estimation",
    "citation_count": 3,
    "authors": [
      "Clément Lalanne",
      "Aurélien Garivier",
      "Rémi Gribonval"
    ]
  },
  "https://openreview.net/forum?id=REtKapdkyI": {
    "title": "Some Remarks on Identifiability of Independent Component Analysis in Restricted Function Classes",
    "volume": "main",
    "abstract": "In this short note, we comment on recent results on identifiability of independent component analysis. We point out an error in earlier works and clarify that this error cannot be fixed as the chosen approach is not sufficiently powerful to prove identifiability results. In addition, we explain the necessary ingredients to prove stronger identifiability results. Finally, we discuss and extend the flow-based technique to construct spurious solutions for independent component analysis problems and provide a counterexample to an earlier identifiability result",
    "checked": true,
    "id": "b5fcb665718a6931ea908d2616fc6e24ae2fcbe9",
    "semantic_title": "some remarks on identifiability of independent component analysis in restricted function classes",
    "citation_count": 1,
    "authors": [
      "Simon Buchholz"
    ]
  },
  "https://openreview.net/forum?id=Nn71AdKyYH": {
    "title": "You Only Transfer What You Share: Intersection-Induced Graph Transfer Learning for Link Prediction",
    "volume": "main",
    "abstract": "Link prediction is central to many real-world applications, but its performance may be hampered when the graph of interest is sparse. To alleviate issues caused by sparsity, we investigate a previously overlooked phenomenon: in many cases, a densely connected, complementary graph can be found for the original graph. The denser graph may share nodes with the original graph, which offers a natural bridge for transferring selective, meaningful knowledge. We identify this setting as Graph Intersection-induced Transfer Learning (GITL), which is motivated by practical applications in e-commerce or academic co-authorship predictions. We develop a framework to effectively leverage the structural prior in this setting. We first create an intersection subgraph using the shared nodes between the two graphs, then transfer knowledge from the source-enriched intersection subgraph to the full target graph. In the second step, we consider two approaches: a modified label propagation, and a multi-layer perceptron (MLP) model in a teacher-student regime. Experimental results on proprietary e-commerce datasets and open-source citation graphs show that the proposed workflow outperforms existing transfer learning baselines that do not explicitly utilize the intersection structure",
    "checked": true,
    "id": "19cbae4b5d3a10fd5e5cc27de163a4319c9d4341",
    "semantic_title": "you only transfer what you share: intersection-induced graph transfer learning for link prediction",
    "citation_count": 5,
    "authors": [
      "Wenqing Zheng",
      "Edward W Huang",
      "Nikhil Rao",
      "Zhangyang Wang",
      "Karthik Subbian"
    ]
  },
  "https://openreview.net/forum?id=7wA65zL3B3": {
    "title": "Logistic-Normal Likelihoods for Heteroscedastic Label Noise",
    "volume": "main",
    "abstract": "A natural way of estimating heteroscedastic label noise in regression is to model the observed (potentially noisy) target as a sample from a normal distribution, whose parameters can be learned by minimizing the negative log-likelihood. This formulation has desirable loss attenuation properties, as it reduces the contribution of high-error examples. Intuitively, this behavior can improve robustness against label noise by reducing overfitting. We propose an extension of this simple and probabilistic approach to classification that has the same desirable loss attenuation properties. Furthermore, we discuss and address some practical challenges of this extension. We evaluate the effectiveness of the method by measuring its robustness against label noise in classification. We perform enlightening experiments exploring the inner workings of the method, including sensitivity to hyperparameters, ablation studies, and other insightful analyses",
    "checked": false,
    "id": "f6ea00c32d30a2705db262032ae3633807f67495",
    "semantic_title": "logistic-normal likelihoods for heteroscedastic label noise in classification",
    "citation_count": 1,
    "authors": [
      "Erik Englesson",
      "Amir Mehrpanah",
      "Hossein Azizpour"
    ]
  },
  "https://openreview.net/forum?id=Ufc5cWhHko": {
    "title": "RECLIP: Resource-efficient CLIP by Training with Small Images",
    "volume": "main",
    "abstract": "We present RECLIP (Resource-efficient CLIP), a simple method that minimizes computational resource footprint for CLIP (Contrastive Language Image Pretraining). Inspired by the notion of coarse-to-fine in computer vision, we leverage small images to learn from large-scale language supervision efficiently, and finetune the model with high-resolution data in the end. Since the complexity of the vision transformer heavily depends on input image size, our approach significantly reduces the training resource requirements both in theory and in practice. Using the same batch size and training epoch, RECLIP achieves highly competitive zero-shot classification and image-text retrieval accuracy with 6 to 8× less computational resources and 7 to 9× fewer FLOPs than the base- line. Compared to the state-of-the-art contrastive learning methods, RECLIP demonstrates 5 to 59× training resource savings while maintaining highly competitive zero-shot classification and retrieval performance. Finally, RECLIP matches the state of the art in transfer learning to open-vocabulary detection tasks, achieving 32 APr on LVIS. We hope this work will pave the path for the broader research community to explore language supervised pretraining in resource-friendly settings",
    "checked": true,
    "id": "38a71cff020621b2435ae769b0667d7a4595d0e9",
    "semantic_title": "reclip: resource-efficient clip by training with small images",
    "citation_count": 14,
    "authors": [
      "Runze Li",
      "Dahun Kim",
      "Bir Bhanu",
      "Weicheng Kuo"
    ]
  },
  "https://openreview.net/forum?id=ubCoTAynPp": {
    "title": "Reinforcement Learning with Delayed, Composite, and Partially Anonymous Reward",
    "volume": "main",
    "abstract": "We investigate an infinite-horizon average reward Markov Decision Process (MDP) with delayed, composite, and partially anonymous reward feedback. The delay and compositeness of rewards mean that rewards generated as a result of taking an action at a given state are fragmented into different components, and they are sequentially realized at delayed time instances. The partial anonymity attribute implies that a learner, for each state, only observes the aggregate of past reward components generated as a result of different actions taken at that state, but realized at the observation instance. We propose an algorithm named $\\mathrm{DUCRL2}$ to obtain a near-optimal policy for this setting and show that it achieves a regret bound of $\\tilde{\\mathcal{O}}\\left(DS\\sqrt{AT} + d (SA)^3\\right)$ where $S$ and $A$ are the sizes of the state and action spaces, respectively, $D$ is the diameter of the MDP, $d$ is a parameter upper bounded by the maximum reward delay, and $T$ denotes the time horizon. This demonstrates the optimality of the bound in the order of $T$, and an additive impact of the delay",
    "checked": true,
    "id": "384b658132b3ac7d810b4595c0afff7695935f6f",
    "semantic_title": "reinforcement learning with delayed, composite, and partially anonymous reward",
    "citation_count": 2,
    "authors": [
      "Washim Uddin Mondal",
      "Vaneet Aggarwal"
    ]
  },
  "https://openreview.net/forum?id=dPSTDbGtBY": {
    "title": "Towards Multi-spatiotemporal-scale Generalized PDE Modeling",
    "volume": "main",
    "abstract": "Partial differential equations (PDEs) are central to describing complex physical system simulations. Their expensive solution techniques have led to an increased interest in deep neural network based surrogates. However, the practical utility of training such surrogates is contingent on their ability to model complex multi-scale spatio-temporal phenomena. {In recent years}, various neural network architectures have been proposed to target such phenomena, most notably Fourier Neural Operators (FNOs), which give a natural handle over local \\& global spatial information via parameterization of different Fourier modes, and U-Nets which treat local and global information via downsampling and upsampling paths. However, large-scale comparisons between these convolution-based approaches are notoriously sparse. In this work, we make such comprehensive comparisons regarding performance, runtime complexity, memory requirements, and generalization capabilities. Concretely, we stress-test various FNO, (Dilated) ResNet, and U-Net like approaches to fluid mechanics problems in both vorticity-stream and velocity function form. For U-Nets, we transfer recent architectural improvements from computer vision, most notably from object segmentation and generative modeling. Next, we use our insights on design considerations, and introduce U-FNets, i.e., modern U-Nets that are augmented with FNO downsampling layers. Those architectures further improve performance without major degradation of computational cost. Finally, we ablate and discuss various choices for parameter conditioning}, and show promising results on generalization to different PDE parameters and time-scales with a single surrogate model. Source code for our PyTorch benchmark framework is available at https://anonymous.4open.science/r/tmlr-pdemulti-6677/",
    "checked": true,
    "id": "00ffcc997b0bcf0dbf60ff04c29d701919582a62",
    "semantic_title": "towards multi-spatiotemporal-scale generalized pde modeling",
    "citation_count": 144,
    "authors": [
      "Jayesh K Gupta",
      "Johannes Brandstetter"
    ]
  },
  "https://openreview.net/forum?id=z49eaB8kiH": {
    "title": "The Multiquadric Kernel for Moment-Matching Distributional Reinforcement Learning",
    "volume": "main",
    "abstract": "Distributional reinforcement learning has gained significant attention in recent years due to its ability to handle uncertainty and variability in the returns an agent will receive for each action it takes. A key challenge in distributional reinforcement learning is finding a measure of the difference between two distributions that is well-suited for use with the distributional Bellman operator, a function that takes in a value distribution and produces a modified distribution based on the agent's current state and action. In this paper, we address this challenge by introducing the multiquadric kernel to moment-matching distributional reinforcement learning. We show that this kernel is both theoretically sound and empirically effective. Our contribution is mainly of a theoretical nature, presenting the first formally sound kernel for moment-matching distributional reinforcement learning with good practical performance. We also provide insights into why the RBF kernel has been shown to provide good practical results despite its theoretical problems. Finally, we evaluate the performance of our kernel on a number of standard benchmarks, obtaining results comparable to the state-of-the-art",
    "checked": true,
    "id": "6ac6c8082e53a42364e85b451c3d7948e6922018",
    "semantic_title": "the multiquadric kernel for moment-matching distributional reinforcement learning",
    "citation_count": 2,
    "authors": [
      "Ludvig Killingberg",
      "Helge Langseth"
    ]
  },
  "https://openreview.net/forum?id=EDVIHPZhFo": {
    "title": "Nonconvex-nonconcave min-max optimization on Riemannian manifolds",
    "volume": "main",
    "abstract": "This work studies nonconvex-nonconcave min-max problems on Riemannian manifolds. We first characterize the local optimality of nonconvex-nonconcave problems on manifolds with a generalized notion of local minimax points. We then define the stability and convergence criteria of dynamical systems on manifolds and provide necessary and sufficient conditions of strictly stable equilibrium points for both continuous and discrete dynamics. Additionally, we propose several novel second-order methods on manifolds that provably converge to local minimax points asymptotically. We validate the empirical benefits of the proposed methods with extensive experiments",
    "checked": true,
    "id": "1ad0256996ab79716fbeee7fbd621b340aae6032",
    "semantic_title": "nonconvex-nonconcave min-max optimization on riemannian manifolds",
    "citation_count": 7,
    "authors": [
      "Andi Han",
      "Bamdev Mishra",
      "Pratik Jawanpuria",
      "Junbin Gao"
    ]
  },
  "https://openreview.net/forum?id=moZvOx5cxe": {
    "title": "Learning to Boost Resilience of Complex Networks via Neural Edge Rewiring",
    "volume": "main",
    "abstract": "The resilience of complex networks refers to their ability to maintain functionality in the face of structural attacks. This ability can be improved by performing minimal modifications to the network structure via degree-preserving edge rewiring-based methods. Existing learning-free edge rewiring methods, although effective, are limited in their ability to generalize to different graphs. Such a limitation cannot be trivially addressed by existing graph neural networks (GNNs)-based learning approaches since there is no rich initial node features for GNNs to learn meaningful representations. In this work, inspired by persistent homology, we specifically design a variant of GNN called FireGNN to learn meaningful node representations solely from graph structures. We then develop an end-to-end inductive method called ResiNet, which aims to discover resilient network topologies while balancing network utility. ResiNet reformulates the optimization of network resilience as a Markov decision process equipped with edge rewiring action space. It learns to sequentially select the appropriate edges to rewire for maximizing resilience. Extensive experiments demonstrate that ResiNet outperforms existing approaches and achieves near-optimal resilience gains on various graphs while balancing network utility",
    "checked": true,
    "id": "320c729de74825d9e5cb8b7db3269e38b192c9d0",
    "semantic_title": "learning to boost resilience of complex networks via neural edge rewiring",
    "citation_count": 5,
    "authors": [
      "Shanchao Yang",
      "MA KAILI",
      "Baoxiang Wang",
      "Tianshu Yu",
      "Hongyuan Zha"
    ]
  },
  "https://openreview.net/forum?id=y8RZoPjEUl": {
    "title": "Simulate Time-integrated Coarse-grained Molecular Dynamics with Multi-scale Graph Networks",
    "volume": "main",
    "abstract": "Molecular dynamics (MD) simulation is essential for various scientific domains but computationally expensive. Learning-based force fields have made significant progress in accelerating ab-initio MD simulation but are not fast enough for many real-world applications due to slow inference for large systems and small time steps (femtosecond-level). We aim to address these challenges by learning a multi-scale graph neural network that directly simulates coarse-grained MD with a very large time step (nanosecond-level) and a novel refinement module based on diffusion models to mitigate simulation instability. The effectiveness of our method is demonstrated in two complex systems: single-chain coarse-grained polymers and multi-component Li-ion polymer electrolytes. For evaluation, we simulate trajectories much longer than the training trajectories for systems with different chemical compositions that the model is not trained on. Structural and dynamical properties can be accurately recovered at several orders of magnitude higher speed than classical force fields by getting out of the femtosecond regime",
    "checked": true,
    "id": "3333f169bd4815f92c03c9445761d8267c4e9ef2",
    "semantic_title": "simulate time-integrated coarse-grained molecular dynamics with multi-scale graph networks",
    "citation_count": 17,
    "authors": [
      "Xiang Fu",
      "Tian Xie",
      "Nathan J. Rebello",
      "Bradley Olsen",
      "Tommi S. Jaakkola"
    ]
  },
  "https://openreview.net/forum?id=R2hUure38l": {
    "title": "Meta-Calibration: Learning of Model Calibration Using Differentiable Expected Calibration Error",
    "volume": "main",
    "abstract": "Calibration of neural networks is a topical problem that is becoming more and more important as neural networks increasingly underpin real-world applications. The problem is especially noticeable when using modern neural networks, for which there is a significant difference between the confidence of the model and the probability of correct prediction. Various strategies have been proposed to improve calibration, yet accurate calibration remains challenging. We propose a novel framework with two contributions: introducing a new differentiable surrogate for expected calibration error (DECE) that allows calibration quality to be directly optimised, and a meta-learning framework that uses DECE to optimise for validation set calibration with respect to model hyper-parameters. The results show that we achieve competitive performance with existing calibration approaches. Our framework opens up a new avenue and toolset for tackling calibration, which we believe will inspire further work on this important challenge",
    "checked": true,
    "id": "bc200b53c46c38dcadfa22ea14645e899c73e99f",
    "semantic_title": "meta-calibration: learning of model calibration using differentiable expected calibration error",
    "citation_count": 23,
    "authors": [
      "Ondrej Bohdal",
      "Yongxin Yang",
      "Timothy Hospedales"
    ]
  },
  "https://openreview.net/forum?id=v5ew3FPTgb": {
    "title": "Understanding convolution on graphs via energies",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) typically operate by message-passing, where the state of a node is updated based on the information received from its neighbours. Most message-passing models act as graph convolutions, where features are mixed by a shared, linear transformation before being propagated over the edges. On node-classification tasks, graph convolutions have been shown to suffer from two limitations: poor performance on heterophilic graphs, and over-smoothing. It is common belief that both phenomena occur because such models behave as low-pass filters, meaning that the Dirichlet energy of the features decreases along the layers incurring a smoothing effect that ultimately makes features no longer distinguishable. In this work, we rigorously prove that simple graph-convolutional models can actually enhance high frequencies and even lead to an asymptotic behaviour we refer to as over-sharpening, opposite to over-smoothing. We do so by showing that linear graph convolutions with symmetric weights minimize a multi-particle energy that generalizes the Dirichlet energy; in this setting, the weight matrices induce edge-wise attraction (repulsion) through their positive (negative) eigenvalues, thereby controlling whether the features are being smoothed or sharpened. We also extend the analysis to non-linear GNNs, and demonstrate that some existing time-continuous GNNs are instead always dominated by the low frequencies. Finally, we validate our theoretical findings through ablations and real-world experiments",
    "checked": true,
    "id": "826d4aa5047f3a9074a11e7ea39e587d7e2d0759",
    "semantic_title": "understanding convolution on graphs via energies",
    "citation_count": 54,
    "authors": [
      "Francesco Di Giovanni",
      "James Rowbottom",
      "Benjamin Paul Chamberlain",
      "Thomas Markovich",
      "Michael M. Bronstein"
    ]
  },
  "https://openreview.net/forum?id=ZPMf53vE1L": {
    "title": "One-Step Distributional Reinforcement Learning",
    "volume": "main",
    "abstract": "Reinforcement learning (RL) allows an agent interacting sequentially with an environment to maximize its long-term expected return. In the distributional RL (DistrRL) paradigm, the agent goes beyond the limit of the expected value, to capture the underlying probability distribution of the return across all time steps. The set of DistrRL algorithms has led to improved empirical performance. Nevertheless, the theory of DistrRL is still not fully understood, especially in the control case. In this paper, we present the simpler one-step distributional reinforcement learning (OS-DistrRL) framework encompassing only the randomness induced by the one-step dynamics of the environment. Contrary to DistrRL, we show that our approach comes with a unified theory for both policy evaluation and control. Indeed, we propose two OS-DistrRL algorithms for which we provide an almost sure convergence analysis. The proposed approach compares favorably with categorical DistrRL on various environments",
    "checked": true,
    "id": "40ebcd12c830d411c31b6b6014a43635866807be",
    "semantic_title": "one-step distributional reinforcement learning",
    "citation_count": 3,
    "authors": [
      "Mastane Achab",
      "Reda ALAMI",
      "YASSER ABDELAZIZ DAHOU DJILALI",
      "Kirill Fedyanin",
      "Eric Moulines"
    ]
  },
  "https://openreview.net/forum?id=PHAr3q49h6": {
    "title": "Dual Representation Learning for Out-of-distribution Detection",
    "volume": "main",
    "abstract": "To classify in-distribution samples, deep neural networks explore strongly label-related information and discard weakly label-related information according to the information bottleneck. Out-of-distribution samples drawn from distributions differing from that of in-distribution samples could be assigned with unexpected high-confidence predictions because they could obtain minimum strongly label-related information. To distinguish in- and out-of-distribution samples, Dual Representation Learning (DRL) makes out-of-distribution samples harder to have high-confidence predictions by exploring both strongly and weakly label-related information from in-distribution samples. For a pretrained network exploring strongly label-related information to learn label-discriminative representations, DRL trains its auxiliary network exploring the remaining weakly label-related information to learn distribution-discriminative representations. Specifically, for a label-discriminative representation, DRL constructs its complementary distribution-discriminative representation by integrating diverse representations less similar to the label-discriminative representation. Accordingly, DRL combines label- and distribution-discriminative representations to detect out-of-distribution samples. Experiments show that DRL outperforms the state-of-the-art methods for out-of-distribution detection",
    "checked": true,
    "id": "585e3fbf75e1cd3df556f12a1284dc280c782ace",
    "semantic_title": "dual representation learning for out-of-distribution detection",
    "citation_count": 3,
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao"
    ]
  },
  "https://openreview.net/forum?id=83rgSFPpws": {
    "title": "Cyclophobic Reinforcement Learning",
    "volume": "main",
    "abstract": "In environments with sparse rewards, finding a good inductive bias for exploration is crucial to the agent's success. However, there are two competing goals: novelty search and systematic exploration. While existing approaches such as curiosity-driven exploration find novelty, they sometimes do not systematically explore the whole state space, akin to depth-first-search vs breadth-first-search. In this paper, we propose a new intrinsic reward that is cyclophobic, i.e., it does not reward novelty, but punishes redundancy by avoiding cycles. Augmenting the cyclophobic intrinsic reward with a sequence of hierarchical representations based on the agent's cropped observations we are able to achieve excellent results in the MiniGrid and MiniHack environments. Both are particularly hard, as they require complex interactions with different objects in order to be solved. Detailed comparisons with previous approaches and thorough ablation studies show that our newly proposed cyclophobic reinforcement learning is more sample efficient than other state of the art methods in a variety of tasks",
    "checked": true,
    "id": "ccca35498d185ee5b91a6ed4f82861f8bbd59229",
    "semantic_title": "cyclophobic reinforcement learning",
    "citation_count": 1,
    "authors": [
      "Stefan Sylvius Wagner",
      "Peter Arndt",
      "Jan Robine",
      "Stefan Harmeling"
    ]
  },
  "https://openreview.net/forum?id=nYzhlFyjjd": {
    "title": "Rotation-Invariant Random Features Provide a Strong Baseline for Machine Learning on 3D Point Clouds",
    "volume": "main",
    "abstract": "Rotational invariance is a popular inductive bias used by many fields in machine learning, such as computer vision and machine learning for quantum chemistry. Rotation-invariant machine learning methods set the state of the art for many tasks, including molecular property prediction and 3D shape classification. These methods generally either rely on task-specific rotation-invariant features, or they use general-purpose deep neural networks which are complicated to design and train. However, it is unclear whether the success of these methods is primarily due to the rotation invariance or the deep neural networks. To address this question, we suggest a simple and general-purpose method for learning rotation-invariant functions of three-dimensional point cloud data using a random features approach. Specifically, we extend the random features method of Rahimi & Recht (2007) by deriving a version that is invariant to three-dimensional rotations and showing that it is fast to evaluate on point cloud data. We show through experiments that our method matches or outperforms the performance of general-purpose rotation-invariant neural networks on standard molecular property prediction benchmark datasets QM7 and QM9. We also show that our method is general-purpose and provides a rotation-invariant baseline on the ModelNet40 shape classification task. Finally, we show that our method has an order of magnitude smaller prediction latency than competing kernel methods",
    "checked": true,
    "id": "631836cec708152538719af313bf9c1a261f3ec5",
    "semantic_title": "rotation-invariant random features provide a strong baseline for machine learning on 3d point clouds",
    "citation_count": 3,
    "authors": [
      "Owen Melia",
      "Eric M Jonas",
      "Rebecca Willett"
    ]
  },
  "https://openreview.net/forum?id=pHCdMat0gI": {
    "title": "Graph Neural Networks for Temporal Graphs: State of the Art, Open Challenges, and Opportunities",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) have become the leading paradigm for learning on (static) graph-structured data. However, many real-world systems are dynamic in nature, since the graph and node/edge attributes change over time. In recent years, GNN-based models for temporal graphs have emerged as a promising area of research to extend the capabilities of GNNs. In this work, we provide the first comprehensive overview of the current state-of-the-art of temporal GNN, introducing a rigorous formalization of learning settings and tasks and a novel taxonomy categorizing existing approaches in terms of how the temporal aspect is represented and processed. We conclude the survey with a discussion of the most relevant open challenges for the field, from both research and application perspectives",
    "checked": true,
    "id": "b88f456daaf29860d2b59c621be3bd878a581a59",
    "semantic_title": "graph neural networks for temporal graphs: state of the art, open challenges, and opportunities",
    "citation_count": 66,
    "authors": [
      "Antonio Longa",
      "Veronica Lachi",
      "Gabriele Santin",
      "Monica Bianchini",
      "Bruno Lepri",
      "Pietro Lio",
      "franco scarselli",
      "Andrea Passerini"
    ]
  },
  "https://openreview.net/forum?id=0f8tU3QwWD": {
    "title": "FairGrad: Fairness Aware Gradient Descent",
    "volume": "main",
    "abstract": "We address the problem of group fairness in classification, where the objective is to learn models that do not unjustly discriminate against subgroups of the population. Most existing approaches are limited to simple binary tasks or involve difficult to implement training mechanisms which reduces their practical applicability. In this paper, we propose FairGrad, a method to enforce fairness based on a re-weighting scheme that iteratively learns group specific weights based on whether they are advantaged or not. FairGrad is easy to implement, accommodates various standard fairness definitions, and comes with minimal overhead. Furthermore, we show that it is competitive with standard baselines over various datasets including ones used in natural language processing and computer vision. FairGrad is available as a PyPI package at - https://pypi.org/project/fairgrad",
    "checked": true,
    "id": "7118e545c3786e0f9a87b25214f1c7d930e068bb",
    "semantic_title": "fairgrad: fairness aware gradient descent",
    "citation_count": 12,
    "authors": [
      "Gaurav Maheshwari",
      "Michaël Perrot"
    ]
  },
  "https://openreview.net/forum?id=qHZs2p4ZD4": {
    "title": "V1T: large-scale mouse V1 response prediction using a Vision Transformer",
    "volume": "main",
    "abstract": "Accurate predictive models of the visual cortex neural response to natural visual stimuli remain a challenge in computational neuroscience. In this work, we introduce $V{\\small 1}T$, a novel Vision Transformer based architecture that learns a shared visual and behavioral representation across animals. We evaluate our model on two large datasets recorded from mouse primary visual cortex and outperform previous convolution-based models by more than 12.7% in prediction performance. Moreover, we show that the self-attention weights learned by the Transformer correlate with the population receptive fields. Our model thus sets a new benchmark for neural response prediction and can be used jointly with behavioral and neural recordings to reveal meaningful characteristic features of the visual cortex",
    "checked": true,
    "id": "370717d2027ae6b8762d8dad518b0b8d706d706a",
    "semantic_title": "v1t: large-scale mouse v1 response prediction using a vision transformer",
    "citation_count": 9,
    "authors": [
      "Bryan M. Li",
      "Isabel Maria Cornacchia",
      "Nathalie Rochefort",
      "Arno Onken"
    ]
  },
  "https://openreview.net/forum?id=ey5b7kODvK": {
    "title": "Novel Class Discovery for Long-tailed Recognition",
    "volume": "main",
    "abstract": "While the novel class discovery has recently made great progress, existing methods typically focus on improving algorithms on class-balanced benchmarks. However, in real-world recognition tasks, the class distributions of their corresponding datasets are often imbalanced, which leads to serious performance degeneration of those methods. In this paper, we consider a more realistic setting for novel class discovery where the distributions of novel and known classes are long-tailed. One main challenge of this new problem is to discover imbalanced novel classes with the help of long-tailed known classes. To tackle this problem, we propose an adaptive self-labeling strategy based on an equiangular prototype representation of classes. Our method infers high-quality pseudo-labels for the novel classes by solving a relaxed optimal transport problem and effectively mitigates the class biases in learning the known and novel classes. We perform extensive experiments on CIFAR100, ImageNet100, Herbarium19 and large-scale iNaturalist18 datasets, and the results demonstrate the superiority of our method. Our code is available at \\url{https://github.com/kleinzcy/NCDLR}",
    "checked": true,
    "id": "bedf5fa16ae127f599d2e1f562b96f7a12ef7f13",
    "semantic_title": "novel class discovery for long-tailed recognition",
    "citation_count": 17,
    "authors": [
      "Chuyu Zhang",
      "Ruijie Xu",
      "Xuming He"
    ]
  },
  "https://openreview.net/forum?id=U4XgzRjfF1": {
    "title": "Asymptotic Analysis of Conditioned Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "In this paper, we investigate a general class of stochastic gradient descent (SGD) algorithms, called $\\textit{conditioned}$ SGD, based on a preconditioning of the gradient direction. Using a discrete-time approach with martingale tools, we establish under mild assumptions the weak convergence of the rescaled sequence of iterates for a broad class of conditioning matrices including stochastic first-order and second-order methods. Almost sure convergence results, which may be of independent interest, are also presented. Interestingly, the asymptotic normality result consists in a stochastic equicontinuity property so when the conditioning matrix is an estimate of the inverse Hessian, the algorithm is asymptotically optimal",
    "checked": false,
    "id": "c7b411f10d2d6bbcc4824177fa9bd9942292f61d",
    "semantic_title": "non-asymptotic analysis of online multiplicative stochastic gradient descent",
    "citation_count": 0,
    "authors": [
      "Rémi Leluc",
      "François Portier"
    ]
  },
  "https://openreview.net/forum?id=WYKTCKpImz": {
    "title": "Learned Thresholds Token Merging and Pruning for Vision Transformers",
    "volume": "main",
    "abstract": "Vision transformers have demonstrated remarkable success in a wide range of computer vision tasks over the last years, however, their high computational costs remains a significant barrier to their practical deployment. In particular, the complexity of transformer models is quadratic with respect to the number of input tokens. Therefore techniques that reduce the number of input tokens that need to be processed have been proposed. This paper introduces Learned Thresholds token Merging and Pruning (LTMP), a novel approach that leverages the strengths of both token merging and token pruning. LTMP uses learned threshold masking modules that dynamically determine which tokens to merge and which to prune. We demonstrate our approach with extensive experiments on vision transformers on the ImageNet classification task. Our results demonstrate that LTMP achieves state-of-the-art accuracy across reduction rates while requiring only a single fine-tuning epoch, which is an order of magnitude faster than previous methods",
    "checked": true,
    "id": "80754642beb97b91167efd16b2a265024213857c",
    "semantic_title": "learned thresholds token merging and pruning for vision transformers",
    "citation_count": 26,
    "authors": [
      "Maxim Bonnaerens",
      "Joni Dambre"
    ]
  },
  "https://openreview.net/forum?id=FqOG4osY7C": {
    "title": "MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks",
    "volume": "main",
    "abstract": "The development of language models have moved from encoder-decoder to decoder-only designs. In addition, we observe that the two most popular multimodal tasks, the generative and contrastive tasks, are nontrivial to accommodate in one architecture, and further need adaptations for downstream tasks. We propose a novel paradigm of training with a decoder-only model for multimodal tasks, which is surprisingly effective in jointly learning of these disparate vision-language tasks. This is done with a simple model, called MaMMUT. It consists of a single vision encoder and a text decoder, and is able to accommodate contrastive and generative learning by a novel two-pass approach on the text decoder. We demonstrate that joint learning of these diverse objectives is simple, effective, and maximizes the weight-sharing of the model across these tasks. Furthermore, the same architecture enables straightforward extensions to open-vocabulary object detection and video-language tasks. The model tackles a diverse range of tasks, while being modest in capacity. Our model achieves the state of the art on image-text and text-image retrieval, video question answering and open-vocabulary detection tasks, outperforming much larger and more extensively trained foundational models. It shows very competitive results on VQA and Video Captioning, especially considering its capacity. Ablations confirm the flexibility and advantages of our approach",
    "checked": true,
    "id": "26eb6745006e94317cfb634123fe3015702fb224",
    "semantic_title": "mammut: a simple architecture for joint learning for multimodal tasks",
    "citation_count": 27,
    "authors": [
      "Weicheng Kuo",
      "AJ Piergiovanni",
      "Dahun Kim",
      "xiyang luo",
      "Benjamin Caine",
      "Wei Li",
      "Abhijit Ogale",
      "Luowei Zhou",
      "Andrew M. Dai",
      "Zhifeng Chen",
      "Claire Cui",
      "Anelia Angelova"
    ]
  },
  "https://openreview.net/forum?id=EwJJks2cSa": {
    "title": "Chasing Better Deep Image Priors between Over- and Under-parameterization",
    "volume": "main",
    "abstract": "Deep Neural Networks (DNNs) are well-known to act as \\textbf{over-parameterized} deep image priors (DIP) that regularize various image inverse problems. Meanwhile, researchers also proposed extremely compact, \\textbf{under-parameterized} image priors (e.g., deep decoder) that are strikingly competent for image restoration too, despite a loss of accuracy. These two extremes push us to think whether there exists a better solution in the middle: \\textit{between over- and under-parameterized image priors, can one identify ``intermediate\" parameterized image priors that achieve better trade-offs between performance, efficiency, and even preserving strong transferability?} Drawing inspirations from the lottery ticket hypothesis (LTH), we conjecture and study a novel ``lottery image prior\" (\\textbf{LIP}) by exploiting DNN inherent sparsity, stated as: \\textit{given an over-parameterized DNN-based image prior, it will contain a sparse subnetwork that can be trained in isolation, to match the original DNN's performance when being applied as a prior to various image inverse problems}. Our results validate the superiority of LIPs: we can successfully locate the LIP subnetworks from over-parameterized DIPs at substantial sparsity ranges. Those LIP subnetworks significantly outperform deep decoders under comparably compact model sizes (by often fully preserving the effectiveness of their over-parameterized counterparts), and they also possess high transferability across different images as well as restoration task types. Besides, we also extend LIP to compressive sensing image reconstruction, where a \\textit{pre-trained} GAN generator is used as the prior (in contrast to \\textit{untrained} DIP or deep decoder), and confirm its validity in this setting too. To our best knowledge, this is the first time that LTH is demonstrated to be relevant in the context of inverse problems or image priors. Codes are available at https://github.com/VITA-Group/Chasing-Better-DIPs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiming Wu",
      "Xiaohan Chen",
      "Yifan Jiang",
      "Zhangyang Wang"
    ]
  },
  "https://openreview.net/forum?id=TjaMO63fc9": {
    "title": "Federated High-Dimensional Online Decision Making",
    "volume": "main",
    "abstract": "We resolve the main challenge of federated bandit policy design via exploration-exploitation trade-off delineation under data decentralization with a local privacy protection argument. Such a challenge is practical in domain-specific applications and admits another layer of complexity in applications of medical decision-making and web marketing, where high- dimensional decision contexts are sensitive but important to inform decision-making. Exist- ing (low dimensional) federated bandits suffer super-linear theoretical regret upper bound in high-dimensional scenarios and are at risk of client information leakage due to their in- ability to separate exploration from exploitation. This paper proposes a class of bandit policy design, termed Fedego Lasso, to complete the task of federated high-dimensional online decision-making with sub-linear theoretical regret and local client privacy argument. Fedego Lasso relies on a novel multi-client teamwork-selfish bandit policy design to per- form decentralized collaborative exploration and federated egocentric exploration with log- arithmic communication costs. Experiments demonstrate the effectiveness of the proposed algorithms on both synthetic and real-world datasets",
    "checked": true,
    "id": "8adee03bb063e0e4140ac38a2f35553e65b4c119",
    "semantic_title": "federated high-dimensional online decision making",
    "citation_count": 3,
    "authors": [
      "Chi-Hua Wang",
      "Wenjie Li",
      "Guang Lin"
    ]
  },
  "https://openreview.net/forum?id=QnT41ZGNh9": {
    "title": "Regret Bounds for Satisficing in Multi-Armed Bandit Problems",
    "volume": "main",
    "abstract": "This paper considers the objective of \\textit{satisficing} in multi-armed bandit problems. Instead of aiming to find an optimal arm, the learner is content with an arm whose reward is above a given satisfaction level. We provide algorithms and analysis for the realizable case when such a satisficing arm exists as well as for the general case when this may not be the case. Introducing the notion of \\textit{satisficing regret}, our main result shows that in the general case it is possible to obtain constant satisficing regret when there is a satisficing arm (thereby correcting a contrary claim in the literature), while standard logarithmic regret bounds can be re-established otherwise. Experiments illustrate that our algorithm is not only superior to standard algorithms in the satisficing setting, but also works well in the classic bandit setting",
    "checked": true,
    "id": "ffe948b79308cbe0fa0e75011ba0f0cf828ee65f",
    "semantic_title": "regret bounds for satisficing in multi-armed bandit problems",
    "citation_count": 4,
    "authors": [
      "Thomas Michel",
      "Hossein Hajiabolhassan",
      "Ronald Ortner"
    ]
  },
  "https://openreview.net/forum?id=nFWRuJXPkU": {
    "title": "Using Confounded Data in Latent Model-Based Reinforcement Learning",
    "volume": "main",
    "abstract": "In the presence of confounding, naively using off-the-shelf offline reinforcement learning (RL) algorithms leads to sub-optimal behaviour. In this work, we propose a safe method to exploit confounded offline data in model-based RL, which improves the sample-efficiency of an interactive agent that also collects online, unconfounded data. First, we import ideas from the well-established framework of $do$-calculus to express model-based RL as a causal inference problem, thus bridging the gap between the fields of RL and causality. Then, we propose a generic method for learning a causal transition model from offline and online data, which captures and corrects the confounding effect using a hidden latent variable. We prove that our method is correct and efficient, in the sense that it attains better generalization guarantees thanks to the confounded offline data (in the asymptotic case), regardless of the confounding effect (the offline expert's behaviour). We showcase our method on a series of synthetic experiments, which demonstrate that a) using confounded offline data naively degrades the sample-efficiency of an RL agent; b) using confounded offline data correctly improves sample-efficiency",
    "checked": true,
    "id": "103881e6eb432286ad86b2a345880e276c60ff50",
    "semantic_title": "using confounded data in latent model-based reinforcement learning",
    "citation_count": 2,
    "authors": [
      "Maxime Gasse",
      "Damien GRASSET",
      "Guillaume Gaudron",
      "Pierre-Yves Oudeyer"
    ]
  },
  "https://openreview.net/forum?id=1irVjE7A3w": {
    "title": "Meta-Learning via Classifier(-free) Diffusion Guidance",
    "volume": "main",
    "abstract": "We introduce meta-learning algorithms that perform zero-shot weight-space adaptation of neural network models to unseen tasks. Our methods repurpose the popular generative image synthesis techniques of natural language guidance and diffusion models to generate neural network weights adapted for tasks. We first train an unconditional generative hypernetwork model to produce neural network weights; then we train a second \"guidance\" model that, given a natural language task description, traverses the hypernetwork latent space to find high-performance task-adapted weights in a zero-shot manner. We explore two alternative approaches for latent space guidance: \"HyperCLIP\"-based classifier guidance and a conditional Hypernetwork Latent Diffusion Model (\"HyperLDM\"), which we show to benefit from the classifier-free guidance technique common in image generation. Finally, we demonstrate that our approaches outperform existing multi-task and meta-learning methods in a series of zero-shot learning experiments on our Meta-VQA dataset",
    "checked": true,
    "id": "b83c62f3875a649aeafb22ff1c380a7bdd744b43",
    "semantic_title": "meta-learning via classifier(-free) diffusion guidance",
    "citation_count": 6,
    "authors": [
      "Elvis Nava",
      "Seijin Kobayashi",
      "Yifei Yin",
      "Robert K. Katzschmann",
      "Benjamin F Grewe"
    ]
  },
  "https://openreview.net/forum?id=nGW2Hotpq3": {
    "title": "Optimizing Learning Rate Schedules for Iterative Pruning of Deep Neural Networks",
    "volume": "main",
    "abstract": "The importance of learning rate (LR) schedules on network pruning has been observed in a few recent works. As an example, Frankle and Carbin (2019) highlighted that winning tickets (i.e., accuracy preserving subnetworks) can not be found without applying a LR warmup schedule. Renda, Frankle and Carbin (2020) also demonstrated that rewinding the LR to its initial state at the end of each pruning cycle can improve pruning performance. In this paper, we go one step further by first providing a theoretical justification for the surprising effect of LR schedules. Next, we propose a LR schedule for network pruning called SILO, which stands for S-shaped Improved Learning rate Optimization. The advantages of SILO over existing LR schedules are two-fold: (i) SILO has a strong theoretical motivation and dynamically adjusts the LR during pruning to improve generalization. Specifically, SILO increases the LR upper bound (max_lr) in an S-shape. This leads to an improvement of 2% - 4% in extensive experiments with various types of networks (e.g., Vision Transformers, ResNet) on popular datasets such as ImageNet, CIFAR-10/100. (ii) In addition to the strong theoretical motivation, SILO is empirically optimal in the sense of matching an Oracle, which exhaustively searches for the optimal value of max_lr via grid search. We find that SILO is able to precisely adjust the value of max_lr to be within the Oracle optimized interval, resulting in performance competitive with the Oracle with significantly lower complexity",
    "checked": true,
    "id": "2e09a43f15dfe8068283207f37795f2e918bbe15",
    "semantic_title": "optimizing learning rate schedules for iterative pruning of deep neural networks",
    "citation_count": 0,
    "authors": [
      "Shiyu Liu",
      "Rohan Ghosh",
      "John Chong Min Tan",
      "Mehul Motani"
    ]
  },
  "https://openreview.net/forum?id=wvLQMHtyLk": {
    "title": "Foiling Explanations in Deep Neural Networks",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) have greatly impacted numerous fields over the past decade. Yet despite exhibiting superb performance over many problems, their black-box nature still poses a significant challenge with respect to explainability. Indeed, explainable artificial intelligence (XAI) is crucial in several fields, wherein the answer alone---sans a reasoning of how said answer was derived---is of little value. This paper uncovers a troubling property of explanation methods for image-based DNNs: by making small visual changes to the input image---hardly influencing the network's output---we demonstrate how explanations may be arbitrarily manipulated through the use of evolution strategies. Our novel algorithm, AttaXAI, a model-and-data XAI-agnostic, adversarial attack on XAI algorithms, only requires access to the output logits of a classifier and to the explanation map; these weak assumptions render our approach highly useful where real-world models and data are concerned. We compare our method's performance on two benchmark datasets---CIFAR100 and ImageNet---using four different pretrained deep-learning models: VGG16-CIFAR100, VGG16-ImageNet, MobileNet-CIFAR100, and Inception-v3-ImageNet. We find that the XAI methods can be manipulated without the use of gradients or other model internals. Our novel algorithm is successfully able to manipulate an image in a manner imperceptible to the human eye, such that the XAI method outputs a specific explanation map. To our knowledge, this is the first such method in a black-box setting, and we believe it has significant value where explainability is desired, required, or legally mandatory",
    "checked": true,
    "id": "7e03f90aeef01523cc3b20e2e6f81ef1f6c3e0d5",
    "semantic_title": "foiling explanations in deep neural networks",
    "citation_count": 17,
    "authors": [
      "Snir Vitrack Tamam",
      "Raz Lapid",
      "Moshe Sipper"
    ]
  },
  "https://openreview.net/forum?id=pCbC3aQB5W": {
    "title": "Long-term Forecasting with TiDE: Time-series Dense Encoder",
    "volume": "main",
    "abstract": "Recent work has shown that simple linear models can outperform several Transformer based approaches in long term time-series forecasting. Motivated by this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model, \\underline{Ti}me-series \\underline{D}ense \\underline{E}ncoder (TiDE), for long-term time-series forecasting that enjoys the simplicity and speed of linear models while also being able to handle covariates and non-linear dependencies. Theoretically, we prove that the simplest linear analogue of our model can achieve near optimal error rate for linear dynamical systems (LDS) under some assumptions. Empirically, we show that our method can match or outperform prior approaches on popular long-term time-series forecasting benchmarks while being 5-10x faster than the best Transformer based model",
    "checked": true,
    "id": "2ced138789c8a1c39f0f57c8fbb18b94e6ed8034",
    "semantic_title": "long-term forecasting with tide: time-series dense encoder",
    "citation_count": 307,
    "authors": [
      "Abhimanyu Das",
      "Weihao Kong",
      "Andrew Leach",
      "Shaan K Mathur",
      "Rajat Sen",
      "Rose Yu"
    ]
  },
  "https://openreview.net/forum?id=Y3saBb7mCE": {
    "title": "Empirical Limitations of the NTK for Understanding Scaling Laws in Deep Learning",
    "volume": "main",
    "abstract": "The ``Neural Tangent Kernel'' (NTK) (Jacot et al 2018), and its empirical variants have been proposed as a proxy to capture certain behaviors of real neural networks. In this work, we study NTKs through the lens of scaling laws, and demonstrate that they fall short of explaining important aspects of neural network generalization. In particular, we demonstrate realistic settings where finite-width neural networks have significantly better data scaling exponents as compared to their corresponding empirical and infinite NTKs at initialization. This reveals a more fundamental difference between the real networks and NTKs, beyond just a few percentage points of test accuracy. Further, we show that even if the empirical NTK is allowed to be pre-trained on a constant number of samples, the kernel scaling does not catch up to the neural network scaling. Finally, we show that the empirical NTK continues to evolve throughout most of the training, in contrast with prior work which suggests that it stabilizes after a few epochs of training. Altogether, our work establishes concrete limitations of the NTK approach in understanding scaling laws of real networks on natural datasets",
    "checked": true,
    "id": "3881801d73a223cac1fd317a5c47df26be87af57",
    "semantic_title": "empirical limitations of the ntk for understanding scaling laws in deep learning",
    "citation_count": 7,
    "authors": [
      "Nikhil Vyas",
      "Yamini Bansal",
      "Preetum Nakkiran"
    ]
  },
  "https://openreview.net/forum?id=7KW7zvKd7J": {
    "title": "Transport Score Climbing: Variational Inference Using Forward KL and Adaptive Neural Transport",
    "volume": "main",
    "abstract": "Variational inference often minimizes the ``reverse'' Kullbeck-Leibler (KL) $D_{KL}(q||p)$ from the approximate distribution $q$ to the posterior $p$. Recent work studies the ``forward'' KL $D_{KL}(p||q)$, which unlike reverse KL does not lead to variational approximations that underestimate uncertainty. Markov chain Monte Carlo (MCMC) methods were used to evaluate the expectation in computing the forward KL. This paper introduces Transport Score Climbing (TSC), a method that optimizes $D_{KL}(p||q)$ by using Hamiltonian Monte Carlo (HMC) but running the HMC chain on a transformed, or warped, space. A function called the transport map performs the transformation by acting as a change-of-variable from the latent variable space. TSC uses HMC samples to dynamically train the transport map while optimizing $D_{KL}(p||q)$. TSC leverages synergies, where better transport maps lead to better HMC sampling, which then leads to better transport maps. We demonstrate TSC on synthetic and real data, including using TSC to train variational auto-encoders. We find that TSC achieves competitive performance on the experiments",
    "checked": true,
    "id": "5de7813ce5bc9f361f2b6fd09f884b468dcb43bf",
    "semantic_title": "transport score climbing: variational inference using forward kl and adaptive neural transport",
    "citation_count": 7,
    "authors": [
      "Liyi Zhang",
      "David Blei",
      "Christian A Naesseth"
    ]
  },
  "https://openreview.net/forum?id=D5Z2E8CNsD": {
    "title": "Distributionally Robust Classification on a Data Budget",
    "volume": "main",
    "abstract": "Real world uses of deep learning require predictable model behavior under distribution shifts. Models such as CLIP show emergent natural distributional robustness comparable to humans, but may require hundreds of millions of training samples. Can we train robust learners in a domain where data is limited? To rigorously address this question, we introduce JANuS (Joint Annotations and Names Set), a collection of four new training datasets with images, labels, and corresponding captions, and perform a series of carefully controlled investigations of factors contributing to robustness in image classification, then compare those results to findings derived from a large-scale meta-analysis. Using this approach, we show that standard ResNet-50 trained with the cross-entropy loss on 2.4 million image samples can attain comparable robustness to a CLIP ResNet-50 trained on 400 million samples. To our knowledge, this is the first result showing (near) state-of-the-art distributional robustness on limited data budgets",
    "checked": true,
    "id": "6a4e7c54648487cfce1d18344fdadf4a095c055b",
    "semantic_title": "distributionally robust classification on a data budget",
    "citation_count": 2,
    "authors": [
      "Benjamin Feuer",
      "Ameya Joshi",
      "Minh Pham",
      "Chinmay Hegde"
    ]
  },
  "https://openreview.net/forum?id=8ykyGbtt2q": {
    "title": "The ConceptARC Benchmark: Evaluating Understanding and Generalization in the ARC Domain",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0febeb46b8216f12337b448ac81ac505c28782c1",
    "semantic_title": "the conceptarc benchmark: evaluating understanding and generalization in the arc domain",
    "citation_count": 80,
    "authors": [
      "Arsenii Kirillovich Moskvichev",
      "Victor Vikram Odouard",
      "Melanie Mitchell"
    ]
  },
  "https://openreview.net/forum?id=Rb6VDOHebB": {
    "title": "Adaptive Compression for Communication-Efficient Distributed Training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e87dea6df52984f4df14edc229515ceb623bfd1a",
    "semantic_title": "adaptive compression for communication-efficient distributed training",
    "citation_count": 16,
    "authors": [
      "Maksim Makarenko",
      "Elnur Gasanov",
      "Abdurakhmon Sadiev",
      "Rustem Islamov",
      "Peter Richtárik"
    ]
  },
  "https://openreview.net/forum?id=H1SekypXKA": {
    "title": "Expected Worst Case Regret via Stochastic Sequential Covering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "69d9f836fb20625cc3fd5d74410612ff45392165",
    "semantic_title": "expected worst case regret via stochastic sequential covering",
    "citation_count": 12,
    "authors": [
      "Changlong Wu",
      "Mohsen Heidari",
      "Ananth Grama",
      "Wojciech Szpankowski"
    ]
  },
  "https://openreview.net/forum?id=HVAeM6sNo8": {
    "title": "Robust Alzheimer's Progression Modeling using Cross-Domain Self-Supervised Deep Learning",
    "volume": "main",
    "abstract": "Developing successful artificial intelligence systems in practice depends on both robust deep learning models and large, high-quality data. However, acquiring and labeling data can be prohibitively expensive and time-consuming in many real-world applications, such as clinical disease models. Self-supervised learning has demonstrated great potential in increasing model accuracy and robustness in small data regimes. In addition, many clinical imaging and disease modeling applications rely heavily on regression of continuous quantities. However, the applicability of self-supervised learning for these medical-imaging regression tasks has not been extensively studied. In this study, we develop a cross-domain self-supervised learning approach for disease prognostic modeling as a regression problem using medical images as input. We demonstrate that self-supervised pretraining can improve the prediction of Alzheimer's Disease progression from brain MRI. We also show that pretraining on extended (but not labeled) brain MRI data outperforms pretraining on natural images. We further observe that the highest performance is achieved when both natural images and extended brain-MRI data are used for pretraining",
    "checked": true,
    "id": "c0767c2a97506c762d28b5356d312dab0682da8a",
    "semantic_title": "robust alzheimer's progression modeling using cross-domain self-supervised deep learning",
    "citation_count": 0,
    "authors": [
      "Saba Dadsetan",
      "Mohsen Hejrati",
      "Shandong Wu",
      "Somaye Hashemifar"
    ]
  },
  "https://openreview.net/forum?id=LRYtNj8Xw0": {
    "title": "Learning Augmentation Distributions using Transformed Risk Minimization",
    "volume": "main",
    "abstract": "We propose a new \\emph{Transformed Risk Minimization} (TRM) framework as an extension of classical risk minimization. In TRM, we optimize not only over predictive models, but also over data transformations; specifically over distributions thereof. As a key application, we focus on learning augmentations; for instance appropriate rotations of images, to improve classification performance with a given class of predictors. Our TRM method (1) jointly learns transformations and models in a \\emph{single training loop}, (2) works with any training algorithm applicable to standard risk minimization, and (3) handles any transforms, such as discrete and continuous classes of augmentations. To avoid overfitting when implementing empirical transformed risk minimization, we propose a novel regularizer based on PAC-Bayes theory. For learning augmentations of images, we propose a new parametrization of the space of augmentations via a stochastic composition of blocks of geometric transforms. This leads to the new \\emph{Stochastic Compositional Augmentation Learning} (SCALE) algorithm. The performance of TRM with SCALE compares favorably to prior methods on CIFAR10/100. Additionally, we show empirically that SCALE can correctly learn certain symmetries in the data distribution (recovering rotations on rotated MNIST) and can also improve calibration of the learned model",
    "checked": true,
    "id": "dff0c9f18456b38aaefe44daccc0070a7c47b89f",
    "semantic_title": "learning augmentation distributions using transformed risk minimization",
    "citation_count": 15,
    "authors": [
      "Evangelos Chatzipantazis",
      "Stefanos Pertigkiozoglou",
      "Kostas Daniilidis",
      "Edgar Dobriban"
    ]
  },
  "https://openreview.net/forum?id=qUxBs3Ln41": {
    "title": "Structured Low-Rank Tensors for Generalized Linear Models",
    "volume": "main",
    "abstract": "Recent works have shown that imposing tensor structures on the coefficient tensor in regression problems can lead to more reliable parameter estimation and lower sample complexity compared to vector-based methods. This work investigates a new low-rank tensor model, called Low Separation Rank (LSR), in Generalized Linear Model (GLM) problems. The LSR model – which generalizes the well-known Tucker and CANDECOMP/PARAFAC (CP) models, and is a special case of the Block Tensor Decomposition (BTD) model – is imposed onto the coefficient tensor in the GLM model. This work proposes a block coordinate descent algorithm for parameter estimation in LSR-structured tensor GLMs. Most importantly, it derives a minimax lower bound on the error threshold on estimating the coefficient tensor in LSR tensor GLM problems. The minimax bound is proportional to the intrinsic degrees of freedom in the LSR tensor GLM problem, suggesting that its sample complexity may be significantly lower than that of vectorized GLMs. This result can also be specialised to lower bound the estimation error in CP and Tucker-structured GLMs. The derived bounds are comparable to tight bounds in the literature for Tucker linear regression, and the tightness of the minimax lower bound is further assessed numerically. Finally, numerical experiments on synthetic datasets demonstrate the efficacy of the proposed LSR tensor model for three regression types (linear, logistic and Poisson). Experiments on a collection of medical imaging datasets demonstrate the usefulness of the LSR model over other tensor models (Tucker and CP) on real, imbalanced data with limited available samples",
    "checked": true,
    "id": "a50e94dba02e53b032039f29bef46a70e6d63150",
    "semantic_title": "structured low-rank tensors for generalized linear models",
    "citation_count": 2,
    "authors": [
      "Batoul Ahmad Taki",
      "Anand Sarwate",
      "Waheed U. Bajwa"
    ]
  },
  "https://openreview.net/forum?id=dXAuvo6CGI": {
    "title": "Scalable Stochastic Gradient Riemannian Langevin Dynamics in Non-Diagonal Metrics",
    "volume": "main",
    "abstract": "Stochastic-gradient sampling methods are often used to perform Bayesian inference on neural networks. It has been observed that the methods in which notions of differential geometry are included tend to have better performances, with the Riemannian metric improving posterior exploration by accounting for the local curvature. However, the existing methods often resort to simple diagonal metrics to remain computationally efficient. This loses some of the gains. We propose two non-diagonal metrics that can be used in stochastic-gradient samplers to improve convergence and exploration but have only a minor computational overhead over diagonal metrics. We show that for fully connected neural networks (NNs) with sparsity-inducing priors and convolutional NNs with correlated priors, using these metrics can provide improvements. For some other choices the posterior is sufficiently easy also for the simpler metrics",
    "checked": true,
    "id": "5bcc7910b5dd5fe9c3445428c27412c3ef2c4eac",
    "semantic_title": "scalable stochastic gradient riemannian langevin dynamics in non-diagonal metrics",
    "citation_count": 6,
    "authors": [
      "Hanlin Yu",
      "Marcelo Hartmann",
      "Bernardo Williams",
      "Arto Klami"
    ]
  },
  "https://openreview.net/forum?id=HwcB5elyuG": {
    "title": "Towards a Defense Against Federated Backdoor Attacks Under Continuous Training",
    "volume": "main",
    "abstract": "Backdoor attacks are dangerous and difficult to prevent in federated learning (FL), where training data is sourced from untrusted clients over long periods of time. These difficulties arise because: (a) defenders in FL do not have access to raw training data, and (b) a phenomenon we identify called backdoor leakage causes models trained continuously to eventually suffer from backdoors due to cumulative errors in defense mechanisms. We propose a framework called shadow learning for defending against backdoor attacks in the FL setting under long-range training. Shadow learning trains two models in parallel: a backbone model and a shadow model. The backbone is trained without any defense mechanism to obtain good performance on the main task. The shadow model combines filtering of malicious clients with early-stopping to control the attack success rate even as the data distribution changes. We theoretically motivate our design and show experimentally that our framework significantly improves upon existing defenses against backdoor attacks",
    "checked": true,
    "id": "fdcd2cb908f32a35b5504467182f7ca631074aaf",
    "semantic_title": "towards a defense against federated backdoor attacks under continuous training",
    "citation_count": 0,
    "authors": [
      "Shuaiqi Wang",
      "Jonathan Hayase",
      "Giulia Fanti",
      "Sewoong Oh"
    ]
  },
  "https://openreview.net/forum?id=9jnsPp8DP3": {
    "title": "mL-BFGS: A Momentum-based L-BFGS for Distributed Large-scale Neural Network Optimization",
    "volume": "main",
    "abstract": "Quasi-Newton methods still face significant challenges in training large-scale neural networks due to additional compute costs in the Hessian related computations and instability issues in stochastic training. A well-known method, L-BFGS that efficiently approximates the Hessian using history parameter and gradient changes, suffers convergence instability in stochastic training. So far, attempts that adapt L-BFGS to large-scale stochastic training incur considerable extra overhead, which offsets its convergence benefits in wall-clock time. In this paper, we propose mL-BFGS, a lightweight momentum-based L-BFGS algorithm that paves the way for quasi-Newton (QN) methods in large-scale distributed deep neural network (DNN) optimization. mL-BFGS introduces a nearly cost-free momentum scheme into L-BFGS update and greatly reduces stochastic noise in the Hessian, therefore stabilizing convergence during stochastic optimization. For model training at a large scale, mL-BFGS approximates a block-wise Hessian, thus enabling distributing compute and memory costs across all computing nodes. We provide a supporting convergence analysis for mL-BFGS in stochastic settings. To investigate mL-BFGS's potential in large-scale DNN training, we train benchmark neural models using mL-BFGS and compare performance with baselines (SGD, Adam, and other quasi-Newton methods). Results show that mL-BFGS achieves both noticeable iteration-wise and wall-clock speedup",
    "checked": true,
    "id": "f43c6109e3275fd025c95982653e378f93e5e5b2",
    "semantic_title": "ml-bfgs: a momentum-based l-bfgs for distributed large-scale neural network optimization",
    "citation_count": 2,
    "authors": [
      "Yue Niu",
      "Zalan Fabian",
      "Sunwoo Lee",
      "Mahdi Soltanolkotabi",
      "Salman Avestimehr"
    ]
  },
  "https://openreview.net/forum?id=lu4oAq55iK": {
    "title": "Mitigating Real-World Distribution Shifts in the Fourier Domain",
    "volume": "main",
    "abstract": "While machine learning systems can be highly accurate in their training environments, their performance in real-world deployments can suffer significantly due to distribution shifts. Real-world distribution shifts involve various input distortions due to noise, weather, device and other variations. Many real-world distribution shifts are not represented in standard domain adaptation datasets and prior empirical work has shown that domain adaptation methods developed using these standard datasets may not generalize well to real-world distribution shifts. Furthermore, motivated by observations of the sensitivity of deep neural networks (DNN) to the spectral statistics of data, which can vary in real-world scenarios, we propose Fourier Moment Matching (FMM), a model-agnostic input transformation that matches the Fourier-amplitude statistics of source to target data using unlabeled samples. We demonstrate through extensive empirical evaluations across time-series, image classification and semantic segmentation tasks that FMM is effective both individually and when combined with a variety of existing methods to overcome real-world distribution shifts. Code is available at https://github.com/kiranchari/FourierMomentMatching",
    "checked": true,
    "id": "48c2dcc475d7e331787665c63a063fb7ec727b98",
    "semantic_title": "mitigating real-world distribution shifts in the fourier domain",
    "citation_count": 2,
    "authors": [
      "Kiran Krishnamachari",
      "See-Kiong Ng",
      "Chuan-Sheng Foo"
    ]
  },
  "https://openreview.net/forum?id=nOIGfQnFZm": {
    "title": "Learning representations that are closed-form Monge mapping optimal with application to domain adaptation",
    "volume": "main",
    "abstract": "Optimal transport (OT) is a powerful geometric tool used to compare and align probability measures following the least effort principle. Despite its widespread use in machine learning (ML), OT problem still bears its computational burden, while at the same time suffering from the curse of dimensionality for measures supported on general high-dimensional spaces. In this paper, we propose to tackle these challenges using representation learning. In particular, we seek to learn an embedding space such that the samples of the two input measures become alignable in it with a simple affine mapping that can be calculated efficiently in closed-form. We then show that such approach leads to results that are comparable to solving the original OT problem when applied to the transfer learning task on which many OT baselines where previously evaluated in both homogeneous and heterogeneous DA settings",
    "checked": true,
    "id": "a627931bd2fcecee236ee12a4074449cdd246020",
    "semantic_title": "learning representations that are closed-form monge mapping optimal with application to domain adaptation",
    "citation_count": 2,
    "authors": [
      "Oliver Struckmeier",
      "Ievgen Redko",
      "Anton Mallasto",
      "Karol Arndt",
      "Markus Heinonen",
      "Ville Kyrki"
    ]
  },
  "https://openreview.net/forum?id=kdfiEu1ul6": {
    "title": "Learning from time-dependent streaming data with online stochastic algorithms",
    "volume": "main",
    "abstract": "This paper addresses stochastic optimization in a streaming setting with time-dependent and biased gradient estimates. We analyze several first-order methods, including Stochastic Gradient Descent (SGD), mini-batch SGD, and time-varying mini-batch SGD, along with their Polyak-Ruppert averages. Our non-asymptotic analysis establishes novel heuristics that link dependence, biases, and convexity levels, enabling accelerated convergence. Specifically, our findings demonstrate that (i) time-varying mini-batch SGD methods have the capability to break long- and short-range dependence structures, (ii) biased SGD methods can achieve comparable performance to their unbiased counterparts, and (iii) incorporating Polyak-Ruppert averaging can accelerate the convergence of the stochastic optimization algorithms. To validate our theoretical findings, we conduct a series of experiments using both simulated and real-life time-dependent data",
    "checked": true,
    "id": "d03adf26d8e776be8a5f98d6a100187e5d7c142f",
    "semantic_title": "learning from time-dependent streaming data with online stochastic algorithms",
    "citation_count": 4,
    "authors": [
      "Antoine Godichon-Baggioni",
      "Nicklas Werge",
      "Olivier Wintenberger"
    ]
  },
  "https://openreview.net/forum?id=W0ehjkl9x7": {
    "title": "DoCoM: Compressed Decentralized Optimization with Near-Optimal Sample Complexity",
    "volume": "main",
    "abstract": "This paper proposes the Doubly Compressed Momentum-assisted stochastic gradient tracking algorithm (DoCoM) for communication-efficient decentralized optimization. The algorithm features two main ingredients to achieve a near-optimal sample complexity while allowing for communication compression. First, the algorithm tracks both the averaged iterate and stochastic gradient using compressed gossiping consensus. Second, a momentum step is incorporated for adaptive variance reduction with the local gradient estimates. We show that DoCoM finds a near-stationary solution at all participating agents satisfying $\\mathbb{E}[ \\| \\nabla f( \\theta ) \\|^2 ] = {\\cal O}( 1 / T^{2/3} )$ in $T$ iterations, where $f(\\theta)$ is a smooth (possibly non-convex) objective function. Notice that the proof is achieved via analytically designing a new potential function that tightly tracks the one-iteration progress of DoCoM. As a corollary, our analysis also established the linear convergence of DoCoM to a global optimal solution for objective functions with the Polyak-Łojasiewicz condition. Numerical experiments demonstrate that our algorithm outperforms several state-of-the-art algorithms in practice",
    "checked": true,
    "id": "daaf014ab4b0630e0146dd6870a035075dcaaf55",
    "semantic_title": "docom: compressed decentralized optimization with near-optimal sample complexity",
    "citation_count": 7,
    "authors": [
      "Chung-Yiu Yau",
      "Hoi To Wai"
    ]
  },
  "https://openreview.net/forum?id=moVEUgJaHO": {
    "title": "GPS++: Reviving the Art of Message Passing for Molecular Property Prediction",
    "volume": "main",
    "abstract": "We present GPS++, a hybrid Message Passing Neural Network / Graph Transformer model for molecular property prediction. Our model integrates a well-tuned local message passing component and biased global attention with other key ideas from prior literature to achieve state-of-the-art results on large-scale molecular dataset PCQM4Mv2. Through a thorough ablation study we highlight the impact of individual components and find that nearly all of the model's performance can be maintained without any use of global self-attention, showing that message passing is still a competitive approach for 3D molecular property prediction despite the recent dominance of graph transformers. We also find that our approach is significantly more accurate than prior art when 3D positional information is not available",
    "checked": true,
    "id": "db3d0ad5e70f073c9383d199093127e9f70d74db",
    "semantic_title": "gps++: reviving the art of message passing for molecular property prediction",
    "citation_count": 8,
    "authors": [
      "Dominic Masters",
      "Josef Dean",
      "Kerstin Klaeser",
      "Zhiyi Li",
      "Samuel Maddrell-Mander",
      "Adam Sanders",
      "Hatem Helal",
      "Deniz Beker",
      "Andrew W Fitzgibbon",
      "Shenyang Huang",
      "Ladislav Rampášek",
      "Dominique Beaini"
    ]
  },
  "https://openreview.net/forum?id=3LzgOQ3eOb": {
    "title": "Tackling Provably Hard Representative Selection via Graph Neural Networks",
    "volume": "main",
    "abstract": "Representative Selection (RS) is the problem of finding a small subset of exemplars from a dataset that is representative of the dataset. In this paper, we study RS for attributed graphs, and focus on finding representative nodes that optimize the accuracy of a model trained on the selected representatives. Theoretically, we establish a new hardness result for RS (in the absence of a graph structure) by proving that a particular, highly practical variant of it (RS for Learning) is hard to approximate in polynomial time within any reasonable factor, which implies a significant potential gap between the optimum solution of widely-used surrogate functions and the actual accuracy of the model. We then study the setting where a (homophilous) graph structure is available, or can be constructed, between the data points. We show that with an appropriate modeling approach, the presence of such a structure can turn a hard RS (for learning) problem into one that can be effectively solved. To this end, we develop RS-GNN, a representation learning-based RS model based on Graph Neural Networks. Empirically, we demonstrate the effectiveness of RS-GNN on problems with predefined graph structures as well as problems with graphs induced from node feature similarities, by showing that RS-GNN achieves significant improvements over established baselines on a suite of eight benchmarks",
    "checked": true,
    "id": "ba9e9e6fbc3ed6104a2184004278d825854020aa",
    "semantic_title": "tackling provably hard representative selection via graph neural networks",
    "citation_count": 2,
    "authors": [
      "Mehran Kazemi",
      "Anton Tsitsulin",
      "Hossein Esfandiari",
      "Mohammadhossein Bateni",
      "Deepak Ramachandran",
      "Bryan Perozzi",
      "Vahab Mirrokni"
    ]
  },
  "https://openreview.net/forum?id=Qlvgq9eC63": {
    "title": "Improved Group Robustness via Classifier Retraining on Independent Splits",
    "volume": "main",
    "abstract": "Deep neural networks trained by minimizing the average risk can achieve strong average performance. Still, their performance for a subgroup may degrade if the subgroup is underrepresented in the overall data population. Group distributionally robust optimization (Sagawa et al., 2020a), or group DRO in short, is a widely used baseline for learning models with strong worst-group performance. We note that this method requires group labels for every example at training time and can overfit to small groups, requiring strong regularization. Given a limited amount of group labels at training time, Just Train Twice (Liu et al., 2021), or JTT in short, is a two-stage method that infers a pseudo group label for every unlabeled example first, then applies group DRO based on the inferred group labels. The inference process is also sensitive to overfitting, sometimes involving additional hyperparameters. This paper designs a simple method based on the idea of classifier retraining on independent splits of the training data. We find that using a novel sample-splitting procedure achieves robust worst-group performance in the fine-tuning step. When evaluated on benchmark image and text classification tasks, our approach consistently performs favorably to group DRO, JTT, and other strong baselines when either group labels are available during training or are only given in validation sets. Importantly, our method only relies on a single hyperparameter, which adjusts the fraction of labels used for training feature extractors vs. training classification layers. We justify the rationale of our splitting scheme with a generalization-bound analysis of the worst-group loss",
    "checked": true,
    "id": "a681cc1250fa84b7af8472b59f99563f816fa303",
    "semantic_title": "improved group robustness via classifier retraining on independent splits",
    "citation_count": 2,
    "authors": [
      "Thien Hang Nguyen",
      "Hongyang R. Zhang",
      "Huy Nguyen"
    ]
  },
  "https://openreview.net/forum?id=0XBuaxqEcG": {
    "title": "Execution-based Code Generation using Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "The utilization of programming language (PL) models, pre-trained on large-scale code corpora, as a means of automating software engineering processes has demonstrated considerable potential in streamlining various code generation tasks such as code completion, code translation, and program synthesis. However, current approaches mainly rely on supervised fine-tuning objectives borrowed from text generation, neglecting unique sequence-level characteristics of code, including but not limited to compilability as well as syntactic and functional correctness. To address this limitation, we propose PPOCoder, a new framework for code generation that synergistically combines pre-trained PL models with Proximal Policy Optimization (PPO) which is a widely used deep reinforcement learning technique. By utilizing non-differentiable feedback from code execution and structure alignment, PPOCoder seamlessly integrates external code-specific knowledge into the model optimization process. It's important to note that PPOCoder is a task-agnostic and model-agnostic framework that can be used across different code generation tasks and PLs. Extensive experiments on three code generation tasks demonstrate the effectiveness of our proposed approach compared to SOTA methods, achieving significant improvements in compilation success rates and functional correctness across different PLs",
    "checked": true,
    "id": "0a6bc37a07a37e3573d36e10cc11669eca0ff903",
    "semantic_title": "execution-based code generation using deep reinforcement learning",
    "citation_count": 66,
    "authors": [
      "Parshin Shojaee",
      "Aneesh Jain",
      "Sindhu Tipirneni",
      "Chandan K. Reddy"
    ]
  },
  "https://openreview.net/forum?id=TIsrnWpjQ0": {
    "title": "TabCBM: Concept-based Interpretable Neural Networks for Tabular Data",
    "volume": "main",
    "abstract": "Concept-based interpretability addresses the opacity of deep neural networks by constructing an explanation for a model's prediction using high-level units of information referred to as concepts. Research in this area, however, has been mainly focused on image and graph-structured data, leaving high-stakes tasks whose data is tabular out of reach of existing methods. In this paper, we address this gap by introducing the first definition of what a high-level concept may entail in tabular data. We use this definition to propose Tabular Concept Bottleneck Models (TabCBMs), a family of interpretable self-explaining neural architectures capable of learning high-level concept explanations for tabular tasks. As our method produces concept-based explanations both when partial concept supervision or no concept supervision is available at training time, it is adaptable to settings where concept annotations are missing. We evaluate our method in both synthetic and real-world tabular tasks and show that TabCBM outperforms or performs competitively compared to state-of-the-art methods, while providing a high level of interpretability as measured by its ability to discover known high-level concepts. Finally, we show that TabCBM can discover important high-level concepts in synthetic datasets inspired by critical tabular tasks (e.g., single-cell RNAseq) and allows for human-in-the-loop concept interventions in which an expert can identify and correct mispredicted concepts to boost the model's performance",
    "checked": true,
    "id": "ed820008a5e3694147c155359387ab0120732acc",
    "semantic_title": "tabcbm: concept-based interpretable neural networks for tabular data",
    "citation_count": 13,
    "authors": [
      "Mateo Espinosa Zarlenga",
      "Zohreh Shams",
      "Michael Edward Nelson",
      "Been Kim",
      "Mateja Jamnik"
    ]
  },
  "https://openreview.net/forum?id=giw2vcAhiH": {
    "title": "Spectral learning of Bernoulli linear dynamical systems models for decision-making",
    "volume": "main",
    "abstract": "Latent linear dynamical systems with Bernoulli observations provide a powerful modeling framework for identifying the temporal dynamics underlying binary time series data, which arise in a variety of contexts such as binary decision-making and discrete stochastic processes such as binned neural spike trains. Here we develop a spectral learning method for fast, efficient fitting of probit-Bernoulli latent linear dynamical system (LDS) models. Our approach extends traditional subspace identification methods to the Bernoulli setting via a transformation of the first and second sample moments. This results in a robust, fixed-cost estimator that avoids the hazards of local optima and the long computation time of iterative fitting procedures like the expectation-maximization (EM) algorithm. In regimes where data is limited or assumptions about the statistical structure of the data are not met, we demonstrate that the spectral estimate provides a good initialization for Laplace-EM fitting. Finally, we show that the estimator provides substantial benefits to real world settings by analyzing data from mice performing a sensory decision-making task",
    "checked": true,
    "id": "ca305aaa6504e314e4deb8d8a561119c60590c68",
    "semantic_title": "spectral learning of bernoulli linear dynamical systems models for decision-making",
    "citation_count": 1,
    "authors": [
      "Iris R Stone",
      "Yotam Sagiv",
      "Il Memming Park",
      "Jonathan W. Pillow"
    ]
  },
  "https://openreview.net/forum?id=bnBeNFB27b": {
    "title": "Self-Supervision is All You Need for Solving Rubik's Cube",
    "volume": "main",
    "abstract": "Existing combinatorial search methods are often complex and require some level of expertise. This work introduces a simple and efficient deep learning method for solving combinatorial problems with a predefined goal, represented by Rubik's Cube. We demonstrate that, for such problems, training a deep neural network on random scrambles branching from the goal state is sufficient to achieve near-optimal solutions. When tested on Rubik's Cube, 15 Puzzle, and 7$\\times$7 Lights Out, our method outperformed the previous state-of-the-art method DeepCubeA, improving the trade-off between solution optimality and computational cost, despite significantly less training data. Furthermore, we investigate the scaling law of our Rubik's Cube solver with respect to model size and training data volume",
    "checked": true,
    "id": "28141ca1ce5a2c536358d3934a23045b837e2d0c",
    "semantic_title": "self-supervision is all you need for solving rubik's cube",
    "citation_count": 2,
    "authors": [
      "Kyo Takano"
    ]
  },
  "https://openreview.net/forum?id=EYjfLeJL4l": {
    "title": "Towards Better Generalization with Flexible Representation of Multi-Module Graph Neural Networks",
    "volume": "main",
    "abstract": "Graph neural networks (GNNs) have become compelling models designed to perform learning and inference on graph-structured data. However, little work has been done to understand the fundamental limitations of GNNs for scaling to larger graphs and generalizing to out-of-distribution (OOD) inputs. In this paper, we use a random graph generator to systematically investigate how the graph size and structural properties affect the predictive performance of GNNs. We present specific evidence that the average node degree is a key feature in determining whether GNNs can generalize to unseen graphs, and that the use of multiple node update functions can improve the generalization performance of GNNs when dealing with graphs of multimodal degree distributions. Accordingly, we propose a multi-module GNN framework that allows the network to adapt flexibly to new graphs by generalizing a single canonical nonlinear transformation over aggregated inputs. Our results show that the multi-module GNNs improve the OOD generalization on a variety of inference tasks in the direction of diverse structural features",
    "checked": true,
    "id": "54c6b4e63a2b1390ea6d182a8fc88f63264c2000",
    "semantic_title": "towards better generalization with flexible representation of multi-module graph neural networks",
    "citation_count": 2,
    "authors": [
      "HyunGeun Lee",
      "Kijung Yoon"
    ]
  },
  "https://openreview.net/forum?id=5rq8iRzHAQ": {
    "title": "Assisting Human Decisions in Document Matching",
    "volume": "main",
    "abstract": "Many practical applications, ranging from paper-reviewer assignment in peer review to job-applicant matching for hiring, require human decision makers to identify relevant matches by combining their expertise with predictions from machine learning models. In many such model-assisted document matching tasks, the decision makers have stressed the need for assistive information about the model outputs (or the data) to facilitate their decisions. In this paper, we devise a proxy matching task that allows us to evaluate which kinds of assistive information improve decision makers' performance (in terms of accuracy and time). Through a crowdsourced (N = 271 participants) study, we find that providing black-box model explanations reduces users' accuracy on the matching task, contrary to the commonly-held belief that they can be helpful by allowing better understanding of the model. On the other hand, custom methods that are designed to closely attend to some task-specific desiderata are found to be effective in improving user performance. Surprisingly, we also find that the users' perceived utility of assistive information is misaligned with their objective utility (measured through their task performance)",
    "checked": true,
    "id": "92f9859569cf60f841911960af13efeec095882e",
    "semantic_title": "assisting human decisions in document matching",
    "citation_count": 5,
    "authors": [
      "Joon Sik Kim",
      "Valerie Chen",
      "Danish Pruthi",
      "Nihar B Shah",
      "Ameet Talwalkar"
    ]
  },
  "https://openreview.net/forum?id=T5sXdAO3EQ": {
    "title": "Bayesian Quadrature for Neural Ensemble Search",
    "volume": "main",
    "abstract": "Ensembling can improve the performance of Neural Networks, but existing approaches struggle when the architecture likelihood surface has dispersed, narrow peaks. Furthermore, existing methods construct equally weighted ensembles, and this is likely to be vulnerable to the failure modes of the weaker architectures. By viewing ensembling as approximately marginalising over architectures we construct ensembles using the tools of Bayesian Quadrature -- tools which are well suited to the exploration of likelihood surfaces with dispersed, narrow peaks. Additionally, the resulting ensembles consist of architectures weighted commensurate with their performance. We show empirically -- in terms of test likelihood, accuracy, and expected calibration error -- that our method outperforms state-of-the-art baselines, and verify via ablation studies that its components do so independently",
    "checked": true,
    "id": "ac698e49c4ff0a56ec6349bfd7ff28a019fbba0c",
    "semantic_title": "bayesian quadrature for neural ensemble search",
    "citation_count": 1,
    "authors": [
      "Saad Hamid",
      "Xingchen Wan",
      "Martin Jørgensen",
      "Binxin Ru",
      "Michael A Osborne"
    ]
  },
  "https://openreview.net/forum?id=MMsyqXIJuk": {
    "title": "JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games",
    "volume": "main",
    "abstract": "This paper presents an empirical exploration of non-transitivity in perfect-information games, specifically focusing on Xiangqi, a traditional Chinese board game comparable in game-tree complexity to chess and shogi. By analyzing over 10,000 records of human Xiangqi play, we highlight the existence of both transitive and non-transitive elements within the game's strategic structure. To address non-transitivity, we introduce the JiangJun algorithm, an innovative combination of Monte-Carlo Tree Search (MCTS) and Policy Space Response Oracles (PSRO) designed to approximate a Nash equilibrium. We evaluate the algorithm empirically using a WeChat mini program and achieve a Master level with a 99.41% win rate against human players. The algorithm's effectiveness in overcoming non-transitivity is confirmed by a plethora of metrics, such as relative population performance and visualization results. Our project site is available at https://sites.google.com/view/jiangjun-site/",
    "checked": true,
    "id": "55a71b4f487ee7b44ccf5995be96452f95799ecd",
    "semantic_title": "jiangjun: mastering xiangqi by tackling non-transitivity in two-player zero-sum games",
    "citation_count": 2,
    "authors": [
      "Yang Li",
      "Kun Xiong",
      "Yingping Zhang",
      "Jiangcheng Zhu",
      "Stephen Marcus McAleer",
      "Wei Pan",
      "Jun Wang",
      "Zonghong Dai",
      "Yaodong Yang"
    ]
  },
  "https://openreview.net/forum?id=f39UIDkwwc": {
    "title": "Contrastive Attraction and Contrastive Repulsion for Representation Learning",
    "volume": "main",
    "abstract": "Contrastive learning (CL) methods effectively learn data representations in a self-supervision manner, where the encoder contrasts each positive sample over multiple negative samples via a one-vs-many softmax cross-entropy loss. By leveraging large amounts of unlabeled image data, recent CL methods have achieved promising results when pretrained on large-scale datasets, such as ImageNet. However, most of them consider the augmented views from the same instance are positive pairs, while views from other instances are negative ones. Such binary partition insufficiently considers the relation between samples and tends to yield worse performance when generalized on images in the wild. In this paper, to further improve the performance of CL and enhance its robustness on various datasets, we propose a doubly CL strategy that contrasts positive samples and negative ones within themselves separately. We realize this strategy with contrastive attraction and contrastive repulsion (CACR), which makes the query not only exert a greater force to attract more distant positive samples but also do so to repel closer negative samples. Theoretical analysis reveals that CACR generalizes CL's behavior by positive attraction and negative repulsion. It further considers the intra-contrastive relation within the positive and negative pairs to narrow the gap between the sampled and true distribution, which is important when datasets are less curated. Extensive large-scale experiments on standard vision tasks show that CACR not only consistently outperforms existing CL methods on benchmark datasets, but also shows better robustness when generalized on imbalanced image datasets",
    "checked": true,
    "id": "bc25c37c98b6e0e5424ee173425983228c6e09ab",
    "semantic_title": "contrastive attraction and contrastive repulsion for representation learning",
    "citation_count": 12,
    "authors": [
      "Huangjie Zheng",
      "Xu Chen",
      "Jiangchao Yao",
      "Hongxia Yang",
      "Chunyuan Li",
      "Ya Zhang",
      "Hao Zhang",
      "Ivor Tsang",
      "Jingren Zhou",
      "Mingyuan Zhou"
    ]
  },
  "https://openreview.net/forum?id=HyzCuCV1jH": {
    "title": "Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success",
    "volume": "main",
    "abstract": "Self-supervised learning (SSL) has emerged as a promising alternative to create supervisory signals to real-world problems, avoiding the extensive cost of manual labeling. SSL is particularly attractive for unsupervised tasks such as anomaly detection (AD), where labeled anomalies are rare or often nonexistent. A large catalog of augmentation functions has been used for SSL-based AD (SSAD) on image data, and recent works have reported that the type of augmentation has a significant impact on accuracy. Motivated by those, this work sets out to put image-based SSAD under a larger lens and investigate the role of data augmentation in SSAD. Through extensive experiments on 3 different detector models and across 420 AD tasks, we provide comprehensive numerical and visual evidences that the alignment between data augmentation and anomaly-generating mechanism is the key to the success of SSAD, and in the lack thereof, SSL may even impair accuracy. To the best of our knowledge, this is the first meta-analysis on the role of data augmentation in SSAD",
    "checked": true,
    "id": "55b54d10679881181433da73d535a7506fca6c17",
    "semantic_title": "data augmentation is a hyperparameter: cherry-picked self-supervision for unsupervised anomaly detection is creating the illusion of success",
    "citation_count": 8,
    "authors": [
      "Jaemin Yoo",
      "Tiancheng Zhao",
      "Leman Akoglu"
    ]
  },
  "https://openreview.net/forum?id=Wcui061fxr": {
    "title": "Conditional Generative Models are Provably Robust: Pointwise Guarantees for Bayesian Inverse Problems",
    "volume": "main",
    "abstract": "Conditional generative models became a very powerful tool to sample from Bayesian inverse problem posteriors. It is well-known in classical Bayesian literature that posterior measures are quite robust with respect to perturbations of both the prior measure and the negative log-likelihood, which includes perturbations of the observations. However, to the best of our knowledge, the robustness of conditional generative models with respect to perturbations of the observations has not been investigated yet. In this paper, we prove for the first time that appropriately learned conditional generative models provide robust results for single observations",
    "checked": true,
    "id": "e657d82a6773a87cefe110a3e9d6f0bc5385c056",
    "semantic_title": "conditional generative models are provably robust: pointwise guarantees for bayesian inverse problems",
    "citation_count": 9,
    "authors": [
      "Fabian Altekrüger",
      "Paul Hagemann",
      "Gabriele Steidl"
    ]
  },
  "https://openreview.net/forum?id=eLX5XrajXh": {
    "title": "A Characteristic Function for Shapley-Value-Based Attribution of Anomaly Scores",
    "volume": "main",
    "abstract": "In anomaly detection, the degree of irregularity is often summarized as a real-valued anomaly score. We address the problem of attributing such anomaly scores to input features for interpreting the results of anomaly detection. We particularly investigate the use of the Shapley value for attributing anomaly scores of semi-supervised detection methods. We propose a characteristic function specifically designed for attributing anomaly scores. The idea is to approximate the absence of some features by locally minimizing the anomaly score with regard to the to-be-absent features. We examine the applicability of the proposed characteristic function and other general approaches for interpreting anomaly scores on multiple datasets and multiple anomaly detection methods. The results indicate the potential utility of the attribution methods including the proposed one",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naoya Takeishi",
      "Yoshinobu Kawahara"
    ]
  },
  "https://openreview.net/forum?id=QBMyDZsPMd": {
    "title": "The Open MatSci ML Toolkit: A Flexible Framework for Machine Learning in Materials Science",
    "volume": "main",
    "abstract": "We present the Open MatSci ML Toolkit: a flexible, self-contained, and scalable Python-based framework to apply deep learning models and methods on scientific data with a specific focus on materials science and the OpenCatalyst Dataset. Our toolkit provides: 1. A scalable machine learning workflow for materials science leveraging PyTorch Lightning, which enables seamless scaling across different computation capabilities (laptop, server, cluster) and hardware platforms (CPU, GPU, XPU). 2. Deep Graph Library (DGL) support for rapid graph neural network prototyping and development. By publishing and sharing this toolkit with the research community via open-source release, we hope to: 1. Lower the entry barrier for new machine learning researchers and practitioners that want to get started with the OpenCatalyst dataset, which presently comprises the largest computational materials science dataset. 2. Enable the scientific community to apply advanced machine learning tools to high-impact scientific challenges, such as modeling of materials behavior for clean energy applications. We demonstrate the capabilities of our framework by enabling three new equivariant neural network models for multiple OpenCatalyst tasks and arrive at promising results for compute scaling and model performance. The code of the framework and experiments presented in this is paper are publicly available at https://github.com/IntelLabs/matsciml",
    "checked": true,
    "id": "21f9ddb6f39b2678bf9266d63895cdf71906784e",
    "semantic_title": "the open matsci ml toolkit: a flexible framework for machine learning in materials science",
    "citation_count": 19,
    "authors": [
      "Santiago Miret",
      "Kin Long Kelvin Lee",
      "Carmelo Gonzales",
      "Marcel Nassar",
      "Matthew Spellings"
    ]
  },
  "https://openreview.net/forum?id=mXfkKtu5JA": {
    "title": "Differentiable Logic Machines",
    "volume": "main",
    "abstract": "The integration of reasoning, learning, and decision-making is key to build more general artificial intelligence systems. As a step in this direction, we propose a novel neural-logic architecture, called differentiable logic machine (DLM), that can solve both inductive logic programming (ILP) and reinforcement learning (RL) problems, where the solution can be interpreted as a first-order logic program. Our proposition includes several innovations. Firstly, our architecture defines a restricted but expressive continuous relaxation of the space of first-order logic programs by assigning weights to predicates instead of rules, in contrast to most previous neural-logic approaches. Secondly, with this differentiable architecture, we propose several (supervised and RL) training procedures, based on gradient descent, which can recover a fully-interpretable solution (i.e., logic formula). Thirdly, to accelerate RL training, we also design a novel critic architecture that enables actor-critic algorithms. Fourthly, to solve hard problems, we propose an incremental training procedure that can learn a logic program progressively. Compared to state-of-the-art (SOTA) differentiable ILP methods, DLM successfully solves all the considered ILP problems with a higher percentage of successful seeds (up to 3.5x). On RL problems, without requiring an interpretable solution, DLM outperforms other non-interpretable neural-logic RL approaches in terms of rewards (up to 3.9%). When enforcing interpretability, DLM can solve harder RL problems (e.g., Sorting, Path) than other interpretable RL methods. Moreover, we show that deep logic programs can be learned via incremental supervised training. In addition to this excellent performance, DLM can scale well in terms of memory and computational time, especially during the testing phase where it can deal with much more constants (>2x) than SOTA",
    "checked": true,
    "id": "467704b051b96198fb38c83eb5dcf046c1ef6779",
    "semantic_title": "differentiable logic machines",
    "citation_count": 25,
    "authors": [
      "Matthieu Zimmer",
      "Xuening Feng",
      "Claire Glanois",
      "Zhaohui JIANG",
      "Jianyi Zhang",
      "Paul Weng",
      "Dong Li",
      "Jianye HAO",
      "Wulong Liu"
    ]
  },
  "https://openreview.net/forum?id=kdPcLdJbt1": {
    "title": "Vulnerability-Aware Instance Reweighting For Adversarial Training",
    "volume": "main",
    "abstract": "Adversarial Training (AT) has been found to substantially improve the robustness of deep learning classifiers against adversarial attacks. AT involves obtaining robustness by including adversarial examples in training a classifier. Most variants of AT algorithms treat every training example equally. However, recent works have shown that better performance is achievable by treating them unequally. In addition, it has been observed that AT exerts an uneven influence on different classes in a training set and unfairly hurts examples corresponding to classes that are inherently harder to classify. Consequently, various reweighting schemes have been proposed that assign unequal weights to robust losses of individual examples in a training set. In this work, we propose a novel instance-wise reweighting scheme. It considers the vulnerability of each natural example and the resulting information loss on its adversarial counterpart occasioned by adversarial attacks. Through extensive experiments, we show that our proposed method significantly improves over existing reweighting schemes, especially against strong white and black-box attacks",
    "checked": true,
    "id": "544a68888a72406b86732d84447b00b769994509",
    "semantic_title": "vulnerability-aware instance reweighting for adversarial training",
    "citation_count": 2,
    "authors": [
      "Olukorede Fakorede",
      "Ashutosh Kumar Nirala",
      "Modeste Atsague",
      "Jin Tian"
    ]
  },
  "https://openreview.net/forum?id=V7tahqGrOq": {
    "title": "Lifelong Reinforcement Learning with Modulating Masks",
    "volume": "main",
    "abstract": "Lifelong learning aims to create AI systems that continuously and incrementally learn during a lifetime, similar to biological learning. Attempts so far have met problems, including catastrophic forgetting, interference among tasks, and the inability to exploit previous knowledge. While considerable research has focused on learning multiple supervised classification tasks that involve changes in the input distribution, lifelong reinforcement learning (LRL) must deal with variations in the state and transition distributions, and in the reward functions. Modulating masks with a fixed backbone network, recently developed for classification, are particularly suitable to deal with such a large spectrum of task variations. In this paper, we adapted modulating masks to work with deep LRL, specifically PPO and IMPALA agents. The comparison with LRL baselines in both discrete and continuous RL tasks shows superior performance. We further investigated the use of a linear combination of previously learned masks to exploit previous knowledge when learning new tasks: not only is learning faster, the algorithm solves tasks that we could not otherwise solve from scratch due to extremely sparse rewards. The results suggest that RL with modulating masks is a promising approach to lifelong learning, to the composition of knowledge to learn increasingly complex tasks, and to knowledge reuse for efficient and faster learning",
    "checked": true,
    "id": "f0477752396768025ddcd52ea9305813e51b5f35",
    "semantic_title": "lifelong reinforcement learning with modulating masks",
    "citation_count": 24,
    "authors": [
      "Eseoghene Ben-Iwhiwhu",
      "Saptarshi Nath",
      "Praveen Kumar Pilly",
      "Soheil Kolouri",
      "Andrea Soltoggio"
    ]
  },
  "https://openreview.net/forum?id=ILNqQhGbLx": {
    "title": "Semantic Self-adaptation: Enhancing Generalization with a Single Sample",
    "volume": "main",
    "abstract": "The lack of out-of-domain generalization is a critical weakness of deep networks for semantic segmentation. Previous studies relied on the assumption of a static model, i. e., once the training process is complete, model parameters remain fixed at test time. In this work, we challenge this premise with a self-adaptive approach for semantic segmentation that adjusts the inference process to each input sample. Self-adaptation operates on two levels. First, it fine-tunes the parameters of convolutional layers to the input image using consistency regularization. Second, in Batch Normalization layers, self-adaptation interpolates between the training and the reference distribution derived from a single test sample. Despite both techniques being well known in the literature, their combination sets new state-of-the-art accuracy on synthetic-to-real generalization benchmarks. Our empirical study suggests that self-adaptation may complement the established practice of model regularization at training time for improving deep network generalization to out-of-domain data. Our code and pre-trained models are available at https://github.com/visinf/self-adaptive",
    "checked": true,
    "id": "dbf4423150f45eb3d0cc7e78d6530f95a73cc401",
    "semantic_title": "semantic self-adaptation: enhancing generalization with a single sample",
    "citation_count": 9,
    "authors": [
      "Sherwin Bahmani",
      "Oliver Hahn",
      "Eduard Zamfir",
      "Nikita Araslanov",
      "Daniel Cremers",
      "Stefan Roth"
    ]
  },
  "https://openreview.net/forum?id=MyQ1e1VQQ3": {
    "title": "Fair Kernel Regression through Cross-Covariance Operators",
    "volume": "main",
    "abstract": "Ensuring fairness in machine learning models is a difficult problem from both a formulation and implementation perspective. One sensible criterion for achieving fairness is Equalised Odds, which requires that subjects in protected and unprotected groups have equal true and false positive rates. However, practical implementation is challenging. This work proposes two ways to address this issue through the conditional independence operator. First, given the output values, it is used as a fairness measure of independence between model predictions and sensitive variables. Second, it is used as a regularisation term in the problem formulation, which seeks optimal models that balance performance and fairness concerning the sensitive variables. To illustrate the potential of our approach, we consider different scenarios. First, we use the Gaussian model to provide new insights into the problem formulation and numerical results on its convergence. Second, we present the formulation using the conditional cross-covariance operator. We anticipate that a closed-form solution is possible in the general problem formulation, including in the case of a kernel formulation setting. Third, we introduce a normalised criterion of the conditional independence operator. All formulations are posed under the risk minimisation principle, which leads to theoretical results on the performance. Additionally, insights are provided into using these operators under a Gaussian Process setting. Our methods are compared to state-of-the-art methods in terms of performance and fairness metrics on a representative set of real problems. The results obtained with our proposed methodology show promising performance-fairness curves. Furthermore, we discuss the usefulness of linear weights in the fair model to describe the behaviour of the features when enforcing fairness over a particular set of input features",
    "checked": true,
    "id": "662d30853e87a43be7a21ffa4d4e9983dd5bce4c",
    "semantic_title": "fair kernel regression through cross-covariance operators",
    "citation_count": 2,
    "authors": [
      "Adrian Perez-Suay",
      "Paula Gordaliza",
      "Jean-Michel Loubes",
      "Dino Sejdinovic",
      "Gustau Camps-Valls"
    ]
  },
  "https://openreview.net/forum?id=dpGSNLUCzu": {
    "title": "The Score-Difference Flow for Implicit Generative Modeling",
    "volume": "main",
    "abstract": "Implicit generative modeling (IGM) aims to produce samples of synthetic data matching the characteristics of a target data distribution. Recent work (e.g. score-matching networks, diffusion models) has approached the IGM problem from the perspective of pushing synthetic source data toward the target distribution via dynamical perturbations or flows in the ambient space. In this direction, we present the score difference (SD) between arbitrary target and source distributions as a flow that optimally reduces the Kullback-Leibler divergence between them while also solving the Schrödinger bridge problem. We apply the SD flow to convenient proxy distributions, which are aligned if and only if the original distributions are aligned. We demonstrate the formal equivalence of this formulation to denoising diffusion models under certain conditions. We also show that the training of generative adversarial networks includes a hidden data-optimization sub-problem, which induces the SD flow under certain choices of loss function when the discriminator is optimal. As a result, the SD flow provides a theoretical link between model classes that individually address the three challenges of the \"generative modeling trilemma\"—high sample quality, mode coverage, and fast sampling—thereby setting the stage for a unified approach",
    "checked": true,
    "id": "676b97f1fceae606b06f79e4d7396907732de74b",
    "semantic_title": "the score-difference flow for implicit generative modeling",
    "citation_count": 2,
    "authors": [
      "Romann M. Weber"
    ]
  },
  "https://openreview.net/forum?id=tLBjsX4tjs": {
    "title": "A Unified Perspective on Natural Gradient Variational Inference with Gaussian Mixture Models",
    "volume": "main",
    "abstract": "Variational inference with Gaussian mixture models (GMMs) enables learning of highly tractable yet multi-modal approximations of intractable target distributions with up to a few hundred dimensions. The two currently most effective methods for GMM-based variational inference, VIPS and iBayes-GMM, both employ independent natural gradient updates for the individual components and their weights. We show for the first time, that their derived updates are equivalent, although their practical implementations and theoretical guarantees differ. We identify several design choices that distinguish both approaches, namely with respect to sample selection, natural gradient estimation, stepsize adaptation, and whether trust regions are enforced or the number of components adapted. We argue that for both approaches, the quality of the learned approximations can heavily suffer from the respective design choices: By updating the individual components using samples from the mixture model, iBayes-GMM often fails to produce meaningful updates to low-weight components, and by using a zero-order method for estimating the natural gradient, VIPS scales badly to higher-dimensional problems. Furthermore, we show that information-geometric trust-regions (used by VIPS) are effective even when using first-order natural gradient estimates, and often outperform the improved Bayesian learning rule (iBLR) update used by iBayes-GMM. We systematically evaluate the effects of design choices and show that a hybrid approach significantly outperforms both prior works. Along with this work, we publish our highly modular and efficient implementation for natural gradient variational inference with Gaussian mixture models, which supports $432$ different combinations of design choices, facilitates the reproduction of all our experiments, and may prove valuable for the practitioner",
    "checked": true,
    "id": "2d5bad54c108443a8532a11febd50c1ce69ea9d5",
    "semantic_title": "a unified perspective on natural gradient variational inference with gaussian mixture models",
    "citation_count": 17,
    "authors": [
      "Oleg Arenz",
      "Philipp Dahlinger",
      "Zihan Ye",
      "Michael Volpp",
      "Gerhard Neumann"
    ]
  },
  "https://openreview.net/forum?id=FbztvhdCX9": {
    "title": "On the Gradient Formula for learning Generative Models with Regularized Optimal Transport Costs",
    "volume": "main",
    "abstract": "Learning a Wasserstein Generative Adversarial Networks (WGAN) requires the differentiation of the optimal transport cost with respect to the parameters of the generative model. In this work, we provide sufficient conditions for the existence of a gradient formula in two different frameworks: the case of semi-discrete optimal transport (i.e. with a discrete target distribution) and the case of regularized optimal transport (i.e. with an entropic penalty). In both cases the gradient formula involves a solution of the semi-dual formulation of the optimal transport cost. Our study makes a connection between the gradient of the WGAN loss function and the Laguerre diagrams associated to semi-discrete transport maps. The learning problem is addressed with an alternating algorithm, which is in general not convergent. However, in most cases, it stabilizes close to a relevant solution for the generative learning problem. We also show that entropic regularization can improve the convergence speed but noticeably changes the shape of the learned generative model",
    "checked": true,
    "id": "a95b8fa116e60976e8256d124780c6cce17b8acc",
    "semantic_title": "on the gradient formula for learning generative models with regularized optimal transport costs",
    "citation_count": 2,
    "authors": [
      "Antoine Houdard",
      "Arthur Leclaire",
      "Nicolas Papadakis",
      "Julien Rabin"
    ]
  },
  "https://openreview.net/forum?id=HP7Qpui5YE": {
    "title": "Understanding Self-Supervised Pretraining with Part-Aware Representation Learning",
    "volume": "main",
    "abstract": "In this paper, we are interested in understanding self-supervised pretraining through studying the capability that self-supervised methods learn part-aware representations. The study is mainly motivated by that random views, used in contrastive learning, and random masked (visible) patches, used in masked image modeling, are often about object parts. We explain that contrastive learning is a part-to-whole task: the projection layer hallucinates the whole object representation from the object part representation learned from the encoder, and that masked image modeling is a part-to-part task: the masked patches of the object are hallucinated from the visible patches. The explanation suggests that the self-supervised pretrained encoder leans toward understanding the object part. We empirically compare the off-the-shelf encoders pretrained with several representative methods on object-level recognition and part-level recognition. The results show that the fully-supervised model outperforms self-supervised models for object-level recognition, and most self-supervised contrastive learning and masked image modeling methods outperform the fully-supervised method for part-level recognition. It is observed that the combination of contrastive learning and masked image modeling further improves the performance",
    "checked": true,
    "id": "fb28002574cf7e6f08a10e3fb39b8f05bc4bad7b",
    "semantic_title": "understanding self-supervised pretraining with part-aware representation learning",
    "citation_count": 8,
    "authors": [
      "Jie Zhu",
      "Jiyang Qi",
      "Mingyu Ding",
      "Xiaokang Chen",
      "Ping Luo",
      "Xinggang Wang",
      "Wenyu Liu",
      "Leye Wang",
      "Jingdong Wang"
    ]
  },
  "https://openreview.net/forum?id=SaVEXFuozg": {
    "title": "DSpar: An Embarrassingly Simple Strategy for Efficient GNN training and inference via Degree-based Sparsification",
    "volume": "main",
    "abstract": "Running Graph Neural Networks (GNNs) on large graphs suffers from notoriously inefficiency. This is attributed to the sparse graph-based operations, which is hard to be accelerated by community hardware, e.g., GPUs and CPUs. One potential solution is to ``sketch'' the original graph by removing unimportant edges, then both the training and inference process are executed on the sparsified graph with improved efficiency. Traditional graph sparsification work calculates the edge importance score, i.e., effective resistance, from graph topology with theoretical guarantee. However, estimating effective resistance is even more expensive than training GNNs itself. Later, learning-based sparsification methods propose to learn the edge importance from data, but with significant overhead due to the extra learning process. Thus, both of them introduce significant ahead-of-training overhead. In this paper, we experimentally and theoretically prove that effective resistance can be approximated using only the node degree information and achieve similar node presentations on graph with/without sparsification. Based on this finding, we propose DSpar, to sparsify the graph once before training based on only the node degree information with negligible ahead-of-training overhead. In practice, for the training phase, DSpar achieves up to $5.9\\times$ faster than baseline with almost no accuracy drop. For the inference phase, DSpar reduces up to $90\\%$ latency",
    "checked": true,
    "id": "809e2aedcbc3703ab6fbf31450b6c115fe00efca",
    "semantic_title": "dspar: an embarrassingly simple strategy for efficient gnn training and inference via degree-based sparsification",
    "citation_count": 15,
    "authors": [
      "Zirui Liu",
      "Kaixiong Zhou",
      "Zhimeng Jiang",
      "Li Li",
      "Rui Chen",
      "Soo-Hyun Choi",
      "Xia Hu"
    ]
  },
  "https://openreview.net/forum?id=1QqIfGZOWu": {
    "title": "Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations",
    "volume": "main",
    "abstract": "Offline reinforcement learning has shown great promise in leveraging large pre-collected datasets for policy learning, allowing agents to forgo often-expensive online data collection. However, offline reinforcement learning from visual observations with continuous action spaces remains under-explored, with a limited understanding of the key challenges in this complex domain. In this paper, we establish simple baselines for continuous control in the visual domain and introduce a suite of benchmarking tasks for offline reinforcement learning from visual observations designed to better represent the data distributions present in real-world offline RL problems and guided by a set of desiderata for offline RL from visual observations, including robustness to visual distractions and visually identifiable changes in dynamics. Using this suite of benchmarking tasks, we show that simple modifications to two popular vision-based online reinforcement learning algorithms, DreamerV2 and DrQ-v2, suffice to outperform existing offline RL methods and establish competitive baselines for continuous control in the visual domain. We rigorously evaluate these algorithms and perform an empirical evaluation of the differences between state-of-the-art model-based and model-free offline RL methods for continuous control from visual observations. All code and data used in this evaluation are open-sourced to facilitate progress in this domain",
    "checked": true,
    "id": "bbae3200de2d742b2bdcecab51f40a8dccb228cb",
    "semantic_title": "challenges and opportunities in offline reinforcement learning from visual observations",
    "citation_count": 56,
    "authors": [
      "Cong Lu",
      "Philip J. Ball",
      "Tim G. J. Rudner",
      "Jack Parker-Holder",
      "Michael A Osborne",
      "Yee Whye Teh"
    ]
  },
  "https://openreview.net/forum?id=LEVbhNrLEL": {
    "title": "Mind the Gap: Mitigating the Distribution Gap in Graph Few-shot Learning",
    "volume": "main",
    "abstract": "Prevailing supervised deep graph learning models often suffer from the issue of label scarcity, leading to performance degradation in the face of limited annotated data. Although numerous graph few-shot learning (GFL) methods have been developed to mitigate this problem, they tend to rely excessively on labeled data. This over-reliance on labeled data can result in impaired generalization ability in the test phase due to the existence of a distribution gap. Moreover, existing GFL methods lack a general purpose as their designs are coupled with task or data-specific characteristics. To address these shortcomings, we propose a novel Self-Distilled Graph Few-shot Learning framework (SDGFL) that is both general and effective. SDGFL leverages a self-distilled contrastive learning procedure to boost GFL. Specifically, our model first pre-trains a graph encoder with contrastive learning using unlabeled data. Later, the trained encoder is frozen as a teacher model to distill a student model with a contrastive loss. The distilled model is then fed to GFL. By learning data representation in a self-supervised manner, SDGFL effectively mitigates the distribution gap and enhances generalization ability. Furthermore, our proposed framework is task and data-independent, making it a versatile tool for general graph mining purposes. To evaluate the effectiveness of our proposed framework, we introduce an information-based measurement that quantifies its capability. Through comprehensive experiments, we demonstrate that SDGFL outperforms state-of-the-art baselines on various graph mining tasks across multiple datasets in the few-shot scenario. We also provide a quantitative measurement of SDGFL's superior performance in comparison to existing methods",
    "checked": true,
    "id": "8c945d9ebce699687fe10ed9d6f2a3c4721842ba",
    "semantic_title": "mind the gap: mitigating the distribution gap in graph few-shot learning",
    "citation_count": 4,
    "authors": [
      "Chunhui Zhang",
      "Hongfu Liu",
      "Jundong Li",
      "Yanfang Ye",
      "Chuxu Zhang"
    ]
  },
  "https://openreview.net/forum?id=HqIuAzBxbh": {
    "title": "Consistent Collaborative Filtering via Tensor Decomposition",
    "volume": "main",
    "abstract": "Collaborative filtering is the de facto standard for analyzing users' activities and building recommendation systems for items. In this work we develop Sliced Anti-symmetric Decomposition (SAD), a new model for collaborative filtering based on implicit feedback. In contrast to traditional techniques where a latent representation of users (user vectors) and items (item vectors) are estimated, SAD introduces one additional latent vector to each item, using a novel three-way tensor view of user-item interactions. This new vector extends user-item preferences calculated by standard dot products to general inner products, producing interactions between items when evaluating their relative preferences. SAD reduces to state-of-the-art (SOTA) collaborative filtering models when the vector collapses to 1, while in this paper we allow its value to be estimated from data. Allowing the values of the new item vector to be different from 1 has profound implications. It suggests users may have nonlinear mental models when evaluating items, allowing the existence of cycles in pairwise comparisons. We demonstrate the efficiency of SAD in both simulated and real world datasets containing over 1M user-item interactions. By comparing with seven SOTA collaborative filtering models with implicit feedbacks, SAD produces the most consistent personalized preferences, in the meanwhile maintaining top-level of accuracy in personalized recommendations. We release the model and inference algorithms in a Python library https://github.com/apple/ml-sad",
    "checked": true,
    "id": "0dccc06f3f05b7174be9756142a795579f6c6eb5",
    "semantic_title": "consistent collaborative filtering via tensor decomposition",
    "citation_count": 0,
    "authors": [
      "Shiwen Zhao",
      "Guillermo Sapiro"
    ]
  },
  "https://openreview.net/forum?id=jkTqJJOGMS": {
    "title": "Provably Convergent Policy Optimization via Metric-aware Trust Region Methods",
    "volume": "main",
    "abstract": "Trust-region methods based on Kullback-Leibler divergence are pervasively used to stabilize policy optimization in reinforcement learning. In this paper, we exploit more flexible metrics and examine two natural extensions of policy optimization with Wasserstein and Sinkhorn trust regions, namely Wasserstein policy optimization (WPO) and Sinkhorn policy optimization (SPO). Instead of restricting the policy to a parametric distribution class, we directly optimize the policy distribution and derive their close-form policy updates based on the Lagrangian duality. Theoretically, we show that WPO guarantees a monotonic performance improvement, and SPO provably converges to WPO as the entropic regularizer diminishes. Moreover, we prove that with a decaying Lagrangian multiplier to the trust region constraint, both methods converge to global optimality. Experiments across tabular domains, robotic locomotion, and continuous control tasks further demonstrate the performance improvement of both approaches, more robustness of WPO to sample insufficiency, and faster convergence of SPO, over state-of-art policy gradient methods",
    "checked": true,
    "id": "2732028656ffa7c240932d38a7e134747c2aefeb",
    "semantic_title": "provably convergent policy optimization via metric-aware trust region methods",
    "citation_count": 3,
    "authors": [
      "Jun Song",
      "Niao He",
      "Lijun Ding",
      "Chaoyue Zhao"
    ]
  },
  "https://openreview.net/forum?id=P6NcRPb13w": {
    "title": "Adjusting Machine Learning Decisions for Equal Opportunity and Counterfactual Fairness",
    "volume": "main",
    "abstract": "Machine learning (ML) methods have the potential to automate high-stakes decisions, such as bail admissions or credit lending, by analyzing and learning from historical data. But these algorithmic decisions may be unfair: in learning from historical data, they may replicate discriminatory practices from the past. In this paper, we propose two algorithms that adjust fitted ML predictors to produce decisions that are fair. Our methods provide post-hoc adjustments to the predictors, without requiring that they be retrained. We consider a causal model of the ML decisions, define fairness through counterfactual decisions within the model, and then form algorithmic decisions that capture the historical data as well as possible but are provably fair. In particular, we consider two definitions of fairness. The first is ``equal counterfactual opportunity,'' where the counterfactual distribution of the decision is the same regardless of the protected attribute; the second is counterfactual fairness. We evaluate the algorithms, and the trade-off between accuracy and fairness, on datasets about admissions, income, credit, and recidivism",
    "checked": true,
    "id": "cb39129d23d427b397d930bca1079a7b8d0176c6",
    "semantic_title": "adjusting machine learning decisions for equal opportunity and counterfactual fairness",
    "citation_count": 4,
    "authors": [
      "Yixin Wang",
      "Dhanya Sridhar",
      "David Blei"
    ]
  },
  "https://openreview.net/forum?id=JJrKbq35l4": {
    "title": "On Average-Case Error Bounds for Kernel-Based Bayesian Quadrature",
    "volume": "main",
    "abstract": "In this paper, we study error bounds for Bayesian quadrature (BQ), with an emphasis on noisy settings, randomized algorithms, and average-case performance measures. We seek to approximate the integral of functions in a Reproducing Kernel Hilbert Space (RKHS), particularly focusing on the Mat\\'ern-$\\nu$ and squared exponential (SE) kernels, with samples from the function potentially being corrupted by Gaussian noise. We provide a two-step meta-algorithm that serves as a general tool for relating the average-case quadrature error with the $L^2$-function approximation error. When specialized to the Mat\\'ern kernel, we recover an existing near-optimal error rate while avoiding the existing method of repeatedly sampling points. When specialized to other settings, we obtain new average-case results for settings including the SE kernel with noise and the Mat\\'ern kernel with misspecification. Finally, we present algorithm-independent lower bounds that have greater generality and/or give distinct proofs compared to existing ones",
    "checked": true,
    "id": "013e187dbf20d5153198b74cef2382b8d47b5413",
    "semantic_title": "on average-case error bounds for kernel-based bayesian quadrature",
    "citation_count": 3,
    "authors": [
      "Xu Cai",
      "Thanh Lam",
      "Jonathan Scarlett"
    ]
  },
  "https://openreview.net/forum?id=ThhMzfrd6r": {
    "title": "Self-Supervised Graph Representation Learning for Neuronal Morphologies",
    "volume": "main",
    "abstract": "Unsupervised graph representation learning has recently gained interest in several application domains such as neuroscience, where modeling the diverse morphology of cell types in the brain is one of the key challenges. It is currently unknown how many excitatory cortical cell types exist and what their defining morphological features are. Here we present GraphDINO, a purely data-driven approach to learn low-dimensional representations of 3D neuronal morphologies from unlabeled large-scale datasets. GraphDINO is a novel transformer-based representation learning method for spatially-embedded graphs. To enable self-supervised learning on transformers, we (1) developed data augmentation strategies for spatially-embedded graphs, (2) adapted the positional encoding and (3) introduced a novel attention mechanism, AC-Attention, which combines attention-based global interaction between nodes and classic graph convolutional processing. We show, in two different species and across multiple brain areas, that this method yields morphological cell type clusterings that are on par with manual feature-based classification by experts, but without using prior knowledge about the structural features of neurons. Moreover, it outperforms previous approaches on quantitative benchmarks predicting expert labels. Our method could potentially enable data-driven discovery of novel morphological features and cell types in large-scale datasets. It is applicable beyond neuroscience in settings where samples in a dataset are graphs and graph-level embeddings are desired",
    "checked": true,
    "id": "804f1bff8f76488c13657f492b5c9d2523ad3a45",
    "semantic_title": "self-supervised graph representation learning for neuronal morphologies",
    "citation_count": 8,
    "authors": [
      "Marissa A. Weis",
      "Laura Pede",
      "Timo Lüddecke",
      "Alexander S Ecker"
    ]
  },
  "https://openreview.net/forum?id=VV4zJwLwI7": {
    "title": "Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling",
    "volume": "main",
    "abstract": "Trying to capture the sample-label relationship, conditional generative models often end up inheriting the spurious correlation in the training dataset, giving label-conditional distributions that are severely imbalanced in another latent attribute. To mitigate such undesirable correlations engraved into generative models, which we call spurious causality, we propose a general two-step strategy. (a) Fairness Intervention (FI): Emphasize the minority samples that are hard to be generated due to the spurious correlation in the training dataset. (b) Corrective Sampling (CS): Filter the generated samples explicitly to follow the desired label-conditional latent attribute distribution. We design the fairness intervention for various degrees of supervision on the spurious attribute, including unsupervised, weakly-supervised, and semi-supervised scenarios. Our experimental results show that the proposed FICS can successfully resolve the spurious correlation in generated samples on various datasets",
    "checked": true,
    "id": "a7cf8f52c7797f2015ab9600cfb4f2993379acb9",
    "semantic_title": "breaking the spurious causality of conditional generation via fairness intervention with corrective sampling",
    "citation_count": 7,
    "authors": [
      "Junhyun Nam",
      "Sangwoo Mo",
      "Jaeho Lee",
      "Jinwoo Shin"
    ]
  },
  "https://openreview.net/forum?id=VpaXrBFYZ9": {
    "title": "Stochastic Constrained DRO with a Complexity Independent of Sample Size",
    "volume": "main",
    "abstract": "Distributionally Robust Optimization (DRO), as a popular method to train robust models against distribution shift between training and test sets, has received tremendous attention in recent years. In this paper, we propose and analyze stochastic algorithms that apply to both non-convex and convex losses for solving Kullback–Leibler divergence constrained DRO problem. Compared with existing methods solving this problem, our stochastic algorithms not only enjoy competitive if not better complexity independent of sample size but also just require a constant batch size at every iteration, which is more practical for broad applications. We establish a nearly optimal complexity bound for finding an $\\epsilon$-stationary solution for non-convex losses and an optimal complexity for finding an $\\epsilon$-optimal solution for convex losses. Empirical studies demonstrate the effectiveness of the proposed algorithms for solving non-convex and convex constrained DRO problems",
    "checked": true,
    "id": "a1382290160a39a7211d8291faa21f3833818061",
    "semantic_title": "stochastic constrained dro with a complexity independent of sample size",
    "citation_count": 16,
    "authors": [
      "Qi Qi",
      "Jiameng Lyu",
      "Kung-Sik Chan",
      "Er-Wei Bai",
      "Tianbao Yang"
    ]
  },
  "https://openreview.net/forum?id=nddEHTSnqg": {
    "title": "Neural Networks beyond explainability: Selective inference for sequence motifs",
    "volume": "main",
    "abstract": "Over the past decade, neural networks have been successful at making predictions from biological sequences, especially in the context of regulatory genomics. As in other fields of deep learning, tools have been devised to extract features such as sequence motifs that can explain the predictions made by a trained network. Here we intend to go beyond explainable machine learning and introduce SEISM, a selective inference procedure to test the association between these extracted features and the predicted phenotype. In particular, we discuss how training a one-layer convolutional network is formally equivalent to selecting motifs maximizing some association score. We adapt existing sampling-based selective inference procedures by quantizing this selection over an infinite set to a large but finite grid. Finally,we show that sampling under a specific choice of parameters is sufficient to characterize the composite null hypothesis typically used for selective inference - a result that goes well beyond our particular framework. We illustrate the behavior of our method in terms of calibration, power and speed and discuss its power/speed trade-off with a simpler data-split strategy. SEISM paves the way to an easier analysis of neural networks used in regulatory genomics, and to more powerful methods for genome wide association studies (GWAS)",
    "checked": true,
    "id": "206b19e38788b5bb0ea8bedac2a1a8fd43f6375f",
    "semantic_title": "neural networks beyond explainability: selective inference for sequence motifs",
    "citation_count": 0,
    "authors": [
      "Antoine Villié",
      "Philippe Veber",
      "Yohann De Castro",
      "Laurent Jacob"
    ]
  },
  "https://openreview.net/forum?id=w36pqfaJ4t": {
    "title": "Dynamics Adapted Imitation Learning",
    "volume": "main",
    "abstract": "We consider Imitation Learning with dynamics variation between the expert demonstration (source domain) and the environment (target domain). Based on the popular framework of Adversarial Imitation Learning, we propose a novel algorithm – Dynamics Adapted Imitation Learning (DYNAIL), which incorporates the dynamics variation into the state-action occupancy measure matching as a regularization term. The dynamics variation is modeled by a pair of classifiers to distinguish between source dynamics and target dynamics. Theoretically, we provide an upper bound on the divergence between the learned policy and expert demonstrations in the source domain. Our error bound only depends on the expectation of the discrepancy between the source and target dynamics for the optimal policy in the target domain. The experiment evaluation validates that our method achieves superior results on high dimensional continuous control tasks, compared to existing imitation learning methods",
    "checked": true,
    "id": "e436df13213f288a3f398482b2a540f1c0602eb9",
    "semantic_title": "dynamics adapted imitation learning",
    "citation_count": 0,
    "authors": [
      "Zixuan Liu",
      "Liu Liu",
      "Bingzhe Wu",
      "Lanqing Li",
      "Xueqian Wang",
      "Bo Yuan",
      "Peilin Zhao"
    ]
  },
  "https://openreview.net/forum?id=CkXOwlhf27": {
    "title": "A Proximal Algorithm for Sampling",
    "volume": "main",
    "abstract": "We study sampling problems associated with potentials that lack smoothness. The potentials can be either convex or non-convex. Departing from the standard smooth setting, the potentials are only assumed to be weakly smooth or non-smooth, or the summation of multiple such functions. We develop a sampling algorithm that resembles proximal algorithms in optimization for this challenging sampling task. Our algorithm is based on a special case of Gibbs sampling known as the alternating sampling framework (ASF). The key contribution of this work is a practical realization of the ASF based on rejection sampling for both non-convex and convex potentials that are not necessarily smooth. In almost all the cases of sampling considered in this work, our proximal sampling algorithm achieves a better complexity than all existing methods",
    "checked": true,
    "id": "be5a49e6dc47608a36cf8ac8f4ec80088e133023",
    "semantic_title": "a proximal algorithm for sampling",
    "citation_count": 20,
    "authors": [
      "Jiaming Liang",
      "Yongxin Chen"
    ]
  },
  "https://openreview.net/forum?id=j3FK00HyfU": {
    "title": "The Meta-Evaluation Problem in Explainable AI: Identifying Reliable Estimators with MetaQuantus",
    "volume": "main",
    "abstract": "One of the unsolved challenges in the field of Explainable AI (XAI) is determining how to most reliably estimate the quality of an explanation method in the absence of ground truth explanation labels. Resolving this issue is of utmost importance as the evaluation outcomes generated by competing evaluation methods (or ``quality estimators''), which aim at measuring the same property of an explanation method, frequently present conflicting rankings. Such disagreements can be challenging for practitioners to interpret, thereby complicating their ability to select the best-performing explanation method. We address this problem through a meta-evaluation of different quality estimators in XAI, which we define as ``the process of evaluating the evaluation method''. Our novel framework, MetaQuantus, analyses two complementary performance characteristics of a quality estimator: its resilience to noise and reactivity to randomness, thus circumventing the need for ground truth labels. We demonstrate the effectiveness of our framework through a series of experiments, targeting various open questions in XAI such as the selection and hyperparameter optimisation of quality estimators. Our work is released under an open-source license (https://github.com/annahedstroem/MetaQuantus) to serve as a development tool for XAI- and Machine Learning (ML) practitioners to verify and benchmark newly constructed quality estimators in a given explainability context. With this work, we provide the community with clear and theoretically-grounded guidance for identifying reliable evaluation methods, thus facilitating reproducibility in the field",
    "checked": true,
    "id": "498cc16f23413c66b17b4bffc8475a4079cb312c",
    "semantic_title": "the meta-evaluation problem in explainable ai: identifying reliable estimators with metaquantus",
    "citation_count": 23,
    "authors": [
      "Anna Hedström",
      "Philine Lou Bommer",
      "Kristoffer Knutsen Wickstrøm",
      "Wojciech Samek",
      "Sebastian Lapuschkin",
      "Marina MC Höhne"
    ]
  },
  "https://openreview.net/forum?id=LdSP6cvTS4": {
    "title": "Calibrating and Improving Graph Contrastive Learning",
    "volume": "main",
    "abstract": "Graph contrastive learning algorithms have demonstrated remarkable success in various applications such as node classification, link prediction, and graph clustering. However, in unsupervised graph contrastive learning, some contrastive pairs may contradict the truths in downstream tasks and thus the decrease of losses on these pairs undesirably harms the performance in the downstream tasks. To assess the discrepancy between the prediction and the ground-truth in the downstream tasks for these contrastive pairs, we adapt expected calibration error (ECE) to graph contrastive learning. The analysis of ECE motivates us to propose a novel regularization method, Contrast-Reg, to ensure that decreasing the contrastive loss leads to better performance in the downstream tasks. As a plug-in regularizer, Contrast-Reg effectively improves the performance of existing graph contrastive learning algorithms. We provide both theoretical and empirical results to demonstrate the effectiveness of Contrast-Reg in enhancing the generalizability of the Graph Neural Network (GNN) model and improving the performance of graph contrastive algorithms with different similarity definitions and encoder backbones across various downstream tasks",
    "checked": true,
    "id": "34cce045b2106decb208e25197619628859fa3c0",
    "semantic_title": "calibrating and improving graph contrastive learning",
    "citation_count": 7,
    "authors": [
      "MA KAILI",
      "Garry YANG",
      "Han Yang",
      "Yongqiang Chen",
      "James Cheng"
    ]
  },
  "https://openreview.net/forum?id=nfYwRIezvg": {
    "title": "DORA: Exploring Outlier Representations in Deep Neural Networks",
    "volume": "main",
    "abstract": "Deep Neural Networks (DNNs) excel at learning complex abstractions within their internal representations. However, the concepts they learn remain opaque, a problem that becomes particularly acute when models unintentionally learn spurious correlations. In this work, we present DORA (Data-agnOstic Representation Analysis), the first data-agnostic framework for analyzing the representational space of DNNs. Central to our framework is the proposed Extreme-Activation (EA) distance measure, which assesses similarities between representations by analyzing their activation patterns on data points that cause the highest level of activation. As spurious correlations often manifest in features of data that are anomalous to the desired task, such as watermarks or artifacts, we demonstrate that internal representations capable of detecting such artifactual concepts can be found by analyzing relationships within neural representations. We validate the EA metric quantitatively, demonstrating its effectiveness both in controlled scenarios and real-world applications. Finally, we provide practical examples from popular Computer Vision models to illustrate that representations identified as outliers using the EA metric often correspond to undesired and spurious concepts",
    "checked": true,
    "id": "93f691020a216dc3a6079ef04b422d8f3a215da0",
    "semantic_title": "dora: exploring outlier representations in deep neural networks",
    "citation_count": 14,
    "authors": [
      "Kirill Bykov",
      "Mayukh Deb",
      "Dennis Grinwald",
      "Klaus Robert Muller",
      "Marina MC Höhne"
    ]
  },
  "https://openreview.net/forum?id=g97OHbQyk1": {
    "title": "The Vendi Score: A Diversity Evaluation Metric for Machine Learning",
    "volume": "main",
    "abstract": "Diversity is an important criterion for many areas of machine learning (ML), including generative modeling and dataset curation. However, existing metrics for measuring diversity are often domain-specific and limited in flexibility. In this paper we address the diversity evaluation problem by proposing the Vendi Score, which connects and extends ideas from ecology and quantum statistical mechanics to ml. The Vendi Score is defined as the exponential of the Shannon entropy of the eigenvalues of a similarity matrix. This matrix is induced by a user-defined similarity function applied to the sample to be evaluated for diversity. In taking a similarity function as input, the Vendi Score enables its user to specify any desired form of diversity. Importantly, unlike many existing metrics in ML, the Vendi Score does not require a reference dataset or distribution over samples or labels, it is therefore general and applicable to any generative model, decoding algorithm, and dataset from any domain where similarity can be defined. We showcase the Vendi Score on molecular generative modeling where we found it addresses shortcomings of the current diversity metric of choice in that domain. We also applied the Vendi Score to generative models of images and decoding algorithms of text where we found it confirms known results about diversity in those domains. Furthermore, we used the Vendi Score to measure mode collapse, a known shortcoming of generative adversarial networks (GANs). In particular, the Vendi Score revealed that even GANs that capture all the modes of a labelled dataset can be less diverse than the original dataset. Finally, the interpretability of the Vendi Score allowed us to diagnose several benchmark ML datasets for diversity, opening the door for diversity-informed data augmentation",
    "checked": true,
    "id": "b03c078303326ff022f525fccdf028b73ccb1cb4",
    "semantic_title": "the vendi score: a diversity evaluation metric for machine learning",
    "citation_count": 138,
    "authors": [
      "Dan Friedman",
      "Adji Bousso Dieng"
    ]
  },
  "https://openreview.net/forum?id=OqbGu3hdQb": {
    "title": "Contextual Combinatorial Multi-output GP Bandits with Group Constraints",
    "volume": "main",
    "abstract": "In federated multi-armed bandit problems, maximizing global reward while satisfying minimum privacy requirements to protect clients is the main goal. To formulate such problems, we consider a combinatorial contextual bandit setting with groups and changing action sets, where similar base arms arrive in groups and a set of base arms, called a super arm, must be chosen in each round to maximize super arm reward while satisfying the constraints of the rewards of groups from which base arms were chosen. To allow for greater flexibility, we let each base arm have two outcomes, modeled as the output of a two-output Gaussian process (GP), where one outcome is used to compute super arm reward and the other for group reward. We then propose a novel double-UCB GP-bandit algorithm, called Thresholded Combinatorial Gaussian Process Upper Confidence Bounds (TCGP-UCB), which balances between maximizing cumulative super arm reward and satisfying group reward constraints and can be tuned to prefer one over the other. We also define a new notion of regret that combines super arm regret with group reward constraint satisfaction and prove that TCGP-UCB incurs $\\tilde{O}(\\sqrt{KT\\overline{\\gamma}_{T}} )$ regret with high probability, where $\\overline{\\gamma}_{T}$ is the maximum information gain associated with the set of base arm contexts that appeared in the first $T$ rounds and $K$ is the maximum super arm cardinality over all rounds. We lastly show in experiments using synthetic and real-world data and based on a federated learning setup as well as a content-recommendation one that our algorithm performs better then the current non-GP state-of-the-art combinatorial bandit algorithm, while satisfying group constraints",
    "checked": true,
    "id": "e514ef53e5e44559cb403bf3cb6a7cad57e0938e",
    "semantic_title": "contextual combinatorial multi-output gp bandits with group constraints",
    "citation_count": 2,
    "authors": [
      "Sepehr Elahi",
      "Baran Atalar",
      "Sevda Öğüt",
      "Cem Tekin"
    ]
  },
  "https://openreview.net/forum?id=Gbu1bHQhEL": {
    "title": "Active Acquisition for Multimodal Temporal Data: A Challenging Decision-Making Task",
    "volume": "main",
    "abstract": "We introduce a challenging decision-making task that we call active acquisition for multimodal temporal data (A2MT). In many real-world scenarios, input features are not readily available at test time and must instead be acquired at significant cost. With A2MT, we aim to learn agents that actively select which modalities of an input to acquire, trading off acquisition cost and predictive performance. A2MT extends a previous task called active feature acquisition to temporal decision making about high-dimensional inputs. We propose a method based on the Perceiver IO architecture to address A2MT in practice. Our agents are able to solve a novel synthetic scenario requiring practically relevant cross-modal reasoning skills. On two large-scale, real-world datasets, Kinetics-700 and AudioSet, our agents successfully learn cost-reactive acquisition behavior. However, an ablation reveals they are unable to learn adaptive acquisition strategies, emphasizing the difficulty of the task even for state-of-the-art models. Applications of A2MT may be impactful in domains like medicine, robotics, or finance, where modalities differ in acquisition cost and informativeness",
    "checked": true,
    "id": "56b35f7bca65566543469e79b04497e3d7436637",
    "semantic_title": "active acquisition for multimodal temporal data: a challenging decision-making task",
    "citation_count": 11,
    "authors": [
      "Jannik Kossen",
      "Cătălina Cangea",
      "Eszter Vértes",
      "Andrew Jaegle",
      "Viorica Patraucean",
      "Ira Ktena",
      "Nenad Tomasev",
      "Danielle Belgrave"
    ]
  },
  "https://openreview.net/forum?id=gwRwHUZUgz": {
    "title": "Learning Symbolic Rules for Reasoning in Quasi-Natural Language",
    "volume": "main",
    "abstract": "Symbolic reasoning, rule-based symbol manipulation, is a hallmark of human intelligence. However, rule-based systems have had limited success competing with learning-based systems outside formalized domains such as automated theorem proving. We hypothesize that this is due to the manual construction of rules in past attempts. In this work, we take initial steps towards rule-based systems that can reason with natural language but without manually constructing rules. We propose MetaQNL, a \"Quasi-Natural Language\" that can express both formal logic and natural language sentences, and MetaInduce, a learning algorithm that induces MetaQNL rules from training data consisting of questions and answers, with or without intermediate reasoning steps. In addition, we introduce soft matching—a flexible mechanism for applying rules without rigid matching, overcoming a typical source of brittleness in symbolic reasoning. Our approach achieves state-of-the-art accuracies on multiple reasoning benchmarks; it learns compact models with much less data and produces not only answers but also checkable proofs. Further, experiments on two simple real-world datasets demonstrate the possibility for our method to handle noise and ambiguity",
    "checked": true,
    "id": "2db6c10f135d5701ae7aec45986124ce264c1344",
    "semantic_title": "learning symbolic rules for reasoning in quasi-natural language",
    "citation_count": 13,
    "authors": [
      "Kaiyu Yang",
      "Jia Deng"
    ]
  },
  "https://openreview.net/forum?id=XJIg4kQbkv": {
    "title": "CoCoFL: Communication- and Computation-Aware Federated Learning via Partial NN Freezing and Quantization",
    "volume": "main",
    "abstract": "Devices participating in federated learning (FL) typically have heterogeneous communication, computation, and memory resources. However, in synchronous FL, all devices need to finish training by the same deadline dictated by the server. Our results show that training a smaller subset of the neural network (NN) at constrained devices, i.e., dropping neurons/filters as proposed by state of the art, is inefficient, preventing these devices to make an effective contribution to the model. This causes unfairness w.r.t the achievable accuracies of constrained devices, especially in cases with a skewed distribution of class labels across devices. We present a novel FL technique, CoCoFL, which maintains the full NN structure on all devices. To adapt to the devices' heterogeneous resources, CoCoFL freezes and quantizes selected layers, reducing communication, computation, and memory requirements, whereas other layers are still trained in full precision, enabling to reach a high accuracy. Thereby, CoCoFL efficiently utilizes the available resources on devices and allows constrained devices to make a significant contribution to the FL system, preserving fairness among participants (accuracy parity) and significantly improving final accuracy",
    "checked": false,
    "id": "518747257702484d80d0d106185eec67c39a57ab",
    "semantic_title": "coco-fl: communication- and computation-aware federated learning via partial nn freezing and quantization",
    "citation_count": 11,
    "authors": [
      "Kilian Pfeiffer",
      "Martin Rapp",
      "Ramin Khalili",
      "Joerg Henkel"
    ]
  },
  "https://openreview.net/forum?id=TdzQtbLeVw": {
    "title": "Online Min-max Problems with Non-convexity and Non-stationarity",
    "volume": "main",
    "abstract": "Online min-max optimization has recently gained considerable interest due to its rich applications to game theory, multi-agent reinforcement learning, online robust learning, etc. Theoretical understanding in this field has been mainly focused on convex-concave settings. Online min-max optimization with nonconvex geometries, which captures various online deep learning problems, has yet been studied so far. In this paper, we make the first effort and investigate online nonconvex-strongly-concave min-max optimization in the nonstationary environment. We first introduce a natural notion of local Nash equilibrium (NE)-regret, and then propose a novel algorithm coined TSODA to achieve the optimal regret. We further generalize our study to the setting with stochastic first-order feedback, and show that a variation of TSODA can also achieve the same optimal regret in expectation. Our theoretical results and the superior performance of the proposed method are further validated by empirical experiments. To our best knowledge, this is the first exploration of efficient online nonconvex min-max optimization",
    "checked": true,
    "id": "0cc96b88549fb81e161e446da8a067cedeb814f4",
    "semantic_title": "online min-max problems with non-convexity and non-stationarity",
    "citation_count": 1,
    "authors": [
      "Yu Huang",
      "Yuan Cheng",
      "Yingbin Liang",
      "Longbo Huang"
    ]
  },
  "https://openreview.net/forum?id=LKz5SqIXPJ": {
    "title": "On the Robustness of Dataset Inference",
    "volume": "main",
    "abstract": "Machine learning (ML) models are costly to train as they can require a significant amount of data, computational resources and technical expertise. Thus, they constitute valuable intellectual property that needs protection from adversaries wanting to steal them. Ownership verification techniques allow the victims of model stealing attacks to demonstrate that a suspect model was in fact stolen from theirs. Although a number of ownership verification techniques based on watermarking or fingerprinting have been proposed, most of them fall short either in terms of security guarantees (well-equipped adversaries can evade verification) or computational cost. A fingerprinting technique, Dataset Inference (DI) has been shown to offer better robustness and efficiency than prior methods. The authors of DI provided a correctness proof for linear (suspect) models. However, in a subspace of the same setting, we prove that DI suffers from high false positives (FPs) -- it can incorrectly identify an independent model trained with non-overlapping data from the same distribution as stolen. We further prove that DI also triggers FPs in realistic, non-linear suspect models. We then confirm empirically that DI in the black-box setting leads to FPs, with high confidence. Second, we show that DI also suffers from false negatives (FNs) -- an adversary can fool DI by regularising a stolen model's decision boundaries using adversarial training, thereby leading to an FN. To this end, we demonstrate that black-box DI fails to identify a model adversarially trained from a stolen dataset -- the setting where DI is the hardest to evade. Finally, we discuss the implications of our findings, the viability of fingerprinting-based ownership verification in general, and suggest directions for future work",
    "checked": true,
    "id": "a46d1f8e5ed6182df8c864e72160372cf2a14b13",
    "semantic_title": "on the robustness of dataset inference",
    "citation_count": 7,
    "authors": [
      "Sebastian Szyller",
      "Rui Zhang",
      "Jian Liu",
      "N Asokan"
    ]
  },
  "https://openreview.net/forum?id=sY35BAiIf4": {
    "title": "Improving Differentially Private SGD via Randomly Sparsified Gradients",
    "volume": "main",
    "abstract": "Differentially private stochastic gradient descent (DP-SGD) has been widely adopted in deep learning to provide rigorously defined privacy, which requires gradient clipping to bound the maximum norm of individual gradients and additive isotropic Gaussian noise. With analysis of the convergence rate of DP-SGD in a non-convex setting, we identify that randomly sparsifying gradients before clipping and noisification adjusts a trade-off between internal components of the convergence bound and leads to a smaller upper bound when the noise is dominant. Additionally, our theoretical analysis and empirical evaluations show that the trade-off is not trivial but possibly a unique property of DP-SGD, as either canceling noisification or gradient clipping eliminates the trade-off in the bound. This observation is indicative, as it implies DP-SGD has special inherent room for (even simply random) gradient compression. To verify the observation an utilize it, we propose an efficient and lightweight extension using random sparsification (RS) to strengthen DP-SGD. Experiments with various DP-SGD frameworks show that RS can improve performance. Additionally, the produced sparse gradients of RS exhibit advantages in reducing communication cost and strengthening privacy against reconstruction attacks, which are also key problems in private machine learning",
    "checked": true,
    "id": "ba5b71313ab921d4c79626e537563c6e0614446f",
    "semantic_title": "improving differentially private sgd via randomly sparsified gradients",
    "citation_count": 6,
    "authors": [
      "Junyi Zhu",
      "Matthew B. Blaschko"
    ]
  },
  "https://openreview.net/forum?id=p28wv4G65d": {
    "title": "SC2 Benchmark: Supervised Compression for Split Computing",
    "volume": "main",
    "abstract": "With the increasing demand for deep learning models on mobile devices, splitting neural network computation between the device and a more powerful edge server has become an attractive solution. However, existing split computing approaches often underperform compared to a naive baseline of remote computation on compressed data. Recent studies propose learning compressed representations that contain more relevant information for supervised downstream tasks, showing improved tradeoffs between compressed data size and supervised performance. However, existing evaluation metrics only provide an incomplete picture of split computing. This study introduces supervised compression for split computing (SC2) and proposes new evaluation criteria: minimizing computation on the mobile device, minimizing transmitted data size, and maximizing model accuracy. We conduct a comprehensive benchmark study using 10 baseline methods, three computer vision tasks, and over 180 trained models, and discuss various aspects of SC2. We also release our code and sc2bench, a Python package for future research on SC2. Our proposed metrics and package will help researchers better understand the tradeoffs of supervised compression in split computing",
    "checked": true,
    "id": "5592106cb23e8958920a10b211921a96afe65199",
    "semantic_title": "sc2 benchmark: supervised compression for split computing",
    "citation_count": 21,
    "authors": [
      "Yoshitomo Matsubara",
      "Ruihan Yang",
      "Marco Levorato",
      "Stephan Mandt"
    ]
  },
  "https://openreview.net/forum?id=izL3B8dPx1": {
    "title": "Inherent Limits on Topology-Based Link Prediction",
    "volume": "main",
    "abstract": "Link prediction systems (e.g. recommender systems) typically use graph topology as one of their main sources of information. However, automorphisms and related properties of graphs beget inherent limits in predictability. We calculate hard upper bounds on how well graph topology alone enables link prediction for a wide variety of real-world graphs. We find that in the sparsest of these graphs the upper bounds are surprisingly low, thereby demonstrating that prediction systems on sparse graph data are inherently limited and require information in addition to the graph topology",
    "checked": true,
    "id": "8cebabc99da5ba488dadeae98626b38347ba6b49",
    "semantic_title": "inherent limits on topology-based link prediction",
    "citation_count": 2,
    "authors": [
      "Justus Isaiah Hibshman",
      "Tim Weninger"
    ]
  },
  "https://openreview.net/forum?id=uv32JOdQuh": {
    "title": "Invariant Feature Coding using Tensor Product Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": "a42f518428bc91d100f323611ddc1179e063feea",
    "semantic_title": "quantum state preparation using tensor networks",
    "citation_count": 39,
    "authors": [
      "YUSUKE Mukuta",
      "Tatsuya Harada"
    ]
  },
  "https://openreview.net/forum?id=wk8oXR0kFA": {
    "title": "Releasing Graph Neural Networks with Differential Privacy Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ccc0c140abed03b094531b52f9587e334540aeaa",
    "semantic_title": "releasing graph neural networks with differential privacy guarantees",
    "citation_count": 49,
    "authors": [
      "Iyiola Emmanuel Olatunji",
      "Thorben Funke",
      "Megha Khosla"
    ]
  },
  "https://openreview.net/forum?id=ERqGqZzSu5": {
    "title": "Sequential Query Encoding for Complex Query Answering on Knowledge Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b45ea6ddc9d964116addaf1dafd0641d78a6228e",
    "semantic_title": "sequential query encoding for complex query answering on knowledge graphs",
    "citation_count": 18,
    "authors": [
      "Jiaxin Bai",
      "Tianshi Zheng",
      "Yangqiu Song"
    ]
  },
  "https://openreview.net/forum?id=sFk3aBNb81": {
    "title": "TransFool: An Adversarial Attack against Neural Machine Translation Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c5e9fdb1b81edf470141843c44264a5eb1ff0cc1",
    "semantic_title": "transfool: an adversarial attack against neural machine translation models",
    "citation_count": 12,
    "authors": [
      "Sahar Sadrizadeh",
      "Ljiljana Dolamic",
      "Pascal Frossard"
    ]
  },
  "https://openreview.net/forum?id=9pWjgQ3y85": {
    "title": "An Explicit Expansion of the Kullback-Leibler Divergence along its Fisher-Rao Gradient Flow",
    "volume": "main",
    "abstract": "Let $V_* : \\mathbb{R}^d \\to \\mathbb{R}$ be some (possibly non-convex) potential function, and consider the probability measure $\\pi \\propto e^{-V_*}$. When $\\pi$ exhibits multiple modes, it is known that sampling techniques based on Wasserstein gradient flows of the Kullback-Leibler (KL) divergence (e.g. Langevin Monte Carlo) suffer poorly in the rate of convergence, where the dynamics are unable to easily traverse between modes. In stark contrast, the work of Lu et al. (2019; 2022) has shown that the gradient flow of the KL with respect to the Fisher-Rao (FR) geometry exhibits a convergence rate to $\\pi$ is that \\textit{independent} of the potential function. In this short note, we complement these existing results in the literature by providing an explicit expansion of $\\text{KL}(\\rho_t^{\\text{FR}}\\|\\pi)$ in terms of $e^{-t}$, where $(\\rho_t^{\\text{FR}})_{t\\geq 0}$ is the FR gradient flow of the KL divergence. In turn, we are able to provide a clean asymptotic convergence rate, where the burn-in time is guaranteed to be finite. Our proof is based on observing a similarity between FR gradient flows and simulated annealing with linear scaling, and facts about cumulant generating functions. We conclude with simple synthetic experiments that demonstrate our theoretical findings are indeed tight. Based on our numerical findings, we conjecture that the asymptotic rates of convergence for Wasserstein-Fisher-Rao gradient flows are possibly related to this expansion in some cases",
    "checked": true,
    "id": "8570695c0ee3574f1a0829f0fe4672de634acb1b",
    "semantic_title": "an explicit expansion of the kullback-leibler divergence along its fisher-rao gradient flow",
    "citation_count": 13,
    "authors": [
      "Carles Domingo-Enrich",
      "Aram-Alexandre Pooladian"
    ]
  },
  "https://openreview.net/forum?id=ZoXi7n54OB": {
    "title": "Training with Mixed-Precision Floating-Point Assignments",
    "volume": "main",
    "abstract": "When training deep neural networks, keeping all tensors in high precision (e.g., 32-bit or even 16-bit floats) is often wasteful. However, keeping all tensors in low precision (e.g., 8-bit floats) can lead to unacceptable accuracy loss. Hence, it is important to use a precision assignment—a mapping from all tensors (arising in training) to precision levels (high or low)—that keeps most of the tensors in low precision and leads to sufficiently accurate models. We provide a technique that explores this memory-accuracy tradeoff by generating precision assignments for convolutional neural networks that (i) use less memory and (ii) lead to more accurate convolutional networks at the same time, compared to the precision assignments considered by prior work in low-precision floating-point training. We evaluate our technique on image classiﬁcation tasks by training convolutional networks on CIFAR-10, CIFAR-100, and ImageNet. Our method typically provides > 2× memory reduction over a baseline precision assignment while preserving training accuracy, and gives further reductions by trading off accuracy. Compared to other baselines which sometimes cause training to diverge, our method provides similar or better memory reduction while avoiding divergence",
    "checked": true,
    "id": "6d06cd10665360739317c288ca25c68699611926",
    "semantic_title": "training with mixed-precision floating-point assignments",
    "citation_count": 4,
    "authors": [
      "Wonyeol Lee",
      "Rahul Sharma",
      "Alex Aiken"
    ]
  },
  "https://openreview.net/forum?id=A1N2qp4yAq": {
    "title": "Bandwidth Enables Generalization in Quantum Kernel Models",
    "volume": "main",
    "abstract": "Quantum computers are known to provide speedups over classical state-of-the-art machine learning methods in some specialized settings. For example, quantum kernel methods have been shown to provide an exponential speedup on a learning version of the discrete logarithm problem. Understanding the generalization of quantum models is essential to realizing similar speedups on problems of practical interest. Recent results demonstrate that generalization is hindered by the exponential size of the quantum feature space. Although these results suggest that quantum models cannot generalize when the number of qubits is large, in this paper we show that these results rely on overly restrictive assumptions. We consider a wider class of models by varying a hyperparameter that we call quantum kernel bandwidth. We analyze the large-qubit limit and provide explicit formulas for the generalization of a quantum model that can be solved in closed form. Specifically, we show that changing the value of the bandwidth can take a model from provably not being able to generalize to any target function to good generalization for well-aligned targets. Our analysis shows how the bandwidth controls the spectrum of the kernel integral operator and thereby the inductive bias of the model. We demonstrate empirically that our theory correctly predicts how varying the bandwidth affects generalization of quantum models on challenging datasets, including those far outside our theoretical assumptions. We discuss the implications of our results for quantum advantage in machine learning",
    "checked": true,
    "id": "67557d52497b2805a840083564ee2596ef609042",
    "semantic_title": "bandwidth enables generalization in quantum kernel models",
    "citation_count": 45,
    "authors": [
      "Abdulkadir Canatar",
      "Evan Peters",
      "Cengiz Pehlevan",
      "Stefan M. Wild",
      "Ruslan Shaydulin"
    ]
  },
  "https://openreview.net/forum?id=vTsfup5ll6": {
    "title": "Privacy-Preserving Energy-Based Generative Models for Marginal Distribution Protection",
    "volume": "main",
    "abstract": "We consider learning generative models for sensitive financial and healthcare data. While previous work incorporates Differential Privacy (DP) into GAN training to protect the privacy of individual training instances, we consider a different privacy context where the primary objective is protecting the privacy of sensitive marginal distributions of the true generative process. We propose and motivate a new notion of privacy: \\emph{$\\alpha$-Level Marginal Distribution Privacy} ($\\alpha$-LMDP), which provides a statistical guarantee that the sensitive generative marginal distributions are different from the observed real data. We then propose \\emph{Privacy-Preserving Energy Models (PPEMs)}, a novel energy-based generative model formulation where the representations for these attributes are isolated from other attributes. This structured formulation motivates a learning procedure where a penalty based on a statistical goodness of fit test, the \\emph{Kernel Stein Discrepancy}, can be applied to only the attributes requiring privacy so that $\\alpha$-LMDP may be satisfied without affecting the other attributes. We evaluate this approach using financial and healthcare datasets and demonstrate that the resulting learnt generative models produce high fidelity synthetic data while preserving privacy. We also show that PPEMs can incorporate both $\\alpha$-LMDP \\emph{and} DP in contexts where both forms of privacy are required",
    "checked": true,
    "id": "c27a01ff464bcc72124b6901ab3b5e2c0f517d98",
    "semantic_title": "privacy-preserving energy-based generative models for marginal distribution protection",
    "citation_count": 2,
    "authors": [
      "Robert E. Tillman",
      "Tucker Balch",
      "Manuela Veloso"
    ]
  },
  "https://openreview.net/forum?id=B7PFZtm8DA": {
    "title": "Unsupervised Discovery and Composition of Object Light Fields",
    "volume": "main",
    "abstract": "Neural scene representations, both continuous and discrete, have recently emerged as a powerful new paradigm for 3D scene understanding. Recent efforts have tackled unsupervised discovery of object-centric neural scene representations. However, the high cost of ray-marching, exacerbated by the fact that each object representation has to be ray-marched separately, leads to insufficiently sampled radiance fields and thus, noisy renderings, poor framerates, and high memory and time complexity during training and rendering. Here, we propose to represent objects in an object-centric, compositional scene representation as light fields. We propose a novel light field compositor module that enables reconstructing the global light field from a set of object-centric light fields. Dubbed Compositional Object Light Fields (COLF), our method enables unsupervised learning of object-centric neural scene representations, state-of-the-art reconstruction and novel view synthesis performance on standard datasets, and rendering and training speeds at orders of magnitude faster than existing 3D approaches",
    "checked": true,
    "id": "4fa77b26bffc65a1baad55248fd7df06e46bc58e",
    "semantic_title": "unsupervised discovery and composition of object light fields",
    "citation_count": 29,
    "authors": [
      "Cameron Omid Smith",
      "Hong-Xing Yu",
      "Sergey Zakharov",
      "Fredo Durand",
      "Joshua B. Tenenbaum",
      "Jiajun Wu",
      "Vincent Sitzmann"
    ]
  },
  "https://openreview.net/forum?id=dXnccpSSYF": {
    "title": "Pareto Optimization for Active Learning under Out-of-Distribution Data Scenarios",
    "volume": "main",
    "abstract": "Pool-based Active Learning (AL) has proven successful in minimizing labeling costs by sequentially selecting the most informative unlabeled data from large pool and querying their labels from an oracle or annotators. However, existing AL sampling schemes may not perform well in out-of-distribution (OOD) data scenarios, where the unlabeled data pool contains samples that do not belong to the pre-defined categories of the target task. Achieving strong AL performance under OOD data scenarios presents a challenge due to the inherent conflict between AL sampling strategies and OOD data detection. For instance, both more informative in-distribution (ID) data and OOD data in an unlabeled data pool would be assigned high informativeness scores (e.g., high entropy) during AL processes. To address this dilemma, we propose a Monte-Carlo Pareto Optimization for Active Learning (POAL) sampling scheme, which selects optimal subsets of unlabeled samples with fixed batch size from the unlabeled data pool. We formulate the AL sampling task as a multi-objective optimization problem and employ Pareto optimization based on two conflicting objectives: (1) the conventional AL sampling scheme (e.g., maximum entropy) and (2) the confidence of excluding OOD data samples. Experimental results demonstrate the effectiveness of our POAL approach on classical Machine Learning (ML) and Deep Learning (DL) tasks",
    "checked": true,
    "id": "e702416f7a9f62bf275c35a58a08839d65211733",
    "semantic_title": "pareto optimization for active learning under out-of-distribution data scenarios",
    "citation_count": 3,
    "authors": [
      "Xueying Zhan",
      "Zeyu Dai",
      "Qingzhong Wang",
      "Qing Li",
      "Haoyi Xiong",
      "Dejing Dou",
      "Antoni B. Chan"
    ]
  },
  "https://openreview.net/forum?id=jYkWdJzTwn": {
    "title": "Predicting Out-of-Domain Generalization with Neighborhood Invariance",
    "volume": "main",
    "abstract": "Developing and deploying machine learning models safely depends on the ability to char- acterize and compare their abilities to generalize to new environments. Although recent work has proposed a variety of methods that can directly predict or theoretically bound the generalization capacity of a model, they rely on strong assumptions such as matching train/test distributions and access to model gradients. In order to characterize generalization when these assumptions are not satisfied, we propose neighborhood invariance, a measure of a classifier's output invariance in a local transformation neighborhood. Specifically, we sample a set of transformations and given an input test point, calculate the invariance as the largest fraction of transformed points classified into the same class. Crucially, our measure is simple to calculate, does not depend on the test point's true label, makes no assumptions about the data distribution or model, and can be applied even in out-of-domain (OOD) settings where existing methods cannot, requiring only selecting a set of appropriate data transformations. In experiments on robustness benchmarks in image classification, sentiment analysis, and natural language inference, we demonstrate a strong and robust correlation between our neighborhood invariance measure and actual OOD generalization on over 4,600 models evaluated on over 100 train/test domain pairs",
    "checked": true,
    "id": "1faa156ed77ecf0204d6a83d4dd7114943cc57ae",
    "semantic_title": "predicting out-of-domain generalization with neighborhood invariance",
    "citation_count": 5,
    "authors": [
      "Nathan Hoyen Ng",
      "Neha Hulkund",
      "Kyunghyun Cho",
      "Marzyeh Ghassemi"
    ]
  },
  "https://openreview.net/forum?id=ipe0IMglFF": {
    "title": "Empirical Study on Optimizer Selection for Out-of-Distribution Generalization",
    "volume": "main",
    "abstract": "Modern deep learning systems do not generalize well when the test data distribution is slightly different to the training data distribution. While much promising work has been accomplished to address this fragility, a systematic study of the role of optimizers and their out-of-distribution generalization performance has not been undertaken. In this study, we examine the performance of popular first-order optimizers for different classes of distributional shift under empirical risk minimization and invariant risk minimization. We address this question for image and text classification using DomainBed, WILDS, and Backgrounds Challenge as testbeds for studying different types of shifts---namely correlation and diversity shift. We search over a wide range of hyperparameters and examine classification accuracy (in-distribution and out-of-distribution) for over 20,000 models. We arrive at the following findings, which we expect to be helpful for practitioners: i) adaptive optimizers (e.g., Adam) perform worse than non-adaptive optimizers (e.g., SGD, momentum SGD) on out-of-distribution performance. In particular, even though there is no significant difference in in-distribution performance, we show a measurable difference in out-of-distribution performance. ii) in-distribution performance and out-of-distribution performance exhibit three types of behavior depending on the dataset---linear returns, increasing returns, and diminishing returns. For example, in the training of natural language data using Adam, fine-tuning the performance of in-distribution performance does not significantly contribute to the out-of-distribution generalization performance",
    "checked": true,
    "id": "9d99e651212de629568de2f2dcaa0856fe4c0bbe",
    "semantic_title": "empirical study on optimizer selection for out-of-distribution generalization",
    "citation_count": 7,
    "authors": [
      "Hiroki Naganuma",
      "Kartik Ahuja",
      "Shiro Takagi",
      "Tetsuya Motokawa",
      "Rio Yokota",
      "Kohta Ishikawa",
      "Ikuro Sato",
      "Ioannis Mitliagkas"
    ]
  },
  "https://openreview.net/forum?id=FDbQGCAViI": {
    "title": "The Eigenlearning Framework: A Conservation Law Perspective on Kernel Ridge Regression and Wide Neural Networks",
    "volume": "main",
    "abstract": "We derive simple closed-form estimates for the test risk and other generalization metrics of kernel ridge regression (KRR). Relative to prior work, our derivations are greatly simplified and our final expressions are more readily interpreted. In particular, we show that KRR can be interpreted as an explicit competition among kernel eigenmodes for a fixed supply of a quantity we term \"learnability.'' These improvements are enabled by a sharp conservation law which limits the ability of KRR to learn any orthonormal basis of functions. Test risk and other objects of interest are expressed transparently in terms of our conserved quantity evaluated in the kernel eigenbasis. We use our improved framework to: i) provide a theoretical explanation for the \"deep bootstrap\" of Nakkiran et al (2020), ii) generalize a previous result regarding the hardness of the classic parity problem, iii) fashion a theoretical tool for the study of adversarial robustness, and iv) draw a tight analogy between KRR and a well-studied system in statistical physics",
    "checked": true,
    "id": "c607d9ebf5a6605d8f31e03e6f0408f96edbdd4b",
    "semantic_title": "the eigenlearning framework: a conservation law perspective on kernel ridge regression and wide neural networks",
    "citation_count": 7,
    "authors": [
      "James B Simon",
      "Madeline Dickens",
      "Dhruva Karkada",
      "Michael R DeWeese"
    ]
  },
  "https://openreview.net/forum?id=kiPsMct7vL": {
    "title": "Unsupervised Domain Adaptation via Minimized Joint Error",
    "volume": "main",
    "abstract": "Unsupervised domain adaptation transfers knowledge from a fully labeled source domain to a different target domain, where no labeled data are available. Some researchers have proposed upper bounds for the target error when transferring knowledge. For example, Ben-David et al. (2010) established a theory based on minimizing the source error and distance between marginal distributions simultaneously. However, in most research, the joint error is ignored because of its intractability. In this research, we argue that joint errors are essential for domain adaptation problems, particularly when the domain gap is large. To address this problem, we propose a novel objective related to the upper bound of the joint error. Moreover, we adopt a source/pseudo-target label-induced hypothesis space that can reduce the search space to further tighten this bound. To measure the dissimilarity between hypotheses, we define a novel cross-margin discrepancy to alleviate instability during adversarial learning. In addition, we present extensive empirical evidence showing that the proposed method boosts the performance of image classification accuracy on standard domain adaptation benchmarks",
    "checked": true,
    "id": "d8fcfb51844125476ebcaf2ffe53352e06d5dd89",
    "semantic_title": "unsupervised domain adaptation via minimized joint error",
    "citation_count": 6,
    "authors": [
      "Dexuan Zhang",
      "Thomas Westfechtel",
      "Tatsuya Harada"
    ]
  },
  "https://openreview.net/forum?id=r6oHDYOZ6p": {
    "title": "Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification",
    "volume": "main",
    "abstract": "While a broad range of techniques have been proposed to tackle distribution shift, the simple baseline of training on an undersampled balanced dataset often achieves close to state-of-the-art-accuracy across several popular benchmarks. This is rather surprising, since undersampling algorithms discard excess majority group data. To understand this phenomenon, we ask if learning is fundamentally constrained by a lack of minority group samples. We prove that this is indeed the case in the setting of nonparametric binary classification. Our results show that in the worst case, an algorithm cannot outperform undersampling unless there is a high degree of overlap between the train and test distributions (which is unlikely to be the case in real-world datasets), or if the algorithm leverages additional structure about the distribution shift. In particular, in the case of label shift we show that there is always an undersampling algorithm that is minimax optimal. In the case of group-covariate shift we show that there is an undersampling algorithm that is minimax optimal when the overlap between the group distributions is small. We also perform an experimental case study on a label shift dataset and find that in line with our theory, the test accuracy of robust neural network classifiers is constrained by the number of minority samples",
    "checked": true,
    "id": "694120fd1ad7220fd064870573bcaba46444a80e",
    "semantic_title": "undersampling is a minimax optimal robustness intervention in nonparametric classification",
    "citation_count": 6,
    "authors": [
      "Niladri S. Chatterji",
      "Saminul Haque",
      "Tatsunori Hashimoto"
    ]
  },
  "https://openreview.net/forum?id=K0CAGgjYS1": {
    "title": "On the Convergence and Calibration of Deep Learning with Differential Privacy",
    "volume": "main",
    "abstract": "Differentially private (DP) training preserves the data privacy usually at the cost of slower convergence (and thus lower accuracy), as well as more severe mis-calibration than its non-private counterpart. To analyze the convergence of DP training, we formulate a continuous time analysis through the lens of neural tangent kernel (NTK), which characterizes the per-sample gradient clipping and the noise addition in DP training, for arbitrary network architectures and loss functions. Interestingly, we show that the noise addition only affects the privacy risk but not the convergence or calibration, whereas the per-sample gradient clipping (under both flat and layerwise clipping styles) only affects the convergence and calibration. Furthermore, we observe that while DP models trained with small clipping norm usually achieve the best accurate, but are poorly calibrated and thus unreliable. In sharp contrast, DP models trained with large clipping norm enjoy the same privacy guarantee and similar accuracy, but are significantly more \\textit{calibrated}. Our code can be found at https://github.com/woodyx218/opacus_global_clipping",
    "checked": true,
    "id": "ff8510fcddb11b0306da2fffb2c3e88d1172bdda",
    "semantic_title": "on the convergence and calibration of deep learning with differential privacy",
    "citation_count": 4,
    "authors": [
      "Zhiqi Bu",
      "Hua Wang",
      "Zongyu Dai",
      "Qi Long"
    ]
  },
  "https://openreview.net/forum?id=B0WYWvVA2r": {
    "title": "Attentional-Biased Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "In this paper, we present a simple yet effective provable method (named ABSGD) for addressing the data imbalance or label noise problem in deep learning. Our method is a simple modification to momentum SGD where we assign an individual importance weight to each sample in the mini-batch. The individual-level weight of a sampled data is systematically proportional to the exponential of a scaled loss value of the data, where the scaling factor is interpreted as the regularization parameter in the framework of distributionally robust optimization (DRO). Depending on whether the scaling factor is positive or negative, ABSGD is guaranteed to converge to a stationary point of an information-regularized min-max or min-min DRO problem, respectively. Compared with existing class-level weighting schemes, our method can capture the diversity between individual examples within each class. Compared with existing individual-level weighting methods using meta-learning that require three backward propagations for computing mini-batch stochastic gradients, our method is more efficient with only one backward propagation at each iteration as in standard deep learning methods. ABSGD is flexible enough to combine with other robust losses without any additional cost. Our empirical studies on several benchmark datasets demonstrate the effectiveness of the proposed method",
    "checked": false,
    "id": "f807f8705a93d3170e25a8937d33854b2071ebb5",
    "semantic_title": "block-missing data in linear systems: an unbiased stochastic gradient descent approach",
    "citation_count": 1,
    "authors": [
      "Qi Qi",
      "Yi Xu",
      "Wotao Yin",
      "Rong Jin",
      "Tianbao Yang"
    ]
  },
  "https://openreview.net/forum?id=G2GKiicaJI": {
    "title": "Reinforcement Teaching",
    "volume": "main",
    "abstract": "Machine learning algorithms learn to solve a task, but are unable to improve their ability to learn. Meta-learning methods learn about machine learning algorithms and improve them so that they learn more quickly. However, existing meta-learning methods are either hand-crafted to improve one specific component of an algorithm or only work with differentiable algorithms. We develop a unifying meta-learning framework, called \\textit{Reinforcement Teaching}, to improve the learning process of \\emph{any} algorithm. Under Reinforcement Teaching, a teaching policy is learned, through reinforcement, to improve a student's learning algorithm. To learn an effective teaching policy, we introduce the \\textit{parametric-behavior embedder} that learns a representation of the student's learnable parameters from its input/output behavior. We further use \\textit{learning progress} to shape the teacher's reward, allowing it to more quickly maximize the student's performance. To demonstrate the generality of Reinforcement Teaching, we conduct experiments in which a teacher learns to significantly improve both reinforcement and supervised learning algorithms. Reinforcement Teaching outperforms previous work using heuristic reward functions and state representations, as well as other parameter representations",
    "checked": true,
    "id": "fa71320d3ef00075f4ddd6df0d328d00016377b0",
    "semantic_title": "reinforcement teaching",
    "citation_count": 2,
    "authors": [
      "Calarina Muslimani",
      "Alex Lewandowski",
      "Dale Schuurmans",
      "Matthew E. Taylor",
      "Jun Luo"
    ]
  },
  "https://openreview.net/forum?id=zshemTAa6U": {
    "title": "Test-Time Adaptation for Visual Document Understanding",
    "volume": "main",
    "abstract": "For visual document understanding (VDU), self-supervised pretraining has been shown to successfully generate transferable representations, yet, effective adaptation of such representations to distribution shifts at test-time remains to be an unexplored area. We propose DocTTA, a novel test-time adaptation method for documents, that does source-free domain adaptation using unlabeled target document data. DocTTA leverages cross-modality self-supervised learning via masked visual language modeling, as well as pseudo labeling to adapt models learned on a \\textit{source} domain to an unlabeled \\textit{target} domain at test time. We introduce new benchmarks using existing public datasets for various VDU tasks, including entity recognition, key-value extraction, and document visual question answering. DocTTA shows significant improvements on these compared to the source model performance, up to 1.89\\% in (F1 score), 3.43\\% (F1 score), and 17.68\\% (ANLS score), respectively",
    "checked": true,
    "id": "2ab8d3a547d6a806d75332bae0915d4f37a41d1e",
    "semantic_title": "test-time adaptation for visual document understanding",
    "citation_count": 6,
    "authors": [
      "Sayna Ebrahimi",
      "Sercan O Arik",
      "Tomas Pfister"
    ]
  },
  "https://openreview.net/forum?id=W98AEKQ38Y": {
    "title": "Learning to Incentivize Improvements from Strategic Agents",
    "volume": "main",
    "abstract": "Machine learning systems are often used in settings where individuals adapt their features to obtain a desired outcome. In such settings, strategic behavior leads to a sharp loss in model performance in deployment. In this work, we aim to address this problem by learning classifiers that encourage decision subjects to change their features in a way that leads to improvement in both predicted and true outcome. We frame the dynamics of prediction and adaptation as a two-stage game, and characterize optimal strategies for the model designer and its decision subjects. In benchmarks on simulated and real-world datasets, we find that classifiers trained using our method maintain the accuracy of existing approaches while inducing higher levels of improvement and less manipulation",
    "checked": true,
    "id": "a2a0667a08b3c043b2e480786321b8f6039f1084",
    "semantic_title": "learning to incentivize improvements from strategic agents",
    "citation_count": 3,
    "authors": [
      "Yatong Chen",
      "Jialu Wang",
      "Yang Liu"
    ]
  },
  "https://openreview.net/forum?id=TSy0vuwQFN": {
    "title": "Finding Competence Regions in Domain Generalization",
    "volume": "main",
    "abstract": "We investigate a \"learning to reject\" framework to address the problem of silent failures in Domain Generalization (DG), where the test distribution differs from the training distribution. Assuming a mild distribution shift, we wish to accept out-of-distribution (OOD) data from a new domain whenever a model's estimated competence foresees trustworthy responses, instead of rejecting OOD data outright. Trustworthiness is then predicted via a proxy incompetence score that is tightly linked to the performance of a classifier. We present a comprehensive experimental evaluation of existing proxy scores as incompetence scores for classification and highlight the resulting trade-offs between rejection rate and accuracy gain. For comparability with prior work, we focus on standard DG benchmarks and consider the effect of measuring incompetence via different learned representations in a closed versus an open world setting. Our results suggest that increasing incompetence scores are indeed predictive of reduced accuracy, leading to significant improvements of the average accuracy below a suitable incompetence threshold. However, the scores are not yet good enough to allow for a favorable accuracy/rejection trade-off in all tested domains. Surprisingly, our results also indicate that classifiers optimized for DG robustness do not outperform a naive Empirical Risk Minimization (ERM) baseline in the competence region, that is, where test samples elicit low incompetence scores",
    "checked": true,
    "id": "376fd16949012d585fa4482540cbcdae8cf6ad5d",
    "semantic_title": "finding competence regions in domain generalization",
    "citation_count": 4,
    "authors": [
      "Jens Müller",
      "Stefan T. Radev",
      "Robert Schmier",
      "Felix Draxler",
      "Carsten Rother",
      "Ullrich Koethe"
    ]
  },
  "https://openreview.net/forum?id=r7imkFEAQb": {
    "title": "Noise-robust Graph Learning by Estimating and Leveraging Pairwise Interactions",
    "volume": "main",
    "abstract": "Teaching Graph Neural Networks (GNNs) to accurately classify nodes under severely noisy labels is an important problem in real-world graph learning applications, but is currently underexplored. Although pairwise training methods have demonstrated promise in supervised metric learning and unsupervised contrastive learning, they remain less studied on noisy graphs, where the structural pairwise interactions (PI) between nodes are abundant and thus might benefit label noise learning rather than the pointwise methods. This paper bridges the gap by proposing a pairwise framework for noisy node classification on graphs, which relies on the PI as a primary learning proxy in addition to the pointwise learning from the noisy node class labels. Our proposed framework PI-GNN contributes two novel components: (1) a confidence-aware PI estimation model that adaptively estimates the PI labels, which are defined as whether the two nodes share the same node labels, and (2) a decoupled training approach that leverages the estimated PI labels to regularize a node classification model for robust node classification. Extensive experiments on different datasets and GNN architectures demonstrate the effectiveness of PI-GNN, yielding a promising improvement over the state-of-the-art methods. Code is publicly available at https://github.com/TianBian95/pi-gnn",
    "checked": true,
    "id": "564bd41471fdfd371d11bbc83b7c4b97fccaf429",
    "semantic_title": "noise-robust graph learning by estimating and leveraging pairwise interactions",
    "citation_count": 16,
    "authors": [
      "Xuefeng Du",
      "Tian Bian",
      "Yu Rong",
      "Bo Han",
      "Tongliang Liu",
      "Tingyang Xu",
      "Wenbing Huang",
      "Yixuan Li",
      "Junzhou Huang"
    ]
  },
  "https://openreview.net/forum?id=SwlfyDq6B3": {
    "title": "3D-Aware Video Generation",
    "volume": "main",
    "abstract": "Generative models have emerged as an essential building block for many image synthesis and editing tasks. Recent advances in this field have also enabled high-quality 3D or video content to be generated that exhibits either multi-view or temporal consistency. With our work, we explore 4D generative adversarial networks (GANs) that learn unconditional generation of 3D-aware videos. By combining neural implicit representations with time-aware discriminator, we develop a GAN framework that synthesizes 3D video supervised only with monocular videos. We show that our method learns a rich embedding of decomposable 3D structures and motions that enables new visual effects of spatio-temporal renderings while producing imagery with quality comparable to that of existing 3D or video GANs",
    "checked": true,
    "id": "17771572e21e3f92fa7c1495341848c19fe2b62e",
    "semantic_title": "3d-aware video generation",
    "citation_count": 20,
    "authors": [
      "Sherwin Bahmani",
      "Jeong Joon Park",
      "Despoina Paschalidou",
      "Hao Tang",
      "Gordon Wetzstein",
      "Leonidas Guibas",
      "Luc Van Gool",
      "Radu Timofte"
    ]
  },
  "https://openreview.net/forum?id=sixOD8YVvM": {
    "title": "Bounded Space Differentially Private Quantiles",
    "volume": "main",
    "abstract": "Estimating the quantiles of a large dataset is a fundamental problem in both the streaming algorithms literature and the differential privacy literature. However, all existing private mechanisms for distribution-independent quantile computation require space at least linear in the input size $n$. In this work, we devise a differentially private algorithm for the quantile estimation problem, with strongly sublinear space complexity, in the one-shot and continual observation settings. Our basic mechanism estimates any $\\alpha$-approximate quantile of a length-$n$ stream over a data universe $\\mathcal{X}$ with probability $1-\\beta$ using $O\\left( \\frac{\\log (|\\mathcal{X}|/\\beta) \\log (\\alpha \\epsilon n)}{\\alpha \\epsilon} \\right)$ space while satisfying $\\epsilon$-differential privacy at a single time point. Our approach builds upon deterministic streaming algorithms for non-private quantile estimation instantiating the exponential mechanism using a utility function defined on sketch items, while (privately) sampling from intervals defined by the sketch. We also present another algorithm based on histograms that is especially well-suited to the multiple quantiles case. We implement our algorithms and experimentally evaluate them on synthetic and real-world datasets",
    "checked": true,
    "id": "3ef96d9ee132ca2edc5fdb5e76f4c4cf538e4ece",
    "semantic_title": "bounded space differentially private quantiles",
    "citation_count": 17,
    "authors": [
      "Daniel Alabi",
      "Omri Ben-Eliezer",
      "Anamay Chaturvedi"
    ]
  },
  "https://openreview.net/forum?id=pxpbTdUEpD": {
    "title": "The Stack: 3 TB of permissively licensed source code",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) play an ever-increasing role in the field of Artificial Intelligence (AI)--not only for natural language processing but also for code understanding and generation. To stimulate open and responsible research on LLMs for code, we introduce The Stack, a 3.1 TB dataset consisting of permissively licensed source code in 30 programming languages. We describe how we collect the full dataset, construct a permissively licensed subset, present a data governance plan, discuss limitations, and show promising results on text2code benchmarks by training 350M-parameter decoders on different Python subsets. We find that (1) near-deduplicating the data significantly boosts performance across all experiments, and (2) it is possible to match previously reported HumanEval and MBPP performance using only permissively licensed data. We make the dataset available at https://hf.co/BigCode, provide a tool called \"Am I in The Stack\" for developers to search The Stack for copies of their code (https://hf.co/spaces/bigcode/in-the-stack), and provide a process for code to be removed from the dataset",
    "checked": true,
    "id": "f3a6115e5fb2237df938976e005468f0b18da797",
    "semantic_title": "the stack: 3 tb of permissively licensed source code",
    "citation_count": 347,
    "authors": [
      "Denis Kocetkov",
      "Raymond Li",
      "Loubna Ben allal",
      "Jia LI",
      "Chenghao Mou",
      "Yacine Jernite",
      "Margaret Mitchell",
      "Carlos Muñoz Ferrandis",
      "Sean Hughes",
      "Thomas Wolf",
      "Dzmitry Bahdanau",
      "Leandro Von Werra",
      "Harm de Vries"
    ]
  },
  "https://openreview.net/forum?id=sWQJfb2GSk": {
    "title": "Exploring the Approximation Capabilities of Multiplicative Neural Networks for Smooth Functions",
    "volume": "main",
    "abstract": "Multiplication layers are a key component in various influential neural network modules, including self-attention and hypernetwork layers. In this paper, we investigate the approximation capabilities of deep neural networks with intermediate neurons connected by simple multiplication operations. We consider two classes of target functions: generalized bandlimited functions, which are frequently used to model real-world signals with finite bandwidth, and Sobolev-Type balls, which are embedded in the Sobolev Space $\\mathcal{W}^{r,2}$. Our results demonstrate that multiplicative neural networks can approximate these functions with significantly fewer layers and neurons compared to standard ReLU neural networks, with respect to both input dimension and approximation error. These findings suggest that multiplicative gates can outperform standard feed-forward layers and have potential for improving neural network design",
    "checked": true,
    "id": "c27bbdd8968c11513a68383145f7935293a57c25",
    "semantic_title": "exploring the approximation capabilities of multiplicative neural networks for smooth functions",
    "citation_count": 3,
    "authors": [
      "Ido Ben-Shaul",
      "Tomer Galanti",
      "Shai Dekel"
    ]
  },
  "https://openreview.net/forum?id=na5sHG69rI": {
    "title": "Assuming Locally Equal Calibration Errors for Non-Parametric Multiclass Calibration",
    "volume": "main",
    "abstract": "A probabilistic classifier is considered calibrated if it outputs probabilities equal to the expected class distribution given the classifier's output. Calibration is essential in safety-critical tasks where small deviations between the predicted probabilities and the actually observed class proportions can incur high costs. A common approach to improve the calibration of a classifier is to use a hold-out data set and a post-hoc calibration method to learn a correcting transformation for the classifier's output. This work explores the field of post-hoc calibration methods for multi-class classifiers and formulates two assumptions about the probability simplex which have been used by many existing non-parametric calibration methods, but despite this, have never been explicitly stated: assuming locally equal label distributions or assuming locally equal calibration errors. Based on the latter assumption, an intuitive non-parametric post-hoc calibration method is proposed, which is shown to offer improvements to the state-of-the-art according to the expected calibration error metric on CIFAR-10 and CIFAR-100 data sets",
    "checked": true,
    "id": "98a59cf71e7f2623625cfae4772b12388a723751",
    "semantic_title": "assuming locally equal calibration errors for non-parametric multiclass calibration",
    "citation_count": 0,
    "authors": [
      "Kaspar Valk",
      "Meelis Kull"
    ]
  },
  "https://openreview.net/forum?id=OILbP0WErR": {
    "title": "Learning Graph Structure from Convolutional Mixtures",
    "volume": "main",
    "abstract": "Machine learning frameworks such as graph neural networks typically rely on a given, fixed graph to exploit relational inductive biases and thus effectively learn from network data. However, when said graphs are (partially) unobserved, noisy, or dynamic, the problem of inferring graph structure from data becomes relevant. In this paper, we postulate a graph convolutional relationship between the observed and latent graphs, and formulate the graph structure learning task as a network inverse (deconvolution) problem. In lieu of eigendecomposition-based spectral methods or iterative optimization solutions, we unroll and truncate proximal gradient iterations to arrive at a parameterized neural network architecture that we call a Graph Deconvolution Network (GDN). GDNs can learn a distribution of graphs in a supervised fashion, perform link prediction or edge-weight regression tasks by adapting the loss function, and they are inherently inductive as well as node permutation equivariant. We corroborate GDN's superior graph learning performance and its generalization to larger graphs using synthetic data in supervised settings. Moreover, we demonstrate the robustness and representation power of GDNs on real world neuroimaging and social network datasets",
    "checked": true,
    "id": "064a66238196f14b5815dc5bed72a5499bef2e5b",
    "semantic_title": "learning graph structure from convolutional mixtures",
    "citation_count": 6,
    "authors": [
      "Max Wasserman",
      "Saurabh Sihag",
      "Gonzalo Mateos",
      "Alejandro Ribeiro"
    ]
  },
  "https://openreview.net/forum?id=NrfSRtTpN5": {
    "title": "Learning Object-Centric Neural Scattering Functions for Free-viewpoint Relighting and Scene Composition",
    "volume": "main",
    "abstract": "Photorealistic object appearance modeling from 2D images is a constant topic in vision and graphics. While neural implicit methods (such as Neural Radiance Fields) have shown high-fidelity view synthesis results, they cannot relight the captured objects. More recent neural inverse rendering approaches have enabled object relighting, but they represent surface properties as simple BRDFs, and therefore cannot handle translucent objects. We propose Object-Centric Neural Scattering Functions (OSFs) for learning to reconstruct object appearance from only images. OSFs not only support free-viewpoint object relighting, but also can model both opaque and translucent objects. While accurately modeling subsurface light transport for translucent objects can be highly complex and even intractable for neural methods, OSFs learn to approximate the radiance transfer from a distant light to an outgoing direction at any spatial location. This approximation avoids explicitly modeling complex subsurface scattering, making learning a neural implicit model tractable. Experiments on real and synthetic data show that OSFs accurately reconstruct appearances for both opaque and translucent objects, allowing faithful free-viewpoint relighting as well as scene composition. In our supplementary material, we include a video for an overview. Project website with video results: https://kovenyu.com/OSF/",
    "checked": true,
    "id": "2622704ad6d5585d9ba4cdced8174454e37ed864",
    "semantic_title": "learning object-centric neural scattering functions for free-viewpoint relighting and scene composition",
    "citation_count": 20,
    "authors": [
      "Hong-Xing Yu",
      "Michelle Guo",
      "Alireza Fathi",
      "Yen-Yu Chang",
      "Eric Ryan Chan",
      "Ruohan Gao",
      "Thomas Funkhouser",
      "Jiajun Wu"
    ]
  },
  "https://openreview.net/forum?id=Y42xVBQusn": {
    "title": "Contextualize Me – The Case for Context in Reinforcement Learning",
    "volume": "main",
    "abstract": "While Reinforcement Learning ( RL) has made great strides towards solving increasingly complicated problems, many algorithms are still brittle to even slight environmental changes. Contextual Reinforcement Learning (cRL) provides a framework to model such changes in a principled manner, thereby enabling flexible, precise and interpretable task specification and generation. Our goal is to show how the framework of cRL contributes to improving zero-shot generalization in RL through meaningful benchmarks and structured reasoning about generalization tasks. We confirm the insight that optimal behavior in cRL requires context information, as in other related areas of partial observability. To empirically validate this in the cRL framework, we provide various context-extended versions of common RL environments. They are part of the first benchmark library, CARL, designed for generalization based on cRL extensions of popular benchmarks, which we propose as a testbed to further study general agents. We show that in the contextual setting, even simple RL environments become challenging - and that naive solutions are not enough to generalize across complex context spaces",
    "checked": false,
    "id": "df8e5f2e19b696fc5ed4bec9b61835943c8e8a8f",
    "semantic_title": "contextualize me - the case for context in reinforcement learning",
    "citation_count": 36,
    "authors": [
      "Carolin Benjamins",
      "Theresa Eimer",
      "Frederik Schubert",
      "Aditya Mohan",
      "Sebastian Döhler",
      "André Biedenkapp",
      "Bodo Rosenhahn",
      "Frank Hutter",
      "Marius Lindauer"
    ]
  },
  "https://openreview.net/forum?id=KxBQPz7HKh": {
    "title": "Multi-dimensional concept discovery (MCD): A unifying framework with completeness guarantees",
    "volume": "main",
    "abstract": "The completeness axiom renders the explanation of a post-hoc eXplainable AI (XAI) method only locally faithful to the model, i.e. for a single decision. For the trustworthy application of XAI, in particular for high-stake decisions, a more global model understanding is required. To this end, concept-based methods have been proposed, which are however not guaranteed to be bound to the actual model reasoning. To circumvent this problem, we propose Multi-dimensional Concept Discovery (MCD) as an extension of previous approaches that fulfills a completeness relation on the level of concepts. Our method starts from general linear subspaces as concepts and does neither require reinforcing concept interpretability nor re-training of model parts. We propose sparse subspace clustering to discover improved concepts and fully leverage the potential of multi-dimensional subspaces. MCD offers two complementary analysis tools for concepts in input space: (1) concept activation maps, that show where a concept is expressed within a sample, allowing for concept characterization through prototypical samples, and (2) concept relevance heatmaps, that decompose the model decision into concept contributions. Both tools together enable a detailed global understanding of the model reasoning, which is guaranteed to relate to the model via a completeness relation. Thus, MCD paves the way towards more trustworthy concept-based XAI. We empirically demonstrate the superiority of MCD against more constrained concept definitions",
    "checked": true,
    "id": "e695a6a6d8a677f528add0118effc7736da35709",
    "semantic_title": "multi-dimensional concept discovery (mcd): a unifying framework with completeness guarantees",
    "citation_count": 43,
    "authors": [
      "Johanna Vielhaben",
      "Stefan Bluecher",
      "Nils Strodthoff"
    ]
  },
  "https://openreview.net/forum?id=TyBd56VK7z": {
    "title": "Dr-Fairness: Dynamic Data Ratio Adjustment for Fair Training on Real and Generated Data",
    "volume": "main",
    "abstract": "Fair visual recognition has become critical for preventing demographic disparity. A major cause of model unfairness is the imbalanced representation of different groups in training data. Recently, several works aim to alleviate this issue using generated data. However, these approaches often use generated data to obtain similar amounts of data across groups, which is not optimal for achieving high fairness due to different learning difficulties and generated data qualities across groups. To address this issue, we propose a novel adaptive sampling approach that leverages both real and generated data for fairness. We design a bilevel optimization that finds the optimal data sampling ratios among groups and between real and generated data while training a model. The ratios are dynamically adjusted considering both the model's accuracy as well as its fairness. To efficiently solve our non-convex bilevel optimization, we propose a simple approximation to the solution given by the implicit function theorem. Extensive experiments show that our framework achieves state-of-the-art fairness and accuracy on the CelebA and ImageNet People Subtree datasets. We also observe that our method adaptively relies less on the generated data when it has poor quality. Our work shows the importance of using generated data together with real data for improving model fairness",
    "checked": true,
    "id": "37aa9f75ac8b983470e89989a533e277e00c0ef8",
    "semantic_title": "dr-fairness: dynamic data ratio adjustment for fair training on real and generated data",
    "citation_count": 8,
    "authors": [
      "Yuji Roh",
      "Weili Nie",
      "De-An Huang",
      "Steven Euijong Whang",
      "Arash Vahdat",
      "Anima Anandkumar"
    ]
  },
  "https://openreview.net/forum?id=N7lCDaeNiS": {
    "title": "Federated Learning under Covariate Shifts with Generalization Guarantees",
    "volume": "main",
    "abstract": "This paper addresses intra-client and inter-client covariate shifts in federated learning (FL) with a focus on the overall generalization performance. To handle covariate shifts, we formulate a new global model training paradigm and propose Federated Importance-Weighted Empirical Risk Minimization (FTW-ERM) along with improving density ratio matching methods without requiring perfect knowledge of the supremum over true ratios. We also propose the communication-efficient variant FITW-ERM with the same level of privacy guarantees as those of classical ERM in FL. We theoretically show that FTW-ERM achieves smaller generalization error than classical ERM under certain settings. Experimental results demonstrate the superiority of FTW-ERM over existing FL baselines in challenging imbalanced federated settings in terms of data distribution shifts across clients",
    "checked": true,
    "id": "537ede99556e763aaeb1ccaa1a34801d276daee4",
    "semantic_title": "federated learning under covariate shifts with generalization guarantees",
    "citation_count": 9,
    "authors": [
      "Ali Ramezani-Kebrya",
      "Fanghui Liu",
      "Thomas Pethick",
      "Grigorios Chrysos",
      "Volkan Cevher"
    ]
  },
  "https://openreview.net/forum?id=pbs22kJmEO": {
    "title": "When Does Uncertainty Matter?: Understanding the Impact of Predictive Uncertainty in ML Assisted Decision Making",
    "volume": "main",
    "abstract": "As machine learning (ML) models are increasingly being employed to assist human decision makers, it becomes critical to provide these decision makers with relevant inputs which can help them decide if and how to incorporate model predictions into their decision making. For instance, communicating the uncertainty associated with model predictions could potentially be helpful in this regard. In this work, we carry out user studies (1,330 responses from 190 participants) to systematically assess how people with differing levels of expertise respond to different types of predictive uncertainty (i.e., posterior predictive distributions with different shapes and variances) in the context of ML assisted decision making for predicting apartment rental prices. We found that showing posterior predictive distributions led to smaller disagreements with the ML model's predictions, regardless of the shapes and variances of the posterior predictive distributions we considered, and that these effects may be sensitive to expertise in both ML and the domain. This suggests that posterior predictive distributions can potentially serve as useful decision aids which should be used with caution and take into account the type of distribution and the expertise of the human",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sean McGrath",
      "Parth Mehta",
      "Alexandra Zytek",
      "Isaac Lage",
      "Himabindu Lakkaraju"
    ]
  },
  "https://openreview.net/forum?id=QhHLwn3D0Y": {
    "title": "The Robustness Limits of SoTA Vision Models to Natural Variation",
    "volume": "main",
    "abstract": "Recent state-of-the-art vision models have introduced new architectures, learning paradigms, and larger pretraining data, leading to impressive performance on tasks such as classification. While previous generations of vision models were shown to lack robustness to factors such as pose, the extent to which this next generation of models are more robust remains unclear. To study this question, we develop a dataset of more than 7 million images with controlled changes in pose, position background, lighting color, and size. We study not only how robust recent state-of- the-art models are, but also the extent to which models can generalize to variation in each of these factors. We consider a catalog of recent vision models, including vision transformers (ViT), self-supervised models such as masked autoencoders (MAE), and models trained on larger datasets such as CLIP. We find that even today's best models are not robust to common changes in pose, size, and background. When some samples varied during training, we found models required a significant portion of instances seen varying to generalize—though eventually robustness did improve. When variability is only witnessed for some classes however, we found that models did not generalize to other classes unless the classes were very similar to those seen varying during training. We hope our work will shed further light on the blind spots of SoTA models and spur the development of more robust vision models",
    "checked": true,
    "id": "8b1aa3a20638363be3a6d941e907df704c738dfc",
    "semantic_title": "the robustness limits of sota vision models to natural variation",
    "citation_count": 17,
    "authors": [
      "Mark Ibrahim",
      "Quentin Garrido",
      "Ari S. Morcos",
      "Diane Bouchacourt"
    ]
  },
  "https://openreview.net/forum?id=CqTkapZ6H9": {
    "title": "Robust Multi-Agent Reinforcement Learning with State Uncertainty",
    "volume": "main",
    "abstract": "In real-world multi-agent reinforcement learning (MARL) applications, agents may not have perfect state information (e.g., due to inaccurate measurement or malicious attacks), which challenges the robustness of agents' policies. Though robustness is getting important in MARL deployment, little prior work has studied state uncertainties in MARL, neither in problem formulation nor algorithm design. Motivated by this robustness issue and the lack of corresponding studies, we study the problem of MARL with state uncertainty in this work. We provide the first attempt to the theoretical and empirical analysis of this challenging problem. We first model the problem as a Markov Game with state perturbation adversaries (MG-SPA) by introducing a set of state perturbation adversaries into a Markov Game. We then introduce robust equilibrium (RE) as the solution concept of an MG-SPA. We conduct a fundamental analysis regarding MG-SPA such as giving conditions under which such a robust equilibrium exists. Then we propose a robust multi-agent Q-learning (RMAQ) algorithm to find such an equilibrium, with convergence guarantees. To handle high-dimensional state-action space, we design a robust multi-agent actor-critic (RMAAC) algorithm based on an analytical expression of the policy gradient derived in the paper. Our experiments show that the proposed RMAQ algorithm converges to the optimal value function; our RMAAC algorithm outperforms several MARL and robust MARL methods in multiple multi-agent environments when state uncertainty is present. The source code is public on https://github.com/sihongho/robust_marl_with_state_uncertainty",
    "checked": true,
    "id": "b1dd351bab053ea1acac9c1822034480fa3a201e",
    "semantic_title": "robust multi-agent reinforcement learning with state uncertainty",
    "citation_count": 48,
    "authors": [
      "Sihong He",
      "Songyang Han",
      "Sanbao Su",
      "Shuo Han",
      "Shaofeng Zou",
      "Fei Miao"
    ]
  },
  "https://openreview.net/forum?id=ClIcmwdlxn": {
    "title": "Optimum-statistical Collaboration Towards General and Efficient Black-box Optimization",
    "volume": "main",
    "abstract": "In this paper, we make the key delineation on the roles of resolution and statistical uncertainty in hierarchical bandits-based black-box optimization algorithms, guiding a more general analysis and a more efficient algorithm design. We introduce the optimum-statistical collaboration, an algorithm framework of managing the interaction between optimization error flux and statistical error flux evolving in the optimization process. We provide a general analysis of this framework without specifying the forms of statistical error and uncertainty quantifier. Our framework and its analysis, due to their generality, can be applied to a large family of functions and partitions that satisfy different local smoothness assumptions and have different numbers of local optimums, which is much richer than the class of functions studied in prior works. Our framework also inspires us to propose a better measure of the statistical uncertainty and consequently a variance-adaptive algorithm VHCT. In theory, we prove the algorithm enjoys rate-optimal regret bounds under different local smoothness assumptions; in experiments, we show the algorithm outperforms prior efforts in different settings",
    "checked": true,
    "id": "c3a62d14244c5c7fea01c161e32685c0c6e2f043",
    "semantic_title": "optimum-statistical collaboration towards general and efficient black-box optimization",
    "citation_count": 8,
    "authors": [
      "Wenjie Li",
      "Chi-Hua Wang",
      "Guang Cheng",
      "Qifan Song"
    ]
  },
  "https://openreview.net/forum?id=KBhSyBBeeO": {
    "title": "An Adaptive Half-Space Projection Method for Stochastic Optimization Problems with Group Sparse Regularization",
    "volume": "main",
    "abstract": "Optimization problems with group sparse regularization are ubiquitous in various popular downstream applications, such as feature selection and compression for Deep Neural Networks (DNNs). Nonetheless, the existing methods in the literature do not perform particularly well when such regularization is used in combination with a stochastic loss function. In particular, it is challenging to design a computationally efficient algorithm with a convergence guarantee and can compute group-sparse solutions. Recently, a half-space stochastic projected gradient (HSPG) method was proposed that partly addressed these challenges. This paper presents a substantially enhanced version of HSPG that we call AdaHSPG+ that makes two noticeable advances. First, AdaHSPG+ is shown to have a stronger convergence result under significantly looser assumptions than those required by HSPG. This improvement in convergence is achieved by integrating variance reduction techniques with a new adaptive strategy for iteratively predicting the support of a solution. Second, AdaHSPG+ requires significantly less parameter tuning compared to HSPG, thus making it more practical and user-friendly. This advance is achieved by designing automatic and adaptive strategies for choosing the type of step employed at each iteration and for updating key hyperparameters. The numerical effectiveness of our proposed AdaHSPG+ algorithm is demonstrated on both convex and non-convex benchmark problems. The source code is available at https://github.com/tianyic/adahspg",
    "checked": true,
    "id": "6826fe9e5d593cb63129039d35e19d7c0f482790",
    "semantic_title": "an adaptive half-space projection method for stochastic optimization problems with group sparse regularization",
    "citation_count": 6,
    "authors": [
      "Yutong Dai",
      "Tianyi Chen",
      "Guanyi Wang",
      "Daniel Robinson"
    ]
  },
  "https://openreview.net/forum?id=iDNMZgjJuJ": {
    "title": "Causally-guided Regularization of Graph Attention Improves Generalizability",
    "volume": "main",
    "abstract": "Graph attention networks estimate the relational importance of node neighbors to aggregate relevant information over local neighborhoods for a prediction task. However, the inferred attentions are vulnerable to spurious correlations and connectivity in the training data, hampering the generalizability of models. We introduce CAR, a general-purpose regularization framework for graph attention networks. Embodying a causal inference approach based on invariance prediction, CAR aligns the attention mechanism with the causal effects of active interventions on graph connectivity in a scalable manner. CAR is compatible with a variety of graph attention architectures, and we show that it systematically improves generalizability on various node classification tasks. Our ablation studies indicate that CAR hones in on the aspects of graph structure most pertinent to the prediction (e.g., homophily), and does so more effectively than alternative approaches. Finally, we also show that \\methodname enhances interpretability of attention coefficients by accentuating node-neighbor relations that point to causal hypotheses",
    "checked": true,
    "id": "72251264a02dc750b3293837be108b47a82fb7a7",
    "semantic_title": "causally-guided regularization of graph attention improves generalizability",
    "citation_count": 4,
    "authors": [
      "Alexander P Wu",
      "Thomas Markovich",
      "Bonnie Berger",
      "Nils Yannick Hammerla",
      "Rohit Singh"
    ]
  },
  "https://openreview.net/forum?id=nEX2q5B2RQ": {
    "title": "Analyzing Deep PAC-Bayesian Learning with Neural Tangent Kernel: Convergence, Analytic Generalization Bound, and Efficient Hyperparameter Selection",
    "volume": "main",
    "abstract": "PAC-Bayes is a well-established framework for analyzing generalization performance in machine learning models. This framework provides a bound on the expected population error by considering the sum of training error and the divergence between posterior and prior distributions. In addition to being a successful generalization bound analysis tool, the PAC-Bayesian bound can also be incorporated into an objective function for training probabilistic neural networks, which we refer to simply as {\\it Deep PAC-Bayesian Learning}. Deep PAC-Bayesian learning has been shown to achieve competitive expected test set error and provide a tight generalization bound in practice at the same time through gradient descent training. Despite its empirical success, theoretical analysis of deep PAC-Bayesian learning for neural networks is rarely explored. To this end, this paper proposes a theoretical convergence and generalization analysis for Deep PAC-Bayesian learning. For a deep and wide probabilistic neural network, our analysis shows that PAC-Bayesian learning corresponds to solving a kernel ridge regression when the probabilistic neural tangent kernel (PNTK) is used as the kernel. We utilize this outcome in conjunction with the PAC-Bayes $\\mathcal{C}$-bound, enabling us to derive an analytical and guaranteed PAC-Bayesian generalization bound for the first time. Finally, drawing insight from our theoretical results, we propose a proxy measure for efficient hyperparameter selection, which is proven to be time-saving on various benchmarks. Our work not only provides a better understanding of the theoretical underpinnings of Deep PAC-Bayesian learning, but also offers practical tools for improving the training and generalization performance of these models",
    "checked": true,
    "id": "8dab53b0cc7358b36a0fc7e5ff09f5c9a492b1c8",
    "semantic_title": "analyzing deep pac-bayesian learning with neural tangent kernel: convergence, analytic generalization bound, and efficient hyperparameter selection",
    "citation_count": 4,
    "authors": [
      "Wei Huang",
      "Chunrui Liu",
      "Yilan Chen",
      "Richard Yi Da Xu",
      "Miao Zhang",
      "Tsui-Wei Weng"
    ]
  },
  "https://openreview.net/forum?id=ttzypy3kT7": {
    "title": "High-Modality Multimodal Transformer: Quantifying Modality & Interaction Heterogeneity for High-Modality Representation Learning",
    "volume": "main",
    "abstract": "Many real-world problems are inherently multimodal, from the communicative modalities humans use to express social and emotional states such as spoken language, gestures, and paralinguistics to the force, proprioception, and visual sensors ubiquitous on robots. While there has been an explosion of interest in multimodal representation learning, these methods are still largely focused on a small set of modalities, primarily in the language, vision, and audio space. In order to accelerate generalization towards diverse and understudied modalities, this paper studies efficient representation learning for high-modality scenarios involving a large set of diverse modalities. Since adding new models for every new modality or task becomes prohibitively expensive, a critical technical challenge is heterogeneity quantification: how can we measure which modalities encode similar information and interactions in order to permit parameter sharing with previous modalities? This paper proposes two new information theoretic metrics for heterogeneity quantification: (1) modality heterogeneity studies how similar $2$ modalities $\\{X_1,X_2\\}$ are by measuring how much information can be transferred from $X_1$ to $X_2$, while (2) interaction heterogeneity studies how similarly pairs of modalities $\\{X_1,X_2\\}, \\{X_3,X_4\\}$ interact by measuring how much interaction information can be transferred from $\\{X_1,X_2\\}$ to $\\{X_3,X_4\\}$. We show the importance of these $2$ proposed metrics in high-modality scenarios as a way to automatically prioritize the fusion of modalities that contain unique information or unique interactions. The result is a single model, HighMMT, that scales up to $10$ modalities (text, image, audio, video, sensors, proprioception, speech, time-series, sets, and tables) and $15$ tasks from $5$ different research areas. Not only does HighMMT outperform prior methods on the tradeoff between performance and efficiency, it also demonstrates a crucial scaling behavior: performance continues to improve with each modality added, and it transfers to entirely new modalities and tasks during fine-tuning. We release our code and benchmarks, which we hope will present a unified platform for subsequent theoretical and empirical analysis",
    "checked": true,
    "id": "0651e9cbe0b8c1b4465c80d2309af62e5e4da574",
    "semantic_title": "high-modality multimodal transformer: quantifying modality & interaction heterogeneity for high-modality representation learning",
    "citation_count": 34,
    "authors": [
      "Paul Pu Liang",
      "Yiwei Lyu",
      "Xiang Fan",
      "Jeffrey Tsaw",
      "Yudong Liu",
      "Shentong Mo",
      "Dani Yogatama",
      "Louis-Philippe Morency",
      "Russ Salakhutdinov"
    ]
  },
  "https://openreview.net/forum?id=TH6YrEcbth": {
    "title": "Learning Interpolations between Boltzmann Densities",
    "volume": "main",
    "abstract": "We introduce a training objective for continuous normalizing flows that can be used in the absence of samples but in the presence of an energy function. Our method relies on either a prescribed or a learnt interpolation $f_t$ of energy functions between the target energy $f_1$ and the energy function of a generalized Gaussian $f_0(x) = ||x/\\sigma||_p^p$. The interpolation of energy functions induces an interpolation of Boltzmann densities $p_t \\propto e^{-f_t}$ and we aim to find a time-dependent vector field $V_t$ that transports samples along the family $p_t$ of densities. The condition of transporting samples along the family $p_t$ is equivalent to satisfying the continuity equation with $V_t$ and $p_t = Z_t^{-1}e^{-f_t}$. Consequently, we optimize $V_t$ and $f_t$ to satisfy this partial differential equation. We experimentally compare the proposed training objective to the reverse KL-divergence on Gaussian mixtures and on the Boltzmann density of a quantum mechanical particle in a double-well potential",
    "checked": true,
    "id": "6404636ef49ceef284c09ed6aaa32641b6723cde",
    "semantic_title": "learning interpolations between boltzmann densities",
    "citation_count": 31,
    "authors": [
      "Bálint Máté",
      "François Fleuret"
    ]
  },
  "https://openreview.net/forum?id=LjDFIWWVVa": {
    "title": "Retiring $\\Delta \\text{DP}$: New Distribution-Level Metrics for Demographic Parity",
    "volume": "main",
    "abstract": "Demographic parity is the most widely recognized measure of group fairness in machine learning, which ensures equal treatment of different demographic groups. Numerous works aim to achieve demographic parity by pursuing the commonly used metric $\\Delta DP$. Unfortunately, in this paper, we reveal that the fairness metric $\\Delta DP$ can not precisely measure the violation of demographic parity, because it inherently has the following drawbacks: i) zero-value $\\Delta DP$ does not guarantee zero violation of demographic parity, ii) $\\Delta DP$ values can vary with different classification thresholds. To this end, we propose two new fairness metrics, Area Between Probability density function Curves (ABPC) and Area Between Cumulative density function Curves (ABCC), to precisely measure the violation of demographic parity at the distribution level. The new fairness metrics directly measure the difference between the distributions of the prediction probability for different demographic groups. Thus our proposed new metrics enjoy: i) zero-value ABCC/ABPC guarantees zero violation of demographic parity; ii) ABCC/ABPC guarantees demographic parity while the classification thresholds are adjusted. We further re-evaluate the existing fair models with our proposed fairness metrics and observe different fairness behaviors of those models under the new metrics",
    "checked": false,
    "id": "8dc4f76559e3d603412d4ba7b3af118233942b05",
    "semantic_title": "retiring $\\delta$dp: new distribution-level metrics for demographic parity",
    "citation_count": 4,
    "authors": [
      "Xiaotian Han",
      "Zhimeng Jiang",
      "Hongye Jin",
      "Zirui Liu",
      "Na Zou",
      "Qifan Wang",
      "Xia Hu"
    ]
  },
  "https://openreview.net/forum?id=2f81Q622ww": {
    "title": "Generating Adversarial Examples with Task Oriented Multi-Objective Optimization",
    "volume": "main",
    "abstract": "Deep learning models, even the-state-of-the-art ones, are highly vulnerable to adversarial examples. Adversarial training is one of the most efficient methods to improve the model's robustness. The key factor for the success of adversarial training is the capability to generate qualified and divergent adversarial examples which satisfy some objectives/goals (e.g., finding adversarial examples that maximize the model losses for simultaneously attacking multiple models). Therefore, multi-objective optimization (MOO) is a natural tool for adversarial example generation to achieve multiple objectives/goals simultaneously. However, we observe that a naive application of MOO tends to maximize all objectives/goals equally, without caring if an objective/goal has been achieved yet. This leads to useless effort to further improve the goal-achieved tasks, while putting less focus on the goal-unachieved tasks. In this paper, we propose \\emph{Task Oriented MOO} to address this issue, in the context where we can explicitly define the goal achievement for a task. Our principle is to only maintain the goal-achieved tasks, while letting the optimizer spend more effort on improving the goal-unachieved tasks. We conduct comprehensive experiments for our Task Oriented MOO on various adversarial example generation schemes. The experimental results firmly demonstrate the merit of our proposed approach",
    "checked": true,
    "id": "8836eebd5420c337565937a9623156a193623444",
    "semantic_title": "generating adversarial examples with task oriented multi-objective optimization",
    "citation_count": 1,
    "authors": [
      "Anh Tuan Bui",
      "Trung Le",
      "He Zhao",
      "Quan Hung Tran",
      "Paul Montague",
      "Dinh Phung"
    ]
  },
  "https://openreview.net/forum?id=D45gGvUZp2": {
    "title": "Denise: Deep Robust Principal Component Analysis for Positive Semidefinite Matrices",
    "volume": "main",
    "abstract": "The robust PCA of covariance matrices plays an essential role when isolating key explanatory features. The currently available methods for performing such a low-rank plus sparse decomposition are matrix specific, meaning, those algorithms must re-run for every new matrix. Since these algorithms are computationally expensive, it is preferable to learn and store a function that nearly instantaneously performs this decomposition when evaluated. Therefore, we introduce Denise, a deep learning-based algorithm for robust PCA of covariance matrices, or more generally, of symmetric positive semidefinite matrices, which learns precisely such a function. Theoretical guarantees for Denise are provided. These include a novel universal approximation theorem adapted to our geometric deep learning problem and convergence to an optimal solution to the learning problem. Our experiments show that Denise matches state-of-the-art performance in terms of decomposition quality, while being approximately $2000\\times$ faster than the state-of-the-art, principal component pursuit (PCP), and $200 \\times$ faster than the current speed-optimized method, fast PCP",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Calypso Herrera",
      "Florian Krach",
      "Anastasis Kratsios",
      "Pierre Ruyssen",
      "Josef Teichmann"
    ]
  },
  "https://openreview.net/forum?id=ZME2nZMTvY": {
    "title": "Mean-Field Control based Approximation of Multi-Agent Reinforcement Learning in Presence of a Non-decomposable Shared Global State",
    "volume": "main",
    "abstract": "Mean Field Control (MFC) is a powerful approximation tool to solve large-scale Multi-Agent Reinforcement Learning (MARL) problems. However, the success of MFC relies on the presumption that given the local states and actions of all the agents, the next (local) states of the agents evolve conditionally independent of each other. Here we demonstrate that even in a MARL setting where agents share a common global state in addition to their local states evolving conditionally independently (thus introducing a correlation between the state transition processes of individual agents), the MFC can still be applied as a good approximation tool. The global state is assumed to be non-decomposable i.e., it cannot be expressed as a collection of local states of the agents. We compute the approximation error as $\\mathcal{O}(e)$ where $e=\\frac{1}{\\sqrt{N}}\\left[\\sqrt{|\\mathcal{X}|} +\\sqrt{|\\mathcal{U}|}\\right]$. The size of the agent population is denoted by the term $N$, and $|\\mathcal{X}|, |\\mathcal{U}|$ respectively indicate the sizes of (local) state and action spaces of individual agents. The approximation error is found to be independent of the size of the shared global state space. We further demonstrate that in a special case if the reward and state transition functions are independent of the action distribution of the population, then the error can be improved to $e=\\frac{\\sqrt{|\\mathcal{X}|}}{\\sqrt{N}}$. Finally, we devise a Natural Policy Gradient based algorithm that solves the MFC problem with $\\mathcal{O}(\\epsilon^{-3})$ sample complexity and obtains a policy that is within $\\mathcal{O}(\\max\\{e,\\epsilon\\})$ error of the optimal MARL policy for any $\\epsilon>0$",
    "checked": true,
    "id": "715daa423edae09c6213f0ff43f6c759384a8906",
    "semantic_title": "mean-field control based approximation of multi-agent reinforcement learning in presence of a non-decomposable shared global state",
    "citation_count": 9,
    "authors": [
      "Washim Uddin Mondal",
      "Vaneet Aggarwal",
      "Satish Ukkusuri"
    ]
  },
  "https://openreview.net/forum?id=DdZoPUPm0a": {
    "title": "Interpretable Mixture of Experts",
    "volume": "main",
    "abstract": "The need for reliable model explanations is prominent for many machine learning applications, particularly for tabular and time-series data as their use cases often involve high-stakes decision making. Towards this goal, we introduce a novel interpretable modeling framework, Interpretable Mixture of Experts (IME), that yields high accuracy, comparable to `black-box' Deep Neural Networks (DNNs) in many cases, along with useful interpretability capabilities. IME consists of an assignment module and a mixture of experts, with each sample being assigned to a single expert for prediction. We introduce multiple options for IME based on the assignment and experts being interpretable. When the experts are chosen to be interpretable such as linear models, IME yields an inherently-interpretable architecture where the explanations produced by IME are the exact descriptions of how the prediction is computed. In addition to constituting a standalone inherently-interpretable architecture, IME has the premise of being integrated with existing DNNs to offer interpretability to a subset of samples while maintaining the accuracy of the DNNs. Through extensive experiments on 15 tabular and time-series datasets, IME is demonstrated to be more accurate than single interpretable models and perform comparably with existing state-of-the-art DNNs in accuracy. On most datasets, IME even outperforms DNNs, while providing faithful explanations. Lastly, IME's explanations are compared to commonly-used post-hoc explanations methods through a user study -- participants are able to better predict the model behavior when given IME explanations, while finding IME's explanations more faithful and trustworthy",
    "checked": true,
    "id": "ba244bcdba17129dbb5955159fdf793db505c2f8",
    "semantic_title": "interpretable mixture of experts",
    "citation_count": 11,
    "authors": [
      "Aya Abdelsalam Ismail",
      "Sercan O Arik",
      "Jinsung Yoon",
      "Ankur Taly",
      "Soheil Feizi",
      "Tomas Pfister"
    ]
  },
  "https://openreview.net/forum?id=162TqkUNPO": {
    "title": "Comparative Generalization Bounds for Deep Neural Networks",
    "volume": "main",
    "abstract": "In this work, we investigate the generalization capabilities of deep neural networks. We introduce a novel measure of the effective depth of neural networks, defined as the first layer at which sample embeddings are separable using the nearest-class center classifier. Our empirical results demonstrate that, in standard classification settings, neural networks trained using Stochastic Gradient Descent (SGD) tend to have small effective depths. We also explore the relationship between effective depth, the complexity of the training dataset, and generalization. For instance, we find that the effective depth of a trained neural network increases as the proportion of random labels in the data rises. Finally, we derive a generalization bound by comparing the effective depth of a network with the minimal depth required to fit the same dataset with partially corrupted labels. This bound provides non-vacuous predictions of test performance and is found to be empirically independent of the actual depth of the network",
    "checked": true,
    "id": "70425b0964fcff792cba8b82e8571f7047008ab2",
    "semantic_title": "comparative generalization bounds for deep neural networks",
    "citation_count": 7,
    "authors": [
      "Tomer Galanti",
      "Liane Galanti",
      "Ido Ben-Shaul"
    ]
  },
  "https://openreview.net/forum?id=wNBARGxoJn": {
    "title": "Learning to correct spectral methods for simulating turbulent flows",
    "volume": "main",
    "abstract": "Despite their ubiquity throughout science and engineering, only a handful of partial differential equations (PDEs) have analytical, or closed-form solutions. This motivates a vast amount of classical work on numerical simulation of PDEs and more recently, a whirlwind of research into data-driven techniques leveraging machine learning (ML). A recent line of work indicates that a hybrid of classical numerical techniques and machine learning can offer significant improvements over either approach alone. In this work, we show that the choice of the numerical scheme is crucial when incorporating physics-based priors. We build upon Fourier-based spectral methods, which are known to be more efficient than other numerical schemes for simulating PDEs with smooth and periodic solutions. Specifically, we develop ML-augmented spectral solvers for three common PDEs of fluid dynamics. Our models are more accurate (2-4x) than standard spectral solvers at the same resolution but have longer overall runtimes (~2x), due to the additional runtime cost of the neural network component. We also demonstrate a handful of key design principles for combining machine learning and numerical methods for solving PDEs",
    "checked": true,
    "id": "e6e0222b93b6531833fc2d4ff8f6fc35588b5b2b",
    "semantic_title": "learning to correct spectral methods for simulating turbulent flows",
    "citation_count": 64,
    "authors": [
      "Gideon Dresdner",
      "Dmitrii Kochkov",
      "Peter Christian Norgaard",
      "Leonardo Zepeda-Nunez",
      "Jamie Smith",
      "Michael Brenner",
      "Stephan Hoyer"
    ]
  },
  "https://openreview.net/forum?id=xzCDD9i4IZ": {
    "title": "Cox-Hawkes: doubly stochastic spatiotemporal Poisson processes",
    "volume": "main",
    "abstract": "Hawkes processes are point process models that have been used to capture self-excitatory behaviour in social interactions, neural activity, earthquakes and viral epidemics. They can model the occurrence of the times and locations of events. Here we develop a new class of spatiotemporal Hawkes processes that can capture both triggering and clustering behaviour and we provide an efficient method for performing inference. We use a log-Gaussian Cox process (LGCP) as prior for the background rate of the Hawkes process which gives arbitrary flexibility to capture a wide range of underlying background effects (for infectious diseases these are called endemic effects). The Hawkes process and LGCP are computationally expensive due to the former having a likelihood with quadratic complexity in the number of observations and the latter involving inversion of the precision matrix which is cubic in observations. Here we propose a novel approach to perform MCMC sampling for our Hawkes process with LGCP background, using pre-trained Gaussian Process generators which provide direct and cheap access to samples during inference. We show the efficacy and flexibility of our approach in experiments on simulated data and use our methods to uncover the trends in a dataset of reported crimes in the US",
    "checked": true,
    "id": "f89396d31e0d0f35ac7a99de4a73707f00b9cd04",
    "semantic_title": "cox-hawkes: doubly stochastic spatiotemporal poisson processes",
    "citation_count": 4,
    "authors": [
      "Xenia Miscouridou",
      "Samir Bhatt",
      "George Mohler",
      "Seth Flaxman",
      "Swapnil Mishra"
    ]
  },
  "https://openreview.net/forum?id=ilHM31lXC4": {
    "title": "Personalized Federated Learning: A Unified Framework and Universal Optimization Techniques",
    "volume": "main",
    "abstract": "We investigate the optimization aspects of personalized Federated Learning (FL). We propose general optimizers that can be applied to numerous existing personalized FL objectives, specifically a tailored variant of Local SGD and variants of accelerated coordinate descent/accelerated SVRCD. By examining a general personalized objective capable of recovering many existing personalized FL objectives as special cases, we develop a comprehensive optimization theory applicable to a wide range of strongly convex personalized FL models in the literature. We showcase the practicality and/or optimality of our methods in terms of communication and local computation. Remarkably, our general optimization solvers and theory can recover the best-known communication and computation guarantees for addressing specific personalized FL objectives. Consequently, our proposed methods can serve as universal optimizers, rendering the design of task-specific optimizers unnecessary in many instances",
    "checked": true,
    "id": "44fa4438b1319f0ca97af13fe1a361f01e16aab6",
    "semantic_title": "personalized federated learning: a unified framework and universal optimization techniques",
    "citation_count": 54,
    "authors": [
      "Filip Hanzely",
      "Boxin Zhao",
      "mladen kolar"
    ]
  },
  "https://openreview.net/forum?id=l5BzfQhROl": {
    "title": "Generating Teammates for Training Robust Ad Hoc Teamwork Agents via Best-Response Diversity",
    "volume": "main",
    "abstract": "Ad hoc teamwork (AHT) is the challenge of designing a robust learner agent that effectively collaborates with unknown teammates without prior coordination mechanisms. Early approaches address the AHT challenge by training the learner with a diverse set of handcrafted teammate policies, usually designed based on an expert's domain knowledge about the policies the learner may encounter. However, implementing teammate policies for training based on domain knowledge is not always feasible. In such cases, recent approaches attempted to improve the robustness of the learner by training it with teammate policies generated by optimising information-theoretic diversity metrics. The problem with optimising existing information-theoretic diversity metrics for teammate policy generation is the emergence of superficially different teammates. When used for AHT training, superficially different teammate behaviours may not improve a learner's robustness during collaboration with unknown teammates. In this paper, we present an automated teammate policy generation method optimising the Best-Response Diversity (BRDiv) metric, which measures diversity based on the compatibility of teammate policies in terms of returns. We evaluate our approach in environments with multiple valid coordination strategies, comparing against methods optimising information-theoretic diversity metrics and an ablation not optimising any diversity metric. Our experiments indicate that optimising BRDiv yields a diverse set of training teammate policies that improve the learner's performance relative to previous teammate generation approaches when collaborating with near-optimal previously unseen teammate policies",
    "checked": true,
    "id": "ede53ce63a31e7398b657463415e7429399a6bb0",
    "semantic_title": "generating teammates for training robust ad hoc teamwork agents via best-response diversity",
    "citation_count": 11,
    "authors": [
      "Arrasy Rahman",
      "Elliot Fosong",
      "Ignacio Carlucho",
      "Stefano V Albrecht"
    ]
  },
  "https://openreview.net/forum?id=ZgXfXSz51n": {
    "title": "Guillotine Regularization: Why removing layers is needed to improve generalization in Self-Supervised Learning",
    "volume": "main",
    "abstract": "One unexpected technique that emerged in recent years consists in training a Deep Network (DN) with a Self-Supervised Learning (SSL) method, and using this network on downstream tasks but with its last few layers entirely removed. This usually skimmed-over trick of throwing away the entire projector is actually critical for SSL methods to display competitive performances. For example, on ImageNet classification, more than 30 points of percentage can be gained that way. This is a little vexing, as one would hope that the network layer at which invariance is explicitly enforced by the SSL criterion during training (the last layer) should be the one to use for best generalization performance downstream. But it seems not to be, and this study sheds some light on why. This trick, which we name Guillotine Regularization (GR), is in fact a generically applicable method that has been used to improve generalization performance in transfer learning scenarios. In this work, we identify the underlying reasons behind its success and challenge the preconceived idea that we should through away the entire projector in SSL. In fact, the optimal layer to use might change significantly depending on the training setup, the data or the downstream task. Lastly, we give some insights on how to reduce the need for a projector in SSL by aligning the pretext SSL task and the downstream task",
    "checked": true,
    "id": "3f60e8735f735cc84febde2340cb735e33fa1a76",
    "semantic_title": "guillotine regularization: why removing layers is needed to improve generalization in self-supervised learning",
    "citation_count": 25,
    "authors": [
      "Florian Bordes",
      "Randall Balestriero",
      "Quentin Garrido",
      "Adrien Bardes",
      "Pascal Vincent"
    ]
  },
  "https://openreview.net/forum?id=MTFf1rDDEI": {
    "title": "Successor Feature Representations",
    "volume": "main",
    "abstract": "Transfer in Reinforcement Learning aims to improve learning performance on target tasks using knowledge from experienced source tasks. Successor Representations (SR) and their extension Successor Features (SF) are prominent transfer mechanisms in domains where reward functions change between tasks. They reevaluate the expected return of previously learned policies in a new target task to transfer their knowledge. The SF framework extended SR by linearly decomposing rewards into successor features and a reward weight vector allowing their application in high-dimensional tasks. But this came with the cost of having a linear relationship between reward functions and successor features, limiting its application to tasks where such a linear relationship exists. We propose a novel formulation of SR based on learning the cumulative discounted probability of successor features, called Successor Feature Representations (SFR). Crucially, SFR allows to reevaluate the expected return of policies for general reward functions. We introduce different SFR variations, prove its convergence, and provide a guarantee on its transfer performance. Experimental evaluations based on SFR with function approximation demonstrate its advantage over SF not only for general reward functions, but also in the case of linearly decomposable reward functions",
    "checked": true,
    "id": "f8d4cb5d710fd6fc93bb55a8e1ccf3a1af05443d",
    "semantic_title": "successor feature representations",
    "citation_count": 5,
    "authors": [
      "Chris Reinke",
      "Xavier Alameda-Pineda"
    ]
  },
  "https://openreview.net/forum?id=Jjl2c8kWUc": {
    "title": "Lightweight Learner for Shared Knowledge Lifelong Learning",
    "volume": "main",
    "abstract": "In Lifelong Learning (LL), agents continually learn as they encounter new conditions and tasks. Most current LL is limited to a single agent that learns tasks sequentially. Dedicated LL machinery is then deployed to mitigate the forgetting of old tasks as new tasks are learned. This is inherently slow. We propose a new Shared Knowledge Lifelong Learning (SKILL) challenge, which deploys a decentralized population of LL agents that each sequentially learn different tasks, with all agents operating independently and in parallel. After learning their respective tasks, agents share and consolidate their knowledge over a decentralized communication network, so that, in the end, all agents can master all tasks. We present one solution to SKILL which uses Lightweight Lifelong Learning (LLL) agents, where the goal is to facilitate efficient sharing by minimizing the fraction of the agent that is specialized for any given task. Each LLL agent thus consists of a common task-agnostic immutable part, where most parameters are, and individual task-specific modules that contain fewer parameters but are adapted to each task. Agents share their task-specific modules, plus summary information (\"task anchors\") representing their tasks in the common task-agnostic latent space of all agents. Receiving agents register each received task-specific module using the corresponding anchor. Thus, every agent improves its ability to solve new tasks each time new task-specific modules and anchors are received. If all agents can communicate with all others, eventually all agents become identical and can solve all tasks. On a new, very challenging SKILL-102 dataset with 102 image classification tasks (5,033 classes in total, 2,041,225 training, 243,464 validation, and 243,464 test images), we achieve much higher (and SOTA) accuracy over 8 LL baselines, while also achieving near perfect parallelization. Code and data can be found at https://github.com/gyhandy/Shared-Knowledge-Lifelong-Learning",
    "checked": true,
    "id": "beed9a33fe65602bf10e3dd283206f1e1fcdf9c3",
    "semantic_title": "lightweight learner for shared knowledge lifelong learning",
    "citation_count": 12,
    "authors": [
      "Yunhao Ge",
      "Yuecheng Li",
      "Di Wu",
      "Ao Xu",
      "Adam M. Jones",
      "Amanda Sofie Rios",
      "Iordanis Fostiropoulos",
      "shixian wen",
      "Po-Hsuan Huang",
      "Zachary William Murdock",
      "Gozde Sahin",
      "Shuo Ni",
      "Kiran Lekkala",
      "Sumedh Anand Sontakke",
      "Laurent Itti"
    ]
  },
  "https://openreview.net/forum?id=6rbcq0qacA": {
    "title": "Deep Plug-and-Play Clustering with Unknown Number of Clusters",
    "volume": "main",
    "abstract": "Clustering is an essential task for the purpose that data points can be classified in an unsupervised manner. Most deep clustering algorithms are very effective when given the number of clusters K. However, when K is unknown, finding the appropriate K for these algorithms can be computationally expensive via model-selection criteria, and applying algorithms with an inaccurate K can hardly achieve the state-of-the-art performance. This paper proposes a plug-and-play clustering module to automatically adjust the number of clusters, which can be easily embedded into existing deep parametric clustering methods. By analyzing the goal of clustering, a split-and-merge framework is introduced to reduce the intra-class diversity and increase the inter-class difference, which leverages the entropy between different clusters. Specifically, given an initial clustering number, clusters can be split into sub-clusters or merged into super-clusters and converge to a stable number of K clusters at the end of training. Experiments on benchmark datasets demonstrate that the proposed method can achieve comparable performance with the state-of-the-art works without requiring the number of clusters",
    "checked": true,
    "id": "5c83672a68e1aa8bcc7db8a6bc77607cdb102751",
    "semantic_title": "deep plug-and-play clustering with unknown number of clusters",
    "citation_count": 2,
    "authors": [
      "An Xiao",
      "Hanting Chen",
      "Tianyu Guo",
      "QINGHUA ZHANG",
      "Yunhe Wang"
    ]
  },
  "https://openreview.net/forum?id=v73h3bYE2Z": {
    "title": "When to Trust Aggregated Gradients: Addressing Negative Client Sampling in Federated Learning",
    "volume": "main",
    "abstract": "Federated Learning has become a widely-used framework which allows learning a global model on decentralized local datasets under the condition of protecting local data privacy. However, federated learning faces severe optimization difficulty when training samples are not independently and identically distributed (non-i.i.d.). In this paper, we point out that the client sampling practice plays a decisive role in the aforementioned optimization difficulty. We find that the negative client sampling will cause the merged data distribution of currently sampled clients heavily inconsistent with that of all available clients, and further make the aggregated gradient unreliable. To address this issue, we propose a novel learning rate adaptation mechanism to adaptively adjust the server learning rate for the aggregated gradient in each round, according to the consistency between the merged data distribution of currently sampled clients and that of all available clients. Specifically, we make theoretical deductions to find a meaningful and robust indicator that is positively related to the optimal server learning rate, which is supposed to minimize the Euclidean distance between the aggregated gradient given currently sampled clients and that if all clients could participate in the current round. We show that our proposed indicator can effectively reflect the merged data distribution of sampled clients, thus we utilize it for the server learning rate adaptation. Extensive experiments on multiple image and text classification tasks validate the great effectiveness of our method in various settings. Our code is available at https://github.com/lancopku/FedGLAD",
    "checked": true,
    "id": "90bf8112b28e6daf397873ba744f59ce8a5c3cbb",
    "semantic_title": "when to trust aggregated gradients: addressing negative client sampling in federated learning",
    "citation_count": 2,
    "authors": [
      "Wenkai Yang",
      "Yankai Lin",
      "Guangxiang Zhao",
      "Peng Li",
      "Jie Zhou",
      "Xu Sun"
    ]
  },
  "https://openreview.net/forum?id=R8TU3pfzFr": {
    "title": "A Measure of the Complexity of Neural Representations based on Partial Information Decomposition",
    "volume": "main",
    "abstract": "In neural networks, task-relevant information is represented jointly by groups of neurons. However, the specific way in which this mutual information about the classification label is distributed among the individual neurons is not well understood: While parts of it may only be obtainable from specific single neurons, other parts are carried redundantly or synergistically by multiple neurons. We show how Partial Information Decomposition (PID), a recent extension of information theory, can disentangle these different contributions. From this, we introduce the measure of ``Representational Complexity'', which quantifies the difficulty of accessing information spread across multiple neurons. We show how this complexity is directly computable for smaller layers. For larger layers, we propose subsampling and coarse-graining procedures and prove corresponding bounds on the latter. Empirically, for quantized deep neural networks solving the MNIST and CIFAR10 tasks, we observe that representational complexity decreases both through successive hidden layers and over training, and compare the results to related measures. Overall, we propose representational complexity as a principled and interpretable summary statistic for analyzing the structure and evolution of neural representations and complex systems in general",
    "checked": true,
    "id": "42b41c171e6c11443cbb5f4b1b1783d77b036917",
    "semantic_title": "a measure of the complexity of neural representations based on partial information decomposition",
    "citation_count": 20,
    "authors": [
      "David Alexander Ehrlich",
      "Andreas Christian Schneider",
      "Viola Priesemann",
      "Michael Wibral",
      "Abdullah Makkeh"
    ]
  },
  "https://openreview.net/forum?id=MR4glug5GU": {
    "title": "Trip-ROMA: Self-Supervised Learning with Triplets and Random Mappings",
    "volume": "main",
    "abstract": "Contrastive self-supervised learning (SSL) methods, such as MoCo and SimCLR, have achieved great success in unsupervised visual representation learning. They rely on a large number of negative pairs and thus require either large memory banks or large batches. Some recent non-contrastive SSL methods, such as BYOL and SimSiam, attempt to discard negative pairs and have also shown remarkable performance. To avoid collapsed solutions caused by not using negative pairs, these methods require non-trivial asymmetry designs. However, in small data regimes, we can not obtain a sufficient number of negative pairs or effectively avoid the over-fitting problem when negatives are not used at all. To address this situation, we argue that negative pairs are still important but one is generally sufficient for each positive pair. We show that a simple Triplet-based loss (Trip) can achieve surprisingly good performance without requiring large batches or asymmetry designs. Moreover, to alleviate the over-fitting problem in small data regimes and further enhance the effect of Trip, we propose a simple plug-and-play RandOm MApping (ROMA) strategy by randomly mapping samples into other spaces and requiring these randomly projected samples to satisfy the same relationship indicated by the triplets. Integrating the triplet-based loss with random mapping, we obtain the proposed method Trip-ROMA. Extensive experiments, including unsupervised representation learning and unsupervised few-shot learning, have been conducted on ImageNet-1K and seven small datasets. They successfully demonstrate the effectiveness of Trip-ROMA and consistently show that ROMA can further effectively boost other SSL methods. Code is available at https://github.com/WenbinLee/Trip-ROMA",
    "checked": true,
    "id": "ce4996bf6ad0b0e50fcfd38646a137d31e4a5ceb",
    "semantic_title": "trip-roma: self-supervised learning with triplets and random mappings",
    "citation_count": 0,
    "authors": [
      "Wenbin Li",
      "Xuesong Yang",
      "Meihao Kong",
      "Lei Wang",
      "Jing Huo",
      "Yang Gao",
      "Jiebo Luo"
    ]
  },
  "https://openreview.net/forum?id=DUsgPi3oCC": {
    "title": "Conditional Permutation Invariant Flows",
    "volume": "main",
    "abstract": "We present a conditional generative probabilistic model of set-valued data with a tractable log density. This model is a continuous normalizing flow governed by permutation equivariant dynamics. These dynamics are driven by a learnable per-set-element term and pairwise interactions, both parametrized by deep neural networks. We illustrate the utility of this model via applications including (1) complex traffic scene generation conditioned on visually specified map information, and (2) object bounding box generation conditioned directly on images. We train our model by maximizing the expected likelihood of labeled conditional data under our flow, with the aid of a penalty that ensures the dynamics are smooth and hence efficiently solvable. Our method significantly outperforms non-permutation invariant baselines in terms of log likelihood and domain-specific metrics (offroad, collision, and combined infractions), yielding realistic samples that are difficult to distinguish from data",
    "checked": true,
    "id": "635ba79662d9becdd2331ab7a3d1336bbb8ed39c",
    "semantic_title": "conditional permutation invariant flows",
    "citation_count": 9,
    "authors": [
      "Berend Zwartsenberg",
      "Adam Scibior",
      "Matthew Niedoba",
      "Vasileios Lioutas",
      "Justice Sefas",
      "Yunpeng Liu",
      "Setareh Dabiri",
      "Jonathan Wilder Lavington",
      "Trevor Campbell",
      "Frank Wood"
    ]
  },
  "https://openreview.net/forum?id=RLYkyucU6k": {
    "title": "Agent-State Construction with Auxiliary Inputs",
    "volume": "main",
    "abstract": "In many, if not every realistic sequential decision-making task, the decision-making agent is not able to model the full complexity of the world. The environment is often much larger and more complex than the agent, a setting also known as partial observability. In such settings, the agent must leverage more than just the current sensory inputs; it must construct an agent state that summarizes previous interactions with the world. Currently, a popular approach for tackling this problem is to learn the agent-state function via a recurrent network from the agent's sensory stream as input. Many impressive reinforcement learning applications have instead relied on environment-specific functions to aid the agent's inputs for history summarization. These augmentations are done in multiple ways, from simple approaches like concatenating observations to more complex ones such as uncertainty estimates. Although ubiquitous in the field, these additional inputs, which we term auxiliary inputs, are rarely emphasized, and it is not clear what their role or impact is. In this work we explore this idea further, and relate these auxiliary inputs to prior classic approaches to state construction. We present a series of examples illustrating the different ways of using auxiliary inputs for reinforcement learning. We show that these auxiliary inputs can be used to discriminate between observations that would otherwise be aliased, leading to more expressive features that smoothly interpolate between different states. Finally, we show that this approach is complementary to state-of-the-art methods such as recurrent neural networks and truncated back-propagation through time, and acts as a heuristic that facilitates longer temporal credit assignment, leading to better performance",
    "checked": true,
    "id": "a04611387661acfc81266260fa443803062953d0",
    "semantic_title": "agent-state construction with auxiliary inputs",
    "citation_count": 5,
    "authors": [
      "Ruo Yu Tao",
      "Adam White",
      "Marlos C. Machado"
    ]
  },
  "https://openreview.net/forum?id=9KoBOlstTq": {
    "title": "Modelling sequential branching dynamics with a multivariate branching Gaussian process",
    "volume": "main",
    "abstract": "The Branching Gaussian Process (BGP) model is a modification of the Overlapping Mixture of Gaussian Processes (OMGP) where latent functions branch in time. The BGP model was introduced as a method to model bifurcations in single-cell gene expression data and order genes by inferring their branching time parameter. A limitation of the current BGP model is that the assignment of observations to latent functions is inferred independently for each output dimension (gene). This leads to inconsistent assignments across outputs and reduces the accuracy of branching time inference. Here, we propose a multivariate branching Gaussian process (MBGP) model to perform joint branch assignment inference across multiple output dimensions. This ensures that branch assignments are consistent and leverages more data for branching time inference. Model inference is more challenging than for the original BGP or OMGP models because assignment labels can switch from trunk to branch lineages as branching times change during inference. To scale up inference to large datasets we use sparse variational Bayesian inference. We examine the effectiveness of our approach on synthetic data and a single-cell RNA-Seq dataset from mouse haematopoietic stem cells (HSCs). Our approach ensures assignment consistency by design and achieves improved accuracy in branching time inference and assignment accuracy",
    "checked": true,
    "id": "d1d330bf943ce3fe103970e755064de18398e0a8",
    "semantic_title": "modelling sequential branching dynamics with a multivariate branching gaussian process",
    "citation_count": 0,
    "authors": [
      "Elvijs Sarkans",
      "Sumon Ahmed",
      "Magnus Rattray",
      "Alexis Boukouvalas"
    ]
  },
  "https://openreview.net/forum?id=j3oQF9coJd": {
    "title": "U-NO: U-shaped Neural Operators",
    "volume": "main",
    "abstract": "Neural operators generalize classical neural networks to maps between infinite-dimensional spaces, e.g., function spaces. Prior works on neural operators proposed a series of novel methods to learn such maps and demonstrated unprecedented success in learning solution operators of partial differential equations. Due to their close proximity to fully connected architectures, these models mainly suffer from high memory usage and are generally limited to shallow deep learning models. In this paper, we propose U-shaped Neural Operator (U-NO), a U-shaped memory enhanced architecture that allows for deeper neural operators. U-NOs exploit the problem structures in function predictions and demonstrate fast training, data efficiency, and robustness with respect to hyperparameters choices. We study the performance of U-NO on PDE benchmarks, namely, Darcy's flow law and the Navier-Stokes equations. We show that U-NO results in an average of 26% and 44% prediction improvement on Darcy's flow and turbulent Navier-Stokes equations, respectively, over the state of the art. On Navier-Stokes 3D spatiotemporal operator learning task, we show U-NO provides 37% improvement over the state of art methods",
    "checked": true,
    "id": "d7ec7ddcbba6a702991a5c66c7c36c168e384dfc",
    "semantic_title": "u-no: u-shaped neural operators",
    "citation_count": 155,
    "authors": [
      "Md Ashiqur Rahman",
      "Zachary E Ross",
      "Kamyar Azizzadenesheli"
    ]
  },
  "https://openreview.net/forum?id=nOk4XEB7Ke": {
    "title": "Fast&Fair: Training Acceleration and Bias Mitigation for GNNs",
    "volume": "main",
    "abstract": "Graph neural networks (GNNs) have been demonstrated to achieve state-of-the-art performance for a number of graph-based learning tasks, which leads to a rise in their employment in various domains. However, it has been shown that GNNs may inherit and even amplify bias within training data, which leads to unfair results towards certain sensitive groups. Meanwhile, training of GNNs introduces additional challenges, such as slow convergence and possible instability. Faced with these limitations, this work proposes FairNorm, a unified normalization-based framework that reduces the bias in GNN-based learning while also providing provably faster convergence. Specifically, FairNorm presents individual normalization operators over different sensitive groups and introduces fairness regularizers on the learnable parameters of normalization layers to reduce the bias in GNNs. The design of the proposed regularizers is built upon analyses that illuminate the sources of bias in graph-based learning. Experiments on node classification over real-world networks demonstrate the efficiency of the proposed scheme in improving fairness in terms of statistical parity and equal opportunity compared to fairness-aware baselines. In addition, it is empirically shown that the proposed framework leads to faster convergence compared to the naive baseline where no normalization is employed",
    "checked": true,
    "id": "59a3e8b8586e497c39e227a7c4399d87314f90f1",
    "semantic_title": "fast&fair: training acceleration and bias mitigation for gnns",
    "citation_count": 9,
    "authors": [
      "Oyku Deniz Kose",
      "Yanning Shen"
    ]
  },
  "https://openreview.net/forum?id=IqJsyulDUX": {
    "title": "Ensembles for Uncertainty Estimation: Benefits of Prior Functions and Bootstrapping",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f030e634f1b20b23f5d6ea5bf4472426244d66d5",
    "semantic_title": "ensembles for uncertainty estimation: benefits of prior functions and bootstrapping",
    "citation_count": 20,
    "authors": [
      "Vikranth Dwaracherla",
      "Zheng Wen",
      "Ian Osband",
      "Xiuyuan Lu",
      "Seyed Mohammad Asghari",
      "Benjamin Van Roy"
    ]
  },
  "https://openreview.net/forum?id=W98rebBxlQ": {
    "title": "Soft Diffusion: Score Matching with General Corruptions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "aecbe351822b77cb36d22e8a43b4fe2bda6ab998",
    "semantic_title": "soft diffusion: score matching with general corruptions",
    "citation_count": 5,
    "authors": [
      "Giannis Daras",
      "Mauricio Delbracio",
      "Hossein Talebi",
      "Alex Dimakis",
      "Peyman Milanfar"
    ]
  },
  "https://openreview.net/forum?id=mySiFHCeAl": {
    "title": "Spectral Regularization Allows Data-frugal Learning over Combinatorial Spaces",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a902afd1e45a9409c3b6209fe2f634232cd7cf11",
    "semantic_title": "spectral regularization allows data-frugal learning over combinatorial spaces",
    "citation_count": 2,
    "authors": [
      "Amirali Aghazadeh",
      "Nived Rajaraman",
      "Tony Tu",
      "Kannan Ramchandran"
    ]
  },
  "https://openreview.net/forum?id=jVMMdg31De": {
    "title": "A Cubic Regularization Approach for Finding Local Minimax Points in Nonconvex Minimax Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "010ccf4ee5abc99cbba51ae62deeb458e35d7ad1",
    "semantic_title": "a cubic regularization approach for finding local minimax points in nonconvex minimax optimization",
    "citation_count": 7,
    "authors": [
      "Ziyi Chen",
      "Zhengyang Hu",
      "Qunwei Li",
      "Zhe Wang",
      "Yi Zhou"
    ]
  },
  "https://openreview.net/forum?id=SEDWlhcFWA": {
    "title": "Assisted Learning for Organizations with Limited Imbalanced Data",
    "volume": "main",
    "abstract": "In the era of big data, many big organizations are integrating machine learning into their work pipelines to facilitate data analysis. However, the performance of their trained models is often restricted by limited and imbalanced data available to them. In this work, we develop an assisted learning framework for assisting organizations to improve their learning performance. The organizations have sufficient computation resources but are subject to stringent data-sharing and collaboration policies. Their limited imbalanced data often cause biased inference and sub-optimal decision-making. In assisted learning, an organizational learner purchases assistance service from an external service provider and aims to enhance its model performance within only a few assistance rounds. We develop effective stochastic training algorithms for both assisted deep learning and assisted reinforcement learning. Different from existing distributed algorithms that need to frequently transmit gradients or models, our framework allows the learner to only occasionally share information with the service provider, but still obtain a model that achieves near-oracle performance as if all the data were centralized",
    "checked": true,
    "id": "f823a18b300f8029075089f6b617aa53b6ab113f",
    "semantic_title": "assisted learning for organizations with limited imbalanced data",
    "citation_count": 3,
    "authors": [
      "Cheng Chen",
      "Jiaying Zhou",
      "Jie Ding",
      "Yi Zhou"
    ]
  },
  "https://openreview.net/forum?id=EPPqt3uERT": {
    "title": "Transformer for Partial Differential Equations' Operator Learning",
    "volume": "main",
    "abstract": "Data-driven learning of partial differential equations' solution operators has recently emerged as a promising paradigm for approximating the underlying solutions. The solution operators are usually parameterized by deep learning models that are built upon problem-specific inductive biases. An example is a convolutional or a graph neural network that exploits the local grid structure where functions' values are sampled. The attention mechanism, on the other hand, provides a flexible way to implicitly exploit the patterns within inputs, and furthermore, relationship between arbitrary query locations and inputs. In this work, we present an attention-based framework for data-driven operator learning, which we term Operator Transformer (OFormer). Our framework is built upon self-attention, cross-attention, and a set of point-wise multilayer perceptrons (MLPs), and thus it makes few assumptions on the sampling pattern of the input function or query locations. We show that the proposed framework is competitive on standard PDE benchmark problems and can flexibly be adapted to different types of grids",
    "checked": true,
    "id": "179070d3d43e97d1ce4d12127a3dc63581328809",
    "semantic_title": "transformer for partial differential equations' operator learning",
    "citation_count": 182,
    "authors": [
      "Zijie Li",
      "Kazem Meidani",
      "Amir Barati Farimani"
    ]
  },
  "https://openreview.net/forum?id=gvcDSDYUZx": {
    "title": "Efficient Model-Based Multi-Agent Mean-Field Reinforcement Learning",
    "volume": "main",
    "abstract": "Learning in multi-agent systems is highly challenging due to several factors including the non-stationarity introduced by agents' interactions and the combinatorial nature of their state and action spaces. In particular, we consider the Mean-Field Control (MFC) problem which assumes an asymptotically infinite population of identical agents that aim to collaboratively maximize the collective reward. In many cases, solutions of an MFC problem are good approximations for large systems, hence, efficient learning for MFC is valuable for the analogous discrete agent setting with many agents. Specifically, we focus on the case of unknown system dynamics where the goal is to simultaneously optimize for the rewards and learn from experience. We propose an efficient model-based reinforcement learning algorithm, $\\text{M}^3$--UCRL, that runs in episodes, balances between exploration and exploitation during policy learning, and provably solves this problem. Our main theoretical contributions are the first general regret bounds for model-based reinforcement learning for MFC, obtained via a novel mean-field type analysis. To learn the system's dynamics, $\\text{M}^3$--UCRL can be instantiated with various statistical models, e.g., neural networks or Gaussian Processes. Moreover, we provide a practical parametrization of the core optimization problem that facilitates gradient-based optimization techniques when combined with differentiable dynamics approximation methods such as neural networks",
    "checked": true,
    "id": "88b80affbaeacc42da08831a86a874d825f28555",
    "semantic_title": "efficient model-based multi-agent mean-field reinforcement learning",
    "citation_count": 42,
    "authors": [
      "Barna Pásztor",
      "Andreas Krause",
      "Ilija Bogunovic"
    ]
  },
  "https://openreview.net/forum?id=y4CGF1A8VG": {
    "title": "Machine Explanations and Human Understanding",
    "volume": "main",
    "abstract": "Explanations are hypothesized to improve human understanding of machine learning models and achieve a variety of desirable outcomes, ranging from model debugging to enhancing human decision making. However, empirical studies have found mixed and even negative results. An open question, therefore, is under what conditions explanations can improve human understanding and in what way. To address this question, we first identify three core concepts that cover most existing quantitative measures of understanding: task decision boundary, model decision boundary, and model error. Using adapted causal diagrams, we provide a formal characterization of the relationship between these concepts and human approximations (i.e., understanding) of them. The relationship varies by the level of human intuition in different task types, such as emulation and discovery, which are often ignored when building or evaluating explanation methods. Our key result is that human intuitions are necessary for generating and evaluating machine explanations in human-AI decision making: without assumptions about human intuitions, explanations may improve human understanding of model decision boundary, but cannot improve human understanding of task decision boundary or model error. To validate our theoretical claims, we conduct human subject studies to show the importance of human intuitions. Together with our theoretical contributions, we provide a new paradigm for designing behavioral studies towards a rigorous view of the role of machine explanations across different tasks of human-AI decision making",
    "checked": true,
    "id": "101309da0732648e72929a5327341d325fca57fa",
    "semantic_title": "machine explanations and human understanding",
    "citation_count": 30,
    "authors": [
      "Chacha Chen",
      "Shi Feng",
      "Amit Sharma",
      "Chenhao Tan"
    ]
  },
  "https://openreview.net/forum?id=9aXKUJEKwV": {
    "title": "Learning to Look by Self-Prediction",
    "volume": "main",
    "abstract": "We present a method for learning active vision skills, to move the camera to observe a robot's sensors from informative points of view, without external rewards or labels. We do this by jointly training a visual predictor network, which predicts future returns of the sensors using pixels, and a camera control agent, which we reward using the negative error of the predictor. The agent thus moves the camera to points of view that are most predictive for a chosen sensor, which we select using a conditioning input to the agent. We observe that despite this noisy learned reward function, the learned policies a exhibit competence by reliably framing the sensor in a specific location in the view, an emergent location which we call a behavioral fovea. We find that replacing the conventional camera with a foveal camera further increases the policies' precision",
    "checked": true,
    "id": "496349bd33b2793f66b151eda9266e856bc1e9ab",
    "semantic_title": "learning to look by self-prediction",
    "citation_count": 7,
    "authors": [
      "Matthew Koichi Grimes",
      "Joseph Varughese Modayil",
      "Piotr W Mirowski",
      "Dushyant Rao",
      "Raia Hadsell"
    ]
  },
  "https://openreview.net/forum?id=slsAQHpS7n": {
    "title": "Computationally-efficient initialisation of GPs: The generalised variogram method",
    "volume": "main",
    "abstract": "We present a computationally-efficient strategy to initialise the hyperparameters of a Gaussian process (GP) avoiding the computation of the likelihood function. Our strategy can be used as a pretraining stage to find initial conditions for maximum-likelihood (ML) training, or as a standalone method to compute hyperparameters values to be plugged in directly into the GP model. Motivated by the fact that training a GP via ML is equivalent (on average) to minimising the KL-divergence between the true and learnt model, we set to explore different metrics/divergences among GPs that are computationally inexpensive and provide hyperparameter values that are close to those found via ML. In practice, we identify the GP hyperparameters by projecting the empirical covariance or (Fourier) power spectrum onto a parametric family, thus proposing and studying various measures of discrepancy operating on the temporal and frequency domains. Our contribution extends the variogram method developed by the geostatistics literature and, accordingly, it is referred to as the generalised variogram method (GVM). In addition to the theoretical presentation of GVM, we provide experimental validation in terms of accuracy, consistency with ML and computational complexity for different kernels using synthetic and real-world data",
    "checked": true,
    "id": "1047c86bdd1a18ea12b2191afece931e6b15cf77",
    "semantic_title": "computationally-efficient initialisation of gps: the generalised variogram method",
    "citation_count": 0,
    "authors": [
      "Felipe Tobar",
      "Elsa Cazelles",
      "Taco de Wolff"
    ]
  },
  "https://openreview.net/forum?id=f4VyYhkRvi": {
    "title": "Fairness via In-Processing in the Over-parameterized Regime: A Cautionary Tale with MinDiff Loss",
    "volume": "main",
    "abstract": "Prior work has observed that the test error of state-of-the-art deep neural networks often continues to decrease with increasing over-parameterization, a phenomenon referred to as double descent. This allows deep learning engineers to instantiate large models without having to worry about over-fitting. Despite its benefits, however, prior work has shown that over-parameterization can exacerbate bias against minority subgroups. Several fairness-constrained DNN training methods have been proposed to address this concern. Here, we critically examine MinDiff, a fairness-constrained training procedure implemented within TensorFlow's Responsible AI Toolkit, that aims to achieve Equality of Opportunity. We show that although MinDiff improves fairness for under-parameterized models, it is likely to be ineffective in the over-parameterized regime. This is because an overfit model with zero training loss is trivially group-wise fair on training data, creating an \"illusion of fairness,\" thus turning off the MinDiff optimization (this will apply to any disparity-based measures which care about errors or accuracy; while it won't apply to demographic parity). We find that within specified fairness constraints, under-parameterized MinDiff models can even have lower error compared to their over-parameterized counterparts (despite baseline over-parameterized models having lower error compared to their under-parameterized counterparts). We further show that MinDiff optimization is very sensitive to choice of batch size in the under-parameterized regime. Thus, fair model training using MinDiff requires time-consuming hyper-parameter searches. Finally, we suggest using previously proposed regularization techniques, viz. L2, early stopping and flooding in conjunction with MinDiff to train fair over-parameterized models. In our results, over-parameterized models trained using MinDiff+regularization with standard batch sizes are fairer than their under-parameterized counterparts, suggesting that at the very least, regularizers should be integrated into fair deep learning flows, like MinDiff",
    "checked": false,
    "id": "20fcf4d635036d16db881c503c1fcaf52695188b",
    "semantic_title": "fairness via in-processing in the over-parameterized regime: a cautionary tale",
    "citation_count": 7,
    "authors": [
      "Akshaj Kumar Veldanda",
      "Ivan Brugere",
      "Jiahao Chen",
      "Sanghamitra Dutta",
      "Alan Mishler",
      "Siddharth Garg"
    ]
  },
  "https://openreview.net/forum?id=Oq5XKRVYpQ": {
    "title": "Graph-based Multi-ODE Neural Networks for Spatio-Temporal Traffic Forecasting",
    "volume": "main",
    "abstract": "There is a recent surge in the development of spatio-temporal forecasting models in the transportation domain. Long-range traffic forecasting, however, remains a challenging task due to the intricate and extensive spatio-temporal correlations observed in traffic networks. Current works primarily rely on road networks with graph structures and learn representations using graph neural networks (GNNs), but this approach suffers from over-smoothing problem in deep architectures. To tackle this problem, recent methods introduced the combination of GNNs with residual connections or neural ordinary differential equations (ODE). However, current graph ODE models face two key limitations in feature extraction: (1) they lean towards global temporal patterns, overlooking local patterns that are important for unexpected events; and (2) they lack dynamic semantic edges in their architectural design. In this paper, we propose a novel architecture called Graph-based Multi-ODE Neural Networks (GRAM-ODE) which is designed with multiple connective ODE-GNN modules to learn better representations by capturing different views of complex local and global dynamic spatio-temporal dependencies. We also add some techniques like shared weights and divergence constraints into the intermediate layers of distinct ODE-GNN modules to further improve their communication towards the forecasting task. Our extensive set of experiments conducted on six real-world datasets demonstrate the superior performance of GRAM-ODE compared with state-of-the-art baselines as well as the contribution of different components to the overall performance",
    "checked": true,
    "id": "295b40b0e734987aa6fa41d18a0673bf6eb51d03",
    "semantic_title": "graph-based multi-ode neural networks for spatio-temporal traffic forecasting",
    "citation_count": 13,
    "authors": [
      "Zibo Liu",
      "Parshin Shojaee",
      "Chandan K. Reddy"
    ]
  },
  "https://openreview.net/forum?id=iMmsCI0JsS": {
    "title": "TimeSeAD: Benchmarking Deep Multivariate Time-Series Anomaly Detection",
    "volume": "main",
    "abstract": "Developing new methods for detecting anomalies in time series is of great practical significance, but progress is hindered by the difficulty of assessing the benefit of new methods, for the following reasons. (1) Public benchmarks are flawed (e.g., due to potentially erroneous anomaly labels), (2) there is no widely accepted standard evaluation metric, and (3) evaluation protocols are mostly inconsistent. In this work, we address all three issues: (1) We critically analyze several of the most widely-used multivariate datasets, identify a number of significant issues, and select the best candidates for evaluation. (2) We introduce a new evaluation metric for time-series anomaly detection, which—in contrast to previous metrics—is recall consistent and takes temporal correlations into account. (3) We analyze and overhaul existing evaluation protocols and provide the largest benchmark of deep multivariate time-series anomaly detection methods to date. We focus on deep-learning based methods and multivariate data, a common setting in modern anomaly detection. We provide all implementations and analysis tools in a new comprehensive library for Time Series Anomaly Detection, called TimeSeAD",
    "checked": true,
    "id": "4c151732cfc97c2cdceed47728ff5ded4f2050c9",
    "semantic_title": "timesead: benchmarking deep multivariate time-series anomaly detection",
    "citation_count": 30,
    "authors": [
      "Dennis Wagner",
      "Tobias Michels",
      "Florian C.F. Schulz",
      "Arjun Nair",
      "Maja Rudolph",
      "Marius Kloft"
    ]
  },
  "https://openreview.net/forum?id=I4IkGmgFJz": {
    "title": "Data Models for Dataset Drift Controls in Machine Learning With Optical Images",
    "volume": "main",
    "abstract": "Camera images are ubiquitous in machine learning research. They also play a central role in the delivery of important public services spanning medicine or environmental surveying. However, the application of machine learning models in these domains has been limited because of robustness concerns. A primary failure mode are performance drops due to differences between the training and deployment data. While there are methods to prospectively validate the robustness of machine learning models to such dataset drifts, existing approaches do not account for explicit models of machine learning's primary object of interest: the data. This limits our ability to study and understand the relationship between data generation and downstream machine learning model performance in a physically accurate manner. In this study, we demonstrate how to overcome this limitation by pairing traditional machine learning with physical optics to obtain explicit and differentiable data models. We demonstrate how such data models can be constructed for image data and used to control downstream machine learning model performance related to dataset drift. The findings are distilled into three applications. First, drift synthesis enables the controlled generation of physically faithful drift test cases to power model selection and targeted generalization. Second, the gradient connection between machine learning task model and data model allows advanced, precise tolerancing of task model sensitivity to changes in the data generation. These drift forensics can be used to precisely specify the acceptable data environments in which a task model may be run. Third, drift optimization opens up the possibility to create drifts that can help the task model learn better faster, effectively optimizing the data generating process itself to support the downstream machine vision task. This is an interesting upgrade to existing imaging pipelines which traditionally have been optimized to be consumed by human users but not machine learning models. Alongside the data model code we release two datasets to the public that we collected as part of this work. In total, the two datasets, Raw-Microscopy and Raw-Drone, comprise 1,488 scientifically calibrated reference raw sensor measurements, 8,928 raw intensity variations as well as 17,856 images processed through twelve data models with different configurations. A guide to access the open code and datasets is available at https://github.com/aiaudit-org/raw2logit",
    "checked": true,
    "id": "74009c57ded629bf5cae2021805fbdd0f693f331",
    "semantic_title": "data models for dataset drift controls in machine learning with optical images",
    "citation_count": 6,
    "authors": [
      "Luis Oala",
      "Marco Aversa",
      "Gabriel Nobis",
      "Kurt Willis",
      "Yoan Neuenschwander",
      "Michèle Buck",
      "Christian Matek",
      "Jerome Extermann",
      "Enrico Pomarico",
      "Wojciech Samek",
      "Roderick Murray-Smith",
      "Christoph Clausen",
      "Bruno Sanguinetti"
    ]
  },
  "https://openreview.net/forum?id=1nhTDzxxMA": {
    "title": "Multi-Source Transfer Learning for Deep Model-Based Reinforcement Learning",
    "volume": "main",
    "abstract": "A crucial challenge in reinforcement learning is to reduce the number of interactions with the environment that an agent requires to master a given task. Transfer learning proposes to address this issue by re-using knowledge from previously learned tasks. However, determining which source task qualifies as the most appropriate for knowledge extraction, as well as the choice regarding which algorithm components to transfer, represent severe obstacles to its application in reinforcement learning. The goal of this paper is to address these issues with modular multi-source transfer learning techniques. The proposed techniques automatically learn how to extract useful information from source tasks, regardless of the difference in state-action space and reward function. We support our claims with extensive and challenging cross-domain experiments for visual control",
    "checked": true,
    "id": "3ca47f259959f099608b074bb29256e69c1dba31",
    "semantic_title": "multi-source transfer learning for deep model-based reinforcement learning",
    "citation_count": 10,
    "authors": [
      "Remo Sasso",
      "Matthia Sabatelli",
      "Marco A. Wiering"
    ]
  },
  "https://openreview.net/forum?id=YwNrPLjHSL": {
    "title": "Do Vision-Language Pretrained Models Learn Composable Primitive Concepts?",
    "volume": "main",
    "abstract": "Vision-language (VL) pretrained models have achieved impressive performance on multimodal reasoning and zero-shot recognition tasks. Many of these VL models are pretrained on unlabeled image and caption pairs from the internet. In this paper, we study whether representations of primitive concepts–such as colors, shapes, or the attributes of object parts–emerge automatically within these pretrained VL models. We propose a two-step framework, Compositional Concept Mapping (CompMap), to investigate this. CompMap first asks a VL model to generate concept activations with text prompts from a predefined list of primitive concepts, and then learns to construct an explicit composition model that maps the primitive concept activations (e.g. the likelihood of black tail or red wing) to com- posite concepts (e.g. a red-winged blackbird). We demonstrate that a composition model can be designed as a set operation, and show that a composition model is straightforward for machines to learn from ground truth primitive concepts (as a linear classifier). We thus hypothesize that if primitive concepts indeed emerge in a VL pretrained model, its primitive concept activations can be used to learn a composition model similar to the one designed by experts. We propose a quantitative metric to measure the degree of similarity, and refer to the metric as the interpretability of the VL models' learned primitive concept representations. We also measure the classification accuracy when using the primitive concept activations and the learned composition model to predict the composite concepts, and refer to it as the usefulness metric. Our study reveals that state-of-the-art VL pretrained models learn primitive concepts that are highly useful for fine-grained visual recognition on the CUB dataset, and compositional generalization tasks on the MIT-States dataset. However, we observe that the learned composition models have low interpretability in our qualitative analyses. Our results reveal the limitations of existing VL models, and the necessity of pretraining objectives that encourage the acquisition of primitive concepts",
    "checked": true,
    "id": "222c1b5c2e883ea877c0b8f789585b1bb51f235e",
    "semantic_title": "do vision-language pretrained models learn composable primitive concepts?",
    "citation_count": 28,
    "authors": [
      "Tian Yun",
      "Usha Bhalla",
      "Ellie Pavlick",
      "Chen Sun"
    ]
  },
  "https://openreview.net/forum?id=KSvr8A62MD": {
    "title": "A Simulation Environment and Reinforcement Learning Method for Waste Reduction",
    "volume": "main",
    "abstract": "In retail (e.g., grocery stores, apparel shops, online retailers), inventory managers have to balance short-term risk (no items to sell) with long-term-risk (over ordering leading to product waste). This balancing task is made especially hard due to the lack of information about future customer purchases. In this paper, we study the problem of restocking a grocery store's inventory with perishable items over time, from a distributional point of view. The objective is to maximize sales while minimizing waste, with uncertainty about the actual consumption by costumers. This problem is of a high relevance today, given the growing demand for food and the impact of food waste on the environment, the economy, and purchasing power. We frame inventory restocking as a new reinforcement learning task that exhibits stochastic behavior conditioned on the agent's actions, making the environment partially observable. We make two main contributions. First, we introduce a new reinforcement learning environment, RetaiL, based on real grocery store data and expert knowledge. This environment is highly stochastic, and presents a unique challenge for reinforcement learning practitioners. We show that uncertainty about the future behavior of the environment is not handled well by classical supply chain algorithms, and that distributional approaches are a good way to account for the uncertainty. Second, we introduce GTDQN, a distributional reinforcement learning algorithm that learns a generalized lambda distribution over the reward space. GTDQN provides a strong baseline for our environment. It outperforms other distributional reinforcement learning approaches in this partially observable setting, in both overall reward and generated waste",
    "checked": true,
    "id": "a6f9ad0139c17555afb36c1a205a621da8068127",
    "semantic_title": "a simulation environment and reinforcement learning method for waste reduction",
    "citation_count": 4,
    "authors": [
      "Sami Jullien",
      "Mozhdeh Ariannezhad",
      "Paul Groth",
      "Maarten de Rijke"
    ]
  },
  "https://openreview.net/forum?id=JkIH4MeOc3": {
    "title": "Group Fairness in Reinforcement Learning",
    "volume": "main",
    "abstract": "We pose and study the problem of satisfying fairness in the online Reinforcement Learning (RL) setting. We focus on the group notions of fairness, according to which agents belonging to different groups should have similar performance based on some given measure. We consider the setting of maximizing return in an unknown environment (unknown transition and reward function) and show that it is possible to have RL algorithms that learn the best fair policies without violating the fairness requirements at any point in time during the learning process. In the tabular finite-horizon episodic setting, we provide an algorithm that combines the principle of optimism and pessimism under uncertainty to achieve zero fairness violation with arbitrarily high probability while also maintaining sub-linear regret guarantees. For the high-dimensional Deep-RL setting, we present algorithms based on the performance-difference style approximate policy improvement update step and we report encouraging empirical results on various traditional RL-inspired benchmarks showing that our algorithms display the desired behavior of learning the optimal policy while performing a fair learning process",
    "checked": true,
    "id": "29bcebb46f4fbc3ae1eb6069bbfee9dc8cb5f2eb",
    "semantic_title": "group fairness in reinforcement learning",
    "citation_count": 4,
    "authors": [
      "Harsh Satija",
      "Alessandro Lazaric",
      "Matteo Pirotta",
      "Joelle Pineau"
    ]
  },
  "https://openreview.net/forum?id=OarsigVib0": {
    "title": "On the Statistical Complexity of Estimation and Testing under Privacy Constraints",
    "volume": "main",
    "abstract": "The challenge of producing accurate statistics while respecting the privacy of the individuals in a sample is an important area of research. We study minimax lower bounds for classes of differentially private estimators. In particular, we show how to characterize the power of a statistical test under differential privacy in a plug-and-play fashion by solving an appropriate transport problem. With specific coupling constructions, this observation allows us to derive Le Cam-type and Fano-type inequalities not only for regular definitions of differential privacy but also for those based on Renyi divergence. We then proceed to illustrate our results on three simple, fully worked out examples. In particular, we show that the problem class has a huge importance on the provable degradation of utility due to privacy. In certain scenarios, we show that maintaining privacy results in a noticeable reduction in performance only when the level of privacy protection is very high. Conversely, for other problems, even a modest level of privacy protection can lead to a significant decrease in performance. Finally, we demonstrate that the DP-SGLD algorithm, a private convex solver, can be employed for maximum likelihood estimation with a high degree of confidence, as it provides near-optimal results with respect to both the size of the sample and the level of privacy protection. This algorithm is applicable to a broad range of parametric estimation procedures, including exponential families",
    "checked": true,
    "id": "0c0adac4160bafc39cfd7dd1abd24a6bc8c487fa",
    "semantic_title": "on the statistical complexity of estimation and testing under privacy constraints",
    "citation_count": 7,
    "authors": [
      "Clément Lalanne",
      "Aurélien Garivier",
      "Rémi Gribonval"
    ]
  },
  "https://openreview.net/forum?id=B4J40x7NjA": {
    "title": "Positive Difference Distribution for Image Outlier Detection using Normalizing Flows and Contrastive Data",
    "volume": "main",
    "abstract": "Detecting test data deviating from training data is a central problem for safe and robust machine learning. Likelihoods learned by a generative model, e.g., a normalizing flow via standard log-likelihood training, perform poorly as an outlier score. We propose to use an unlabelled auxiliary dataset and a probabilistic outlier score for outlier detection. We use a self-supervised feature extractor trained on the auxiliary dataset and train a normalizing flow on the extracted features by maximizing the likelihood on in-distribution data and minimizing the likelihood on the contrastive dataset. We show that this is equivalent to learning the normalized positive difference between the in-distribution and the contrastive feature density. We conduct experiments on benchmark datasets and compare to the likelihood, the likelihood ratio and state-of-the-art anomaly detection methods",
    "checked": true,
    "id": "b2259c1bc23f7a03aebf4d418e75498a15966dcc",
    "semantic_title": "positive difference distribution for image outlier detection using normalizing flows and contrastive data",
    "citation_count": 5,
    "authors": [
      "Robert Schmier",
      "Ullrich Koethe",
      "Christoph-Nikolas Straehle"
    ]
  },
  "https://openreview.net/forum?id=s9efQF3QW1": {
    "title": "Uncovering the Representation of Spiking Neural Networks Trained with Surrogate Gradient",
    "volume": "main",
    "abstract": "Spiking Neural Networks (SNNs) are recognized as the candidate for the next-generation neural networks due to their bio-plausibility and energy efficiency. Recently, researchers have demonstrated that SNNs are able to achieve nearly state-of-the-art performance in image recognition tasks using surrogate gradient training. However, some essential questions exist pertaining to SNNs that are little studied: Do SNNs trained with surrogate gradient learn different representations from traditional Artificial Neural Networks (ANNs)? Does the time dimension in SNNs provide unique representation power? In this paper, we aim to answer these questions by conducting a representation similarity analysis between SNNs and ANNs using Centered Kernel Alignment (CKA). We start by analyzing the spatial dimension of the networks, including both the width and the depth. Furthermore, our analysis of residual connections shows that SNNs learn a periodic pattern, which rectifies the representations in SNNs to be ANN-like. We additionally investigate the effect of the time dimension on SNN representation, finding that deeper layers encourage more dynamics along the time dimension. We also investigate the impact of input data such as event-stream data and adversarial attacks. Our work uncovers a host of new findings of representations in SNNs. We hope this work will inspire future research to fully comprehend the representation power of SNNs. Code is released at https://github.com/Intelligent-Computing-Lab-Yale/SNNCKA",
    "checked": true,
    "id": "75759d9eb0f9cfc4d7adaea33986611a084857e1",
    "semantic_title": "uncovering the representation of spiking neural networks trained with surrogate gradient",
    "citation_count": 16,
    "authors": [
      "Yuhang Li",
      "Youngeun Kim",
      "Hyoungseob Park",
      "Priyadarshini Panda"
    ]
  },
  "https://openreview.net/forum?id=qxrwt6F3sf": {
    "title": "PAC-Bayes Generalisation Bounds for Heavy-Tailed Losses through Supermartingales",
    "volume": "main",
    "abstract": "While PAC-Bayes is now an established learning framework for light-tailed losses (\\emph{e.g.}, subgaussian or subexponential), its extension to the case of heavy-tailed losses remains largely uncharted and has attracted a growing interest in recent years. We contribute PAC-Bayes generalisation bounds for heavy-tailed losses under the sole assumption of bounded variance of the loss function. Under that assumption, we extend previous results from \\citet{kuzborskij2019efron}. Our key technical contribution is exploiting an extention of Markov's inequality for supermartingales. Our proof technique unifies and extends different PAC-Bayesian frameworks by providing bounds for unbounded martingales as well as bounds for batch and online learning with heavy-tailed losses",
    "checked": true,
    "id": "97bc9a20d4020fa60741f579998b599db079b948",
    "semantic_title": "pac-bayes generalisation bounds for heavy-tailed losses through supermartingales",
    "citation_count": 22,
    "authors": [
      "Maxime Haddouche",
      "Benjamin Guedj"
    ]
  },
  "https://openreview.net/forum?id=Sb6p5mcefw": {
    "title": "Generalization as Dynamical Robustness--The Role of Riemannian Contraction in Supervised Learning",
    "volume": "main",
    "abstract": "A key property of successful learning algorithms is generalization. In classical supervised learning, generalization can be achieved by ensuring that the empirical error converges to the expected error as the number of training samples goes to infinity. Within this classical setting, we analyze the generalization properties of iterative optimizers such as stochastic gradient descent and natural gradient flow through the lens of dynamical systems and control theory. Specifically, we use contraction analysis to show that generalization and dynamical robustness are intimately related through the notion of algorithmic stability. In particular, we prove that Riemannian contraction in a supervised learning setting implies generalization. We show that if a learning algorithm is contracting in some Riemannian metric with rate $\\lambda > 0$, it is uniformly algorithmically stable with rate $\\mathcal{O}(1/\\lambda n)$, where $n$ is the number of examples in the training set. The results hold for stochastic and deterministic optimization, in both continuous and discrete-time, for convex and non-convex loss surfaces. The associated generalization bounds reduce to well-known results in the particular case of gradient descent over convex or strongly convex loss surfaces. They can be shown to be optimal in certain linear settings, such as kernel ridge regression under gradient flow. Finally, we demonstrate that the well-known Polyak-Lojasiewicz condition is intimately related to the contraction of a model's outputs as they evolve under gradient descent. This correspondence allows us to derive uniform algorithmic stability bounds for nonlinear function classes such as wide neural networks",
    "checked": false,
    "id": "82ee2f8b7aa0a48e1052d4b36baeef899e6b3e6c",
    "semantic_title": "generalization as dynamical robustness-the role of riemannian contraction in supervised learning",
    "citation_count": 10,
    "authors": [
      "Leo Kozachkov",
      "Patrick Wensing",
      "Jean-Jacques Slotine"
    ]
  },
  "https://openreview.net/forum?id=Hnr23knZfY": {
    "title": "POLTER: Policy Trajectory Ensemble Regularization for Unsupervised Reinforcement Learning",
    "volume": "main",
    "abstract": "The goal of Unsupervised Reinforcement Learning (URL) is to find a reward-agnostic prior policy on a task domain, such that the sample-efficiency on supervised downstream tasks is improved. Although agents initialized with such a prior policy can achieve a significantly higher reward with fewer samples when finetuned on the downstream task, it is still an open question how an optimal pretrained prior policy can be achieved in practice. In this work, we present POLTER (Policy Trajectory Ensemble Regularization) – a general method to regularize the pretraining that can be applied to any URL algorithm and is especially useful on data- and knowledge-based URL algorithms. It utilizes an ensemble of policies that are discovered during pretraining and moves the policy of the URL algorithm closer to its optimal prior. Our method is based on a theoretical framework, and we analyze its practical effects on a white-box benchmark, allowing us to study POLTER with full control. In our main experiments, we evaluate POLTER on the Unsupervised Reinforcement Learning Benchmark (URLB), which consists of 12 tasks in 3 domains. We demonstrate the generality of our approach by improving the performance of a diverse set of data- and knowledge-based URL algorithms by 19% on average and up to 40% in the best case. Under a fair comparison with tuned baselines and tuned POLTER, we establish a new state-of-the-art for model-free methods on the URLB",
    "checked": true,
    "id": "c18bed90f9781e0750ffc634143015919886725b",
    "semantic_title": "polter: policy trajectory ensemble regularization for unsupervised reinforcement learning",
    "citation_count": 5,
    "authors": [
      "Frederik Schubert",
      "Carolin Benjamins",
      "Sebastian Döhler",
      "Bodo Rosenhahn",
      "Marius Lindauer"
    ]
  },
  "https://openreview.net/forum?id=8WUyeeMxMH": {
    "title": "Proximal Curriculum for Reinforcement Learning Agents",
    "volume": "main",
    "abstract": "We consider the problem of curriculum design for reinforcement learning (RL) agents in contextual multi-task settings. Existing techniques on automatic curriculum design typically require domain-specific hyperparameter tuning or have limited theoretical underpinnings. To tackle these limitations, we design our curriculum strategy, ProCuRL, inspired by the pedagogical concept of Zone of Proximal Development (ZPD). ProCuRL captures the intuition that learning progress is maximized when picking tasks that are neither too hard nor too easy for the learner. We mathematically derive ProCuRL by analyzing two simple learning settings. We also present a practical variant of ProCuRL that can be directly integrated with deep RL frameworks with minimal hyperparameter tuning. Experimental results on a variety of domains demonstrate the effectiveness of our curriculum strategy over state-of-the-art baselines in accelerating the training process of deep RL agents",
    "checked": true,
    "id": "8f160848f3c296a8c106512fb6f534bbeea5dd5b",
    "semantic_title": "proximal curriculum for reinforcement learning agents",
    "citation_count": 11,
    "authors": [
      "Georgios Tzannetos",
      "Bárbara Gomes Ribeiro",
      "Parameswaran Kamalaruban",
      "Adish Singla"
    ]
  },
  "https://openreview.net/forum?id=R6W7zkMz0P": {
    "title": "Pre-trained Perceptual Features Improve Differentially Private Image Generation",
    "volume": "main",
    "abstract": "Training even moderately-sized generative models with differentially-private stochastic gradient descent (DP-SGD) is difficult: the required level of noise for reasonable levels of privacy is simply too large. We advocate instead building off a good, relevant representation on an informative public dataset, then learning to model the private data with that representation. In particular, we minimize the maximum mean discrepancy (MMD) between private target data and a generator's distribution, using a kernel based on perceptual features learned from a public dataset. With the MMD, we can simply privatize the data-dependent term once and for all, rather than introducing noise at each step of optimization as in DP-SGD. Our algorithm allows us to generate CIFAR10-level images with $\\epsilon \\approx 2$ which capture distinctive features in the distribution, far surpassing the current state of the art, which mostly focuses on datasets such as MNIST and FashionMNIST at a large $\\epsilon \\approx 10$. Our work introduces simple yet powerful foundations for reducing the gap between private and non-private deep generative models. Our code is available at https://github.com/ParkLabML/DP-MEPF",
    "checked": true,
    "id": "013542bd961c21cfd581e96cf642ddeff9935c26",
    "semantic_title": "pre-trained perceptual features improve differentially private image generation",
    "citation_count": 30,
    "authors": [
      "Frederik Harder",
      "Milad Jalali",
      "Danica J. Sutherland",
      "Mijung Park"
    ]
  },
  "https://openreview.net/forum?id=SM1BkjGePI": {
    "title": "Bridging performance gap between minimal and maximal SVM models",
    "volume": "main",
    "abstract": "Multi-class support vector machine (SVM) models are typically built using all possible pairs of binary SVM in a one-against-one fashion. This requires too much computation for datasets with hundreds or thousands of classes, which motivates the search for multi-class models that do not use all pairwise SVM. Our models correspond to the choice of the model graph, whose vertices correspond to classes and edges represent which pairwise SVMs are trained. We conduct experiments to uncover metrical and topological properties that impact the accuracy of a multi-class SVM model. Based on their results we propose a way to construct intermediate multi-class SVM models. The key insight is that for model graphs of diameter two, we can estimate missing pairwise probabilities from the known ones thus transforming the computation of posteriors to the usual complete (maximal) case. Our proposed algorithm allows one to reduce computational effort by 50-80% while keeping accuracy near, or even above that of a softmax classifier. In our work we use convolutional data sets, which have multiple advantages for benchmarking multi-class SVM models",
    "checked": true,
    "id": "816269bcf6908a5243302b0eb8d67b31c0f1bfbe",
    "semantic_title": "bridging performance gap between minimal and maximal svm models",
    "citation_count": 0,
    "authors": [
      "Ondrej Such",
      "René Fabricius"
    ]
  },
  "https://openreview.net/forum?id=YJDqQSAuB6": {
    "title": "Weisfeiler and Leman Go Infinite: Spectral and Combinatorial Pre-Colorings",
    "volume": "main",
    "abstract": "The limit in the expressivity of Message Passing Graph Neural Networks (MPGNNs) has recently led to the development of end-to-end learning GNN architectures. These advanced GNNs usually generalize existing notions in the GNN architecture or suggest new ones that break the limit of the existing, relatively simple MPGNNs. In this paper, we focus on a different solution, the two-phase approach (or pre-coloring), which enables to use of the same simple MPGNNs while improving their expressivity. We prove that using pre-colorings could strictly increase the expressivity of MPGNNs ad infinitum. We also suggest new pre-coloring based on the spectral decomposition of the graph Laplacian and prove that it strictly improves the expressivity of standard MPGNNs. An extensive evaluation of the proposed method with different MPGNN models on various graph classification and node property prediction datasets consistently outperforms previous pre-coloring strategies. The code to reproduce our experiments is available at \\url{https://github.com/TPFI22/Spectral-and-Combinatorial}",
    "checked": true,
    "id": "211af952734e053c01cae09f8f0aaca3b1564bf1",
    "semantic_title": "weisfeiler and leman go infinite: spectral and combinatorial pre-colorings",
    "citation_count": 16,
    "authors": [
      "Or Feldman",
      "Amit Boyarski",
      "Shai Feldman",
      "Dani Kogan",
      "Avi Mendelson",
      "Chaim Baskin"
    ]
  },
  "https://openreview.net/forum?id=2Yo9xqR6Ab": {
    "title": "Jacobian-based Causal Discovery with Nonlinear ICA",
    "volume": "main",
    "abstract": "Today's methods for uncovering causal relationships from observational data either constrain functional assignments (linearity/additive noise assumptions) or the data generating process (e.g., non-i.i.d. assumptions). Unlike previous works, which use conditional independence tests, we rely on the inference function's Jacobian to determine nonlinear cause-effect relationships. We prove that, under strong identifiability, the inference function's Jacobian captures the sparsity structure of the causal graph; thus, generalizing the classic LiNGAM method to the nonlinear case. We use nonlinear Independent Component Analysis (ICA) to infer the underlying sources from the observed variables and show how nonlinear ICA is compatible with causal discovery via non-i.i.d data. Our approach avoids the cost of exponentially many independence tests and makes our method end-to-end differentiable. We demonstrate that the proposed method can infer the causal graph on multiple synthetic data sets, and in most scenarios outperforms previous work",
    "checked": true,
    "id": "2d2976aa4b3007c84d675cfb7897703083b99136",
    "semantic_title": "jacobian-based causal discovery with nonlinear ica",
    "citation_count": 21,
    "authors": [
      "Patrik Reizinger",
      "Yash Sharma",
      "Matthias Bethge",
      "Bernhard Schölkopf",
      "Ferenc Huszár",
      "Wieland Brendel"
    ]
  },
  "https://openreview.net/forum?id=1IYJfwJtjQ": {
    "title": "FASTRAIN-GNN: Fast and Accurate Self-Training for Graph Neural Networks",
    "volume": "main",
    "abstract": "Few-shot learning with Graph Neural Networks (GNNs) is an important challenge in expanding the remarkable success that GNNs have achieved. In the transductive node classification scenario, conventional supervised training methods for GNNs fail when only few labeled nodes are available. Self-training, wherein the GNN is trained in stages by augmenting the training data with a subset of the unlabeled data and the predictions of the GNN on this data (pseudolabels), has emerged as a promising approach to few-shot transductive learning. However, multi-stage self-training significantly increases the computational demands of GNN training. In addition, while the training set evolves considerably across the stages of self-training, the GNN architecture, graph topology and training hyperparameters are kept constant, adversely affecting the accuracy of the resulting model as well as the computational efficiency of training. To address this challenge, we propose FASTRAIN-GNN, a framework for efficient and accurate self-training of GNNs with few labeled nodes. FASTRAIN-GNN performs four main optimizations in each stage of self-training: (1) Sampling-based Pseudolabel Filtering removes nodes whose pseudolabels are likely to be incorrect from the enlarged training set. (2,3) Dynamic Sizing and Dynamic Regularization find the optimal network architecture and amount of training regularization in each stage of self-training, respectively, and (4) Progressive Graph Pruning removes selected edges between nodes in the training set to reduce the impact of over-smoothing. On few-shot node classification tasks using different GNN architectures, FASTRAIN-GNN produces models that are consistently more accurate (by up to 4.4%), while also substantially reducing the self-training time (by up to 2.1X) over the current state-of-the-art methods. Code is available at https://github.com/amrnag/FASTRAIN-GNN",
    "checked": true,
    "id": "ef1e5bf8a579d6b3d4996d1cb6cd11697e8b18cc",
    "semantic_title": "fastrain-gnn: fast and accurate self-training for graph neural networks",
    "citation_count": 2,
    "authors": [
      "Amrit Nagarajan",
      "Anand Raghunathan"
    ]
  },
  "https://openreview.net/forum?id=5nVJlKgmxp": {
    "title": "Online Optimal Tracking of Linear Systems with Adversarial Disturbances",
    "volume": "main",
    "abstract": "This paper presents a memory-augmented control solution to the optimal reference tracking problem for linear systems subject to adversarial disturbances. We assume that the dynamics of the linear system are known and that the reference signal is generated by a linear system with unknown dynamics. Under these assumptions, finding the optimal tracking controller is formalized as an online convex optimization problem that leverages memory of past disturbance and reference values to capture their temporal effects on the performance. That is, a (disturbance, reference)-action control policy is formalized, which selects the control actions as a linear map of the past disturbance and reference values. The online convex optimization is then formulated over the parameters of the policy on its past disturbance and reference values to optimize general convex costs. It is shown that our approach outperforms robust control methods and achieves a tight regret bound O(√T) where in our regret analysis, we have benchmarked against the best linear policy",
    "checked": true,
    "id": "3f064ccdb4745925c3a8ba79041291db9f70c526",
    "semantic_title": "online optimal tracking of linear systems with adversarial disturbances",
    "citation_count": 2,
    "authors": [
      "Farnaz Adib Yaghmaie",
      "Hamidreza Modares"
    ]
  },
  "https://openreview.net/forum?id=T1XtOqrVKn": {
    "title": "Reducing Predictive Feature Suppression in Resource-Constrained Contrastive Image-Caption Retrieval",
    "volume": "main",
    "abstract": "To train image-caption retrieval (ICR) methods, contrastive loss functions are a common choice for optimization functions. Unfortunately, contrastive ICR methods are vulnerable to predictive feature suppression. Predictive features are features that correctly indicate the similarity between a query and a candidate item. However, in the presence of multiple predictive features during training, encoder models tend to suppress redundant predictive features, since these features are not needed to learn to discriminate between positive and negative pairs. We introduce an approach to reduce predictive feature suppression for resource-constrained ICR methods: latent target decoding (LTD). We add an additional decoder to the contrastive ICR framework, to reconstruct the input caption in a latent space of a general-purpose sentence encoder, which prevents the image and caption encoder from suppressing predictive features. We implement the LTD objective as an optimization constraint, to ensure that the reconstruction loss is below a bound value while primarily optimizing for the contrastive loss. Importantly, LTD does not depend on additional training data or expensive (hard) negative mining strategies. Our experiments show that, unlike reconstructing the input caption in the input space, LTD reduces predictive feature suppression, measured by obtaining higher recall@k, r-precision, and nDCG scores than a contrastive ICR baseline. Moreover, we show that LTD should be implemented as an optimization constraint instead of a dual optimization objective. Finally, we show that LTD can be used with different contrastive learning losses and a wide variety of resource-constrained ICR methods",
    "checked": true,
    "id": "5c8029a0b9b154e48e4b845462dc03d914123e8d",
    "semantic_title": "reducing predictive feature suppression in resource-constrained contrastive image-caption retrieval",
    "citation_count": 4,
    "authors": [
      "Maurits Bleeker",
      "Andrew Yates",
      "Maarten de Rijke"
    ]
  },
  "https://openreview.net/forum?id=fempQstMbV": {
    "title": "Deep Double Descent via Smooth Interpolation",
    "volume": "main",
    "abstract": "The ability of overparameterized deep networks to interpolate noisy data, while at the same time showing good generalization performance, has been recently characterized in terms of the double descent curve for the test error. Common intuition from polynomial regression suggests that overparameterized networks are able to sharply interpolate noisy data, without considerably deviating from the ground-truth signal, thus preserving generalization ability. At present, a precise characterization of the relationship between interpolation and generalization for deep networks is missing. In this work, we quantify sharpness of fit of the training data interpolated by neural network functions, by studying the loss landscape w.r.t. to the input variable locally to each training point, over volumes around cleanly- and noisily-labelled training samples, as we systematically increase the number of model parameters and training epochs. Our findings show that loss sharpness in the input space follows both model- and epoch-wise double descent, with worse peaks observed around noisy labels. While small interpolating models sharply fit both clean and noisy data, large interpolating models express a smooth loss landscape, where noisy targets are predicted over large volumes around training data points, in contrast to existing intuition",
    "checked": true,
    "id": "2d7485b9ccba11028f651828892b48124285a561",
    "semantic_title": "deep double descent via smooth interpolation",
    "citation_count": 11,
    "authors": [
      "Matteo Gamba",
      "Erik Englesson",
      "Mårten Björkman",
      "Hossein Azizpour"
    ]
  },
  "https://openreview.net/forum?id=4zCgjqjzAv": {
    "title": "Bayesian Transformed Gaussian Processes",
    "volume": "main",
    "abstract": "The Bayesian transformed Gaussian (BTG) model, proposed by Kedem and Oliviera in 1997, was developed as a Bayesian approach to trans-Kriging in the spatial statistics community. In this paper, we revisit BTG in the context of modern Gaussian process literature by framing it as a fully Bayesian counterpart to the Warped Gaussian process that marginalizes out a joint prior over input warping and kernel hyperparameters. As with any other fully Bayesian approach, this treatment introduces prohibitively expensive computational overhead; unsurprisingly, the BTG posterior predictive distribution, itself estimated through high-dimensional integration, must be inverted in order to perform model prediction. To address these challenges, we introduce principled numerical techniques for computing with BTG efficiently using a combination of doubly sparse quadrature rules, tight quantile bounds, and rank-one matrix algebra to enable both fast model prediction and model selection. These efficient methods allow us to compute with higher-dimensional datasets and apply BTG with layered transformations that greatly improve its expressibility. We demonstrate that BTG achieves superior empirical performance over MLE-based models in the low-data regime ---situations in which MLE tends to overfit",
    "checked": true,
    "id": "6db8d8457974645c818c70178deb8ba8e854fc9a",
    "semantic_title": "bayesian transformed gaussian processes",
    "citation_count": 1,
    "authors": [
      "Xinran Zhu",
      "Leo Huang",
      "Eric Hans Lee",
      "Cameron Alexander Ibrahim",
      "David Bindel"
    ]
  },
  "https://openreview.net/forum?id=AZ4GobeSLq": {
    "title": "A Variational Perspective on Generative Flow Networks",
    "volume": "main",
    "abstract": "Generative flow networks (GFNs) are a class of probabilistic models for sequential sampling of composite objects, proportional to a target distribution that is defined in terms of an energy function or a reward. GFNs are typically trained using a flow matching or trajectory balance objective, which matches forward and backward transition models over trajectories. In this work we introduce a variational objective for training GFNs, which is a convex combination of the reverse- and forward KL divergences, and compare it to the trajectory balance objective when sampling from the forward- and backward model, respectively. We show that, in certain settings, variational inference for GFNs is equivalent to minimizing the trajectory balance objective, in the sense that both methods compute the same score-function gradient. This insight suggests that in these settings, control variates, which are commonly used to reduce the variance of score-function gradient estimates, can also be used with the trajectory balance objective. We evaluate our findings and the performance of the proposed variational objective numerically by comparing it to the trajectory balance objective on two synthetic tasks",
    "checked": true,
    "id": "bc63bccfa8d1246fddb20f935ea9bb6ea56be4fb",
    "semantic_title": "a variational perspective on generative flow networks",
    "citation_count": 37,
    "authors": [
      "Heiko Zimmermann",
      "Fredrik Lindsten",
      "Jan-Willem van de Meent",
      "Christian A Naesseth"
    ]
  },
  "https://openreview.net/forum?id=oq3tx5kinu": {
    "title": "Active Learning of Ordinal Embeddings: A User Study on Football Data",
    "volume": "main",
    "abstract": "Humans innately measure distance between instances in an unlabeled dataset using an unknown similarity function. Distance metrics can only serve as proxy for similarity in information retrieval of similar instances. Learning a good similarity function from human annotations improves the quality of retrievals. This work uses deep metric learning to learn these user-defined similarity functions from few annotations for a large football trajectory dataset. We adapt an entropy-based active learning method with recent work from triplet mining to collect easy-to-answer but still informative annotations from human participants and use them to train a deep convolutional network that generalizes to unseen samples. Our user study shows that our approach improves the quality of the information retrieval compared to a previous deep metric learning approach that relies on a Siamese network. Specifically, we shed light on the strengths and weaknesses of passive sampling heuristics and active learners alike by analyzing the participants' response efficacy. To this end, we collect accuracy, algorithmic time complexity, the participants' fatigue and time-to-response, qualitative self-assessment and statements, as well as the effects of mixed-expertise annotators and their consistency on model performance and transfer-learning",
    "checked": true,
    "id": "33a32cfadd3564797539fd94dc50bcdc73960c69",
    "semantic_title": "active learning of ordinal embeddings: a user study on football data",
    "citation_count": 1,
    "authors": [
      "Christoffer Löffler",
      "Kion Fallah",
      "Stefano Fenu",
      "Dario Zanca",
      "Bjoern Eskofier",
      "Christopher John Rozell",
      "Christopher Mutschler"
    ]
  },
  "https://openreview.net/forum?id=55BcghgicI": {
    "title": "Differentially private partitioned variational inference",
    "volume": "main",
    "abstract": "Learning a privacy-preserving model from sensitive data which are distributed across multiple devices is an increasingly important problem. The problem is often formulated in the federated learning context, with the aim of learning a single global model while keeping the data distributed. Moreover, Bayesian learning is a popular approach for modelling, since it naturally supports reliable uncertainty estimates. However, Bayesian learning is generally intractable even with centralised non-private data and so approximation techniques such as variational inference are a necessity. Variational inference has recently been extended to the non-private federated learning setting via the partitioned variational inference algorithm. For privacy protection, the current gold standard is called differential privacy. Differential privacy guarantees privacy in a strong, mathematically clearly defined sense. In this paper, we present differentially private partitioned variational inference, the first general framework for learning a variational approximation to a Bayesian posterior distribution in the federated learning setting while minimising the number of communication rounds and providing differential privacy guarantees for data subjects. We propose three alternative implementations in the general framework, one based on perturbing local optimisation runs done by individual parties, and two based on perturbing updates to the global model (one using a version of federated averaging, the second one adding virtual parties to the protocol), and compare their properties both theoretically and empirically. We show that perturbing the local optimisation works well with simple and complex models as long as each party has enough local data. However, the privacy is always guaranteed independently by each party. In contrast, perturbing the global updates works best with relatively simple models. Given access to suitable secure primitives, such as secure aggregation or secure shuffling, the performance can be improved by all parties guaranteeing privacy jointly",
    "checked": true,
    "id": "c429c9759760b272332874316447f184ccaeaf59",
    "semantic_title": "differentially private partitioned variational inference",
    "citation_count": 2,
    "authors": [
      "Mikko A. Heikkilä",
      "Matthew Ashman",
      "Siddharth Swaroop",
      "Richard E Turner",
      "Antti Honkela"
    ]
  },
  "https://openreview.net/forum?id=a0T3nOP9sB": {
    "title": "Adaptive patch foraging in deep reinforcement learning agents",
    "volume": "main",
    "abstract": "Patch foraging is one of the most heavily studied behavioral optimization challenges in biology. However, despite its importance to biological intelligence, this behavioral optimization problem is understudied in artificial intelligence research. Patch foraging is especially amenable to study given that it has a known optimal solution, which may be difficult to discover given current techniques in deep reinforcement learning. Here, we investigate deep reinforcement learning agents in an ecological patch foraging task. For the first time, we show that machine learning agents can learn to patch forage adaptively in patterns similar to biological foragers, and approach optimal patch foraging behavior when accounting for temporal discounting. Finally, we show emergent internal dynamics in these agents that resemble single-cell recordings from foraging non-human primates, which complements experimental and theoretical work on the neural mechanisms of biological foraging. This work suggests that agents interacting in complex environments with ecologically valid pressures arrive at common solutions, suggesting the emergence of foundational computations behind adaptive, intelligent behavior in both biological and artificial agents",
    "checked": true,
    "id": "e7badd5598aa73fc183653756ac21249df9e8c17",
    "semantic_title": "adaptive patch foraging in deep reinforcement learning agents",
    "citation_count": 8,
    "authors": [
      "Nathan Wispinski",
      "Andrew Butcher",
      "Kory Wallace Mathewson",
      "Craig S Chapman",
      "Matthew Botvinick",
      "Patrick M. Pilarski"
    ]
  },
  "https://openreview.net/forum?id=onufdyHvqN": {
    "title": "Private Multi-Task Learning: Formulation and Applications to Federated Learning",
    "volume": "main",
    "abstract": "Many problems in machine learning rely on multi-task learning (MTL), in which the goal is to solve multiple related machine learning tasks simultaneously. MTL is particularly relevant for privacy-sensitive applications in areas such as healthcare, finance, and IoT computing, where sensitive data from multiple, varied sources are shared for the purpose of learning. In this work, we formalize notions of client-level privacy for MTL via billboard privacy (BP), a relaxation of differential privacy for mechanism design and distributed optimization. We then propose an algorithm for mean-regularized MTL, an objective commonly used for applications in personalized federated learning, subject to BP. We analyze our objective and solver, providing certifiable guarantees on both privacy and utility. Empirically, we find that our method provides improved privacy/utility trade-offs relative to global baselines across common federated learning benchmarks",
    "checked": true,
    "id": "ac3160a35b5b2fbbb8f129aa10aea6446dfb149c",
    "semantic_title": "private multi-task learning: formulation and applications to federated learning",
    "citation_count": 21,
    "authors": [
      "Shengyuan Hu",
      "Steven Wu",
      "Virginia Smith"
    ]
  },
  "https://openreview.net/forum?id=82hRiAbnnm": {
    "title": "Sobolev Spaces, Kernels and Discrepancies over Hyperspheres",
    "volume": "main",
    "abstract": "This work extends analytical foundations for kernel methods beyond the usual Euclidean manifold. Specifically, we characterise the smoothness of the native spaces (reproducing kernel Hilbert spaces) that are reproduced by geodesically isotropic kernels in the hyperspherical context. Our results are relevant to several areas of machine learning; we focus on their consequences for kernel cubature, determining the rate of convergence of the worst case error, and expanding the applicability of cubature algorithms based on Stein's method. First, we introduce a characterisation of Sobolev spaces on the $d$-dimensional sphere based on the Fourier--Schoenberg sequences associated with a given kernel. Such sequences are hard (if not impossible) to compute analytically on $d$-dimensional spheres, but often feasible over Hilbert spheres, where $d = \\infty$. Second, we circumvent this problem by finding a projection operator that allows us to map from Hilbert spheres to finite-dimensional spheres. Our findings are illustrated for selected parametric families of kernel",
    "checked": true,
    "id": "5917f15a28a4042907ea513d65139787d69c832c",
    "semantic_title": "sobolev spaces, kernels and discrepancies over hyperspheres",
    "citation_count": 5,
    "authors": [
      "Simon Hubbert",
      "Emilio Porcu",
      "Chris J. Oates",
      "Mark Girolami"
    ]
  },
  "https://openreview.net/forum?id=SgTKk6ryPr": {
    "title": "Monotone deep Boltzmann machines",
    "volume": "main",
    "abstract": "Deep Boltzmann machines (DBMs), one of the first ``deep'' learning methods ever studied, are multi-layered probabilistic models governed by a pairwise energy function that describes the likelihood of all variables/nodes in the network. In practice, DBMs are often constrained, i.e., via the \\emph{restricted} Boltzmann machine (RBM) architecture (which does not permit intra-layer connections), in order to allow for more efficient inference. In this work, we revisit the generic DBM approach, and ask the question: are there other possible restrictions to their design that would enable efficient (approximate) inference? In particular, we develop a new class of restricted model, the monotone DBM, which allows for arbitrary self-connection in each layer, but restricts the \\emph{weights} in a manner that guarantees the existence and global uniqueness of a mean-field fixed point. To do this, we leverage tools from the recently-proposed monotone Deep Equilibrium model and show that a particular choice of activation results in a fixed-point iteration that gives a variational mean-field solution. While this approach is still largely conceptual, it is the first architecture that allows for efficient approximate inference in fully-general weight structures for DBMs. We apply this approach to simple deep convolutional Boltzmann architectures and demonstrate that it allows for tasks such as the joint completion and classification of images, within a single deep probabilistic setting, while avoiding the pitfalls of mean-field inference in traditional RBMs",
    "checked": true,
    "id": "aa4519cfbe38d2c9dd0cca16fb65d32f99ac0c68",
    "semantic_title": "monotone deep boltzmann machines",
    "citation_count": 1,
    "authors": [
      "Zhili Feng",
      "Ezra Winston",
      "J Zico Kolter"
    ]
  },
  "https://openreview.net/forum?id=4eL6z9ziw7": {
    "title": "NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds",
    "volume": "main",
    "abstract": "In order for artificial agents to successfully perform tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification, where images focus on one distinct, well-centered object. New benchmarks are needed to represent the challenges of navigating the complex scenes of an open world. Our new NovelCraft dataset contains multimodal episodic data of the images and symbolic world-states seen by an agent completing a pogo stick assembly task within a modified Minecraft environment. In some episodes, we insert novel objects of varying size within the complex 3D scene that may impact gameplay. Our visual novelty detection benchmark finds that methods that rank best on popular area-under-the-curve metrics may be outperformed by simpler alternatives when controlling false positives matters most. Further multimodal novelty detection experiments suggest that methods that fuse both visual and symbolic information can improve time until detection as well as overall discrimination. Finally, our evaluation of recent generalized category discovery methods suggests that adapting to new imbalanced categories in complex scenes remains an exciting open problem",
    "checked": true,
    "id": "7c2bf08c3b4cff6927f4bd7ed6d67879860822ee",
    "semantic_title": "novelcraft: a dataset for novelty detection and discovery in open worlds",
    "citation_count": 6,
    "authors": [
      "Cynthia Feeney",
      "Sarah Schneider",
      "Panagiotis Lymperopoulos",
      "Liping Liu",
      "Matthias Scheutz",
      "Michael C Hughes"
    ]
  },
  "https://openreview.net/forum?id=OsKXlWamTQ": {
    "title": "Integrating Bayesian Network Structure into Residual Flows and Variational Autoencoders",
    "volume": "main",
    "abstract": "Deep generative models have become more popular in recent years due to their scalability and representation capacity. Unlike probabilistic graphical models, they typically do not incorporate specific domain knowledge. As such, this work explores incorporating arbitrary dependency structures, as specified by Bayesian networks, into variational autoencoders (VAEs). This is achieved by developing a new type of graphical normalizing flow, which extends residual flows by encoding conditional independence through masking of the flow's residual block weight matrices, and using these to extend both the prior and inference network of the VAE. We show that the proposed graphical VAE provides a more interpretable model that generalizes better in data-sparse settings, when practitioners know or can hypothesize about certain latent factors in their domain. Furthermore, we show that graphical residual flows provide not only density estimation and inference performance competitive with existing graphical flows, but also more stable and accurate inversion in practice as a byproduct of the flow's Lipschitz bounds",
    "checked": true,
    "id": "cbd91ec8fcedfd34efddb87ce3e0aac5279ae380",
    "semantic_title": "integrating bayesian network structure into residual flows and variational autoencoders",
    "citation_count": 4,
    "authors": [
      "Jacobie Mouton",
      "Rodney Stephen Kroon"
    ]
  },
  "https://openreview.net/forum?id=QTXocpAP9p": {
    "title": "Neural Collapse: A Review on Modelling Principles and Generalization",
    "volume": "main",
    "abstract": "Deep classifier neural networks enter the terminal phase of training (TPT) when training error reaches zero and tend to exhibit intriguing Neural Collapse (NC) properties. Neural collapse essentially represents a state at which the within-class variability of final hidden layer outputs is infinitesimally small and their class means form a simplex equiangular tight frame. This simplifies the last layer behaviour to that of a nearest-class center decision rule. Despite the simplicity of this state, the dynamics and implications of reaching it are yet to be fully understood. In this work, we review the principles which aid in modelling neural collapse, followed by the implications of this state on generalization and transfer learning capabilities of neural networks. Finally, we conclude by discussing potential avenues and directions for future research",
    "checked": true,
    "id": "f4723ed9bf2be70e63865bc97f3b903e2762c269",
    "semantic_title": "neural collapse: a review on modelling principles and generalization",
    "citation_count": 87,
    "authors": [
      "Vignesh Kothapalli"
    ]
  },
  "https://openreview.net/forum?id=ZOAb497iaY": {
    "title": "Unifying physical systems' inductive biases in neural ODE using dynamics constraints",
    "volume": "main",
    "abstract": "Conservation of energy is at the core of many physical phenomena and dynamical systems. There have been a significant number of works in the past few years aimed at predicting the trajectory of motion of dynamical systems using neural networks while adhering to the law of conservation of energy. Most of these works are inspired by classical mechanics such as Hamiltonian and Lagrangian mechanics as well as Neural Ordinary Differential Equations. While these works have been shown to work well in specific domains respectively, there is a lack of a unifying method that is more generally applicable without requiring significant changes to the neural network architectures. In this work, we aim to address this issue by providing a simple method that could be applied to not just energy-conserving systems, but also dissipative systems, by including a different inductive bias in different cases in the form of a regularisation term in the loss function. The proposed method does not require changing the neural network architecture and could form the basis to validate a novel idea, therefore showing promises to accelerate research in this direction",
    "checked": true,
    "id": "e142b0e670725afc66c6d4ce926b0738f1a8ad2b",
    "semantic_title": "unifying physical systems' inductive biases in neural ode using dynamics constraints",
    "citation_count": 6,
    "authors": [
      "Yi Heng Lim",
      "Muhammad Firmansyah Kasim"
    ]
  },
  "https://openreview.net/forum?id=tE2NiMGd07": {
    "title": "Bridging Graph Position Encodings for Transformers with Weighted Graph-Walking Automata",
    "volume": "main",
    "abstract": "A current goal in the graph neural network literature is to enable transformers to operate on graph-structured data, given their success on language and vision tasks. Since the transformer's original sinusoidal positional encodings (PEs) are not applicable to graphs, recent work has focused on developing graph PEs, rooted in spectral graph theory or various spatial features of a graph. In this work, we introduce a new graph PE, Graph Automaton PE (GAPE), based on weighted graph-walking automata (a novel extension of graph-walking automata). We compare the performance of GAPE with other PE schemes on both machine translation and graph-structured tasks, and we show that it generalizes several other PEs. An additional contribution of this study is a theoretical and controlled experimental comparison of many recent PEs in graph transformers, independent of the use of edge features",
    "checked": true,
    "id": "410a958c4b51650e055c9a2c5bd9e9a7fa2162d4",
    "semantic_title": "bridging graph position encodings for transformers with weighted graph-walking automata",
    "citation_count": 0,
    "authors": [
      "Patrick Soga",
      "David Chiang"
    ]
  },
  "https://openreview.net/forum?id=jdGMBgYvfX": {
    "title": "UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural Representations for Computed Tomography",
    "volume": "main",
    "abstract": "Implicit neural representations (INRs) have achieved impressive results for scene reconstruction and computer graphics, where their performance has primarily been assessed on reconstruction accuracy. As INRs make their way into other domains, where model predictions inform high-stakes decision-making, uncertainty quantification of INR inference is becoming critical. To that end, we study a Bayesian reformulation of INRs, UncertaINR, in the context of computed tomography, and evaluate several Bayesian deep learning implementations in terms of accuracy and calibration. We find that they achieve well-calibrated uncertainty, while retaining accuracy competitive with other classical, INR-based, and CNN-based reconstruction techniques. Contrary to common intuition in the Bayesian deep learning literature, we find that INRs obtain the best calibration with computationally efficient Monte Carlo dropout, outperforming Hamiltonian Monte Carlo and deep ensembles. Moreover, in contrast to the best-performing prior approaches, UncertaINR does not require a large training dataset, but only a handful of validation images",
    "checked": true,
    "id": "343ba2ac5601e67143395e2fae162e67868cf301",
    "semantic_title": "uncertainr: uncertainty quantification of end-to-end implicit neural representations for computed tomography",
    "citation_count": 13,
    "authors": [
      "Francisca Vasconcelos",
      "Bobby He",
      "Nalini M Singh",
      "Yee Whye Teh"
    ]
  },
  "https://openreview.net/forum?id=FdMWtpVT1I": {
    "title": "Training Data Size Induced Double Descent For Denoising Feedforward Neural Networks and the Role of Training Noise",
    "volume": "main",
    "abstract": "When training an unregularized denoising feedforward neural network, we show that the generalization error versus the number of training data points is a double descent curve. We formalize the question of how many training data points should be used by looking at the generalization error for denoising noisy test data. Prior work on computing the generalization error focuses on adding noise to target outputs. However, adding noise to the input is more in line with current pre-training practices. In the linear (in the inputs) regime, we provide an asymptotically exact formula for the generalization error for rank 1 data and an approximation for the generalization error for rank $r$ data. From this, we derive a formula for the amount of noise that needs to be added to the training data to minimize the denoising error. This results in the emergence of a shrinkage phenomenon for improving the performance of denoising DNNs by making the training SNR smaller than the test SNR. Further, we see that the amount of shrinkage (ratio of the train to test SNR) also follows a double descent curve",
    "checked": true,
    "id": "737b52a421e993b51605b6d9c578dc5d44bb7fc0",
    "semantic_title": "training data size induced double descent for denoising feedforward neural networks and the role of training noise",
    "citation_count": 6,
    "authors": [
      "Rishi Sonthalia",
      "Raj Rao Nadakuditi"
    ]
  },
  "https://openreview.net/forum?id=10JdgrzNOk": {
    "title": "Scalable Deep Compressive Sensing",
    "volume": "main",
    "abstract": "Deep learning has been used to image compressive sensing (CS) for enhanced reconstruction performance. However, most existing deep learning methods train different models for different subsampling ratios, which brings an additional hardware burden. In this paper, we develop a general framework named scalable deep compressive sensing (SDCS) for the scalable sampling and reconstruction (SSR) of all existing end-to-end-trained models. In the proposed way, images are measured and initialized linearly. Two sampling matrix masks are introduced to flexibly control the subsampling ratios used in sampling and reconstruction, respectively. To achieve a reconstruction model with flexible subsampling ratios, a training strategy dubbed scalable training is developed. In scalable training, the model is trained with the sampling matrix and the initialization matrix at various subsampling ratios by integrating different sampling matrix masks. Experimental results show that models with SDCS can achieve SSR without changing their structure while maintaining good performance, and SDCS outperforms other SSR methods",
    "checked": true,
    "id": "02e0a615c98b5cc323319a72039a50585fa2d1f9",
    "semantic_title": "scalable deep compressive sensing",
    "citation_count": 3,
    "authors": [
      "Zhonghao Zhang",
      "Yipeng Liu",
      "Xingyu Cao",
      "Fei Wen",
      "Ce Zhu"
    ]
  },
  "https://openreview.net/forum?id=MRLHN4MSmA": {
    "title": "A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues",
    "volume": "main",
    "abstract": "Data missingness and quality are common problems in machine learning, especially for high-stakes applications such as healthcare. Developers often train machine learning models on carefully curated datasets using only high-quality data; however, this reduces the utility of such models in production environments. We propose a novel neural network modification to mitigate the impacts of low-quality and missing data which involves replacing the fixed weights of a fully-connected layer with a function of additional input. This is inspired by neuromodulation in biological neural networks where the cortex can up- and down-regulate inputs based on their reliability and the presence of other data. In testing, with reliability scores as a modulating signal, models with modulating layers were found to be more robust against data quality degradation, including additional missingness. These models are superior to imputation as they save on training time by entirely skipping the imputation process and further allow the introduction of other data quality measures that imputation cannot handle. Our results suggest that explicitly accounting for reduced information quality with a modulating fully connected layer can enable the deployment of artificial intelligence systems in real-time applications",
    "checked": true,
    "id": "4d73170ded0fd3b3bffe723cb9cebaf72300b27e",
    "semantic_title": "a modulation layer to increase neural network robustness against data quality issues",
    "citation_count": 2,
    "authors": [
      "Mohamed Abdelhack",
      "Jiaming Zhang",
      "Sandhya Tripathi",
      "Bradley A Fritz",
      "Daniel Felsky",
      "Michael Avidan",
      "Yixin Chen",
      "Christopher Ryan King"
    ]
  },
  "https://openreview.net/forum?id=gR9UVgH8PZ": {
    "title": "Neural Shape Compiler: A Unified Framework for Transforming between Text, Point Cloud, and Program",
    "volume": "main",
    "abstract": "3D shapes have complementary abstractions from low-level geometry to part-based hierarchies to languages, which convey different levels of information. This paper presents a unified framework to translate between pairs of shape abstractions: $\\textit{Text}$ $\\Longleftrightarrow$ $\\textit{Point Cloud}$ $\\Longleftrightarrow$ $\\textit{Program}$. We propose $\\textbf{\\textit{Neural Shape Compiler}}$ to model the abstraction transformation as a conditional generation process. It converts 3D shapes of three abstract types into unified discrete shape code, transforms each shape code into code of other abstract types through the proposed $\\textit{ShapeCode Transformer}$, and decodes them to output the target shape abstraction. Point Cloud code is obtained in a class-agnostic way by the proposed $\\textit{Point}$VQVAE. On Text2Shape, ShapeGlot, ABO, Genre, and Program Synthetic datasets, Neural Shape Compiler shows strengths in $\\textit{Text}$ $\\Longrightarrow$ $\\textit{Point Cloud}$, $\\textit{Point Cloud}$ $\\Longrightarrow$ $\\textit{Text}$, $\\textit{Point Cloud}$ $\\Longrightarrow$ $\\textit{Program}$, and Point Cloud Completion tasks. Additionally, Neural Shape Compiler benefits from jointly training on all heterogeneous data and tasks",
    "checked": true,
    "id": "76d4fcc32c0004cab928d3c827f0718f5c3e74bc",
    "semantic_title": "neural shape compiler: a unified framework for transforming between text, point cloud, and program",
    "citation_count": 6,
    "authors": [
      "Tiange Luo",
      "Honglak Lee",
      "Justin Johnson"
    ]
  },
  "https://openreview.net/forum?id=6IFi2soduD": {
    "title": "Can Pruning Improve Certified Robustness of Neural Networks?",
    "volume": "main",
    "abstract": "With the rapid development of deep learning, the sizes of deep neural networks are getting larger beyond the affordability of hardware platforms. Given the fact that neural networks are often over-parameterized, one effective way to reduce such computational overhead is neural network pruning, by removing redundant parameters from trained neural networks. It has been recently observed that pruning can not only reduce computational overhead but also can improve empirical robustness of deep neural networks (NNs), potentially owing to removing spurious correlations while preserving the predictive accuracies. This paper for the first time demonstrates that pruning can generally improve $L_\\infty$ certified robustness for ReLU-based NNs under the \\textit{complete verification} setting. Using the popular Branch-and-Bound (BaB) framework, we find that pruning can enhance the estimated bound tightness of certified robustness verification, by alleviating linear relaxation and sub-domain split problems. We empirically verify our findings with off-the-shelf pruning methods and further present a new stability-based pruning method tailored for reducing neuron instability, that outperforms existing pruning methods in enhancing certified robustness. Our experiments show that by appropriately pruning an NN, its certified accuracy can be boosted up to \\textbf{8.2\\%} under standard training, and up to \\textbf{24.5\\%} under adversarial training on the CIFAR10 dataset. We additionally observe the possible existence of {\\it certified lottery tickets} in our experiments that can match both standard and certified robust accuracies of the original dense models across different datasets. Our findings offer a new angle to study the intriguing interaction between sparsity and robustness, i.e. interpreting the interaction of sparsity and certified robustness via neuron stability. Codes will be fully released",
    "checked": true,
    "id": "6f0b89a3ce7c835dc42afe798b9424471f4ca585",
    "semantic_title": "can pruning improve certified robustness of neural networks?",
    "citation_count": 13,
    "authors": [
      "Zhangheng LI",
      "Tianlong Chen",
      "Linyi Li",
      "Bo Li",
      "Zhangyang Wang"
    ]
  },
  "https://openreview.net/forum?id=v5jwDLqfQo": {
    "title": "Extended Agriculture-Vision: An Extension of a Large Aerial Image Dataset for Agricultural Pattern Analysis",
    "volume": "main",
    "abstract": "A key challenge for much of the machine learning work on remote sensing and earth observation data is the difficulty in acquiring large amounts of accurately labeled data. This is particularly true for semantic segmentation tasks, which are much less common in the remote sensing domain because of the incredible difficulty in collecting precise, accurate, pixel-level annotations at scale. Recent efforts have addressed these challenges both through the creation of supervised datasets as well as the application of self-supervised methods. We continue these efforts on both fronts. First, we generate and release an improved version of the Agriculture-Vision dataset (Chiu et al., 2020b) to include raw, full-field imagery for greater experimental flexibility. Second, we extend this dataset with the release of 3600 large, high-resolution (10cm/pixel), full-field, red-green-blue and near-infrared images for pre-training. Third, we incorporate the Pixel-to-Propagation Module Xie et al. (2021b) originally built on the SimCLR framework into the framework of MoCo-V2 Chen et al.(2020b). Finally, we demonstrate the usefulness of this data by benchmarking different contrastive learning approaches on both downstream classification and semantic segmentation tasks. We explore both CNN and Swin Transformer Liu et al. (2021a) architectures within different frameworks based on MoCo-V2. Together, these approaches enable us to better detect key agricultural patterns of interest across a field from aerial imagery so that farmers may be alerted to problematic areas in a timely fashion to inform their management decisions. Furthermore, the release of these datasets will support numerous avenues of research for computer vision in remote sensing for agriculture",
    "checked": true,
    "id": "b4c3a79927744a80cb72fddc75a89b1f375ace27",
    "semantic_title": "extended agriculture-vision: an extension of a large aerial image dataset for agricultural pattern analysis",
    "citation_count": 23,
    "authors": [
      "Jing Wu",
      "David Pichler",
      "Daniel Marley",
      "Naira Hovakimyan",
      "David A Wilson",
      "Jennifer Hobbs"
    ]
  },
  "https://openreview.net/forum?id=OJtYpdiHNo": {
    "title": "Transframer: Arbitrary Frame Prediction with Generative Models",
    "volume": "main",
    "abstract": "We present a general-purpose framework for image modelling and vision tasks based on probabilistic frame prediction. Our approach unifies a broad range of tasks, from image segmentation, to novel view synthesis and video interpolation. We pair this framework with an architecture we term \\modelname, which uses U-Net and Transformer components to condition on annotated context frames, and outputs sequences of sparse, compressed image features. Transframer is the state-of-the-art on a variety of video generation benchmarks, is competitive with the strongest models on few-shot view synthesis, and can generate coherent 30 second videos from a single image without any explicit geometric information. A single generalist Transframer simultaneously produces promising results on 8 tasks, including semantic segmentation, image classification and optical flow prediction with no task-specific architectural components, demonstrating that multi-task computer vision can be tackled using probabilistic image models. Our approach can in principle be applied to a wide range of applications that require learning the conditional structure of annotated image-formatted data",
    "checked": true,
    "id": "b079f791e01e0b308b8e3dae7989a917be73a1a4",
    "semantic_title": "transframer: arbitrary frame prediction with generative models",
    "citation_count": 40,
    "authors": [
      "Charlie Nash",
      "Joao Carreira",
      "Jacob C Walker",
      "Iain Barr",
      "Andrew Jaegle",
      "Mateusz Malinowski",
      "Peter Battaglia"
    ]
  },
  "https://openreview.net/forum?id=xqS8k9E75c": {
    "title": "Prior and Posterior Networks: A Survey on Evidential Deep Learning Methods For Uncertainty Estimation",
    "volume": "main",
    "abstract": "Popular approaches for quantifying predictive uncertainty in deep neural networks often involve distributions over weights or multiple models, for instance via Markov Chain sampling, ensembling, or Monte Carlo dropout. These techniques usually incur overhead by having to train multiple model instances or do not produce very diverse predictions. This comprehensive and extensive survey aims to familiarize the reader with an alternative class of models based on the concept of Evidential Deep Learning: For unfamiliar data, they admit \"what they don't know\" and fall back onto a prior belief. Furthermore, they allow uncertainty estimation in a single model and forward pass by parameterizing distributions over distributions. This survey recapitulates existing works, focusing on the implementation in a classification setting, before surveying the application of the same paradigm to regression. We also reflect on the strengths and weaknesses compared to other existing methods and provide the most fundamental derivations using a unified notation to aid future research",
    "checked": true,
    "id": "f9a522bae646c7d3a1b33e16a595f4c938558068",
    "semantic_title": "prior and posterior networks: a survey on evidential deep learning methods for uncertainty estimation",
    "citation_count": 60,
    "authors": [
      "Dennis Thomas Ulmer",
      "Christian Hardmeier",
      "Jes Frellsen"
    ]
  },
  "https://openreview.net/forum?id=jM8nzUzBWr": {
    "title": "Estimating the Density Ratio between Distributions with High Discrepancy using Multinomial Logistic Regression",
    "volume": "main",
    "abstract": "Functions of the ratio of the densities $p/q$ are widely used in machine learning to quantify the discrepancy between the two distributions $p$ and $q$. For high-dimensional distributions, binary classification-based density ratio estimators have shown great promise. However, when densities are well-separated, estimating the density ratio with a binary classifier is challenging. In this work, we show that the state-of-the-art density ratio estimators do perform poorly on well-separated cases and demonstrate that this is due to distribution shifts between training and evaluation time. We present an alternative method that leverages multi-class classification for density ratio estimation and does not suffer from distribution shift issues. The method uses a set of auxiliary densities $\\{m_k\\}_{k=1}^K$ and trains a multi-class logistic regression to classify the samples from $p, q$ and $\\{m_k\\}_{k=1}^K$ into $K+2$ classes. We show that if these auxiliary densities are constructed such that they overlap with $p$ and $q$, then a multi-class logistic regression allows for estimating $\\log p/q$ on the domain of any of the $K+2$ distributions and resolves the distribution shift problems of the current state-of-the-art methods. We compare our method to state-of-the-art density ratio estimators on both synthetic and real datasets and demonstrate its superior performance on the tasks of density ratio estimation, mutual information estimation, and representation learning",
    "checked": true,
    "id": "f3f9be5014b4bcec701bdef4ee01c94f3cf719f6",
    "semantic_title": "estimating the density ratio between distributions with high discrepancy using multinomial logistic regression",
    "citation_count": 11,
    "authors": [
      "Akash Srivastava",
      "Seungwook Han",
      "Kai Xu",
      "Benjamin Rhodes",
      "Michael U. Gutmann"
    ]
  },
  "https://openreview.net/forum?id=QzWr4w8PXx": {
    "title": "A Revenue Function for Comparison-Based Hierarchical Clustering",
    "volume": "main",
    "abstract": "Comparison-based learning addresses the problem of learning when, instead of explicit features or pairwise similarities, one only has access to comparisons of the form: \\emph{Object $A$ is more similar to $B$ than to $C$.} Recently, it has been shown that, in Hierarchical Clustering, single and complete linkage can be directly implemented using only such comparisons while several algorithms have been proposed to emulate the behaviour of average linkage. Hence, finding hierarchies (or dendrograms) using only comparisons is a well understood problem. However, evaluating their meaningfulness when no ground-truth nor explicit similarities are available remains an open question. In this paper, we bridge this gap by proposing a new revenue function that allows one to measure the goodness of dendrograms using only comparisons. We show that this function is closely related to Dasgupta's cost for hierarchical clustering that uses pairwise similarities. On the theoretical side, we use the proposed revenue function to resolve the open problem of whether one can approximately recover a latent hierarchy using few triplet comparisons. On the practical side, we present principled algorithms for comparison-based hierarchical clustering based on the maximisation of the revenue and we empirically compare them with existing methods",
    "checked": true,
    "id": "0154e89f07b22c60adfd4e2cb89a63b9b28669ba",
    "semantic_title": "a revenue function for comparison-based hierarchical clustering",
    "citation_count": 4,
    "authors": [
      "Aishik Mandal",
      "Michaël Perrot",
      "Debarghya Ghoshdastidar"
    ]
  },
  "https://openreview.net/forum?id=C1Xl8dYCBn": {
    "title": "ChemSpacE: Interpretable and Interactive Chemical Space Exploration",
    "volume": "main",
    "abstract": "Discovering meaningful molecules in the vast combinatorial chemical space has been a long-standing challenge in many fields, from materials science to drug design. Recent progress in machine learning, especially with generative models, shows great promise for automated molecule synthesis. Nevertheless, most molecule generative models remain black-boxes, whose utilities are limited by a lack of interpretability and human participation in the generation process. In this work, we propose \\textbf{Chem}ical \\textbf{Spac}e \\textbf{E}xplorer (ChemSpacE), a simple yet effective method for exploring the chemical space with pre-trained deep generative models. Our method enables users to interact with existing generative models and steer the molecule generation process. We demonstrate the efficacy of ChemSpacE on the molecule optimization task and the latent molecule manipulation task in single-property and multi-property settings. On the molecule optimization task, the performance of ChemSpacE is on par with previous black-box optimization methods yet is considerably faster and more sample efficient. Furthermore, the interface from ChemSpacE facilitates human-in-the-loop chemical space exploration and interactive molecule design. Code and demo are available at \\url{https://github.com/yuanqidu/ChemSpacE}",
    "checked": true,
    "id": "035e620fbefe8adee0fb4dc6cf232a914779d72c",
    "semantic_title": "chemspace: interpretable and interactive chemical space exploration",
    "citation_count": 11,
    "authors": [
      "Yuanqi Du",
      "Xian Liu",
      "Nilay Mahesh Shah",
      "Shengchao Liu",
      "Jieyu Zhang",
      "Bolei Zhou"
    ]
  },
  "https://openreview.net/forum?id=dQxBRqCjLr": {
    "title": "A Free Lunch with Influence Functions? An Empirical Evaluation of Influence Functions for Average Treatment Effect Estimation",
    "volume": "main",
    "abstract": "The applications of causal inference may be life-critical, including the evaluation of vaccinations, medicine, and social policy. However, when undertaking estimation for causal inference, practitioners rarely have access to what might be called `ground-truth' in a supervised learning setting, meaning the chosen estimation methods cannot be evaluated and must be assumed to be reliable. It is therefore crucial that we have a good understanding of the performance consistency of typical methods available to practitioners. In this work we provide a comprehensive evaluation of recent semiparametric methods (including neural network approaches) for average treatment effect estimation. Such methods have been proposed as a means to derive unbiased causal effect estimates and statistically valid confidence intervals, even when using otherwise non-parametric, data-adaptive machine learning techniques. We also propose a new estimator `MultiNet', and a variation on the semiparametric update step `MultiStep', which we evaluate alongside existing approaches. The performance of both semiparametric and `regular' methods are found to be dataset dependent, indicating an interaction between the methods used, the sample size, and nature of the data generating process. Our experiments highlight the need for practitioners to check the consistency of their findings, potentially by undertaking multiple analyses with different combinations of estimators",
    "checked": true,
    "id": "b71088ddba8e3d94ee0f18ba1b04c1d31c79369e",
    "semantic_title": "a free lunch with influence functions? an empirical evaluation of influence functions for average treatment effect estimation",
    "citation_count": 2,
    "authors": [
      "Matthew James Vowels",
      "Sina Akbari",
      "Necati Cihan Camgoz",
      "Richard Bowden"
    ]
  },
  "https://openreview.net/forum?id=TzRXyO3CzX": {
    "title": "Clustering using Approximate Nearest Neighbour Oracles",
    "volume": "main",
    "abstract": "We study the problem of clustering data points in a streaming setting when one has access to the geometry of the space only via approximate nearest neighbour (ANN) oracles. In this setting, we present algorithms for streaming $O(1)$-approximate $k$-median clustering and its (streaming) coreset construction. In certain domains of interest, such as spaces with constant expansion, our algorithms improve upon the best-known runtime of both these problems. Furthermore, our results extend to cost functions satisfying the approximate triangle inequality, which subsumes $k$-means clustering and $M$-estimators. Finally, we run experiments on Census1990 dataset wherein the results empirically support our theory",
    "checked": true,
    "id": "2e864475d80f551d97232f9a6cba079dd128c54d",
    "semantic_title": "clustering using approximate nearest neighbour oracles",
    "citation_count": 1,
    "authors": [
      "Enayat Ullah",
      "Harry Lang",
      "Raman Arora",
      "Vladimir Braverman"
    ]
  },
  "https://openreview.net/forum?id=JwgVBv18RG": {
    "title": "Bayesian Optimization with Informative Covariance",
    "volume": "main",
    "abstract": "Bayesian optimization is a methodology for global optimization of unknown and expensive objectives. It combines a surrogate Bayesian regression model with an acquisition function to decide where to evaluate the objective. Typical regression models are given by Gaussian processes with stationary covariance functions. However, these functions are unable to express prior input-dependent information, including possible locations of the optimum. The ubiquity of stationary models has led to the common practice of exploiting prior information via informative mean functions. In this paper, we highlight that these models can perform poorly, especially in high dimensions. We propose novel informative covariance functions for optimization, leveraging nonstationarity to encode preferences for certain regions of the search space and adaptively promote local exploration during optimization. We demonstrate that the proposed functions can increase the sample efficiency of Bayesian optimization in high dimensions, even under weak prior information",
    "checked": true,
    "id": "61b5f3b43048090f42e5a428d393f41c4ab7f19b",
    "semantic_title": "bayesian optimization with informative covariance",
    "citation_count": 3,
    "authors": [
      "Afonso Eduardo",
      "Michael U. Gutmann"
    ]
  },
  "https://openreview.net/forum?id=2UQv8L1Cv9": {
    "title": "Turning Normalizing Flows into Monge Maps with Geodesic Gaussian Preserving Flows",
    "volume": "main",
    "abstract": "Normalizing Flows (NF) are powerful likelihood-based generative models that are able to trade off between expressivity and tractability to model complex densities. A now well established research avenue leverages optimal transport (OT) and looks for Monge maps, i.e. models with minimal effort between the source and target distributions. This paper introduces a method based on Brenier's polar factorization theorem to transform any trained NF into a more OT-efficient version without changing the final density. We do so by learning a rearrangement of the source (Gaussian) distribution that minimizes the OT cost between the source and the final density. The Gaussian preserving transformation is implemented with the construction of high dimensional divergence free functions and the path leading to the estimated Monge map is further constrained to lie on a geodesic in the space of volume-preserving diffeomorphisms thanks to Euler's equations. The proposed method leads to smooth flows with reduced OT costs for several existing models without affecting the model performance",
    "checked": true,
    "id": "13379ebec73b759f0d887d7f7b458228f6e4790e",
    "semantic_title": "turning normalizing flows into monge maps with geodesic gaussian preserving flows",
    "citation_count": 6,
    "authors": [
      "Guillaume Morel",
      "Lucas Drumetz",
      "Simon Benaïchouche",
      "Nicolas Courty",
      "François Rousseau"
    ]
  },
  "https://openreview.net/forum?id=h4BYtZ79uy": {
    "title": "Graph Neural Networks Designed for Different Graph Types: A Survey",
    "volume": "main",
    "abstract": "Graphs are ubiquitous in nature and can therefore serve as models for many practical but also theoretical problems. For this purpose, they can be defined as many different types which suitably reflect the individual contexts of the represented problem. To address cutting-edge problems based on graph data, the research field of Graph Neural Networks (GNNs) has emerged. Despite the field's youth and the speed at which new models are developed, many recent surveys have been published to keep track of them. Nevertheless, it has not yet been gathered which GNN can process what kind of graph types. In this survey, we give a detailed overview of already existing GNNs and, unlike previous surveys, categorize them according to their ability to handle different graph types and properties. We consider GNNs operating on static and dynamic graphs of different structural constitutions, with or without node or edge attributes. Moreover, we distinguish between GNN models for discrete-time or continuous-time dynamic graphs and group the models according to their architecture. We find that there are still graph types that are not or only rarely covered by existing GNN models. We point out where models are missing and give potential reasons for their absence",
    "checked": true,
    "id": "246c97ebe5ebd13603be168515cd5f5a347e7e0a",
    "semantic_title": "graph neural networks designed for different graph types: a survey",
    "citation_count": 31,
    "authors": [
      "Josephine Thomas",
      "Alice Moallemy-Oureh",
      "Silvia Beddar-Wiesing",
      "Clara Holzhüter"
    ]
  },
  "https://openreview.net/forum?id=KwWKB9Bqam": {
    "title": "Generalization bounds for Kernel Canonical Correlation Analysis",
    "volume": "main",
    "abstract": "We study the problem of multiview representation learning using kernel canonical correlation analysis (KCCA) and establish non-asymptotic bounds on generalization error for regularized empirical risk minimization. In particular, we give fine-grained high-probability bounds on generalization error ranging from $O(n^{-1/6})$ to $O(n^{-1/5})$ depending on underlying distributional properties, where $n$ is the number of data samples. For the special case of finite-dimensional Hilbert spaces (such as linear CCA), our rates improve, ranging from $O(n^{-1/2})$ to $O(n^{-1})$. Finally, our results generalize to the problem of functional canonical correlation analysis over abstract Hilbert spaces",
    "checked": true,
    "id": "4a55079d0145870461cbe2a48f53e40e64b7db3d",
    "semantic_title": "generalization bounds for kernel canonical correlation analysis",
    "citation_count": 1,
    "authors": [
      "Enayat Ullah",
      "Raman Arora"
    ]
  },
  "https://openreview.net/forum?id=gyhiZYrk5y": {
    "title": "Learning Identity-Preserving Transformations on Data Manifolds",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1a013d43da7bbe97926f9d2fa0f782e97dd42212",
    "semantic_title": "learning identity-preserving transformations on data manifolds",
    "citation_count": 6,
    "authors": [
      "Marissa Catherine Connor",
      "Kion Fallah",
      "Christopher John Rozell"
    ]
  },
  "https://openreview.net/forum?id=YtU0nDb5e8": {
    "title": "A Halfspace-Mass Depth-Based Method for Adversarial Attack Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "272da9d059a466064421de6da8ee7d428d9ea215",
    "semantic_title": "a halfspace-mass depth-based method for adversarial attack detection",
    "citation_count": 8,
    "authors": [
      "Marine Picot",
      "Federica Granese",
      "Guillaume Staerman",
      "Marco Romanelli",
      "Francisco Messina",
      "Pablo Piantanida",
      "Pierre Colombo"
    ]
  },
  "https://openreview.net/forum?id=qdDmxzGuzu": {
    "title": "Reusable Options through Gradient-based Meta Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3ecbf75ca51133eb59a66ddb28d057a14dd538c1",
    "semantic_title": "reusable options through gradient-based meta learning",
    "citation_count": 0,
    "authors": [
      "David Kuric",
      "Herke van Hoof"
    ]
  },
  "https://openreview.net/forum?id=qvRWcDXBam": {
    "title": "Containing a spread through sequential learning: to exploit or to explore?",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e1882d966a72c9e2c774d02895c482c2a6fcd33a",
    "semantic_title": "containing a spread through sequential learning: to exploit or to explore?",
    "citation_count": 1,
    "authors": [
      "Xingran Chen",
      "Hesam Nikpey",
      "Jungyeol Kim",
      "Saswati Sarkar",
      "Shirin Saeedi Bidokhti"
    ]
  },
  "https://openreview.net/forum?id=WVwnccBJLz": {
    "title": "Bidirectional View based Consistency Regularization for Semi-Supervised Domain Adaptation",
    "volume": "main",
    "abstract": "Distinguished from unsupervised domain adaptation (UDA), semi-supervised domain adaptation (SSDA) could access a few labeled target samples during learning additionally. Although achieving remarkable progress, target supervised information is easily overwhelmed by massive source supervised information, as there are many more labeled source samples than those in the target domain. In this work, we propose a novel method BVCR that better utilizes the supervised information by three schemes, i.e., modeling, exploration, and interaction. In the modeling scheme, BVCR models the source supervision and target supervision separately to avoid target supervised information being overwhelmed by source supervised information and better utilize the target supervision. Besides, as both supervised information naturally offer distinct views for the target domain, the exploration scheme performs intra-domain consistency regularization to better explore target information with bidirectional views. Moreover, as both views are complementary to each other, the interaction scheme introduces inter-domain consistency regularization to activate information interaction bidirectionally. Thus, the proposed method is elegantly symmetrical by design and easy to implement. Extensive experiments are conducted, and the results show the effectiveness of the proposed method",
    "checked": true,
    "id": "ea1c76b6bd108e7e3a1a7dbbabdbc0c9e377416d",
    "semantic_title": "bidirectional view based consistency regularization for semi-supervised domain adaptation",
    "citation_count": 1,
    "authors": [
      "Yuntao Du",
      "娟 江",
      "Hongtao Luo",
      "Haiyang Yang",
      "MingCai Chen",
      "Chongjun Wang"
    ]
  },
  "https://openreview.net/forum?id=UvJBKWaSSH": {
    "title": "FLUID: A Unified Evaluation Framework for Flexible Sequential Data",
    "volume": "main",
    "abstract": "Modern machine learning methods excel when training data is IID, large-scale, and well labeled. Learning in less ideal conditions remains an open challenge. The sub-fields of few-shot, continual, transfer, and representation learning have made substantial strides in learning under adverse conditions, each affording distinct advantages through methods and insights. These methods address different challenges such as data arriving sequentially or scarce training examples, however often the difficult conditions an ML system will face over its lifetime cannot be anticipated prior to deployment. Therefore, general ML systems which can handle the many challenges of learning in practical settings are needed. To foster research towards the goal of general ML methods, we introduce a new unified evaluation framework – FLUID (Flexible Sequential Data). FLUID integrates the objectives of few-shot, continual, transfer, and representation learning while enabling comparison and integration of techniques across these subfields. In FLUID, a learner faces a stream of data and must make sequential predictions while choosing how to update itself, adapt quickly to novel classes, and deal with changing data distributions; while accounting for the total amount of compute. We conduct experiments on a broad set of methods which shed new insight on the advantages and limitations of current techniques and indicate new research problems to solve. As a starting point towards more general methods, we present two new baselines which outperform other evaluated methods on FLUID",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew Wallingford",
      "Aditya Kusupati",
      "Keivan Alizadeh-Vahid",
      "Aaron Walsman",
      "Aniruddha Kembhavi",
      "Ali Farhadi"
    ]
  },
  "https://openreview.net/forum?id=bCiNWDmlY2": {
    "title": "The Low-Rank Simplicity Bias in Deep Networks",
    "volume": "main",
    "abstract": "Modern deep neural networks are highly over-parameterized compared to the data on which they are trained, yet they often generalize remarkably well. A flurry of recent work has asked: why do deep networks not overfit to their training data? In this work, we make a series of empirical observations that investigate and extend the hypothesis that deeper networks are inductively biased to find solutions with lower effective rank embeddings. We conjecture that this bias exists because the volume of functions that maps to low effective rank embedding increases with depth. We show empirically that our claim holds true on finite width linear and non-linear models on practical learning paradigms and show that on natural data, these are often the solutions that generalize well. We then show that the simplicity bias exists at both initialization and after training and is resilient to hyper-parameters and learning methods. We further demonstrate how linear over-parameterization of deep non-linear models can be used to induce low-rank bias, improving generalization performance on CIFAR and ImageNet without changing the modeling capacity",
    "checked": true,
    "id": "be0c0dbe570ea7f4f3470e7579ac765c63beaf16",
    "semantic_title": "the low-rank simplicity bias in deep networks",
    "citation_count": 119,
    "authors": [
      "Minyoung Huh",
      "Hossein Mobahi",
      "Richard Zhang",
      "Brian Cheung",
      "Pulkit Agrawal",
      "Phillip Isola"
    ]
  },
  "https://openreview.net/forum?id=LIT8tjs6rJ": {
    "title": "Parameter Efficient Node Classification on Homophilic Graphs",
    "volume": "main",
    "abstract": "Deep Learning on Graphs was recently made possible with the introduction of Graph Neural Networks (GNNs). GNNs use learnable diffusion processes to propagate information through the graph and improve performance on downstream tasks. However, learning this diffusion process can be expensive in terms of memory and computation. While a lot of research has gone into making these models more expressive and able to capture more complex patterns, in practice, edges in common benchmarking datasets often encode similarity of nodes with respect to the downstream task. This property is called homophily. We argue that for these homophilic graphs, learnable diffusion processes and large receptive fields are not required to achieve competitive performance. We propose Graph Non-Parametric Diffusion (GNPD) a method that outperforms traditional GNNs using only 2 linear models and non-parameteric diffusion. Our method takes ideas from Correct & Smooth (C&S) and the Scalable Inception Graph Network (SIGN) and combines them to create a simpler model that outperforms both of them on several datasets. Our method achieves an unmatched parameter efficiency, competing with models with two orders of magnitude more parameters. Additionally GNPD can also forego spectral embeddings which are the computational bottleneck of the C&S method",
    "checked": true,
    "id": "8cb11718be44145fae4b0b265c2d53caccfaffd0",
    "semantic_title": "parameter efficient node classification on homophilic graphs",
    "citation_count": 3,
    "authors": [
      "Lucas Prieto",
      "Jeroen Den Boef",
      "Paul Groth",
      "Joran Cornelisse"
    ]
  },
  "https://openreview.net/forum?id=xkrtvHlp3P": {
    "title": "Towards Better Out-of-Distribution Generalization of Neural Algorithmic Reasoning Tasks",
    "volume": "main",
    "abstract": "In this paper, we study the OOD generalization of neural algorithmic reasoning tasks, where the goal is to learn an algorithm (e.g., sorting, breadth-first search, and depth-first search) from input-output pairs using deep neural networks. First, we argue that OOD generalization in this setting is significantly different than common OOD settings. For example, some phenomena in OOD generalization of image classifications such as \\emph{accuracy on the line} are not observed here, and techniques such as data augmentation methods do not help as assumptions underlying many augmentation techniques are often violated. Second, we analyze the main challenges (e.g., input distribution shift, non-representative data generation, and uninformative validation metrics) of the current leading benchmark, i.e., CLRS \\citep{deepmind2021clrs}, which contains 30 algorithmic reasoning tasks. We propose several solutions, including a simple-yet-effective fix to the input distribution shift and improved data generation. Finally, we propose an attention-based 2WL-graph neural network (GNN) processor which complements message-passing GNNs so their combination outperforms the state-of-the-art model by a $3\\%$ margin averaged over all algorithms",
    "checked": true,
    "id": "57196d1c3a7d8a3c8b074886858969dc16cb61d4",
    "semantic_title": "towards better out-of-distribution generalization of neural algorithmic reasoning tasks",
    "citation_count": 27,
    "authors": [
      "Sadegh Mahdavi",
      "Kevin Swersky",
      "Thomas Kipf",
      "Milad Hashemi",
      "Christos Thrampoulidis",
      "Renjie Liao"
    ]
  },
  "https://openreview.net/forum?id=9lyqt3rbDc": {
    "title": "L-SVRG and L-Katyusha with Adaptive Sampling",
    "volume": "main",
    "abstract": "Stochastic gradient-based optimization methods, such as L-SVRG and its accelerated variant L-Katyusha (Kovalev et al., 2020), are widely used to train machine learning models. Theoretical and empirical performance of L-SVRG and L-Katyusha can be improved by sampling the observations from a non-uniform distribution Qian et al. (2021). However, to design a desired sampling distribution, Qian et al. (2021) rely on prior knowledge of smoothness constants that can be computationally intractable to obtain in practice when the dimension of the model parameter is high. We propose an adaptive sampling strategy for L-SVRG and L-Katyusha that learns the sampling distribution with little computational overhead, while allowing it to change with iterates, and at the same time does not require any prior knowledge on the problem parameters. We prove convergence guarantees for L-SVRG and L-Katyusha for convex objectives when the sampling distribution changes with iterates. These results show that even without prior information, the proposed adaptive sampling strategy matches, and in some cases even surpasses, the performance of the sampling scheme in Qian et al. (2021). Extensive simulations support our theory and the practical utility of the proposed sampling scheme on real data",
    "checked": true,
    "id": "d2b42b66f53a63a3751e464a00531bc303acc153",
    "semantic_title": "l-svrg and l-katyusha with adaptive sampling",
    "citation_count": 3,
    "authors": [
      "Boxin Zhao",
      "Boxiang Lyu",
      "mladen kolar"
    ]
  },
  "https://openreview.net/forum?id=HG11PAmwQ6": {
    "title": "Quantum Policy Iteration via Amplitude Estimation and Grover Search – Towards Quantum Advantage for Reinforcement Learning",
    "volume": "main",
    "abstract": "We present a full implementation and simulation of a novel quantum reinforcement learning method. Our work is a detailed and formal proof of concept for how quantum algorithms can be used to solve reinforcement learning problems and shows that, given access to error- free, efficient quantum realizations of the agent and environment, quantum methods can yield provable improvements over classical Monte-Carlo based methods in terms of sample complexity. Our approach shows in detail how to combine amplitude estimation and Grover search into a policy evaluation and improvement scheme. We first develop quantum policy evaluation (QPE) which is quadratically more efficient compared to an analogous classi- cal Monte Carlo estimation and is based on a quantum mechanical realization of a finite Markov decision process (MDP). Building on QPE, we derive a quantum policy iteration that repeatedly improves an initial policy using Grover search until the optimum is reached. Finally, we present an implementation of our algorithm for a two-armed bandit MDP which we then simulate",
    "checked": false,
    "id": "b332c9c938b66dede45a4a86aa6841d53dad0e45",
    "semantic_title": "quantum policy iteration via amplitude estimation and grover search - towards quantum advantage for reinforcement learning",
    "citation_count": 27,
    "authors": [
      "Simon Wiedemann",
      "Daniel Hein",
      "Steffen Udluft",
      "Christian B. Mendl"
    ]
  },
  "https://openreview.net/forum?id=tEVpz2xJWX": {
    "title": "Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance",
    "volume": "main",
    "abstract": "Denoising diffusion probabilistic models (DDPMs) are a recent family of generative models that achieve state-of-the-art results. In order to obtain class-conditional generation, it was suggested to guide the diffusion process by gradients from a time-dependent classifier. While the idea is theoretically sound, deep learning-based classifiers are infamously susceptible to gradient-based adversarial attacks. Therefore, while traditional classifiers may achieve good accuracy scores, their gradients are possibly unreliable and might hinder the improvement of the generation results. Recent work discovered that adversarially robust classifiers exhibit gradients that are aligned with human perception, and these could better guide a generative process towards semantically meaningful images. We utilize this observation by defining and training a time-dependent adversarially robust classifier and use it as guidance for a generative diffusion model. In experiments on the highly challenging and diverse ImageNet dataset, our scheme introduces significantly more intelligible intermediate gradients, better alignment with theoretical findings, as well as improved generation results under several evaluation metrics. Furthermore, we conduct an opinion survey whose findings indicate that human raters prefer our method's results",
    "checked": true,
    "id": "fdcd785502144fdee49e4169212962cfd3de4818",
    "semantic_title": "enhancing diffusion-based image synthesis with robust classifier guidance",
    "citation_count": 39,
    "authors": [
      "Bahjat Kawar",
      "Roy Ganz",
      "Michael Elad"
    ]
  },
  "https://openreview.net/forum?id=RjZq6W6FoE": {
    "title": "Improved Overparametrization Bounds for Global Convergence of SGD for Shallow Neural Networks",
    "volume": "main",
    "abstract": "We study the overparametrization bounds required for the global convergence of stochastic gradient descent algorithm for a class of one hidden layer feed-forward neural networks equipped with ReLU activation function. We improve the existing state-of-the-art results in terms of the required hidden layer width. We introduce a new proof technique combining nonlinear analysis with properties of random initializations of the network",
    "checked": true,
    "id": "7d8105bf54b8506c33c5886449e8cc637f2ca4c9",
    "semantic_title": "improved overparametrization bounds for global convergence of sgd for shallow neural networks",
    "citation_count": 1,
    "authors": [
      "Bartłomiej Polaczyk",
      "Jacek Cyranka"
    ]
  },
  "https://openreview.net/forum?id=wmGlMhaBe0": {
    "title": "A Unified View of Masked Image Modeling",
    "volume": "main",
    "abstract": "Masked image modeling has demonstrated great potential to eliminate the label-hungry problem of training large-scale vision Transformers, achieving impressive performance on various downstream tasks. In this work, we propose a unified view of masked image modeling after revisiting existing methods. Under the unified view, we introduce a simple yet effective method, termed as MaskDistill, which reconstructs normalized semantic features from teacher models at the masked positions, conditioning on corrupted input images. Experimental results on image classification and semantic segmentation show that MaskDistill achieves comparable or superior performance than state-of-the-art methods. When using the huge vision Transformer and pretraining 300 epochs, MaskDistill obtains 88.3% fine-tuning top-1 accuracy on ImageNet-1k (224 size) and 58.8 semantic segmentation mIoU metric on ADE20k (512 size). Code is enclosed in the supplementary materials",
    "checked": true,
    "id": "eba51c023f3ae9eeca783893b973db60e7a99a6c",
    "semantic_title": "a unified view of masked image modeling",
    "citation_count": 38,
    "authors": [
      "Zhiliang Peng",
      "Li Dong",
      "Hangbo Bao",
      "Furu Wei",
      "Qixiang Ye"
    ]
  },
  "https://openreview.net/forum?id=11pGlecTz2": {
    "title": "How Robust is Your Fairness? Evaluating and Sustaining Fairness under Unseen Distribution Shifts",
    "volume": "main",
    "abstract": "Increasing concerns have been raised on deep learning fairness in recent years. Existing fairness-aware machine learning methods mainly focus on the fairness of in-distribution data. However, in real-world applications, it is common to have distribution shift between the training and test data. In this paper, we first show that the fairness achieved by existing methods can be easily broken by slight distribution shifts. To solve this problem, we propose a novel fairness learning method termed CUrvature MAtching (CUMA), which can achieve robust fairness generalizable to unseen domains with unknown distributional shifts. Specifically, CUMA enforces the model to have similar generalization ability on the majority and minority groups, by matching the loss curvature distributions of the two groups. We evaluate our method on three popular fairness datasets. Compared with existing methods, CUMA achieves superior fairness under unseen distribution shifts, without sacrificing either the overall accuracy or the in-distribution fairness",
    "checked": true,
    "id": "f86dd357dd183ded38167d98ed2038c5894f855c",
    "semantic_title": "how robust is your fairness? evaluating and sustaining fairness under unseen distribution shifts",
    "citation_count": 11,
    "authors": [
      "Haotao Wang",
      "Junyuan Hong",
      "Jiayu Zhou",
      "Zhangyang Wang"
    ]
  },
  "https://openreview.net/forum?id=OzGIu4T4Cz": {
    "title": "Leveraging Demonstrations with Latent Space Priors",
    "volume": "main",
    "abstract": "Demonstrations provide insight into relevant state or action space regions, bearing great potential to boost the efficiency and practicality of reinforcement learning agents. In this work, we propose to leverage demonstration datasets by combining skill learning and sequence modeling. Starting with a learned joint latent space, we separately train a generative model of demonstration sequences and an accompanying low-level policy. The sequence model forms a latent space prior over plausible demonstration behaviors to accelerate learning of high-level policies. We show how to acquire such priors from state-only motion capture demonstrations and explore several methods for integrating them into policy learning on transfer tasks. Our experimental results confirm that latent space priors provide significant gains in learning speed and final performance. We benchmark our approach on a set of challenging sparse-reward environments with a complex, simulated humanoid, and on offline RL benchmarks for navigation and object manipulation",
    "checked": true,
    "id": "caa03f47176505fc27e56708c2ce990c5e7abed2",
    "semantic_title": "leveraging demonstrations with latent space priors",
    "citation_count": 6,
    "authors": [
      "Jonas Gehring",
      "Deepak Gopinath",
      "Jungdam Won",
      "Andreas Krause",
      "Gabriel Synnaeve",
      "Nicolas Usunier"
    ]
  },
  "https://openreview.net/forum?id=Gp0pHyUyrb": {
    "title": "Solving Nonconvex-Nonconcave Min-Max Problems exhibiting Weak Minty Solutions",
    "volume": "main",
    "abstract": "We investigate a structured class of nonconvex-nonconcave min-max problems exhibiting so-called \\emph{weak Minty} solutions, a notion which was only recently introduced, but is able to simultaneously capture different generalizations of monotonicity. We prove novel convergence results for a generalized version of the optimistic gradient method (OGDA) in this setting, matching the $1/k$ rate for the best iterate in terms of the squared operator norm recently shown for the extragradient method (EG). In addition we propose an adaptive step size version of EG, which does not require knowledge of the problem parameters",
    "checked": true,
    "id": "4267f395a184a1be00c5c63ce68862b60d059413",
    "semantic_title": "solving nonconvex-nonconcave min-max problems exhibiting weak minty solutions",
    "citation_count": 35,
    "authors": [
      "Axel Böhm"
    ]
  },
  "https://openreview.net/forum?id=3epEbhdgbv": {
    "title": "Extreme Masking for Learning Instance and Distributed Visual Representations",
    "volume": "main",
    "abstract": "The paper presents a scalable approach for learning spatially distributed visual representations over individual tokens and a holistic instance representation simultaneously. We use self-attention blocks to represent spatially distributed tokens, followed by cross-attention blocks to aggregate the holistic instance. The core of the approach is the use of extremely large token masking (75\\%-90\\%) as the data augmentation for supervision. Our model, named ExtreMA, follows the plain BYOL approach where the instance representation from the unmasked subset is trained to predict that from the intact input. Instead of encouraging invariance across inputs, learning requires the model to capture informative variations in an image. The paper makes three contributions: 1) It presents random masking as a strong and computationally efficient data augmentation for siamese representation learning. 2) With multiple sampling per instance, extreme masking greatly speeds up learning and improves performance with more data. 3) ExtreMA obtains stronger linear probing performance than masked modeling methods, and better transfer performance than prior contrastive models",
    "checked": true,
    "id": "81608078b71036556a1643b8f05e1162b5487537",
    "semantic_title": "extreme masking for learning instance and distributed visual representations",
    "citation_count": 23,
    "authors": [
      "Zhirong Wu",
      "Zihang Lai",
      "Xiao Sun",
      "Stephen Lin"
    ]
  },
  "https://openreview.net/forum?id=LBA2Jj5Gqn": {
    "title": "Temperature check: theory and practice for training models with softmax-cross-entropy losses",
    "volume": "main",
    "abstract": "The softmax function combined with a cross-entropy loss is a principled approach to modeling probability distributions that has become ubiquitous in deep learning. The softmax function is defined by a lone hyperparameter, the temperature, that is commonly set to one or regarded as a way to tune model confidence after training; however, less is known about how the temperature impacts training dynamics or generalization performance. In this work we develop a theory of early learning for models trained with softmax-cross-entropy loss and show that the learning dynamics depend crucially on the inverse-temperature $\\beta$ as well as the magnitude of the logits at initialization, $||\\beta\\textbf{z}||_{2}$. We follow up these analytic results with a large-scale empirical study of a variety of model architectures trained on CIFAR10, ImageNet, and IMDB sentiment analysis. We find that generalization performance depends strongly on the temperature, but only weakly on the initial logit magnitude. We provide evidence that the dependence of generalization on $\\beta$ is not due to changes in model confidence, but is a dynamical phenomenon. It follows that the addition of $\\beta$ as a tunable hyperparameter is key to maximizing model performance. Although we find the optimal $\\beta$ to be sensitive to the architecture, experimental results suggest that tuning $\\beta$ over the range $10^{-2}$ to $10^1$ improves performance over all architectures studied. We find that smaller $\\beta$ may lead to better peak performance at the cost of sensitivity to the random seed",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atish Agarwala",
      "Samuel Stern Schoenholz",
      "Jeffrey Pennington",
      "Yann Dauphin"
    ]
  },
  "https://openreview.net/forum?id=QtrjqVIZna": {
    "title": "Fusion of Global and Local Knowledge for Personalized Federated Learning",
    "volume": "main",
    "abstract": "Personalized federated learning, as a variant of federated learning, trains customized models for clients using their heterogeneously distributed data. However, it is still inconclusive about how to design personalized models with better representation of shared global knowledge and personalized pattern. To bridge the gap, we in this paper explore personalized models with low-rank and sparse decomposition. Specifically, we employ proper regularization to extract a low-rank global knowledge representation (GKR), so as to distill global knowledge into a compact representation. Subsequently, we employ a sparse component over the obtained GKR to fuse the personalized pattern into the global knowledge. As a solution, we propose a two-stage proximal-based algorithm named \\textbf{Fed}erated learning with mixed \\textbf{S}parse and \\textbf{L}ow-\\textbf{R}ank representation (FedSLR) to efficiently search for the mixed models. Theoretically, under proper assumptions, we show that the GKR trained by FedSLR can at least sub-linearly converge to a stationary point of the regularized problem, and that the sparse component being fused can converge to its stationary point under proper settings. Extensive experiments also demonstrate the superior empirical performance of FedSLR. Moreover, FedSLR reduces the number of parameters, and lowers the down-link communication complexity, which are all desirable for federated learning algorithms. Source code is available in \\url{https://github.com/huangtiansheng/fedslr}",
    "checked": true,
    "id": "4241a8d9d5b5268493cdb4154f78bda67b0bb4cb",
    "semantic_title": "fusion of global and local knowledge for personalized federated learning",
    "citation_count": 12,
    "authors": [
      "Tiansheng Huang",
      "Li Shen",
      "Yan Sun",
      "Weiwei Lin",
      "Dacheng Tao"
    ]
  },
  "https://openreview.net/forum?id=goPsLn3RVo": {
    "title": "Defense Against Reward Poisoning Attacks in Reinforcement Learning",
    "volume": "main",
    "abstract": "We study defense strategies against reward poisoning attacks in reinforcement learning. As a threat model, we consider cost-effective targeted attacks---these attacks minimally alter rewards to make the attacker's target policy uniquely optimal under the poisoned rewards, with the optimality gap specified by an attack parameter. Our goal is to design agents that are robust against such attacks in terms of the worst-case utility w.r.t. the true, unpoisoned, rewards while computing their policies under the poisoned rewards. We propose an optimization framework for deriving optimal defense policies, both when the attack parameter is known and unknown. For this optimization framework, we first provide characterization results for generic attack cost functions. These results show that the functional form of the attack cost function and the agent's knowledge about it are critical for establishing lower bounds on the agent's performance, as well as for the computational tractability of the defense problem. We then focus on a cost function based on $\\ell_2$ norm, for which we show that the defense problem can be efficiently solved and yields defense policies whose expected returns under the true rewards are lower bounded by their expected returns under the poison rewards. Using simulation-based experiments, we demonstrate the effectiveness and robustness of our defense approach",
    "checked": true,
    "id": "0a26f7a7579415e854324e4caa0c436f63804e83",
    "semantic_title": "defense against reward poisoning attacks in reinforcement learning",
    "citation_count": 28,
    "authors": [
      "Kiarash Banihashem",
      "Adish Singla",
      "Goran Radanovic"
    ]
  },
  "https://openreview.net/forum?id=DHEZuKStzH": {
    "title": "Learning Energy Conserving Dynamics Efficiently with Hamiltonian Gaussian Processes",
    "volume": "main",
    "abstract": "Hamiltonian mechanics is one of the cornerstones of the natural sciences. Recently there has been significant interest in learning Hamiltonian systems in a free-form way directly from trajectory data. Previous methods have tackled the problem of learning from many short, low-noise trajectories, but learning from a small number of long, noisy trajectories, whilst accounting for model uncertainty has not been addressed. In this work, we present a Gaussian process model for Hamiltonian systems with efficient decoupled parameterisation, and introduce an energy-conserving shooting method that allows robust inference from both short and long trajectories. We demonstrate the method's success in learning Hamiltonian systems in various data settings",
    "checked": true,
    "id": "6c542af2ce928b96fe2431cab07f7568991b7d65",
    "semantic_title": "learning energy conserving dynamics efficiently with hamiltonian gaussian processes",
    "citation_count": 2,
    "authors": [
      "Magnus Ross",
      "Markus Heinonen"
    ]
  },
  "https://openreview.net/forum?id=iDxfGaMYVr": {
    "title": "Continual Learning by Modeling Intra-Class Variation",
    "volume": "main",
    "abstract": "It has been observed that neural networks perform poorly when the data or tasks are presented sequentially. Unlike humans, neural networks suffer greatly from catastrophic forgetting, making it impossible to perform life-long learning. To address this issue, memory-based continual learning has been actively studied and stands out as one of the best-performing methods. We examine memory-based continual learning and identify that large variation in the representation space is crucial for avoiding catastrophic forgetting. Motivated by this, we propose to diversify representations by using two types of perturbations: model-agnostic variation (i.e., the variation is generated without the knowledge of the learned neural network) and model-based variation (i.e., the variation is conditioned on the learned neural network). We demonstrate that enlarging representational variation serves as a general principle to improve continual learning. Finally, we perform empirical studies which demonstrate that our method, as a simple plug-and-play component, can consistently improve a number of memory-based continual learning methods by a large margin",
    "checked": true,
    "id": "5a4435f9cb579cb9c4e66e64ffa978e0b9ce7291",
    "semantic_title": "continual learning by modeling intra-class variation",
    "citation_count": 14,
    "authors": [
      "Longhui Yu",
      "Tianyang Hu",
      "Lanqing HONG",
      "Zhen Liu",
      "Adrian Weller",
      "Weiyang Liu"
    ]
  },
  "https://openreview.net/forum?id=v6anjyEDVW": {
    "title": "Costs and Benefits of Fair Regression",
    "volume": "main",
    "abstract": "Real-world applications of machine learning tools in high-stakes domains are often regulated to be fair, in the sense that the predicted target should satisfy some quantitative notion of parity with respect to a protected attribute. However, the exact tradeoff between fairness and accuracy with a real-valued target is not entirely clear. In this paper, we characterize the inherent tradeoff between statistical parity and accuracy in the regression setting by providing a lower bound on the error of any attribute-blind fair regressor. Our lower bound is sharp, algorithm-independent, and admits a simple interpretation: when the moments of the target differ between groups, any fair algorithm has to make an error on at least one of the groups. We further extend this result to give a lower bound on the joint error of any (approximately) fair algorithm, using the Wasserstein distance to measure the quality of the approximation. With our novel lower bound, we also show that the price paid by a fair regressor that does not take the protected attribute as input is less than that of a fair regressor with explicit access to the protected attribute. On the upside, we establish the first connection between individual fairness, accuracy parity, and the Wasserstein distance by showing that if a regressor is individually fair, it also approximately verifies the accuracy parity, where the gap is again given by the Wasserstein distance between the two groups. Inspired by our theoretical results, we develop a practical algorithm for fair regression through the lens of representation learning, and conduct experiments on a real-world dataset to corroborate our findings",
    "checked": true,
    "id": "6096bd1d7108681545098fe136cb8c8429ecfc32",
    "semantic_title": "costs and benefits of fair regression",
    "citation_count": 8,
    "authors": [
      "Han Zhao"
    ]
  },
  "https://openreview.net/forum?id=kJcwlP7BRs": {
    "title": "Transfer Entropy Bottleneck: Learning Sequence to Sequence Information Transfer",
    "volume": "main",
    "abstract": "When presented with a data stream of two statistically dependent variables, predicting the future of one of the variables (the target stream) can benefit from information about both its history and the history of the other variable (the source stream). For example, fluctuations in temperature at a weather station can be predicted using both temperatures and barometric readings. However, a challenge when modelling such data is that it is easy for a neural network to rely on the greatest joint correlations within the target stream, which may ignore a crucial but small information transfer from the source to the target stream. As well, there are often situations where the target stream may have previously been modelled independently and it would be useful to use that model to inform a new joint model. Here, we develop an information bottleneck approach for conditional learning on two dependent streams of data. Our method, which we call Transfer Entropy Bottleneck (TEB), allows one to learn a model that bottlenecks the directed information transferred from the source variable to the target variable, while quantifying this information transfer within the model. As such, TEB provides a useful new information bottleneck approach for modelling two statistically dependent streams of data in order to make predictions about one of them",
    "checked": true,
    "id": "836966bc9bb5bdce1df9de77ca1c5f3e83373b28",
    "semantic_title": "transfer entropy bottleneck: learning sequence to sequence information transfer",
    "citation_count": 4,
    "authors": [
      "Damjan Kalajdzievski",
      "Ximeng Mao",
      "Pascal Fortier-Poisson",
      "Guillaume Lajoie",
      "Blake Aaron Richards"
    ]
  },
  "https://openreview.net/forum?id=bomdTc9HyL": {
    "title": "Transductive Decoupled Variational Inference for Few-Shot Classification",
    "volume": "main",
    "abstract": "The versatility to learn from a handful of samples is the hallmark of human intelligence. Few-shot learning is an endeavour to transcend this capability down to machines. Inspired by the promise and power of probabilistic deep learning, we propose a novel variational inference network for few-shot classification (coined as TRIDENT) to decouple the representation of an image into semantic and label latent variables, and simultaneously infer them in an intertwined fashion. To induce task-awareness, as part of the inference mechanics of TRIDENT, we exploit information across both query and support images of a few-shot task using a novel built-in attention-based transductive feature extraction module (we call AttFEX). Our extensive experimental results corroborate the efficacy of TRIDENT and demonstrate that, using the simplest of backbones, it sets a new state-of-the-art in the most commonly adopted datasets miniImageNet and tieredImageNet (offering up to 4% and 5% improvements, respectively), as well as for the recent challenging cross-domain miniImagenet --> CUB scenario offering a significant margin (up to 20% improvement) beyond the best existing baselines",
    "checked": true,
    "id": "3097de4b5c82c69eb745e5eb54cef03addd32cc6",
    "semantic_title": "transductive decoupled variational inference for few-shot classification",
    "citation_count": 17,
    "authors": [
      "Anuj Rajeeva Singh",
      "Hadi Jamali-Rad"
    ]
  },
  "https://openreview.net/forum?id=IvsGP7xRvm": {
    "title": "Black-Box Prompt Learning for Pre-trained Language Models",
    "volume": "main",
    "abstract": "The increasing scale of general-purpose Pre-trained Language Models (\\textbf{PLMs}) necessitates the study of more efficient adaptation across different downstream tasks. In this paper, we establish a Black-box Discrete Prompt Learning (\\textbf{BDPL}) to resonate with pragmatic interactions between the cloud infrastructure and edge devices. Particularly, instead of fine-tuning the model in the cloud, we adapt PLMs by prompt learning, which efficiently optimizes only a few parameters of the discrete prompts. Moreover, we consider the scenario that we do not have access to the parameters and gradients of the pre-trained models, except for its outputs given inputs. This black-box setting secures the cloud infrastructure from potential attack and misuse to cause a single-point failure, which is preferable to the white-box counterpart by current infrastructures. Under this black-box constraint, we apply a variance-reduced policy gradient algorithm to estimate the gradients of parameters in the categorical distribution of each discrete prompt. In light of our method, the user devices can efficiently tune their tasks by querying the PLMs bounded by a range of API calls. Our experiments on RoBERTa and GPT-3 demonstrate that the proposed algorithm achieves significant improvement on eight benchmarks in a cloud-device collaboration manner. Finally, we conduct in-depth case studies to comprehensively analyze our method in terms of various data sizes, prompt lengths, training budgets, optimization objectives, prompt transferability, and explanations of the learned prompts",
    "checked": true,
    "id": "5faa744dcc28cbbdd9bd67eb703320c6e2d85e52",
    "semantic_title": "black-box prompt learning for pre-trained language models",
    "citation_count": 73,
    "authors": [
      "Shizhe Diao",
      "Zhichao Huang",
      "Ruijia Xu",
      "Xuechun Li",
      "LIN Yong",
      "Xiao Zhou",
      "Tong Zhang"
    ]
  },
  "https://openreview.net/forum?id=Z2L5d9ay4B": {
    "title": "Image Compression with Product Quantized Masked Image Modeling",
    "volume": "main",
    "abstract": "Recent neural compression methods have been based on the popular hyperprior framework. It relies on Scalar Quantization and offers a very strong compression performance. This contrasts from recent advances in image generation and representation learning, where Vector Quantization is more commonly employed. In this work, we attempt to bring these lines of research closer by revisiting vector quantization for image compression. We build upon the VQ-VAE framework and introduce several modifications. First, we replace the vanilla vector quantizer by a product quantizer. This intermediate solution between vector and scalar quantization allows for a much wider set of rate-distortion points: It implicitly defines high-quality quantizers that would otherwise require intractably large codebooks. Second, inspired by the success of Masked Image Modeling (MIM) in the context of self-supervised learning and generative image models, we propose a novel conditional entropy model which improves entropy coding by modelling the co-dependencies of the quantized latent codes. The resulting PQ-MIM model is surprisingly effective: its compression performance on par with recent hyperprior methods. It also outperforms HiFiC in terms of FID and KID metrics when optimized with perceptual losses (e.g. adversarial). Finally, since PQ-MIM is compatible with image generation frameworks, we show qualitatively that it can operate under a hybrid mode between compression and generation, with no further training or finetuning. As a result, we explore the extreme compression regime where an image is compressed into 200 bytes, i.e., less than a tweet",
    "checked": true,
    "id": "dd77326d15fc524de4c0686237c9e9fafe5a511c",
    "semantic_title": "image compression with product quantized masked image modeling",
    "citation_count": 32,
    "authors": [
      "Alaaeldin El-Nouby",
      "Matthew J. Muckley",
      "Karen Ullrich",
      "Ivan Laptev",
      "Jakob Verbeek",
      "Herve Jegou"
    ]
  },
  "https://openreview.net/forum?id=yhGCKUsKJS": {
    "title": "Action Poisoning Attacks on Linear Contextual Bandits",
    "volume": "main",
    "abstract": "Contextual bandit algorithms have many applicants in a variety of scenarios. In order to develop trustworthy contextual bandit systems, understanding the impacts of various adversarial attacks on contextual bandit algorithms is essential. In this paper, we propose a new class of attacks: action poisoning attacks, where an adversary can change the action signal selected by the agent. We design action poisoning attack schemes against disjoint linear contextual bandit algorithms in both white-box and black-box settings. We further analyze the cost of the proposed attack strategies for a very popular and widely used bandit algorithm: LinUCB. We show that, in both white-box and black-box settings, the proposed attack schemes can force the LinUCB agent to pull a target arm very frequently by spending only logarithm cost. We also extend the proposed attack strategies to generalized linear models and show the effectiveness of the proposed strategies",
    "checked": true,
    "id": "70f0ea6c8f3f48235c5230bc5a1d9269969db78b",
    "semantic_title": "action poisoning attacks on linear contextual bandits",
    "citation_count": 1,
    "authors": [
      "Guanlin Liu",
      "Lifeng Lai"
    ]
  },
  "https://openreview.net/forum?id=MKZyHtmfwH": {
    "title": "Mixed effects in machine learning – A flexible mixedML framework to add random effects to supervised machine learning regression",
    "volume": "main",
    "abstract": "Clustered data can frequently be found not only in social and behavioral sciences (e.g., multiple measurements of individuals) but also in typical machine learning problems (e.g., weather forecast in different cities, house prices in different regions). This implies dependencis for observations within one cluster, leading to violations of i.i.d. assumptions, biased estimates, and false inference. A typical approach to address this issue is to include random effects instead of fixed effects. We introduce the general mixedML framework, which includes random effects in supervised regression machine learning models, and present different estimation procedures. A segmentation of the problem allows to include random effects as an additional correction to the standard machine learning regression problem. Thus, the framework can be applied on top of the machine learning task, without the need to change the model or architecture, which distinguishes mixedML from other models in this field. With a simulation study and empirical data sets, we show that the framework produces comparable estimates to typical mixed effects frameworks in the linear case and increases the prediction quality and the gained information of the standard machine learning models in both the linear and non-linear case. Furthermore, the presented estimation procedures significantly decrease estimation time. Compared to other approaches in this area, the framework does not restrict the choice of machine learning algorithms and still includes random effects",
    "checked": false,
    "id": "6d41112b76389f3412176735bbae933033588b0f",
    "semantic_title": "mixed effects in machine learning - a flexible mixedml framework to add random effects to supervised machine learning regression",
    "citation_count": 5,
    "authors": [
      "Pascal Kilian",
      "Sangbeak Ye",
      "Augustin Kelava"
    ]
  },
  "https://openreview.net/forum?id=fTNorIvVXG": {
    "title": "Probing Predictions on OOD Images via Nearest Categories",
    "volume": "main",
    "abstract": "We study out-of-distribution (OOD) prediction behavior of neural networks when they classify images from unseen classes or corrupted images. To probe the OOD behavior, we introduce a new measure, nearest category generalization (NCG), where we compute the fraction of OOD inputs that are classified with the same label as their nearest neighbor in the training set. Our motivation stems from understanding the prediction patterns of adversarially robust networks, since previous work has identified unexpected consequences of training to be robust to norm-bounded perturbations. We find that robust networks have consistently higher NCG accuracy than natural training, even when the OOD data is much farther away than the robustness radius. This implies that the local regularization of robust training has a significant impact on the network's decision regions. We replicate our findings using many datasets, comparing new and existing training methods. Overall, adversarially robust networks resemble a nearest neighbor classifier when it comes to OOD data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao-Yuan Yang",
      "Cyrus Rashtchian",
      "Ruslan Salakhutdinov",
      "Kamalika Chaudhuri"
    ]
  },
  "https://openreview.net/forum?id=k5m8xXTOrC": {
    "title": "Solving a Special Type of Optimal Transport Problem by a Modified Hungarian Algorithm",
    "volume": "main",
    "abstract": "Computing the empirical Wasserstein distance in the Wasserstein-distance-based independence test is an optimal transport (OT) problem with a special structure. This observation inspires us to study a special type of OT problem and propose {\\it a modified Hungarian algorithm} to solve it {\\it exactly}. For the OT problem involving two marginals with $m$ and $n$ atoms ($m\\geq n$), respectively, the computational complexity of the proposed algorithm is $\\mathcal{O}(m^2n)$. Computing the empirical Wasserstein distance in the independence test requires solving this special type of OT problem, where $m=n^2$. The associated computational complexity of the proposed algorithm is $\\mathcal{O}(n^5)$, while the order of applying the classic Hungarian algorithm is $\\mathcal{O}(n^6)$. In addition to the aforementioned special type of OT problem, it is shown that the modified Hungarian algorithm could be adopted to solve a wider range of OT problems. Broader applications of the proposed algorithm are discussed---solving the one-to-many assignment problem and the many-to-many assignment problem. We conduct numerical experiments to validate our theoretical results. The experiment results demonstrate that the proposed modified Hungarian algorithm compares favorably with the Hungarian algorithm and the well-known Sinkhorn algorithm, and the network simplex algorithm",
    "checked": true,
    "id": "074a0abc36181f666a8e08b951365a4b5a110e6a",
    "semantic_title": "solving a special type of optimal transport problem by a modified hungarian algorithm",
    "citation_count": 5,
    "authors": [
      "Yiling Xie",
      "Yiling Luo",
      "Xiaoming Huo"
    ]
  },
  "https://openreview.net/forum?id=WoXJFsJ6Zw": {
    "title": "AI-SARAH: Adaptive and Implicit Stochastic Recursive Gradient Methods",
    "volume": "main",
    "abstract": "We present AI-SARAH, a practical variant of SARAH. As a variant of SARAH, this algorithm employs the stochastic recursive gradient yet adjusts step-size based on local geometry. AI-SARAH implicitly computes step-size and efficiently estimates local Lipschitz smoothness of stochastic functions. It is fully adaptive, tune-free, straightforward to implement, and computationally efficient. We provide technical insight and intuitive illustrations on its design and convergence. We conduct extensive empirical analysis and demonstrate its strong performance compared with its classical counterparts and other state-of-the-art first-order methods in solving convex machine learning problems",
    "checked": true,
    "id": "ebf1782199646426259bc98538afc4af67575dff",
    "semantic_title": "ai-sarah: adaptive and implicit stochastic recursive gradient methods",
    "citation_count": 13,
    "authors": [
      "Zheng Shi",
      "Abdurakhmon Sadiev",
      "Nicolas Loizou",
      "Peter Richtárik",
      "Martin Takáč"
    ]
  },
  "https://openreview.net/forum?id=oXmwAPlbVw": {
    "title": "U-Statistics for Importance-Weighted Variational Inference",
    "volume": "main",
    "abstract": "We propose the use of U-statistics to reduce variance for gradient estimation in importance-weighted variational inference. The key observation is that, given a base gradient estimator that requires $m > 1$ samples and a total of $n > m$ samples to be used for estimation, lower variance is achieved by averaging the base estimator on overlapping batches of size $m$ than disjoint batches, as currently done. We use classical U-statistic theory to analyze the variance reduction, and propose novel approximations with theoretical guarantees to ensure computational efficiency. We find empirically that U-statistic variance reduction can lead to modest to significant improvements in inference performance on a range of models, with little computational cost",
    "checked": true,
    "id": "a7a14cd01e175d6fea41bcc89d21208d7977b165",
    "semantic_title": "u-statistics for importance-weighted variational inference",
    "citation_count": 1,
    "authors": [
      "Javier Burroni",
      "Kenta Takatsu",
      "Justin Domke",
      "Daniel Sheldon"
    ]
  },
  "https://openreview.net/forum?id=BVi6MhKO0G": {
    "title": "OADAT: Experimental and Synthetic Clinical Optoacoustic Data for Standardized Image Processing",
    "volume": "main",
    "abstract": "Optoacoustic (OA) imaging is based on excitation of biological tissues with nanosecond-duration laser pulses followed by subsequent detection of ultrasound waves generated via light-absorption-mediated thermoelastic expansion. OA imaging features a powerful combination between rich optical contrast and high resolution in deep tissues. This enabled the exploration of a number of attractive new applications both in clinical and laboratory settings. However, no standardized datasets generated with different types of experimental set-up and associated processing methods are available to facilitate advances in broader applications of OA in clinical settings. This complicates an objective comparison between new and established data processing methods, often leading to qualitative results and arbitrary interpretations of the data. In this paper, we provide both experimental and synthetic OA raw signals and reconstructed image domain datasets rendered with different experimental parameters and tomographic acquisition geometries. We further provide trained neural networks to tackle three important challenges related to OA image processing, namely accurate reconstruction under limited view tomographic conditions, removal of spatial undersampling artifacts and anatomical segmentation for improved image reconstruction. Specifically, we define 44 experiments corresponding to the aforementioned challenges as benchmarks to be used as a reference for the development of more advanced processing methods",
    "checked": true,
    "id": "4ffd175b6a3001cfadf1756c99bd8eb8ad8b3d48",
    "semantic_title": "oadat: experimental and synthetic clinical optoacoustic data for standardized image processing",
    "citation_count": 5,
    "authors": [
      "Firat Ozdemir",
      "Berkan Lafci",
      "Xose Luis Dean-Ben",
      "Daniel Razansky",
      "Fernando Perez-Cruz"
    ]
  },
  "https://openreview.net/forum?id=mNEqiC924B": {
    "title": "Stacking Diverse Architectures to Improve Machine Translation",
    "volume": "main",
    "abstract": "Repeated applications of the same neural block primarily based on self-attention characterize the current state-of-the-art in neural architectures for machine translation. In such architectures the decoder adopts a masked version of the same encoding block. Although simple this strategy doesn't encode the various inductive biases such as locality that arise from alternative architectures and that are central to the modelling of translation. We propose Lasagna, an encoder-decoder model that aims to combine the inductive benefits of different architectures by layering multiple instances of different blocks. Lasagna's encoder first grows the representation from local to mid-sized using convolutional blocks and only then applies a pair of final self-attention blocks. Lasagna's decoder uses only convolutional blocks that attend to the encoder representation. On a large suit of machine translation tasks, we find that Lasagna not only matches or outperforms the Transformer baseline, but it does so more efficiently thanks to widespread use of the efficient convolutional blocks. These findings suggest that the widespread use of uniform architectures may be suboptimal in certain scenarios and exploiting the diversity of inductive architectural biases can lead to substantial gains",
    "checked": true,
    "id": "79c1d260493bda96218742a51e19b58a6df40d41",
    "semantic_title": "stacking diverse architectures to improve machine translation",
    "citation_count": 0,
    "authors": [
      "Andrea Schioppa",
      "Nal Kalchbrenner"
    ]
  },
  "https://openreview.net/forum?id=GbkWw3jwL9": {
    "title": "Contrastive Search Is What You Need For Neural Text Generation",
    "volume": "main",
    "abstract": "Generating text with autoregressive language models (LMs) is of great importance to many natural language processing (NLP) applications. Previous solutions for this task often produce text that contains degenerative expressions (Welleck et al., 2020) or lacks semantic consistency (Basu et al., 2021). Recently, Su et al. (2022b) introduced a new decoding method, contrastive search, based on the isotropic representation space of the language model and obtained new state of the art on various benchmarks. Additionally, Su et al. (2022b) argued that the representations of autoregressive LMs (e.g. GPT-2) are intrinsically anisotropic which is also shared by previous studies (Ethayarajh, 2019). Therefore, to ensure the language model follows an isotropic distribution, Su et al. (2022b) proposed a contrastive learning scheme, SimCTG, which calibrates the language model's representations through additional training. In this study, we first answer the question: \"Are autoregressive LMs really anisotropic?\". To this end, we extensively evaluate the isotropy of LMs across 16 major languages. Surprisingly, we find that the anisotropic problem only exists in the two specific English GPT-2-small/medium models. On the other hand, all other evaluated LMs are naturally isotropic which is in contrast to the conclusion drawn by previous studies (Ethayarajh, 2019; Su et al., 2022b). Based on our findings, we further assess the contrastive search decoding method using off-the-shelf LMs on four generation tasks across 16 languages. Our experimental results demonstrate that contrastive search significantly outperforms previous decoding methods without any additional training. More notably, on 12 out of the 16 evaluated languages, contrastive search performs comparably with human-level performances as judged by human evaluations",
    "checked": true,
    "id": "5697a0ede5425954d48daa6e1893dc87bd7d8be7",
    "semantic_title": "contrastive search is what you need for neural text generation",
    "citation_count": 57,
    "authors": [
      "Yixuan Su",
      "Nigel Collier"
    ]
  },
  "https://openreview.net/forum?id=tBl4yBEjKi": {
    "title": "Separable Self-attention for Mobile Vision Transformers",
    "volume": "main",
    "abstract": "Mobile vision transformers (MobileViT) can achieve state-of-the-art performance across several mobile vision tasks, including classification and detection. Though these models have fewer parameters, they have high latency as compared to convolutional neural network-based models. The main efficiency bottleneck in MobileViT is the multi-headed self-attention (MHA) in transformers, which requires $O(k^2)$ time complexity with respect to the number of tokens (or patches) $k$. Moreover, MHA requires costly operations (e.g., batch-wise matrix multiplication) for computing self-attention, impacting latency on resource-constrained devices. This paper introduces a separable self-attention method with linear complexity, i.e. $O(k)$. A simple yet effective characteristic of the proposed method is that it uses element-wise operations for computing self-attention, making it a good choice for resource-constrained devices. The improved model, MobileViTv2, is state-of-the-art on several mobile vision tasks, including ImageNet object classification and MS-COCO object detection. With about three million parameters, MobileViTv2 achieves a top-1 accuracy of 75.6% on the ImageNet dataset, outperforming MobileViT by about 1% while running $3.2\\times$ faster on a mobile device. Our source code is available at: https://github.com/apple/ml-cvnets",
    "checked": true,
    "id": "066c143b427571fb5568f2c581ea9066478d2e55",
    "semantic_title": "separable self-attention for mobile vision transformers",
    "citation_count": 283,
    "authors": [
      "Sachin Mehta",
      "Mohammad Rastegari"
    ]
  },
  "https://openreview.net/forum?id=iEq6lhG4O3": {
    "title": "A Flexible Nadaraya-Watson Head Can Offer Explainable and Calibrated Classification",
    "volume": "main",
    "abstract": "In this paper, we empirically analyze a simple, non-learnable, and nonparametric Nadaraya-Watson (NW) prediction head that can be used with any neural network architecture. In the NW head, the prediction is a weighted average of labels from a support set. The weights are computed from distances between the query feature and support features. This is in contrast to the dominant approach of using a learnable classification head (e.g., a fully-connected layer) on the features, which can be challenging to interpret and can yield poorly calibrated predictions. Our empirical results on an array of computer vision tasks demonstrate that the NW head can yield better calibration with comparable accuracy compared to its parametric counterpart, particularly in data-limited settings. To further increase inference-time efficiency, we propose a simple approach that involves a clustering step run on the training set to create a relatively small distilled support set. Furthermore, we explore two means of interpretability/explainability that fall naturally from the NW head. The first is the label weights, and the second is our novel concept of the ``support influence function,'' which is an easy-to-compute metric that quantifies the influence of a support element on the prediction for a given query. As we demonstrate in our experiments, the influence function can allow the user to debug a trained model. We believe that the NW head is a flexible, interpretable, and highly useful building block that can be used in a range of applications",
    "checked": true,
    "id": "17e588d07af5df4dc737a8dc49eeac25c2dc89a7",
    "semantic_title": "a flexible nadaraya-watson head can offer explainable and calibrated classification",
    "citation_count": 5,
    "authors": [
      "Alan Q. Wang",
      "Mert R. Sabuncu"
    ]
  },
  "https://openreview.net/forum?id=hHiIbk7ApW": {
    "title": "Diffusion-based Time Series Imputation and Forecasting with Structured State Space Models",
    "volume": "main",
    "abstract": "The imputation of missing values represents a significant obstacle for many real-world data analysis pipelines. Here, we focus on time series data and put forward SSSD, an imputation model that relies on two emerging technologies, (conditional) diffusion models as state-ofthe-art generative models and structured state space models as internal model architecture, which are particularly suited to capture long-term dependencies in time series data. We demonstrate that SSSD matches or even exceeds state-of-the-art probabilistic imputation and forecasting performance on a broad range of data sets and different missingness scenarios, including the challenging blackout-missing scenarios, where prior approaches failed to provide meaningful results",
    "checked": true,
    "id": "ef7993ab30d0a8afabb4ebab080e471c0d5c743c",
    "semantic_title": "diffusion-based time series imputation and forecasting with structured state space models",
    "citation_count": 187,
    "authors": [
      "Juan Lopez Alcaraz",
      "Nils Strodthoff"
    ]
  },
  "https://openreview.net/forum?id=oe4dl4MCGY": {
    "title": "Robust Hybrid Learning With Expert Augmentation",
    "volume": "main",
    "abstract": "Hybrid modelling reduces the misspecification of expert models by combining them with machine learning (ML) components learned from data. Similarly to many ML algorithms, hybrid model performance guarantees are limited to the training distribution. Leveraging the insight that the expert model is usually valid even outside the training domain, we overcome this limitation by introducing a hybrid data augmentation strategy termed \\textit{expert augmentation}. Based on a probabilistic formalization of hybrid modelling, we demonstrate that expert augmentation, which can be incorporated into existing hybrid systems, improves generalization. We empirically validate the expert augmentation on three controlled experiments modelling dynamical systems with ordinary and partial differential equations. Finally, we assess the potential real-world applicability of expert augmentation on a dataset of a real double pendulum",
    "checked": true,
    "id": "728df8e3f3584c5bb04528b5df1aba83ae78a69b",
    "semantic_title": "robust hybrid learning with expert augmentation",
    "citation_count": 10,
    "authors": [
      "Antoine Wehenkel",
      "Jens Behrmann",
      "Hsiang Hsu",
      "Guillermo Sapiro",
      "Gilles Louppe",
      "Joern-Henrik Jacobsen"
    ]
  },
  "https://openreview.net/forum?id=paguBNtqiO": {
    "title": "Improved Differentially Private Riemannian Optimization: Fast Sampling and Variance Reduction",
    "volume": "main",
    "abstract": "A common step in differentially private ({DP}) Riemannian optimization is sampling from the (tangent) Gaussian distribution as noise needs to be generated in the tangent space to perturb the gradient. In this regard, existing works either use the Markov chain Monte Carlo ({MCMC}) sampling or explicit basis construction based sampling methods on the tangent space. This becomes a computational bottleneck in the practical use of {DP} Riemannian optimization, especially when performing stochastic optimization. In this paper, we discuss different sampling strategies and develop efficient sampling procedures by exploiting linear isometry between tangent spaces and show them to be orders of magnitude faster than both the {MCMC} and sampling using explicit basis construction. Furthermore, we develop the {DP} Riemannian stochastic variance reduced gradient algorithm and compare it with DP Riemannian gradient descent and stochastic gradient descent algorithms on various problems",
    "checked": true,
    "id": "df539aa087692055975d2d6f58a3bf2ed618360e",
    "semantic_title": "improved differentially private riemannian optimization: fast sampling and variance reduction",
    "citation_count": 6,
    "authors": [
      "Saiteja Utpala",
      "Andi Han",
      "Pratik Jawanpuria",
      "Bamdev Mishra"
    ]
  },
  "https://openreview.net/forum?id=lmr2WwlaFc": {
    "title": "Dirichlet Mechanism for Differentially Private KL Divergence Minimization",
    "volume": "main",
    "abstract": "Given an empirical distribution $f(x)$ of sensitive data $x$, we consider the task of minimizing $F(y) = D_{\\text{KL}} (f(x)\\Vert y)$ over a probability simplex, while protecting the privacy of $x$. We observe that, if we take the exponential mechanism and use the KL divergence as the loss function, then the resulting algorithm is the $Dirichlet\\text{ }mechanism$ that outputs a single draw from a Dirichlet distribution. Motivated by this, we propose a Rényi differentially private (RDP) algorithm that employs the Dirichlet mechanism to solve the KL divergence minimization task. In addition, given $f(x)$ as above and $\\hat{y}$ an output of the Dirichlet mechanism, we prove a probability tail bound on $D_{\\text{KL}} (f(x)\\Vert \\hat{y})$, which is then used to derive a lower bound for the sample complexity of our RDP algorithm. Experiments on real-world datasets demonstrate advantages of our algorithm over Gaussian and Laplace mechanisms in supervised classification and maximum likelihood estimation",
    "checked": true,
    "id": "3da3ab4c7e4fb2c16d7ea1aa918af2fecd9da52a",
    "semantic_title": "dirichlet mechanism for differentially private kl divergence minimization",
    "citation_count": 1,
    "authors": [
      "Donlapark Ponnoprat"
    ]
  },
  "https://openreview.net/forum?id=cKsKXR28cG": {
    "title": "Regularized Training of Intermediate Layers for Generative Models for Inverse Problems",
    "volume": "main",
    "abstract": "Generative Adversarial Networks (GANs) have been shown to be powerful and flexible priors when solving inverse problems. One challenge of using them is overcoming representation error, the fundamental limitation of the network in representing any particular signal. Recently, multiple proposed inversion algorithms reduce representation error by optimizing over intermediate layer representations. These methods are typically applied to generative models that were trained agnostic of the downstream inversion algorithm. In our work, we introduce a principle that if a generative model is intended for inversion using an algorithm based on optimization of intermediate layers, it should be trained in a way that regularizes those intermediate layers. We instantiate this principle for two notable recent inversion algorithms: Intermediate Layer Optimization and the Multi-Code GAN prior. For both of these inversion algorithms, we introduce a new regularized GAN training algorithm and demonstrate that the learned generative model results in lower reconstruction errors across a wide range of under sampling ratios when solving compressed sensing, inpainting, and super-resolution problems",
    "checked": true,
    "id": "470172601b574787c8c7c9563ad7cc9e9130fdbb",
    "semantic_title": "regularized training of intermediate layers for generative models for inverse problems",
    "citation_count": 2,
    "authors": [
      "Sean Gunn",
      "Jorio Cocola",
      "PAul HAnd"
    ]
  },
  "https://openreview.net/forum?id=6dsvH7pQHH": {
    "title": "Layerwise Bregman Representation Learning of Neural Networks with Applications to Knowledge Distillation",
    "volume": "main",
    "abstract": "We propose a new method for layerwise representation learning of a trained neural network that conforms to the non-linearity of the layer's transfer function. In particular, we form a Bregman divergence based on the convex function induced by the layer's transfer function and construct an extension of the original Bregman PCA formulation by incorporating a mean vector and revising the normalization constraint on the principal directions. These modifications allow exporting the learned representation as a fixed layer with a non-linearity. As an application to knowledge distillation, we cast the learning problem for the student network as predicting the compression coefficients of the teacher's representations, which is then passed as the input to the imported layer. Our empirical findings indicate that our approach is substantially more effective for transferring information between networks than typical teacher-student training that uses the teacher's soft labels",
    "checked": true,
    "id": "fde7d07775d937e80fad0796ed7480714c8f9720",
    "semantic_title": "layerwise bregman representation learning of neural networks with applications to knowledge distillation",
    "citation_count": 2,
    "authors": [
      "Ehsan Amid",
      "Rohan Anil",
      "Christopher Fifty",
      "Manfred K Warmuth"
    ]
  },
  "https://openreview.net/forum?id=WN1O2MJDST": {
    "title": "Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural Networks",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) are often trained on the premise that the complete training data set is provided ahead of time. However, in real-world scenarios, data often arrive in chunks over time. This leads to important considerations about the optimal strategy for training DNNs, such as whether to fine-tune them with each chunk of incoming data (warm-start) or to retrain them from scratch with the entire corpus of data whenever a new chunk is available. While employing the latter for training can be resource-intensive, recent work has pointed out the lack of generalization in warm-start models. Therefore, to strike a balance between efficiency and generalization, we introduce \"Learn, Unlearn, and Relearn (LURE)\" an online learning paradigm for DNNs. LURE interchanges between the unlearning phase, which selectively forgets the undesirable information in the model through weight reinitialization in a data-dependent manner, and the relearning phase, which emphasizes learning on generalizable features. We show that our training paradigm provides consistent performance gains across datasets in both classification and few-shot settings. We further show that it leads to more robust and well-calibrated models",
    "checked": true,
    "id": "c92eed4bfe1f55ada9e488f26cb3c4c9231e6b27",
    "semantic_title": "learn, unlearn and relearn: an online learning paradigm for deep neural networks",
    "citation_count": 8,
    "authors": [
      "Vijaya Raghavan T Ramkumar",
      "Elahe Arani",
      "Bahram Zonooz"
    ]
  },
  "https://openreview.net/forum?id=5II12ypVQo": {
    "title": "KRADA: Known-region-aware Domain Alignment for Open-set Domain Adaptation in Semantic Segmentation",
    "volume": "main",
    "abstract": "In semantic segmentation, we aim to train a pixel-level classifier to assign category labels to all pixels in an image, where labeled training images and unlabeled test images are from the same distribution and share the same label set. However, in an open world, the unlabeled test images probably contain unknown categories and have different distributions from the labeled images. Hence, in this paper, we consider a new, more realistic, and more challenging problem setting where the pixel-level classifier has to be trained with labeled images and unlabeled open-world images—we name it open world semantic segmentation (OSS). In OSS, the trained classifier is expected to identify unknown-class pixels and classify known-class pixels well. To solve OSS, we first investigate which distribution that unknown-class pixels obey. Then, motivated by the goodness-of-fit test, we use statistical measurements to show how a pixel fits the distribution of an unknown class and select highly-fitted pixels to form the unknown region in each test image. Eventually, we propose an end-to-end learning framework, known-region-aware domain alignment (KRADA), to distinguish unknown classes while aligning the distributions of known classes in labeled and unlabeled open-world images. The effectiveness of KRADA has been verified on two synthetic tasks and one COVID-19 segmentation task",
    "checked": true,
    "id": "ef7628d87ebcf1746f0cb6d1bd0820be6b579bd4",
    "semantic_title": "krada: known-region-aware domain alignment for open-set domain adaptation in semantic segmentation",
    "citation_count": 1,
    "authors": [
      "Chenhong Zhou",
      "Feng Liu",
      "Chen Gong",
      "Rongfei Zeng",
      "Tongliang Liu",
      "William Cheung",
      "Bo Han"
    ]
  },
  "https://openreview.net/forum?id=gZna3IiGfl": {
    "title": "Mean-field analysis for heavy ball methods: Dropout-stability, connectivity, and global convergence",
    "volume": "main",
    "abstract": "The stochastic heavy ball method (SHB), also known as stochastic gradient descent (SGD) with Polyak's momentum, is widely used in training neural networks. However, despite the remarkable success of such algorithm in practice, its theoretical characterization remains limited. In this paper, we focus on neural networks with two and three layers and provide a rigorous understanding of the properties of the solutions found by SHB: \\emph{(i)} stability after dropping out part of the neurons, \\emph{(ii)} connectivity along a low-loss path, and \\emph{(iii)} convergence to the global optimum. To achieve this goal, we take a mean-field view and relate the SHB dynamics to a certain partial differential equation in the limit of large network widths. This mean-field perspective has inspired a recent line of work focusing on SGD while, in contrast, our paper considers an algorithm with momentum. More specifically, after proving existence and uniqueness of the limit differential equations, we show convergence to the global optimum and give a quantitative bound between the mean-field limit and the SHB dynamics of a finite-width network. Armed with this last bound, we are able to establish the dropout-stability and connectivity of SHB solutions",
    "checked": true,
    "id": "24505a45ec64b76710522a2656091d7596429588",
    "semantic_title": "mean-field analysis for heavy ball methods: dropout-stability, connectivity, and global convergence",
    "citation_count": 3,
    "authors": [
      "Diyuan Wu",
      "Vyacheslav Kungurtsev",
      "Marco Mondelli"
    ]
  },
  "https://openreview.net/forum?id=RZveYHgZbu": {
    "title": "Signed Graph Neural Networks: A Frequency Perspective",
    "volume": "main",
    "abstract": "Graph convolutional networks (GCNs) and its variants are designed for unsigned graphs containing only positive links. Many existing GCNs have been derived from the spectral domain analysis of signals lying over (unsigned) graphs and in each convolution layer they perform low-pass filtering of the input features followed by a learnable linear transformation. Their extension to signed graphs with positive as well as negative links imposes multiple issues including computational irregularities and ambiguous frequency interpretation, making the design of computationally efficient low pass filters challenging. In this paper, we address these issues via spectral analysis of signed graphs and propose two different signed graph neural networks, one keeps only low-frequency information and one also retains high-frequency information. We further introduce magnetic signed Laplacian and use its eigendecomposition for spectral analysis of directed signed graphs. We test our methods for node classification and link sign prediction tasks on signed graphs and achieve state-of-the-art performances",
    "checked": true,
    "id": "f28470068c164e0e4d1d8c9fa3fe4213253dede1",
    "semantic_title": "signed graph neural networks: a frequency perspective",
    "citation_count": 11,
    "authors": [
      "Rahul Singh",
      "Yongxin Chen"
    ]
  },
  "https://openreview.net/forum?id=TNocbXm5MZ": {
    "title": "Guaranteed Discovery of Control-Endogenous Latent States with Multi-Step Inverse Models",
    "volume": "main",
    "abstract": "In many sequential decision-making tasks, the agent is not able to model the full complexity of the world, which consists of multitudes of relevant and irrelevant information. For example, a person walking along a city street who tries to model all aspects of the world would quickly be overwhelmed by a multitude of shops, cars, and people moving in and out of view, each following their own complex and inscrutable dynamics. Is it possible to turn the agent's firehose of sensory information into a minimal latent state that is both necessary and sufficient for an agent to successfully act in the world? We formulate this question concretely, and propose the Agent Control-Endogenous State Discovery algorithm (AC-State), which has theoretical guarantees and is practically demonstrated to discover the minimal control-endogenous latent state which contains all of the information necessary for controlling the agent, while fully discarding all irrelevant information. This algorithm consists of a multi-step inverse model (predicting actions from distant observations) with an information bottleneck. AC-State enables localization, exploration, and navigation without reward or demonstrations. We demonstrate the discovery of the control-endogenous latent state in three domains: localizing a robot arm with distractions (e.g., changing lighting conditions and background), exploring a maze alongside other agents, and navigating in the Matterport house simulator",
    "checked": true,
    "id": "df2499f13dd98d4ce7a46888834084798c9930e4",
    "semantic_title": "guaranteed discovery of control-endogenous latent states with multi-step inverse models",
    "citation_count": 25,
    "authors": [
      "Alex Lamb",
      "Riashat Islam",
      "Yonathan Efroni",
      "Aniket Rajiv Didolkar",
      "Dipendra Misra",
      "Dylan J Foster",
      "Lekan P Molu",
      "Rajan Chari",
      "Akshay Krishnamurthy",
      "John Langford"
    ]
  },
  "https://openreview.net/forum?id=rm0zIzlhcX": {
    "title": "Beyond Intuition: Rethinking Token Attributions inside Transformers",
    "volume": "main",
    "abstract": "The multi-head attention mechanism, or rather the Transformer-based models have always been under the spotlight, not only in the domain of text processing, but also for computer vision. Several works have recently been proposed around exploring the token attributions along the intrinsic decision process. However, the ambiguity of the expression formulation can lead to an accumulation of error, which makes the interpretation less trustworthy and less applicable to different variants. In this work, we propose a novel method to approximate token contributions inside Transformers. We start from the partial derivative to each token, divide the interpretation process into attention perception and reasoning feedback with the chain rule and explore each part individually with explicit mathematical derivations. In attention perception, we propose the head-wise and token-wise approximations in order to learn how the tokens interact to form the pooled vector. As for reasoning feedback, we adopt a noise-decreasing strategy by applying the integrated gradients to the last attention map. Our method is further validated qualitatively and quantitatively through the faithfulness evaluations across different settings: single modality (BERT and ViT) and bi-modality (CLIP), different model sizes (ViT-L) and different pooling strategies (ViT-MAE) to demonstrate the broad applicability and clear improvements over existing methods",
    "checked": true,
    "id": "7920371e6b296460183b00f8d31796a5664db582",
    "semantic_title": "beyond intuition: rethinking token attributions inside transformers",
    "citation_count": 12,
    "authors": [
      "Jiamin Chen",
      "Xuhong Li",
      "Lei Yu",
      "Dejing Dou",
      "Haoyi Xiong"
    ]
  },
  "https://openreview.net/forum?id=KQRv0O8iW4": {
    "title": "Finite-Time Analysis of Decentralized Single-Timescale Actor-Critic",
    "volume": "main",
    "abstract": "Decentralized Actor-Critic (AC) algorithms have been widely utilized for multi-agent reinforcement learning (MARL) and have achieved remarkable success. Apart from its empirical success, the theoretical convergence property of decentralized AC algorithms is largely unexplored. Most of the existing finite-time convergence results are derived based on either double-loop update or two-timescale step sizes rule, and this is the case even for centralized AC algorithm under a single-agent setting. In practice, the *single-timescale* update is widely utilized, where actor and critic are updated in an alternating manner with step sizes being of the same order. In this work, we study a decentralized *single-timescale* AC algorithm. Theoretically, using linear approximation for value and reward estimation, we show that the algorithm has sample complexity of $\\tilde{\\mathcal{O}}(\\varepsilon^{-2})$ under Markovian sampling, which matches the optimal complexity with a double-loop implementation (here, $\\tilde{\\mathcal{O}}$ hides a logarithmic term). When we reduce to the single-agent setting, our result yields new sample complexity for centralized AC using a single-timescale update scheme. The central to establishing our complexity results is *the hidden smoothness of the optimal critic variable* we revealed. We also provide a local action privacy-preserving version of our algorithm and its analysis. Finally, we conduct experiments to show the superiority of our algorithm over the existing decentralized AC algorithms",
    "checked": true,
    "id": "315335df487b6ae65870769b4a40d70c08426b9f",
    "semantic_title": "finite-time analysis of decentralized single-timescale actor-critic",
    "citation_count": 1,
    "authors": [
      "qijun luo",
      "Xiao Li"
    ]
  },
  "https://openreview.net/forum?id=GcO6ugrLKp": {
    "title": "Supervised Feature Selection with Neuron Evolution in Sparse Neural Networks",
    "volume": "main",
    "abstract": "Feature selection that selects an informative subset of variables from data not only enhances the model interpretability and performance but also alleviates the resource demands. Recently, there has been growing attention in feature selection using neural networks. However, existing methods usually suffer from high computational costs when applied to high-dimensional datasets. In this paper, inspired by evolution processes, we propose a novel resource-efficient supervised feature selection method using sparse neural networks, named \"NeuroFS\". By gradually pruning the uninformative features from the input layer of a sparse neural network trained from scratch, NeuroFS derives an informative subset of features efficiently. By performing several experiments on $11$ low and high-dimensional real-world benchmarks of different types, we demonstrate that NeuroFS achieves the highest ranking-based score among the considered state-of-the-art supervised feature selection models. We will make the code publicly available on GitHub after acceptance of the paper",
    "checked": true,
    "id": "42fc11d7a5d317bb467afa3b6f36dc5f3136b33f",
    "semantic_title": "supervised feature selection with neuron evolution in sparse neural networks",
    "citation_count": 12,
    "authors": [
      "Zahra Atashgahi",
      "Xuhao Zhang",
      "Neil Kichler",
      "Shiwei Liu",
      "Lu Yin",
      "Mykola Pechenizkiy",
      "Raymond Veldhuis",
      "Decebal Constantin Mocanu"
    ]
  },
  "https://openreview.net/forum?id=mAx8QqZ14f": {
    "title": "Differentially Private Fréchet Mean on the Manifold of Symmetric Positive Definite (SPD) Matrices with log-Euclidean Metric",
    "volume": "main",
    "abstract": "Differential privacy has become crucial in the real-world deployment of statistical and machine learning algorithms with rigorous privacy guarantees. The earliest statistical queries, for which differential privacy mechanisms have been developed, were for the release of the sample mean. In Geometric Statistics, the sample Fréchet mean represents one of the most fundamental statistical summaries, as it generalizes the sample mean for data belonging to nonlinear manifolds. In that spirit, the only geometric statistical query for which a differential privacy mechanism has been developed, so far, is for the release of the sample Fréchet mean: the \\emph{Riemannian Laplace mechanism} was recently proposed to privatize the Fréchet mean on complete Riemannian manifolds. In many fields, the manifold of Symmetric Positive Definite (SPD) matrices is used to model data spaces, including in medical imaging where privacy requirements are key. We propose a novel, simple and fast mechanism - the \\emph{tangent Gaussian mechanism} - to compute a differentially private Fréchet mean on the SPD manifold endowed with the log-Euclidean Riemannian metric. We show that our new mechanism has significantly better utility and is computationally efficient --- as confirmed by extensive experiments",
    "checked": true,
    "id": "d2f64a8c7f8f4ec30c048e7223488d514388a1f1",
    "semantic_title": "differentially private fréchet mean on the manifold of symmetric positive definite (spd) matrices with log-euclidean metric",
    "citation_count": 8,
    "authors": [
      "Saiteja Utpala",
      "Praneeth Vepakomma",
      "Nina Miolane"
    ]
  },
  "https://openreview.net/forum?id=UntUoeLwwu": {
    "title": "Tailoring to the Tails: Risk Measures for Fine-Grained Tail Sensitivity",
    "volume": "main",
    "abstract": "Expected risk minimization (ERM) is at the core of many machine learning systems. This means that the risk inherent in a loss distribution is summarized using a single number - its average. In this paper, we propose a general approach to construct risk measures which exhibit a desired tail sensitivity and may replace the expectation operator in ERM. Our method relies on the specification of a reference distribution with a desired tail behaviour, which is in a one-to-one correspondence to a coherent upper probability. Any risk measure, which is compatible with this upper probability, displays a tail sensitivity which is finely tuned to the reference distribution. As a concrete example, we focus on divergence risk measures based on f-divergence ambiguity sets, which are a widespread tool used to foster distributional robustness of machine learning systems. For instance, we show how ambiguity sets based on the Kullback-Leibler divergence are intricately tied to the class of subexponential random variables. We elaborate the connection of divergence risk measures and rearrangement invariant Banach norms",
    "checked": true,
    "id": "23d808fc5e949837752176dd5b3ac66b73fef8d0",
    "semantic_title": "tailoring to the tails: risk measures for fine-grained tail sensitivity",
    "citation_count": 5,
    "authors": [
      "Christian Fröhlich",
      "Robert Williamson"
    ]
  },
  "https://openreview.net/forum?id=JnsGy9uWtI": {
    "title": "Controlling Neural Network Smoothness for Neural Algorithmic Reasoning",
    "volume": "main",
    "abstract": "The modelling framework of neural algorithmic reasoning (Veličković & Blundell, 2021) postulates that a continuous neural network may learn to emulate the discrete reasoning steps of a symbolic algorithm. We investigate the underlying hypothesis in the most simple conceivable scenario – the addition of real numbers. Our results show that two layer neural networks fail to learn the structure of the task, despite containing multiple solutions of the true function within their hypothesis class. Growing the network's width leads to highly complex error regions in the input space. Moreover, we find that the network fails to generalise with increasing severity i) in the training domain, ii) outside of the training domain but within its convex hull, and iii) outside the training domain's convex hull. This behaviour can be emulated with Gaussian process regressors that use radial basis function kernels of decreasing length scale. Classical results establish an equivalence between Gaussian processes and infinitely wide neural networks. We demonstrate a tight linkage between the scaling of a network weights' standard deviation and its effective length scale on a sinusoidal regression problem, suggesting simple modifications to control the length scale of the function learned by a neural network and, thus, its smoothness. This has important applications for the different generalisation scenarios suggested above, but it also suggests a partial remedy to the brittleness of neural network predictions as exposed by adversarial examples. We demonstrate the gains in adversarial robustness that our modification achieves on a standard classification problem of handwritten digit recognition. In conclusion, this work shows inherent problems of neural networks even for the simplest algorithmic tasks which, however, may be partially remedied through links to Gaussian processes",
    "checked": true,
    "id": "1d6ca8d8401e14bbb764d35ba13a9505af0dcc2f",
    "semantic_title": "controlling neural network smoothness for neural algorithmic reasoning",
    "citation_count": 2,
    "authors": [
      "David A. Klindt"
    ]
  },
  "https://openreview.net/forum?id=vxyjTUPV24": {
    "title": "Target Propagation via Regularized Inversion for Recurrent Neural Networks",
    "volume": "main",
    "abstract": "Target Propagation (TP) algorithms compute targets instead of gradients along neural networks and propagate them backward in a way that is similar to yet different than gradient back-propagation (BP). The idea initially appeared as a perturbative alternative to BP that may improve gradient evaluation accuracy when training multi-layer neural networks (LeCun, 1985) and has gained popularity as a biologically plausible counterpart of BP. However, there have been many variations of TP, and a simple version of TP still remains worthwhile. Revisiting the insights of LeCun (1985) and Lee et al (2015), we present a simple version of TP based on regularized inversions of layers of recurrent neural networks. The proposed TP algorithm is easily implementable in a differentiable programming framework. We illustrate the algorithm with recurrent neural networks on long sequences in various sequence modeling problems and delineate the regimes in which the computational complexity of TP can be attractive compared to BP",
    "checked": false,
    "id": "a37f92669487cfed6a66d7d7fff5985032d111dd",
    "semantic_title": "target propagation via regularized inversion",
    "citation_count": 4,
    "authors": [
      "Vincent Roulet",
      "Zaid Harchaoui"
    ]
  },
  "https://openreview.net/forum?id=sMsGv5Kfm3": {
    "title": "Bayesian Causal Bandits with Backdoor Adjustment Prior",
    "volume": "main",
    "abstract": "The causal bandit problem setting is a sequential decision-making framework where actions of interest correspond to interventions on variables in a system assumed to be governed by a causal model. The underlying causality may be exploited when investigating actions in the interest of optimizing the yield of the reward variable. Most existing approaches assume prior knowledge of the underlying causal graph, which is in practice restrictive and often unrealistic. In this paper, we develop a novel Bayesian framework for tackling causal bandit problems that does not rely on possession of the causal graph, but rather simultaneously learns the causal graph while exploiting causal inferences to optimize the reward. Our methods efficiently utilize joint inferences from interventional and observational data in a unified Bayesian model constructed with intervention calculus and causal graph learning. For the implementation of our proposed methodology in the discrete distributional setting, we derive an approximation of the sampling variance of the backdoor adjustment estimator. In the Gaussian setting, we characterize the interventional variance with intervention calculus and propose a simple graphical criterion to share information between arms. We validate our proposed methodology in an extensive empirical study, demonstrating compelling cumulative regret performance against state-of-the-art standard algorithms as well as optimistic implementations of their causal variants that assume strong prior knowledge of the causal structure",
    "checked": true,
    "id": "b9948e4f6e1e01fe0dc879188125440a0e6c2fa3",
    "semantic_title": "bayesian causal bandits with backdoor adjustment prior",
    "citation_count": 1,
    "authors": [
      "Jireh Huang",
      "Qing Zhou"
    ]
  },
  "https://openreview.net/forum?id=znNITCJyTI": {
    "title": "Accelerated Quality-Diversity through Massive Parallelism",
    "volume": "main",
    "abstract": "Quality-Diversity (QD) optimization algorithms are a well-known approach to generate large collections of diverse and high-quality solutions. However, derived from evolutionary computation, QD algorithms are population-based methods which are known to be data-inefficient and requires large amounts of computational resources. This makes QD algorithms slow when used in applications where solution evaluations are computationally costly. A common approach to speed up QD algorithms is to evaluate solutions in parallel, for instance by using physical simulators in robotics. Yet, this approach is limited to several dozen of parallel evaluations as most physics simulators can only be parallelized more with a greater number of CPUs. With recent advances in simulators that run on accelerators, thousands of evaluations can now be performed in parallel on single GPU/TPU. In this paper, we present QDax, an accelerated implementation of MAP-Elites which leverages massive parallelism on accelerators to make QD algorithms more accessible. We show that QD algorithms are ideal candidates to take advantage of progress in hardware acceleration. We demonstrate that QD algorithms can scale with massive parallelism to be run at interactive timescales without any significant effect on the performance. Results across standard optimization functions and four neuroevolution benchmark environments shows that experiment runtimes are reduced by two factors of magnitudes, turning days of computation into minutes. More surprising, we observe that reducing the number of generations by two orders of magnitude, and thus having significantly shorter lineage does not impact the performance of QD algorithms. These results show that QD can now benefit from hardware acceleration, which contributed significantly to the bloom of deep learning",
    "checked": true,
    "id": "e5c5b15ff7b523ef7160968331dc5bfe057b62fe",
    "semantic_title": "accelerated quality-diversity through massive parallelism",
    "citation_count": 18,
    "authors": [
      "Bryan Lim",
      "Maxime Allard",
      "Luca Grillotti",
      "Antoine Cully"
    ]
  },
  "https://openreview.net/forum?id=y7RGNXhGSR": {
    "title": "BIGRoC: Boosting Image Generation via a Robust Classifier",
    "volume": "main",
    "abstract": "The interest of the machine learning community in image synthesis has grown significantly in recent years, with the introduction of a wide range of deep generative models and means for training them. In this work, we propose a general model-agnostic technique for improving the image quality and the distribution fidelity of generated images obtained by any generative model. Our method, termed BIGRoC (Boosting Image Generation via a Robust Classifier), is based on a post-processing procedure via the guidance of a given robust classifier and without a need for additional training of the generative model. Given a synthesized image, we propose to update it through projected gradient steps over the robust classifier to refine its recognition. We demonstrate this post-processing algorithm on various image synthesis methods and show a significant quantitative and qualitative improvement on CIFAR-10 and ImageNet. Surprisingly, although BIGRoC is the first model agnostic among refinement approaches and requires much less information, it outperforms competitive methods. Specifically, BIGRoC improves the image synthesis best performing diffusion model on ImageNet $128\\times128$ by 14.81%, attaining an FID score of 2.53 and on $256\\times256$ by 7.87%, achieving an FID of 3.63. Moreover, we conduct an opinion survey, according to which humans significantly prefer our method's outputs",
    "checked": true,
    "id": "94249f97e0656784dad58a95032142d3a3a33f7b",
    "semantic_title": "bigroc: boosting image generation via a robust classifier",
    "citation_count": 10,
    "authors": [
      "Roy Ganz",
      "Michael Elad"
    ]
  },
  "https://openreview.net/forum?id=CUDdbTT1QC": {
    "title": "Constrained Parameter Inference as a Principle for Learning",
    "volume": "main",
    "abstract": "Learning in neural networks is often framed as a problem in which targeted error signals are directly propagated to parameters and used to produce updates that induce more optimal network behaviour. Backpropagation of error (BP) is an example of such an approach and has proven to be a highly successful application of stochastic gradient descent to deep neural networks. We propose constrained parameter inference (COPI) as a new principle for learning. The COPI approach assumes that learning can be set up in a manner where parameters infer their own values based upon observations of their local neuron activities. We find that this estimation of network parameters is possible under the constraints of decorrelated neural inputs and top-down perturbations of neural states for credit assignment. We show that the decorrelation required for COPI allows learning at extremely high learning rates, competitive with that of adaptive optimizers, as used by BP. We further demonstrate that COPI affords a new approach to feature analysis and network compression. Finally, we argue that COPI may shed new light on learning in biological networks given the evidence for decorrelation in the brain",
    "checked": true,
    "id": "2f0c5874020403df7f8f0efa1c31abca0c5a1876",
    "semantic_title": "constrained parameter inference as a principle for learning",
    "citation_count": 11,
    "authors": [
      "Nasir Ahmad",
      "Ellen Schrader",
      "Marcel van Gerven"
    ]
  },
  "https://openreview.net/forum?id=czgMCpvrDM": {
    "title": "SMILE: Sample-to-feature Mixup for Efficient Transfer Learning",
    "volume": "main",
    "abstract": "To improve the performance of deep learning, mixup has been proposed to force the neural networks favoring simple linear behaviors in-between training samples. Performing mixup for transfer learning with pre-trained models however is not that simple, a high capacity pre-trained model with a large fully-connected (FC) layer could easily overfit to the target dataset even with samples-to-labels mixed up. In this work, we propose SMILE — Sample-to-feature Mixup for Efficient Transfer Learning. With mixed images as inputs, SMILE regularizes the outputs of CNN feature extractors to learn from the mixed feature vectors of inputs, in addition to the mixed labels. SMILE incorporates a mean teacher to provide the surrogate \"ground truth\" for mixed feature vectors. The sample-to-feature mixup regularizer is imposed both on deep features for the target domain and classifier outputs for the source domain, bounding the linearity in-between samples for target tasks. Extensive experiments have been done to verify the performance improvement made by SMILE, in comparisons with a wide spectrum of transfer learning algorithms, including fine-tuning, L$^2$-SP, DELTA, BSS, RIFLE, Co-Tuning and RegSL, even with mixup strategies combined. Ablation studies show that the vanilla sample-to-label mixup strategies could marginally increase the linearity in-between training samples but lack of generalizability, while SMILE significantly improves the mixup effects in both label and feature spaces with both training and testing datasets. The empirical observations backup our design intuition and purposes",
    "checked": true,
    "id": "fa26bc7c58ff683a03d99089e6466cec9366008f",
    "semantic_title": "smile: sample-to-feature mixup for efficient transfer learning",
    "citation_count": 1,
    "authors": [
      "Xingjian Li",
      "Haoyi Xiong",
      "Cheng-zhong Xu",
      "Dejing Dou"
    ]
  },
  "https://openreview.net/forum?id=Q6ZXm7VBFY": {
    "title": "Optimal Convergence Rates of Deep Convolutional Neural Networks: Additive Ridge Functions",
    "volume": "main",
    "abstract": "Convolutional neural networks have shown impressive abilities in many applications, especially those related to the classification tasks. However, for the regression problem, the abilities of convolutional structures have not been fully understood, and further investigation is needed. In this paper, we consider the mean squared error analysis for deep convolutional neural networks. We show that, for additive ridge functions, convolutional neural networks followed by one fully connected layer with ReLU activation functions can reach optimal mini-max rates (up to a log factor). The input dimension only appears in the constant of convergence rates. This work shows the statistical optimality of convolutional neural networks and may shed light on why convolutional neural networks are able to behave well for high dimensional input",
    "checked": true,
    "id": "57effa366b69baca0d4e6605051f68b75d18cba1",
    "semantic_title": "optimal convergence rates of deep convolutional neural networks: additive ridge functions",
    "citation_count": 2,
    "authors": [
      "Zhiying Fang",
      "Guang Cheng"
    ]
  },
  "https://openreview.net/forum?id=myjAVQrRxS": {
    "title": "Dropped Scheduled Task: Mitigating Negative Transfer in Multi-task Learning using Dynamic Task Dropping",
    "volume": "main",
    "abstract": "In Multi-Task Learning (MTL), K distinct tasks are jointly optimized. With the varying nature and complexities of tasks, few tasks might dominate learning. For other tasks, their respective performances may get compromised due to a negative transfer from dominant tasks. We propose a Dropped-Scheduled Task (DST) algorithm, which probabilistically \"drops\" specific tasks during joint optimization while scheduling others to reduce negative transfer. For each task, a scheduling probability is decided based on four different metrics: (i) task depth, (ii) number of ground-truth samples per task, (iii) amount of training completed, and (iv) task stagnancy. Based on the scheduling probability, specific tasks get joint computation cycles while others are \"dropped\". To demonstrate the effectiveness of the proposed DST algorithm, we perform multi-task learning on three applications and two architectures. Across unilateral (single input) and bilateral (multiple input) multi-task net- works, the chosen applications are (a) face (AFLW), (b) fingerprint (IIITD MOLF, MUST, and NIST SD27), and (c) character recognition (Omniglot) applications. Experimental results show that the proposed DST algorithm has the minimum negative transfer and overall least errors across different state-of-the-art algorithms and tasks",
    "checked": true,
    "id": "e13bde06aa3a53f307216838232b2da560746251",
    "semantic_title": "dropped scheduled task: mitigating negative transfer in multi-task learning using dynamic task dropping",
    "citation_count": 6,
    "authors": [
      "Aakarsh Malhotra",
      "Mayank Vatsa",
      "Richa Singh"
    ]
  },
  "https://openreview.net/forum?id=wkecshlYxI": {
    "title": "Revisiting adversarial training for the worst-performing class",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a94711bf63db66d7d119f281d3ed8c39949a5c46",
    "semantic_title": "revisiting adversarial training for the worst-performing class",
    "citation_count": 7,
    "authors": [
      "Thomas Pethick",
      "Grigorios Chrysos",
      "Volkan Cevher"
    ]
  },
  "https://openreview.net/forum?id=JyKNuoZGux": {
    "title": "Calibrate and Debias Layer-wise Sampling for Graph Convolutional Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cb8de98f5c3096939c0f094eb32a127cfb6548af",
    "semantic_title": "calibrate and debias layer-wise sampling for graph convolutional networks",
    "citation_count": 5,
    "authors": [
      "Yifan Chen",
      "Tianning Xu",
      "Dilek Hakkani-Tur",
      "Di Jin",
      "Yun Yang",
      "Ruoqing Zhu"
    ]
  },
  "https://openreview.net/forum?id=nAr9PhyEbQ": {
    "title": "Online Learning for Prediction via Covariance Fitting: Computation, Performance and Robustness",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d05ea934710b796a5c2afeccd025a6d0bd51c910",
    "semantic_title": "online learning for prediction via covariance fitting: computation, performance and robustness",
    "citation_count": 0,
    "authors": [
      "Muhammad Osama",
      "Dave Zachariah",
      "Peter Stoica",
      "Thomas B. Schön"
    ]
  },
  "https://openreview.net/forum?id=DzJ7JfPXkE": {
    "title": "ViViT: Curvature Access Through The Generalized Gauss-Newton's Low-Rank Structure",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e02312242749757b7a2f33e08058d35db60e4c62",
    "semantic_title": "vivit: curvature access through the generalized gauss-newton's low-rank structure",
    "citation_count": 13,
    "authors": [
      "Felix Dangel",
      "Lukas Tatzel",
      "Philipp Hennig"
    ]
  },
  "https://openreview.net/forum?id=EYrRzKPinA": {
    "title": "On a continuous time model of gradient descent dynamics and instability in deep learning",
    "volume": "main",
    "abstract": "The recipe behind the success of deep learning has been the combination of neural networks and gradient-based optimization. Understanding the behavior of gradient descent however, and particularly its instability, has lagged behind its empirical success. To add to the theoretical tools available to study gradient descent we propose the principal flow (PF), a continuous time flow that approximates gradient descent dynamics. To our knowledge, the PF is the only continuous flow that captures the divergent and oscillatory behaviors of gradient descent, including escaping local minima and saddle points. Through its dependence on the eigendecomposition of the Hessian the PF sheds light on the recently observed edge of stability phenomena in deep learning. Using our new understanding of instability we propose a learning rate adaptation method which enables us to control the trade-off between training stability and test set evaluation performance",
    "checked": true,
    "id": "c7e552c3a0a2f4542e8fe0a0abcff48597000b17",
    "semantic_title": "on a continuous time model of gradient descent dynamics and instability in deep learning",
    "citation_count": 10,
    "authors": [
      "Mihaela Rosca",
      "Yan Wu",
      "Chongli Qin",
      "Benoit Dherin"
    ]
  },
  "https://openreview.net/forum?id=Lx19EyKX77": {
    "title": "Gradient-adjusted Incremental Target Propagation Provides Effective Credit Assignment in Deep Neural Networks",
    "volume": "main",
    "abstract": "Many of the recent advances in the field of artificial intelligence have been fueled by the highly successful backpropagation of error (BP) algorithm, which efficiently solves the credit assignment problem in artificial neural networks. However, it is unlikely that BP is implemented in its usual form within biological neural networks, because of its reliance on non-local information in propagating error gradients. Since biological neural networks are capable of highly efficient learning and responses from BP trained models can be related to neural responses, it seems reasonable that a biologically viable approximation of BP underlies synaptic plasticity in the brain. Gradient-adjusted incremental target propagation (GAIT-prop or GP for short) has recently been derived directly from BP and has been shown to successfully train networks in a more biologically plausible manner. However, so far, GP has only been shown to work on relatively low-dimensional problems, such as handwritten-digit recognition. This work addresses some of the scaling issues in GP and shows it to perform effective multi-layer credit assignment in deeper networks and on the much more challenging ImageNet dataset",
    "checked": true,
    "id": "6871d28d275ff0313b64bffcfa3e37a2f835a583",
    "semantic_title": "gradient-adjusted incremental target propagation provides effective credit assignment in deep neural networks",
    "citation_count": 1,
    "authors": [
      "Sander Dalm",
      "Nasir Ahmad",
      "Luca Ambrogioni",
      "Marcel van Gerven"
    ]
  },
  "https://openreview.net/forum?id=ryUHgEdWCQ": {
    "title": "Proportional Fairness in Federated Learning",
    "volume": "main",
    "abstract": "With the increasingly broad deployment of federated learning (FL) systems in the real world, it is critical but challenging to ensure fairness in FL, i.e. reasonably satisfactory performances for each of the numerous diverse clients. In this work, we introduce and study a new fairness notion in FL, called proportional fairness (PF), which is based on the relative change of each client's performance. From its connection with the bargaining games, we propose PropFair, a novel and easy-to-implement algorithm for finding proportionally fair solutions in FL, and study its convergence properties. Through extensive experiments on vision and language datasets, we demonstrate that PropFair can approximately find PF solutions, and it achieves a good balance between the average performances of all clients and of the worst 10% clients",
    "checked": true,
    "id": "986f54f8cf6c27a1ee14ba0f8d2125026bd6d92f",
    "semantic_title": "proportional fairness in federated learning",
    "citation_count": 26,
    "authors": [
      "Guojun Zhang",
      "Saber Malekmohammadi",
      "Xi Chen",
      "Yaoliang Yu"
    ]
  },
  "https://openreview.net/forum?id=56cTmVrg5w": {
    "title": "On the Role of Fixed Points of Dynamical Systems in Training Physics-Informed Neural Networks",
    "volume": "main",
    "abstract": "This paper empirically studies commonly observed training difficulties of Physics-Informed Neural Networks (PINNs) on dynamical systems. Our results indicate that fixed points which are inherent to these systems play a key role in the optimization of the in PINNs embedded physics loss function. We observe that the loss landscape exhibits local optima that are shaped by the presence of fixed points. We find that these local optima contribute to the complexity of the physics loss optimization which can explain common training difficulties and resulting nonphysical predictions. Under certain settings, e.g., initial conditions close to fixed points or long simulations times, we show that those optima can even become better than that of the desired solution",
    "checked": true,
    "id": "549a41ac9ffbbd8ae0e68ac22dd2880a5a3548a0",
    "semantic_title": "on the role of fixed points of dynamical systems in training physics-informed neural networks",
    "citation_count": 20,
    "authors": [
      "Franz M. Rohrhofer",
      "Stefan Posch",
      "Clemens Gößnitzer",
      "Bernhard C Geiger"
    ]
  },
  "https://openreview.net/forum?id=EiX2L4sDPG": {
    "title": "VN-Transformer: Rotation-Equivariant Attention for Vector Neurons",
    "volume": "main",
    "abstract": "Rotation equivariance is a desirable property in many practical applications such as motion forecasting and 3D perception, where it can offer benefits like sample efficiency, better generalization, and robustness to input perturbations. Vector Neurons (VN) is a recently developed framework offering a simple yet effective approach for deriving rotation-equivariant analogs of standard machine learning operations by extending one-dimensional scalar neurons to three-dimensional \"vector neurons.\" We introduce a novel \"VN-Transformer\" architecture to address several shortcomings of the current VN models. Our contributions are: (i) we derive a rotation-equivariant attention mechanism which eliminates the need for the heavy feature preprocessing required by the original Vector Neurons models; (ii) we extend the VN framework to support non-spatial attributes, expanding the applicability of these models to real-world datasets; (iii) we derive a rotation-equivariant mechanism for multi-scale reduction of point-cloud resolution, greatly speeding up inference and training; (iv) we show that small tradeoffs in equivariance ($\\epsilon$-approximate equivariance) can be used to obtain large improvements in numerical stability and training robustness on accelerated hardware, and we bound the propagation of equivariance violations in our models. Finally, we apply our VN-Transformer to 3D shape classification and motion forecasting with compelling results",
    "checked": true,
    "id": "9628221b1fa271d93968e97a0a5868b657e0a5be",
    "semantic_title": "vn-transformer: rotation-equivariant attention for vector neurons",
    "citation_count": 20,
    "authors": [
      "Serge Assaad",
      "Carlton Downey",
      "Rami Al-Rfou'",
      "Nigamaa Nayakanti",
      "Benjamin Sapp"
    ]
  },
  "https://openreview.net/forum?id=1U0aPkBVz0": {
    "title": "lo-fi: distributed fine-tuning without communication",
    "volume": "main",
    "abstract": "When fine-tuning large neural networks, it is common to use multiple nodes and to communicate gradients at each optimization step. By contrast, we investigate completely local fine-tuning, which we refer to as lo-fi. During lo-fi, each node fine-tunes independently without any communication. Then, the weights are averaged across nodes at the conclusion of fine-tuning. When fine-tuning DeiT-base and DeiT-large on ImageNet, this procedure matches accuracy in-distribution and improves accuracy under distribution shift compared to the baseline, which observes the same amount of data but communicates gradients at each step. We also observe that lo-fi matches the baseline's performance when fine-tuning OPT language models (up to 1.3B parameters) on Common Crawl. By removing the communication requirement, lo-fi reduces resource barriers for fine-tuning large models and enables fine-tuning in settings with prohibitive communication cost",
    "checked": true,
    "id": "5ecf91d9f3bcc5dee65e3a8ac1ab65dacf777de6",
    "semantic_title": "lo-fi: distributed fine-tuning without communication",
    "citation_count": 24,
    "authors": [
      "Mitchell Wortsman",
      "Suchin Gururangan",
      "Shen Li",
      "Ali Farhadi",
      "Ludwig Schmidt",
      "Michael Rabbat",
      "Ari S. Morcos"
    ]
  },
  "https://openreview.net/forum?id=mHSAy1n65Z": {
    "title": "Optimal Threshold Labeling for Ordinal Regression Methods",
    "volume": "main",
    "abstract": "For an ordinal regression task, a classification task for ordinal data, one-dimensional transformation (1DT)-based methods are often employed since they are considered to capture the ordinal relation of ordinal data well. They learn a 1DT of the observation of the explanatory variables so that an observation with a larger class label tends to have a larger value of the 1DT, and classify the observation by labeling that learned 1DT. In this paper, we study the labeling procedure for 1DT-based methods, which have not been sufficiently discussed in existing studies. While regression-based methods and classical threshold methods conventionally use threshold labelings, which label a learned 1DT according to the rank of the interval to which the 1DT belongs among intervals on the real line separated by threshold parameters, we prove that likelihood-based labeling used in popular statistical 1DT-based methods is also a threshold labeling in typical usages. Moreover, we show that these threshold labelings can be sub-optimal ones depending on the learning result of the 1DT and the task under consideration. On the basis of these findings, we propose to apply empirical optimal threshold labeling, which is a threshold labeling that uses threshold parameters minimizing the empirical task risk for a learned 1DT, to those methods. In experiments with real-world datasets, changing the labeling procedure of existing 1DT-based methods to the proposed one improved the classification performance in many tried cases",
    "checked": true,
    "id": "ec08eae556382e491b5a4e0a6cc9fd82cc9109ad",
    "semantic_title": "optimal threshold labeling for ordinal regression methods",
    "citation_count": 2,
    "authors": [
      "Ryoya Yamasaki"
    ]
  },
  "https://openreview.net/forum?id=LTAdaRM29K": {
    "title": "Recognition Models to Learn Dynamics from Partial Observations with Neural ODEs",
    "volume": "main",
    "abstract": "Identifying dynamical systems from experimental data is a notably difficult task. Prior knowledge generally helps, but the extent of this knowledge varies with the application, and customized models are often needed. Neural ordinary differential equations can be written as a flexible framework for system identification and can incorporate a broad spectrum of physical insight, giving physical interpretability to the resulting latent space. In the case of partial observations, however, the data points cannot directly be mapped to the latent state of the ODE. Hence, we propose to design recognition models, in particular inspired by nonlinear observer theory, to link the partial observations to the latent state. We demonstrate the performance of the proposed approach on numerical simulations and on an experimental dataset from a robotic exoskeleton",
    "checked": true,
    "id": "b1aeafbf4fbd9b0055f33795c059a5769cbbeb55",
    "semantic_title": "recognition models to learn dynamics from partial observations with neural odes",
    "citation_count": 6,
    "authors": [
      "Mona Buisson-Fenet",
      "Valery Morgenthaler",
      "Sebastian Trimpe",
      "Florent Di Meglio"
    ]
  },
  "https://openreview.net/forum?id=GzqdMrFQsE": {
    "title": "Attention Beats Concatenation for Conditioning Neural Fields",
    "volume": "main",
    "abstract": "Neural fields model signals by mapping coordinate inputs to sampled values. They are becoming an increasingly important backbone architecture across many fields from vision and graphics to biology and astronomy. In this paper, we explore the differences between common conditioning mechanisms within these networks, an essential ingredient in shifting neural fields from memorization of signals to generalization, where the set of signals lying on a manifold is modelled jointly. In particular, we are interested in the scaling behaviour of these mechanisms to increasingly high-dimensional conditioning variables. As we show in our experiments, high-dimensional conditioning is key to modelling complex data distributions, thus it is important to determine what architecture choices best enable this when working on such problems. To this end, we run experiments modelling 2D, 3D, and 4D signals with neural fields, employing concatenation, hyper-network, and attention-based conditioning strategies -- a necessary but laborious effort that has not been performed in the literature. We find that attention-based conditioning outperforms other approaches in a variety of settings",
    "checked": true,
    "id": "2ea820473b4a232e196f7bd874f5b9605d194a65",
    "semantic_title": "attention beats concatenation for conditioning neural fields",
    "citation_count": 23,
    "authors": [
      "Daniel Rebain",
      "Mark J. Matthews",
      "Kwang Moo Yi",
      "Gopal Sharma",
      "Dmitry Lagun",
      "Andrea Tagliasacchi"
    ]
  },
  "https://openreview.net/forum?id=d3rHk4VAf0": {
    "title": "A Ranking Game for Imitation Learning",
    "volume": "main",
    "abstract": "We propose a new framework for imitation learning---treating imitation as a two-player ranking-based game between a policy and a reward. In this game, the reward agent learns to satisfy pairwise performance rankings between behaviors, while the policy agent learns to maximize this reward. In imitation learning, near-optimal expert data can be difficult to obtain, and even in the limit of infinite data cannot imply a total ordering over trajectories as preferences can. On the other hand, learning from preferences alone is challenging as a large number of preferences are required to infer a high-dimensional reward function, though preference data is typically much easier to collect than expert demonstrations. The classical inverse reinforcement learning (IRL) formulation learns from expert demonstrations but provides no mechanism to incorporate learning from offline preferences and vice versa. We instantiate the proposed ranking-game framework with a novel ranking loss giving an algorithm that can simultaneously learn from expert demonstrations and preferences, gaining the advantages of both modalities. Our experiments show that the proposed method achieves state-of-the-art sample efficiency and can solve previously unsolvable tasks in the Learning from Observation (LfO) setting",
    "checked": true,
    "id": "622a5434eae1b53fe0b74ad0d0942212cd722c36",
    "semantic_title": "a ranking game for imitation learning",
    "citation_count": 22,
    "authors": [
      "Harshit Sikchi",
      "Akanksha Saran",
      "Wonjoon Goo",
      "Scott Niekum"
    ]
  },
  "https://openreview.net/forum?id=LfTukxzxTj": {
    "title": "Implicit Ensemble Training for Efficient and Robust Multiagent Reinforcement Learning",
    "volume": "main",
    "abstract": "An important issue in competitive multiagent scenarios is the distribution mismatch between training and testing caused by variations in other agents' policies. As a result, policies optimized during training are typically sub-optimal (possibly very poor) in testing. Ensemble training is an effective approach for learning robust policies that avoid significant performance degradation when competing against previously unseen opponents. A large ensemble can improve diversity during the training, which leads to more robust learning. However, the computation and memory requirements increase linearly with respect to the ensemble size, which is not scalable as the ensemble size required for learning robust policy can be quite large. This paper proposes a novel parameterization of a policy ensemble based on a deep latent variable model with a multi-task network architecture, which represents an ensemble of policies implicitly within a single network. Our implicit ensemble training (IET) approach strikes a better trade-off between ensemble diversity and scalability compared to standard ensemble training. We demonstrate in several competitive multiagent scenarios in the board game and robotic domains that our new approach improves robustness against unseen adversarial opponents while achieving higher sample-efficiency and less computation",
    "checked": true,
    "id": "337d69e8b1261709ba90f115a221fdad2a357a85",
    "semantic_title": "implicit ensemble training for efficient and robust multiagent reinforcement learning",
    "citation_count": 1,
    "authors": [
      "Macheng Shen",
      "JONATHAN P HOW"
    ]
  },
  "https://openreview.net/forum?id=hVT7SHlilx": {
    "title": "Named Tensor Notation",
    "volume": "main",
    "abstract": "We propose a notation for tensors with named axes, which relieves the author, reader, and future implementers of machine learning models from the burden of keeping track of the order of axes and the purpose of each. The notation makes it easy to lift operations on low-order tensors to higher order ones, for example, from images to minibatches of images, or from an attention mechanism to multiple attention heads. After a brief overview and formal definition of the notation, we illustrate it through several examples from modern machine learning, from building blocks like attention and convolution to full models like Transformers and LeNet. We then discuss differential calculus in our notation and compare with some alternative notations. Our proposals build on ideas from many previous papers and software libraries. We hope that this document will encourage more authors to use named tensors, resulting in clearer papers and more precise implementations",
    "checked": true,
    "id": "260d92c87296078ab4f822a5a95e309863d4b069",
    "semantic_title": "named tensor notation",
    "citation_count": 11,
    "authors": [
      "David Chiang",
      "Alexander M Rush",
      "Boaz Barak"
    ]
  },
  "https://openreview.net/forum?id=X1pjWMCMB0": {
    "title": "PCPs: Patient Cardiac Prototypes to Probe AI-based Medical Diagnoses, Distill Datasets, and Retrieve Patients",
    "volume": "main",
    "abstract": "Clinical deep learning systems often generate population-based and opaque medical diagnoses. This is in contrast to how primary care physicians make decisions, often adapting population-based protocols to the unique patient under consideration. Inspired by the workflow of such physicians, we develop a framework for learning embeddings, referred to as patient cardiac prototypes (PCPs), which capture information that is unique to an individual patient's electrocardiogram (ECG) data. Through rigorous evaluation on three publicly-available ECG datasets, we show that PCPs allow researchers to inspect why a particular diagnosis was made. We also demonstrate that PCPs are effective dataset distillers, where they can be used to train a model in lieu of a dataset orders of magnitude larger to achieve comparable performance. We show that PCPs can also be exploited to retrieve similar patient data across clinical databases. Our framework contributes to the development of transparent and patient-specific clinical deep learning systems",
    "checked": true,
    "id": "620c66066427f7254e98f6df39f81862ab0e7db0",
    "semantic_title": "pcps: patient cardiac prototypes to probe ai-based medical diagnoses, distill datasets, and retrieve patients",
    "citation_count": 2,
    "authors": [
      "Dani Kiyasseh",
      "Tingting Zhu",
      "David A. Clifton"
    ]
  },
  "https://openreview.net/forum?id=RbLsYz1Az9": {
    "title": "On the infinite-depth limit of finite-width neural networks",
    "volume": "main",
    "abstract": "In this paper, we study the infinite-depth limit of finite-width residual neural networks with random Gaussian weights. With proper scaling, we show that by fixing the width and taking the depth to infinity, the pre-activations converge in distribution to a zero-drift diffusion process. Unlike the infinite-width limit where the pre-activation converge weakly to a Gaussian random variable, we show that the infinite-depth limit yields different distributions depending on the choice of the activation function. We document two cases where these distributions have closed-form (different) expressions. We further show an intriguing change-of-regime phenomenon of the post-activation norms when the width increases from 3 to 4. Lastly, we study the sequential limit infinite-depth-then-infinite-width, and compare it with the more commonly studied infinite-width-then-infinite-depth limit",
    "checked": true,
    "id": "0484a65707706e11eaa53fde8817c3122f07550d",
    "semantic_title": "on the infinite-depth limit of finite-width neural networks",
    "citation_count": 23,
    "authors": [
      "Soufiane Hayou"
    ]
  },
  "https://openreview.net/forum?id=85BfDdYMBY": {
    "title": "Intrinsic Dimension for Large-Scale Geometric Learning",
    "volume": "main",
    "abstract": "The concept of dimension is essential to grasp the complexity of data. A naive approach to determine the dimension of a dataset is based on the number of attributes. More sophisticated methods derive a notion of intrinsic dimension (ID) that employs more complex feature functions, e.g., distances between data points. Yet, many of these approaches are based on empirical observations, cannot cope with the geometric character of contemporary datasets, and do lack an axiomatic foundation. A different approach was proposed by V. Pestov, who links the intrinsic dimension axiomatically to the mathematical concentration of measure phenomenon. First methods to compute this and related notions for ID were computationally intractable for large-scale real-world datasets. In the present work, we derive a computationally feasible method for determining said axiomatic ID functions. Moreover, we demonstrate how the geometric properties of complex data are accounted for in our modeling. In particular, we propose a principle way to incorporate neighborhood information, as in graph data, into the ID. This allows for new insights into common graph learning procedures, which we illustrate by experiments on the Open Graph Benchmark",
    "checked": true,
    "id": "2f42d120ccaecedeed9ad1095fdc0207fa4c8e64",
    "semantic_title": "intrinsic dimension for large-scale geometric learning",
    "citation_count": 5,
    "authors": [
      "Maximilian Stubbemann",
      "Tom Hanika",
      "Friedrich Martin Schneider"
    ]
  },
  "https://openreview.net/forum?id=Xq1sTZTQVm": {
    "title": "Beyond Information Gain: An Empirical Benchmark for Low-Switching-Cost Reinforcement Learning",
    "volume": "main",
    "abstract": "A ubiquitous requirement in many practical reinforcement learning (RL) applications is that the deployed policy that actually interacts with the environment cannot change frequently. Such an RL setting is called low-switching-cost RL, i.e., achieving the highest reward while reducing the number of policy switches during training. It has been a recent trend in theoretical RL research to develop provably efficient RL algorithms with low switching cost. The core idea in these theoretical works is to measure the information gain and switch the policy when the information gain is doubled. Despite of the theoretical advances, none of existing approaches have been validated empirically. We conduct the first empirical evaluation of different policy switching criteria on popular RL testbeds, including a medical treatment environment, the Atari games, and robotic control tasks. Surprisingly, although information-gain-based methods do recover the optimal rewards, they often lead to a substantially higher switching cost. By contrast, we find that a feature-based criterion, which has been largely ignored in the theoretical research, consistently produces the best performances over all the domains. We hope our benchmark could bring insights to the community and inspire future research. Our code and complete results can be found at https: // sites. google. com/ view/ low-switching-cost-rl",
    "checked": true,
    "id": "81e78a7bdbd578a838cf0cc5f128b1f168500f03",
    "semantic_title": "beyond information gain: an empirical benchmark for low-switching-cost reinforcement learning",
    "citation_count": 3,
    "authors": [
      "Shusheng Xu",
      "Yancheng Liang",
      "Yunfei Li",
      "Simon Shaolei Du",
      "Yi Wu"
    ]
  },
  "https://openreview.net/forum?id=EgHnKOLaKW": {
    "title": "DisCo: Improving Compositional Generalization in Visual Reasoning through Distribution Coverage",
    "volume": "main",
    "abstract": "We present DisCo, a learning paradigm for improving compositional generalization of visual reasoning models by leveraging unlabeled, out-of-distribution images from the test distribution. DisCo has two components. The first is an iterative pseudo-labeling framework with an entropy measure, which effectively labels images of novel attribute compositions paired with randomly sampled questions. The second is a distribution coverage metric, serving as a model selection strategy that approximates generalization capability to test examples drawn from a different attribute combination distribution to the train set, without the use of labeled data from the test distribution. Both components are built on strong empirical evidence of the correlation between the chosen metric and model generalization, and improve distribution coverage on unlabeled images. We apply DisCo to visual question answering, with three backbone networks (FiLM, TbD-net, and the Neuro-Symbolic Concept Learner), and demonstrate that it consistently enhances performance on a variety of compositional generalization tasks with varying levels of train data bias",
    "checked": true,
    "id": "d5bb41678f7f38376bd3e8280e02318f9221852f",
    "semantic_title": "disco: improving compositional generalization in visual reasoning through distribution coverage",
    "citation_count": 1,
    "authors": [
      "Joy Hsu",
      "Jiayuan Mao",
      "Jiajun Wu"
    ]
  },
  "https://openreview.net/forum?id=RA0TDqt3hC": {
    "title": "Hidden Heterogeneity: When to Choose Similarity-Based Calibration",
    "volume": "main",
    "abstract": "Trustworthy classifiers are essential to the adoption of machine learning predictions in many real-world settings. The predicted probability of possible outcomes can inform high-stakes decision making, particularly when assessing the expected value of alternative decisions or the risk of bad outcomes. These decisions require well-calibrated probabilities, not just the correct prediction of the most likely class. Black-box classifier calibration methods can improve the reliability of a classifier's output without requiring retraining. However, these methods are unable to detect subpopulations where calibration could also improve prediction accuracy. Such subpopulations are said to exhibit \"hidden heterogeneity\" (HH), because the original classifier did not detect them. The paper proposes a quantitative measure for HH. It also introduces two similarity-weighted calibration methods that can address HH by adapting locally to each test item: SWC weights the calibration set by similarity to the test item, and SWC-HH explicitly incorporates hidden heterogeneity to filter the calibration set. Experiments show that the improvements in calibration achieved by similarity-based calibration methods correlate with the amount of HH present and, given sufficient calibration data, generally exceed calibration achieved by global methods. HH can therefore serve as a useful diagnostic tool for identifying when local calibration methods would be beneficial",
    "checked": true,
    "id": "e9d2d59b10815556150569fa352fe0454d2a99b5",
    "semantic_title": "hidden heterogeneity: when to choose similarity-based calibration",
    "citation_count": 1,
    "authors": [
      "Kiri L. Wagstaff",
      "Thomas G Dietterich"
    ]
  },
  "https://openreview.net/forum?id=zKnqZeUCLO": {
    "title": "PolyViT: Co-training Vision Transformers on Images, Videos and Audio",
    "volume": "main",
    "abstract": "Can we train a single transformer model capable of processing multiple modalities and datasets, whilst sharing almost all of its learnable parameters? We present PolyViT, a model trained on images, audio and video to answer this question. PolyViT consists of a single transformer backbone, modality-specific tokenizers and task-specific output heads. By co-training on different tasks of a single modality, we are able to achieve significant accuracy improvements on 5 standard video- and audio-classification datasets. Furthermore, co-training PolyViT on multiple modalities and tasks leads to a parameter-efficient model which generalizes across multiple domains. In particular, our multi-modal PolyViT trained on 9 datasets across 3 modalities uses 8.3 times fewer parameters and outperforms a state-of-the-art single-task baseline on 2 of these datasets, whilst achieving competitive performance on the others. Finally, this simple and practical approach necessitates less hyperparameter tuning as the per-task hyperparameters can be readily reused",
    "checked": true,
    "id": "00d7dfde1cd69d2247e8c36d10807b0dee9656d7",
    "semantic_title": "polyvit: co-training vision transformers on images, videos and audio",
    "citation_count": 76,
    "authors": [
      "Valerii Likhosherstov",
      "Anurag Arnab",
      "Krzysztof Marcin Choromanski",
      "Mario Lucic",
      "Yi Tay",
      "Mostafa Dehghani"
    ]
  },
  "https://openreview.net/forum?id=lheUXtDNvP": {
    "title": "GSR: A Generalized Symbolic Regression Approach",
    "volume": "main",
    "abstract": "Identifying the mathematical relationships that best describe a dataset remains a very challenging problem in machine learning, and is known as Symbolic Regression (SR). In contrast to neural networks which are often treated as black boxes, SR attempts to gain insight into the underlying relationships between the independent variables and the target variable of a given dataset by assembling analytical functions. In this paper, we present GSR, a Generalized Symbolic Regression approach, by modifying the conventional SR optimization problem formulation, while keeping the main SR objective intact. In GSR, we infer mathematical relationships between the independent variables and some transformation of the target variable. We constrain our search space to a weighted sum of basis functions, and propose a genetic programming approach with a matrix-based encoding scheme. We show that our GSR method is competitive with strong SR benchmark methods, achieving promising experimental performance on the well-known SR benchmark problem sets. Finally, we highlight the strengths of GSR by introducing SymSet, a new SR benchmark set which is more challenging relative to the existing benchmarks",
    "checked": true,
    "id": "6b189f3a9df39cd9dc6a4902d0a8464b77a99d6e",
    "semantic_title": "gsr: a generalized symbolic regression approach",
    "citation_count": 14,
    "authors": [
      "Tony Tohme",
      "Dehong Liu",
      "KAMAL YOUCEF-TOUMI"
    ]
  },
  "https://openreview.net/forum?id=jbZEUtULft": {
    "title": "Bounding generalization error with input compression: An empirical study with infinite-width networks",
    "volume": "main",
    "abstract": "Estimating the Generalization Error (GE) of Deep Neural Networks (DNNs) is an important task that often relies on availability of held-out data. The ability to better predict GE based on a single training set may yield overarching DNN design principles to reduce a reliance on trial-and-error, along with other performance assessment advantages. In search of a quantity relevant to GE, we investigate the Mutual Information (MI) between the input and final layer representations, using the infinite-width DNN limit to bound MI. An existing input compression-based GE bound is used to link MI and GE. To the best of our knowledge, this represents the first empirical study of this bound. In our attempt to empirically stress test the theoretical bound, we find that it is often tight for best-performing models. Furthermore, it detects randomization of training labels in many cases, reflects test-time perturbation robustness, and works well given only few training samples. These results are promising given that input compression is broadly applicable where MI can be estimated with confidence",
    "checked": true,
    "id": "2ecc56bf864691a58af12ab1189b130e31390cb6",
    "semantic_title": "bounding generalization error with input compression: an empirical study with infinite-width networks",
    "citation_count": 4,
    "authors": [
      "Angus Galloway",
      "Anna Golubeva",
      "Mahmoud Salem",
      "Mihai Nica",
      "Yani Ioannou",
      "Graham W. Taylor"
    ]
  },
  "https://openreview.net/forum?id=wIXHG8LZ2w": {
    "title": "Learning Representations for Pixel-based Control: What Matters and Why?",
    "volume": "main",
    "abstract": "Learning representations for pixel-based control has garnered significant attention recently in reinforcement learning. A wide range of methods have been proposed to enable efficient learning, leading to sample complexities similar to those in the full state setting. However, moving beyond carefully curated pixel data sets (centered crop, appropriate lighting, clear background, etc.) remains challenging. In this paper, we adopt a more difficult setting, incorporating background distractors, as a first step towards addressing this challenge. We start by exploring a simple baseline approach that does not use metric-based learning, data augmentations, world-model learning, or contrastive learning. We then analyze when and why previously proposed methods are likely to fail or reduce to the same performance as the baseline in this harder setting and why we should think carefully about extending such methods beyond the well curated environments. Our results show that finer categorization of benchmarks on the basis of characteristics like density of reward, planning horizon of the problem, presence of task-irrelevant components, etc., is crucial in evaluating algorithms. Based on these observations, we propose different metrics to consider when evaluating an algorithm on benchmark tasks. We hope such a data-centric view can motivate researchers to rethink representation learning when investigating how to best apply RL to real-world tasks. Code available: https://github.com/UtkarshMishra04/pixel-representations-RL",
    "checked": true,
    "id": "79419a74d1e9295c9a21659076adca3540af677f",
    "semantic_title": "learning representations for pixel-based control: what matters and why?",
    "citation_count": 28,
    "authors": [
      "Manan Tomar",
      "Utkarsh Aashu Mishra",
      "Amy Zhang",
      "Matthew E. Taylor"
    ]
  },
  "https://openreview.net/forum?id=MzWgBjZ6Le": {
    "title": "FedDAG: Federated DAG Structure Learning",
    "volume": "main",
    "abstract": "To date, most directed acyclic graphs (DAGs) structure learning approaches require data to be stored in a central server. However, due to the consideration of privacy protection, data owners gradually refuse to share their personalized raw data to avoid private information leakage, making this task more troublesome by cutting off the first step. Thus, a puzzle arises: how do we discover the underlying DAG structure from decentralized data? In this paper, focusing on the additive noise models (ANMs) assumption of data generation, we take the first step in developing a gradient-based learning framework named FedDAG, which can learn the DAG structure without directly touching the local data and also can naturally handle the data heterogeneity. Our method benefits from a two-level structure of each local model. The first level structure learns the edges and directions of the graph and communicates with the server to get the model information from other clients during the learning procedure, while the second level structure approximates the mechanisms among variables and personally updates on its own data to accommodate the data heterogeneity. Moreover, FedDAG formulates the overall learning task as a continuous optimization problem by taking advantage of an equality acyclicity constraint, which can be solved by gradient descent methods to boost the searching efficiency. Extensive experiments on both synthetic and real-world datasets verify the efficacy of the proposed method",
    "checked": true,
    "id": "b947afabee09c802698675d988ee350c73897698",
    "semantic_title": "feddag: federated dag structure learning",
    "citation_count": 17,
    "authors": [
      "Erdun Gao",
      "Junjia Chen",
      "Li Shen",
      "Tongliang Liu",
      "Mingming Gong",
      "Howard Bondell"
    ]
  },
  "https://openreview.net/forum?id=tnRRHzZPMq": {
    "title": "Communication-Efficient Distributionally Robust Decentralized Learning",
    "volume": "main",
    "abstract": "Decentralized learning algorithms empower interconnected devices to share data and computational resources to collaboratively train a machine learning model without the aid of a central coordinator. In the case of heterogeneous data distributions at the network nodes, collaboration can yield predictors with unsatisfactory performance for a subset of the devices. For this reason, in this work, we consider the formulation of a distributionally robust decentralized learning task and we propose a decentralized single loop gradient descent/ascent algorithm (AD-GDA) to directly solve the underlying minimax optimization problem. We render our algorithm communication-efficient by employing a compressed consensus scheme and we provide convergence guarantees for smooth convex and non-convex loss functions. Finally, we corroborate the theoretical findings with empirical results that highlight AD-GDA's ability to provide unbiased predictors and to greatly improve communication efficiency compared to existing distributionally robust algorithms",
    "checked": true,
    "id": "47fd26571d3b782c67bdb1faed18b5a88453252d",
    "semantic_title": "communication-efficient distributionally robust decentralized learning",
    "citation_count": 9,
    "authors": [
      "Matteo Zecchin",
      "Marios Kountouris",
      "David Gesbert"
    ]
  },
  "https://openreview.net/forum?id=GRBbtkW3Lp": {
    "title": "EdiBERT: a generative model for image editing",
    "volume": "main",
    "abstract": "Advances in computer vision are pushing the limits of image manipulation, with generative models sampling highly-realistic detailed images on various tasks. However, a specialized model is often developed and trained for each specific task, even though many image edition tasks share similarities. In denoising, inpainting, or image compositing, one always aims at generating a realistic image from a low-quality one. In this paper, we aim at making a step towards a unified approach for image editing. To do so, we propose EdiBERT, a bidirectional transformer that re-samples image patches conditionally to a given image. Using one generic objective, we show that the model resulting from a single training matches state-of-the-art GANs inversion on several tasks: image denoising, image completion, and image composition. We also provide several insights on the latent space of vector-quantized auto-encoders, such as locality and reconstruction capacities. The code is available at https://github.com/EdiBERT4ImageManipulation/EdiBERT",
    "checked": false,
    "id": "80b77e6faa04b58b24bac0c59eecb183960fa6df",
    "semantic_title": "edibert, a generative model for image editing",
    "citation_count": 12,
    "authors": [
      "Thibaut Issenhuth",
      "Ugo Tanielian",
      "Jeremie Mary",
      "David Picard"
    ]
  },
  "https://openreview.net/forum?id=2wWJxtpFer": {
    "title": "OpenCon: Open-world Contrastive Learning",
    "volume": "main",
    "abstract": "Machine learning models deployed in the wild naturally encounter unlabeled samples from both known and novel classes. Challenges arise in learning from both the labeled and unlabeled data, in an open-world semi-supervised manner. In this paper, we introduce a new learning framework, open-world contrastive learning (OpenCon). OpenCon tackles the challenges of learning compact representations for both known and novel classes and facilitates novelty discovery along the way. We demonstrate the effectiveness of OpenCon on challenging benchmark datasets and establish competitive performance. On the ImageNet dataset, OpenCon significantly outperforms the current best method by 11.9% and 7.4% on novel and overall classification accuracy, respectively. Theoretically, OpenCon can be rigorously interpreted from an EM algorithm perspective—minimizing our contrastive loss partially maximizes the likelihood by clustering similar samples in the embedding space. The code is available at https://github.com/deeplearning-wisc/opencon",
    "checked": true,
    "id": "26999b90336199506c2d638db8aa7e81ffa22318",
    "semantic_title": "opencon: open-world contrastive learning",
    "citation_count": 44,
    "authors": [
      "Yiyou Sun",
      "Yixuan Li"
    ]
  },
  "https://openreview.net/forum?id=fjkN5Ur2d6": {
    "title": "Linking Neural Collapse and L2 Normalization with Improved Out-of-Distribution Detection in Deep Neural Networks",
    "volume": "main",
    "abstract": "We propose a simple modification to standard ResNet architectures--L2 normalization over feature space--that substantially improves out-of-distribution (OoD) performance on the previously proposed Deep Deterministic Uncertainty (DDU) benchmark. We show that this change also induces early Neural Collapse (NC), an effect linked to better OoD performance. Our method achieves comparable or superior OoD detection scores and classification accuracy in a small fraction of the training time of the benchmark. Additionally, it substantially improves worst case OoD performance over multiple, randomly initialized models. Though we do not suggest that NC is the sole mechanism or a comprehensive explanation for OoD behaviour in deep neural networks (DNN), we believe NC's simple mathematical and geometric structure can provide a framework for analysis of this complex phenomenon in future work",
    "checked": true,
    "id": "5d6d0bb2df73f3c6da10884481303f165ae8d7c2",
    "semantic_title": "linking neural collapse and l2 normalization with improved out-of-distribution detection in deep neural networks",
    "citation_count": 20,
    "authors": [
      "Jarrod Haas",
      "William Yolland",
      "Bernhard T Rabus"
    ]
  },
  "https://openreview.net/forum?id=Grhi800jVz": {
    "title": "Euclidean-Norm-Induced Schatten-p Quasi-Norm Regularization for Low-Rank Tensor Completion and Tensor Robust Principal Component Analysis",
    "volume": "main",
    "abstract": "The nuclear norm and Schatten-$p$ quasi-norm are popular rank proxies in low-rank matrix recovery. However, computing the nuclear norm or Schatten-$p$ quasi-norm of a tensor is hard in both theory and practice, hindering their application to low-rank tensor completion (LRTC) and tensor robust principal component analysis (TRPCA). In this paper, we propose a new class of tensor rank regularizers based on the Euclidean norms of the CP component vectors of a tensor and show that these regularizers are monotonic transformations of tensor Schatten-$p$ quasi-norm. This connection enables us to minimize the Schatten-$p$ quasi-norm in LRTC and TRPCA implicitly via the component vectors. The method scales to big tensors and provides an arbitrarily sharper rank proxy for low-rank tensor recovery compared to the nuclear norm. On the other hand, we study the generalization abilities of LRTC with the Schatten-$p$ quasi-norm regularizer and LRTC with the proposed regularizers. The theorems show that a relatively sharper regularizer leads to a tighter error bound, which is consistent with our numerical results. Particularly, we prove that for LRTC with Schatten-$p$ quasi-norm regularizer on $d$-order tensors, $p=1/d$ is always better than any $p>1/d$ in terms of the generalization ability. We also provide a recovery error bound to verify the usefulness of small $p$ in the Schatten-$p$ quasi-norm for TRPCA. Numerical results on synthetic data and real data demonstrate the effectiveness of the regularization methods and theorems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jicong Fan",
      "Lijun Ding",
      "Chengrun Yang",
      "Zhao Zhang",
      "Madeleine Udell"
    ]
  },
  "https://openreview.net/forum?id=TGuXXlbKsn": {
    "title": "Benchmarks and Algorithms for Offline Preference-Based Reward Learning",
    "volume": "main",
    "abstract": "Learning a reward function from human preferences is challenging as it typically requires having a high-fidelity simulator or using expensive and potentially unsafe actual physical rollouts in the environment. However, in many tasks the agent might have access to offline data from related tasks in the same target environment. While offline data is increasingly being used to aid policy optimization via offline RL, our observation is that it can be a surprisingly rich source of information for preference learning as well. We propose an approach that uses an offline dataset to craft preference queries via pool-based active learning, learns a distribution over reward functions, and optimizes a corresponding policy via offline RL. Crucially, our proposed approach does not require actual physical rollouts or an accurate simulator for either the reward learning or policy optimization steps. To test our approach, we first evaluate existing offline RL benchmarks for their suitability for offline reward learning. Surprisingly, for many offline RL domains, we find that simply using a trivial reward function results good policy performance, making these domains ill-suited for evaluating learned rewards. To address this, we identify a subset of existing offline RL benchmarks that are well suited for offline reward learning and also propose new offline apprenticeship learning benchmarks which allow for more open-ended behaviors. When evaluated on this curated set of domains, our empirical results suggest that combining offline RL with learned human preferences can enable an agent to learn to perform novel tasks that were not explicitly shown in the offline data",
    "checked": true,
    "id": "88ae720354fa4883be13e25e1cf92dcd4fed5f5d",
    "semantic_title": "benchmarks and algorithms for offline preference-based reward learning",
    "citation_count": 59,
    "authors": [
      "Daniel Shin",
      "Anca Dragan",
      "Daniel S. Brown"
    ]
  },
  "https://openreview.net/forum?id=mrTXGDZns2": {
    "title": "Fairness and robustness in anti-causal prediction",
    "volume": "main",
    "abstract": "Robustness to distribution shift and fairness have independently emerged as two important desiderata required of modern machine learning models. While these two desiderata seem related, the connection between them is often unclear in practice. Here, we discuss these connections through a causal lens, focusing on anti-causal prediction tasks, where the input to a classifier (e.g., an image) is assumed to be generated as a function of the target label and the protected attribute. By taking this perspective, we draw explicit connections between a common fairness criterion - separation - and a common notion of robustness - risk invariance. These connections provide new motivation for applying the separation criterion in anticausal settings, and inform old discussions regarding fairness-performance tradeoffs. In addition, our findings suggest that robustness-motivated approaches can be used to enforce separation, and that they often work better in practice than methods designed to directly enforce separation. Using a medical dataset, we empirically validate our findings on the task of detecting pneumonia from X-rays, in a setting where differences in prevalence across sex groups motivates a fairness mitigation. Our findings highlight the importance of considering causal structure when choosing and enforcing fairness criteria",
    "checked": true,
    "id": "f7f24b42836539b19186b08f788d7c93914d119b",
    "semantic_title": "fairness and robustness in anti-causal prediction",
    "citation_count": 12,
    "authors": [
      "Maggie Makar",
      "Alexander D'Amour"
    ]
  },
  "https://openreview.net/forum?id=bx24KpJ4Eb": {
    "title": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback",
    "volume": "survey",
    "abstract": "Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-layered approach to the development of safer AI systems",
    "checked": true,
    "id": "6eb46737bf0ef916a7f906ec6a8da82a45ffb623",
    "semantic_title": "open problems and fundamental limitations of reinforcement learning from human feedback",
    "citation_count": 564,
    "authors": [
      "Stephen Casper",
      "Xander Davies",
      "Claudia Shi",
      "Thomas Krendl Gilbert",
      "Jérémy Scheurer",
      "Javier Rando",
      "Rachel Freedman",
      "Tomek Korbak",
      "David Lindner",
      "Pedro Freire",
      "Tony Tong Wang",
      "Samuel Marks",
      "Charbel-Raphael Segerie",
      "Micah Carroll",
      "Andi Peng",
      "Phillip J.K. Christoffersen",
      "Mehul Damani",
      "Stewart Slocum",
      "Usman Anwar",
      "Anand Siththaranjan",
      "Max Nadeau",
      "Eric J Michaud",
      "Jacob Pfau",
      "Dmitrii Krasheninnikov",
      "Xin Chen",
      "Lauro Langosco",
      "Peter Hase",
      "Erdem Biyik",
      "Anca Dragan",
      "David Krueger",
      "Dorsa Sadigh",
      "Dylan Hadfield-Menell"
    ]
  },
  "https://openreview.net/forum?id=ed8SkMdYFT": {
    "title": "Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods",
    "volume": "featured",
    "abstract": "Stochastic gradient descent (SGD) and adaptive gradient methods, such as Adam and RMSProp, have been widely used in training deep neural networks. We empirically show that while the difference between the standard generalization performance of models trained using these methods is small, those trained using SGD exhibit far greater robustness under input perturbations. Notably, our investigation demonstrates the presence of irrelevant frequencies in natural datasets, where alterations do not affect models' generalization performance. However, models trained with adaptive methods show sensitivity to these changes, suggesting that their use of irrelevant frequencies can lead to solutions sensitive to perturbations. To better understand this difference, we study the learning dynamics of gradient descent (GD) and sign gradient descent (signGD) on a synthetic dataset that mirrors natural signals. With a three-dimensional input space, the models optimized with GD and signGD have standard risks close to zero but vary in their adversarial risks. Our result shows that linear models' robustness to $\\ell_2$-norm bounded changes is inversely proportional to the model parameters' weight norm: a smaller weight norm implies better robustness. In the context of deep learning, our experiments show that SGD-trained neural networks have smaller Lipschitz constants, explaining the better robustness to input perturbations than those trained with adaptive gradient methods. Our source code is available at https://github.com/averyma/opt-robust",
    "checked": true,
    "id": "bc9b799d50bf14f3b5b3af87a137a748be1854ef",
    "semantic_title": "understanding the robustness difference between stochastic gradient descent and adaptive gradient methods",
    "citation_count": 7,
    "authors": [
      "Avery Ma",
      "Yangchen Pan",
      "Amir-massoud Farahmand"
    ]
  },
  "https://openreview.net/forum?id=ioFIAQOBOS": {
    "title": "Learning to reconstruct signals from binary measurements alone",
    "volume": "featured",
    "abstract": "Recent advances in unsupervised learning have highlighted the possibility of learning to reconstruct signals from noisy and incomplete linear measurements alone. These methods play a key role in medical and scientific imaging and sensing, where ground truth data is often scarce or difficult to obtain. However, in practice measurements are not only noisy and incomplete but also quantized. Here we explore the extreme case of learning from binary observations and provide necessary and sufficient conditions on the number of measurements required for identifying a set of signals from incomplete binary data. Our results are complementary to existing bounds on signal recovery from binary measurements. Furthermore, we introduce a novel self-supervised learning approach, which we name SSBM, that only requires binary data for training. We demonstrate in a series of experiments with real datasets that SSBM performs on par with supervised learning and outperforms sparse reconstruction methods with a fixed wavelet basis by a large margin",
    "checked": false,
    "id": "7bc2556370238b0d8d888cb16c753c082b722a47",
    "semantic_title": "learning to reconstruct signals from binary measurements",
    "citation_count": 2,
    "authors": [
      "Julián Tachella",
      "Laurent Jacques"
    ]
  },
  "https://openreview.net/forum?id=DwgRm72GQF": {
    "title": "Inverse Scaling: When Bigger Isn't Better",
    "volume": "featured",
    "abstract": "Work on scaling laws has found that large language models (LMs) show predictable improvements to overall loss with increased scale (model size, training data, and compute). Here, we present evidence for the claim that LMs may show inverse scaling, or worse task performance with increased scale, e.g., due to flaws in the training objective and data. We present empirical evidence of inverse scaling on 11 datasets collected by running a public contest, the Inverse Scaling Prize, with a substantial prize pool. Through analysis of the datasets, along with other examples found in the literature, we identify four potential causes of inverse scaling: (i) preference to repeat memorized sequences over following in-context instructions, (ii) imitation of undesirable patterns in the training data, (iii) tasks containing an easy distractor task which LMs could focus on, rather than the harder real task, and (iv) correct but misleading few-shot demonstrations of the task. We release the winning datasets at inversescaling.com/data to allow for further investigation of inverse scaling. Our tasks have helped drive the discovery of U-shaped and inverted-U scaling trends, where an initial trend reverses, suggesting that scaling trends are less reliable at predicting the behavior of larger-scale models than previously understood. Overall, our results suggest that there are tasks for which increased model scale alone may not lead to progress, and that more careful thought needs to go into the data and objectives for training language models",
    "checked": true,
    "id": "31d65e179b1d00484154b3525d93846dd82f23d8",
    "semantic_title": "inverse scaling: when bigger isn't better",
    "citation_count": 149,
    "authors": [
      "Ian R. McKenzie",
      "Alexander Lyzhov",
      "Michael Martin Pieler",
      "Alicia Parrish",
      "Aaron Mueller",
      "Ameya Prabhu",
      "Euan McLean",
      "Xudong Shen",
      "Joe Cavanagh",
      "Andrew George Gritsevskiy",
      "Derik Kauffman",
      "Aaron T. Kirtland",
      "Zhengping Zhou",
      "Yuhui Zhang",
      "Sicong Huang",
      "Daniel Wurgaft",
      "Max Weiss",
      "Alexis Ross",
      "Gabriel Recchia",
      "Alisa Liu",
      "Jiacheng Liu",
      "Tom Tseng",
      "Tomasz Korbak",
      "Najoung Kim",
      "Samuel R. Bowman",
      "Ethan Perez"
    ]
  },
  "https://openreview.net/forum?id=a7nvXxNmdV": {
    "title": "Improved baselines for vision-language pre-training",
    "volume": "featured",
    "abstract": "Contrastive learning has emerged as an efficient framework to learn multimodal representations. CLIP, a seminal work in this area, achieved impressive results by training on paired image-text data using the contrastive loss. Recent work claims improvements over CLIP using additional non-contrastive losses inspired from self-supervised learning. However, it is sometimes hard to disentangle the contribution of these additional losses from other implementation details, \\eg, data augmentation or regularization techniques, used to train the model. To shed light on this matter, in this paper, we first propose, implement and evaluate several baselines obtained by combining contrastive learning with recent advances in self-supervised learning. In particular, we use the loss functions that were proven successful for visual self-supervised learning to align image and text modalities. We find that these baselines outperform a basic implementation of CLIP. However, when a stronger training recipe is employed, the advantage disappears. Indeed, we find that a simple CLIP baseline can also be improved substantially, up to a 25\\% relative improvement on downstream zero-shot tasks, by using well-known training techniques that are popular in other subfields. Moreover, we discover that it is enough to apply image and text augmentations to make up for most of the improvement attained by prior works. With our improved training recipe for CLIP, we obtain state-of-the-art performance on four standard datasets, and consistently outperform prior work (up to +4\\% on the largest dataset), while being substantially simpler",
    "checked": true,
    "id": "f6acf07b93347884699d838c91d6a83a9499e31d",
    "semantic_title": "improved baselines for vision-language pre-training",
    "citation_count": 24,
    "authors": [
      "Enrico Fini",
      "Pietro Astolfi",
      "Adriana Romero-Soriano",
      "Jakob Verbeek",
      "Michal Drozdzal"
    ]
  },
  "https://openreview.net/forum?id=UIalYAHdBH": {
    "title": "On the Sample Complexity of Lipschitz Constant Estimation",
    "volume": "featured",
    "abstract": "Estimating the Lipschitz constant of a function, also known as Lipschitz learning, is a fundamental problem with broad applications in fields such as control and global optimization. In this paper, we study the Lipschitz learning problem with minimal parametric assumptions on the target function. As a first theoretical contribution, we derive novel lower bounds on the sample complexity of this problem for both noise-free and noisy settings under mild assumptions. Moreover, we propose a simple Lipschitz learning algorithm called $\\textit{Lipschitz Constant Estimation by Least Squares Regression}$ (referred to as LCLS). We show that LCLS is asymptotically consistent for general noise assumptions and offers finite sample guarantees that can be translated to new upper bounds on the sample complexity of the Lipschitz learning problem. Our analysis shows that the sample complexity rates derived in this paper are optimal in both the noise-free setting and in the noisy setting when the noise is assumed to follow a Gaussian distribution and that LCLS is a sample-optimal algorithm in both cases. Finally, we show that by design, the LCLS algorithm is computationally faster than existing theoretically consistent methods, and can be readily adapted to various noise assumptions with little to no prior knowledge of the target function properties or noise distribution",
    "checked": true,
    "id": "fedd7bd92a1ee912275796e6e5c2cc973d068560",
    "semantic_title": "on the sample complexity of lipschitz constant estimation",
    "citation_count": 11,
    "authors": [
      "Julien Walden Huang",
      "Stephen J. Roberts",
      "Jan-Peter Calliess"
    ]
  },
  "https://openreview.net/forum?id=XXfEmIMJDm": {
    "title": "Achieving the Pareto Frontier of Regret Minimization and Best Arm Identification in Multi-Armed Bandits",
    "volume": "featured",
    "abstract": "We study the Pareto frontier of two archetypal objectives in multi-armed bandits, namely, regret minimization (RM) and best arm identification (BAI) with a fixed horizon. It is folklore that the balance between exploitation and exploration is crucial for both RM and BAI, but exploration is more critical in achieving the optimal performance for the latter objective. To this end, we design and analyze the BoBW-lil'UCB($\\gamma$) algorithm. Complementarily, by establishing lower bounds on the regret achievable by any algorithm with a given BAI failure probability, we show that (i) no algorithm can simultaneously perform optimally for both the RM and BAI objectives, and (ii) BoBW-lil'UCB($\\gamma$) achieves order-wise optimal performance for RM or BAI under different values of $\\gamma$. Our work elucidates the trade-off more precisely by showing how the constants in previous works depend on certain hardness parameters. Finally, we show that BoBW-lil'UCB outperforms a close competitor UCB$_\\alpha$ (Degenne et al., 2019) in terms of the time complexity and the regret on diverse datasets such as MovieLens and Published Kinase Inhibitor Set",
    "checked": true,
    "id": "25675ad6d49e3b8575c8b3aff0c218a770a92ef0",
    "semantic_title": "achieving the pareto frontier of regret minimization and best arm identification in multi-armed bandits",
    "citation_count": 5,
    "authors": [
      "Zixin Zhong",
      "Wang Chi Cheung",
      "Vincent Tan"
    ]
  },
  "https://openreview.net/forum?id=ivCd8z8zR2": {
    "title": "High Fidelity Neural Audio Compression",
    "volume": "reprod",
    "abstract": "We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks. It consists in a streaming encoder-decoder architecture with quantized latent space trained in an end-to-end fashion. We simplify and speed-up the training by using a single multiscale spectrogram adversary that efficiently reduces artifacts and produce high-quality samples. We introduce a novel loss balancer mechanism to stabilize training: the weight of a loss now defines the fraction of the overall gradient it should represent, thus decoupling the choice of this hyper-parameter from the typical scale of the loss. Finally, we study how lightweight Transformer models can be used to further compress the obtained representation by up to 40%, while staying faster than real time. We provide a detailed description of the key design choices of the proposed model including: training objective, architectural changes and a study of various perceptual loss functions. We present an extensive subjective evaluation (MUSHRA tests) together with an ablation study for a range of bandwidths and audio domains, including speech, noisy-reverberant speech, and music. Our approach is superior to the baselines methods across all evaluated settings, considering both 24 kHz monophonic and 48 kHz stereophonic audio. Code and samples are available under github.com/facebookresearch/encodec",
    "checked": true,
    "id": "cdcfeb447fa8554c131c0a13a7ffcba30c0381e1",
    "semantic_title": "high fidelity neural audio compression",
    "citation_count": 730,
    "authors": [
      "Alexandre Défossez",
      "Jade Copet",
      "Gabriel Synnaeve",
      "Yossi Adi"
    ]
  },
  "https://openreview.net/forum?id=EGQSpkUDdD": {
    "title": "AP: Selective Activation for De-sparsifying Pruned Networks",
    "volume": "featured",
    "abstract": "The rectified linear unit (ReLU) is a highly successful activation function in neural networks as it allows networks to easily obtain sparse representations, which reduces overfitting in overparameterized networks. However, in the context of network pruning, we find that the sparsity introduced by ReLU, which we quantify by a term called dynamic dead neuron rate (DNR), is not beneficial for the pruned network. Interestingly, the more the network is pruned, the smaller the dynamic DNR becomes during and after optimization. This motivates us to propose a method to explicitly reduce the dynamic DNR for the pruned network, i.e., de-sparsify the network. We refer to our method as Activate-while-Pruning (AP). We note that AP does not function as a stand-alone method, as it does not evaluate the importance of weights. Instead, it works in tandem with existing pruning methods and aims to improve their performance by selective activation of nodes to reduce the dynamic DNR. We conduct extensive experiments using various popular networks (e.g., ResNet, VGG, DenseNet, MobileNet) via two classical and three state-of-the-art pruning methods. The experimental results on public datasets (e.g., CIFAR-10, CIFAR-100) suggest that AP works well with existing pruning methods and improves the performance by 3% - 4%. For larger scale datasets (e.g., ImageNet) and state-of-the-art networks (e.g., vision transformer), we observe an improvement of 2% - 3% with AP as opposed to without. Lastly, we conduct an ablation study to examine the effectiveness of the components comprising AP",
    "checked": true,
    "id": "c8d6a12a973d9624699ef3e5a9e0085b4ff62533",
    "semantic_title": "ap: selective activation for de-sparsifying pruned networks",
    "citation_count": 0,
    "authors": [
      "Shiyu Liu",
      "Rohan Ghosh",
      "Mehul Motani"
    ]
  },
  "https://openreview.net/forum?id=mvftzofTYQ": {
    "title": "WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series",
    "volume": "featured",
    "abstract": "Deep learning models often fail to generalize well under distribution shifts. Understanding and overcoming these failures have led to a new research field on Out-of-Distribution (OOD) generalization. Despite being extensively studied for static computer vision tasks, OOD generalization has been severely underexplored for time series tasks. To shine a light on this gap, we present WOODS: 10 challenging time series benchmarks covering a diverse range of data modalities, such as videos, brain recordings, and smart device sensory signals. We revise the existing OOD generalization algorithms for time series tasks and evaluate them using our systematic framework. Our experiments show a large room for improvement for empirical risk minimization and OOD generalization algorithms on our datasets, thus underscoring the new challenges posed by time series tasks",
    "checked": false,
    "id": "2c6230fd6c474790d3a3199b8491bef0d54f8fd3",
    "semantic_title": "woods: benchmarks for out-of-distribution generalization in time series tasks",
    "citation_count": 32,
    "authors": [
      "Jean-Christophe Gagnon-Audet",
      "Kartik Ahuja",
      "Mohammad Javad Darvishi Bayazi",
      "Pooneh Mousavi",
      "Guillaume Dumas",
      "Irina Rish"
    ]
  },
  "https://openreview.net/forum?id=iO4LZibEqW": {
    "title": "Holistic Evaluation of Language Models",
    "volume": "outstanding",
    "abstract": "Language models (LMs) are becoming the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of language models. First, we taxonomize the vast space of potential scenarios (i.e. use cases) and metrics (i.e. desiderata) that are of interest for LMs. Then we select a broad subset based on coverage and feasibility, noting what's missing or underrepresented (e.g. question answering for neglected English dialects, metrics for trustworthiness). Second, we adopt a multi-metric approach: We measure 7 metrics (accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency) for each of 16 core scenarios to the extent possible (87.5% of the time), ensuring that metrics beyond accuracy don't fall to the wayside, and that trade-offs across models and metrics are clearly exposed. We also perform 7 targeted evaluations, based on 26 targeted scenarios, to more deeply analyze specific aspects (e.g. knowledge, reasoning, memorization/copyright, disinformation). Third, we conduct a large-scale evaluation of 30 prominent language models (spanning open, limited-access, and closed models) on all 42 scenarios, including 21 scenarios that were not previously used in mainstream LM evaluation. Prior to HELM, models on average were evaluated on just 17.9% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0%: now all 30 models have been densely benchmarked on a set of core scenarios and metrics under standardized conditions. Our evaluation surfaces 25 top-level findings concerning the interplay between different scenarios, metrics, and models. For full transparency, we release all raw model prompts and completions publicly for further analysis, as well as a general modular toolkit for easily adding new scenarios, models, metrics, and prompting strategies. We intend for HELM to be a living benchmark for the community, continuously updated with new scenarios, metrics, and models",
    "checked": true,
    "id": "ce913026f693101e54d3ab9152e107034d81fce1",
    "semantic_title": "holistic evaluation of language models",
    "citation_count": 1034,
    "authors": [
      "Percy Liang",
      "Rishi Bommasani",
      "Tony Lee",
      "Dimitris Tsipras",
      "Dilara Soylu",
      "Michihiro Yasunaga",
      "Yian Zhang",
      "Deepak Narayanan",
      "Yuhuai Wu",
      "Ananya Kumar",
      "Benjamin Newman",
      "Binhang Yuan",
      "Bobby Yan",
      "Ce Zhang",
      "Christian Cosgrove",
      "Christopher D Manning",
      "Christopher Re",
      "Diana Acosta-Navas",
      "Drew A. Hudson",
      "Eric Zelikman",
      "Esin Durmus",
      "Faisal Ladhak",
      "Frieda Rong",
      "Hongyu Ren",
      "Huaxiu Yao",
      "Jue WANG",
      "Keshav Santhanam",
      "Laurel Orr",
      "Lucia Zheng",
      "Mert Yuksekgonul",
      "Mirac Suzgun",
      "Nathan Kim",
      "Neel Guha",
      "Niladri S. Chatterji",
      "Omar Khattab",
      "Peter Henderson",
      "Qian Huang",
      "Ryan Andrew Chi",
      "Sang Michael Xie",
      "Shibani Santurkar",
      "Surya Ganguli",
      "Tatsunori Hashimoto",
      "Thomas Icard",
      "Tianyi Zhang",
      "Vishrav Chaudhary",
      "William Wang",
      "Xuechen Li",
      "Yifan Mai",
      "Yuhui Zhang",
      "Yuta Koreeda"
    ]
  },
  "https://openreview.net/forum?id=yrkJGne0vN": {
    "title": "Neural Ordinary Differential Equations for Modeling Epidemic Spreading",
    "volume": "expert",
    "abstract": "Mathematical models of infectious diseases have long been used for studying the mechanisms by which diseases spread, for predicting the spread of epidemics, and also for controlling their outbreaks. These models are based on some assumptions and different assumptions give rise to different models. Models on social networks of individuals which capture contact patterns are usually more realistic and can more accurately model contagion dynamics. Unfortunately, computing the output of realistic models is often hard. Thus, modeling the evolution of contagion dynamics over large complex networks constitutes a challenging task. In this paper, we present a computational approach to model the contagion dynamics underlying infectious diseases. Specifically, we focus on the susceptible-infectious-recovered (SIR) epidemic model on networks. Given that this model can be expressed by an intractable system of ordinary differential equations, we devise a simpler system that approximates the output of the model. Then, we capitalize on recent advances in neural ordinary differential equations and propose a neural architecture that can effectively predict the course of an epidemic on the network. We apply the proposed architecture on several network datasets and compare it against state-of-the-art methods under different experimental settings. Our results indicate that the proposed method improves predictions in various spreading scenarios, paving the way for the extensive application of interpretable neural networks in the field of epidemic spreading. At the same time, the proposed model is highly efficient even when trained on very large networks where traditional algorithms become significantly slower",
    "checked": true,
    "id": "02c282db6cc2cdedf79d4d3cc8e2aa4e055c56b8",
    "semantic_title": "neural ordinary differential equations for modeling epidemic spreading",
    "citation_count": 9,
    "authors": [
      "Chrysoula Kosma",
      "Giannis Nikolentzos",
      "George Panagopoulos",
      "Jean-Marc Steyaert",
      "Michalis Vazirgiannis"
    ]
  },
  "https://openreview.net/forum?id=2mZSlQscj3": {
    "title": "Neural Monge Map estimation and its applications",
    "volume": "featured",
    "abstract": "Monge map refers to the optimal transport map between two probability distributions and provides a principled approach to transform one distribution to another. Neural network-based optimal transport map solver has gained great attention in recent years. Along this line, we present a scalable algorithm for computing the neural Monge map between two probability distributions. Our algorithm is based on a weak form of the optimal transport problem, thus it only requires samples from the marginals instead of their analytic expressions, and can be applied in large-scale settings. Furthermore, using the duality gap we prove rigorously \\textit{a posteriori} error analysis for the method. Our algorithm is suitable for general cost functions, compared with other existing methods for estimating Monge maps using samples, which are usually for quadratic costs. The performance of our algorithms is demonstrated through a series of experiments with both synthetic and realistic data, including text-to-image generation, class-preserving map, and image inpainting tasks",
    "checked": true,
    "id": "01cf79938c9c9572ffbdf89b69802419c8ab24ca",
    "semantic_title": "neural monge map estimation and its applications",
    "citation_count": 29,
    "authors": [
      "Jiaojiao Fan",
      "Shu Liu",
      "Shaojun Ma",
      "Hao-Min Zhou",
      "Yongxin Chen"
    ]
  },
  "https://openreview.net/forum?id=igdWKxK5RZ": {
    "title": "Finding and Only Finding Differential Nash Equilibria by Both Pretending to be a Follower",
    "volume": "featured",
    "abstract": "Finding Nash equilibria in two-player differentiable games is a classical problem in game theory with important relevance in machine learning. We propose double Follow-the-Ridge (double-FTR), an algorithm that locally converges to and only to differential Nash equilibria in general-sum two-player differentiable games. To our knowledge, double-FTR is the first algorithm with such guarantees for general-sum games. Furthermore, we show that by varying its preconditioner, double-FTR leads to a broader family of algorithms with the same convergence guarantee. In addition, double-FTR avoids oscillation near equilibria due to the real-eigenvalues of its Jacobian at fixed points. Empirically, we validate the double-FTR algorithm on a range of simple zero-sum and general sum games, as well as simple Generative Adversarial Network (GAN) tasks",
    "checked": true,
    "id": "b6561ec7a10618593e2b7d81d74c6558f5071f6a",
    "semantic_title": "finding and only finding differential nash equilibria by both pretending to be a follower",
    "citation_count": 0,
    "authors": [
      "Xuchan Bao",
      "Guodong Zhang"
    ]
  },
  "https://openreview.net/forum?id=25G63lDHV2": {
    "title": "Efficient Reward Poisoning Attacks on Online Deep Reinforcement Learning",
    "volume": "featured",
    "abstract": "We study reward poisoning attacks on online deep reinforcement learning (DRL), where the attacker is oblivious to the learning algorithm used by the agent and the dynamics of the environment. We demonstrate the intrinsic vulnerability of state-of-the-art DRL algorithms by designing a general, black-box reward poisoning framework called adversarial MDP attacks. We instantiate our framework to construct two new attacks which only corrupt the rewards for a small fraction of the total training timesteps and make the agent learn a low-performing policy. We provide a theoretical analysis of the efficiency of our attack and perform an extensive empirical evaluation. Our results show that our attacks efficiently poison agents learning in several popular classical control and MuJoCo environments with a variety of state-of-the-art DRL algorithms, such as DQN, PPO, SAC, etc",
    "checked": true,
    "id": "e3ffdea7a763991114252275cc7258c6a8c83eb3",
    "semantic_title": "efficient reward poisoning attacks on online deep reinforcement learning",
    "citation_count": 7,
    "authors": [
      "Yinglun Xu",
      "Qi Zeng",
      "Gagandeep Singh"
    ]
  },
  "https://openreview.net/forum?id=VmyFF5lL3F": {
    "title": "Inversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration",
    "volume": "outstanding",
    "abstract": "Inversion by Direct Iteration (InDI) is a new formulation for supervised image restoration that avoids the so-called ``regression to the mean'' effect and produces more realistic and detailed images than existing regression-based methods. It does this by gradually improving image quality in small steps, similar to generative denoising diffusion models. Image restoration is an ill-posed problem where multiple high-quality images are plausible reconstructions of a given low-quality input. Therefore, the outcome of a single step regression model is typically an aggregate of all possible explanations, therefore lacking details and realism. The main advantage of InDI is that it does not try to predict the clean target image in a single step but instead gradually improves the image in small steps, resulting in better perceptual quality. While generative denoising diffusion models also work in small steps, our formulation is distinct in that it does not require knowledge of any analytic form of the degradation process. Instead, we directly learn an iterative restoration process from low-quality and high-quality paired examples. InDI can be applied to virtually any image degradation, given paired training data. In conditional denoising diffusion image restoration the denoising network generates the restored image by repeatedly denoising an initial image of pure noise, conditioned on the degraded input. Contrary to conditional denoising formulations, InDI directly proceeds by iteratively restoring the input low-quality image, producing high-quality results on a variety of image restoration tasks, including motion and out-of-focus deblurring, super-resolution, compression artifact removal, and denoising",
    "checked": true,
    "id": "026133b8636adfa1ba40d4a7d8250ef498624ef6",
    "semantic_title": "inversion by direct iteration: an alternative to denoising diffusion for image restoration",
    "citation_count": 135,
    "authors": [
      "Mauricio Delbracio",
      "Peyman Milanfar"
    ]
  },
  "https://openreview.net/forum?id=vXSsTYs6ZB": {
    "title": "LEAD: Min-Max Optimization from a Physical Perspective",
    "volume": "featured",
    "abstract": "Adversarial formulations such as generative adversarial networks (GANs) have rekindled interest in two-player min-max games. A central obstacle in the optimization of such games is the rotational dynamics that hinder their convergence. In this paper, we show that game optimization shares dynamic properties with particle systems subject to multiple forces, and one can leverage tools from physics to improve optimization dynamics. Inspired by the physical framework, we propose LEAD, an optimizer for min-max games. Next, using Lyapunov stability theory and spectral analysis, we study LEAD's convergence properties in continuous and discrete time settings for a class of quadratic min-max games to demonstrate linear convergence to the Nash equilibrium. Finally, we empirically evaluate our method on synthetic setups and CIFAR-10 image generation to demonstrate improvements in GAN training",
    "checked": false,
    "id": "ef4b26fa66c921aad4faa8ee1673431641e93f48",
    "semantic_title": "an enhanced ofdm light weight physical layer encryption scheme",
    "citation_count": 1,
    "authors": [
      "Reyhane Askari Hemmat",
      "Amartya Mitra",
      "Guillaume Lajoie",
      "Ioannis Mitliagkas"
    ]
  },
  "https://openreview.net/forum?id=XNFo3dQiCJ": {
    "title": "Generalizability of Adversarial Robustness Under Distribution Shifts",
    "volume": "featured",
    "abstract": "Recent progress in empirical and certified robustness promises to deliver reliable and deployable Deep Neural Networks (DNNs). Despite that success, most existing evaluations of DNN robustness have been done on images sampled from the same distribution on which the model was trained on. However, in the real world, DNNs may be deployed in dynamic environments that exhibit significant distribution shifts. In this work, we take a first step towards thoroughly investigating the interplay between empirical and certified adversarial robustness on one hand and domain generalization on another. To do so, we train robust models on multiple domains and evaluate their accuracy and robustness on an unseen domain. We observe that: (1) both empirical and certified robustness generalize to unseen domains, and (2) the level of generalizability does not correlate well with input visual similarity, measured by the FID between source and target domains. We also extend our study to cover a real-world medical application, in which adversarial augmentation significantly boosts the generalization of robustness with minimal effect on clean data accuracy",
    "checked": true,
    "id": "691c9ad4b629be8e0de737a7ba80ef0417dbd964",
    "semantic_title": "generalizability of adversarial robustness under distribution shifts",
    "citation_count": 10,
    "authors": [
      "Kumail Alhamoud",
      "Hasan Abed Al Kader Hammoud",
      "Motasem Alfarra",
      "Bernard Ghanem"
    ]
  },
  "https://openreview.net/forum?id=r9vGSpbbRO": {
    "title": "Attacking Perceptual Similarity Metrics",
    "volume": "featured",
    "abstract": "Perceptual similarity metrics have progressively become more correlated with human judgments on perceptual similarity; however, despite recent advances, the addition of an imperceptible distortion can still compromise these metrics. In our study, we systematically examine the robustness of these metrics to imperceptible adversarial perturbations. Following the two-alternative forced-choice experimental design with two distorted images and one reference image, we perturb the distorted image closer to the reference via an adversarial attack until the metric flips its judgment. We first show that all metrics in our study are susceptible to perturbations generated via common adversarial attacks such as FGSM, PGD, and the One-pixel attack. Next, we attack the widely adopted LPIPS metric using spatial-transformation-based adversarial perturbations (stAdv) in a white-box setting to craft adversarial examples that can effectively transfer to other similarity metrics in a black-box setting. We also combine the spatial attack stAdv with PGD ($\\ell_\\infty$-bounded) attack to increase transferability and use these adversarial examples to benchmark the robustness of both traditional and recently developed metrics. Our benchmark provides a good starting point for discussion and further research on the robustness of metrics to imperceptible adversarial perturbations",
    "checked": true,
    "id": "4b410be4f1fb02d8ea29e2fc1196efffe3106bc0",
    "semantic_title": "attacking perceptual similarity metrics",
    "citation_count": 10,
    "authors": [
      "Abhijay Ghildyal",
      "Feng Liu"
    ]
  },
  "https://openreview.net/forum?id=uyTL5Bvosj": {
    "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models",
    "volume": "featured",
    "abstract": "Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG- bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood develop- ment, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google- internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit \"breakthrough\" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting",
    "checked": true,
    "id": "9dfe937f405b95bfc5e8e3679329a1f16b37e276",
    "semantic_title": "beyond the imitation game: quantifying and extrapolating the capabilities of language models",
    "citation_count": 245,
    "authors": [
      "Aarohi Srivastava",
      "Abhinav Rastogi",
      "Abhishek Rao",
      "Abu Awal Md Shoeb",
      "Abubakar Abid",
      "Adam Fisch",
      "Adam R. Brown",
      "Adam Santoro",
      "Aditya Gupta",
      "Adrià Garriga-Alonso",
      "Agnieszka Kluska",
      "Aitor Lewkowycz",
      "Akshat Agarwal",
      "Alethea Power",
      "Alex Ray",
      "Alex Warstadt",
      "Alexander W. Kocurek",
      "Ali Safaya",
      "Ali Tazarv",
      "Alice Xiang",
      "Alicia Parrish",
      "Allen Nie",
      "Aman Hussain",
      "Amanda Askell",
      "Amanda Dsouza",
      "Ambrose Slone",
      "Ameet Rahane",
      "Anantharaman S. Iyer",
      "Anders Johan Andreassen",
      "Andrea Madotto",
      "Andrea Santilli",
      "Andreas Stuhlmüller",
      "Andrew M. Dai",
      "Andrew La",
      "Andrew Kyle Lampinen",
      "Andy Zou",
      "Angela Jiang",
      "Angelica Chen",
      "Anh Vuong",
      "Animesh Gupta",
      "Anna Gottardi",
      "Antonio Norelli",
      "Anu Venkatesh",
      "Arash Gholamidavoodi",
      "Arfa Tabassum",
      "Arul Menezes",
      "Arun Kirubarajan",
      "Asher Mullokandov",
      "Ashish Sabharwal",
      "Austin Herrick",
      "Avia Efrat",
      "Aykut Erdem",
      "Ayla Karakaş",
      "B. Ryan Roberts",
      "Bao Sheng Loe",
      "Barret Zoph",
      "Bartłomiej Bojanowski",
      "Batuhan Özyurt",
      "Behnam Hedayatnia",
      "Behnam Neyshabur",
      "Benjamin Inden",
      "Benno Stein",
      "Berk Ekmekci",
      "Bill Yuchen Lin",
      "Blake Howald",
      "Bryan Orinion",
      "Cameron Diao",
      "Cameron Dour",
      "Catherine Stinson",
      "Cedrick Argueta",
      "Cesar Ferri",
      "Chandan Singh",
      "Charles Rathkopf",
      "Chenlin Meng",
      "Chitta Baral",
      "Chiyu Wu",
      "Chris Callison-Burch",
      "Christopher Waites",
      "Christian Voigt",
      "Christopher D Manning",
      "Christopher Potts",
      "Cindy Ramirez",
      "Clara E. Rivera",
      "Clemencia Siro",
      "Colin Raffel",
      "Courtney Ashcraft",
      "Cristina Garbacea",
      "Damien Sileo",
      "Dan Garrette",
      "Dan Hendrycks",
      "Dan Kilman",
      "Dan Roth",
      "C. Daniel Freeman",
      "Daniel Khashabi",
      "Daniel Levy",
      "Daniel Moseguí González",
      "Danielle Perszyk",
      "Danny Hernandez",
      "Danqi Chen",
      "Daphne Ippolito",
      "Dar Gilboa",
      "David Dohan",
      "David Drakard",
      "David Jurgens",
      "Debajyoti Datta",
      "Deep Ganguli",
      "Denis Emelin",
      "Denis Kleyko",
      "Deniz Yuret",
      "Derek Chen",
      "Derek Tam",
      "Dieuwke Hupkes",
      "Diganta Misra",
      "Dilyar Buzan",
      "Dimitri Coelho Mollo",
      "Diyi Yang",
      "Dong-Ho Lee",
      "Dylan Schrader",
      "Ekaterina Shutova",
      "Ekin Dogus Cubuk",
      "Elad Segal",
      "Eleanor Hagerman",
      "Elizabeth Barnes",
      "Elizabeth Donoway",
      "Ellie Pavlick",
      "Emanuele Rodolà",
      "Emma Lam",
      "Eric Chu",
      "Eric Tang",
      "Erkut Erdem",
      "Ernie Chang",
      "Ethan A Chi",
      "Ethan Dyer",
      "Ethan Jerzak",
      "Ethan Kim",
      "Eunice Engefu Manyasi",
      "Evgenii Zheltonozhskii",
      "Fanyue Xia",
      "Fatemeh Siar",
      "Fernando Martínez-Plumed",
      "Francesca Happé",
      "Francois Chollet",
      "Frieda Rong",
      "Gaurav Mishra",
      "Genta Indra Winata",
      "Gerard de Melo",
      "Germàn Kruszewski",
      "Giambattista Parascandolo",
      "Giorgio Mariani",
      "Gloria Xinyue Wang",
      "Gonzalo Jaimovitch-Lopez",
      "Gregor Betz",
      "Guy Gur-Ari",
      "Hana Galijasevic",
      "Hannah Kim",
      "Hannah Rashkin",
      "Hannaneh Hajishirzi",
      "Harsh Mehta",
      "Hayden Bogar",
      "Henry Francis Anthony Shevlin",
      "Hinrich Schuetze",
      "Hiromu Yakura",
      "Hongming Zhang",
      "Hugh Mee Wong",
      "Ian Ng",
      "Isaac Noble",
      "Jaap Jumelet",
      "Jack Geissinger",
      "Jackson Kernion",
      "Jacob Hilton",
      "Jaehoon Lee",
      "Jaime Fernández Fisac",
      "James B Simon",
      "James Koppel",
      "James Zheng",
      "James Zou",
      "Jan Kocon",
      "Jana Thompson",
      "Janelle Wingfield",
      "Jared Kaplan",
      "Jarema Radom",
      "Jascha Sohl-Dickstein",
      "Jason Phang",
      "Jason Wei",
      "Jason Yosinski",
      "Jekaterina Novikova",
      "Jelle Bosscher",
      "Jennifer Marsh",
      "Jeremy Kim",
      "Jeroen Taal",
      "Jesse Engel",
      "Jesujoba Alabi",
      "Jiacheng Xu",
      "Jiaming Song",
      "Jillian Tang",
      "Joan Waweru",
      "John Burden",
      "John Miller",
      "John U. Balis",
      "Jonathan Batchelder",
      "Jonathan Berant",
      "Jörg Frohberg",
      "Jos Rozen",
      "Jose Hernandez-Orallo",
      "Joseph Boudeman",
      "Joseph Guerr",
      "Joseph Jones",
      "Joshua B. Tenenbaum",
      "Joshua S. Rule",
      "Joyce Chua",
      "Kamil Kanclerz",
      "Karen Livescu",
      "Karl Krauth",
      "Karthik Gopalakrishnan",
      "Katerina Ignatyeva",
      "Katja Markert",
      "Kaustubh Dhole",
      "Kevin Gimpel",
      "Kevin Omondi",
      "Kory Wallace Mathewson",
      "Kristen Chiafullo",
      "Ksenia Shkaruta",
      "Kumar Shridhar",
      "Kyle McDonell",
      "Kyle Richardson",
      "Laria Reynolds",
      "Leo Gao",
      "Li Zhang",
      "Liam Dugan",
      "Lianhui Qin",
      "Lidia Contreras-Ochando",
      "Louis-Philippe Morency",
      "Luca Moschella",
      "Lucas Lam",
      "Lucy Noble",
      "Ludwig Schmidt",
      "Luheng He",
      "Luis Oliveros-Colón",
      "Luke Metz",
      "Lütfi Kerem Senel",
      "Maarten Bosma",
      "Maarten Sap",
      "Maartje Ter Hoeve",
      "Maheen Farooqi",
      "Manaal Faruqui",
      "Mantas Mazeika",
      "Marco Baturan",
      "Marco Marelli",
      "Marco Maru",
      "Maria Jose Ramirez-Quintana",
      "Marie Tolkiehn",
      "Mario Giulianelli",
      "Martha Lewis",
      "Martin Potthast",
      "Matthew L Leavitt",
      "Matthias Hagen",
      "Mátyás Schubert",
      "Medina Orduna Baitemirova",
      "Melody Arnaud",
      "Melvin McElrath",
      "Michael Andrew Yee",
      "Michael Cohen",
      "Michael Gu",
      "Michael Ivanitskiy",
      "Michael Starritt",
      "Michael Strube",
      "Michał Swędrowski",
      "Michele Bevilacqua",
      "Michihiro Yasunaga",
      "Mihir Kale",
      "Mike Cain",
      "Mimee Xu",
      "Mirac Suzgun",
      "Mitch Walker",
      "Mo Tiwari",
      "Mohit Bansal",
      "Moin Aminnaseri",
      "Mor Geva",
      "Mozhdeh Gheini",
      "Mukund Varma T",
      "Nanyun Peng",
      "Nathan Andrew Chi",
      "Nayeon Lee",
      "Neta Gur-Ari Krakover",
      "Nicholas Cameron",
      "Nicholas Roberts",
      "Nick Doiron",
      "Nicole Martinez",
      "Nikita Nangia",
      "Niklas Deckers",
      "Niklas Muennighoff",
      "Nitish Shirish Keskar",
      "Niveditha S. Iyer",
      "Noah Constant",
      "Noah Fiedel",
      "Nuan Wen",
      "Oliver Zhang",
      "Omar Agha",
      "Omar Elbaghdadi",
      "Omer Levy",
      "Owain Evans",
      "Pablo Antonio Moreno Casares",
      "Parth Doshi",
      "Pascale Fung",
      "Paul Pu Liang",
      "Paul Vicol",
      "Pegah Alipoormolabashi",
      "Peiyuan Liao",
      "Percy Liang",
      "Peter W Chang",
      "Peter Eckersley",
      "Phu Mon Htut",
      "Pinyu Hwang",
      "Piotr Miłkowski",
      "Piyush Patil",
      "Pouya Pezeshkpour",
      "Priti Oli",
      "Qiaozhu Mei",
      "Qing Lyu",
      "Qinlang Chen",
      "Rabin Banjade",
      "Rachel Etta Rudolph",
      "Raefer Gabriel",
      "Rahel Habacker",
      "Ramon Risco",
      "Raphaël Millière",
      "Rhythm Garg",
      "Richard Barnes",
      "Rif A. Saurous",
      "Riku Arakawa",
      "Robbe Raymaekers",
      "Robert Frank",
      "Rohan Sikand",
      "Roman Novak",
      "Roman Sitelew",
      "Ronan Le Bras",
      "Rosanne Liu",
      "Rowan Jacobs",
      "Rui Zhang",
      "Russ Salakhutdinov",
      "Ryan Andrew Chi",
      "Seungjae Ryan Lee",
      "Ryan Stovall",
      "Ryan Teehan",
      "Rylan Yang",
      "Sahib Singh",
      "Saif M. Mohammad",
      "Sajant Anand",
      "Sam Dillavou",
      "Sam Shleifer",
      "Sam Wiseman",
      "Samuel Gruetter",
      "Samuel R. Bowman",
      "Samuel Stern Schoenholz",
      "Sanghyun Han",
      "Sanjeev Kwatra",
      "Sarah A. Rous",
      "Sarik Ghazarian",
      "Sayan Ghosh",
      "Sean Casey",
      "Sebastian Bischoff",
      "Sebastian Gehrmann",
      "Sebastian Schuster",
      "Sepideh Sadeghi",
      "Shadi Hamdan",
      "Sharon Zhou",
      "Shashank Srivastava",
      "Sherry Shi",
      "Shikhar Singh",
      "Shima Asaadi",
      "Shixiang Shane Gu",
      "Shubh Pachchigar",
      "Shubham Toshniwal",
      "Shyam Upadhyay",
      "Shyamolima Shammie Debnath",
      "Siamak Shakeri",
      "Simon Thormeyer",
      "Simone Melzi",
      "Siva Reddy",
      "Sneha Priscilla Makini",
      "Soo-Hwan Lee",
      "Spencer Torene",
      "Sriharsha Hatwar",
      "Stanislas Dehaene",
      "Stefan Divic",
      "Stefano Ermon",
      "Stella Biderman",
      "Stephanie Lin",
      "Stephen Prasad",
      "Steven Piantadosi",
      "Stuart Shieber",
      "Summer Misherghi",
      "Svetlana Kiritchenko",
      "Swaroop Mishra",
      "Tal Linzen",
      "Tal Schuster",
      "Tao Li",
      "Tao Yu",
      "Tariq Ali",
      "Tatsunori Hashimoto",
      "Te-Lin Wu",
      "Théo Desbordes",
      "Theodore Rothschild",
      "Thomas Phan",
      "Tianle Wang",
      "Tiberius Nkinyili",
      "Timo Schick",
      "Timofei Kornev",
      "Titus Tunduny",
      "Tobias Gerstenberg",
      "Trenton Chang",
      "Trishala Neeraj",
      "Tushar Khot",
      "Tyler Shultz",
      "Uri Shaham",
      "Vedant Misra",
      "Vera Demberg",
      "Victoria Nyamai",
      "Vikas Raunak",
      "Vinay Venkatesh Ramasesh",
      "vinay uday prabhu",
      "Vishakh Padmakumar",
      "Vivek Srikumar",
      "William Fedus",
      "William Saunders",
      "William Zhang",
      "Wout Vossen",
      "Xiang Ren",
      "Xiaoyu Tong",
      "Xinran Zhao",
      "Xinyi Wu",
      "Xudong Shen",
      "Yadollah Yaghoobzadeh",
      "Yair Lakretz",
      "Yangqiu Song",
      "Yasaman Bahri",
      "Yejin Choi",
      "Yichi Yang",
      "Sophie Hao",
      "Yifu Chen",
      "Yonatan Belinkov",
      "Yu Hou",
      "Yufang Hou",
      "Yuntao Bai",
      "Zachary Seid",
      "Zhuoye Zhao",
      "Zijian Wang",
      "Zijie J. Wang",
      "Zirui Wang",
      "Ziyi Wu"
    ]
  },
  "https://openreview.net/forum?id=KgfFAI9f3E": {
    "title": "Identification of Negative Transfers in Multitask Learning Using Surrogate Models",
    "volume": "featured",
    "abstract": "Multitask learning is widely used in practice to train a low-resource target task by augmenting it with multiple related source tasks. Yet, naively combining all the source tasks with a target task does not always improve the prediction performance for the target task due to negative transfers. Thus, a critical problem in multitask learning is identifying subsets of source tasks that would benefit the target task. This problem is computationally challenging since the number of subsets grows exponentially with the number of source tasks; efficient heuristics for subset selection does not always capture the relationship between task subsets and multitask learning performances. In this paper, we introduce an efficient procedure to address this problem via surrogate modeling. In surrogate modeling, we sample (random) subsets of source tasks and precompute their multitask learning performances; Then, we approximate the precomputed performances with a linear regression model that can also be used to predict the multitask performance of unseen task subsets. We show theoretically and empirically that fitting this model only requires sampling linearly many subsets in the number of source tasks. The fitted model provides a relevance score between each source task and the target task; We use the relevance scores to perform subset selection for multitask learning by thresholding. Through extensive experiments, we show that our approach predicts negative transfers from multiple source tasks to target tasks much more accurately than existing task affinity measures. Additionally, we demonstrate that for five weak supervision datasets, our approach consistently improves upon existing optimization methods for multi-task learning",
    "checked": true,
    "id": "535dfd1a3472136ca032be7d34a8d6ed71a24503",
    "semantic_title": "identification of negative transfers in multitask learning using surrogate models",
    "citation_count": 14,
    "authors": [
      "Dongyue Li",
      "Huy Nguyen",
      "Hongyang Ryan Zhang"
    ]
  },
  "https://openreview.net/forum?id=rAnB7JSMXL": {
    "title": "Patches Are All You Need?",
    "volume": "featured",
    "abstract": "Although convolutional neural networks have been the dominant architecture for computer vision for many years, Vision Transformers (ViTs) have recently shown promise as an alternative. Subsequently, many new models have been proposed which replace the self-attention layer within the ViT architecture with novel operations (such as MLPs), all of which have also been relatively performant. We note that these architectures all share a common component--the patch embedding layer--which enables the use of a simple isotropic template with alternating steps of channel- and spatial-dimension mixing. This raises a question: is the success of ViT-style models due to novel, highly-expressive operations like self-attention, or is it at least in part due to using patches? In this paper, we present some evidence for the latter: specifically, we propose the ConvMixer, an extremely simple and parameter-efficient fully-convolutional model in which we replace the self-attention and MLP layers within the ViT with less-expressive depthwise and pointwise convolutional layers, respectively. Despite its unusual simplicity, ConvMixer outperforms the ViT, MLP-Mixer, and their variants for similar data set sizes and parameter counts, in addition to outperforming classical vision models like ResNet. We argue that this contributes to the evidence that patches are sufficient for designing simple and effective vision models. Our code is available at https://github.com/locuslab/convmixer",
    "checked": true,
    "id": "3425495ee3b6ead009f35aeb70edeac4e6eb2d10",
    "semantic_title": "patches are all you need?",
    "citation_count": 429,
    "authors": [
      "Asher Trockman",
      "J Zico Kolter"
    ]
  },
  "https://openreview.net/forum?id=11osftjEbF": {
    "title": "Numerical Accounting in the Shuffle Model of Differential Privacy",
    "volume": "featured",
    "abstract": "Shuffle model of differential privacy is a novel distributed privacy model based on a combination of local privacy mechanisms and a secure shuffler. It has been shown that the additional randomisation provided by the shuffler improves privacy bounds compared to the purely local mechanisms. Accounting tight bounds, however, is complicated by the complexity brought by the shuffler. The recently proposed numerical techniques for evaluating $(\\varepsilon,\\delta)$-differential privacy guarantees have been shown to give tighter bounds than commonly used methods for compositions of various complex mechanisms. In this paper, we show how to utilise these numerical accountants for adaptive compositions of general $\\varepsilon$-LDP shufflers and for shufflers of $k$-randomised response mechanisms, including their subsampled variants. This is enabled by an approximation that speeds up the evaluation of the corresponding privacy loss distribution from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n)$, where $n$ is the number of users, without noticeable change in the resulting $\\delta(\\varepsilon)$-upper bounds. We also demonstrate looseness of the existing bounds and methods found in the literature, improving previous composition results for shufflers significantly",
    "checked": true,
    "id": "024336fcecab6c9fd2eed6967801320c6cb0b152",
    "semantic_title": "numerical accounting in the shuffle model of differential privacy",
    "citation_count": 8,
    "authors": [
      "Antti Koskela",
      "Mikko A. Heikkilä",
      "Antti Honkela"
    ]
  },
  "https://openreview.net/forum?id=L9othQvPks": {
    "title": "Workflow Discovery from Dialogues in the Low Data Regime",
    "volume": "featured",
    "abstract": "Text-based dialogues are now widely used to solve real-world problems. In cases where solution strategies are already known, they can sometimes be codified into workflows and used to guide humans or artificial agents through the task of helping clients. We introduce a new problem formulation that we call Workflow Discovery (WD) in which we are interested in the situation where a formal workflow may not yet exist. Still, we wish to discover the set of actions that have been taken to resolve a particular problem. We also examine a sequence-to-sequence (Seq2Seq) approach for this novel task. We present experiments where we extract workflows from dialogues in the Action-Based Conversations Dataset (ABCD). Since the ABCD dialogues follow known workflows to guide agents, we can evaluate our ability to extract such workflows using ground truth sequences of actions. We propose and evaluate an approach that conditions models on the set of possible actions, and we show that using this strategy, we can improve WD performance. Our conditioning approach also improves zero-shot and few-shot WD performance when transferring learned models to unseen domains within and across datasets. Further, on ABCD a modified variant of our Seq2Seq method achieves state-of-the-art performance on related but different problems of Action State Tracking (AST) and Cascading Dialogue Success (CDS) across many evaluation metrics",
    "checked": true,
    "id": "341e56712efba42841275dea4f47e3db70e749f9",
    "semantic_title": "workflow discovery from dialogues in the low data regime",
    "citation_count": 11,
    "authors": [
      "Amine El hattami",
      "Issam H. Laradji",
      "Stefania Raimondo",
      "David Vazquez",
      "Pau Rodriguez",
      "Christopher Pal"
    ]
  },
  "https://openreview.net/forum?id=JwDpZSv3yz": {
    "title": "SPADE: Semi-supervised Anomaly Detection under Distribution Mismatch",
    "volume": "featured",
    "abstract": "Semi-supervised anomaly detection is a common problem, as often the datasets containing anomalies are partially labeled. We propose a canonical framework: Semi-supervised Pseudo-labeler Anomaly Detection with Ensembling (SPADE) that isn't limited by the assumption that labeled and unlabeled data come from the same distribution. Indeed, the assumption is often violated in many applications -- for example, the labeled data may contain only anomalies unlike unlabeled data, or unlabeled data may contain different types of anomalies, or labeled data may contain only `easy-to-label' samples. SPADE utilizes an ensemble of one class classifiers as the pseudo-labeler to improve the robustness of pseudo-labeling with distribution mismatch. Partial matching is proposed to automatically select the critical hyper-parameters for pseudo-labeling without validation data, which is crucial with limited labeled data. SPADE shows state-of-the-art semi-supervised anomaly detection performance across a wide range of scenarios with distribution mismatch in both tabular and image domains. In some common real-world settings such as model facing new types of unlabeled anomalies, SPADE outperforms the state-of-the-art alternatives by 5% AUC in average",
    "checked": true,
    "id": "7b92bf5f85d7c720ccafe9d929650dd4cf94392e",
    "semantic_title": "spade: semi-supervised anomaly detection under distribution mismatch",
    "citation_count": 11,
    "authors": [
      "Jinsung Yoon",
      "Kihyuk Sohn",
      "Chun-Liang Li",
      "Sercan O Arik",
      "Tomas Pfister"
    ]
  },
  "https://openreview.net/forum?id=ZR2CDgADRo": {
    "title": "SolidGen: An Autoregressive Model for Direct B-rep Synthesis",
    "volume": "featured",
    "abstract": "The Boundary representation (B-rep) format is the de-facto shape representation in computer-aided design (CAD) to model solid and sheet objects. Recent approaches to generating CAD models have focused on learning sketch-and-extrude modeling sequences that are executed by a solid modeling kernel in postprocess to recover a B-rep. In this paper we present a new approach that enables learning from and synthesizing B-reps without the need for supervision through CAD modeling sequence data. Our method SolidGen, is an autoregressive neural network that models the B-rep directly by predicting the vertices, edges, and faces using Transformer-based and pointer neural networks. Key to achieving this is our Indexed Boundary Representation that references B-rep vertices, edges and faces in a well-defined hierarchy to capture the geometric and topological relations suitable for use with machine learning. SolidGen can be easily conditioned on contexts e.g., class labels, images, and voxels thanks to its probabilistic modeling of the B-rep distribution. We demonstrate qualitatively, quantitatively, and through perceptual evaluation by human subjects that SolidGen can produce high quality, realistic CAD models",
    "checked": true,
    "id": "301bf1ecb28ae1035e6dcef5ed67add79271c252",
    "semantic_title": "solidgen: an autoregressive model for direct b-rep synthesis",
    "citation_count": 55,
    "authors": [
      "Pradeep Kumar Jayaraman",
      "Joseph George Lambourne",
      "Nishkrit Desai",
      "Karl Willis",
      "Aditya Sanghi",
      "Nigel J. W. Morris"
    ]
  },
  "https://openreview.net/forum?id=KoFOg41haE": {
    "title": "StarCoder: may the source be with you!",
    "volume": "reprod",
    "abstract": "The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license",
    "checked": true,
    "id": "3e4085e5869f1b7959707a1e1d7d273b6057eb4e",
    "semantic_title": "starcoder: may the source be with you!",
    "citation_count": 843,
    "authors": [
      "Raymond Li",
      "Loubna Ben allal",
      "Yangtian Zi",
      "Niklas Muennighoff",
      "Denis Kocetkov",
      "Chenghao Mou",
      "Marc Marone",
      "Christopher Akiki",
      "Jia LI",
      "Jenny Chim",
      "Qian Liu",
      "Evgenii Zheltonozhskii",
      "Terry Yue Zhuo",
      "Thomas Wang",
      "Olivier Dehaene",
      "Joel Lamy-Poirier",
      "Joao Monteiro",
      "Nicolas Gontier",
      "Ming-Ho Yee",
      "Logesh Kumar Umapathi",
      "Jian Zhu",
      "Ben Lipkin",
      "Muhtasham Oblokulov",
      "Zhiruo Wang",
      "Rudra Murthy",
      "Jason T Stillerman",
      "Siva Sankalp Patel",
      "Dmitry Abulkhanov",
      "Marco Zocca",
      "Manan Dey",
      "Zhihan Zhang",
      "Urvashi Bhattacharyya",
      "Wenhao Yu",
      "Sasha Luccioni",
      "Paulo Villegas",
      "Fedor Zhdanov",
      "Tony Lee",
      "Nadav Timor",
      "Jennifer Ding",
      "Claire S Schlesinger",
      "Hailey Schoelkopf",
      "Jan Ebert",
      "Tri Dao",
      "Mayank Mishra",
      "Alex Gu",
      "Carolyn Jane Anderson",
      "Brendan Dolan-Gavitt",
      "Danish Contractor",
      "Siva Reddy",
      "Daniel Fried",
      "Dzmitry Bahdanau",
      "Yacine Jernite",
      "Carlos Muñoz Ferrandis",
      "Sean Hughes",
      "Thomas Wolf",
      "Arjun Guha",
      "Leandro Von Werra",
      "Harm de Vries"
    ]
  },
  "https://openreview.net/forum?id=vlY9GDCCA6": {
    "title": "PAVI: Plate-Amortized Variational Inference",
    "volume": "reprod",
    "abstract": "Given observed data and a probabilistic generative model, Bayesian inference searches for the distribution of the model's parameters that could have yielded the data. Inference is challenging for large population studies where millions of measurements are performed over a cohort of hundreds of subjects, resulting in a massive parameter space. This large cardinality renders off-the-shelf Variational Inference (VI) computationally impractical. In this work, we design structured VI families that efficiently tackle large population studies. Our main idea is to share the parameterization and learning across the different i.i.d. variables in a generative model -symbolized by the model's $\\textit{plates}$. We name this concept $\\textit{plate amortization}$. Contrary to off-the-shelf stochastic VI --which slows down inference-- plate amortization results in orders of magnitude faster to train variational distributions. Applied to large-scale hierarchical problems, PAVI yields expressive, parsimoniously parameterized VI with an affordable training time --effectively unlocking inference in those regimes. We illustrate the practical utility of PAVI through a challenging Neuroimaging example featuring 400 million latent parameters, demonstrating a significant step towards scalable and expressive Variational Inference",
    "checked": true,
    "id": "d3902a83fcc82204cdae4487b0b67c84e715cd3d",
    "semantic_title": "pavi: plate-amortized variational inference",
    "citation_count": 1,
    "authors": [
      "Louis Rouillard",
      "Alexandre Le Bris",
      "Thomas Moreau",
      "Demian Wassermann"
    ]
  },
  "https://openreview.net/forum?id=1dwXa9vmOI": {
    "title": "Does ‘Deep Learning on a Data Diet' reproduce? Overall yes, but GraNd at Initialization does not",
    "volume": "expert",
    "abstract": "Training deep neural networks on vast datasets often results in substantial computational demands, underscoring the need for efficient data pruning. In this context, we critically re-evaluate the data pruning metrics introduced in `Deep Learning on a Data Diet' by Paul et al. (2021): the Gradient Norm (GraNd) (at initialization) and the Error L2 Norm (EL2N). Our analysis uncovers a strong correlation between the GraNd scores at initialization and a sample's input norm, suggesting the latter as a potential baseline for data pruning. However, comprehensive tests on CIFAR-10 show neither metric outperforming random pruning, contradicting one of the findings in Paul et al. (2021). We pinpoint the inconsistency in the GraNd at initialization results to a later-fixed bug in FLAX's checkpoint restoring mechanism (https://github.com/google/flax/commit/28fbd95500f4bf2f9924d2560062fa50e919b1a5). Altogether, our findings do not support using the input norm or GraNd scores at initialization for effective data pruning. Nevertheless, EL2N and GraNd scores at later training epochs do provide useful pruning signals, aligning with the expected performance",
    "checked": false,
    "id": "4a7be268a27cf58619745f849624957dccd0b5d6",
    "semantic_title": "does \"deep learning on a data diet\" reproduce? overall yes, but grand at initialization does not",
    "citation_count": 5,
    "authors": [
      "Andreas Kirsch"
    ]
  },
  "https://openreview.net/forum?id=KqR3rgooXb": {
    "title": "Numerical Data Imputation for Multimodal Data Sets: A Probabilistic Nearest-Neighbor Kernel Density Approach",
    "volume": "reprod",
    "abstract": "Numerical data imputation algorithms replace missing values by estimates to leverage incomplete data sets. Current imputation methods seek to minimize the error between the unobserved ground truth and the imputed values. But this strategy can create artifacts leading to poor imputation in the presence of multimodal or complex distributions. To tackle this problem, we introduce the $k$NN$\\times$KDE algorithm: a data imputation method combining nearest neighbor estimation ($k$NN) and density estimation with Gaussian kernels (KDE). We compare our method with previous data imputation methods using artificial and real-world data with different data missing scenarios and various data missing rates, and show that our method can cope with complex original data structure, yields lower data imputation errors, and provides probabilistic estimates with higher likelihood than current methods. We release the code in open-source for the community",
    "checked": true,
    "id": "9704c0fbf093740f7344d8223474f66cbe2db17e",
    "semantic_title": "numerical data imputation for multimodal data sets: a probabilistic nearest-neighbor kernel density approach",
    "citation_count": 4,
    "authors": [
      "Florian Lalande",
      "Kenji Doya"
    ]
  },
  "https://openreview.net/forum?id=R9CgBkeZ6Z": {
    "title": "Aux-Drop: Handling Haphazard Inputs in Online Learning Using Auxiliary Dropouts",
    "volume": "reprod",
    "abstract": "",
    "checked": true,
    "id": "83266e391692d00d80798d6ec478c537361c47f6",
    "semantic_title": "aux-drop: handling haphazard inputs in online learning using auxiliary dropouts",
    "citation_count": 5,
    "authors": [
      "Rohit Agarwal",
      "Deepak Gupta",
      "Alexander Horsch",
      "Dilip K. Prasad"
    ]
  },
  "https://openreview.net/forum?id=jWr41htaB3": {
    "title": "A Stochastic Proximal Polyak Step Size",
    "volume": "reprod",
    "abstract": "",
    "checked": true,
    "id": "5f11660071912f1ad21c0c18663103bafb25e722",
    "semantic_title": "a stochastic proximal polyak step size",
    "citation_count": 12,
    "authors": [
      "Fabian Schaipp",
      "Robert M. Gower",
      "Michael Ulbrich"
    ]
  },
  "https://openreview.net/forum?id=RYeRNwRjNE": {
    "title": "Explaining Visual Counterfactual Explainers",
    "volume": "reprod",
    "abstract": "",
    "checked": true,
    "id": "01522701fc2b129be7d1b5a0a5fe561958f7b3fb",
    "semantic_title": "explaining visual counterfactual explainers",
    "citation_count": 0,
    "authors": [
      "Diego Velazquez",
      "Pau Rodriguez",
      "Alexandre Lacoste",
      "Issam H. Laradji",
      "Xavier Roca",
      "Jordi Gonzàlez"
    ]
  },
  "https://openreview.net/forum?id=JjbsIYOuNi": {
    "title": "PRUDEX-Compass: Towards Systematic Evaluation of Reinforcement Learning in Financial Markets",
    "volume": "reprod",
    "abstract": "",
    "checked": true,
    "id": "b759f3fcf2459013c710bc0b000c46c8e70f9bf8",
    "semantic_title": "prudex-compass: towards systematic evaluation of reinforcement learning in financial markets",
    "citation_count": 5,
    "authors": [
      "Shuo Sun",
      "Molei Qin",
      "Xinrun Wang",
      "Bo An"
    ]
  },
  "https://openreview.net/forum?id=AXtFeYjboj": {
    "title": "A Survey on the Possibilities & Impossibilities of AI-generated Text Detection",
    "volume": "survey",
    "abstract": "Large Language Models (LLMs) have revolutionized the domain of natural language processing (NLP) with remarkable capabilities of generating human-like text responses. However, despite these advancements, several works in the existing literature have raised serious concerns about the potential misuse of LLMs such as spreading misinformation, generating fake news, plagiarism in academia, and contaminating the web. To address these concerns, a consensus among the research community is to develop algorithmic solutions to detect AI-generated text. The basic idea is that whenever we can tell if the given text is either written by a human or an AI, we can utilize this information to address the above-mentioned concerns. To that end, a plethora of detection frameworks have been proposed, highlighting the possibilities of AI-generated text detection. But in parallel to the development of detection frameworks, researchers have also concentrated on designing strategies to elude detection, i.e., focusing on the impossibilities of AI-generated text detection. This is a crucial step in order to make sure the detection frameworks are robust enough and it is not too easy to fool a detector. Despite the huge interest and the flurry of research in this domain, the community currently lacks a comprehensive analysis of recent developments. In this survey, we aim to provide a concise categorization and overview of current work encompassing both the prospects and the limitations of AI-generated text detection. To enrich the collective knowledge, we engage in an exhaustive discussion on critical and challenging open questions related to ongoing research on AI-generated text detection",
    "checked": true,
    "id": "f582daa2f2822c0aa1291fe3925f69c25280e37e",
    "semantic_title": "a survey on the possibilities & impossibilities of ai-generated text detection",
    "citation_count": 16,
    "authors": [
      "Soumya Suvra Ghosal",
      "Souradip Chakraborty",
      "Jonas Geiping",
      "Furong Huang",
      "Dinesh Manocha",
      "Amrit Bedi"
    ]
  },
  "https://openreview.net/forum?id=z9EkXfvxta": {
    "title": "Modular Deep Learning",
    "volume": "survey",
    "abstract": "Transfer learning has recently become the dominant paradigm of machine learning. Pre-trained models fine-tuned for downstream tasks achieve better performance with fewer labelled examples. Nonetheless, it remains unclear how to develop models that specialise towards multiple tasks without incurring negative interference and that generalise systematically to non-identically distributed tasks. Modular deep learning has emerged as a promising solution to these challenges. In this framework, units of computation are often implemented as autonomous parameter-efficient modules. Information is conditionally routed to a subset of modules and subsequently aggregated. These properties enable positive transfer and systematic generalisation by separating computation from routing and updating modules locally. We offer a survey of modular architectures, providing a unified view over several threads of research that evolved independently in the scientific literature. Moreover, we explore various additional purposes of modularity, including scaling language models, causal inference and discovery, programme simulation, and hierarchical reinforcement learning. Finally, we report various concrete applications where modularity has been successfully deployed such as cross-lingual and cross-modal knowledge transfer",
    "checked": true,
    "id": "1f346f74e8eabececa4896d734ab9b261f30830d",
    "semantic_title": "modular deep learning",
    "citation_count": 84,
    "authors": [
      "Jonas Pfeiffer",
      "Sebastian Ruder",
      "Ivan Vulić",
      "Edoardo Ponti"
    ]
  },
  "https://openreview.net/forum?id=cHroS8VIyN": {
    "title": "Benchmarks for Physical Reasoning AI",
    "volume": "survey",
    "abstract": "Physical reasoning is a crucial aspect in the development of general AI systems, given that human learning starts with interacting with the physical world before progressing to more complex concepts. Although researchers have studied and assessed the physical reasoning of AI approaches through various specific benchmarks, there is no comprehensive approach to evaluating and measuring progress. Therefore, we aim to offer an overview of existing benchmarks and their solution approaches and propose a unified perspective for measuring the physical reasoning capacity of AI systems. We select benchmarks that are designed to test algorithmic performance in physical reasoning tasks. While each of the selected benchmarks poses a unique challenge, their ensemble provides a comprehensive proving ground for an AI generalist agent with a measurable skill level for various physical reasoning concepts. This gives an advantage to such an ensemble of benchmarks over other holistic benchmarks that aim to simulate the real world by intertwining its complexity and many concepts. We group the presented set of physical reasoning benchmarks into subcategories so that more narrow generalist AI agents can be tested first on these groups",
    "checked": true,
    "id": "74f310af61b146b4b264bca0d5db6e55a4db8f08",
    "semantic_title": "benchmarks for physical reasoning ai",
    "citation_count": 9,
    "authors": [
      "Andrew Melnik",
      "Robin Schiewer",
      "Moritz Lange",
      "Andrei Ioan Muresanu",
      "mozhgan saeidi",
      "Animesh Garg",
      "Helge Ritter"
    ]
  },
  "https://openreview.net/forum?id=qqnttX9LPo": {
    "title": "Causal Reinforcement Learning: A Survey",
    "volume": "survey",
    "abstract": "Reinforcement learning is an essential paradigm for solving sequential decision problems under uncertainty. Despite many remarkable achievements in recent decades, applying reinforcement learning methods in the real world remains challenging. One of the main obstacles is that reinforcement learning agents lack a fundamental understanding of the world and must therefore learn from scratch through numerous trial-and-error interactions. They may also face challenges in providing explanations for their decisions and generalizing the acquired knowledge. Causality, however, offers notable advantages by formalizing knowledge in a systematic manner and harnessing invariance for effective knowledge transfer. This has led to the emergence of causal reinforcement learning, a subfield of reinforcement learning that seeks to enhance existing algorithms by incorporating causal relationships into the learning process. In this survey, we provide a comprehensive review of the literature in this domain. We begin by introducing basic concepts in causality and reinforcement learning, and then explain how causality can help address key challenges faced by traditional reinforcement learning. We categorize and systematically evaluate existing causal reinforcement learning approaches, with a focus on their ability to enhance sample efficiency, advance generalizability, facilitate knowledge transfer, mitigate spurious correlations, and promote explainability, fairness, and safety. Lastly, we outline the limitations of current research and shed light on future directions in this rapidly evolving field",
    "checked": true,
    "id": "d293a75f529d7b1abb161480a95122c9a3ed6376",
    "semantic_title": "causal reinforcement learning: a survey",
    "citation_count": 24,
    "authors": [
      "Zhihong Deng",
      "Jing Jiang",
      "Guodong Long",
      "Chengqi Zhang"
    ]
  },
  "https://openreview.net/forum?id=mcN0ezbnzO": {
    "title": "Provably Safe Reinforcement Learning: Conceptual Analysis, Survey, and Benchmarking",
    "volume": "survey",
    "abstract": "Ensuring the safety of reinforcement learning (RL) algorithms is crucial to unlock their potential for many real-world tasks. However, vanilla RL and most safe RL approaches do not guarantee safety. In recent years, several methods have been proposed to provide hard safety guarantees for RL, which is essential for applications where unsafe actions could have disastrous consequences. Nevertheless, there is no comprehensive comparison of these provably safe RL methods. Therefore, we introduce a categorization of existing provably safe RL methods, present the conceptual foundations for both continuous and discrete action spaces, and empirically benchmark existing methods. We categorize the methods based on how they adapt the action: action replacement, action projection, and action masking. Our experiments on an inverted pendulum and a quadrotor stabilization task indicate that action replacement is the best-performing approach for these applications despite its comparatively simple realization. Furthermore, adding a reward penalty, every time the safety verification is engaged, improved training performance in our experiments. Finally, we provide practical guidance on selecting provably safe RL approaches depending on the safety specification, RL algorithm, and type of action space",
    "checked": true,
    "id": "b1fb5611b7e0e92f1f9d2f269e6e7ce8b4d1cedb",
    "semantic_title": "provably safe reinforcement learning: conceptual analysis, survey, and benchmarking",
    "citation_count": 23,
    "authors": [
      "Hanna Krasowski",
      "Jakob Thumm",
      "Marlon Müller",
      "Lukas Schäfer",
      "Xiao Wang",
      "Matthias Althoff"
    ]
  },
  "https://openreview.net/forum?id=9sVCIngrhP": {
    "title": "Private GANs, Revisited",
    "volume": "survey",
    "abstract": "We show that the canonical approach for training differentially private GANs -- updating the discriminator with differentially private stochastic gradient descent (DPSGD) -- can yield significantly improved results after modifications to training. Specifically, we propose that existing instantiations of this approach neglect to consider how adding noise only to discriminator updates inhibits discriminator training, disrupting the balance between the generator and discriminator necessary for successful GAN training. We show that a simple fix -- taking more discriminator steps between generator steps -- restores parity between the generator and discriminator and improves results. Additionally, with the goal of restoring parity, we experiment with other modifications -- namely, large batch sizes and adaptive discriminator update frequency -- to improve discriminator training and see further improvements in generation quality. Our results demonstrate that on standard image synthesis benchmarks, DPSGD outperforms all alternative GAN privatization schemes. Code: https://github.com/alexbie98/dpgan-revisit",
    "checked": true,
    "id": "7426cc7b947f48cedb3bb3b5f8b5a0db17c9302d",
    "semantic_title": "private gans, revisited",
    "citation_count": 17,
    "authors": [
      "Alex Bie",
      "Gautam Kamath",
      "Guojun Zhang"
    ]
  },
  "https://openreview.net/forum?id=r30yuDPvf2": {
    "title": "A Survey on Transformers in Reinforcement Learning",
    "volume": "survey",
    "abstract": "Transformer has been considered the dominating neural architecture in NLP and CV, mostly under supervised settings. Recently, a similar surge of using Transformers has appeared in the domain of reinforcement learning (RL), but it is faced with unique design choices and challenges brought by the nature of RL. However, the evolution of Transformers in RL has not yet been well unraveled. In this paper, we seek to systematically review motivations and progress on using Transformers in RL, provide a taxonomy on existing works, discuss each sub-field, and summarize future prospects",
    "checked": true,
    "id": "638b5c76d96e32f54475a8327a9c68e0167156a9",
    "semantic_title": "a survey on transformers in reinforcement learning",
    "citation_count": 61,
    "authors": [
      "Wenzhe Li",
      "Hao Luo",
      "Zichuan Lin",
      "Chongjie Zhang",
      "Zongqing Lu",
      "Deheng Ye"
    ]
  },
  "https://openreview.net/forum?id=YdMrdhGx9y": {
    "title": "A Survey on Causal Discovery Methods for I.I.D. and Time Series Data",
    "volume": "survey",
    "abstract": "The ability to understand causality from data is one of the major milestones of human-level intelligence. Causal Discovery (CD) algorithms can identify the cause-effect relationships among the variables of a system from related observational data with certain assumptions. Over the years, several methods have been developed primarily based on the statistical properties of data to uncover the underlying causal mechanism. In this study, we present an extensive discussion on the methods designed to perform causal discovery from both independent and identically distributed (I.I.D.) data and time series data. For this purpose, we first introduce the common terminologies used in causal discovery literature and then provide a comprehensive discussion of the algorithms designed to identify causal relations in different settings. We further discuss some of the benchmark datasets available for evaluating the algorithmic performance, off-the-shelf tools or software packages to perform causal discovery readily, and the common metrics used to evaluate these methods. We also evaluate some widely used causal discovery algorithms on multiple benchmark datasets and compare their performances. Finally, we conclude by discussing the research challenges and the applications of causal discovery algorithms in multiple areas of interest",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Uzma Hasan",
      "Emam Hossain",
      "Md Osman Gani"
    ]
  },
  "https://openreview.net/forum?id=lmXMXP74TO": {
    "title": "Data Distillation: A Survey",
    "volume": "survey",
    "abstract": "The popularity of deep learning has led to the curation of a vast number of massive and multifarious datasets. Despite having close-to-human performance on individual tasks, training parameter-hungry models on large datasets poses multi-faceted problems such as (a) high model-training time; (b) slow research iteration; and (c) poor eco-sustainability. As an alternative, data distillation approaches aim to synthesize terse data summaries, which can serve as effective drop-in replacements of the original dataset for scenarios like model training, inference, architecture search, etc. In this survey, we present a formal framework for data distillation, along with providing a detailed taxonomy of existing approaches. Additionally, we cover data distillation approaches for different data modalities, namely images, graphs, and user-item interactions (recommender systems), while also identifying current challenges and future research directions",
    "checked": true,
    "id": "1673b72a4ebb56ae3775131937c40afae3853e9b",
    "semantic_title": "data distillation: a survey",
    "citation_count": 82,
    "authors": [
      "Noveen Sachdeva",
      "Julian McAuley"
    ]
  },
  "https://openreview.net/forum?id=3OSISBQPrM": {
    "title": "On the Predictive Accuracy of Neural Temporal Point Process Models for Continuous-time Event Data",
    "volume": "survey",
    "abstract": "Temporal Point Processes (TPPs) serve as the standard mathematical framework for modeling asynchronous event sequences in continuous time. However, classical TPP models are often constrained by strong assumptions, limiting their ability to capture complex real-world event dynamics. To overcome this limitation, researchers have proposed Neural TPPs, which leverage neural network parametrizations to offer more flexible and efficient modeling. While recent studies demonstrate the effectiveness of Neural TPPs, they often lack a unified setup, relying on different baselines, datasets, and experimental configurations. This makes it challenging to identify the key factors driving improvements in predictive accuracy, hindering research progress. To bridge this gap, we present a comprehensive large-scale experimental study that systematically evaluates the predictive accuracy of state-of-the-art neural TPP models. Our study encompasses multiple real-world and synthetic event sequence datasets, following a carefully designed unified setup. We thoroughly investigate the influence of major architectural components such as event encoding, history encoder, and decoder parametrization on both time and mark prediction tasks. Additionally, we delve into the less explored area of probabilistic calibration for neural TPP models. By analyzing our results, we draw insightful conclusions regarding the significance of history size and the impact of architectural components on predictive accuracy. Furthermore, we shed light on the miscalibration of mark distributions in neural TPP models. Our study aims to provide valuable insights into the performance and characteristics of neural TPP models, contributing to a better understanding of their strengths and limitations",
    "checked": true,
    "id": "c1eaa21b2a5bb9500efe9b7f59e3073411f2e488",
    "semantic_title": "on the predictive accuracy of neural temporal point process models for continuous-time event data",
    "citation_count": 10,
    "authors": [
      "Tanguy Bosser",
      "Souhaib Ben Taieb"
    ]
  },
  "https://openreview.net/forum?id=jh7wH2AzKK": {
    "title": "Augmented Language Models: a Survey",
    "volume": "survey",
    "abstract": "This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues",
    "checked": true,
    "id": "2029349c55c1dba3493c5b3bd25152f18ba21ae2",
    "semantic_title": "augmented language models: a survey",
    "citation_count": 406,
    "authors": [
      "Grégoire Mialon",
      "Roberto Dessi",
      "Maria Lomeli",
      "Christoforos Nalmpantis",
      "Ramakanth Pasunuru",
      "Roberta Raileanu",
      "Baptiste Roziere",
      "Timo Schick",
      "Jane Dwivedi-Yu",
      "Asli Celikyilmaz",
      "Edouard Grave",
      "Yann LeCun",
      "Thomas Scialom"
    ]
  },
  "https://openreview.net/forum?id=FByH3qL87G": {
    "title": "On Averaging ROC Curves",
    "volume": "survey",
    "abstract": "Receiver operating characteristic (ROC) curves are a popular method of summarising the performance of classifiers. The ROC curve describes the separability of the distributions of predictions from a two-class classifier. There are a variety of situations in which an analyst seeks to aggregate multiple ROC curves into a single representative example. A number of methods of doing so are available; however, there is a degree of subtlety that is often overlooked when selecting the appropriate one. An important component of this relates to the interpretation of the decision process for which the classifier will be used. This paper summarises a number of methods of aggregation and carefully delineates the interpretations of each in order to inform their correct usage. A toy example is provided that highlights how an injudicious choice of aggregation method can lead to erroneous conclusions",
    "checked": true,
    "id": "56c51ca25403444019ce44e8745f6bc6f2675220",
    "semantic_title": "on averaging roc curves",
    "citation_count": 10,
    "authors": [
      "Jack Hogan",
      "Niall M. Adams"
    ]
  },
  "https://openreview.net/forum?id=VynY6Bk03b": {
    "title": "How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition",
    "volume": "survey",
    "abstract": "A major goal of artificial intelligence (AI) is to create an agent capable of acquiring a general understanding of the world. Such an agent would require the ability to continually accumulate and build upon its knowledge as it encounters new experiences. Lifelong or continual learning addresses this setting, whereby an agent faces a continual stream of problems and must strive to capture the knowledge necessary for solving each new task it encounters. If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions. Despite the intuitive appeal of this simple idea, the literatures on lifelong learning and compositional learning have proceeded largely separately. In an effort to promote developments that bridge between the two fields, this article surveys their respective research landscapes and discusses existing and future connections between them",
    "checked": true,
    "id": "cee54f7f0760feb8b59bf0f428066c083fd88d19",
    "semantic_title": "how to reuse and compose knowledge for a lifetime of tasks: a survey on continual learning and functional composition",
    "citation_count": 33,
    "authors": [
      "Jorge A Mendez",
      "ERIC EATON"
    ]
  },
  "https://openreview.net/forum?id=Ma25S4ludQ": {
    "title": "Know Your Self-supervised Learning: A Survey on Image-based Generative and Discriminative Training",
    "volume": "survey",
    "abstract": "Although supervised learning has been highly successful in improving the state-of-the-art in the domain of image-based computer vision in the past, the margin of improvement has diminished significantly in recent years, indicating that a plateau is in sight. Meanwhile, the use of self-supervised learning (SSL) for the purpose of natural language processing (NLP) has seen tremendous successes during the past couple of years, with this new learning paradigm yielding powerful language models. Inspired by the excellent results obtained in the field of NLP, self-supervised methods that rely on clustering, contrastive learning, distillation, and information-maximization, which all fall under the banner of discriminative SSL, have experienced a swift uptake in the area of computer vision. Shortly afterwards, generative SSL frameworks that are mostly based on masked image modeling, complemented and surpassed the results obtained with discriminative SSL. Consequently, within a span of three years, over $100$ unique general-purpose frameworks for generative and discriminative SSL, with a focus on imaging, were proposed. In this survey, we review a plethora of research efforts conducted on image-oriented SSL, providing a historic view and paying attention to best practices as well as useful software packages. While doing so, we discuss pretext tasks for image-based SSL, as well as techniques that are commonly used in image-based SSL. Lastly, to aid researchers who aim at contributing to image-focused SSL, we outline a number of promising research directions",
    "checked": true,
    "id": "6209b614db0065de89331196a1ae8aa59404f0db",
    "semantic_title": "know your self-supervised learning: a survey on image-based generative and discriminative training",
    "citation_count": 40,
    "authors": [
      "Utku Ozbulak",
      "Hyun Jung Lee",
      "Beril Boga",
      "Esla Timothy Anzaku",
      "Ho-min Park",
      "Arnout Van Messem",
      "Wesley De Neve",
      "Joris Vankerschaver"
    ]
  },
  "https://openreview.net/forum?id=A8pqQipwkt": {
    "title": "Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations",
    "volume": "survey",
    "abstract": "Molecular dynamics (MD) simulation techniques are widely used for various natural science applications. Increasingly, machine learning (ML) force field (FF) models begin to replace ab-initio simulations by predicting forces directly from atomic structures. Despite significant progress in this area, such techniques are primarily benchmarked by their force/energy prediction errors, even though the practical use case would be to produce realistic MD trajectories. We aim to fill this gap by introducing a novel benchmark suite for ML MD simulation. We curate representative MD systems, including water, organic molecules, peptide, and materials, and design evaluation metrics corresponding to the scientific objectives of respective systems. We benchmark a collection of state-of-the-art (SOTA) ML FF models and illustrate, in particular, how the commonly benchmarked force accuracy is not well aligned with relevant simulation metrics. We demonstrate when and how selected SOTA methods fail, along with offering directions for further improvement. Specifically, we identify stability as a key metric for ML models to improve. Our benchmark suite comes with a comprehensive open-source codebase for training and simulation with ML FFs to facilitate future work",
    "checked": true,
    "id": "08a82b3865ba09c457ad525449eb0c7691479574",
    "semantic_title": "forces are not enough: benchmark and critical evaluation for machine learning force fields with molecular simulations",
    "citation_count": 146,
    "authors": [
      "Xiang Fu",
      "Zhenghao Wu",
      "Wujie Wang",
      "Tian Xie",
      "Sinan Keten",
      "Rafael Gomez-Bombarelli",
      "Tommi Jaakkola"
    ]
  },
  "https://openreview.net/forum?id=e0xaRylNuT": {
    "title": "Partition-Based Active Learning for Graph Neural Networks",
    "volume": "survey",
    "abstract": "We study the problem of semi-supervised learning with Graph Neural Networks (GNNs) in an active learning setup. We propose GraphPart, a novel partition-based active learning approach for GNNs. GraphPart first splits the graph into disjoint partitions and then selects representative nodes within each partition to query. The proposed method is motivated by a novel analysis of the classification error under realistic smoothness assumptions over the graph and the node features. Extensive experiments on multiple benchmark datasets demonstrate that the proposed method outperforms existing active learning methods for GNNs under a wide range of annotation budget constraints. In addition, the proposed method does not introduce additional hyperparameters, which is crucial for model training, especially in the active learning setting where a labeled validation set may not be available",
    "checked": true,
    "id": "460f16dc71dd15f660ffe7888865f54953b42a84",
    "semantic_title": "partition-based active learning for graph neural networks",
    "citation_count": 18,
    "authors": [
      "Jiaqi Ma",
      "Ziqiao Ma",
      "Joyce Chai",
      "Qiaozhu Mei"
    ]
  },
  "https://openreview.net/forum?id=AU4qHN2VkS": {
    "title": "Better Theory for SGD in the Nonconvex World",
    "volume": "survey",
    "abstract": "Large-scale nonconvex optimization problems are ubiquitous in modern machine learning, and among practitioners interested in solving them, Stochastic Gradient Descent (SGD) reigns supreme. We revisit the analysis of SGD in the nonconvex setting and propose a new variant of the recently introduced \\emph{expected smoothness} assumption which governs the behavior of the second moment of the stochastic gradient. We show that our assumption is both more general and more reasonable than assumptions made in all prior work. Moreover, our results yield the optimal $\\mathcal{O}(\\epsilon^{-4})$ rate for finding a stationary point of nonconvex smooth functions, and recover the optimal $\\mathcal{O}(\\epsilon^{-1})$ rate for finding a global solution if the Polyak-Łojasiewicz condition is satisfied. We compare against convergence rates under convexity and prove a theorem on the convergence of SGD under Quadratic Functional Growth and convexity, which might be of independent interest. Moreover, we perform our analysis in a framework which allows for a detailed study of the effects of a wide array of sampling strategies and minibatch sizes for finite-sum optimization problems. We corroborate our theoretical results with experiments on real and synthetic data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Khaled",
      "Peter Richtárik"
    ]
  },
  "https://openreview.net/forum?id=WFtTpQ47A7": {
    "title": "SHAP-XRT: The Shapley Value Meets Conditional Independence Testing",
    "volume": "expert",
    "abstract": "The complex nature of artificial neural networks raises concerns on their reliability, trustworthiness, and fairness in real-world scenarios. The Shapley value---a solution concept from game theory---is one of the most popular explanation methods for machine learning models. More traditionally, from a statistical perspective, feature importance is defined in terms of conditional independence. So far, these two approaches to interpretability and feature importance have been considered separate and distinct. In this work, we show that Shapley-based explanation methods and conditional independence testing are closely related. We introduce the \\textbf{SHAP}ley E\\textbf{X}planation \\textbf{R}andomization \\textbf{T}est (SHAP-XRT), a testing procedure inspired by the Conditional Randomization Test (CRT) for a specific notion of local (i.e., on a sample) conditional independence. With it, we prove that for binary classification problems, the marginal contributions in the Shapley value provide lower and upper bounds to the expected $p$-values of their respective tests. Furthermore, we show that the Shapley value itself provides an upper bound to the expected $p$-value of a global (i.e., overall) null hypothesis. As a result, we further our understanding of Shapley-based explanation methods from a novel perspective and characterize the conditions under which one can make statistically valid claims about feature importance via the Shapley value",
    "checked": true,
    "id": "5e116b6fc68336b09c6d8474b3c529d7ac50ae86",
    "semantic_title": "shap-xrt: the shapley value meets conditional independence testing",
    "citation_count": 5,
    "authors": [
      "Jacopo Teneggi",
      "Beepul Bharti",
      "Yaniv Romano",
      "Jeremias Sulam"
    ]
  },
  "https://openreview.net/forum?id=rq1SaHQg2k": {
    "title": "Pairwise Learning with Adaptive Online Gradient Descent",
    "volume": "expert",
    "abstract": "In this paper, we propose an adaptive online gradient descent method with momentum for pairwise learning, in which the stepsize is determined by historical information. Due to the structure of pairwise learning, the sample pairs are dependent on the parameters, causing difficulties in the convergence analysis. To this end, we develop novel techniques for the convergence analysis of the proposed algorithm. We show that the proposed algorithm can output the desired solution in strongly convex, convex, and nonconvex cases. Furthermore, we present theoretical explanations for why our proposed algorithm can accelerate previous workhorses for online pairwise learning. All assumptions used in the theoretical analysis are mild and common, making our results applicable to various pairwise learning problems. To demonstrate the efficiency of our algorithm, we compare the proposed adaptive method with the non-adaptive counterpart on the benchmark online AUC maximization problem",
    "checked": true,
    "id": "b8360e77bf4b3f077310fe57415182d0963f54c3",
    "semantic_title": "pairwise learning with adaptive online gradient descent",
    "citation_count": 1,
    "authors": [
      "Tao Sun",
      "Qingsong Wang",
      "Yunwen Lei",
      "Dongsheng Li",
      "Bao Wang"
    ]
  },
  "https://openreview.net/forum?id=GlhM6XX1wv": {
    "title": "DPVIm: Differentially Private Variational Inference Improved",
    "volume": "expert",
    "abstract": "Differentially private (DP) release of multidimensional statistics typically considers an aggregate sensitivity, e.g. the vector norm of a high-dimensional vector. However, different dimensions of that vector might have widely different magnitudes and therefore DP perturbation disproportionately affects the signal across dimensions. We observe this problem in the gradient release of the DP-SGD algorithm when using it for variational inference (VI), where it manifests in poor convergence as well as high variance in outputs for certain variational parameters, and make the following contributions: (i) We mathematically isolate the cause for the difference in magnitudes between gradient parts corresponding to different variational parameters. Using this as prior knowledge we establish a link between the gradients of the variational parameters, and propose an efficient while simple fix for the problem to obtain a less noisy gradient estimator, which we call \\emph{aligned} gradients. This approach allows us to obtain the updates for the covariance parameter of a Gaussian posterior approximation without a privacy cost. We compare this to alternative approaches for scaling the gradients using analytically derived preconditioning, e.g. natural gradients. (ii) We suggest using iterate averaging over the DP parameter traces recovered during the training, to reduce the DP-induced noise in parameter estimates at no additional cost in privacy. Finally, (iii) to accurately capture the additional uncertainty DP introduces to the model parameters, we infer the DP-induced noise from the parameter traces and include that in the learned posteriors to make them \\emph{noise aware}. We demonstrate the efficacy of our proposed improvements through various experiments on real data",
    "checked": true,
    "id": "3e41e67660d377c2f00c7946486cb0f868a78444",
    "semantic_title": "dpvim: differentially private variational inference improved",
    "citation_count": 3,
    "authors": [
      "Joonas Jälkö",
      "Lukas Prediger",
      "Antti Honkela",
      "Samuel Kaski"
    ]
  },
  "https://openreview.net/forum?id=vcHwQyNBjW": {
    "title": "Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning",
    "volume": "expert",
    "abstract": "We examine a simple stochastic strategy for adapting well-known single-point acquisition functions to allow batch active learning. Unlike acquiring the top-K points from the pool set, score- or rank-based sampling takes into account that acquisition scores change as new data are acquired. This simple strategy for adapting standard single-sample acquisition strategies can even perform just as well as compute-intensive state-of-the-art batch acquisition functions, like BatchBALD or BADGE while using orders of magnitude less compute. In addition to providing a practical option for machine learning practitioners, the surprising success of the proposed method in a wide range of experimental settings raises a difficult question for the field: when are these expensive batch acquisition methods pulling their weight?",
    "checked": true,
    "id": "8fa22f45cfc8b5244fe070144dd263d60fd51e64",
    "semantic_title": "stochastic batch acquisition: a simple baseline for deep active learning",
    "citation_count": 22,
    "authors": [
      "Andreas Kirsch",
      "Sebastian Farquhar",
      "Parmida Atighehchian",
      "Andrew Jesson",
      "Frédéric Branchaud-Charron",
      "Yarin Gal"
    ]
  },
  "https://openreview.net/forum?id=rdHVPPVuXa": {
    "title": "Neural Causal Structure Discovery from Interventions",
    "volume": "expert",
    "abstract": "Recent promising results have generated a surge of interest in continuous optimization methods for causal discovery from observational data. However, there are theoretical limitations on the identifiability of underlying structures obtained solely from observational data. Interventional data, on the other hand, provides richer information about the underlying data-generating process. Nevertheless, extending and applying methods designed for observational data to include interventions is a challenging problem. To address this issue, we propose a general framework based on neural networks to develop models that incorporate both observational and interventional data. Notably, our method can handle the challenging and realistic scenario where the identity of the intervened upon variable is unknown. We evaluate our proposed approach in the context of graph recovery, both de novo and from a partially-known edge set. Our method achieves strong benchmark results on various structure learning tasks, including structure recovery of synthetic graphs as well as standard graphs from the Bayesian Network Repository",
    "checked": true,
    "id": "f15462bb66433c95ddf87bc1fe82573c2dcfe097",
    "semantic_title": "neural causal structure discovery from interventions",
    "citation_count": 5,
    "authors": [
      "Nan Rosemary Ke",
      "Olexa Bilaniuk",
      "Anirudh Goyal",
      "Stefan Bauer",
      "Hugo Larochelle",
      "Bernhard Schölkopf",
      "Michael Curtis Mozer",
      "Christopher Pal",
      "Yoshua Bengio"
    ]
  },
  "https://openreview.net/forum?id=xuWTFQ4VGO": {
    "title": "Diffusion Models for Constrained Domains",
    "volume": "expert",
    "abstract": "Denoising diffusion models are a novel class of generative algorithms that achieve state-of-the-art performance across a range of domains, including image generation and text-to-image tasks. Building on this success, diffusion models have recently been extended to the Riemannian manifold setting, broadening their applicability to a range of problems from the natural and engineering sciences. However, these Riemannian diffusion models are built on the assumption that their forward and backward processes are well-defined for all times, preventing them from being applied to an important set of tasks that consider manifolds defined via a set of inequality constraints. In this work, we introduce a principled framework to bridge this gap. We present two distinct noising processes based on (i) the logarithmic barrier metric and (ii) the reflected Brownian motion induced by the constraints. As existing diffusion model techniques cannot be applied in this setting, we proceed to derive new tools to define such models in our framework. We then empirically demonstrate the scalability and flexibility of our methods on a number of synthetic and real-world tasks, including applications from robotics and protein design",
    "checked": true,
    "id": "781a6e7b7b611b016d8a3c81c1df07b473910725",
    "semantic_title": "diffusion models for constrained domains",
    "citation_count": 41,
    "authors": [
      "Nic Fishman",
      "Leo Klarner",
      "Valentin De Bortoli",
      "Emile Mathieu",
      "Michael John Hutchinson"
    ]
  },
  "https://openreview.net/forum?id=10hCbu70Sr": {
    "title": "Catastrophic overfitting can be induced with discriminative non-robust features",
    "volume": "expert",
    "abstract": "Adversarial training (AT) is the de facto method for building robust neural networks, but it can be computationally expensive. To mitigate this, fast single-step attacks can be used, but this may lead to catastrophic overfitting (CO). This phenomenon appears when networks gain non-trivial robustness during the first stages of AT, but then reach a breaking point where they become vulnerable in just a few iterations. The mechanisms that lead to this failure mode are still poorly understood. In this work, we study the onset of CO in single-step AT methods through controlled modifications of typical datasets of natural images. In particular, we show that CO can be induced at much smaller $\\epsilon$ values than it was observed before just by injecting images with seemingly innocuous features. These features aid non-robust classification but are not enough to achieve robustness on their own. Through extensive experiments we analyze this novel phenomenon and discover that the presence of these easy features induces a learning shortcut that leads to CO. Our findings provide new insights into the mechanisms of CO and improve our understanding of the dynamics of AT",
    "checked": true,
    "id": "b74747b361c433984c7883270454be6caa02c386",
    "semantic_title": "catastrophic overfitting can be induced with discriminative non-robust features",
    "citation_count": 3,
    "authors": [
      "Guillermo Ortiz-Jimenez",
      "Pau de Jorge",
      "Amartya Sanyal",
      "Adel Bibi",
      "Puneet K. Dokania",
      "Pascal Frossard",
      "Grégory Rogez",
      "Philip Torr"
    ]
  },
  "https://openreview.net/forum?id=brGgOAXYtr": {
    "title": "POMRL: No-Regret Learning-to-Plan with Increasing Horizons",
    "volume": "expert",
    "abstract": "We study the problem of planning under model uncertainty in an online meta-reinforcement learning (RL) setting where an agent is presented with a sequence of related tasks with limited interactions per task. The agent can use its experience in each task and across tasks to estimate both the transition model and the distribution over tasks. We propose an algorithm to meta-learn the underlying relatedness across tasks, utilize it to plan in each task, and upper-bound the regret of the planning loss. Our bound suggests that the average regret over tasks decreases as the number of tasks increases and as the tasks are more similar. In the classical single-task setting, it is known that the planning horizon should depend on the estimated model's accuracy, that is, on the number of samples within task. We generalize this finding to meta-RL and study this dependence of planning horizons on the number of tasks. Based on our theoretical findings, we derive heuristics for selecting slowly increasing discount factors, and we validate its significance empirically",
    "checked": true,
    "id": "f10ccb539d8de23a3b618d92402150110625407b",
    "semantic_title": "pomrl: no-regret learning-to-plan with increasing horizons",
    "citation_count": 0,
    "authors": [
      "Khimya Khetarpal",
      "Claire Vernade",
      "Brendan O'Donoghue",
      "Satinder Singh",
      "Tom Zahavy"
    ]
  },
  "https://openreview.net/forum?id=XnYtGPgG9p": {
    "title": "Off-Policy Evaluation with Out-of-Sample Guarantees",
    "volume": "expert",
    "abstract": "We consider the problem of evaluating the performance of a decision policy using past observational data. The outcome of a policy is measured in terms of a loss (aka. disutility or negative reward) and the main problem is making valid inferences about its out-of-sample loss when the past data was observed under a different and possibly unknown policy. Using a sample-splitting method, we show that it is possible to draw such inferences with finite-sample coverage guarantees about the entire loss distribution, rather than just its mean. Importantly, the method takes into account model misspecifications of the past policy - including unmeasured confounding. The evaluation method can be used to certify the performance of a policy using observational data under a specified range of credible model assumptions",
    "checked": true,
    "id": "eac9a2b2aa6478d00f3b5c5d8e78e8d1d445540b",
    "semantic_title": "off-policy evaluation with out-of-sample guarantees",
    "citation_count": 4,
    "authors": [
      "Sofia Ek",
      "Dave Zachariah",
      "Fredrik D. Johansson",
      "Peter Stoica"
    ]
  },
  "https://openreview.net/forum?id=MaDvbLaBiF": {
    "title": "Towards a More Rigorous Science of Blindspot Discovery in Image Classification Models",
    "volume": "expert",
    "abstract": "A growing body of work studies Blindspot Discovery Methods (\"BDM\"s): methods that use an image embedding to find semantically meaningful (i.e., united by a human-understandable concept) subsets of the data where an image classifier performs significantly worse. Motivated by observed gaps in prior work, we introduce a new framework for evaluating BDMs, SpotCheck, that uses synthetic image datasets to train models with known blindspots and a new BDM, PlaneSpot, that uses a 2D image representation. We use SpotCheck to run controlled experiments that identify factors that influence BDM performance (e.g., the number of blindspots in a model, or features used to define the blindspot) and show that PlaneSpot is competitive with and in many cases outperforms existing BDMs. Importantly, we validate these findings by designing additional experiments that use real image data from MS-COCO, a large image benchmark dataset. Our findings suggest several promising directions for future work on BDM design and evaluation. Overall, we hope that the methodology and analyses presented in this work will help facilitate a more rigorous science of blindspot discovery",
    "checked": true,
    "id": "cc8a830290262fb00de2a72c8ed49ef700fb639f",
    "semantic_title": "towards a more rigorous science of blindspot discovery in image classification models",
    "citation_count": 6,
    "authors": [
      "Gregory Plumb",
      "Nari Johnson",
      "Angel Cabrera",
      "Ameet Talwalkar"
    ]
  },
  "https://openreview.net/forum?id=fvEvDlKko6": {
    "title": "Black-Box Batch Active Learning for Regression",
    "volume": "expert",
    "abstract": "Batch active learning is a popular approach for efficiently training machine learning models on large, initially unlabelled datasets by repeatedly acquiring labels for batches of data points. However, many recent batch active learning methods are white-box approaches and are often limited to differentiable parametric models: they score unlabeled points using acquisition functions based on model embeddings or first- and second-order derivatives. In this paper, we propose black-box batch active learning for regression tasks as an extension of white-box approaches. Crucially, our method only relies on model predictions. This approach is compatible with a wide range of machine learning models, including regular and Bayesian deep learning models and non-differentiable models such as random forests. It is rooted in Bayesian principles and utilizes recent kernel-based approaches. This allows us to extend a wide range of existing state-of-the-art white-box batch active learning methods (BADGE, BAIT, LCMD) to black-box models. We demonstrate the effectiveness of our approach through extensive experimental evaluations on regression datasets, achieving surprisingly strong performance compared to white-box approaches for deep learning models",
    "checked": true,
    "id": "073c97a6bbebcebd0f9b5d441c194d397b6654cb",
    "semantic_title": "black-box batch active learning for regression",
    "citation_count": 9,
    "authors": [
      "Andreas Kirsch"
    ]
  },
  "https://openreview.net/forum?id=p7UTv2hWgM": {
    "title": "Stochastic gradient updates yield deep equilibrium kernels",
    "volume": "expert",
    "abstract": "Implicit deep learning allows one to compute with implicitly defined features, for example features that solve optimisation problems. We consider the problem of computing with implicitly defined features in a kernel regime. We call such a kernel a deep equilibrium kernel (DEKer). Specialising on a stochastic gradient descent (SGD) update rule applied to features (not weights) in a latent variable model, we find an exact deterministic update rule for the (DEKer) in a high dimensional limit. This derived update rule resembles previously introduced infinitely wide neural network kernels. To perform our analysis, we describe an alternative parameterisation of the link function of exponential families, a result that may be of independent interest. This new parameterisation allows us to draw new connections between a statistician's inverse link function and a machine learner's activation function. We describe an interesting property of SGD in this high dimensional limit: even though individual iterates are random vectors, inner products of any two iterates are deterministic, and can converge to a unique fixed point as the number of iterates increases. We find that the (DEKer) empirically outperforms related neural network kernels on a series of benchmarks",
    "checked": true,
    "id": "97add8809de93dbe854b5eb900c4222c43e847fb",
    "semantic_title": "stochastic gradient updates yield deep equilibrium kernels",
    "citation_count": 0,
    "authors": [
      "Russell Tsuchida",
      "Cheng Soon Ong"
    ]
  },
  "https://openreview.net/forum?id=akg6kdx0Pk": {
    "title": "Instance-Adaptive Video Compression: Improving Neural Codecs by Training on the Test Set",
    "volume": "expert",
    "abstract": "We introduce a video compression algorithm based on instance-adaptive learning. On each video sequence to be transmitted, we finetune a pretrained compression model. The optimal parameters are transmitted to the receiver along with the latent code. By entropy-coding the parameter updates under a suitable mixture model prior, we ensure that the network parameters can be encoded efficiently. This instance-adaptive compression algorithm is agnostic about the choice of base model and has the potential to improve any neural video codec. On UVG, HEVC, and Xiph datasets, our codec improves the performance of a scale-space flow model by between 21% and 27% BD-rate savings, and that of a state-of-the-art B-frame model by 17 to 20% BD-rate savings. We also demonstrate that instance-adaptive finetuning improves the robustness to domain shift. Finally, our approach reduces the capacity requirements of compression models. We show that it enables a competitive performance even after reducing the network size by 70%",
    "checked": true,
    "id": "2e35509f6d2d64a138787a8f78e383a7fa33182d",
    "semantic_title": "instance-adaptive video compression: improving neural codecs by training on the test set",
    "citation_count": 24,
    "authors": [
      "Ties van Rozendaal",
      "Johann Brehmer",
      "Yunfan Zhang",
      "Reza Pourreza",
      "Auke J. Wiggers",
      "Taco Cohen"
    ]
  },
  "https://openreview.net/forum?id=nHfPXl1ly7": {
    "title": "A Kernel Perspective on Behavioural Metrics for Markov Decision Processes",
    "volume": "expert",
    "abstract": "We present a novel perspective on behavioural metrics for Markov decision processes via the use of positive definite kernels. We define a new metric under this lens that is provably equivalent to the recently introduced MICo distance (Castro et al., 2021). The kernel perspective enables us to provide new theoretical results, including value-function bounds and low-distortion finite-dimensional Euclidean embeddings, which are crucial when using behavioural metrics for reinforcement learning representations. We complement our theory with strong empirical results that demonstrate the effectiveness of these methods in practice",
    "checked": true,
    "id": "5519514e57c40d36189fdfeeadb79bff1ef5b83f",
    "semantic_title": "a kernel perspective on behavioural metrics for markov decision processes",
    "citation_count": 5,
    "authors": [
      "Pablo Samuel Castro",
      "Tyler Kastner",
      "Prakash Panangaden",
      "Mark Rowland"
    ]
  },
  "https://openreview.net/forum?id=jgMqve6Qhw": {
    "title": "Dual PatchNorm",
    "volume": "expert",
    "abstract": "We propose Dual PatchNorm: two Layer Normalization layers (LayerNorms), before and after the patch embedding layer in Vision Transformers. We demonstrate that Dual PatchNorm outperforms the result of exhaustive search for alternative LayerNorm placement strategies in the Transformer block itself. In our experiments on image classification and contrastive learning, incorporating this trivial modification, often leads to improved accuracy over well-tuned vanilla Vision Transformers and never hurts",
    "checked": true,
    "id": "08fedef308bbf139f3fc498b0df891d1ad1969a7",
    "semantic_title": "dual patchnorm",
    "citation_count": 12,
    "authors": [
      "Manoj Kumar",
      "Mostafa Dehghani",
      "Neil Houlsby"
    ]
  },
  "https://openreview.net/forum?id=NNRIGE8bvF": {
    "title": "Fast Treatment Personalization with Latent Bandits in Fixed-Confidence Pure Exploration",
    "volume": "expert",
    "abstract": "Personalizing treatments for patients often involves a period of trial-and-error search until an optimal choice is found. To minimize suffering and other costs, it is critical to make this process as short as possible. When treatments have primarily short-term effects, search can be performed with multi-armed bandits (MAB), but these typically require long exploration periods to guarantee optimality. In this work, we design MAB algorithms which provably identify optimal treatments quickly by leveraging prior knowledge of the types of decision processes (patients) we can encounter, in the form of a latent variable model. We present two algorithms, the Latent LP-based Track and Stop (LLPT) explorer and the Divergence Explorer for this setting: fixed-confidence pure-exploration latent bandits. We give a lower bound on the stopping time of any algorithm which is correct at a given certainty level, and prove that the expected stopping time of the LLPT Explorer matches the lower bound in the high-certainty limit. Finally, we present results from an experimental study based on realistic simulation data for Alzheimer's disease, demonstrating that our formulation and algorithms lead to a significantly reduced stopping time",
    "checked": true,
    "id": "3fd87281e451eaa2362b7e21685bb27c6836418d",
    "semantic_title": "fast treatment personalization with latent bandits in fixed-confidence pure exploration",
    "citation_count": 6,
    "authors": [
      "Newton Mwai Kinyanjui",
      "Emil Carlsson",
      "Fredrik D. Johansson"
    ]
  },
  "https://openreview.net/forum?id=fvyh6mDWFr": {
    "title": "Understanding Noise-Augmented Training for Randomized Smoothing",
    "volume": "expert",
    "abstract": "Randomized smoothing is a technique for providing provable robustness guarantees against adversarial attacks while making minimal assumptions about a classifier. This method relies on taking a majority vote of any base classifier over multiple noise-perturbed inputs to obtain a smoothed classifier, and it remains the tool of choice to certify deep and complex neural network models. Nonetheless, non-trivial performance of such smoothed classifier crucially depends on the base model being trained on noise-augmented data, i.e., on a smoothed input distribution. While widely adopted in practice, it is still unclear how this noisy training of the base classifier precisely affects the risk of the robust smoothed classifier, leading to heuristics and tricks that are poorly understood. In this work we analyze these trade-offs theoretically in a binary classification setting, proving that these common observations are not universal. We show that, without making stronger distributional assumptions, no benefit can be expected from predictors trained with noise-augmentation, and we further characterize distributions where such benefit is obtained. Our analysis has direct implications to the practical deployment of randomized smoothing, and we illustrate some of these via experiments on CIFAR-10 and MNIST, as well as on synthetic datasets",
    "checked": true,
    "id": "6192f29f301f201b71d3c6b5d7bf2d09c15076bb",
    "semantic_title": "understanding noise-augmented training for randomized smoothing",
    "citation_count": 7,
    "authors": [
      "Ambar Pal",
      "Jeremias Sulam"
    ]
  },
  "https://openreview.net/forum?id=Cj6pLclmwT": {
    "title": "Differentially Private Image Classification from Features",
    "volume": "expert",
    "abstract": "In deep learning, leveraging transfer learning has recently been shown to be an effective strategy for training large high performance models with Differential Privacy (DP). Moreover, somewhat surprisingly, recent works have found that privately training just the last layer of a pre-trained model provides the best utility with DP. While past studies largely rely on using first-order differentially private training algorithms like DP-SGD for training large models, in the specific case of privately learning from features, we observe that computational burden is often low enough to allow for more sophisticated optimization schemes, including second-order methods. To that end, we systematically explore the effect of design parameters such as loss function and optimization algorithm. We find that, while commonly used logistic regression performs better than linear regression in the non-private setting, the situation is reversed in the private setting. We find that least-squares linear regression is much more effective than logistic regression from both privacy and computational standpoint, especially at stricter epsilon values ($\\epsilon < 1$). On the optimization side, we also explore using Newton's method, and find that second-order information is quite helpful even with privacy, although the benefit significantly diminishes with stricter privacy guarantees. While both methods use second-order information, least squares is more effective at lower epsilon values while Newton's method is more effective at larger epsilon values. To combine the benefits of both methods, we propose a novel optimization algorithm called DP-FC, which leverages feature covariance instead of the Hessian of the logistic regression loss and performs well across all $\\epsilon$ values we tried. With this, we obtain new SOTA results on ImageNet-1k, CIFAR-100 and CIFAR-10 across all values of $\\epsilon$ typically considered. Most remarkably, on ImageNet-1K, we obtain top-1 accuracy of 88\\% under DP guarantee of (8, $8 * 10^{-7}$) and 84.3\\% under (0.1, $8 * 10^{-7}$)",
    "checked": true,
    "id": "6ad9563abfd9dc2a8e09f156466ac27204d566c9",
    "semantic_title": "differentially private image classification from features",
    "citation_count": 8,
    "authors": [
      "Harsh Mehta",
      "Walid Krichene",
      "Abhradeep Guha Thakurta",
      "Alexey Kurakin",
      "Ashok Cutkosky"
    ]
  },
  "https://openreview.net/forum?id=eGLdVRvvfQ": {
    "title": "DEUP: Direct Epistemic Uncertainty Prediction",
    "volume": "expert",
    "abstract": "Epistemic Uncertainty is a measure of the lack of knowledge of a learner which diminishes with more evidence. While existing work focuses on using the variance of the Bayesian posterior due to parameter uncertainty as a measure of epistemic uncertainty, we argue that this does not capture the part of lack of knowledge induced by model misspecification. We discuss how the excess risk, which is the gap between the generalization error of a predictor and the Bayes predictor, is a sound measure of epistemic uncertainty which captures the effect of model misspecification. We thus propose a principled framework for directly estimating the excess risk by learning a secondary predictor for the generalization error and subtracting an estimate of aleatoric uncertainty, i.e., intrinsic unpredictability. We discuss the merits of this novel measure of epistemic uncertainty, and highlight how it differs from variance-based measures of epistemic uncertainty and addresses its major pitfall. Our framework, Direct Epistemic Uncertainty Prediction (DEUP) is particularly interesting in interactive learning environments, where the learner is allowed to acquire novel examples in each round. Through a wide set of experiments, we illustrate how existing methods in sequential model optimization can be improved with epistemic uncertainty estimates from DEUP, and how DEUP can be used to drive exploration in reinforcement learning. We also evaluate the quality of uncertainty estimates from DEUP for probabilistic image classification and predicting synergies of drug combinations",
    "checked": true,
    "id": "8a4a90a925d0376e740df508ac307613c647e5c3",
    "semantic_title": "deup: direct epistemic uncertainty prediction",
    "citation_count": 97,
    "authors": [
      "Salem Lahlou",
      "Moksh Jain",
      "Hadi Nekoei",
      "Victor I Butoi",
      "Paul Bertin",
      "Jarrid Rector-Brooks",
      "Maksym Korablyov",
      "Yoshua Bengio"
    ]
  },
  "https://openreview.net/forum?id=a1meaRy1bN": {
    "title": "Robustness through Data Augmentation Loss Consistency",
    "volume": "expert",
    "abstract": "While deep learning through empirical risk minimization (ERM) has succeeded at achieving human-level performance at a variety of complex tasks, ERM is not robust to distribution shifts or adversarial attacks. Synthetic data augmentation followed by empirical risk minimization (DA-ERM) is a simple and widely used solution to improve robustness in ERM. In addition, consistency regularization can be applied to further improve the robustness of the model by forcing the representation of the original sample and the augmented one to be similar. However, existing consistency regularization methods are not applicable to covariant data augmentation, where the label in the augmented sample is dependent on the augmentation function. For example, dialog state covaries with named entity when we augment data with a new named entity. In this paper, we propose data augmented loss invariant regularization (DAIR), a simple form of consistency regularization that is applied directly at the loss level rather than intermediate features, making it widely applicable to both invariant and covariant data augmentation regardless of network architecture, problem setup, and task. We apply DAIR to real-world learning problems involving covariant data augmentation: robust neural task-oriented dialog state tracking and robust visual question answering. We also apply DAIR to tasks involving invariant data augmentation: robust regression, robust classification against adversarial attacks, and robust ImageNet classification under distribution shift. Our experiments show that DAIR consistently outperforms ERM and DA-ERM with little marginal computational cost and sets new state-of-the-art results in several benchmarks involving covariant data augmentation. Our code of all experiments are available at: https://github.com/optimization-for-data-driven-science/DAIR",
    "checked": true,
    "id": "1fa65fffaae68bcb15a4db6219007e8421cef685",
    "semantic_title": "robustness through data augmentation loss consistency",
    "citation_count": 8,
    "authors": [
      "Tianjian Huang",
      "Shaunak Ashish Halbe",
      "Chinnadhurai Sankar",
      "Pooyan Amini",
      "Satwik Kottur",
      "Alborz Geramifard",
      "Meisam Razaviyayn",
      "Ahmad Beirami"
    ]
  },
  "https://openreview.net/forum?id=Uu8WwCFpQv": {
    "title": "Towards Large Scale Transfer Learning for Differentially Private Image Classification",
    "volume": "expert",
    "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) has emerged as a popular private training algorithm. Unfortunately, the computational cost of training large-scale models with DP-SGD is substantially higher than non-private training. This is further exacerbated by the fact that increasing the number of parameters leads to larger degradation in utility with DP. In this work, we zoom in on the ImageNet dataset and demonstrate that, similar to the non-private case, pre-training over-parameterized models on a large public dataset can lead to substantial gains when the models are finetuned privately. Moreover, by systematically comparing private and non-private models across a range of large batch sizes, we find that similar to the non-private setting, the choice of optimizer can further improve performance substantially with DP. By using the LAMB optimizer, we saw improvement of up to 20$\\%$ points (absolute). We also show that finetuning just the last layer for a \\emph{single step} in the full batch setting, combined with extremely small-scale (near-zero) initialization leads to both SOTA results of 81.7 $\\%$ under a wide privacy budget range of $\\epsilon \\in [4, 10]$ and $\\delta$ = $10^{-6}$ while minimizing the computational overhead substantially. Finally, we present additional results on CIFAR-10 and CIFAR-100, surpassing previous state of the art by leveraging transfer learning with our recommendations",
    "checked": true,
    "id": "ba8a5e07e9f7fdc6e53b67a1c85b7f6024860943",
    "semantic_title": "towards large scale transfer learning for differentially private image classification",
    "citation_count": 11,
    "authors": [
      "Harsh Mehta",
      "Abhradeep Guha Thakurta",
      "Alexey Kurakin",
      "Ashok Cutkosky"
    ]
  }
}