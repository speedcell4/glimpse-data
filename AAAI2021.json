{
  "https://ojs.aaai.org/index.php/AAAI/article/view/16071": {
    "title": "The Undergraduate Games Corpus: A Dataset for Machine Perception of Interactive Media",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f7a96c935cd4475699fcf16bf9f07878c931b990",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16072": {
    "title": "Efficient Poverty Mapping from High Resolution Remote Sensing Images",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "22ae04d51c341487068cb56f76ffb5f10e214679",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16073": {
    "title": "Optimal Kidney Exchange with Immunosuppressants",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "75045b41ed7498ddf2537c8511e7c15d5a0b08e9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16074": {
    "title": "TreeCaps: Tree-Based Capsule Networks for Source Code Processing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "11a0bdb1a049eaeae72c38278936c1d599728f87",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16075": {
    "title": "A Bottom-Up DAG Structure Extraction Model for Math Word Problems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4ae6b5ce971c58c1280bc971a1879e6d547c5f8c",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16076": {
    "title": "Diagnose Like A Pathologist: Weakly-Supervised Pathologist-Tree Network for Slide-Level Immunohistochemical Scoring",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "50665b18f9b2072c20dbf9419b290e936ca3a402",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16077": {
    "title": "Modeling the Momentum Spillover Effect for Stock Prediction via Attribute-Driven Graph Attention Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6b8048a62b1d8040eff9d007c2a2b0a5be770049",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16078": {
    "title": "Differentially Private Link Prediction with Protected Connections",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2ce1d9a59c5de2a5d48f38f42a7ea693eb061f56",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16079": {
    "title": "Graph Neural Network to Dilute Outliers for Refactoring Monolith Application",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "95f4ed97e39673a1d1c98ba636a69f322177e0d4",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16080": {
    "title": "KAN: Knowledge-aware Attention Network for Fake News Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b357470ddbd30729cb39dc88ea76ed08bc5dabb0",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16081": {
    "title": "When Hashing Met Matching: Efficient Spatio-Temporal Search for Ridesharing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a29867944cf372ea84a00a7f3863686a8119ca29",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16082": {
    "title": "Gene Regulatory Network Inference using 3D Convolutional Neural Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f7bbc056fb75eb6ce13ea418e11a11c500aac88a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16083": {
    "title": "Universal Trading for Order Execution with Oracle Policy Distillation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "daa92545b0363e1d8ea83e74b47d7f7e9790fa80",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16084": {
    "title": "Dual-Octave Convolution for Accelerated Parallel MR Image Reconstruction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "52b22ed78e881a80f919965deffbf85db3d9e776",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16085": {
    "title": "MIMOSA: Multi-constraint Molecule Sampling for Molecule Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "143f3784064bdb042e580534722a6bb395371daf",
    "citation_count": 28
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16086": {
    "title": "ECG ODE-GAN: Learning Ordinary Differential Equations of ECG Dynamics via Generative Adversarial Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "efb462bebead45a81b9e51f008fbed89e627e355",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16087": {
    "title": "Towered Actor Critic For Handling Multiple Action Types In Reinforcement Learning For Drug Discovery",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3cfe1f9f3e1a6a31e2ec18c8641dbedafd538f8a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16088": {
    "title": "Hierarchical Graph Convolution Network for Traffic Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "aeea29ad352a04e74b6a4459e7328aa6e904486d",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16089": {
    "title": "Automated Lay Language Summarization of Biomedical Scientific Reviews",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5b4376a0b97a474a4e063768cc4faf20691b7887",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16090": {
    "title": "Sub-Seasonal Climate Forecasting via Machine Learning: Challenges, Analysis, and Advances",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cac3eda036b01ff0c0c6babab25fb77dd8633afb",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16091": {
    "title": "Compound Word Transformer: Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eb0931c39904a40c6cb4aa35c9b21d5e3b7dc856",
    "citation_count": 54
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16092": {
    "title": "Modeling the Compatibility of Stem Tracks to Generate Music Mashups",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d64482e679b6819301db5e199de9b43c44b83e1",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16093": {
    "title": "SDGNN: Learning Node Representation for Signed Directed Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5c98e15d451980576e01db4fee47543c86920671",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16094": {
    "title": "The Causal Learning of Retail Delinquency",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "96bf5991518241aeb910226e8d61f4a7d5a9fd3b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16095": {
    "title": "Deep Portfolio Optimization via Distributional Prediction of Residual Factors",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "98898ce8f3a1addb1d2e1e126781b4b765a0e4ca",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16096": {
    "title": "Complex Coordinate-Based Meta-Analysis with Probabilistic Programming",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "01c8fe7e0fe22a8c8d1496de8808d99c65df7069",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16097": {
    "title": "Who You Would Like to Share With? A Study of Share Recommendation in Social E-commerce",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dc84ee6eec3d81b8293186eb196db7d239a71c81",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16098": {
    "title": "Estimating Calibrated Individualized Survival Curves with Deep Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "109f81447b6206c7bd8a0efc48b2c22ff9fc6ca2",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16099": {
    "title": "Deep Contextual Clinical Prediction with Reverse Distillation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "885015a0faa0903f170b9b588a5d1b14660dc20f",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16100": {
    "title": "Learning to Stop: Dynamic Simulation Monte-Carlo Tree Search",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ad038ba73ba8a2b7d855624c7e107e711dd63790",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16101": {
    "title": "Predicting Livelihood Indicators from Community-Generated Street-Level Imagery",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "87db72bfebf9226e338279a452c6638ec0f8ab8a",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16102": {
    "title": "Deep Conservation: A Latent-Dynamics Model for Exact Satisfaction of Physical Conservation Laws",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "02327b889e75a9d86d4351cfea7c17e730d8efa4",
    "citation_count": 41
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16103": {
    "title": "Two-Stream Convolution Augmented Transformer for Human Activity Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a3196e65467b80f4755968923b382e40c02ccb51",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16104": {
    "title": "Traffic Flow Prediction with Vehicle Trajectories",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "92a192e9852576bf0618cc6846973af840a48a77",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16105": {
    "title": "RevMan: Revenue-aware Multi-task Online Insurance Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "91d6a9159151f5e7d10843cd574d7c5ecf45e21a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16106": {
    "title": "MeInGame: Create a Game Character Face from a Single Portrait",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e532172848febb7a0a42b853279ad948a2afdb5b",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16107": {
    "title": "Community-Aware Multi-Task Transportation Demand Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6738bad94c8b65ec02088c9c15f9454fdb56b306",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16108": {
    "title": "Asynchronous Stochastic Gradient Descent for Extreme-Scale Recommender Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fc50a687bb3ee2c39a35304ca42a095460dd8ddd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16109": {
    "title": "In-game Residential Home Planning via Visual Context-aware Global Relation Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2b446c6ec0ba9a2a81fb70016c675bfb452f8df6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16110": {
    "title": "Relational Classification of Biological Cells in Microscopy Images",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bc1de021523d712169c1591d8ce93cfe29185482",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16111": {
    "title": "Deep Style Transfer for Line Drawings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f5eec0ff44d936701e3a769917f03b8a60af9086",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16112": {
    "title": "RNA Secondary Structure Representation Network for RNA-proteins Binding Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "428a7f685a1bc12e3bfda32ba97f75262e260560",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16113": {
    "title": "PANTHER: Pathway Augmented Nonnegative Tensor Factorization for HighER-order Feature Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "303149806dc5be379b4c1fc7070092437b3a6ad0",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16114": {
    "title": "Programmatic Strategies for Real-Time Strategy Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c34d71c8eb4d179562d7d658b08b62ff8a587503",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16115": {
    "title": "Capturing Uncertainty in Unsupervised GPS Trajectory Segmentation Using Bayesian Deep Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b40d7a8c86fcfc13c22de33c96aa6f15039263d6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16116": {
    "title": "Low-Rank Registration Based Manifolds for Convection-Dominated PDEs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0f07c175ff6ba8bc46fb7b67cf18d531d19e0028",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16117": {
    "title": "Symbolic Music Generation with Transformer-GANs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f07c5c540233b22f0ca154c80c713e2aed3c9606",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16118": {
    "title": "Bringing UMAP Closer to the Speed of Light with GPU Acceleration",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5b17bfb51597d158100ba3f53148f37ac6aaf7c0",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16119": {
    "title": "Deep Just-In-Time Inconsistency Detection Between Comments and Source Code",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "03b6e258168796f96f1c40d32411bd699b6de922",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16120": {
    "title": "XraySyn: Realistic View Synthesis From a Single Radiograph Through CT Priors",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dbe6bff16563ba3b821f8fd5a93d298d0fd9517a",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16121": {
    "title": "Pragmatic Code Autocomplete",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2db9df2f4d896f43b05fb6155cce593fd748cf29",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16122": {
    "title": "RareBERT: Transformer Architecture for Rare Disease Patient Identification using Administrative Claims",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "66d1f09daff4d3bf4deb3148ce5e080e71d82ca3",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16123": {
    "title": "Queue-Learning: A Reinforcement Learning Approach for Providing Quality of Service",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fd15384646a386521ee4824c35011bc17e6fa987",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16124": {
    "title": "Research Reproducibility as a Survival Analysis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9d8b7b2c4e7a006cbaf4418804318647b6a4fe99",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16125": {
    "title": "DeepPseudo: Pseudo Value Based Deep Learning Models for Competing Risk Analysis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "90821085ac62d12d8849bd23a9d5e13c7229bfe2",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16126": {
    "title": "CardioGAN: Attentive Generative Adversarial Network with Dual Discriminators for Synthesis of ECG from PPG",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "61b661386940a48c1f66a22473e73561de530a01",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16127": {
    "title": "Stock Selection via Spatiotemporal Hypergraph Attention Network: A Learning to Rank Approach",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4ed91fa585dc4e5cdbfb30b30711104a02f7e43e",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16128": {
    "title": "Content Masked Loss: Human-Like Brush Stroke Planning in a Reinforcement Learning Painting Agent",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1b6978955a78e3b2060ce471d6e7a0c52185c219",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16129": {
    "title": "StatEcoNet: Statistical Ecology Neural Networks for Species Distribution Modeling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1011fff0d08d3af2c6c6f38426f0bb68e37c3002",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16130": {
    "title": "Integrating Static and Dynamic Data for Improved Prediction of Cognitive Declines Using Augmented Genotype-Phenotype Representations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "63b77b1147b2e10af86b2661aaa06c791bbadd5d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16131": {
    "title": "GTA: Graph Truncated Attention for Retrosynthesis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d82a03951796a352dc4442387782c21d2b761480",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16132": {
    "title": "Physics-Informed Deep Learning for Traffic State Estimation: A Hybrid Paradigm Informed By Second-Order Traffic Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d2a1df992e2112f579a16301b2df78c2fff5cd8e",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16133": {
    "title": "The LOB Recreation Model: Predicting the Limit Order Book from TAQ History Using an Ordinary Differential Equation Recurrent Neural Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6980d5939304e09125c9fac7881036ee323bea07",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16134": {
    "title": "Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multi-modal Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0c107281ab54d0dd4df7539a18afebf6e3478bfb",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16135": {
    "title": "Oral-3D: Reconstructing the 3D Structure of Oral Cavity from Panoramic X-ray",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "276f98e28d9397f5095fe2454edd303d9ffc1b08",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16136": {
    "title": "Traffic Shaping in E-Commercial Search Engine: Multi-Objective Online Welfare Maximization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e09f71d5a04c5e0b7ea220c01eec87447e4d724b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16137": {
    "title": "Fully Exploiting Cascade Graphs for Real-time Forwarding Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dcd7579ab8ecfa4ad6ab72b372684dbd437af90f",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16138": {
    "title": "A Hierarchical Approach to Multi-Event Survival Analysis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5fa3bec1888184a6e5798853cda9665b014c6a9d",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16139": {
    "title": "DeepWriteSYN: On-Line Handwriting Synthesis via Deep Short-Term Representations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4f5f71882cf26bded7ef941539a746289d5ad27a",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16140": {
    "title": "Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5f8cc52cdd8859963a9f074cf461f2132a38d346",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16141": {
    "title": "PSSM-Distil: Protein Secondary Structure Prediction (PSSP) on Low-Quality PSSM by Knowledge Distillation with Contrastive Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "78cc2f6958a5338b5fadb7ae1e860c74177e7064",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16142": {
    "title": "Commission Fee is not Enough: A Hierarchical Reinforced Framework for Portfolio Management",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bfff859c8600205c69e79a18e0818ab85fc169e5",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16143": {
    "title": "Alternative Baselines for Low-Shot 3D Medical Image Segmentation---An Atlas Perspective",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "da135fef642ac229627d64e1ea5d38bb297ad90e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16144": {
    "title": "DeepTrader: A Deep Reinforcement Learning Approach for Risk-Return Balanced Portfolio Management with Market Conditions Embedding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0b26cb46675c0b00483c254488c9a14d89eec8e5",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16145": {
    "title": "Dynamic Gaussian Mixture based Deep Generative Model For Robust Forecasting on Sparse Multivariate Time Series",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "90f292fd8f0f2e321f3829b8cfee7cd7f72ace6e",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16146": {
    "title": "Automated Symbolic Law Discovery: A Computer Vision Approach",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8951402483e58f6279266ac836a88ad1e445eda6",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16147": {
    "title": "Hierarchically and Cooperatively Learning Traffic Signal Control",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7284ae678ab87196d0e0ed393e0796e6772dc7d4",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16148": {
    "title": "Deep Partial Rank Aggregation for Personalized Attributes",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6e6a44f0dde431467f8aa484abd6d2fe160812d6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16149": {
    "title": "Towards Efficient Selection of Activity Trajectories based on Diversity and Coverage",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e3db5eb9b09842d130ce80f7ba099012c20dc266",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16150": {
    "title": "Minimizing Labeling Cost for Nuclei Instance Segmentation and Classification with Cross-domain Images and Weak Labels",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f9282d8871dd3d87a002ffd6e38eefff65978128",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16151": {
    "title": "Bigram and Unigram Based Text Attack via Adaptive Monotonic Heuristic Search",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "728171df555472656a9d9e2f155c16324fd7cca8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16152": {
    "title": "GRASP: Generic Framework for Health Status Representation Learning Based on Incorporating Knowledge from Similar Patients",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e8ddbcabf0bb3b4e377f1a6d5d766e262264f7a3",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16153": {
    "title": "Window Loss for Bone Fracture Detection and Localization in X-ray Images with Point-based Annotation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "61ee1f053dc557e3772b5a9d208a28f39418e5ee",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16154": {
    "title": "A Spatial Regulated Patch-Wise Approach for Cervical Dysplasia Diagnosis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7f3a41cd8dfdd09cd2630b2163af2421ada9381b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16155": {
    "title": "Online 3D Bin Packing with Constrained Deep Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "106ff550db26df62eb8374527246bbd07b033278",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16156": {
    "title": "DEAR: Deep Reinforcement Learning for Online Advertising Impression in Recommender Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "94e91560da6e649c2d5eda9e989526697ee3e885",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16157": {
    "title": "Towards Balanced Defect Prediction with Better Information Propagation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1a6c541cad9d2851cc5b3c0fcd2421026935af2d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16158": {
    "title": "Many-to-One Distribution Learning and K-Nearest Neighbor Smoothing for Thoracic Disease Identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cd4a32498f016a257f15c227551fad499ec50f63",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16159": {
    "title": "Probabilistic Programming Bots in Intuitive Physics Game Play",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b98726c7c2006970366b84388f3fa18e8679eef8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16160": {
    "title": "Model-Agnostic Fits for Understanding Information Seeking Patterns in Humans",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bf4f673f7e483c35693f989af7d1fd0b4a3c7861",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16161": {
    "title": "Apparently Irrational Choice as Optimal Sequential Decision Making",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d46135b704c65396b3d95dae92aaa811cc1f0355",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16162": {
    "title": "Visual Relation Detection using Hybrid Analogical Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "82ff28447df9049fa006a62060740b0a538d5d62",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16163": {
    "title": "Neural Analogical Matching",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "25b7f92266f09fc9a5bbb438e8f0da71dccbce78",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16164": {
    "title": "Interpretable Self-Supervised Facial Micro-Expression Learning to Predict Cognitive State and Neurological Disorders",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "91a5ba83acbe9e764501a6f8b2bba461c59c0189",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16165": {
    "title": "Quantum Cognitively Motivated Decision Fusion for Video Sentiment Analysis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "937379606f581fc3001f9b22a49ef1c1072e8c58",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16166": {
    "title": "Towards a Better Understanding of VR Sickness: Physical Symptom Prediction for VR Contents",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "afd263ad213f403b491d0e3c3388136725447ea0",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16167": {
    "title": "PHASE: PHysically-grounded Abstract Social Events for Machine Social Perception",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c360c3f6d57e6dede93b00aa3d9cc0d2791a86c8",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16168": {
    "title": "Riemannian Embedding Banks for Common Spatial Patterns with EEG-based SPD Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "613a3b6c80f260e8d086fdbccaffeeb409427b04",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16169": {
    "title": "Plug-and-Play Domain Adaptation for Cross-Subject EEG-based Emotion Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "082d2c12f81f860a53fa9b30e855b2a34f27b2ba",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16170": {
    "title": "Localization in the Crowd with Topological Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e7eefae3477c644364fd18e4172113ddf6b14960",
    "citation_count": 41
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16171": {
    "title": "Deep Event Stereo Leveraged by Event-to-Image Translation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2db03d59e5825f2a5d00bab95bb515fb05280b8f",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16172": {
    "title": "Optical Flow Estimation from a Single Motion-blurred Image",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1d0bf18f627903aacb1dee7f7b2b81ca35b581f4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16173": {
    "title": "Motion-blurred Video Interpolation and Extrapolation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "57ff782643597bbd5be70703320bff63acd50ce8",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16174": {
    "title": "Disentangled Multi-Relational Graph Convolutional Network for Pedestrian Trajectory Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "69bee814d5731fd6f3315c0f2edab5e25fcc79be",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16175": {
    "title": "Dense Events Grounding in Video",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4935b3a6d4e01e7965faf66ba489fd7772d624fe",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16176": {
    "title": "Context-aware Attentional Pooling (CAP) for Fine-grained Visual Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "48913aecd8da6475d93fae7beb13d7ef939b3d8a",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16177": {
    "title": "Appearance-Motion Memory Consistency Network for Video Anomaly Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "08c4fa2132dda85c5f02a88fddfb7f17973f3978",
    "citation_count": 42
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16178": {
    "title": "Rethinking Object Detection in Retail Stores",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "16951f0976a6e181d7c6d252e3f04f8005549f93",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16179": {
    "title": "YOLObile: Real-Time Object Detection on Mobile Devices via Compression-Compilation Co-Design",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "33ed5a8c4a6ec049397f77e493041ff51c91fb6a",
    "citation_count": 38
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16180": {
    "title": "Semantic MapNet: Building Allocentric Semantic Maps and Representations from Egocentric Views",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "32176ebfad512c86f3c9ed22bbacf5a72fcd926b",
    "citation_count": 29
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16181": {
    "title": "Understanding Deformable Alignment in Video Super-Resolution",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "45ddf05fe644114def892da75999f4c5778abd04",
    "citation_count": 63
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16182": {
    "title": "Deep Metric Learning with Graph Consistency",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "19a2340ff810deb44789661c130b5e77b26768f0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16183": {
    "title": "CNN Profiler on Polar Coordinate Images for Tropical Cyclone Structure Analysis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7928cdd65449f24e3b5b480ad233c027d7de2b56",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16184": {
    "title": "Commonsense Knowledge Aware Concept Selection For Diverse and Informative Visual Storytelling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4cfe344e88d2ae5dbd18507025527bd9a27991ba",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16185": {
    "title": "Attention-based Multi-Level Fusion Network for Light Field Depth Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7a2b2338b6ab7481bf111afd6e72e41a69abfa5a",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16186": {
    "title": "Joint Demosaicking and Denoising in the Wild: The Case of Training Under Ground Truth Uncertainty",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2396a969d45b13072526758f8a3cb6bc119631b6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16187": {
    "title": "Spatial-temporal Causal Inference for Partial Image-to-video Adaptation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "75c0c655c2ebd6a9a016a65e095beb5b42bb94b2",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16188": {
    "title": "Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "62ea5fe5ac1795297343b20fbaad9397c0f0b6ff",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16189": {
    "title": "RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2336388131b3cb41eb44e927aeac10a1dabbedad",
    "citation_count": 64
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16190": {
    "title": "Dual Distribution Alignment Network for Generalizable Person Re-Identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ec0f586a489a5c6ce83e8f39487b541d1bb8b19e",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16191": {
    "title": "RGB-D Salient Object Detection via 3D Convolutional Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "609c315d881f8277991abce44706bfc41129bb2e",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16192": {
    "title": "Mind-the-Gap! Unsupervised Domain Adaptation for Text-Video Retrieval",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "781540a3f6ba1a1525b20d08f219f25f89dd852e",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16193": {
    "title": "Local Relation Learning for Face Forgery Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0e668ffa87695c780546ae29bc9d5bdea00234b8",
    "citation_count": 52
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16194": {
    "title": "Deductive Learning for Weakly-Supervised 3D Human Pose Estimation via Uncalibrated Cameras",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0bd8bd7d793a36917cc4c27c87c0dce3426f4c03",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16195": {
    "title": "A Unified Multi-Scenario Attacking Network for Visual Object Tracking",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3a8034426fd3fbe74c4c9e4517d69de706065efe",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16196": {
    "title": "SSD-GAN: Measuring the Realness in the Spatial and Spectral Domains",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f93a162eb8014fee3feef6b03cd1dcd057e6a4e5",
    "citation_count": 27
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16197": {
    "title": "Multi-Scale Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "32cf93d32f5ad013752b95b0ab7d64bcb1d3d6ff",
    "citation_count": 37
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16198": {
    "title": "Cascade Network with Guided Loss and Hybrid Attention for Finding Good Correspondences",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3aab67fe32c12ae4cdcccdac4f938b3aa0918e45",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16199": {
    "title": "Generalizable Representation Learning for Mixture Domain Face Anti-Spoofing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "000194903cb83bd4af714f950d0266382e2772fc",
    "citation_count": 28
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16200": {
    "title": "SSPC-Net: Semi-supervised Semantic 3D Point Cloud Segmentation Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9fca6fd40a7d653ed4bc8f94736b8f8f8fbc02f0",
    "citation_count": 34
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16201": {
    "title": "Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2cd35c6e53580d2adf5f693b05d5caa19844c19c",
    "citation_count": 45
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16202": {
    "title": "Graph and Temporal Convolutional Networks for 3D Multi-person Pose Estimation in Monocular Videos",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "495cae238b305c7d021957405335c4d2a90d5e08",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16203": {
    "title": "DramaQA: Character-Centered Video Story Understanding with Hierarchical QA",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4d21241b930b005847cf4350294c61d6c29ccd9f",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16204": {
    "title": "DeepCollaboration: Collaborative Generative and Discriminative Models for Class Incremental Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ad8672256f1ff77b68470f082cde11113e6909dd",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16205": {
    "title": "Split then Refine: Stacked Attention-guided ResUNets for Blind Single Image Visible Watermark Removal",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ae10018d80eabefd7755ca30cefe242c1ed71de1",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16206": {
    "title": "RSGNet: Relation based Skeleton Graph Network for Crowded Scenes Pose Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5b729da0fcb53adadc583bb4003ae457a5eaa15a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16207": {
    "title": "Voxel R-CNN: Towards High Performance Voxel-based 3D Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e216ac339cbb4a8accdc266be8f26b554c37a284",
    "citation_count": 153
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16208": {
    "title": "Arbitrary Video Style Transfer via Multi-Channel Correlation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "48aaf8d685eafe00d86cce789591dafcdeb53766",
    "citation_count": 43
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16209": {
    "title": "Similarity Reasoning and Filtration for Image-Text Matching",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6d864a6659e2c503cd6d28d05593f0603b9a48bd",
    "citation_count": 70
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16210": {
    "title": "Spatio-Temporal Difference Descriptor for Skeleton-Based Action Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e870e7a38f01c9d4195a6310d2cb9196456c4de4",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16211": {
    "title": "Towards Universal Physical Attacks on Single Object Tracking",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bbc00e0f8a809bd5def5a930004dabb016a1c878",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16212": {
    "title": "Modeling the Probabilistic Distribution of Unlabeled Data for One-shot Medical Image Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d94db8bf218a9ed41d9df8cab81edf5f68162e8c",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16213": {
    "title": "Few-Shot Class-Incremental Learning via Relation Knowledge Distillation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a1364f6e16db9b2f8938ef9bf5c9e2c80b8089f5",
    "citation_count": 27
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16214": {
    "title": "MIEHDR CNN: Main Image Enhancement based Ghost-Free High Dynamic Range Imaging using Dual-Lens Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "11c91ad084ec95257b55c38e5fb005ccb6d956dc",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16215": {
    "title": "Boosting Image-based Mutual Gaze Detection using Pseudo 3D Gaze",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e51cb2c5ce4d42cd410adaa54278e05da54a078a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16216": {
    "title": "How to Save your Annotation Cost for Panoptic Segmentation?",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7e788ab906c1ef7bea762525c1840e2d3da0067f",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16217": {
    "title": "DIRV: Dense Interaction Region Voting for End-to-End Human-Object Interaction Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b3066105ca44e24a47065ad57dc6d4ed8e6b7bd6",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16218": {
    "title": "DecAug: Augmenting HOI Detection via Decomposition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "821ddd3782bdd4a6945ac69dc428d47b342256b5",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16219": {
    "title": "Partially Non-Autoregressive Image Captioning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ffef9f033a6e7383747e674ca7afacda4188d65e",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16220": {
    "title": "Memory-Augmented Image Captioning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d2c10cd2403a7847d4380b68dee2cb29c81f532b",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16221": {
    "title": "Edge-competing Pathological Liver Vessel Segmentation with Limited Labels",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4e0802df6fb69015d4d066beac985feaafdae6a0",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16222": {
    "title": "Visual Boundary Knowledge Translation for Foreground Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8083ad13f6966791fa69ededbe0658e27ad2530e",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16223": {
    "title": "Learning Complex 3D Human Self-Contact",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bcfe7a84f2cbaef7a292595633c5442c9b71d83e",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16224": {
    "title": "Rain Streak Removal via Dual Graph Convolutional Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0794cd16b9c60ffb1f162f37b28005151024253b",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16225": {
    "title": "CompFeat: Comprehensive Feature Aggregation for Video Instance Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0742b295a4bb83f3e28990e2f87545819dcc9e1a",
    "citation_count": 37
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16226": {
    "title": "Deep Metric Learning with Self-Supervised Ranking",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f1bc6f8ad13a44ed1b6e393055bd510f87f7ca69",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16227": {
    "title": "A Systematic Evaluation of Object Detection Networks for Scientific Plots",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2b3248ed0bb8531d70fba6afc98ec5730be336d3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16228": {
    "title": "The Complexity of Object Association in Multiple Object Tracking",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7c4e0b27ea1c52ce1ee984da05bdb618590bd0be",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16229": {
    "title": "Learning Local Neighboring Structure for Robust 3D Shape Representation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "153d5f337920b214389f87aa53492e93fbd7e270",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16230": {
    "title": "Semantic-guided Reinforced Region Embedding for Generalized Zero-Shot Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1ae803c0134baa69987510eebc6afcec239fa2f6",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16231": {
    "title": "Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a2227c1d2e42776af62d732c7fc8370196c72e3f",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16232": {
    "title": "Boundary-Aware Geometric Encoding for Semantic Segmentation of Point Clouds",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3f4b0c80346cfb2a8ae224ff2beda943eb00d0e4",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16233": {
    "title": "Analogical Image Translation for Fog Generation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dc15dca53e34be8dabb3cd7690612faf3e7dde5a",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16234": {
    "title": "Temporal ROI Align for Video Object Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a9d7664078f7192e3a88e71cf13cc36ed65d2e8c",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16235": {
    "title": "SMART Frame Selection for Action Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7c062be0a5ba96b5d0cd606d2eeacd768845a116",
    "citation_count": 44
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16236": {
    "title": "Proxy Synthesis: Learning with Synthetic Classes for Deep Metric Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "62d0b58d27864b030876006037206d59af85946c",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16237": {
    "title": "Interpretable Graph Capsule Networks for Object Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "090ad3927063d2c318e4ce5a344aa253a17746de",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16238": {
    "title": "Class-Incremental Instance Segmentation via Multi-Teacher Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a747a073e580f3db7b164ef1cbb8dab1c949a445",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16239": {
    "title": "EfficientDeRain: Learning Pixel-wise Dilation Filtering for High-Efficiency Single-Image Deraining",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2fe2871e3e21a7ea79a2efa19d9b596749a8c0c5",
    "citation_count": 29
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16240": {
    "title": "Order Regularization on Ordinal Loss for Head Pose, Age and Gaze Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e0ed1b7b7ee65f5891d01e8360743a2fa8a0c2ec",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16241": {
    "title": "Decoupled and Memory-Reinforced Networks: Towards Effective Feature Learning for One-Step Person Search",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "77ce3eea92b13de5f5de0a06b8807b9a402a75fb",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16242": {
    "title": "Spherical Image Generation from a Single Image by Considering Scene Symmetry",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d8ae38800ffbc424a350e7e37a40a9a6384a7fc0",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16243": {
    "title": "Progressive One-shot Human Parsing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3b51a1c4c270651a09c3688e6f7aa4c2f6b01598",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16244": {
    "title": "Consistent-Separable Feature Representation for Semantic Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0aff94ad1c6c8581a62e24085dec00193960d809",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16245": {
    "title": "Error-Aware Density Isomorphism Reconstruction for Unsupervised Cross-Domain Crowd Counting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cf856bc7f6a432f96ab643f76c529ea4a8f387c5",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16246": {
    "title": "DropLoss for Long-Tail Instance Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fee65304d2401d2c4bee5b846b7a9c055843a840",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16247": {
    "title": "Hand-Model-Aware Sign Language Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "832298578168aacc3fb1433296a63dbfa849ee4e",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16248": {
    "title": "Stratified Rule-Aware Network for Abstract Visual Reasoning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a3e9620223f8b00f8950a8d945142b80d401e950",
    "citation_count": 27
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16249": {
    "title": "VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7ba268c6d5489dd3b3c08e3642f1385c6235118e",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16250": {
    "title": "Exploiting Relationship for Complex-scene Image Generation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6a5225f5727eb816a39dd7bcdb69caf69b435cdb",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16251": {
    "title": "Modeling Deep Learning Based Privacy Attacks on Physical Mail",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3660f26001ff7ed6d2643b6ebbb2a18aa09bbd8a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16252": {
    "title": "PTN: A Poisson Transfer Network for Semi-supervised Few-shot Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "35a5fd61a69ee5ad3bc25ed80666ab3038bf3b1c",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16253": {
    "title": "Text-Guided Graph Neural Networks for Referring 3D Instance Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5f1913828e30c3070f32c154d2d142ec17e91189",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16254": {
    "title": "Initiative Defense against Facial Manipulation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d71e911dc4baa1168f1c3cb3953cb48987311f1b",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16255": {
    "title": "SnapMix: Semantically Proportional Mixing for Augmenting Fine-grained Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c3379bbe58886d8d66c0be777fc7416415617435",
    "citation_count": 36
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16256": {
    "title": "A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "34d67dd7fecbb965143bc59ef8a2806eeed5bfe1",
    "citation_count": 39
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16257": {
    "title": "Context-Aware Graph Convolution Network for Target Re-identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "423d5effcbd0aac7b047b52a34385bfd4ebd915d",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16258": {
    "title": "Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7217b5d8d0fb753532026cc36b0aaa056960c6f8",
    "citation_count": 65
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16259": {
    "title": "Frequency Consistent Adaptation for Real World Super Resolution",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f3c954bdeae18ca362b9642965f51757e4d37aba",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16260": {
    "title": "Matching on Sets: Conquer Occluded Person Re-identification Without Alignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ac864febb60668e5740cc6c18c169fb82f7d3245",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16261": {
    "title": "GradingNet: Towards Providing Reliable Supervisions for Weakly Supervised Object Detection by Grading the Box Candidates",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "158bd3ff67a0f0c69dd55b2bc1e9331094c6ec2e",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16262": {
    "title": "SSN3D: Self-Separated Network to Align Parts for 3D Convolution in Video Person Re-Identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "319632a336de42b4c9e1fe3d9e08bcd4fd0c3e5f",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16263": {
    "title": "Training Binary Neural Network without Batch Normalization for Image Super-Resolution",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c53f797ff376b4bfc78cbf60d60d4f2733143dba",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16264": {
    "title": "What to Select: Pursuing Consistent Motion Segmentation from Multiple Geometric Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "845a0d220e6c17ab7d6af6cfe7fd22e2206ce59c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16265": {
    "title": "Asynchronous Teacher Guided Bit-wise Hard Mining for Online Hashing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "944d8ddc77ca215eb23830acf119d5f79917da39",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16266": {
    "title": "Deep Low-Contrast Image Enhancement using Structure Tensor Representation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "683686c755981313661f42adfe88bf6414737bb1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16267": {
    "title": "Spectral Distribution Aware Image Generation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5e8d57a7a7dafb4e5c82eecc798a0b557478500a",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16268": {
    "title": "StarNet: towards Weakly Supervised Few-Shot Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3e71a292d79a2d9033e25453197512aa5621fed6",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16269": {
    "title": "Discriminative Region Suppression for Weakly-Supervised Semantic Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8cb57f85d52f956f7ed820b0eea925110d5ed3d8",
    "citation_count": 37
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16270": {
    "title": "Visual Comfort Aware-Reinforcement Learning for Depth Adjustment of Stereoscopic 3D Images",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "959c45ad2f1a24befb0013b7003417a5faf83392",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16271": {
    "title": "Dual Compositional Learning in Interactive Image Retrieval",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6361a6f8fc2e025907fd1f6a7c9f7171fa2a10aa",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16272": {
    "title": "End-to-End Differentiable Learning to HDR Image Synthesis for Multi-exposure Images",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "70216e8cd6312bfcae3f3639308acf520bcf1492",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16273": {
    "title": "Structured Co-reference Graph Attention for Video-grounded Dialogue",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6c20360aa184c3453be59c13e677873509b96669",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16274": {
    "title": "Cross-Domain Grouping and Alignment for Domain Adaptive Semantic Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b636fb60037af31a1a67e9353e13332771515425",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16275": {
    "title": "Bidirectional RNN-based Few Shot Learning for 3D Medical Image Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "149018b4faf1aa1f3250b6821a51cc1a9c2c7a53",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16276": {
    "title": "DASZL: Dynamic Action Signatures for Zero-shot Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "707b023e6c25ed283f23625bec514da480fb90da",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16277": {
    "title": "Multi-level Distance Regularization for Deep Metric Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a9d5fd03086cad1196277b1c2507a234db536aba",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16278": {
    "title": "Dynamic to Static Lidar Scan Reconstruction Using Adversarially Trained Auto Encoder",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "da3f33c6cc4a1e15c6762ff90fe68a87965b92b2",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16279": {
    "title": "Regularizing Attention Networks for Anomaly Detection in Visual Question Answering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "21f7833c38db29012e082b4ce20bdaa1f9c0e59f",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16280": {
    "title": "Weakly-supervised Temporal Action Localization by Uncertainty Modeling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "73377c17f413d712a96210fe875987b57a2965d1",
    "citation_count": 40
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16281": {
    "title": "Learning Monocular Depth in Dynamic Scenes via Instance-Aware Projection Consistency",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c7132e0a96b018bc5a8e769feca5286f053621c1",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16282": {
    "title": "Patch-Wise Attention Network for Monocular Depth Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "21fde3a3fab044a9b3568c71480764ad93ed1ff1",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16283": {
    "title": "Semi-Supervised Learning for Multi-Task Scene Understanding by Neural Graph Consensus",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7137189bb80146154b86079c6b4f389d28724983",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16284": {
    "title": "Static-Dynamic Interaction Networks for Offline Signature Verification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d0818aaf90c71c7306b1b7c35cf8521b4dd5c215",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16285": {
    "title": "Proposal-Free Video Grounding with Contextual Pyramid Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7cb2a218f37c8fcfa91915cfdbba8ed22ef52d12",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16286": {
    "title": "Write-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d2d605d9c35ecb90c8cab3cad444e6f74f7ce27",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16287": {
    "title": "Exploiting Learnable Joint Groups for Hand Pose Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d2273109e1d58488092651f060acd1b52a7ba431",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16288": {
    "title": "RTS3D: Real-time Stereo 3D Detection from 4D Feature-Consistency Embedding Space for Autonomous Driving",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "35cffc5bc9f26f0760fdf268151b48d21ab2ae78",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16289": {
    "title": "Adversarial Pose Regression Network for Pose-Invariant Face Recognitions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7cd304afc74f6b8d7b1bf4eac57b395426fbe1d2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16290": {
    "title": "Category Dictionary Guided Unsupervised Domain Adaptation for Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5e412cedaa116ed4d1965dc4815ca56969be1be7",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16291": {
    "title": "Joint Semantic-geometric Learning for Polygonal Building Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "40759bee7b649ad871e2598fd12846b749680e01",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16292": {
    "title": "Generalized Zero-Shot Learning via Disentangled Representation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "998a949aed017140074c50209dbd583205e99d7b",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16293": {
    "title": "Learning Omni-Frequency Region-adaptive Representations for Real Image Super-Resolution",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "36fac56c02597f9ea7c9c05419fd7a7109de1056",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16294": {
    "title": "Group-Wise Semantic Mining for Weakly Supervised Semantic Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "811bd1dcacf2dcb3d615daa169a07e0c872fe5a7",
    "citation_count": 51
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16295": {
    "title": "Inference Fusion with Associative Semantics for Unseen Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "99dc5800efc4d41666ef75f4c1eaf41f0097591f",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16296": {
    "title": "Deep Unsupervised Image Hashing by Maximizing Bit Entropy",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "48f33710063f1cdf74abe298245e4cd3834800c9",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16297": {
    "title": "Sequential End-to-end Network for Efficient Person Search",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b4e86385285941ccba5ef0f9a15bfb5001b883f8",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16298": {
    "title": "SD-Pose: Semantic Decomposition for Cross-Domain 6D Object Pose Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "52387d585d5cd97963f460741fdfa719ff078dc2",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16299": {
    "title": "Temporal Pyramid Network for Pedestrian Trajectory Prediction with Multi-Supervision",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6c240231b06495b8386db604b3db685dd467d502",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16300": {
    "title": "Query-Memory Re-Aggregation for Weakly-supervised Video Object Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9a2687319ed3279f579ece9e49b019ef626b3dc3",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16301": {
    "title": "Augmented Partial Mutual Learning with Frame Masking for Video Captioning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "108076978ed3990ee90cb7b30aa572ca0f9c2518",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16302": {
    "title": "Exploiting Audio-Visual Consistency with Partial Supervision for Spatial Audio Generation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0bcab67058596c6ca5dc5d691c9e1004457063e3",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16303": {
    "title": "Single View Point Cloud Generation via Unified 3D Prototype",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6b5e2a64632fefab1260751561134112786ca366",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16304": {
    "title": "Self-Supervised Sketch-to-Image Synthesis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e5956dc1c3e93a37d80aeb908b8a7e76c2185856",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16305": {
    "title": "TIME: Text and Image Mutual-Translation Adversarial Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "343178bf426aacc051a8ea547c4189579635ab09",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16306": {
    "title": "SA-BNN: State-Aware Binary Neural Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cbc644f26710b7b2cd96200878ca1c469daf1997",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16307": {
    "title": "Spatiotemporal Graph Neural Network based Mask Reconstruction for Video Object Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5ec6620a09b1f573fc5351d4d4fe2d5e07ef7f47",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16308": {
    "title": "F2Net: Learning to Focus on the Foreground for Unsupervised Video Object Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "69107a71c9533e204790890591a72fda88d4669a",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16309": {
    "title": "Toward Realistic Virtual Try-on Through Landmark Guided Shape Matching",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "732d67e7b59aee6ce74fd54d0d1800b8afab32aa",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16310": {
    "title": "Large Motion Video Super-Resolution with Dual Subnet and Multi-Stage Communicated Upsampling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7fe680686ee6ee17de447c7c1dee52ab45e66f7d",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16311": {
    "title": "FCFR-Net: Feature Fusion based Coarse-to-Fine Residual Learning for Depth Completion",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1faac3a89e09a75dfdeb27210db7d55128d4119d",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16312": {
    "title": "Activity Image-to-Video Retrieval by Disentangling Appearance and Motion",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "945deb4324ffe267a5093fcc5ed6dec5277cbb65",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16313": {
    "title": "Adaptive Pattern-Parameter Matching for Robust Pedestrian Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "60fe98d9684b347749124e90fd4b5047a80913df",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16314": {
    "title": "Temporal Segmentation of Fine-gained Semantic Action: A Motion-Centered Figure Skating Dataset",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ec1a6acf2615fd931f7f148457f04dcc53201425",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16315": {
    "title": "Learning Hybrid Relationships for Person Re-identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fe4de83dee3a43440a61da488df4d1a8b58e4674",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16316": {
    "title": "Translate the Facial Regions You Like Using Self-Adaptive Region Translation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f1aebad17f7c82e9d055ad438e58d42a0cd84cfe",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16317": {
    "title": "Subtype-aware Unsupervised Domain Adaptation for Medical Diagnosis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3c354b347db3e74f7d7dfd4c8fc5183e3d56b0c7",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16318": {
    "title": "FontRL: Chinese Font Synthesis via Deep Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "63b7201a062de0f0c870db614e4a599f41bf145a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16319": {
    "title": "Hierarchical Information Passing Based Noise-Tolerant Hybrid Learning for Semi-Supervised Human Parsing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "064d4bc44019cfc843ef4575e726a497d7a63587",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16320": {
    "title": "Delving into Variance Transmission and Normalization: Shift of Average Gradient Makes the Network Collapse",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7c5e9932d1fba74668be0365755f441e525ef5c3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16321": {
    "title": "Aggregated Multi-GANs for Controlled 3D Human Motion Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d4b3d71fcbdebbf0e2c759a2566b4fe1129ed2a9",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16322": {
    "title": "ACSNet: Action-Context Separation Network for Weakly Supervised Temporal Action Localization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a56089a2b1d9f2ad942dd5ce841d204322bd16dd",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16323": {
    "title": "Weakly Supervised Temporal Action Localization Through Learning Explicit Subspaces for Action and Context",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7f0971db4836c49788a440ca7e1fd96f630cc807",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16324": {
    "title": "PointINet: Point Cloud Frame Interpolation Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b7e6377d5d5d42c8b06a197465a281624dca8a4d",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16325": {
    "title": "A Global Occlusion-Aware Approach to Self-Supervised Monocular Visual Odometry",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f112e0d301e2481e0ae743bd0b18b4afd7351d5d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16326": {
    "title": "PC-HMR: Pose Calibration for 3D Human Mesh Recovery from 2D Images/Videos",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "788bf5e5ac68aafe77564473869a0740280ae813",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16327": {
    "title": "DeepDT: Learning Geometry From Delaunay Triangulation for Surface Reconstruction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "26a22bded2e64a2e95613a744a9f5ad12b082e1e",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16328": {
    "title": "Dual-level Collaborative Transformer for Image Captioning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ae7e5a4de962ca4face3bb52b36dfd09db5451d8",
    "citation_count": 66
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16329": {
    "title": "HR-Depth: High Resolution Self-Supervised Monocular Depth Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1c7a149cbddff67b48a6c045692fd194b404d4e8",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16330": {
    "title": "SMIL: Multimodal Learning with Severely Missing Modality",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "31d20462d35059502ffeb13e1afbba11a81c7d41",
    "citation_count": 36
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16331": {
    "title": "Pyramidal Feature Shrinking for Salient Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f6597669ffea6f47234af09ecbc6adea7e0e9a4f",
    "citation_count": 34
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16332": {
    "title": "Learning to Count via Unbalanced Optimal Transport",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2b95361a59c894721262db66a356decc86f1ef1c",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16333": {
    "title": "Scene Graph Embeddings Using Relative Similarity Supervision",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3bb090a44596d6396f88d6d31e46105b7f642613",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16334": {
    "title": "Few-Shot Lifelong Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "013ea7e067477ab79c7afb381a0e56a42c417d6b",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16335": {
    "title": "CARPe Posterum: A Convolutional Approach for Real-Time Pedestrian Path Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "01391b4133b722843b45e8634c1b2b5f2f0126d7",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16336": {
    "title": "Dynamic Anchor Learning for Arbitrary-Oriented Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5cc2198ddbbec84f04019b1fd3f02798673dbb91",
    "citation_count": 80
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16337": {
    "title": "Terrace-based Food Counting and Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0c7058fae2176b23e1d3a3cdd852cc3464e4deee",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16338": {
    "title": "Embodied Visual Active Learning for Semantic Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f6c397dc04c3e30ed2d6dc8299884db50d70f0b6",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16339": {
    "title": "TDAF: Top-Down Attention Framework for Vision Tasks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "965571810fcb79fdaaed7329ff57b3720508a241",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16340": {
    "title": "Few-shot Font Generation with Localized Style Representations and Factorization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c1308be7b8f20d62bd1ae896f34c0db5c8285bdd",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16341": {
    "title": "Learning Disentangled Representation for Fair Facial Attribute Classification via Fairness-aware Information Alignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9d02d4d5f4dc33928dc21eae402e5200d1cb2e75",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16342": {
    "title": "Vid-ODE: Continuous-Time Video Generation with Neural Ordinary Differential Equation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "58db26d7064d16bd45d2fda6b5ded997f47278e5",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16343": {
    "title": "CHEF: Cross-modal Hierarchical Embeddings for Food Domain Retrieval",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "582ff0395d97f3e90003811346c940559cec9a51",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16344": {
    "title": "Explainable Models with Consistent Interpretations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "13e5c87d143940a40ffcfa750470711c810e7d59",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16345": {
    "title": "Dual Adversarial Graph Neural Networks for Multi-label Cross-modal Retrieval",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e7b04687dc41ea7b2b603a0a6149dc258321301a",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16346": {
    "title": "KGDet: Keypoint-Guided Fashion Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7b12fa153ebcd81e0cd0f8ba2f160da7397ebc30",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16347": {
    "title": "Learning Modulated Loss for Rotated Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7322a4580299b322223730ca714a0a951788853a",
    "citation_count": 114
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16348": {
    "title": "MANGO: A Mask Attention Guided One-Stage Scene Text Spotter",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e6053e9db1f1c43fa2e075b94164faa99670ad77",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16349": {
    "title": "REFINE: Prediction Fusion Network for Panoptic Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "78a79a7cb5f4d39f7a87980ed7c41c5cd7d990cc",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16350": {
    "title": "AutoLR: Layer-wise Pruning and Auto-tuning of Learning Rates in Fine-tuning of Deep Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c65aa75a17eddf50171f048670319082a1780fe8",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16351": {
    "title": "DPFPS: Dynamic and Progressive Filter Pruning for Compressing Convolutional Neural Networks from Scratch",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e820cc6fa49c094da79c28ff2107854fe235bf5f",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16352": {
    "title": "Efficient Certification of Spatial Robustness",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0892b242f64779c95eb7dec11c603555573b45c3",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16353": {
    "title": "Semantic Grouping Network for Video Captioning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f65f7e7273b1496a191e016318600ba8678b50a1",
    "citation_count": 35
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16354": {
    "title": "Audio-Visual Localization by Synthetic Acoustic Image Generation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e0733d590469f08e0568eee05509e6efbe5d9437",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16355": {
    "title": "Enhanced Regularizers for Attributional Robustness",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3cf4e173598f38b22882d22b99f880ecb26b0c0e",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16356": {
    "title": "Progressive Network Grafting for Few-Shot Knowledge Distillation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "883ea3b74ec1e26ad20f2c5c94f45e0d6db16364",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16357": {
    "title": "Social-DPF: Socially Acceptable Distribution Prediction of Futures",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d2c8117a6843fb8a628067c4d15d85f8a8ec4245",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16358": {
    "title": "Robust Knowledge Transfer via Hybrid Forward on the Teacher-Student Model",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e67acfc16e7adca719d568a14a3d8f6f14d8a25f",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16359": {
    "title": "AttaNet: Attention-Augmented Network for Fast and Accurate Scene Parsing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "79e25185f3b03aba9e12cb70c50e79c5da5c1479",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16360": {
    "title": "To Choose or to Fuse? Scale Selection for Crowd Counting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b5b51d24a7b6ebb71b003f6b64ceb54d8fdf38ee",
    "citation_count": 44
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16361": {
    "title": "Image Captioning with Context-Aware Auxiliary Guidance",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4ce5fd3eaea0422c2971111e4d7fe941b64a3c39",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16362": {
    "title": "Unsupervised Model Adaptation for Continual Semantic Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2ba1e62fe525da2b5450a3f7811c320950e9f1ba",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16363": {
    "title": "BSN++: Complementary Boundary Regressor with Scale-Balanced Relation Modeling for Temporal Action Proposal Generation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1ea2373840d4a5079ecb0132fc47ed37e423bd96",
    "citation_count": 60
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16364": {
    "title": "MangaGAN: Unpaired Photo-to-Manga Translation Based on The Methodology of Manga Drawing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "55f45f009bdf4f8ec0bbf5c1c0da6db0e39508da",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16365": {
    "title": "MAMBA: Multi-level Aggregation via Memory Bank for Video Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "51aac90aab8afb43e8ff20ffe5e6887daad238fa",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16366": {
    "title": "Deep Probabilistic Imaging: Uncertainty Quantification and Multi-modal Solution Characterization for Computational Imaging",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0260c69e347ad2f47f65d43916425933bbde6b69",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16367": {
    "title": "Domain General Face Forgery Detection by Learning to Weight",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a4a9e86d06ca2eb6d2e6b17c9948e0e0cbd38815",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16368": {
    "title": "Object-Centric Image Generation from Layouts",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "198333f1f426224de2f36a3ee2aa48e54cf4ba3e",
    "citation_count": 34
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16369": {
    "title": "Structure-aware Person Image Generation with Pose Decomposition and Semantic Correlation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c764790e6d8ea7c475ecb57f0f8b6f81a34b792b",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16370": {
    "title": "Gradient Regularized Contrastive Learning for Continual Domain Adaptation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "35f9a09a53d1a5c8b006eb86ea5000f890023143",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16371": {
    "title": "Adversarial Training Reduces Information and Improves Transferability",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "08e82ca7906efae2e6bf4b9523c38972e509f96a",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16372": {
    "title": "Adversarial Turing Patterns from Cellular Automata",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c058af5fcc4935ea78bd557c7fa7876785cc8004",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16373": {
    "title": "Artificial Dummies for Urban Dataset Augmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3ff24d04b7964b60dab1f7f8db59ab29f556b34d",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16374": {
    "title": "SCNet: Training Inference Sample Consistency for Instance Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3fd1263f5c4dc00e6efc7253b55a4244ac350172",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16375": {
    "title": "Task-Independent Knowledge Makes for Transferable Representations for Generalized Zero-Shot Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "08db45d0e427cdde77cc16307a4d13bcb1cd3d55",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16376": {
    "title": "Efficient Object-Level Visual Context Modeling for Multimodal Machine Translation: Masking Irrelevant Objects Helps Grounding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "db5393275c4be3378cb669ae59014fe8c5c92859",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16377": {
    "title": "Temporal Relational Modeling with Self-Supervision for Action Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b20ccb5e53bcc5e76d05d173149d3926bec952fd",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16378": {
    "title": "Towards Robust Visual Information Extraction in Real World: New Dataset and Novel Solution",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "43c3ccb02ed34b6f38872bc7d75a85d812ac2746",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16379": {
    "title": "Self-Domain Adaptation for Face Anti-Spoofing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "454b0859346115812730ab2c6a770765b133521c",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16380": {
    "title": "Weakly Supervised Deep Hyperspherical Quantization for Image Retrieval",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "00e332ec098862c764072b5e934bd729858160db",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16381": {
    "title": "Camera-Aware Proxies for Unsupervised Person Re-Identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "155746c016f83aa9fbd5c75828f547f8cbb804e0",
    "citation_count": 46
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16382": {
    "title": "Unsupervised 3D Learning for Shape Analysis via Multiresolution Instance Discrimination",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b91c9c9beeaa0760e383fe702e6df10c51eb0a4c",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16383": {
    "title": "PGNet: Real-time Arbitrarily-Shaped Text Spotting with Point Gathering Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0ad0205d39af43cbf1cd560152d0f34ef85d56e6",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16384": {
    "title": "Dynamic Position-aware Network for Fine-grained Image Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cf0723eab4c75e5b6bdfeca38aa80e76531aaa1b",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16385": {
    "title": "Co-mining: Self-Supervised Learning for Sparsely Annotated Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eaeaae0a559d0bf48f9a785f856c9ec7138a3eea",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16386": {
    "title": "Very Important Person Localization in Unconstrained Conditions: A New Benchmark",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d7fae2c94cf2f9b7601b350db8a0f80b93422a9a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16387": {
    "title": "Teacher Guided Neural Architecture Search for Face Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6591929294e26b330676a7cde4bdfccdd7dd3b84",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16388": {
    "title": "Deep Multi-Task Learning for Diabetic Retinopathy Grading in Fundus Images",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "22d07522a1ece6d81d34d08abfab73d1962ff081",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16389": {
    "title": "Confidence-aware Non-repetitive Multimodal Transformers for TextCaps",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4231637c09d5fa8864cdf85256ed45bff0656eec",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16390": {
    "title": "Geodesic-HOF: 3D Reconstruction Without Cutting Corners",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e7f5a2793ff1eb1581fad2c6b1b28c7cc57bec1a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16391": {
    "title": "C2F-FWN: Coarse-to-Fine Flow Warping Network for Spatial-Temporal Consistent Motion Transfer",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6f00163263f974b9d38b5bd399b1ed15d085cecd",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16392": {
    "title": "Semantic Consistency Networks for 3D Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7685d32091f5620b059995fcf446b259361e0ee5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16393": {
    "title": "Holistic Multi-View Building Analysis in the Wild with Projection Pooling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8b7bd1173b5796bdb3f96b32c715aa2633fe05e8",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16394": {
    "title": "Stereopagnosia: Fooling Stereo Networks with Adversarial Perturbations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "090e227b01a96340e683a6f661f64c7eb93c3741",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16395": {
    "title": "Generalising without Forgetting for Lifelong Person Re-Identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "24d3f71ff6dea01acd60280a17fc69371bdf4943",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16396": {
    "title": "Decentralised Learning from Independent Multi-Domain Labels for Person Re-Identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "193a816d4eeacd0935df5614ad36a066b5462fd0",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16397": {
    "title": "Region-aware Global Context Modeling for Automatic Nerve Segmentation from Ultrasound Images",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "581cf8bfef6e60685f8326957e783f5e1203c70c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16398": {
    "title": "Precise Yet Efficient Semantic Calibration and Refinement in ConvNets for Real-time Polyp Segmentation from Colonoscopy Videos",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7ca83bac3e9836d4088101e53bfceddfdeadd7ff",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16399": {
    "title": "Graph-to-Graph: Towards Accurate and Interpretable Online Handwritten Mathematical Expression Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "33db82502829eb176a6fed2d819a9ed8d2bb4c88",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16400": {
    "title": "Learning Comprehensive Motion Representation for Action Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e7421b46ff5f0f0b029aef2ad73a1ded6ae313dc",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16401": {
    "title": "MVFNet: Multi-View Fusion Network for Efficient Video Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "07e0fd1487b8b31d6641c66f67f20e4659e5848e",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16402": {
    "title": "Anticipating Future Relations via Graph Growing for Action Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f84e81b3e9b979c1f2da330b101f1aebf23d577f",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16403": {
    "title": "Binaural Audio-Visual Localization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "21f36fa303fd70278ff038dc5bbcf2a96c5f018a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16404": {
    "title": "Beating Attackers At Their Own Games: Adversarial Example Detection Using Adversarial Gradient Directions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "df326f0b6d109282f41bc5cc1fbd125437b65341",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16405": {
    "title": "Shape-Pose Ambiguity in Learning 3D Reconstruction from Images",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3f6785d00979183866c2ac76b69c971b165eb6e6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16406": {
    "title": "Boundary Proposal Network for Two-stage Natural Language Video Localization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "72bf41fe2eb7ef7bcf70246816f6f2b54fe5f1bf",
    "citation_count": 56
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16407": {
    "title": "Amodal Segmentation Based on Visible Region Segmentation and Shape Prior",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "447d4008dc08b30a2731d898bfdbc8000c7f5b4a",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16408": {
    "title": "Locate Globally, Segment Locally: A Progressive Architecture With Knowledge Review Network for Salient Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8284d4a279b5c5107c9c5e1f0580fbff3f7b75da",
    "citation_count": 38
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16409": {
    "title": "Invariant Teacher and Equivariant Student for Unsupervised 3D Human Pose Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "feeca807fc480d7175d16427531b64ea007b7672",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16410": {
    "title": "Imagine, Reason and Write: Visual Storytelling with Graph Knowledge and Relational Reasoning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e560bdec8479c1ca4570a4233ec66bf759a0c6ad",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16411": {
    "title": "Self-supervised Multi-view Stereo via Effective Co-Segmentation and Data-Augmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9da0ab9744700e31eef504403ad872cb99ec4fd0",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16412": {
    "title": "Efficient Deep Image Denoising via Class Specific Convolution",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "774640468f3fbbab1891cc02b74166670750e77b",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16413": {
    "title": "Investigate Indistinguishable Points in Semantic Segmentation of 3D Point Cloud",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "251ee18f5d5ff4847b5c9a823b14aca09ddf4e94",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16414": {
    "title": "Learning Geometry-Disentangled Representation for Complementary Understanding of 3D Object Point Cloud",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8eeebb2f74a2a12251442942b619b2846ed5796c",
    "citation_count": 39
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16415": {
    "title": "Searching for Alignment in Face Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "737c1371415c2ea07e9ba63d498e6e68650094a2",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16416": {
    "title": "GIF Thumbnails: Attract More Clicks to Your Videos",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d5e4ffa9b18d50e60dc081232c50c54f7ca79c1c",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16417": {
    "title": "FaceController: Controllable Attribute Editing for Face in the Wild",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "92d6ad1611df532581a6db1467cc4e78ab290555",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16418": {
    "title": "AnchorFace: An Anchor-based Facial Landmark Detector Across Large Poses",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "074e1c09266ce3bafe92e2cc1d5ab22199598850",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16419": {
    "title": "Sparse Single Sweep LiDAR Point Cloud Segmentation via Learning Contextual Shape Priors from Scene Completion",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "601ad774f6305f8a78e878665b3623f2239687c5",
    "citation_count": 48
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16420": {
    "title": "Learning Semantic Context from Normal Samples for Unsupervised Anomaly Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8ee35ed698527d9695c872e3b76715fec4ef69ad",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16421": {
    "title": "Non-Autoregressive Coarse-to-Fine Video Captioning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7b15217075d63714c421ae8d53197d6e62d4d25a",
    "citation_count": 32
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16422": {
    "title": "Learning to Attack Real-World Models for Person Re-identification via Virtual-Guided Meta-Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ce8c00ee14b568ec7752f6d4dd18185972f35cf5",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16423": {
    "title": "Object Relation Attention for Image Paragraph Captioning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eed6293e9d99332dae29dac714ea38eec354311b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16424": {
    "title": "Adversarial Robustness through Disentangled Representations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d57359008ef77c0521bd783a8aa1643a7296c09",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16425": {
    "title": "CPCGAN: A Controllable 3D Point Cloud Generative Adversarial Network with Semantic Label Generating",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e12365294cf79c86b1ad262834b5427903caf691",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16426": {
    "title": "R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "edada2363969e3929366df06aad8a8e9c73ba32f",
    "citation_count": 279
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16427": {
    "title": "One-shot Face Reenactment Using Appearance Adaptive Normalization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8de43d288f4eb44cefe6f37642be1cfc1e902bea",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16428": {
    "title": "A Case Study of the Shortcut Effects in Visual Commonsense Reasoning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7631808b179c2c03030d528ddd1b76356a6a71e9",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16429": {
    "title": "Instance Mining with Class Feature Banks for Weakly Supervised Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "77e44853177cbcaa1c5cb4dddc7eef22841e27fa",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16430": {
    "title": "Multimodal Fusion via Teacher-Student Network for Indoor Action Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1eb3f0c05dd4588cff9a3d4e6a0a58dca39c2e9f",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16431": {
    "title": "ERNIE-ViL: Knowledge Enhanced Vision-Language Representations through Scene Graphs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bc996a4dbf9d4234eacdd0b930a94de1d158e256",
    "citation_count": 194
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16432": {
    "title": "High-Resolution Deep Image Matting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "355a59e2957d11966bebad76cf9a7ca992545337",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16433": {
    "title": "CAKES: Channel-wise Automatic KErnel Shrinking for Efficient 3D Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "08f985bdde257b0814a93af7d3254023e8d2d067",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16434": {
    "title": "Structure-Consistent Weakly Supervised Salient Object Detection with Local Saliency Coherence",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "acafdcd4f53581aa00bf97d15d8ee65a3eb8a591",
    "citation_count": 40
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16435": {
    "title": "Fast and Compact Bilinear Pooling by Shifted Random Maclaurin",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eb9294da10ec2dccde30dc132fa114994270162e",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16436": {
    "title": "Simple and Effective Stochastic Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9b5f1ce51f070595f429e02bdb3fd6960ef659d8",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16437": {
    "title": "Learning Visual Context for Group Activity Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c72a98400c4d6ac2a26e0dd6506f4e9c4224039f",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16438": {
    "title": "StrokeGAN: Reducing Mode Collapse in Chinese Font Generation via Stroke Encoding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b98caf7802c9136f1fcb4094519d2cddddf845c8",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16439": {
    "title": "Demodalizing Face Recognition with Synthetic Samples",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5a03dd7a5ed0e3708cc2c322ae90fb6f29c9cc5d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16440": {
    "title": "EMLight: Lighting Estimation via Spherical Distribution Approximation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9e4e4c56554f5e8e6c43c0475fb72a03f5f2844a",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16441": {
    "title": "Universal Adversarial Perturbations Through the Lens of Deep Steganography: Towards a Fourier Perspective",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4a6b02946fb7311b6bcd512d3c5fef9c082cbb60",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16442": {
    "title": "SPIN: Structure-Preserving Inner Offset Network for Scene Text Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "da76b33644ffa59dd5534830837cc8c1317d7bca",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16443": {
    "title": "Visual Tracking via Hierarchical Deep Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "81d8eb42b13b921ea9fd714c25734c9dc2fe93e2",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16444": {
    "title": "One for More: Selecting Generalizable Samples for Generalizable ReID Model",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d3af32e0c614e7d141997c900fd3e7f9dc147eed",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16445": {
    "title": "Ada-Segment: Automated Multi-loss Adaptation for Panoptic Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8f00eeb1df72e286eaea0ebb3e1b342b763a70dd",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16446": {
    "title": "SIMPLE: SIngle-network with Mimicking and Point Learning for Bottom-up Human Pose Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5ef4c790ac131150a8f6fbff06305ab079101c16",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16447": {
    "title": "Enhancing Audio-Visual Association with Self-Supervised Curriculum Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "261c03a9c904da9cecc48ab07b9859c35cf6aef1",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16448": {
    "title": "Unsupervised Domain Adaptation for Person Re-identification via Heterogeneous Graph Alignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "647e5882a0c66783bbabaee47d191478ad2f08ab",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16449": {
    "title": "Proactive Privacy-preserving Learning for Retrieval",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "29dc41ef9225d4c88e18b831b9ee1f6edda903fd",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16450": {
    "title": "A Novel Visual Interpretability for Deep Neural Networks by Optimizing Activation Maps with Perturbation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3300be8d4191f98b792a02847ca9876cb436a30c",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16451": {
    "title": "Point Cloud Semantic Scene Completion from RGB-D Images",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e9f5fb065ac85696101bd1c87977b406f9bf47aa",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16452": {
    "title": "Consensus Graph Representation Learning for Better Grounded Image Captioning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7d1d75e7830a34642508763e3b538a701ee11958",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16453": {
    "title": "BoW Pooling: A Plug-and-Play Unit for Feature Aggregation of Point Clouds",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "62b2a7956015d89ddf713301eab111e88a31fbdc",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16454": {
    "title": "Diverse Knowledge Distillation for End-to-End Person Search",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f46d48e2afc0ec4c397db66557e80f42e765809a",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16455": {
    "title": "Weakly Supervised Semantic Segmentation for Large-Scale Point Cloud",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cbc760cb2ca8fb3d097bd6166c3820e58ca1a607",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16456": {
    "title": "PC-RGNN: Point Cloud Completion and Graph Neural Network for 3D Object Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6452b177ec8c832e388d1dbd60cc4c17b3e007b7",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16457": {
    "title": "Efficient License Plate Recognition via Holistic Position Attention",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "66c37f7cf1461cd44dcc75d0271da0cb9ac6d3bb",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16458": {
    "title": "Bag of Tricks for Long-Tailed Visual Recognition with Deep Convolutional Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "36df3b2ce26ebd8460bc1dfd55245efc6a514973",
    "citation_count": 37
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16459": {
    "title": "Depth Privileged Object Detection in Indoor Scenes via Deformation Hallucination",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ca9132b955812b2cdc6ab74d1458fcd78c8b4d4f",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16460": {
    "title": "Learning Flexibly Distributional Representation for Low-quality 3D Face Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f34816978c5560250e5f3d6531f7d429bc670b24",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16461": {
    "title": "IA-GM: A Deep Bidirectional Learning Method for Graph Matching",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ca64fd7bafca59d35bfd001f04efd46b9fb79748",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16462": {
    "title": "Distribution Adaptive INT8 Quantization for Training CNNs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7240d82352e1eea633edc925c0903a72920e642b",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16463": {
    "title": "Context-Guided Adaptive Network for Efficient Human Pose Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d68f4e2c382f33552c620c2b6ac065fc4dfad09e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16464": {
    "title": "ePointDA: An End-to-End Simulation-to-Real Domain Adaptation Framework for LiDAR Point Cloud Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "83da7e0bb2adb4a7d7b2d132ffda857e0bbd3841",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16465": {
    "title": "Robust Lightweight Facial Expression Recognition Network with Label Distribution Training",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fc4f0a2d0a18cb9dba465b1e0e9b14a9b5dee2f9",
    "citation_count": 41
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16466": {
    "title": "Joint Color-irrelevant Consistency Learning and Identity-aware Modality Adaptation for Visible-infrared Cross Modality Person Re-identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bc50aa3af1f42a353b3205d5d88f501efafa1f26",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16467": {
    "title": "Robust Multi-Modality Person Re-identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1d382a6ff6f156852375c059381dcd48081bf0f3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16468": {
    "title": "Exploiting Sample Uncertainty for Domain Adaptive Person Re-Identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d477e72f93d8b895fd0ccc38f2a1cc04bf96e3f1",
    "citation_count": 59
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16469": {
    "title": "RESA: Recurrent Feature-Shift Aggregator for Lane Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "15154250e0f4536116a8984037bfd062c10fc535",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16470": {
    "title": "CIA-SSD: Confident IoU-Aware Single-Stage Object Detector From Point Cloud",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "65a60ace6af2c061d5000688727d712c2755e955",
    "citation_count": 91
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16471": {
    "title": "Regional Attention with Architecture-Rebuilt 3D Network for RGB-D Gesture Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "011eb1b8ec239673c288a002d67de28d075f53db",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16472": {
    "title": "Deep Semantic Dictionary Learning for Multi-label Image Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a3c07082b420c9d8b4864124b68ae7b256a0ae91",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16473": {
    "title": "Model Uncertainty Guides Visual Object Tracking",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fe5e0b7bbb8cbb3bdc3b955cc942b5f3d76274f0",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16474": {
    "title": "Optimizing Information Theory Based Bitwise Bottlenecks for Efficient Mixed-Precision Activation Quantization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "72164cce8cee40d3bfeff22e1c565c8ce9c352ff",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16475": {
    "title": "Inferring Camouflaged Objects by Texture-Aware Interactive Guidance Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "43e4bb7ab85eab07b785de49cb51275047b7af97",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16476": {
    "title": "Simple is not Easy: A Simple Strong Baseline for TextVQA and TextCaps",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "952edddbb3438072312756762be1bfde287e1497",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16477": {
    "title": "Fooling Thermal Infrared Pedestrian Detectors in Real World Using Small Bulbs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f57e11b5097376155cf982b9ae10a390554dbce3",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16478": {
    "title": "ASHF-Net: Adaptive Sampling and Hierarchical Folding Network for Robust Point Cloud Completion",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0073d247c6903593d98a6ea573100f58ef08328c",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16479": {
    "title": "New Length Dependent Algorithm for Maximum Satisfiability Problem",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "009ea465496db5f5abd90fd9b3ad4a6a36a5edd6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16480": {
    "title": "Online Search with Maximum Clearance",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bfe12b505e0a0d07ed7e88241669c065d004e00c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16481": {
    "title": "Counting Maximal Satisfiable Subsets",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f9234ce567d234d1438939dd30a3cc72ea3bf741",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16482": {
    "title": "Learning To Scale Mixed-Integer Programs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b04d81729a81f77078c8fd12b1f2ad210094dbe5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16483": {
    "title": "A SAT-based Resolution of Lam's Problem",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "90f75f22bf9788b2d00e528c9942e6e06ff818aa",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16484": {
    "title": "Combining Reinforcement Learning and Constraint Programming for Combinatorial Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6eaeb3687648b8fc8fd23667fa4a66bf49fdba2f",
    "citation_count": 50
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16485": {
    "title": "Necessary and Sufficient Conditions for Avoiding Reopenings in Best First Suboptimal Search with General Bounding Functions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "297956965fd461da0a1cd113602a1cf7fa86d023",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16486": {
    "title": "A Sharp Leap from Quantified Boolean Formula to Stochastic Boolean Satisfiability Solving",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b1b5da54f9c625664aabfcbfabafc94f5b4bb8b0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16487": {
    "title": "An Improved Upper Bound for SAT",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4c08526c25b3e40d29666af2a641d540a0110e80",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16488": {
    "title": "Solving Infinite-Domain CSPs Using the Patchwork Property",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ff9197552f7f5c254380fc3d56e6f80a4f81968f",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16489": {
    "title": "Disjunctive Temporal Problems under Structural Restrictions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5d46d378bc80d363c85ae90c6e2714c2d74e86f3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16490": {
    "title": "Optimal Decision Trees for Nonlinear Metrics",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2a2e69db2538b6e1394285d454ec93a0ce479417",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16491": {
    "title": "Teaching the Old Dog New Tricks: Supervised Learning with Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1a7eb33e95f3c85acf1c5941de5c4dd856e0c152",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16492": {
    "title": "Cutting to the Core of Pseudo-Boolean Optimization: Combining Core-Guided Search with Cutting Planes Reasoning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "02eb66325ae688080a5d6ef491ba9cf6f8def4fc",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16493": {
    "title": "Optimising Automatic Calibration of Electric Muscle Stimulation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eef25c79fe49121fccb09c6c4924241fa83139ca",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16494": {
    "title": "Certifying Parity Reasoning Efficiently Using Pseudo-Boolean Proofs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d8bf3c1b99d2d3eeab9df88a92f0097eef3bb291",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16495": {
    "title": "Finding Diverse Trees, Paths, and More",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "52b406248d83f53b966702092dec2094f0975e0c",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16496": {
    "title": "Scalable Verification of Quantized Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5b91fa48408ecc07c317b3b33c752ebc76b8f433",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16497": {
    "title": "Integrated Optimization of Bipartite Matching and Its Stochastic Behavior: New Formulation and Approximation Algorithm via Min-cost Flow Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6a421bad10387e63285a4ff78e9c434b13bcaa32",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16498": {
    "title": "A Scalable Two Stage Approach to Computing Optimal Decision Sets",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a9b19f9e7805f278e3105b4f7bc5c914f860bd0b",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16499": {
    "title": "Smooth Convex Optimization Using Sub-Zeroth-Order Oracles",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c4e70288f3e9e1a47ed51f0a25818f5f1e19a2e3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16500": {
    "title": "Binary Matrix Factorisation via Column Generation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "36cfa2d70fd575ddca8e70dea2d0f6a63defe790",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16501": {
    "title": "Backdoor Decomposable Monotone Circuits and Propagation Complete Encodings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e0b22adf4863ac0ef59dfede1ec082ee1a3f8187",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16502": {
    "title": "On Continuous Local BDD-Based Search for Hybrid SAT Solving",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "27bea15cfbfadf2c20795e0fa02dd6afd611c557",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16503": {
    "title": "The Power of Literal Equivalence in Model Counting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5c937cc544f4fb052659ece6068144a40e81f5b9",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16504": {
    "title": "Parallel Constraint Acquisition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7e5bb68a25983f7add643f34ae4f250ba5814eae",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16505": {
    "title": "Towards More Practical and Efficient Automatic Dominance Breaking",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "82a6fc9028ec6c2d27ec1b90e73d7d60bc0547ae",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16506": {
    "title": "Dependency Stochastic Boolean Satisfiability: A Logical Formalism for NEXPTIME Decision Problems with Uncertainty",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "494cc5a2d0a7fbf00160d98374a21acda2bd0689",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16507": {
    "title": "Satisfiability and Algorithms for Non-uniform Random k-SAT",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4cfbc0c529134014cb5611f7c9eb9c80ef37b891",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16508": {
    "title": "Turbocharging Treewidth-Bounded Bayesian Network Structure Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4e67c8bc646bbe59f0e030dec45ffc87630b231c",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16509": {
    "title": "SAT-based Decision Tree Learning for Large Data Sets",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eaec75c3494c65c277e717de0f1838015350df15",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16510": {
    "title": "LCollision: Fast Generation of Collision-Free Human Poses using Learned Non-Penetration Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3f1db35aa06afeff6bf2f00ae85a8ceb1febf27e",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16511": {
    "title": "Symmetric Component Caching for Model Counting on Combinatorial Instances",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "473bc283b625f6d21c4905ed33a293cd2c135ec6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16512": {
    "title": "Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "20400881f50e5f199467a605e7f301fb1f369982",
    "citation_count": 38
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16513": {
    "title": "Extreme k-Center Clustering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "59fec9507b847ec9d4211db685ea2bf2d9f467f4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16514": {
    "title": "Beyond Low-frequency Information in Graph Convolutional Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fbc136c8c81cd89206dc0fcb54e16bd98df83b62",
    "citation_count": 121
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16515": {
    "title": "Graph Heterogeneous Multi-Relational Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b6931c0a58963dbe628a13456bf38b5a27307232",
    "citation_count": 34
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16516": {
    "title": "Efficient Optimal Selection for Composited Advertising Creatives with Tree Structure",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4f18ac7e54d4d24c7e7c6e23cd134a2f2c0c4a66",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16517": {
    "title": "Revisiting Consistent Hashing with Bounded Loads",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "06bba5249442ca695201a1c4e376162ec8d6ede1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16518": {
    "title": "A User-Adaptive Layer Selection Framework for Very Deep Sequential Recommender Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b64f0016a9748f55bb50fc7a6e4cde9a3158d7b1",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16519": {
    "title": "Leveraging Table Content for Zero-shot Text-to-SQL with Meta-Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6a6c55c1736fcc8c2fc761e751b9e50f5d32e1a4",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16520": {
    "title": "Towards Faster Deep Collaborative Filtering via Hierarchical Decision Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7235bfcee140991668353393f7daf85e4742baee",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16521": {
    "title": "Deep Transfer Tensor Decomposition with Orthogonal Constraint for Recommender Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b3914d487ff59eb0f996ace5ef1d2819d04ce73d",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16522": {
    "title": "PASSLEAF: A Pool-bAsed Semi-Supervised LEArning Framework for Uncertain Knowledge Graph Embedding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3646e2947827c0a9314443e5cbb15575fafaf4ba",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16523": {
    "title": "Graph Neural Network-Based Anomaly Detection in Multivariate Time Series",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "21d2742e38f7167354dafcf7f565d3894b31d008",
    "citation_count": 128
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16524": {
    "title": "A Hybrid Bandit Framework for Diversified Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e8318bcda63a89c1fa186f17b0fab5d0a4fff1cb",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16525": {
    "title": "Estimating the Number of Induced Subgraphs from Incomplete Data and Neighborhood Queries",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f1a53696fea1812e4bf9a9994937068a7dbcee97",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16526": {
    "title": "Neural Latent Space Model for Dynamic Networks and Temporal Knowledge Graphs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "179b1d82704839b17ed03fb20653494ab067ecbe",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16527": {
    "title": "Exploiting Behavioral Consistence for Universal User Representation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cff8fc77bd7d860a1f9c910ef85e471b00c8b2fb",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16528": {
    "title": "NeuralAC: Learning Cooperation and Competition Effects for Match Outcome Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "62c5ad80264d6f8db1446b5d1517167a1091dd42",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16529": {
    "title": "Joint Air Quality and Weather Prediction Based on Multi-Adversarial Spatiotemporal Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ed360bb72d67d7ae7aae80841137cb9cb34d6978",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16530": {
    "title": "GAN Ensemble for Anomaly Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3e0a7244028e303c94a33d824848d1a9555f4785",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16531": {
    "title": "Complete Closed Time Intervals-Related Patterns Mining",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "68a3887bcdb2cb807d4f41d963b6867a53cb9697",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16532": {
    "title": "Online Learning in Variable Feature Spaces under Incomplete Supervision",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f3b31ed7f41ff441092ab9ddcb9ab69d43b85ab9",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16533": {
    "title": "Knowledge-aware Coupled Graph Neural Network for Social Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c68ccdc85c8616f0bc78b0fb9df1d581429fe691",
    "citation_count": 54
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16534": {
    "title": "Graph-Enhanced Multi-Task Learning of Multi-Level Transition Dynamics for Session-based Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a73a64da2e46139db821b40ee753028f7b77a7c8",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16535": {
    "title": "Anomaly Attribution with Likelihood Compensation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d3e7dcff522432fec10ef05b4c315947deeb1466",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16536": {
    "title": "LREN: Low-Rank Embedded Network for Sample-Free Hyperspectral Anomaly Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "883c5791a627d5bf679da1b5f871ff0d51792c6d",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16537": {
    "title": "On Estimating Recommendation Evaluation Metrics under Sampling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0b3b2bc7b23c27a1d774c6e42f13c3574175d8ae",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16538": {
    "title": "Randomized Generation of Adversary-aware Fake Knowledge Graphs to Combat Intellectual Property Theft",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2dff51bd603d3e8c4ceb377b1ab7c96b92117105",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16539": {
    "title": "PREMERE: Meta-Reweighting via Self-Ensembling for Point-of-Interest Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "084b10e890d07802936fc7f9dfa6d03bdbee3b9a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16540": {
    "title": "Disposable Linear Bandits for Online Recommendations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2e5c5b38b9ea1898b05837ad7f6729aab4816056",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16541": {
    "title": "Hierarchical Negative Binomial Factorization for Recommender Systems on Implicit Feedback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "74503d5a3985a9513b9fe22f1b228b93348a7c50",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16542": {
    "title": "Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "24cff2aafcd66e1b7be4f647e478e8e73cf410a5",
    "citation_count": 115
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16543": {
    "title": "Rejection Sampling for Weighted Jaccard Similarity Revisited",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "279f6380deec7404abb45fd5e72c95d44f804976",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16544": {
    "title": "GraphMSE: Efficient Meta-path Selection in Semantically Aligned Feature Space for Graph Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "587455ffed0462366710d941d5382584faf1360d",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16545": {
    "title": "Cross-Oilfield Reservoir Classification via Multi-Scale Sensor Knowledge Transfer",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "51753e98aaf7fd24f5a29224e0443c3281325b59",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16546": {
    "title": "FedRec++: Lossless Federated Recommendation with Explicit Feedback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9d31c7747e6435417ef18e7b45dddf1b32087781",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16547": {
    "title": "HMS: A Hierarchical Solver with Dependency-Enhanced Understanding for Math Word Problem",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "680b0467861a70be41c31e4f2415fe5e2958fbc0",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16548": {
    "title": "Pre-training Context and Time Aware Location Embeddings from Spatial-Temporal Trajectories for User Next Location Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ac285bc39e1378448bdfd4c14eb55dd0d30e82c2",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16549": {
    "title": "Noninvasive Self-attention for Side Information Fusion in Sequential Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "93cef0465c9632c0f8de1a48c7014b4d20813b85",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16550": {
    "title": "Visual Pivoting for (Unsupervised) Entity Alignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "083b2d08cfce5cf397a965c29168c78eb1ddb1cb",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16551": {
    "title": "Relative and Absolute Location Embedding for Few-Shot Node Classification on Graph",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "96631435fd2c2326244f5b766dde9e617f7d9da6",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16552": {
    "title": "Learning to Pre-train Graph Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "94497472eecb7530a2b75c564548c540ebd61e9b",
    "citation_count": 36
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16553": {
    "title": "Knowledge-Enhanced Top-K Recommendation in Poincar Ball",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ac00f701ea57ba2f588895c31a098928d080f1aa",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16554": {
    "title": "Communicative Message Passing for Inductive Relation Reasoning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f0e9a5611cb444e9131001f3afee984031aae057",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16555": {
    "title": "Learning Accurate and Interpretable Decision Rule Sets from Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0a38fde11e33d0f448a8c7ff3a50a54f77af5a23",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16556": {
    "title": "Robust Spatio-Temporal Purchase Prediction via Deep Meta Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "431f056e7c6fa68e47bb5c2117127e75f4d8651c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16557": {
    "title": "U-BERT: Pre-training User Representations for Improved Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8baedb6c558bfea8ad9c17404f58b77368476a0f",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16558": {
    "title": "DocParser: Hierarchical Document Structure Parsing from Renderings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "adcb8fe66d08e6187f51ecbf4443523870a4b799",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16559": {
    "title": "Knowledge-Driven Distractor Generation for Cloze-Style Multiple Choice Questions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6556bb283669a6cbe218926d4607787de9a76ac5",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16560": {
    "title": "Group Testing on a Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1e32a124869c9ce07f4a405dc3d8a46c8d8936e4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16561": {
    "title": "Detecting Beneficial Feature Interactions for Recommender Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eed0738fe4f6670750876219bcea40ed21389451",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16562": {
    "title": "A Hybrid Probabilistic Approach for Table Understanding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4d6ae639850441b259ec261497f7a55838f9132a",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16563": {
    "title": "Hyperbolic Variational Graph Neural Network for Modeling Dynamic Graphs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6afee340e997b2f9bd728be6505a4ad786030b3e",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16564": {
    "title": "Dynamic Memory based Attention Network for Sequential Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "30b335f0bb84989173e916d655f0c766ea7e172c",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16565": {
    "title": "GaussianPath:A Bayesian Multi-Hop Reasoning Framework for Knowledge Graph Reasoning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7070e2eae96b9602032f9874e18f82d384301f07",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16566": {
    "title": "GSNet: Learning Spatial-Temporal Correlations from Geographical and Semantic Aspects for Traffic Accident Risk Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e90e84a100391c2d65e4852b7ff7e92e7ae026f3",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16567": {
    "title": "Reinforced Imitative Graph Representation Learning for Mobile User Profiling: An Adversarial Training Perspective",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8f110a359fa3e58102cc2a91cdaf50709a36c955",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16568": {
    "title": "Coupling Macro-Sector-Micro Financial Indicators for Learning Stock Representations with Less Uncertainty",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "49d9cd5d2e3e5cebcf51d2e4233ad3a8d69f0d4f",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16569": {
    "title": "Reinforcement Learning with a Disentangled Universal Value Function for Item Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "67768af907a3bc7afbe04bfff8377da8da648501",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16570": {
    "title": "Learning to Recommend from Sparse Data via Generative User Feedback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a12338cd4fd4b45e86eca285617c6da5f63aa7ff",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16571": {
    "title": "How Do We Move: Modeling Human Movement with System Dynamics",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "09805e85dc93d06efe50b1276a09cdff2dbfe19b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16572": {
    "title": "Learning to Truncate Ranked Lists for Information Retrieval",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "62166a8d00d1a135272b29dad4a0e1989317aea0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16573": {
    "title": "Fairness-aware News Recommendation with Decomposed Adversarial Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a61854cb81538a2edd667d84b6127d6b8b4501b2",
    "citation_count": 50
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16574": {
    "title": "Hybrid-order Stochastic Block Model",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "09cd304ea26fc9d14745b45f63439e878cabf89a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16575": {
    "title": "Inductive Graph Neural Networks for Spatiotemporal Kriging",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "05500d98799ba93d6a37479bf75fd2a7d21a8b53",
    "citation_count": 37
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16576": {
    "title": "Knowledge-Enhanced Hierarchical Graph Transformer Network for Multi-Behavior Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "90b1ffb667528ca1aa62bb2f843f95290ab04f35",
    "citation_count": 42
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16577": {
    "title": "AttnMove: History Enhanced Trajectory Recovery via Attentional Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e5c303d73b7ce89f880fecb1dc6943a2359385a0",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16578": {
    "title": "Self-Supervised Hypergraph Convolutional Networks for Session-based Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4097852d10cb6e0bb25f76142f85d7654eb89bc5",
    "citation_count": 111
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16579": {
    "title": "A General Offline Reinforcement Learning Framework for Interactive Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bfef39ab7421dd3bcbb75662a9be5cdcf8bd475d",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16580": {
    "title": "Hierarchical Reinforcement Learning for Integrated Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5649537c0597f26f51b6af2c177db0779f4320f0",
    "citation_count": 29
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16581": {
    "title": "Out-of-Town Recommendation with Travel Intention Modeling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eb10b623a76dae8d69bc5f551cd02e51218dba5e",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16582": {
    "title": "Towards Consumer Loan Fraud Detection: Graph Neural Networks with Role-Constrained Conditional Random Field",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "64918015af5da1554cd547de9401f620c14d1fa5",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16583": {
    "title": "Transformer-Style Relational Reasoning with Dynamic Memory Updating for Temporal Network Modeling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ece43ea9b5d92c2c788864f5e40bca5487e820b8",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16584": {
    "title": "A Unified Pretraining Framework for Passage Ranking and Expansion",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e1b6f95c9dc486eac74f1e20fdc12290d0617c3b",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16585": {
    "title": "Dynamic Knowledge Graph Alignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "37c48eed3f6219f0ef55428613fba5a05471abd1",
    "citation_count": 29
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16586": {
    "title": "Rethinking Graph Regularization for Graph Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "85d1efae8697a0ff6fb29bba4874dfe50e75ee8d",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16587": {
    "title": "Capturing Delayed Feedback in Conversion Rate Prediction via Elapsed-Time Sampling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "037f56d79a5e82866f9527f9764a1d227ba35e14",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16588": {
    "title": "Why Do Attributes Propagate in Graph Convolutional Neural Networks?",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a39193f071efed10af6704133061c15818a27edc",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16589": {
    "title": "Relaxed Clustered Hawkes Process for Student Procrastination Modeling in MOOCs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0b560f4e4fdf18d05c8d02ca16e9165ddf30179c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16590": {
    "title": "Interpretable Clustering on Dynamic Graphs with Recurrent Graph Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6ce84baa6d38997b7d3576d3e0e779ceff5aadec",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16591": {
    "title": "Coupled Layer-wise Graph Convolution for Transportation Demand Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c5826aec6709f12940307d67bf5ea21ed71da974",
    "citation_count": 27
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16592": {
    "title": "Deep Graph-neighbor Coherence Preserving Network for Unsupervised Cross-modal Hashing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "25a18d1757b1e971f8aa4db7b3883d9f88d71491",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16593": {
    "title": "Dual Sparse Attention Network For Session-based Recommendation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "01d033d69873846bf347b75050840cd748f5ed20",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16594": {
    "title": "Self-Supervised Prototype Representation Learning for Event-Based Corporate Profiling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "59fbfabf9db9148f18f505673b2a188cbfc77519",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16595": {
    "title": "AugSplicing: Synchronized Behavior Detection in Streaming Tensors",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1e55852a0471a4ce554a141f13bd8c36e2f2f661",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16596": {
    "title": "Taxonomy Completion via Triplet Matching Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "76be63767799fa50357fab6516b668960b67aa78",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16597": {
    "title": "Tripartite Collaborative Filtering with Observability and Selection for Debiasing Rating Estimation on Missing-Not-at-Random Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d6a33396c564b489a81c8793a61ab15f31b1f49",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16598": {
    "title": "Generalized Relation Learning with Semantic Correlation Awareness for Link Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "258d015243ba2f396f4094aa401ea38b6a423984",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16599": {
    "title": "A Graph-based Relevance Matching Model for Ad-hoc Retrieval",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "37023fc7bcd987e795a3842795a3e72863139f67",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16600": {
    "title": "Heterogeneous Graph Structure Learning for Graph Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6e2bfca21d3c2bacb578b288148c3c1795b8c205",
    "citation_count": 48
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16601": {
    "title": "Cold-start Sequential Recommendation via Meta Learner",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e33f0602a6712d7d37e9b826842158007e7f102a",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16602": {
    "title": "Overcoming Catastrophic Forgetting in Graph Neural Networks with Experience Replay",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8afb82f6c2a48f5ff6f9c70de3594e4a14c11b93",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16603": {
    "title": "Modeling Heterogeneous Relations across Multiple Modes for Potential Crowd Flow Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ba7b80fd765b3326dbc5f8cb7692f5b40ee25a10",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16604": {
    "title": "Learning from History: Modeling Temporal Knowledge Graphs with Sequential Copy-Generation Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "40cfa0263e7d39d4a61cfcb844a5093c8c283152",
    "citation_count": 47
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16605": {
    "title": "Adversarial Directed Graph Embedding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d4677ce389c1c1ef02c7d4e206d902c4f51bdb3",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16606": {
    "title": "Relation-Aware Neighborhood Matching Model for Entity Alignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cfcb0c89fb540d7b21cdf4c2dcc6e646c8978d95",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16607": {
    "title": "Argument Mining Driven Analysis of Peer-Reviews",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ecfac0d377db229d58bc88698ad3bfd4b384ef37",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16608": {
    "title": "Uncovering Latent Biases in Text: Method and Application to Peer Review",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cc19de8d0782917098029ed20261cbe0b0c62bf5",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16609": {
    "title": "A Market-Inspired Bidding Scheme for Peer Review Paper Assignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c6c18ad62f39060e2547a0b683525e83312d0700",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16610": {
    "title": "A Novice-Reviewer Experiment to Address Scarcity of Qualified Reviewers in Large Conferences",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f136a0fdc2065485c83396ae41d431395de51af4",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16611": {
    "title": "Catch Me if I Can: Detecting Strategic Behaviour in Peer Assessment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b0894f5c914cd90cc3b3e16b15bec11efe317b14",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16612": {
    "title": "Savable but Lost Lives when ICU Is Overloaded: a Model from 733 Patients in Epicenter Wuhan, China",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "23f626e34e1a661490950aad6c3267ffb0e88875",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16613": {
    "title": "Persistence of Anti-vaccine Sentiment in Social Networks Through Strategic Interactions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "225a67952c8e373d3dd3f1ef27a07121b47c4374",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16614": {
    "title": "Automated Model Design and Benchmarking of Deep Learning Models for COVID-19 Detection with Chest CT Scans",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3bf6f158e287ae8b296b5233f3586240600a6bf2",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16615": {
    "title": "STELAR: Spatio-temporal Tensor Factorization with Latent Epidemiological Regularization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "16b63ce2e436678c38a8be9c76737d8e70e62af0",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16616": {
    "title": "Transfer Graph Neural Networks for Pandemic Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "279febfb9e479f8d927067762d89197ee507c495",
    "citation_count": 41
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16617": {
    "title": "MiniSeg: An Extremely Minimum Network for Efficient COVID-19 Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "47fdce2b3b27819d61525247bc3de34f2d157983",
    "citation_count": 86
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16618": {
    "title": "Steering a Historical Disease Forecasting Model Under a Pandemic: Case of Flu and COVID-19",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "74fcf647c952d01b1888f2330a3f81a5dfa5c4dd",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16619": {
    "title": "Gaining Insight into SARS-CoV-2 Infection and COVID-19 Severity Using Self-supervised Edge Features and Graph Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6fe2e8b464a53e29cff47e57215ddfe9674dd0b0",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16620": {
    "title": "Context Matters: Graph-based Self-supervised Representation Learning for Medical Images",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "76d2a53b3e6c8db7a0139e0e4da671f5b0846bf4",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16621": {
    "title": "Tracking Disease Outbreaks from Sparse Data with Bayesian Inference",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0c5cb45cecab8d242357d2a0f3400c682595d0a2",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16622": {
    "title": "C-Watcher: A Framework for Early Detection of High-Risk Neighborhoods Ahead of COVID-19 Outbreak",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3e0ee08039f771f6e53cad8a02bff37ca26a4c6d",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16623": {
    "title": "Conversational Neuro-Symbolic Commonsense Reasoning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d5771c13307a00b79a8d9d7ddcc2defe2c495a9",
    "citation_count": 27
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16624": {
    "title": "Interpretable Actions: Controlling Experts with Understandable Commands",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dfd4244e29ea49b7f9e67fb837c3d70ae402e793",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16625": {
    "title": "Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-shot Commonsense Question Answering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9fa9d5dd481400b2f3904b33d542d70a6affccb9",
    "citation_count": 59
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16626": {
    "title": "Aligning Artificial Neural Networks and Ontologies towards Explainable AI",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9b942b8060d5cf0f54fef27c46efc1d78c23aa2d",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16627": {
    "title": "Planning from Pixels in Atari with Learned Symbolic Representations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a8f80b8f5cd4be2da9b8e4b9931135f16cbaa5c8",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16628": {
    "title": "Learning Game-Theoretic Models of Multiagent Trajectories Using Implicit Layers",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "17a985a233ae582158cf5a956c84b913cbcc1b02",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16629": {
    "title": "Learning by Fixing: Solving Math Word Problems with Weak Supervision",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "edaafec59b651d503ac7c8a86f8e2335273e1f7a",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16630": {
    "title": "Answering Complex Queries in Knowledge Graphs with Bidirectional Sequence Encoders",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cd1dffa09c8163b3544a3f19d061ec76749a1e72",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16631": {
    "title": "Self-Supervised Self-Supervision by Combining Deep Learning and Probabilistic Logic",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "90b0f25fc073ce818563002b5481bd52efac944c",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16632": {
    "title": "Explaining Neural Matrix Factorization with Gradient Rollback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8ceb6cf2d5788afd2188cd26822a7652f5fd590b",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16633": {
    "title": "A Scalable Reasoning and Learning Approach for Neural-Symbolic Stream Fusion",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a9f205a46a4d65e7f50c149d8ed9898111a4dc29",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16634": {
    "title": "Recognizing and Verifying Mathematical Equations using Multiplicative Differential Neural Units",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d969066d1dff7203055a493daaa3af8c490bf58e",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16635": {
    "title": "A Unified Framework for Planning with Learned Neural Network Transition Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cc4294064134d32a075048a43be698ce6832cfab",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16636": {
    "title": "Classification by Attention: Scene Graph Classification with Prior Knowledge",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a5661066faa0f28a61f238e860fb14a9057acf6b",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16637": {
    "title": "Differentiable Inductive Logic Programming for Structured Examples",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0eb56e56b07a4e89e5e77e6172be635c827ff17e",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16638": {
    "title": "Encoding Human Domain Knowledge to Warm Start Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5e3712e84884e28b41f6ca775db786b4c66976b4",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16639": {
    "title": "Neural-Symbolic Integration: A Compositional Perspective",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d6e349e385ed1765e4063bd820e2f541ee93b89",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16640": {
    "title": "Adaptive Teaching of Temporal Logic Formulas to Preference-based Learners",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6289cdaf5d8fd566f8b01ebdce4d93c2744400a1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16641": {
    "title": "Double Oracle Algorithm for Computing Equilibria in Continuous Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0a3f967b10838b19cbcf595d27b14ef711f89df1",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16642": {
    "title": "A Few Queries Go a Long Way: Information-Distortion Tradeoffs in Matching",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0c0b3ddf4cad06449e76deac89702d4ae472f909",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16643": {
    "title": "Representative Proxy Voting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2ae4ab85f221ff83615b435975bd2a962df867f2",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16644": {
    "title": "Forming Better Stable Solutions in Group Formation Games Inspired by Internet Exchange Points (IXPs)",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cd5631e12fc741998addfd35e2ee637b27d03bc8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16645": {
    "title": "Achieving Envy-freeness and Equitability with Monetary Transfers",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "efaa1bb26c224d355611b5b1710731564da29716",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16646": {
    "title": "Proportionally Representative Participatory Budgeting with Ordinal Preferences",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2889190d818cc8f192e91797808991c9f96c829e",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16647": {
    "title": "Fair and Truthful Mechanisms for Dichotomous Valuations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a8301e6372f4276e2d7db4f61855abcc5f8b1c0b",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16648": {
    "title": "Bayesian Persuasion under Ex Ante and Ex Post Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5369aea45e605281968cceea144b04a8a3de6832",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16649": {
    "title": "Defending against Contagious Attacks on a Network with Resource Reallocation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a01152175fde708abaedad4fcb6d018d71d7e56e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16650": {
    "title": "Achieving Proportionality up to the Maximin Item with Indivisible Goods",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6c140b85f5720df59fc5709bf3d3f1bbf738d2f8",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16651": {
    "title": "The Price of Connectivity in Fair Division",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "37d5587839cbe908858903e0a8b639456a66e016",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16652": {
    "title": "Dividing a Graphical Cake",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2260aef18efdd391080d4aa810948b316e60dbdf",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16653": {
    "title": "Maximin Fairness with Mixed Divisible and Indivisible Goods",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "24ad786bc8d7f34d1fca449f9ae8eb0cbb961e77",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16654": {
    "title": "Protecting the Protected Group: Circumventing Harmful Fairness",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "01568d72f87012233c7ecf2952b2abfa4b22fffb",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16655": {
    "title": "Selfish Creation of Social Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f89f716e305635fdaa67fa2f75050cbe73313c1e",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16656": {
    "title": "On the Complexity of Finding Justifications for Collective Decisions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4ef3a8660bc4aadc7ea6205eebf49dc51d2ede0c",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16657": {
    "title": "Preserving Condorcet Winners under Strategic Manipulation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "efd278ed3ecea58aa5f35bddcf0d55296d77d545",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16658": {
    "title": "Reaching Individually Stable Coalition Structures in Hedonic Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0b0405370edb654fbc3dfe786e7a65465c9c0ec8",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16659": {
    "title": "Reinforcement Learning of Sequential Price Mechanisms",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e90ee8f27d98ae7500b0c27c0ada78fb0ba046ab",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16660": {
    "title": "Margin of Victory in Tournaments: Structural and Experimental Results",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7191c84fc3a92b57cbb5d5cf57738a0e27240759",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16661": {
    "title": "Welfare Guarantees in Schelling Segregation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "85acdfee72c487de549394060162584beca9e8cd",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16662": {
    "title": "Persuading Voters in District-based Elections",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "097638237894cbf9a56675f746a2eb207aeba883",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16663": {
    "title": "Signaling in Bayesian Network Congestion Games: the Subtle Power of Symmetry",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "85f10fc6261e2ed11728101ec2f8f7bc26b650d3",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16664": {
    "title": "Computing Quantal Stackelberg Equilibrium in Extensive-Form Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a1600c90aa2255a7d3bf6a34348dae9b0fae4e8c",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16665": {
    "title": "Fair and Efficient Allocations under Subadditive Valuations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8567bb211aee04e86221dcf8bb743bc84468a0f8",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16666": {
    "title": "Scalable Equilibrium Computation in Multi-agent Influence Games on Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c6ca8fce8a8002bb506d28cbca6eb18250daf2c4",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16667": {
    "title": "Proportional Representation under Single-Crossing Preferences Revisited",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "33d740382f3fe21e006a556afa4d9bc628cf86be",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16668": {
    "title": "Computational Analyses of the Electoral College: Campaigning Is Hard But Approximately Manageable",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f3f3467c363e1a304f208feac0961bfcbf0a286e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16669": {
    "title": "Model-sharing Games: Analyzing Federated Learning Under Voluntary Participation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2e07f2c430f3df00d0a037d594435e0239fdf345",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16670": {
    "title": "On Fair Division under Heterogeneous Matroid Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "aa5f58e9d5cad87629bd40c09465087eec2f9c63",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16671": {
    "title": "PoA of Simple Auctions with Interdependent Values",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ca80110f3551b88f7c74d5b417215563e85e3294",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16672": {
    "title": "Mind the Gap: Cake Cutting With Separation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "777b4b7a3088ffdb5de03e2e9d0fca77624aabc9",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16673": {
    "title": "United for Change: Deliberative Coalition Formation to Change the Status Quo",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5ab039f93b2400488e3baf99db7041d912331750",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16674": {
    "title": "Incentivizing Truthfulness Through Audits in Strategic Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b142858a6d839ded612b9c04e84c8a96f0b665c8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16675": {
    "title": "Almost Envy-freeness, Envy-rank, and Nash Social Welfare Matchings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e8d90f8fdc2ff9ff24faee07fb3bd718f688a28b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16676": {
    "title": "Faster Game Solving via Predictive Blackwell Approachability: Connecting Regret Matching and Mirror Descent",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7a9043a0b2686445e7da328408c370833da56476",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16677": {
    "title": "Bandit Linear Optimization for Sequential Decision Making and Extensive-Form Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4963715eebd852c264a920678cfd6a3cb9ba2af1",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16678": {
    "title": "Model-Free Online Learning in Unknown Sequential Decision Making Problems and Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b852447404447e897e9c2d111609dd18625b03cf",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16679": {
    "title": "Simultaneous 2nd Price Item Auctions with No-Underbidding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "210631482791c5a4ebe8ec8772c0003637206fe9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16680": {
    "title": "Convergence Analysis of No-Regret Bidding Algorithms in Repeated Auctions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5a3e6c92d902ea33ea73373e9b900fabc03f1452",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16681": {
    "title": "Condorcet Relaxation In Spatial Voting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3b46e8efe7cab5f2ed95530de0b9f85d74c98cad",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16682": {
    "title": "Present-Biased Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a548c2c462039f84b393fb131c91aec84f11df15",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16683": {
    "title": "Efficient Truthful Scheduling and Resource Allocation through Monitoring",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5b1efd39e12a0883b697febaa2bcbd6de3fa19c1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16684": {
    "title": "Infinite-Dimensional Fisher Markets: Equilibrium, Duality and Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "03c67180a1c3c85b6f9bc23c49a59158ad1a6c1f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16685": {
    "title": "Fair and Efficient Online Allocations with Normalized Valuations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "31402765433d62d3f6081e1a117162615a964511",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16686": {
    "title": "An Analysis of Approval-Based Committee Rules for 2D-Euclidean Elections",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4235af78c5b356c11f81c7064b029cbb1c723055",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16687": {
    "title": "Aggregating Binary Judgments Ranked by Accuracy",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "776555716806327ebc9ff1460ef612a5cd7f4ead",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16688": {
    "title": "District-Fair Participatory Budgeting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1b161370739624f0f6f68786b928130b8960d5ce",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16689": {
    "title": "Fair and Efficient Allocations under Lexicographic Preferences",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "765d39b6a6c937a7ad4ec6a74376faa3e864616a",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16690": {
    "title": "Necessarily Optimal One-Sided Matchings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "89dbed197cfee471bae7c387a821c1b9076acd02",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16691": {
    "title": "Computing the Proportional Veto Core",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "325a5a83a4e9eef029ac482320c043d1f613030e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16692": {
    "title": "Multi-Scale Games: Representing and Solving Games on Networks with Group Structure",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1bb82e8e8163eab88a366886fc99b94232e35944",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16693": {
    "title": "Multi-Party Campaigning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8603bdce63eeb51eb935f379532d71996a94a8d5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16694": {
    "title": "Classification with Strategically Withheld Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0f395654e69cd2e063a6ef221fb66fb46e68cefd",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16695": {
    "title": "On the PTAS for Maximin Shares in an Indivisible Mixed Manna",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d6fc4a7ef2dc4616b5ce700b50c355048ad620df",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16696": {
    "title": "Evolution Strategies for Approximate Solution of Bayesian Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d473ff103565d8c76e0cbfa33bdd4b0db1cbb23f",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16697": {
    "title": "Safe Search for Stackelberg Equilibria in Extensive-Form Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0c3c71c63153063afb08ecb67e9682b1b13e83fa",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16698": {
    "title": "Budget Feasible Mechanisms Over Graphs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d7dfd442f9c6250b234d6f323417464dfaa26375",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16699": {
    "title": "On the Approximation of Nash Equilibria in Sparse Win-Lose Multi-player Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "af373323824286e8bad31b2d72ff7a0c3543e81f",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16700": {
    "title": "Trembling-Hand Perfection and Correlation in Sequential Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c8994263e4961526b6aeb8e42ef03e4b79534638",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16701": {
    "title": "Complexity and Algorithms for Exploiting Quantal Opponents in Large Two-Player Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e0eeb63ce173987e1ff296bf8deab404d1af5158",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16702": {
    "title": "Hindsight and Sequential Rationality of Correlated Play",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "886ed15d25615e51dff6c453c116a0b394d332ee",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16703": {
    "title": "On Fair and Efficient Allocations of Indivisible Goods",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f50f62a4e70b0d7337d18b73fbb5c305f5289957",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16704": {
    "title": "Coalition Formation in Multi-defender Security Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4aaee2dafc878bfacef7f99af99336a5763ce326",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16705": {
    "title": "Majority Opinion Diffusion in Social Networks: An Adversarial Approach",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4ca5253650a863ab001e0f4da85881080dec9caa",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16706": {
    "title": "Fair and Efficient Allocations with Limited Demands",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "09090858189ce5409f02ccfb669c69596334f64b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16707": {
    "title": "Scarce Societal Resource Allocation and the Price of (Local) Justice",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b64075ecb778621dd2b57acac029743a3b55597d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16708": {
    "title": "From Behavioral Theories to Econometrics: Inferring Preferences of Human Agents from Data on Repeated Interactions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0b4c7e44e5e5d507b55efafdd5a76d85284f1451",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16709": {
    "title": "Preference Elicitation as Average-Case Sorting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d6fc4fff91f3b84f2742529de6a5383471968102",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16710": {
    "title": "Market-Based Explanations of Collective Decisions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d5e09422963dc8db76b6c2424cd8786c1602f95",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16711": {
    "title": "A Permutation-Equivariant Neural Network Architecture For Auction Design",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "235669b26e809b6f57633425bdb92906dd10fe60",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16712": {
    "title": "Estimating -Rank by Maximizing Information Gain",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b799181859a25cc4c60f93249464accae91e6189",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16713": {
    "title": "Online Posted Pricing with Unknown Time-Discounted Valuations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "be8c1fa8bc4181b345cb56cc7cbbc32e289ca94b",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16714": {
    "title": "The Maximin Support Method: An Extension of the D'Hondt Method to Approval-Based Multiwinner Elections",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f7f83205efea8c56b0671329618d02ba342bf600",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16715": {
    "title": "Solution Concepts in Hierarchical Games Under Bounded Rationality With Applications to Autonomous Driving",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1b1f3c807974fb9d99a09ea1d44ba1cb6324be2c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16716": {
    "title": "Modeling Voters in Multi-Winner Approval Voting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "15931520cce546bbf19b4cebeb4161c4debeabe7",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16717": {
    "title": "Coupon Design in Advertising Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "87fd9c9db4067b71a459b559c08c02ebe57ee443",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16718": {
    "title": "Restricted Domains of Dichotomous Preferences with Possibly Incomplete Information",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "89f24fbc114126ed3b3f26ab7a04116e0220f710",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16719": {
    "title": "Facility's Perspective to Fair Facility Location Problems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "46fc13b90ab786538564cf04f723ad02448ecf7d",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16720": {
    "title": "The Smoothed Complexity of Computing Kemeny and Slater Rankings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a35c6813578f8723d7e3200a87f35e23896bb21c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16721": {
    "title": "If You Like Shapley Then You'll Love the Core",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "02e32987366c1ebfcc56d7c2ab822473e4c9032e",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16722": {
    "title": "A Model of Winners Allocation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c5e2d5f879778c62621c19f8fb71bac216ce93a3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16723": {
    "title": "Targeted Negative Campaigning: Complexity and Approximations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bec0e6092cbda41024c320d307828435d86bab77",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16724": {
    "title": "Finding and Certifying (Near-)Optimal Strategies in Black-Box Extensive-Form Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1d225e48891bebf985e29c9608d1074dd7b28e2c",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16725": {
    "title": "Automated Mechanism Design for Classification with Partial Verification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a6ada139344a996f398e1c7441e524b6a875be9c",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16726": {
    "title": "Incentive-Aware PAC Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0042bf7e39f93314621a924c1a0c4bf0d6d686f7",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16727": {
    "title": "Classification with Few Tests through Self-Selection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f4f01097096b6e0d6c13bf3f95d921cde52ae2ea",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16728": {
    "title": "Computing Ex Ante Coordinated Team-Maxmin Equilibria in Zero-Sum Multiplayer Extensive-Form Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "19b08d257228cf340f1153b6b5cc0d44a4ffa98c",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16729": {
    "title": "Power in Liquid Democracy",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "301e6db1e7dcc8fe47431c4bf947061aa51a218e",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16730": {
    "title": "Learning from Crowds by Modeling Common Confusions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "11c6d0851152b6bec34726be40d90bea8d8a90f0",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16731": {
    "title": "Time to Transfer: Predicting and Evaluating Machine-Human Chatting Handoff",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5f5e1a745358981dc2953d2d1718c552eda9adc9",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16732": {
    "title": "Teaching Active Human Learners",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "549544ab6be9232481c5d7abf8fd01f7319135de",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16733": {
    "title": "Automated Storytelling via Causal, Commonsense Plot Ordering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4e0af5f4944c16e3ae49b3c96cce7f81989c30f8",
    "citation_count": 40
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16734": {
    "title": "MARTA: Leveraging Human Rationales for Explainable Text Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0e6338c992b6b72da05cb783f4d422ebf0462451",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16735": {
    "title": "Human Uncertainty Inference via Deterministic Ensemble Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bfaec827c8874cc9a2f245fd06e6edd7e66679d9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16736": {
    "title": "Learning to Sit: Synthesizing Human-Chair Interactions via Hierarchical Control",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ed580995e4a51424d8f1a20f5b64200fe227c2cd",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16737": {
    "title": "User Driven Model Adjustment via Boolean Rule Explanations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d6d5d2d1a7f0351e4d4b31be95a21588bcbd133",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16738": {
    "title": "Classification Under Human Assistance",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4125a8bb23c65dbe6cfbe2470343f6d3929d1fe2",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16739": {
    "title": "Wasserstein Distributionally Robust Inverse Multiobjective Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eef710d6b72b22914a1dbd7ac4048fa8af8a047f",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16740": {
    "title": "Illuminating Mario Scenes in the Latent Space of a Generative Adversarial Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "aa79cd3983e6cfd877a830eb3e55a8ded425fe28",
    "citation_count": 33
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16741": {
    "title": "ActionBert: Leveraging User Actions for Semantic Understanding of User Interfaces",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0285688c1a07e49a663d0f49ef39370fbd00d3aa",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16742": {
    "title": "Goal Blending for Responsive Shared Autonomy in a Navigating Vehicle",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "355e7bbedf75e1b2663a1abc54d7c3fd920d9640",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16743": {
    "title": "Contrastive Adversarial Learning for Person Independent Facial Emotion Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "35c52f5792d3454cf6d628bf420af7f5190e864c",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16744": {
    "title": "AI-Assisted Scientific Data Collection with Iterative Human Feedback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4c57085514bb76df8aac9b5e22c5611c88fe93ab",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16745": {
    "title": "Improving the Performance-Compatibility Tradeoff with Personalized Objective Functions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dc8c9b980b761e4136929b452a7797d429375ddf",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16746": {
    "title": "Indecision Modeling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "85f24a03b710d304b1daf8658fc66a926c52c371",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16747": {
    "title": "Narrative Plan Generation with Self-Supervised Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c4a00c3d61b3656afcde10ba0341e12b3ff54065",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16748": {
    "title": "Uncertain Graph Neural Networks for Facial Action Unit Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "872138459871198199aa517df1a7fef112f29497",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16749": {
    "title": "Learning Rewards From Linguistic Feedback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9c49a2178134517701befea536400c01a1cdefe7",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16750": {
    "title": "Bounded Risk-Sensitive Markov Games: Forward Policy Design and Inverse Reward Learning with Iterative Reasoning and Cumulative Prospect Theory",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "48a7146f79422443b0352233b6e97caad4835ffb",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16751": {
    "title": "Content Learning with Structure-Aware Writing: A Graph-Infused Dual Conditional Variational Autoencoder for Automatic Storytelling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d2aeba4084b3b70d200f6c48f44d3ec0d87fa6b7",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16752": {
    "title": "A Continual Learning Framework for Uncertainty-Aware Interactive Image Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1637f1b07c033a37725c0e045f105d1e370dbfb8",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16753": {
    "title": "Inferring Emotion from Large-scale Internet Voice Data: A Semi-supervised Curriculum Augmentation based Deep Learning Approach",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "72e9d0af53346177932bbb14bd9760085bc48212",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16754": {
    "title": "Automatic Generation of Flexible Plans via Diverse Temporal Planning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c2a54fe5cff534bfde1e0e4980cce9776b3c84dc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16755": {
    "title": "BT Expansion: a Sound and Complete Algorithm for Behavior Planning of Intelligent Robots with Behavior Trees",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "38e1a02dff6f8df48ad7c16ba5da80b5f6354c97",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16756": {
    "title": "I3DOL: Incremental 3D Object Learning without Catastrophic Forgetting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e175fbed816f04a36030f53b0ce926a1f4f47ac9",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16757": {
    "title": "Enabling Fast Instruction-Based Modification of Learned Robot Skills",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "630c9f9aa7eb3c2a724bd5416093796b511c758b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16758": {
    "title": "Consistent Right-Invariant Fixed-Lag Smoother with Application to Visual Inertial SLAM",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a59e2b07e8b2d58a4bb0e1f3ca641139fd5e59e0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16759": {
    "title": "Supervised Training of Dense Object Nets using Optimal Descriptors for Industrial Robotic Applications",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d6737d207aa0af9e5dd056e5ec1b9ece6c9cea77",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16760": {
    "title": "DenserNet: Weakly Supervised Visual Localization Using Multi-Scale Feature Aggregation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "06f9e3ac57f4ffa3e50614c85599cf85b9695f84",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16761": {
    "title": "Learning Intuitive Physics with Multimodal Generative Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8c71b2a8d622463f17ee1e38b71e1bc5296174fd",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16762": {
    "title": "SCAN: A Spatial Context Attentive Network for Joint Multi-Agent Intent Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "597c78770a25216e998e79d3265495d98f66d2b0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16763": {
    "title": "IDOL: Inertial Deep Orientation-Estimation and Localization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "db7b3a85b6a3676b86627b1b5ae45373b2d066b7",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16764": {
    "title": "Differentiable Fluids with Solid Coupling for Learning and Control",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ccbaf40ac70e0c1812910048816b0dcd3332cd97",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16765": {
    "title": "CMAX++ : Leveraging Experience in Planning and Execution using Inaccurate Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4490dc4e270fc708a6106a69f055177b0b391c2f",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16766": {
    "title": "Generative Partial Visual-Tactile Fused Object Clustering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "36fb293613254db235088892b10f588c4fca4a4e",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16767": {
    "title": "VMLoc: Variational Fusion For Learning-Based Multimodal Camera Localization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "49619def5dfb5d52f729f3b733402c336aada869",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16768": {
    "title": "Argumentation Frameworks with Strong and Weak Constraints: Semantics and Complexity",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f75c659cc62fdee3008614097facab2030869743",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16769": {
    "title": "A General Setting for Gradual Semantics Dealing with Similarity",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "aebb4cb19539b0ddc0a282fa877f3da552019b1f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16770": {
    "title": "Living Without Beth and Craig: Definitions and Interpolants in Description Logics with Nominals and Role Inclusions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f57d832293b2efc9b32fcd0dbfd28bf62bd44264",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16771": {
    "title": "Equivalent Causal Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c27dc3a88373955935d80f7c851578e645d6529d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16772": {
    "title": "The Counterfactual NESS Definition of Causation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1fe30f24b9529f757047fab297e2d5fd72b145e4",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16773": {
    "title": "Network Satisfaction for Symmetric Relation Algebras with a Flexible Atom",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5e87cc954f66df7e916b2ee352312d5f17d8e604",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16774": {
    "title": "Conditional Inference under Disjunctive Rationality",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b66bebd41b059637378c0a6171ca9b32b7789139",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16775": {
    "title": "Algebra of Modular Systems: Containment and Equivalence",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f0ceefde2ce7290da473b1e11a652985e508ccc5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16776": {
    "title": "Certifying Top-Down Decision-DNNF Compilers",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "208177504c8775dfe28ecf400ea0a9fbb7c12718",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16777": {
    "title": "Contextual Conditional Reasoning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a59137682b5f27e574b497883f82955f0c082699",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16778": {
    "title": "Preferred Explanations for Ontology-Mediated Queries under Existential Rules",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ed2162571dc97e976dd2c2c87dbb5fab6fe6d232",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16779": {
    "title": "Topology-Aware Correlations Between Relations for Inductive Link Prediction in Knowledge Graphs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "aa6f095df55e5eddf849deaa279aa6fc2fd6e290",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16780": {
    "title": "A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "052cdf7abebc62789f13daf00a34b2a3e83bbf10",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16781": {
    "title": "Recursion in Abstract Argumentation is Hard --- On the Complexity of Semantics Based on Weak Admissibility",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "259f44f153efc65f2ae980cbc9c13bcdb2973174",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16782": {
    "title": "The Complexity Landscape of Claim-Augmented Argumentation Frameworks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f656b1155fa2a78c5e971576fa9bc4ff34e42e60",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16783": {
    "title": "On the Complexity of Sum-of-Products Problems over Semirings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8daae53ad9f080dbf9fde476cb96c17977762feb",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16784": {
    "title": "Treewidth-Aware Complexity in ASP: Not all Positive Cycles are Equally Hard",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "16c2e88c28874cb372e946c7c749fe577f275eaa",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16785": {
    "title": "SMT-based Safety Checking of Parameterized Multi-Agent Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b3dd44b6cedf217b6968296596efd82e7fd04deb",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16786": {
    "title": "A Simple Framework for Cognitive Planning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fe57ba8e833d8ca52b53e93cfb863c47e2bcc595",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16787": {
    "title": "Answering Regular Path Queries Under Approximate Semantics in Lightweight Description Logics",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5c989d2bf3064dd77d8f09a87801e672cfa15b3e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16788": {
    "title": "Knowledge-Base Degrees of Inconsistency: Complexity and Counting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b1ae6a0fb5c8763db633b67918a0cbc6f739771e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16789": {
    "title": "Constraint Logic Programming for Real-World Test Laboratory Scheduling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "322cc7745d6a5ba3bb4e129aa25273a52b2368e7",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16790": {
    "title": "Mining EL Bases with Adaptable Role Depth",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "45c9507bfab80ac31dad215f06ce0fdc29fc11b1",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16791": {
    "title": "REM-Net: Recursive Erasure Memory Network for Commonsense Evidence Refinement",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1d20cceb02fdf51c84e79e93c0d6c93c62017474",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16792": {
    "title": "(Comet-) Atomic 2020: On Symbolic and Neural Commonsense Knowledge Graphs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f8a22859230e0ccafefc020dccc66b5a646fe0ac",
    "citation_count": 150
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16793": {
    "title": "Commonsense Knowledge Augmentation for Low-Resource Languages via Adversarial Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "efd2fdb0c1e38129c72168a64c2426f10489d65b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16794": {
    "title": "Parameterized Logical Theories",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4a99ed8f8ef38947498395fc16817410d58f35d7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16795": {
    "title": "Learning Term Embeddings for Lexical Taxonomies",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ab390fc1019751ea29526476bf65dd152fe3d1d8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16796": {
    "title": "KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "997887cff41577752dc832e9475d5bb22c265093",
    "citation_count": 73
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16797": {
    "title": "Parameterized Complexity of Logic-Based Argumentation in Schaefer's Framework",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2cf1a7e8caafb07dffe7ab939b01511e0785a28b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16798": {
    "title": "Ranking Sets of Defeasible Elements in Preferential Approaches to Structured Argumentation: Postulates, Relations, and Characterizations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "781d7a4f84384bde688864d364c98e6a0feae3fd",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16799": {
    "title": "GENSYNTH: Synthesizing Datalog Programs without Language Bias",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "18bb1574af20159952ada909b88891d57ab6ef85",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16800": {
    "title": "Parameterized Complexity of Small Decision Tree Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "257c931655aec35969e99c58cb769f74637f7000",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16801": {
    "title": "Interpreting Neural Networks as Quantitative Argumentation Frameworks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "38fcd223d3a335b2f38c0f58b0d1a86968ee7fb1",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16802": {
    "title": "ChronoR: Rotation Based Temporal Knowledge Graph Embedding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4e52607397a96fb2104a99c570c9cec29c9ca519",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16803": {
    "title": "Quantification of Resource Production Incompleteness",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7b0f32c186ca55432ac9b257c7b041b7ec613e29",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16804": {
    "title": "Stratified Negation in Datalog with Metric Temporal Operators",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c730812d07de71f50157fa8d64430912609a5c93",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16805": {
    "title": "Strong Explanations in Abstract Argumentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e1e458c7e560c7cc41bd9fdaabb612d780d59cd2",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16806": {
    "title": "On the Tractability of SHAP Explanations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bd6ea16e34c7c4821061fc700cc719a8a44bf8c4",
    "citation_count": 47
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16807": {
    "title": "On Exploiting Hitting Sets for Model Reconciliation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "718989861c2f72751b710caa0b7471e16991ba8d",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16808": {
    "title": "Focused Inference and System P",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9363210990df8ee5644c20f89a05692c69662b2d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16809": {
    "title": "On-the-fly Synthesis for LTL over Finite Traces",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "31bc036140ef9868ef68fcae013bcaed50dab1c5",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16810": {
    "title": "Testing Independence Between Linear Combinations for Causal Discovery",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d52fa1f2d446891bf1e3e5081304ef8a76854778",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16811": {
    "title": "SWIFT: Scalable Wasserstein Factorization for Sparse Nonnegative Tensors",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "136693087a38ef12e1510d4a1eef44fbb79e90b1",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16812": {
    "title": "DART: Adaptive Accept Reject Algorithm for Non-Linear Combinatorial Bandits",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ba589ce23fde1490b54646879fb2e9b3635e8228",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16813": {
    "title": "Improved Worst-Case Regret Bounds for Randomized Least-Squares Value Iteration",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d28c8c16323dec5e93baf82f6c1374ba7e01d99f",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16814": {
    "title": "Semi-supervised Sequence Classification through Change Point Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1e58c9d1153d2f25d94b3a12b785bd7abe43bd1c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16815": {
    "title": "Learning Invariant Representations using Inverse Contrastive Loss",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8d131e78fd5cc6f347730c14b5ef6ee34e18e22a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16816": {
    "title": "Learned Bi-Resolution Image Coding using Generalized Octave Convolutions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "20ab457294795a47471f1c56522591012c09167a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16817": {
    "title": "Deep Bayesian Quadrature Policy Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2087626f72a47e1cae54e9ff9a10ecb26c3d1832",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16818": {
    "title": "eTREE: Learning Tree-structured Embeddings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ac944fb86af10007e0f9ca0df5d8b6203cf593d1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16819": {
    "title": "Does Explainable Artificial Intelligence Improve Human Decision-Making?",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e7411483b88a977ff046f444800d808135535f65",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16820": {
    "title": "Decentralized Multi-Agent Linear Bandits with Safety Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "17e65ef9d81727671cc75280ee30a5e219c2956d",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16821": {
    "title": "Computing an Efficient Exploration Basis for Learning with Univariate Polynomial Features",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "95f8054c68a49c921eba783806f3418dab057f25",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16822": {
    "title": "Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "777873ef6d23c2cdd7dfd6c4834eb56769a25bb1",
    "citation_count": 63
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16823": {
    "title": "An Enhanced Advising Model in Teacher-Student Framework using State Categorization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "63058875fdbcccc1ca84232eccc343ef19de685c",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16824": {
    "title": "On Lipschitz Regularization of Convolutional Layers using Toeplitz Matrix Theory",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3f75dc69849ac5c5ba4c5b86bd1e6418a4f0dea3",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16825": {
    "title": "The Tractability of SHAP-Score-Based Explanations for Classification over Deterministic and Decomposable Boolean Circuits",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "48fbef01f1548bb73f38381fb8ca20392e311961",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16826": {
    "title": "TabNet: Attentive Interpretable Tabular Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "efbd8e7a45cac8f025ba8a4de95b492d8d392c95",
    "citation_count": 287
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16827": {
    "title": "Robust Model Compression Using Deep Hypotheses",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "51e40a7f14794e82bc903e21ce9f87cabe54bc52",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16828": {
    "title": "Deep Radial-Basis Value Functions for Continuous Control",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "09a9cae0503a3a354b420e5bcecdd432283435cc",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16829": {
    "title": "DecAug: Out-of-Distribution Generalization via Decomposed Feature Representation and Semantic Augmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6ea5701aa2ec72cdcddea6b1695e8c2192328261",
    "citation_count": 27
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16830": {
    "title": "Correlative Channel-Aware Fusion for Multi-View Time Series Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6582fb0e0f67ede2541fd1d3aa54437f05482a1c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16831": {
    "title": "Deterministic Mini-batch Sequencing for Training Deep Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0fec66a519228662055cad9b23596f5461261ce3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16832": {
    "title": "Relative Variational Intrinsic Control",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1a7471fb3d324a074bda8a7530e9e7749329cef9",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16833": {
    "title": "A Theory of Independent Mechanisms for Extrapolation in Generative Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "622109cdeb83f7cbdbc8fe126a985f27a671c3df",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16834": {
    "title": "ExGAN: Adversarial Generation of Extreme Samples",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a0e447a465a8b4729c976214368c172d2b272959",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16835": {
    "title": "Ordinal Historical Dependence in Graphical Event Models with Tree Representations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "83a40aa5e96d6301481599354ccc01a6823c8691",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16836": {
    "title": "Characterizing the Loss Landscape in Non-Negative Matrix Factorization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ee2cd9462a37fb861d894fda13df3efbc3abdcb5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16837": {
    "title": "Understanding Decoupled and Early Weight Decay",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cdba52cdc8dcadd8964591170d41bdeeef2355c8",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16838": {
    "title": "Communication-Aware Collaborative Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "178e8d695fd3d72c914f35e52da9164e33d68b49",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16839": {
    "title": "Stochastic Precision Ensemble: Self-Knowledge Distillation for Quantized Deep Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "261aa442c219e6a388642d51834740bdb863a30a",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16840": {
    "title": "Fast Training of Provably Robust Neural Networks by SingleProp",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3e34b4f2f27f77eb2670958ef6ec8c758173db3b",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16841": {
    "title": "Sample-Specific Output Constraints for Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ab9ea01d28a330c1cbc96763c7273066a51eadab",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16842": {
    "title": "Fairness, Semi-Supervised Learning, and More: A General Framework for Clustering with Stochastic Pairwise Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "624ab31f34150e80e7429428f6ab8ae0e47b1358",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16843": {
    "title": "Improving Ensemble Robustness by Collaboratively Promoting and Demoting Adversarial Robustness",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6cfaa925c881ba5aa8efe8980a9ebe6509f0ddaa",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16844": {
    "title": "Cascade Size Distributions: Why They Matter and How to Compute Them Efficiently",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2e2d33a224f1569f071286e13dbf8c00a1291287",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16845": {
    "title": "Exploiting Diverse Characteristics and Adversarial Ambivalence for Domain Adaptive Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0b315769840a70e21427ab705947802e1c54a319",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16846": {
    "title": "Time Series Domain Adaptation via Sparse Associative Structure Alignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "10d557c31213ec81ac61444ab91a879c2cdaad58",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16847": {
    "title": "A Blind Block Term Decomposition of High Order Tensors",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d45a47904d9de515103f2a6f6fbe29a48bb67f9",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16848": {
    "title": "Open-Set Recognition with Gaussian Mixture Variational Autoencoders",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dc304d97a36168a0c888e9668fa29937fcb2e009",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16849": {
    "title": "Provably Secure Federated Learning against Malicious Clients",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c63e954296cf71c46fb2808e7bfaab0c3f635385",
    "citation_count": 46
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16850": {
    "title": "Dual Quaternion Knowledge Graph Embeddings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d947d696b55a3cca1010a4b61b561efc496fae4b",
    "citation_count": 41
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16851": {
    "title": "Counterfactual Explanations for Oblique Decision Trees:Exact, Efficient Algorithms",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b7a607f3ae3baf44b14ffa3a1dfe86a3e0a1b7e6",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16852": {
    "title": "Curriculum Labeling: Revisiting Pseudo-Labeling for Semi-Supervised Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "39e0a6bceec1fe851128c47fedf35a2d4f22b332",
    "citation_count": 56
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16853": {
    "title": "Frivolous Units: Wider Networks Are Not Really That Wide",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "361996e4fbbabe5ef028c85d7ab9e4213e5c777c",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16854": {
    "title": "Automated Clustering of High-dimensional Data with a Feature Weighted Mean Shift Algorithm",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a2feed9d8658fe1cba0e7410af3aae06a85e8d18",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16855": {
    "title": "High-Confidence Off-Policy (or Counterfactual) Variance Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d0725bed339ae51ed7867a7300e8ebe1a3e667d",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16856": {
    "title": "A Multi-step-ahead Markov Conditional Forward Model with Cube Perturbations for Extreme Weather Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "03771ace1d3a6b3eece6d1f9e8fd8fd004bd15d8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16857": {
    "title": "Extending Multi-Sense Word Embedding to Phrases and Sentences for Unsupervised Semantic Applications",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a6f3505451d9ec1099871804cb342e93d1fd6cb3",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16858": {
    "title": "On Online Optimization: Dynamic Regret Analysis of Strongly Convex and Smooth Problems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a4ef878021090b4dc01b1503dda1a19e99077936",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16859": {
    "title": "Provable Benefits of Overparameterization in Model Compression: From Double Descent to Pruning Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5f5c11163e6dce7c92908bc0fe3d131d754f5b88",
    "citation_count": 27
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16860": {
    "title": "Differentially Private Decomposable Submodular Maximization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ffeaf679ecfbb70b9a22dfd640990d10bcc5cdc5",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16861": {
    "title": "Using Hindsight to Anchor Past Knowledge in Continual Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "680f1bf7c3635e87d4064a2757ec0d68c01d69f3",
    "citation_count": 86
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16862": {
    "title": "Deep Verifier Networks: Verification of Deep Discriminative Models with Deep Generative Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7f5fc9db054e5bf6da0cec0da3bb0a47766623b7",
    "citation_count": 40
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16863": {
    "title": "Scalable and Explainable 1-Bit Matrix Completion via Graph Signal Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "99994bea16edd732b6c4c266a669e10f38c9dc3d",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16864": {
    "title": "Addressing Action Oscillations through Learning Policy Inertia",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7cface53d4a081d209c74d953bfadd2e6bf030a5",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16865": {
    "title": "Cross-Layer Distillation with Semantic Calibration",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e3dbe8d2e8d045ae5a8cfa52a520f3aa31a35a21",
    "citation_count": 67
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16866": {
    "title": "Distributed Ranking with Communications: Approximation Analysis and Applications",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "29cfdbe098db7c296fbbd82c46bac815ac27ffd5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16867": {
    "title": "THOR, Trace-based Hardware-driven Layer-Oriented Natural Gradient Descent Computation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "431b7a2790b97c3e2165cc1a571f09f749ef1274",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16868": {
    "title": "Neural Relational Inference with Efficient Message Passing Mechanisms",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "36d1934e8f6e5b16696aa22968d4a78790e6bf4d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16869": {
    "title": "Fitting the Search Space of Weight-sharing NAS with Graph Convolutional Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9535d8cef8bf4c251cb2b7439b773863cd0a2448",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16870": {
    "title": "Deep Spiking Neural Network with Neural Oscillation and Spike-Phase Information",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bd8876db69b685aa0db120410fc9ea1b79c7a870",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16871": {
    "title": "HyDRA: Hypergradient Data Relevance Analysis for Interpreting Deep Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "75b928590b745c701515b5604dcfd162481687d7",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16872": {
    "title": "NASGEM: Neural Architecture Search via Graph Embedding Method",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8d58ba4e876cdcc3fc9debf9b5a9e5262b87c49a",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16873": {
    "title": "Neighborhood Consensus Networks for Unsupervised Multi-view Outlier Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1e84b20fbf0ee69bdfad2c57115cac049d84e933",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16874": {
    "title": "Self-Progressing Robust Training",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "73aa94064c4c2e592ddad579c51960c5838828b8",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16875": {
    "title": "Continuous-Time Attention for Sequential Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ef392f264f49d3ee5ff9796270806a4636599271",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16876": {
    "title": "Transfer Learning for Efficient Iterative Safety Validation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0b4f819fd568a7830aaaff56d0007bb8b608fb98",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16877": {
    "title": "Computationally Tractable Riemannian Manifolds for Graph Embeddings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4fd4dd869b3d5e83ff3f666f50f85d7a05cc0493",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16878": {
    "title": "Cost-aware Graph Generation: A Deep Bayesian Optimization Approach",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "90c70191c5cb5b91d56b3e6bbb86ad8f4a2dfd0d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16879": {
    "title": "Type-augmented Relation Prediction in Knowledge Graphs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7c2e539af1d2eca07ee15b9202f90f2800df6bcc",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16880": {
    "title": "The Value-Improvement Path: Towards Better Representations for Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c035d3bd325fd374f4f4a2c3a9b6aa8483d64c66",
    "citation_count": 37
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16881": {
    "title": "Loop Estimator for Discounted Values in Markov Reward Processes",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6a3cd40b02d310faf807338949132ea148e12315",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16882": {
    "title": "Differentially Private Stochastic Coordinate Descent",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "35336721707c159452bd529cd369379323cd1e63",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16883": {
    "title": "Generalized Adversarially Learned Inference",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0fb1d1d6466fad4c566249008265f0b0a215ea4a",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16884": {
    "title": "Sample-Efficient L0-L2 Constrained Structure Learning of Sparse Ising Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "07a93b02a355035b5fb466c3e3e8f5dfafc288e0",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16885": {
    "title": "Learning with Retrospection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ca73f80bd7f2865cbd63f7345efd24f8d0d0a29a",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16886": {
    "title": "Mercer Features for Efficient Combinatorial Bayesian Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0fe589d100806afdaaff574e76616242ad9f13da",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16887": {
    "title": "Differentially Private and Communication Efficient Collaborative Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cdbe63c788b496b2b3cbea4bf1c5314d74fe6784",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16888": {
    "title": "Knowledge Refinery: Learning from Decoupled Label",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b151ae6e84b973f90350223ae1f22740efcb0e7c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16889": {
    "title": "Semi-Supervised Learning with Variational Bayesian Inference and Maximum Uncertainty Regularization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "02df2a42cd616820b668adf92e37f6afed302281",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16890": {
    "title": "Residual Shuffle-Exchange Networks for Fast Processing of Long Sequences",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "93948a2aac559fcaf4314f8f472a0f122f465411",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16891": {
    "title": "A One-Size-Fits-All Solution to Conservative Bandit Problems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ae90ae196284e210385d2847e9e02b11014cd5ff",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16892": {
    "title": "Combinatorial Pure Exploration with Full-Bandit or Partial Linear Feedback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "329a658cbbd1894c8ea0a828fe1a9cb890003237",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16893": {
    "title": "Knowledge Refactoring for Inductive Program Synthesis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ce423bce21a71eb89905bad7bde4000f2b51ba66",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16894": {
    "title": "Semi-Supervised Metric Learning: A Deep Resurrection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8bc65edb4eaef2d4443ff08406980920d5219ff8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16895": {
    "title": "Reinforcement Learning with Trajectory Feedback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8e79043b89f007bd81d65244345b50f7bff7fca9",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16896": {
    "title": "The Parameterized Complexity of Clustering Incomplete Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8318d55656d4a2b4a1a0b4541cf9e13c14917dfe",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16897": {
    "title": "Learning Prediction Intervals for Model Performance",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "69d439ffa9da071ed163736a9ce1e306404653e4",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16898": {
    "title": "Adaptive Gradient Methods for Constrained Convex Optimization and Variational Inequalities",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8856c69999b5293c68c3d34dc584618f8e09275f",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16899": {
    "title": "Projection-Free Bandit Optimization with Privacy Guarantees",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "80329da8202dba48a5eab5455ee1e6976723cb8e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16900": {
    "title": "Learning to Cascade: Confidence Calibration for Improving the Accuracy and Computational Cost of Cascade Inference Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4b001c535aa5fdac765005641542e8710300bd7d",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16901": {
    "title": "Regret Bounds for Batched Bandits",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2c9c8df8e097ff06ae5741ad35f520110f264549",
    "citation_count": 28
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16902": {
    "title": "Almost Linear Time Density Level Set Estimation via DBSCAN",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eb23a57f5ab32ebeeab74bdb6c7afb25ebd57ba4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16903": {
    "title": "Deep Graph Spectral Evolution Networks for Graph Topological Evolution",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bb4b5ae14d4c22771136ed4630c9c47b055950b2",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16904": {
    "title": "Adversarial Training and Provable Robustness: A Tale of Two Objectives",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1e2b41a9db99311c880b3fdfac21324a475280f9",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16905": {
    "title": "Learning a Gradient-free Riemannian Optimizer on Tangent Spaces",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f50997fe182793a8a31114c88f6a5dafb7e990f5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16906": {
    "title": "Learning to Reweight with Deep Interactions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d4fd57a3b1e857a16b70ba7325b246d3b3b8bb75",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16907": {
    "title": "Deep Switching Auto-Regressive Factorization: Application to Time Series Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ab9c2121338151dfd0056666135cc5113b4809d6",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16908": {
    "title": "UAG: Uncertainty-aware Attention Graph Neural Network for Defending Adversarial Attacks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9bf050287e0cd8df167cc345878335fc5a8d045e",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16909": {
    "title": "SHOT-VAE: Semi-supervised Deep Generative Models With Label-aware ELBO Approximations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e06e573edffdc741c2e9e232b7ee6ee87229cfe1",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16910": {
    "title": "Learning to Augment for Data-scarce Domain BERT Knowledge Distillation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "53c1be1795a93ce3f9f74daafc043a70623c5406",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16911": {
    "title": "Collaborative Group Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7109c1be12710d543776b79ccb8a0870b65db775",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16912": {
    "title": "Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ad01c1c8838d266235dab06b4974cebc8a88f269",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16913": {
    "title": "Few-Shot One-Class Classification via Meta-Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f42f87e4015f1aad3ed464b47c8644214b41748c",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16914": {
    "title": "Towards Effective Context for Meta-Reinforcement Learning: an Approach based on Contrastive Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "77be65bb396cb6309b6d03023c5f71203b3a39ea",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16915": {
    "title": "Agreement-Discrepancy-Selection: Active Learning with Progressive Distribution Alignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ad721b510a709bf914f233f7b36cf5c88459f8ab",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16916": {
    "title": "Generalize a Small Pre-trained Model to Arbitrarily Large TSP Instances",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "50eec8da1acc52a7c4a0a2c527d7696a41bbdc22",
    "citation_count": 45
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16917": {
    "title": "HiGAN: Handwriting Imitation Conditioned on Arbitrary-Length Texts and Disentangled Styles",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2d1c4c63398c333413d9a4e16b10dc0dc9e00b36",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16918": {
    "title": "Diffusion Network Inference from Partial Observations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a30cc9c82469b0a63f0351c93f86df1ab5949579",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16919": {
    "title": "Stabilizing Q Learning Via Soft Mellowmax Operator",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bf591da059e692cb5c2f1d6130e22fcb2fde6f54",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16920": {
    "title": "On the Convergence of Communication-Efficient Local SGD for Federated Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d33bb29be6bb247041b12c704d150e3e4e1afa1",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16921": {
    "title": "A Trace-restricted Kronecker-Factored Approximation to Natural Gradient",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6b3d345d309bf0ffb1076e5ac34462103413af72",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16922": {
    "title": "Addressing Domain Gap via Content Invariant Representation for Semantic Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3a6e7065b3ef718d3064bcb294359db2a5585dd9",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16923": {
    "title": "Increasing Iterate Averaging for Solving Saddle-Point Problems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4199214350e269f674eda392a8a44a8746fac846",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16924": {
    "title": "Uncertainty-Aware Multi-View Representation Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "30531856e51ad6a51044f4766e896e792bb8a0a2",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16925": {
    "title": "Justicia: A Stochastic SAT Approach to Formally Verify Fairness",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "09203d11e98d69d11c25a10fbdc00731e62a31ad",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16926": {
    "title": "The Importance of Modeling Data Missingness in Algorithmic Fairness: A Causal Perspective",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3e2822475a8669ffedd282de12f2e247e6a2b266",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16927": {
    "title": "Attribute-Guided Adversarial Training for Robustness to Natural Perturbations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "58604b3f4337d96ab2f160730976c5ef4e3ee3a1",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16928": {
    "title": "Efficient On-Chip Learning for Optical Neural Networks Through Power-Aware Sparse Zeroth-Order Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "25eb8d25f640615f2874ccf46b5c35e5fccf25ad",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16929": {
    "title": "Attentive Neural Point Processes for Event Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "096fb613da4642aae8094e5081514446fdfb34ae",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16930": {
    "title": "Revisiting Iterative Back-Translation from the Perspective of Compositional Generalization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "df66fcd3fd4f0d55bd96528cddb0e2f08ddb3385",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16931": {
    "title": "Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b74c5b7c97ded089caa481964207ba5e0e65b659",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16932": {
    "title": "Towards Reusable Network Components by Learning Compatible Representations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "35db0fb0eab669b45173bf2f22565efa4e7253e4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16933": {
    "title": "High-Dimensional Bayesian Optimization via Tree-Structured Additive Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "196645bfb3207053c19db2be845cecbb50ca95ed",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16934": {
    "title": "Explanation Consistency Training: Facilitating Consistency-Based Semi-Supervised Learning with Interpretability",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2f88acd32214ffd870d461d62b204903a50ec70b",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16935": {
    "title": "DeepSynth: Automata Synthesis for Automatic Task Segmentation in Deep Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6ebeef3f32f0e1e67bded9362dacc01d12bee5c3",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16936": {
    "title": "Liquid Time-constant Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1b9a07702cd346673b4c5e798d2256157fab1d3f",
    "citation_count": 36
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16937": {
    "title": "Learning with Safety Constraints: Sample Complexity of Reinforcement Learning for Constrained MDPs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0c9bc8f25d03287b32b56f9c6d14078c5fb2155f",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16938": {
    "title": "Analysing the Noise Model Error for Realistic Noisy Label Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c95403947e6f15b12bbfd7448b9476cddccf19eb",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16939": {
    "title": "Provably Good Solutions to the Knapsack Problem via Neural Networks of Bounded Size",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "05e95fdf43e627fb1827ee3e21c35f0ebf0b3ba2",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16940": {
    "title": "Scaling-Up Robust Gradient Descent Techniques",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9c2ad8c8501079a10bddbde5d432e73542c2afc8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16941": {
    "title": "Learning Model-Based Privacy Protection under Budget Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c398f8a81d10c0d582dfae6d7896870d0acd6d82",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16942": {
    "title": "Graph Game Embedding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "028137830e4a383192c21dd349420ffe83d6ec5c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16943": {
    "title": "Topology Distance: A Topology-Based Approach for Evaluating Generative Adversarial Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "57b4ca6091d0f10bd42ba3ba87fbe5d90eaea6d9",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16944": {
    "title": "Storage Fit Learning with Feature Evolvable Streams",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "38e76887033f85efa63eed48159d191cbf536a27",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16945": {
    "title": "Reinforcement Learning Based Multi-Agent Resilient Control: From Deep Neural Networks to an Adaptive Law",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "775a61ba50311ec65d3f01d410608f37e68ba545",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16946": {
    "title": "Slimmable Generative Adversarial Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d5605ee4c28027f8845d5d7505445c7a5c2df6a",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16947": {
    "title": "Disentangled Representation Learning in Heterogeneous Information Network for Large-scale Android Malware Detection in the COVID-19 Era and Beyond",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ffb780edd4527cc39cee0eb34cd8ba539eaac54a",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16948": {
    "title": "Gaussian Process Priors for View-Aware Inference",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bee2b3c7cdb5da193e1a418ae7c0f6b70dc3f468",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16949": {
    "title": "Boosting Multi-task Learning Through Combination of Task Labels - with Applications in ECG Phenotyping",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1b6ea0aff166a38e845689723a14b3596fb786fe",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16950": {
    "title": "OPQ: Compressing Deep Neural Networks with One-shot Pruning-Quantization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7b16367b575d951a98f1762d8f45d7c0eb840581",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16951": {
    "title": "Multi-scale Graph Fusion for Co-saliency Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f04cee8ce9819084648c90d2b3360595fb4ba38d",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16952": {
    "title": "Continual Learning by Using Information of Each Class Holistically",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d8a3986ebff641415995e3c462c7cf5fb4b3819c",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16953": {
    "title": "Predictive Adversarial Learning from Positive and Unlabeled Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d9117676a586c92b3e2a4747823cf8aa8dc798c2",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16954": {
    "title": "Multidimensional Uncertainty-Aware Evidential Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "432b8b15d12af9860c662cb4e0a767b1bcd023d4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16955": {
    "title": "Adversarial Defence by Diversified Simultaneous Training of Deep Ensembles",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3ceb1fda6d7db93da419b583ce77da3cb40ac899",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16956": {
    "title": "Accelerating Continuous Normalizing Flow with Trajectory Polynomial Regularization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3c8a110d71ef3132431288aee05b189e206d6ea9",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16957": {
    "title": "Attributes-Guided and Pure-Visual Attention Alignment for Few-Shot Recognition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "177a57cc39fced688c938a7f29ba251cc747b15e",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16958": {
    "title": "Learning to Reweight Imaginary Transitions for Model-Based Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5b201baf0b648781ef5c23d5f4344fb19504eb95",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16959": {
    "title": "ACMo: Angle-Calibrated Moment Methods for Stochastic Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "efe0af196c18abea1db1e28b7c78dd30c4437585",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16960": {
    "title": "Personalized Cross-Silo Federated Learning on Non-IID Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "679237737ab2392a87a1f3c44d62b2e37f36bf01",
    "citation_count": 144
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16961": {
    "title": "Reward-Biased Maximum Likelihood Estimation for Linear Stochastic Bandits",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5a29de624baa172236f3f544f3c5726293fe9399",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16962": {
    "title": "Large Batch Optimization for Deep Learning Using New Complete Layer-Wise Adaptive Rate Scaling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b89644114c1e6f4133e5f459000b92e06ab7c7d0",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16963": {
    "title": "Accurate and Robust Feature Importance Estimation under Distribution Shifts",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ecc6260cc1efc878c70bf5753d67e1a11b42627a",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16964": {
    "title": "Variance Penalized On-Policy and Off-Policy Actor-Critic",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "08e7fda8b3077db9dbf7630ff5424582909a002a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16965": {
    "title": "Constructing a Fair Classifier with Generated Fair Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "da62e18ef9808523f7678a5f6eb7d45ff54298d7",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16966": {
    "title": "Neural Utility Functions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "384b56b7b609a3966a6c02f8259b94e6f0f3e5de",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16967": {
    "title": "IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "335a732095c8ffa27eed4513220a7c80066213df",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16968": {
    "title": "Active Bayesian Assessment of Black-Box Classifiers",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "85ce98791b72c5c4d7ece02393a894c9c39da2f7",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16969": {
    "title": "Show, Attend and Distill: Knowledge Distillation via Attention-based Feature Matching",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e9f0b81fe2f7f47a68d2d87fc1747d739cdbcd05",
    "citation_count": 43
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16970": {
    "title": "Dynamic Multi-Context Attention Networks for Citation Forecasting of Scientific Publications",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "22d00771c3e2af85ffd79f1038ae6dac30377c03",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16971": {
    "title": "Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5d15dfc3be39915a03c8d50172694613929144cf",
    "citation_count": 55
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16972": {
    "title": "Clustering Ensemble Meets Low-rank Tensor Approximation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "841dfc6985668e78fcc2e44e19788d2ab9c6307e",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16973": {
    "title": "Action Candidate Based Clipped Double Q-learning for Discrete and Continuous Action Tasks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3b1b9d7926dfc2c34cc63095b3e50915ded4d307",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16974": {
    "title": "LightXML: Transformer with Dynamic Negative Sampling for High-Performance Extreme Multi-label Text Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a0cd055650dc69d671b52b7f979d3f1bbfacda4b",
    "citation_count": 38
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16975": {
    "title": "Temporal-Logic-Based Reward Shaping for Continuing Reinforcement Learning Tasks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "691c36c2ca85b6b7e412b79ade52c9a58d988018",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16976": {
    "title": "Power up! Robust Graph Convolutional Network via Graph Powering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7a0ed8ac6832505aafb94f6a30f4ac831aac0444",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16977": {
    "title": "Balanced Open Set Domain Adaptation via Centroid Alignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "96a1d152ab112b56a05c21ed1f693d17e0a4050d",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16978": {
    "title": "Linearly Replaceable Filters for Deep Network Channel Pruning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6e030866df9920344b82fccf858868b06edb12fb",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16979": {
    "title": "A Sample-Efficient Algorithm for Episodic Finite-Horizon MDP with Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4b7af6632be8f790f68ed2d5f02914ee4c6ce681",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16980": {
    "title": "Winning Lottery Tickets in Deep Generative Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "12ff508431c627fa01aaaf5779d68b6336dec5d3",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16981": {
    "title": "Exploration via State influence Modeling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7c2bb6d3e9a154335d9af5c7298b587ac15945bd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16982": {
    "title": "Deep Probabilistic Canonical Correlation Analysis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3a154fe557fc218188e456745e15bc22be32482c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16983": {
    "title": "Learning Generalized Relational Heuristic Networks for Model-Agnostic Planning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6fc0c9e19db469eec8250862a108bfae118bf2b4",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16984": {
    "title": "A Recipe for Global Convergence Guarantee in Deep Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "221956bc9885749aa070f32af002cc0c02a49c97",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16985": {
    "title": "Bayesian Dynamic Mode Decomposition with Variational Matrix Factorization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5dc1a03d0ae0328302c213a1068b7550894d5c5d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16986": {
    "title": "Improving Fairness and Privacy in Selection Problems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "90e70eb36e3ad7192ee958efb925b404408b94a4",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16987": {
    "title": "A Flexible Framework for Communication-Efficient Machine Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "239a5598deb4fa3c99c62a3a4dceec95bce69cb4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16988": {
    "title": "GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "199ac333b1ff37917d1ab4a2e2002d9605b3db1e",
    "citation_count": 59
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16989": {
    "title": "Understanding Catastrophic Overfitting in Single-step Adversarial Training",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "21b192d3d4f092fdc06c8dd799d86fb83b3099cf",
    "citation_count": 33
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16990": {
    "title": "Counterfactual Fairness with Disentangled Causal Effect Variational Autoencoder",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a7bb20f6d5d07c2043712f9b17aa1150aedec362",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16991": {
    "title": "Split-and-Bridge: Adaptable Class Incremental Learning within a Single Neural Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "55c5ef153d0cd05ab3051d67db72fa3d7a55f690",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16992": {
    "title": "DPM: A Novel Training Method for Physics-Informed Neural Networks in Extrapolation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bba8eaa382df676e5b6bc68e5e634c3252cc8420",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16993": {
    "title": "Kernel-convoluted Deep Neural Networks with Data Augmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "46bfb0a8ed89d71d0ec3ae9b535b831dc91fe8a2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16994": {
    "title": "Neural Sequence-to-grid Module for Learning Symbolic Rules",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2c0a266f9cb88bb914c138ece0deaab8cf528f78",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16995": {
    "title": "Visual Concept Reasoning Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fab4598dc40ee5840196dd2c85e62f1238f11a48",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16996": {
    "title": "Sparsity Aware Normalization for GANs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "48e714e7f7e98e62596704eea3950f9341517db2",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16997": {
    "title": "HINT: Hierarchical Invertible Neural Transport for Density Estimation and Bayesian Inference",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1c3d659e9459bb8aad72390d2b340e051add6dac",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16998": {
    "title": "Nearly Linear-Time, Parallelizable Algorithms for Non-Monotone Submodular Maximization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "52c5836ddd2249839bdf17568e9434ae1c88ac96",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16999": {
    "title": "Asynchronous Optimization Methods for Efficient Training of Deep Neural Networks with Guarantees",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "80afd4f0a8c036504cd4730f9d389b732b9d43e2",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17000": {
    "title": "Positions, Channels, and Layers: Fully Generalized Non-Local Network for Singer Identification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fbb14447bb10a87215fd9cbd40976b225999f8b7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17001": {
    "title": "MolGrow: A Graph Normalizing Flow for Hierarchical Molecular Generation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6bcc0ca39c6d120b6a7e8ab0d7e988e577403ab8",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17002": {
    "title": "Compressing Deep Convolutional Neural Networks by Stacking Low-dimensional Binary Convolution Filters",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bbace99bbe05345c2b2bbe35fdb9007bab398228",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17003": {
    "title": "Hypothesis Disparity Regularized Mutual Information Maximization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "721c1e4b889b09ec2dc5c52a80340fec52a02f89",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17004": {
    "title": "Query Training: Learning a Worse Model to Infer Better Marginals in Undirected Graphical Models with Hidden Variables",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4c8ac6887c7dd6397598aeedb3edfa0b2b9c5153",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17005": {
    "title": "Metrics and Continuity in Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d6d2183c79c226129805652c0195cf39896ce8a0",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17006": {
    "title": "Lipschitz Lifelong Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "207c7b8ea8f94463383a089e4f7f24b64503f9c0",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17007": {
    "title": "Norm-Based Generalisation Bounds for Deep Multi-Class Convolutional Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b806ffeea0b172755824b210dbeccf2b2ae714b2",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17008": {
    "title": "Learnable Dynamic Temporal Pooling for Time Series Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "803a1fed191ad3eb79eb3c073900b31e7e5ad0a9",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17009": {
    "title": "Interpretable Embedding Procedure Knowledge Transfer via Stacked Principal Component Analysis and Graph Neural Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "48e02bfbb5d1b69deee0e324e824a1f310f86172",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17010": {
    "title": "Unsupervised Domain Adaptation for Semantic Segmentation by Content Transfer",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "11de73205f632acb422de5cadae7ed4571595bf5",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17011": {
    "title": "Memory and Computation-Efficient Kernel SVM via Binary Embedding and Ternary Model Coefficients",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "64b3a220d31b4b33e50a7c1bc60235c2eed6868b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17012": {
    "title": "Enhancing Parameter-Free Frank Wolfe with an Extra Subproblem",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fde3ce79d4866297a27600ccb22321f80537cb1d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17013": {
    "title": "Unsupervised Active Learning via Subspace Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "48d67498e37ee6b164f6d8d7d50f403e01b59723",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17014": {
    "title": "LRSC: Learning Representations for Subspace Clustering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ebe4c587de2e1820b9f42e6b246126b33c5d26ed",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17015": {
    "title": "GoT: a Growing Tree Model for Clustering Ensemble",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4ee1cb44701e9211acb4d972fd8abbcc3e509adb",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17016": {
    "title": "VSQL: Variational Shadow Quantum Learning for Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a24934da43ebc507be35b7a6facc5d4c71f505a3",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17017": {
    "title": "High Fidelity GAN Inversion via Prior Multi-Subspace Feature Composition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3a2042de18e9b5d2d6c130d5072e2cef921b8d5e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17018": {
    "title": "ShapeNet: A Shapelet-Neural Network Approach for Multivariate Time Series Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "be818bd3db1928dcfe24f23ee7afaa09545f9a61",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17019": {
    "title": "A Bayesian Approach for Subset Selection in Contextual Bandits",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ed247312f1188a44c7f05fc9392879d90b727275",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17020": {
    "title": "Self-Paced Two-dimensional PCA",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "464e75d95841b43eb33e0308fa5924aa202e5fb4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17021": {
    "title": "Learning Intact Features by Erasing-Inpainting for Few-shot Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "43eb7fd1cc8247483e6c5bd6b0f154eb2fdc63a3",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17022": {
    "title": "Token-Aware Virtual Adversarial Training in Natural Language Understanding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fe9cd5bcca161289b0e3da0f49114dcccf62eaa1",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17023": {
    "title": "Synergetic Learning of Heterogeneous Temporal Sequences for Multi-Horizon Probabilistic Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "41de3027e358b39597faa646e8c2baf7ed58cb8c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17024": {
    "title": "Bayesian Distributional Policy Gradients",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "db5ec14be596e3c52cd2fa29473927cb70239973",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17025": {
    "title": "Learning Graph Neural Networks with Approximate Gradient Descent",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "be62a12d7c1dd77157164a0cbc448dc5c0e2db96",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17026": {
    "title": "Multi-View Representation Learning with Manifold Smoothness",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "bebc1c153acf764db685975eb88bedcd3911a5b0",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17027": {
    "title": "Bi-Classifier Determinacy Maximization for Unsupervised Domain Adaptation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fdb6bbec092061d6d4729e016f3277795170adaf",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17028": {
    "title": "Sublinear Classical and Quantum Algorithms for General Matrix Games",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3a69cf4992a77daf4d4e6dba6544e4f6a090a401",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17029": {
    "title": "A Free Lunch for Unsupervised Domain Adaptive Object Detection without Source Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8bd4264cc4e4644e9ff5beff466cceb4a3325e90",
    "citation_count": 43
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17030": {
    "title": "Improving Adversarial Robustness via Probabilistically Compact Loss with Logit Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2ed004ed273bcf3cf33d37f4c6952ed68b55bb4b",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17031": {
    "title": "MFES-HB: Efficient Hyperband with Multi-Fidelity Quality Measurements",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "185ab6081f702d65573e7a151a417ba8b16fc816",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17032": {
    "title": "Learned Extragradient ISTA with Interpretable Residual Structures for Sparse Coding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c7b448b094e3d136e6676de794faf0e4b25b3070",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17033": {
    "title": "One-shot Graph Neural Architecture Search with Dynamic Search Space",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9425619f07e553624140f6f1207cc0d56159d290",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17034": {
    "title": "Scheduled Sampling in Vision-Language Pretraining with Decoupled Encoder-Decoder Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "04dee7bfed6af7e18cf8dcfc639de105120a3f6e",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17035": {
    "title": "Online Optimal Control with Affine Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "23c7a7af699ef6caf1783c4e161f8d2325d5c3f4",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17036": {
    "title": "TRQ: Ternary Neural Networks With Residual Quantization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ae93b52e32df91f4aeb21b045d4b234e75543967",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17037": {
    "title": "Contrastive Clustering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d52ee822014835fcd5a4992c94579d9f95673d55",
    "citation_count": 146
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17038": {
    "title": "Longitudinal Deep Kernel Gaussian Process Regression",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "03c1349c35a36c4fb7984d8f94e34af25ec96019",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17039": {
    "title": "Large Norms of CNN Layers Do Not Hurt Adversarial Robustness",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2f513ef015d7ed4c1340ea92797d8af21b456431",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17040": {
    "title": "Doubly Residual Neural Decoder: Towards Low-Complexity High-Performance Channel Decoding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ee935013cfc1758892e982541dda854e2c8e5ec8",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17041": {
    "title": "From Label Smoothing to Label Relaxation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9c4cad2cc63b56de94057a463b6f4cb6d6a21c26",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17042": {
    "title": "Sample Selection for Universal Domain Adaptation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a61d49e7aca4208c596ad261b760fe644dec58d1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17043": {
    "title": "Class-Attentive Diffusion Network for Semi-Supervised Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "471064962a5db3803faf6c6581b488aea41e02e0",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17044": {
    "title": "Auto-Encoding Transformations in Reparameterized Lie Groups for Unsupervised Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1a9eda9311471faf1a46e170b5b843eb7772af84",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17045": {
    "title": "Multi-Proxy Wasserstein Classifier for Image Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d1023fa9ca56316055902aeb25591778d5b6d868",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17046": {
    "title": "TransTailor: Pruning the Pre-trained Model for Improved Transfer Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4e28880fdfea67e411fb7184e656d1471f293f76",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17047": {
    "title": "Learning a Few-shot Embedding Model with Contrastive Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "46c35cc5e488ff72a256ab4e73d21702487b83b7",
    "citation_count": 42
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17048": {
    "title": "Unchain the Search Space with Hierarchical Differentiable Architecture Search",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b0cb2cf5aba4d07fe152e9eaa3e1008fbb099a0a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17049": {
    "title": "Overcoming Catastrophic Forgetting in Graph Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e41a28daa05cc955e00690c20a3fa15ba2d11cdc",
    "citation_count": 27
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17050": {
    "title": "Stable Adversarial Learning under Distributional Shifts",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "649cbe47d71abe69833ee1135945adb1cb3b71a8",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17051": {
    "title": "Hierarchical Multiple Kernel Clustering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "213ffd7c51242db1428d2261c229dcafb14be674",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17052": {
    "title": "Dynamically Grown Generative Adversarial Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8b33fd37b4615ebdcf234955c1fdbd726bfa4f4f",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17053": {
    "title": "FLAME: Differentially Private Federated Learning in the Shuffle Model",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "50781751a97cbf7ccddb0a4860d04fc550d01f7c",
    "citation_count": 28
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17054": {
    "title": "Post-training Quantization with Multiple Points: Mixed Precision without Mixed Precision",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "41151f89079f1c52761751b2392a40458c6a896d",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17055": {
    "title": "Train a One-Million-Way Instance Classifier for Unsupervised Visual Representation Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ae815a8510a7bf888d0ec10c6b50c6f4472bfc57",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17056": {
    "title": "ROSITA: Refined BERT cOmpreSsion with InTegrAted techniques",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "76ef68c7c2410b503e5f1d43ca0c3d6764f72de1",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17057": {
    "title": "Task Aligned Generative Meta-learning for Zero-shot Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9214ef6db735d2b8cb115c8e04e869e21803fdb9",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17058": {
    "title": "Learning from eXtreme Bandit Feedback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "675da5104616f4b869f7a71d10270f736cc79a24",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17059": {
    "title": "Improving Causal Discovery By Optimal Bayesian Network Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "15c1f24e4b7460cab3f0c7ba2c56b9b440c75286",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17060": {
    "title": "Stochastic Graphical Bandits with Adversarial Corruptions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "94a49625bba0e205ac844d60eff65c5a1c218bd2",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17061": {
    "title": "Stochastic Bandits with Graph Feedback in Non-Stationary Environments",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "520270af8684ae84c5bb8be529fd84c94203751d",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17062": {
    "title": "Decentralized Policy Gradient Descent Ascent for Safe Multi-Agent Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d59d3eb12f58ddf10eed0a6bf4a46a8ee6d8c548",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17063": {
    "title": "Tailoring Embedding Function to Heterogeneous Few-Shot Tasks by Global and Local Feature Adaptors",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "31f5f944b61b3478e2c3d383810737a26eb55d1c",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17064": {
    "title": "PULNS: Positive-Unlabeled Learning with Effective Negative Sample Selector",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4c487f774990b76228de42c30a1fa9be722257c0",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17065": {
    "title": "Revisiting Co-Occurring Directions: Sharper Analysis and Efficient Algorithm for Sparse Matrices",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "93d83c2ae447a2f4944b1b18e3b537cbc1d0f018",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17066": {
    "title": "Semi-supervised Medical Image Segmentation through Dual-task Consistency",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "19e55508e0ca39e0c92c89e47ce6f356f05c54b5",
    "citation_count": 94
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17067": {
    "title": "Adaptive Knowledge Driven Regularization for Deep Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8f7854d172fab854f8ca62a756ad3eec7941c9c8",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17068": {
    "title": "Multi-Domain Multi-Task Rehearsal for Lifelong Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "22e06fa904f2022b63954a08543df4a2da63059e",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17069": {
    "title": "On the Adequacy of Untuned Warmup for Adaptive Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2a48d2b673689e4434fc6b86965ca2a91bb40103",
    "citation_count": 28
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17070": {
    "title": "Learning Representations for Incomplete Time Series Clustering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "437f3a2e01fd10a2ae8448969ae5a5b46b738d81",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17071": {
    "title": "Joint-Label Learning by Dual Augmentation for Time Series Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1de2db9bacf1658219ee50ff173bd436ddd5a967",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17072": {
    "title": "Unsupervised Learning of Graph Hierarchical Abstractions with Differentiable Coarsening and Optimal Transport",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "40484fb2739a5169950a4b59e33f03297525b668",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17073": {
    "title": "Sequential Attacks on Kalman Filter-based Forward Collision Warning Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "92c6ab0a11680f1cf8a4a2b5f2070c2b2486465d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17074": {
    "title": "Exact Reduction of Huge Action Spaces in General Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8769e44ab5d1c04435f895e9c97b4bcf752bb913",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17075": {
    "title": "Composite Adversarial Attacks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2afc07df53deb068d5daf538e84d447224e37a7d",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17076": {
    "title": "Deep Mutual Information Maximin for Cross-Modal Clustering",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "795f78b67aa157df2614679b220fa976fb9dfce6",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17077": {
    "title": "Searching for Machine Learning Pipelines Using a Context-Free Grammar",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ded7f03f7952bc4d9bdcccef5ddf00664b4f2bda",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17078": {
    "title": "Scalable Graph Networks for Particle Simulations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "56f6708f22cbedcc1c600d78408bfbb46669d483",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17079": {
    "title": "Infinite Gaussian Mixture Modeling with an Improved Estimation of the Number of Clusters",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "096c0cc633e179cec92bd9abfcba459dbecd2c2b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17080": {
    "title": "Exacerbating Algorithmic Bias through Fairness Attacks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f29bb1e3f5e98a6887c2414a2036858a076a5915",
    "citation_count": 27
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17081": {
    "title": "Physarum Powered Differentiable Linear Programming Layers and Applications",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "02ae998667e48ccd0b110dfe86f7ec7c3187356d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17082": {
    "title": "Lenient Regret for Multi-Armed Bandits",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e13633617cd72d0b155a48b0abf7018ad93b3b7c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17083": {
    "title": "Policy Optimization as Online Learning with Mediator Feedback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ac6b3d3d85d0cdfdff34c522ad8c3e1677d2f5a1",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17084": {
    "title": "Consistency and Finite Sample Behavior of Binary Class Probability Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "061751124f59decf1802a313141004f7baab6bdf",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17085": {
    "title": "Discovering Fully Oriented Causal Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cfbefb5d92e1715db4a0e8db4c43fe421a4e6ac4",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17086": {
    "title": "Generative Semi-supervised Learning for Multivariate Time Series Imputation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1fe4590e1807c61fc416612966010123036db3e7",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17087": {
    "title": "A General Class of Transfer Learning Regression without Implementation Cost",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "31e417ba28c22220a6bc2eaf95a6911c4b1450d4",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17088": {
    "title": "Scheduling of Time-Varying Workloads Using Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dc9baba1d35cb7ff174c0f294166052cad415aac",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17089": {
    "title": "Improved Mutual Information Estimation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1bdc343c451a01286c31a5dc76d442742a055c12",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17090": {
    "title": "Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c117a59fdad8ebf857d01082612093e9e6aa676e",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17091": {
    "title": "Task-Agnostic Exploration via Policy Gradient of a Non-Parametric State Entropy Estimate",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7e1b6ff0525e61c75c636982b400a3a9576b10e0",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17092": {
    "title": "Elastic Consistency: A Practical Consistency Model for Distributed Stochastic Gradient Descent",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b35560e24f4bbc0e0934cd7bc81bdd32add7cddb",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17093": {
    "title": "Game of Gradients: Mitigating Irrelevant Clients in Federated Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0dfd85b4a7d544d147ddcb02bfb12ad13c69ea93",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17094": {
    "title": "Objective-Based Hierarchical Clustering of Deep Embedding Vectors",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e723eca7e014b67c28d74605a60cb7d7ae5955eb",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17095": {
    "title": "5* Knowledge Graph Embeddings with Projective Transformations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3edceae594b88563bcda0db2502b23b3d0d076b1",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17096": {
    "title": "Advice-Guided Reinforcement Learning in a non-Markovian Environment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4a5cbc5e734130c9aac28c6195f8c2b1ec305654",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17097": {
    "title": "Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4e9dcfe17312d8a4a6092afc36b37348923de347",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17098": {
    "title": "Modular Graph Transformer Networks for Multi-Label Image Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "69a1943e13863b3273d6d8b37fcf4ac066ae0866",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17099": {
    "title": "Differentially Private k-Means via Exponential Mechanism and Max Cover",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7f4ad49b255bbd468edf1749e8a9008565987e55",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17100": {
    "title": "Minimum Robust Multi-Submodular Cover for Fairness",
    "abstract": "In this paper, we study a novel problem, Minimum Robust Multi-Submodular Cover for Fairness (MinRF), as follows: given a ground set V; m monotone submodular functions f_1,...,f_m; m thresholds T_1,...,T_m and a non-negative integer r; MinRF asks for the smallest set S such that f_i(S \\ X)  T_i for all i  [m] and |X|  r. We prove that MinRF is inapproximable within (1- ) ln m; and no algorithm, taking fewer than exponential number of queries in term of r, is able to output a feasible set to MinRF with high certainty. Three bicriteria approximation algorithms with performance guarantees are proposed: one for r = 0, one for r = 1, and one for general r. We further investigate our algorithms' performance in two applications of MinRF, Information Propagation for Multiple Groups and Movie Recommendation for Multiple Users. Our algorithms have shown to outperform baseline heuristics in both solution quality and the number of queries in most cases",
    "volume": "main",
    "checked": true,
    "id": "6ec2c2700ad7f3065899ae98028f7b35a9607fe3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17101": {
    "title": "Temporal Latent Auto-Encoder: A Method for Probabilistic Multivariate Time Series Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "da90d057c5a4379ae3b27f3e9d2bb7b37288a654",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17102": {
    "title": "An Information-Theoretic Framework for Unifying Active Learning Problems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c55349c6f4e93eb4ab4c1d2a3167a0c52f2bc3ba",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17103": {
    "title": "Top-k Ranking Bayesian Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b94836849283be9ef77fc818e6098bb720b7ad69",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17104": {
    "title": "Distributional Reinforcement Learning via Moment Matching",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "572c890478b96e3be80bf1b72013ecf06ccf486b",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17105": {
    "title": "Precision-based Boosting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e1570dc30fb2d0f42f522a25c8307beb9e1c299a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17106": {
    "title": "Improving Model Robustness by Adaptively Correcting Perturbation Levels with Active Queries",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "683e27268a9551d1ec1b20070a3a1d4a2ea4a72e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17107": {
    "title": "Learning of Structurally Unambiguous Probabilistic Grammars",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5f32c39de3f36834994d1eab701c791f04b8aabf",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17108": {
    "title": "RT3D: Achieving Real-Time Execution of 3D Convolutional Neural Networks on Mobile Devices",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2ea24183f37578404d455dccc816a7088b0d0f99",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17109": {
    "title": "Warm Starting CMA-ES for Hyperparameter Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "73d75652588d1f58349d0cd03d0c40e59cd92cf0",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17110": {
    "title": "Inverse Reinforcement Learning From Like-Minded Teachers",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0da646add1af224d36eb16a63687317db97ec982",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17111": {
    "title": "Multinomial Logit Contextual Bandits: Provable Optimality and Practicality",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ce3f88059a43aaa1badbec553970debc9b24e985",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17112": {
    "title": "Learning Deep Generative Models for Queuing Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "de849838b3b97f3e7bcc41726238dc12507688f3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17113": {
    "title": "OT-Flow: Fast and Accurate Continuous Normalizing Flows via Optimal Transport",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1528a5a17af90fee30ca24ee8c77498d7dcacc83",
    "citation_count": 64
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17114": {
    "title": "FC-GAGA: Fully Connected Gated Graph Architecture for Spatio-Temporal Traffic Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2e2439c70d811cbbb64aa8ea7bb6442efef67d55",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17115": {
    "title": "Meta-Learning Framework with Applications to Zero-Shot Time-Series Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2e6a8914745319cae682b807a6b4ae470b08c54a",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17116": {
    "title": "Augmented Experiment in Material Engineering Using Machine Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7e11d26bb62115c2ef6513f784c62c2585d31f63",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17117": {
    "title": "Second Order Techniques for Learning Time-series with Structural Breaks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c9691c1c6801ea60b4b7e6b82c59b11770518f74",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17118": {
    "title": "Defending against Backdoors in Federated Learning with Robust Learning Rate",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3c0bce697a7a91c32966b8255df5780eac0e1238",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17119": {
    "title": "Robustness Guarantees for Mode Estimation with an Application to Bandits",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "df0d4e6036dd0679ae238c6352eeb7f77aab9076",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17120": {
    "title": "Disentangled Information Bottleneck",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "925792be475b1297e75b9193a78b6c063a790799",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17121": {
    "title": "NASTransfer: Analyzing Architecture Transferability in Large Scale Neural Architecture Search",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c0152b279dca4bd11811e6edcfe110670dac6667",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17122": {
    "title": "Robust Reinforcement Learning: A Case Study in Linear Quadratic Regulation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "79da145c480aca3aedca05b4daf44ebf1789ca90",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17123": {
    "title": "Tempered Sigmoid Activations for Deep Learning with Differential Privacy",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7290945147946bc5ac06ec010e07d027e306d6aa",
    "citation_count": 76
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17124": {
    "title": "Vector Quantized Bayesian Neural Network Inference for Data Streams",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6bb14b13338c1d06f5035c8ae4cf3f9f70a457a0",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17125": {
    "title": "Maximum Roaming Multi-Task Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3cecf284fa2cbfbb12dd7f45187e6a47a7496fad",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17126": {
    "title": "Fast PCA in 1-D Wasserstein Spaces via B-splines Representation and Metric Projection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "44e04dd0dee8284a14a8d037837125defdc76f4e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17127": {
    "title": "AutoDropout: Learning Dropout Patterns to Regularize Deep Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ef8854a62e05c8e741894166689a9cd8352a1df0",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17128": {
    "title": "Fast Multi-view Discrete Clustering with Anchor Graphs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0942a3f881415ae6325403dc9f27206acd6d2354",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17129": {
    "title": "Relation-aware Graph Attention Model with Adaptive Self-adversarial Training",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d81869fc4c0d1a0da90262cc6ed146e592aba7e",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17130": {
    "title": "Uncertainty-Aware Policy Optimization: A Robust, Adaptive Trust Region Approach",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b29ef3794829d56ce139a8d02aa88c307d045ed3",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17131": {
    "title": "Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5bd07b7b023b68d8f6d50716afbced6fc35369f9",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17132": {
    "title": "Online DR-Submodular Maximization: Minimizing Regret and Constraint Violation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "030686e9926e2947ae9ce7906e6b25c9d6998d11",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17133": {
    "title": "Improving Generative Moment Matching Networks with Distribution Partition",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ed6fc9a2c9c5ed669a846fca86a0538ae93205d4",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17134": {
    "title": "Multiple Kernel Clustering with Kernel k-Means Coupled Graph Tensor Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d22f1ac208adbc0463c5ea0ef2210e7f4f392bc9",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17135": {
    "title": "Robust Fairness Under Covariate Shift",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4f160697d01b4afe12366c165f1326dd90c05bc1",
    "citation_count": 34
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17136": {
    "title": "Shuffling Recurrent Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1e31c3e42b4d0ba9ed1a13c0d8df962b72b0df7c",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17137": {
    "title": "Why Adversarial Interaction Creates Non-Homogeneous Patterns: A Pseudo-Reaction-Diffusion Model for Turing Instability",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "58448e841fbbd48f0a430f32aa27163cbf35a0c3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17138": {
    "title": "Adversarial Permutation Guided Node Representations for Link Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7ba03ffe68cbdb0e43c3c1f2c0bd3f2adb7e33fd",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17139": {
    "title": "Visual Transfer For Reinforcement Learning Via Wasserstein Domain Confusion",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ca96857a584bab75c5bf8225357a6197fb5892b3",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17140": {
    "title": "Anytime Inference with Distilled Hierarchical Neural Ensembles",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2a8e72636abda540afdfe1925ba6cfdc612b920a",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17141": {
    "title": "Inverse Reinforcement Learning with Explicit Policy Estimates",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9fa8b2b70160791e0d3bad62788fbbdf32068995",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17142": {
    "title": "A Deeper Look at the Hessian Eigenspectrum of Deep Neural Networks and its Applications to Regularization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0aa575ebb8cfe9a2b1e71f0d4219fde7b9907132",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17143": {
    "title": "AdvantageNAS: Efficient Neural Architecture Search with Credit Assignment",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "32c5a0f2f7788fd20970affc260139beb208e86f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17144": {
    "title": "Active Feature Selection for the Mutual Information Criterion",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dfa6e7e6e77528085a683bed033fa73b5c767173",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17145": {
    "title": "Learning Precise Temporal Point Event Detection with Misaligned Labels",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2cecfcd9aadf69ae7263a57da12079c602c62748",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17146": {
    "title": "Multi-type Disentanglement without Adversarial Training",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a75364b0de5bb4da4d54d58d14699e724c422caa",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17147": {
    "title": "Uncertainty-Matching Graph Neural Networks to Defend Against Poisoning Attacks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "400389ca8b23ff77fa9ee96717fe6447df7469af",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17148": {
    "title": "Right for Better Reasons: Training Differentiable Models by Constraining their Influence Functions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "43d13cd464f4a49b3b4d3669dedcfb3261aa7aed",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17149": {
    "title": "Meta-Learning Effective Exploration Strategies for Contextual Bandits",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f3800bae40691c553893c688465ea4ac45c59ccb",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17150": {
    "title": "Membership Privacy for Machine Learning Models Through Knowledge Transfer",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7750e0f88603992999b8079fb624b83a0f508741",
    "citation_count": 29
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17151": {
    "title": "Theoretically Principled Deep RL Acceleration via Nearest Neighbor Function Approximation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "073a3856c867de94aeeb49732d0ee8dfc3149306",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17152": {
    "title": "Time Series Anomaly Detection with Multiresolution Ensemble Decoding",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9862891fcfebd3f4ec25e15e26717daada4bd805",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17153": {
    "title": "STL-SGD: Speeding Up Local SGD with Stagewise Communication Period",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8ac8bc1db6dfb793b0905e966bd8e2fc1fa59650",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17154": {
    "title": "PDO-eS2CNNs: Partial Differential Operator Based Equivariant Spherical CNNs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1226aabf0df82894c54a427ea5da5d176e90c80f",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17155": {
    "title": "Partial Is Better Than All: Revisiting Fine-tuning Strategy for Few-shot Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7bb3a96078c854f03d6e9c2032ad6efe6873d974",
    "citation_count": 33
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17156": {
    "title": "Federated Multi-Armed Bandits",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "19531ac63010c70607e2ea7d6c2f2d282d7a0eb8",
    "citation_count": 32
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17157": {
    "title": "Raven's Progressive Matrices Completion with Latent Gaussian Process Priors",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d826b6e3b8efe68ff5ca9d493fa209127b52d8ac",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17158": {
    "title": "Improved Penalty Method via Doubly Stochastic Gradients for Bilevel Hyperparameter Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "72819e56b779ecdeae811f36e60b446b04d32394",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17159": {
    "title": "Online Class-Incremental Continual Learning with Adversarial Shapley Value",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0a0b75fc5a75b2d37c5c90923400a5463d8e9dfd",
    "citation_count": 45
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17160": {
    "title": "Scalable Affinity Propagation for Massive Datasets",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "96b8fa41d2ed94176d8466c860c41febba93a9d2",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17161": {
    "title": "Interpretable Sequence Classification via Discrete Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dbcb1a868328b1c2d60627b8e3ebf52932972d2b",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17162": {
    "title": "Towards Domain Invariant Single Image Dehazing",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d3faa88ddedd47d5d2acb05a706dc5c6f5d14743",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17163": {
    "title": "DIBS: Diversity Inducing Information Bottleneck in Model Ensembles",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "99fbd94538d9568a04196e055d286ffae32cf58f",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17164": {
    "title": "Differential Spectral Normalization (DSN) for PDE Discovery",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ead459eb90207bffa704fc861adada2bca23a6dd",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17165": {
    "title": "UNIPoint: Universally Approximating Point Processes Intensities",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2e22b7920526000aeb8f1b2ad187f9ac17dfa099",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17166": {
    "title": "Solving Common-Payoff Games with Approximate Policy Iteration",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cdcd7ba7438f3f4510ddebcca6b6307953c6fe68",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17167": {
    "title": "Improving Gradient Flow with Unrolled Highway Expectation Maximization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "39a3bc57da3e8507ee0d60f074ae135aa2f649a3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17168": {
    "title": "Implicit Kernel Attention",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a32ed7f632e087c92ecd8f7a1080cba23aa6ea99",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17169": {
    "title": "Error-Correcting Output Codes with Ensemble Diversity for Robust Learning in Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6eb8bf42193296d57ae04cb01383844927909211",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17170": {
    "title": "Hierarchical Relational Inference",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "52e4325fca11a95ea8385274a0720329af460d65",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17171": {
    "title": "`Less Than One'-Shot Learning: Learning N Classes From M < N Samples",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e3ceaf1fbb353493be6b203d76bc00c9fd92fb37",
    "citation_count": 28
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17172": {
    "title": "HiABP: Hierarchical Initialized ABP for Unsupervised Representation Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "07fd98342daef3d0ee13357962890beabececb46",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17173": {
    "title": "Stability and Generalization of Decentralized Stochastic Gradient Descent",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "02bde59697f537813276dc86ee9d963c3bdd2452",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17174": {
    "title": "TempLe: Learning Template of Transitions for Sample Efficient Multi-task RL",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "00133d41d5ecef1a9d046d2b92bb2a23a335cb7c",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17175": {
    "title": "PAC Learning of Causal Trees with Latent Variables",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6e2047ee30fb09cf62775ef9e476415904936c99",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17176": {
    "title": "Learning Dynamics Models with Stable Invariant Sets",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3e917b66419016b75c624abc426d2a537598fae4",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17177": {
    "title": "Near-Optimal Regret Bounds for Contextual Combinatorial Semi-Bandits with Linear Payoff Functions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2b7f6ace2f62bbe4ce5452e6c56db4f13379d38d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17178": {
    "title": "Explicitly Modeled Attention Maps for Image Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "59eccbe007ccf92172499db8420c12ea0933e24b",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17179": {
    "title": "Proxy Graph Matching with Proximal Matching Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ed64d4c2b158c791c4a1639766c31f87746345e5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17180": {
    "title": "Strategy and Benchmark for Converting Deep Q-Networks to Event-Driven Spiking Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "6a106a837c87c73d1fac65b095a27e13d17b4476",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17181": {
    "title": "Empowering Adaptive Early-Exit Inference with Latency Awareness",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a0b4a132169ad8d5983db9914ae9895f0b8efa28",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17182": {
    "title": "Foresee then Evaluate: Decomposing Value Estimation with Latent Future Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8830afc72b0d7cf65fdd08dcc0033d2d25d4c832",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17183": {
    "title": "Gradient Descent Averaging and Primal-dual Averaging for Strongly Convex Optimization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "09fac8aae6e8a1238dfdd72f4a8b8947f719b520",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17184": {
    "title": "Evolutionary Approach for AutoAugment Using the Thermodynamical Genetic Algorithm",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dec3eb5cf7b4b9913e0075dad47cd8696183d04d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17185": {
    "title": "Semi-Supervised Knowledge Amalgamation for Sequence Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0dd0bc246775e667da10a38867dfa4d975c055aa",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17186": {
    "title": "Online Non-Monotone DR-Submodular Maximization",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "65cb0863d4690f4f716e8b96af989997394554e9",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17187": {
    "title": "Detecting Adversarial Examples from Sensitivity Inconsistency of Spatial-Transform Domain",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a77dd2f328c39fe39be95f5185c555ff68efe5fe",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17188": {
    "title": "Towards Trustworthy Predictions from Deep Neural Networks with Fast Adversarial Calibration",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d3b1cfec88ff61e495a5aeec3e8126651c2472cb",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17189": {
    "title": "Meta Learning for Causal Direction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "738cde0911f9155ee7940fe1a8062311799dde7d",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17190": {
    "title": "Learning Compositional Sparse Gaussian Processes with a Shrinkage Prior",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4522d04e6dff6e05e83e4c595dffd8176711da4d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17191": {
    "title": "Characterizing Deep Gaussian Processes via Nonlinear Recurrence Systems",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8724ccf443b1690778e10c03ef3e8bf1961fa3e8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17192": {
    "title": "Iterative Bounding MDPs: Learning Interpretable Policies via Non-Interpretable Methods",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fff58c6686a95bbe6fda8ad9ea0cbb4ab017ac78",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17193": {
    "title": "Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "824fc6d70a1f88063fde107432116ca15889d99e",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17194": {
    "title": "Learning Adjustment Sets from Observational and Limited Experimental Data",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2b60d9738666bca5baa91284014459db7950cab5",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17195": {
    "title": "*-CFQ: Analyzing the Scalability of Machine Learning on a Compositional Task",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d3edc20ed4a07195f3663abc0ead4220266fd75b",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17196": {
    "title": "Toward Robust Long Range Policy Transfer",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "335f33b9fbbfd0a7da6eb36af4942829d1104ffb",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17197": {
    "title": "Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "af7698add52507d441541fcd4da998b7e84a7b52",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17198": {
    "title": "Deep Fusion Clustering Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "21a5c402b9ca4374b20c737f4b0cce3fe38472e0",
    "citation_count": 32
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17199": {
    "title": "ESCAPED: Efficient Secure and Private Dot Product Framework for Kernel-based Machine Learning Algorithms with Applications in Healthcare",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8cddbe7e863a387ade384c0bb5b9e8f5d9f29326",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17200": {
    "title": "Expected Eligibility Traces",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "51b3c8ca6cacce955a431b8d780143aa0b59ecb5",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17201": {
    "title": "Continual General Chunking Problem and SyncMap",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "733714daeba69d89e34f80569cb79cbf329e7340",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17202": {
    "title": "Gated Linear Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "28ea0a93390300c662795b3d1bd4d0aea85c2779",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17203": {
    "title": "GraphMix: Improved Training of GNNs for Semi-Supervised Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "21e280d67da995dd682f888aa20be11b96afd2e7",
    "citation_count": 39
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17204": {
    "title": "PID-Based Approach to Adversarial Attacks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "06659aaedb5d294f7281b2a28dcb517de360c73a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17205": {
    "title": "Nearest Neighbor Classifier Embedded Network for Active Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "108231372947678333059f7a493edbce7097bcab",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17206": {
    "title": "Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b09d52bcbea21b3428f8eb4de16c1461d937842f",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17207": {
    "title": "Approximate Multiplication of Sparse Matrices with Limited Space",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ba9c1a0b1d1eed095e2614cfe831510ff26eb919",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17208": {
    "title": "Projection-free Online Learning in Dynamic Environments",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "17f97d67a1f35b9aea888c22d9deb23f658799ea",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17209": {
    "title": "Projection-free Online Learning over Strongly Convex Sets",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "279da76413430f1c777dde6dd7375b0e2ab14caa",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17210": {
    "title": "Multi-View Information-Bottleneck Representation Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f7c86725504c7864dd9caef2ae1946b7e49a1e5b",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17211": {
    "title": "Semi-Supervised Node Classification on Graphs: Markov Random Fields vs. Graph Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "48299646b03df5ed39a3e83a5bbd5c103b2591c4",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17212": {
    "title": "Quantum Exploration Algorithms for Multi-Armed Bandits",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "51de5bf0b4c55380d8c86bdefd861e444629ee33",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17213": {
    "title": "Learning from Noisy Labels with Complementary Loss Functions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4298e66ceb6f13bdd95de164a08a4b88a704cee6",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17214": {
    "title": "Debiasing Evaluations That Are Biased by Evaluations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7488429131b8970425a66f3410920d98ff6e9c36",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17215": {
    "title": "Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7270be2fab5fcdb59c325c0fbc8370351956aa22",
    "citation_count": 32
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17216": {
    "title": "Consistency Regularization with High-dimensional Non-adversarial Source-guided Perturbation for Unsupervised Domain Adaptation in Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2f52bb6d47360e531692dfa3ed8c46e8f7d6cc37",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17217": {
    "title": "Embedding Heterogeneous Networks into Hyperbolic Space Without Meta-path",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "45ecb2782d80e53dfdc20b6b727b4a968ace29be",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17218": {
    "title": "Adversarial Linear Contextual Bandits with Graph-Structured Side Observations",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2ffbf836e0392fd3d4b6e4842b6d727f187e79bf",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17219": {
    "title": "Addressing Class Imbalance in Federated Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2f970d898fead11c2504ba8f19e2ac919510a56b",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17220": {
    "title": "Contrastive Transformation for Self-supervised Correspondence Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "367b424aed91745cf79c1d29670b16a64a31967a",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17221": {
    "title": "Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "fde5afcab0731d751bb1ecca773b9bca7914db53",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17222": {
    "title": "Learning with Group Noise",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ccbcacc4fcde0eebcf27a774a874db7d1b391319",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17223": {
    "title": "Adaptive Verifiable Training Using Pairwise Class Similarity",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f77eded7672b3c18a4126ae72483eeb7505624ac",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17224": {
    "title": "Adaptive Algorithms for Multi-armed Bandit with Composite and Anonymous Feedback",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "18d873fb28e3e454bbd9e536fde78058bbfdaf7e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17225": {
    "title": "Harmonized Dense Knowledge Distillation Training for Multi-Exit Architectures",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "38fc2a215f1ba02e6f80ea1b3102c2011180d96e",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17226": {
    "title": "Tied Block Convolution: Leaner and Better CNNs with Shared Thinner Filters",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "8de987b2baafd4a873351528787c60fb9af77e97",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17227": {
    "title": "Deep Recurrent Belief Propagation Network for POMDPs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "482ec6471fd65cde1e11c40ed2442f51e6e42b0a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17228": {
    "title": "Data-Free Knowledge Distillation with Soft Targeted Transfer Set Synthesis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3827fb3155c316a01b0e42877177dcf3fcf8df05",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17229": {
    "title": "Incremental Embedding Learning via Zero-Shot Translation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "773aab0cf44aab244b989963da30db914437b97a",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17230": {
    "title": "Gene Regulatory Network Inference as Relaxed Graph Matching",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "085ddeb9b1fe0747d111461823e6344dffe582da",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17231": {
    "title": "Unified Tensor Framework for Incomplete Multi-view Clustering and Missing-view Inferring",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4e40105fc2b8dba251ed8c6239436e6dd12c3f78",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17232": {
    "title": "Learning Set Functions that are Sparse in Non-Orthogonal Fourier Bases",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2568a27d17413e84b777cffa1e0a0f21de7f1b12",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17233": {
    "title": "BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "013a741927569ae9b40875a9e58d2c5ba6dbb3a8",
    "citation_count": 137
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17234": {
    "title": "Peer Collaborative Learning for Online Knowledge Distillation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a7058717ce5d37094fed32147d3b98d0edc0df16",
    "citation_count": 36
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17235": {
    "title": "Self-Supervised Attention-Aware Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "38537de90fda155cd10794c42dd6e14602b2fa77",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17236": {
    "title": "Training Spiking Neural Networks with Accumulated Spiking Flow",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4caeb73d69f0090776eda00b89aafde99dc4c48d",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17237": {
    "title": "Fast and Scalable Adversarial Training of Kernel SVM via Doubly Stochastic Gradients",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eebc33c1a194f9f094a6073da896309ad922e9c7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17238": {
    "title": "Fine-grained Generalization Analysis of Vector-Valued Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7f163523a2f604256bdb53dc7629420d1e1defc2",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17239": {
    "title": "Frugal Optimization for Cost-related Hyperparameters",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4604b009bcf82385493055a0d59eec416eba7a3c",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17240": {
    "title": "Federated Block Coordinate Descent Scheme for Learning Global and Personalized Models",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a231cad82f3ab7f0121c7750229d9fc48ee253b1",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17241": {
    "title": "Curriculum-Meta Learning for Order-Robust Continual Relation Extraction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1b92ee2694a044b3555ad1c68d7c120fc275f3e6",
    "citation_count": 28
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17242": {
    "title": "Fractal Autoencoders for Feature Selection",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5851119cb4487011aa38b08d7a029e68929c5a46",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17243": {
    "title": "Neural Architecture Search as Sparse Supernet",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0c5627fb5bc540e4f93a725cd6c8e23152887aff",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17244": {
    "title": "Learning to Purify Noisy Labels via Meta Soft Label Corrector",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "13a494cac1a4f2035bf541a43fb5600b102bfd9e",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17245": {
    "title": "Near-Optimal MNL Bandits Under Risk Criteria",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3101d0360cab5007b2cae2ff79c21fb03cb58ce3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17246": {
    "title": "Communication-Efficient Frank-Wolfe Algorithm for Nonconvex Decentralized Distributed Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "18140e61c2242369c7f960d4f1344110911fe498",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17247": {
    "title": "Physics-constrained Automatic Feature Engineering for Predictive Modeling in Materials Science",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "270809df0b5a0f582e3d6a2bb681cda5d5b2d14a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17248": {
    "title": "Distant Transfer Learning via Deep Random Walk",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2c15eed6944d33f6209fe03c8d32d2d6a1e66354",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17249": {
    "title": "Learning Cycle-Consistent Cooperative Networks via Alternating MCMC Teaching for Unsupervised Cross-Domain Translation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e8266aa7606217305c25720c839d9742f60360ac",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17250": {
    "title": "Learning Energy-Based Model with Variational Auto-Encoder as Amortized Sampler",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "114fee31a3038d5d217dd41a18262928211f60b9",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17251": {
    "title": "Domain Adaptation In Reinforcement Learning Via Latent Unified State Representation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "691ba1236f38905fc6e540409787514228e874ab",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17252": {
    "title": "Non-asymptotic Convergence of Adam-type Reinforcement Learning Algorithms under Markovian Sampling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "71c0ca7dbce40ef1ac621e33324b1737b658d8b6",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17253": {
    "title": "Variational Disentanglement for Rare Event Modeling",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f5f196dce229939f4bfc0f6541295da2bc6f272e",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17254": {
    "title": "Step-Ahead Error Feedback for Distributed Training with Compressed Gradient",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "46780b67ec795d143750bcba94406928c6973488",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17255": {
    "title": "Isolation Graph Kernel",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a687250a507a08351d938fbf634d11c229682b58",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17256": {
    "title": "Multi-Task Recurrent Modular Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "18bb3bbeffe2b00378342a876d3de4ed695c57b4",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17257": {
    "title": "Learning Graphons via Structured Gromov-Wasserstein Barycenters",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "29d52d1457677a259977113579a3d39b5345bd6d",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17258": {
    "title": "Towards Generalized Implementation of Wasserstein Distance in GANs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b0494d7e8759990dae712bf5a9b44950e6b480c1",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17259": {
    "title": "Towards Feature Space Adversarial Attack by Style Perturbation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "07968742c9ae269e0023a7540b0a7e51bbc7f29a",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17260": {
    "title": "MUFASA: Multimodal Fusion Architecture Search for Electronic Health Records",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "513a73c77b652a89a916673318d03caf801bea69",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17261": {
    "title": "Deep Frequency Principle Towards Understanding Why Deeper Learning Is Faster",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2ac5861a63c8747133c05fde44436fedc939651d",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17262": {
    "title": "Rethinking Bi-Level Optimization in Neural Architecture Search: A Gibbs Sampling Perspective",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "63065d6a88e7cf10de5200e7a682ff8b2e998caa",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17263": {
    "title": "Toward Understanding the Influence of Individual Clients in Federated Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ee83845e674589bb2f243876bffcc8608592bfd6",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17264": {
    "title": "Adversarial Partial Multi-Label Learning with Label Disambiguation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f799f7affe7337f1fdd78d342ff5d4a2690b338c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17265": {
    "title": "Near Lossless Transfer Learning for Spiking Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "9d8f774e1a4bfdb5a1f411419d7156a634d496e4",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17266": {
    "title": "DeHiB: Deep Hidden Backdoor Attack on Semi-supervised Learning via Adversarial Perturbation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "dc5d70b48a04a6e9c3310e6fda30748a37031d0c",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17267": {
    "title": "Robust Bandit Learning with Imperfect Context",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "386a40c178c4c737a6aff32f815a790417de7814",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17268": {
    "title": "Hierarchical Graph Capsule Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "cce173204b1ea9f41635bd7efa81c4ca2d8b7dfd",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17269": {
    "title": "FracBits: Mixed Precision Quantization via Fractional Bit-Widths",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5bbb9dfc449f77a8c95de0bdd4a70fd96953308e",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17270": {
    "title": "On Convergence of Gradient Expected Sarsa()",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "21fa92e012b6575064dfbd304e67673e7a8f16cc",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17271": {
    "title": "Sample Complexity of Policy Gradient Finding Second-Order Stationary Points",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f2f6502c85228c2dc69f712798f2aba54241d7d6",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17272": {
    "title": "WCSAC: Worst-Case Soft Actor Critic for Safety-Constrained Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5b2370ebd3439ff60ea64a0c8db88fea2dd86a9c",
    "citation_count": 34
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17273": {
    "title": "Characterizing the Evasion Attackability of Multi-label Classifiers",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "af6b7679f847bdae78e0c2e0a400ddee80dfbd47",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17274": {
    "title": "SeCo: Exploring Sequence Supervision for Unsupervised Representation Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "7b4741f8e6667664f1b21c390830b2022eca2da0",
    "citation_count": 60
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17275": {
    "title": "ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "20438e2a38a0c4723fbd9de50b44b7335f6f43cb",
    "citation_count": 99
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17276": {
    "title": "Improving Sample Efficiency in Model-Free Reinforcement Learning from Images",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "88dd6594c9ddd4c4bb7f9b407b162e283907f4f3",
    "citation_count": 201
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17277": {
    "title": "Task Cooperation for Semi-Supervised Few-Shot Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "ffa89c1bc4c853f87f84ceb6c354c64ead20b688",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17278": {
    "title": "Amata: An Annealing Mechanism for Adversarial Training Acceleration",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "085f82a273239242fd511037daf0a84e7e52810b",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17279": {
    "title": "Sequential Generative Exploration Model for Partially Observable Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "31d1cc6aa3a04bc524b40b089087c8ccffab35df",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17280": {
    "title": "Enhanced Audio Tagging via Multi- to Single-Modal Teacher-Student Mutual Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "900c91fac3dac1051cba81c08b9a337fa6820aef",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17281": {
    "title": "Image-to-Image Retrieval by Learning Similarity between Scene Graphs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2e0570df4e56d51be58b53166e853d848ef767af",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17282": {
    "title": "Learning Interpretable Models for Coupled Networks Under Domain Constraints",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "aae7a9c2c8a7ac351295026cca85251a87330fa3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17283": {
    "title": "Identity-aware Graph Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "44b9f16ba417b90e2e7c42f9074378dd06415809",
    "citation_count": 72
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17284": {
    "title": "How Does Data Augmentation Affect Privacy in Machine Learning?",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "590327cab07ae5d5fcc46e7f781b7223b6a92a3a",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17285": {
    "title": "DAST: Unsupervised Domain Adaptation in Semantic Segmentation Based on Discriminator Attention and Self-Training",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c411daf84fe2429437634ca90236b30e45389467",
    "citation_count": 29
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17286": {
    "title": "Any-Precision Deep Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "36562c6788e3d5c56ae5db738170ca32b04b6d50",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17287": {
    "title": "Personalized Adaptive Meta Learning for Cold-start User Preference Prediction",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "449e9f36d28c24a240f463b26abfda2dcf33ce17",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17288": {
    "title": "Measuring Dependence with Matrix-based Entropy Functional",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "efa10c8d7e628341997ab07a5feb99b03db4dc17",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17289": {
    "title": "Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "897937116ac0645e7d8f0d539b68545a6116191f",
    "citation_count": 67
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17290": {
    "title": "Knowledge-Guided Object Discovery with Acquired Deep Impressions",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "3b574ba610553a622e70877a2571b05a74aea595",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17291": {
    "title": "Curse or Redemption? How Data Heterogeneity Affects the Robustness of Federated Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "60153b7dddb861048f16ec07a9067c47261c6178",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17292": {
    "title": "Are Adversarial Examples Created Equal? A Learnable Weighted Minimax Risk for Robustness under Non-uniform Attacks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "eef656a1683e9ea18a40a3a858b085101a088d8d",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17293": {
    "title": "Contrastive Self-supervised Learning for Graph Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "2297049be3eb050bf4dbe27e353669f91702ff08",
    "citation_count": 52
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17294": {
    "title": "Data-driven Competitive Algorithms for Online Knapsack and Set Cover",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b0a3d2672d5a8f5370703861ea5d49d6436ab512",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17295": {
    "title": "A Hybrid Stochastic Gradient Hamiltonian Monte Carlo Method",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "1a1a797efaeaf78d065b105906170356348fcbb8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17296": {
    "title": "CloudLSTM: A Recurrent Neural Model for Spatiotemporal Point-cloud Stream Forecasting",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f6f5e8e057207dffa01363dae38b35037454d7a4",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17297": {
    "title": "Exploration by Maximizing Renyi Entropy for Reward-Free RL Framework",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0a58dedfa7dc8a2bf7b90a4de9e6000b54c2d55b",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17298": {
    "title": "Efficient Folded Attention for Medical Image Reconstruction and Segmentation",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "34c390f3cfa193d56537974af0910944b64c7226",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17299": {
    "title": "Interpreting Multivariate Shapley Interactions in DNNs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c996d77b109899ce22429ba02d7d59c74885349f",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17300": {
    "title": "Sample Efficient Reinforcement Learning with REINFORCE",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "305e04357a7e16292fad7248426e7cf4f51c93a9",
    "citation_count": 35
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17301": {
    "title": "Secure Bilevel Asynchronous Vertical Federated Learning with Backward Updating",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "05f689772fb1ae5a47b5089b2c38f9b53156d285",
    "citation_count": 29
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17302": {
    "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "11d558cf04914a19068338705526593fe7fb6cd3",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17303": {
    "title": "Deep Wasserstein Graph Discriminant Learning for Graph Classification",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f6ea57c9cea1a56150e25b1deb8b2031914f7855",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17304": {
    "title": "Treatment Effect Estimation with Disentangled Latent Factors",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a63b454f24967f9f3b77f4343e0e0b3d7702989e",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17305": {
    "title": "Regret Bounds for Online Kernel Selection in Continuous Kernel Space",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "afce7a70d647819db76e44632737a380d8a49874",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17306": {
    "title": "The Sample Complexity of Teaching by Reinforcement on Q-Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "33f4ce2451f3c4cd2ae8ffa6c33650460d1e920f",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17307": {
    "title": "Partial-Label and Structure-constrained Deep Coupled Factorization Network",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "e77f542230e003f92c9efa34794c8ecfc3e2df34",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17308": {
    "title": "Memory-Gated Recurrent Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "0d8ff0e190ca20c7158675312fc71cd75c6b5270",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17309": {
    "title": "Towards Enabling Learnware to Handle Unseen Jobs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f7122e126ca474442c462d12ebac1c434c4ab326",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17310": {
    "title": "Exploiting Unlabeled Data via Partial Label Assignment for Multi-Class Semi-Supervised Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "415bd000214f5b35cc5454bf3dabc9a206babe23",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17311": {
    "title": "Looking Wider for Better Adaptive Representation in Few-Shot Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "78cd8bcd57084d34e07ccb79f6ee25c02fd651f6",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17312": {
    "title": "Distilling Localization for Self-Supervised Representation Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "f9e9ddec468c1c240a1a8c192e74d485d97205bd",
    "citation_count": 32
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17313": {
    "title": "Exploratory Machine Learning with Unknown Unknowns",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "4a6488c432f6ba6cc5ca578ab12e10f7bd1f2ef1",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17314": {
    "title": "Efficient Classification with Adaptive KNN",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "d86b805219b9281fb091cbe1e5b0887018f14819",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17315": {
    "title": "Data Augmentation for Graph Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "27d5be9322d71b6fd2faa8a6b87250127a12c0cf",
    "citation_count": 144
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17316": {
    "title": "Augmenting Policy Learning with Routines Discovered from a Single Demonstration",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c9af30358358b15d05ce72a86ec5f0ce883afdc6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17317": {
    "title": "Improved Consistency Regularization for GANs",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "b31fdc82691b36e22b2ba15846a7a757061da4fa",
    "citation_count": 73
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17318": {
    "title": "Flow-based Generative Models for Learning Manifold to Manifold Mappings",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "5c5df399a570954be5985c3e38c2544f2bc3a9a1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17319": {
    "title": "Meta Label Correction for Noisy Label Learning",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "96c6f34594279844ca8fd901649fa06491ef822c",
    "citation_count": 52
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17320": {
    "title": "Going Deeper With Directly-Trained Larger Spiking Neural Networks",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "a31ca77b2c76c56775c3b75264f72879712058b4",
    "citation_count": 85
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17321": {
    "title": "Fully-Connected Tensor Network Decomposition and Its Application to Higher-Order Tensor Completion",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "515fc0f3f40d5f65135cb394cdc1f3cc7160a224",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17322": {
    "title": "How Does the Combined Risk Affect the Performance of Unsupervised Domain Adaptation Approaches?",
    "abstract": "",
    "volume": "main",
    "checked": true,
    "id": "c66aa46cdf3e748c4176c4c99bdc829ec31a0f29",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17323": {
    "title": "Multi-task Learning by Leveraging the Semantic Information",
    "abstract": "One crucial objective of multi-task learning is to align distributions across tasks so that the information between them can be transferred and shared. However, existing approaches only focused on matching the marginal feature distribution while ignoring the semantic information, which may hinder the learning performance. To address this issue, we propose to leverage the label information in multi-task learning by exploring the semantic conditional relations among tasks. We first theoretically analyze the generalization bound of multi-task learning based on the notion of Jensen-Shannon divergence, which provides new insights into the value of label information in multi-task learning. Our analysis also leads to a concrete algorithm that jointly matches the semantic distribution and controls label distribution divergence. To confirm the effectiveness of the proposed method, we first compare the algorithm with several baselines on some benchmarks and then test the algorithms under label space shift conditions. Empirical results demonstrate that the proposed method could outperform most baselines and achieve state-of-the-art performance, particularly showing the benefits under the label shift conditions",
    "volume": "main",
    "checked": true,
    "id": "8233ace0b3594482bf72adda98081755a0d890d4",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17324": {
    "title": "MetaAugment: Sample-Aware Data Augmentation Policy Learning",
    "abstract": "Automated data augmentation has shown superior performance in image recognition. Existing works search for dataset-level augmentation policies without considering individual sample variations, which are likely to be sub-optimal. On the other hand, learning different policies for different samples naively could greatly increase the computing cost. In this paper, we learn a sample-aware data augmentation policy efficiently by formulating it as a sample reweighting problem. Specifically, an augmentation policy network takes a transformation and the corresponding augmented image as inputs, and outputs a weight to adjust the augmented image loss computed by a task network. At training stage, the task network minimizes the weighted losses of augmented training images, while the policy network minimizes the loss of the task network on a validation set via meta-learning. We theoretically prove the convergence of the training procedure and further derive the exact convergence rate. Superior performance is achieved on widely-used benchmarks including CIFAR-10/100, Omniglot, and ImageNet",
    "volume": "main",
    "checked": true,
    "id": "951f0cd7a4b43623cb4ad7a4a6215ae0113eb0ab",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17325": {
    "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
    "abstract": "Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efficiently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to LSTF, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efficient transformer-based model for LSTF, named Informer, with three distinctive characteristics: (i) a ProbSparse self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, and has comparable performance on sequences' dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efficiently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer significantly outperforms existing methods and provides a new solution to the LSTF problem",
    "volume": "main",
    "checked": true,
    "id": "35a9749df07a2ab97c51af4d260b095b00da7676",
    "citation_count": 399
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17326": {
    "title": "Inverse Reinforcement Learning with Natural Language Goals",
    "abstract": "Humans generally use natural language to communicate task requirements to each other. Ideally, natural language should also be usable for communicating goals to autonomous machines (e.g., robots) to minimize friction in task specification. However, understanding and mapping natural language goals to sequences of states and actions is challenging. Specifically, existing work along these lines has encountered difficulty in generalizing learned policies to new natural language goals and environments. In this paper, we propose a novel adversarial inverse reinforcement learning algorithm to learn a language-conditioned policy and reward function. To improve generalization of the learned policy and reward function, we use a variational goal generator to relabel trajectories and sample diverse goals during training. Our algorithm outperforms multiple baselines by a large margin on a vision-based natural language instruction following dataset (Room-2-Room), demonstrating a promising advance in enabling the use of natural language instructions in specifying agent goals",
    "volume": "main",
    "checked": true,
    "id": "40848d6a0157d04e2d92576abe6923e8a6370108",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17327": {
    "title": "Tri-level Robust Clustering Ensemble with Multiple Graph Learning",
    "abstract": "Clustering ensemble generates a consensus clustering result by integrating multiple weak base clustering results. Although it often provides more robust results compared with single clustering methods, it still suffers from the robustness problem if it does not treat the unreliability of base results carefully. Conventional clustering ensemble methods often use all data for ensemble, while ignoring the noises or outliers on the data. Although some robust clustering ensemble methods are proposed, which extract the noises on the data, they still characterize the robustness in a single level, and thus they cannot comprehensively handle the complicated robustness problem. In this paper, to address this problem, we propose a novel Tri-level Robust Clustering Ensemble (TRCE) method by transforming the clustering ensemble problem to a multiple graph learning problem. Just as its name implies, the proposed method tackles robustness problem in three levels: base  clustering level, graph level and instance level. By considering the robustness problem in a more comprehensive way, the proposed TRCE can achieve a more robust consensus clustering result. Experimental results on benchmark datasets also demonstrate it. Our method often outperforms other state-of-the-art clustering ensemble methods. Even compared with the robust ensemble methods, ours also performs better",
    "volume": "main",
    "checked": true,
    "id": "661ffe3fcb3ca15e33b038841c4a3fb4d80a3ff1",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17328": {
    "title": "Fairness in Forecasting and Learning Linear Dynamical Systems",
    "abstract": "In machine learning, training data often capture the behaviour of multiple subgroups of some underlying human population.  When the amounts of training data for the subgroups are not controlled carefully, under-representation bias arises.  We introduce two natural notions of subgroup fairness and instantaneous fairness to address such under-representation bias in time-series forecasting problems.  In particular, we consider the subgroup-fair and instant-fair learning of a linear dynamical system (LDS) from multiple trajectories of varying lengths and the associated forecasting problems.  We provide globally convergent methods for the learning problems using hierarchies of convexifications of non-commutative polynomial optimisation problems.   Our empirical results on a biased data set motivated by insurance applications and the well-known COMPAS data set demonstrate both the beneficial impact of fairness considerations on statistical performance and the encouraging effects of exploiting sparsity on run time",
    "volume": "main",
    "checked": true,
    "id": "14abedc428a06f596e810fd5a6bcdea1ff28fc19",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17329": {
    "title": "Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust Performance",
    "abstract": "Spiking neural network (SNN) is promising but the development has fallen far behind conventional deep neural networks (DNNs) because of difficult training. To resolve the training problem, we analyze the closed-form input-output response of spiking neurons and use the response expression to build abstract SNN models for training. This avoids calculating membrane potential during training and makes the direct training of SNN as efficient as DNN. We show that the nonleaky integrate-and-fire neuron with single-spike temporal-coding is the best choice for direct-train deep SNNs. We develop an energy-efficient phase-domain signal processing circuit for the neuron and propose a direct-train deep SNN framework. Thanks to easy training, we train deep SNNs under weight quantizations to study their robustness over low-cost neuromorphic hardware. Experiments show that our direct-train deep SNNs have the highest CIFAR-10 classification accuracy among SNNs, achieve ImageNet classification accuracy within 1% of the DNN of equivalent architecture, and are robust to weight quantization and noise perturbation",
    "volume": "main",
    "checked": true,
    "id": "396964033168f89b460fad047b3279926340b3ca",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17330": {
    "title": "Local Differential Privacy for Bayesian Optimization",
    "abstract": "Motivated by the increasing concern about privacy in nowadays data-intensive online learning systems, we consider a black-box optimization in the nonparametric Gaussian process setting with local differential privacy (LDP) guarantee. Specifically, the rewards from each user are further corrupted to protect privacy and the learner only has access to the corrupted rewards to minimize the regret. We first derive the regret lower bounds for any LDP mechanism and any learning algorithm. Then, we present three almost optimal algorithms based on the GP-UCB framework and Laplace DP mechanism. In this process, we also propose a new Bayesian optimization (BO) method (called MoMA-GP-UCB) based on median-of-means techniques and kernel approximations, which complements previous BO algorithms under heavy-tailed payoffs with reduced complexity. Further, empirical comparisons of different algorithms on both synthetic and real-world datasets highlight the superior performance of MoMA-GP-UCB in both private and non-private scenarios",
    "volume": "main",
    "checked": true,
    "id": "6fcf884343bfac0d4680133b51c558c6a4e0bf35",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17331": {
    "title": "A Primal-Dual Online Algorithm for Online Matching Problem in Dynamic Environments",
    "abstract": "Recently, the online matching problem has attracted much attention due to its wide application on real-world decision-making scenarios. In stationary environments, by adopting the stochastic user arrival model, existing methods are proposed to learn dual optimal prices and are shown to achieve a fast regret bound. However, the stochastic model is no longer a proper assumption when the environment is changing, leading to an optimistic method that may suffer poor performance. In this paper, we study the online matching problem in dynamic environments in which the dual optimal prices are allowed to vary over time. We bound the dynamic regret of online matching problem by the sum of two quantities, including a regret of online max-min problem and a dynamic regret of online convex optimization (OCO) problem. Then we propose a novel online approach named Primal-Dual Online Algorithm (PDOA) to minimize both quantities. In particular, PDOA adopts the primal-dual framework by optimizing dual prices with the online gradient descent (OGD) algorithm to eliminate the online max-min problem's regret. Moreover, it maintains a set of OGD experts and combines them via an expert-tracking algorithm, which gives a sublinear dynamic regret bound for the OCO problem. We show that PDOA achieves an O(K sqrt{T(1+P_T)}) dynamic regret where K is the number of resources, T is the number of iterations and P_T is the path-length of any potential dual price sequence that reflects the dynamic environment. Finally, experiments on real applications exhibit the superiority of our approach",
    "volume": "main",
    "checked": true,
    "id": "b2c738ba34e5e6e446e10748495f96865e53b848",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17332": {
    "title": "Graph Neural Networks with Heterophily",
    "abstract": "Graph Neural Networks (GNNs) have proven to be useful for many different practical applications. However, many existing GNN models have implicitly assumed homophily among the nodes connected in the graph, and therefore have largely overlooked the important setting of heterophily, where most connected nodes are from different classes. In this work, we propose a novel framework called CPGNN that generalizes GNNs for graphs with either homophily or heterophily. The proposed framework incorporates an interpretable compatibility matrix for modeling the heterophily or homophily level in the graph, which can be learned in an end-to-end fashion, enabling it to go beyond the assumption of strong homophily. Theoretically, we show that replacing the compatibility matrix in our framework with the identity (which represents pure homophily) reduces to GCN. Our extensive experiments demonstrate the effectiveness of our approach in more realistic and challenging experimental settings with significantly less training data compared to previous works: CPGNN variants achieve state-of-the-art results in heterophily settings with or without contextual node features, while maintaining comparable performance in homophily settings",
    "volume": "main",
    "checked": true,
    "id": "33b75e9094968c060238d54f1026dbc3c8ab66f7",
    "citation_count": 73
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17333": {
    "title": "Bias and Variance of Post-processing in Differential Privacy",
    "abstract": "Post-processing immunity is a fundamental property of differential  privacy: it enables the application of arbitrary data-independent   transformations to the results of differentially private outputs   without affecting their privacy guarantees.   When query outputs must satisfy domain constraints, post-processing   can be used to project them back onto the feasibility region.   Moreover, when the feasible region is convex, a widely adopted class of post-processing steps is also guaranteed to improve accuracy. Post-processing has   been applied successfully in many applications including census   data, energy systems, and mobility. However, its effects on the   noise distribution is poorly understood: It is often argued that   post-processing may introduce bias and increase variance. This paper   takes a first step towards understanding the properties of   post-processing. It considers the release of census data and   examines, both empirically and theoretically, the behavior of a   widely adopted class of post-processing functions",
    "volume": "main",
    "checked": true,
    "id": "cdd9f0bfb13105ad20514cc6ed60a575d4f311ba",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17334": {
    "title": "Self-correcting Q-learning",
    "abstract": "The Q-learning algorithm is known to be affected by the maximization bias, i.e. the systematic overestimation of action values, an important issue that has recently received renewed attention. Double Q-learning has been proposed as an efficient algorithm to mitigate this bias. However, this comes at the price of an underestimation of action values, in addition to increased memory requirements and a slower convergence.  In this paper, we introduce a new way to address the maximization bias in the form of a \"self-correcting algorithm\" for approximating the maximum of an expected value. Our method balances the overestimation of the single estimator used in conventional Q-learning and the underestimation of the double estimator used in Double Q-learning. Applying this strategy to Q-learning results in Self-correcting Q-learning. We show theoretically that this new algorithm enjoys the same convergence guarantees as Q-learning while being more accurate. Empirically, it performs better than Double Q-learning in domains with rewards of high variance, and it even attains faster convergence than Q-learning in domains with rewards of zero or low variance. These advantages transfer to a Deep Q Network implementation that we call Self-correcting DQN and which outperforms regular DQN and Double DQN on several tasks in the Atari 2600 domain",
    "volume": "main",
    "checked": true,
    "id": "b4e343afbf23f6e6671861ac2b676f843866f5a8",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17335": {
    "title": "An Efficient Algorithm for Deep Stochastic Contextual Bandits",
    "abstract": "In stochastic contextual bandit (SCB) problems, an agent selects an action based on certain observed context to maximize the cumulative reward over iterations. Recently there have been a few studies using a deep neural network (DNN) to predict the expected reward for an action, and the DNN is trained by a stochastic gradient based method. However, convergence analysis has been greatly ignored to examine whether and where these methods converge. In this work, we formulate the SCB that uses a DNN reward function as a non-convex stochastic optimization problem, and design a stage-wise stochastic gradient descent algorithm to optimize the problem and determine the action policy. We prove that with high probability, the action sequence chosen by this algorithm converges to a greedy action policy respecting a local optimal reward function. Extensive experiments have been performed to demonstrate the effectiveness and efficiency of the proposed algorithm on multiple real-world datasets",
    "volume": "main",
    "checked": true,
    "id": "31be2191f11491128bc35069e31a7693deb707e2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17336": {
    "title": "Variational Fair Clustering",
    "abstract": "We propose a general variational framework of fair clustering, which integrates an original Kullback-Leibler (KL) fairness term with a large class of clustering objectives, including prototype or graph based. Fundamentally different from the existing combinatorial and spectral solutions, our variational multi-term approach enables to control the trade-off levels between the fairness and clustering objectives. We derive a general tight upper bound based on a concave-convex decomposition of our fairness term, its Lipschitz-gradient property and the Pinskers inequality. Our tight upper bound can be jointly optimized with various clustering objectives, while yielding a scalable solution, with convergence guarantee. Interestingly, at each iteration, it performs an independent update for each assignment variable. Therefore, it can be easily distributed for large-scale datasets. This scalability is important as it enables to explore different trade-off levels between the fairness and clustering objectives. Unlike spectral relaxation, our formulation does not require computing its eigenvalue decomposition. We report comprehensive evaluations and comparisons with state-of-the-art methods over various fair clustering benchmarks, which show that our variational formulation can yield highly competitive solutions in terms of fairness and clustering objectives",
    "volume": "main",
    "checked": true,
    "id": "0bd3aefd036cdd59186011a7cd2ae80c6173805c",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17337": {
    "title": "Learning Task-Distribution Reward Shaping with Meta-Learning",
    "abstract": "Reward shaping is one of the most effective methods to tackle the crucial yet challenging problem of credit assignment and accelerate Reinforcement Learning. However, designing shaping functions usually requires rich expert knowledge and hand-engineering, and the difficulties are further exacerbated given multiple tasks to solve. In this paper, we consider reward shaping on a distribution of tasks that share state spaces but not necessarily action spaces. We provide insights into optimal reward shaping, and propose a novel meta-learning framework to automatically learn such reward shaping to apply on newly sampled tasks. Theoretical analysis and extensive experiments establish us as the state-of-the-art in learning task-distribution reward shaping, outperforming previous such works (Konidaris and Barto 2006; Snel and Whiteson 2014). We further show that our method outperforms learning intrinsic rewards (Yang et al. 2019; Zheng et al. 2020), outperforms Rainbow (Hessel et al. 2018) in complex pixel-based CoinRun games, and is also better than hand-designed reward shaping on grids. While the goal of this paper is to learn reward shaping rather than to propose new general meta-learning algorithms as PEARL (Rakelly et al. 2019) or MQL (Fakoor et al. 2020), our framework based on MAML (Finn, Abbeel, and Levine 2017) also outperforms PEARL / MQL, and could combine with them for further improvement",
    "volume": "main",
    "checked": true,
    "id": "30a41fffb0138af4c8dfab7f5f92fb3c9ea427ad",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17338": {
    "title": "Improving Continuous-time Conflict Based Search",
    "abstract": "Conflict-Based Search (CBS) is a powerful algorithmic framework for optimally solving classical multi-agent path finding (MAPF) problems, where time is discretized into the time steps. Continuous-time CBS (CCBS) is a recently proposed version of CBS that guarantees optimal solutions without the need to discretize time. However, the scalability of CCBS is limited because it does not include any known improvements of CBS. In this paper, we begin to close this gap and explore how to adapt successful CBS improvements, namely, prioritizing conflicts (PC), disjoint splitting (DS), and high-level heuristics, to the continuous time setting of CCBS. These adaptions are not trivial, and require careful handling of different types of constraints, applying a generalized version of the Safe interval path planning (SIPP) algorithm, and extending the notion of cardinal conflicts. We evaluate the effect of the suggested enhancements by running experiments both on general graphs and 2^k-neighborhood grids. CCBS with these improvements significantly outperforms vanilla CCBS, solving problems with almost twice as many agents in some cases and pushing the limits of multi-agent path finding in continuous-time domains",
    "volume": "main",
    "checked": true,
    "id": "28717af484aebd6e172db0b1a18d358275dbdcd4",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17339": {
    "title": "Inference-Based Deterministic Messaging For Multi-Agent Communication",
    "abstract": "Communication is essential for coordination among humans and animals. Therefore, with the introduction of intelligent agents into the world, agent-to-agent and agent-to-human communication becomes necessary. In this paper, we first study learning in matrix-based signaling games to empirically show that decentralized methods can converge to a suboptimal policy. We then propose a modification to the messaging policy, in which the sender deterministically chooses the best message that helps the receiver to infer the sender's observation. Using this modification, we see, empirically, that the agents converge to the optimal policy in nearly all the runs. We then apply this method to a partially observable gridworld environment which requires cooperation between two agents and show that, with appropriate approximation methods, the proposed sender modification can enhance existing decentralized training methods for more complex domains as well",
    "volume": "main",
    "checked": true,
    "id": "dae58679fd79f9abc240d885ada7020a30e91509",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17340": {
    "title": "Scalable and Safe Multi-Agent Motion Planning with Nonlinear Dynamics and Bounded Disturbances",
    "abstract": "We present a scalable and effective multi-agent safe motion planner that enables a group of agents to move to their desired locations while avoiding collisions with obstacles and other agents, with the presence of rich obstacles, high-dimensional, nonlinear, nonholonomic dynamics, actuation limits, and disturbances. We address this problem by finding a piecewise linear path for each agent such that the actual trajectories following these paths are guaranteed to satisfy the reach-and-avoid requirement. We show that the spatial tracking error of the actual trajectories of the controlled agents can be pre-computed for any qualified path that considers the minimum duration of each path segment due to actuation limits. Using these bounds, we find a collision-free path for each agent by solving Mixed Integer-Linear Programs and coordinate agents by using the priority-based search. We demonstrate our method by benchmarking in 2D and 3D scenarios with ground vehicles and quadrotors, respectively, and show improvements over the solving time and the solution quality compared to two state-of-the-art multi-agent motion planners",
    "volume": "main",
    "checked": true,
    "id": "62a90d3f5f2a607faa182f5aa51cb83954191ce9",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17341": {
    "title": "Learning to Resolve Conflicts for Multi-Agent Path Finding with Conflict-Based Search",
    "abstract": "Conflict-Based Search (CBS) is a state-of-the-art algorithm for multi-agent path finding. On the high level, CBS repeatedly detects conflicts and resolves one of them by splitting the current problem into two subproblems. Previous work chooses the conflict to resolve by categorizing conflicts into three classes and always picking one from the highest-priority class. In this work, we propose an oracle for conflict selection that results in smaller search tree sizes than the one used in previous work. However, the computation of the oracle is slow. Thus, we propose a machine-learning (ML) framework for conflict selection that observes the decisions made by the oracle and learns a conflict-selection strategy represented by a linear ranking function that imitates the oracle's decisions accurately and quickly. Experiments on benchmark maps indicate that our approach, ML-guided CBS, significantly improves the success rates, search tree sizes and runtimes of the current state-of-the-art CBS solver",
    "volume": "main",
    "checked": true,
    "id": "c6a24e9ef8d78128c78406dd33597ad080ce2772",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17342": {
    "title": "The Influence of Memory in Multi-Agent Consensus",
    "abstract": "Multi-agent consensus problems can often be seen as a sequence of autonomous and independent local choices between a finite set of decision options, with each local choice undertaken simultaneously, and with a shared goal of achieving a global consensus state. Being able to estimate probabilities for the different outcomes and to predict how long it takes for a consensus to be formed, if ever, are core issues for such protocols. Little attention has been given to protocols in which agents can remember past or outdated states. In this paper, we propose a framework to study what we call `memory consensus protocol'. We show that the employment of memory allows such processes to always converge, as well as, in some scenarios, such as cycles, converge faster. We provide a theoretical analysis of the probability of each option eventually winning such processes based on the initial opinions expressed by agents. Further, we perform experiments to investigate network topologies in which agents benefit from memory on the expected time needed for consensus",
    "volume": "main",
    "checked": true,
    "id": "91fb87478890a563e22a3eb78635969262045e9f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17343": {
    "title": "Exploration-Exploitation in Multi-Agent Learning: Catastrophe Theory Meets Game Theory",
    "abstract": "Exploration-exploitation is a powerful and practical tool in multi-agent learning (MAL), however, its effects are far from understood. To make progress in this direction, we study a smooth analogue of Q-learning. We start by showing that our learning model has strong theoretical justification as an optimal model for studying exploration-exploitation. Specifically, we prove that smooth Q-learning has bounded regret in arbitrary games for a cost model that explicitly captures the balance between game and exploration costs and that it always converges to the set of quantal-response equilibria (QRE), the standard solution concept for games under bounded rationality, in weighted potential games with heterogeneous learning agents. In our main task, we then turn to measure the effect of exploration in collective system performance. We characterize the geometry of the QRE surface in low-dimensional MAL systems and link our findings with catastrophe (bifurcation) theory. In particular, as the exploration hyperparameter evolves over-time, the system undergoes phase transitions where the number and stability of equilibria can change radically given an infinitesimal change to the exploration parameter. Based on this, we provide a formal theoretical treatment of how tuning the exploration parameter can provably lead to equilibrium selection with both positive as well as negative (and potentially unbounded) effects to system performance.",
    "volume": "main",
    "checked": true,
    "id": "6ddc6b09d3da565fa75b5e08c581fb2f71b8638b",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17344": {
    "title": "Lifelong Multi-Agent Path Finding in Large-Scale Warehouses",
    "abstract": "Multi-Agent Path Finding (MAPF) is the problem of moving a team of agents to their goal locations without collisions. In this paper, we study the lifelong variant of MAPF, where agents are constantly engaged with new goal locations, such as in large-scale automated warehouses. We propose a new framework Rolling-Horizon Collision Resolution (RHCR) for solving lifelong MAPF by decomposing the problem into a sequence of Windowed MAPF instances, where a Windowed MAPF solver resolves collisions among the paths of the agents only within a bounded time horizon and ignores collisions beyond it. RHCR is particularly well suited to generating pliable plans that adapt to continually arriving new goal locations. We empirically evaluate RHCR with a variety of MAPF solvers and show that it can produce high-quality solutions for up to 1,000 agents (= 38.9% of the empty cells on the map) for simulated warehouse instances, significantly outperforming existing work",
    "volume": "main",
    "checked": true,
    "id": "dc6219278e481591b478904a755fbcb1db675399",
    "citation_count": 53
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17345": {
    "title": "Dec-SGTS: Decentralized Sub-Goal Tree Search for Multi-Agent Coordination",
    "abstract": "Multi-agent coordination tends to benefit from efficient communication, where cooperation often happens based on exchanging information about what the agents intend to do, i.e. intention sharing. It becomes a key problem to model the intention by some proper abstraction. Currently, it is either too coarse such as final goals or too fined as primitive steps, which is inefficient due to the lack of modularity and semantics. In this paper, we design a novel multi-agent coordination protocol based on subgoal intentions, defined as the probability distribution over feasible subgoal sequences. The subgoal intentions encode macro-action behaviors with modularity so as to facilitate joint decision making at higher abstraction. Built over the proposed protocol, we present Dec-SGTS (Decentralized Sub-Goal Tree Search) to solve decentralized online multi-agent planning hierarchically and efficiently. Each agent runs Dec-SGTS asynchronously by iteratively performing three phases including local sub-goal tree search, local subgoal intention update and global subgoal intention sharing. We conduct the experiments on courier dispatching problem, and the results show that Dec-SGTS achieves much better reward while enjoying a significant reduction of planning time and communication cost compared with Dec-MCTS (Decentralized Monte Carlo Tree Search)",
    "volume": "main",
    "checked": true,
    "id": "0ec809a051293a0a39b23a26403412ed8b73ab3e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17346": {
    "title": "Expected Value of Communication for Planning in Ad Hoc Teamwork",
    "abstract": "A desirable goal for autonomous agents is to be able to coordinate on the fly with previously unknown teammates. Known as \"ad hoc teamwork\", enabling such a capability has been receiving increasing attention in the research community. One of the central challenges in ad hoc teamwork is quickly recognizing the current plans of other agents and planning accordingly. In this paper, we focus on the scenario in which teammates can communicate with one another, but only at a cost. Thus, they must carefully balance plan recognition based on observations vs. that based on communication.This paper proposes a new metric for evaluating how similar are two policies that a teammate may be following - the Expected Divergence Point (EDP).   We then present a novel planning algorithm for ad hoc teamwork, determining which query to ask and planning accordingly. We demonstrate the effectiveness of this algorithm in a range of increasingly general communication in ad hoc teamwork problems",
    "volume": "main",
    "checked": true,
    "id": "347c796de71a86724354c751bd95f6df9eaa4d6d",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17347": {
    "title": "Time-Independent Planning for Multiple Moving Agents",
    "abstract": "Typical Multi-agent Path Finding (MAPF) solvers assume that agents move synchronously, thus neglecting the reality gap in timing assumptions, e.g., delays caused by an imperfect execution of asynchronous moves. So far, two policies enforce a robust execution of MAPF plans taken as input: either by forcing agents to synchronize or by executing plans while preserving temporal dependencies. This paper proposes an alternative approach, called time-independent planning, which is both online and distributed. We represent reality as a transition system that changes configurations according to atomic actions of agents, and use it to generate a time-independent schedule. Empirical results in a simulated environment with stochastic delays of agents' moves support the validity of our proposal",
    "volume": "main",
    "checked": true,
    "id": "1cd62f72f0854a7ff9ffd577754ab09cd7a208b5",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17348": {
    "title": "Resilient Multi-Agent Reinforcement Learning with Adversarial Value Decomposition",
    "abstract": "We focus on resilience in cooperative multi-agent systems, where agents can change their behavior due to udpates or failures of hardware and software components. Current state-of-the-art approaches to cooperative multi-agent reinforcement learning (MARL) have either focused on idealized settings without any changes or on very specialized scenarios, where the number of changing agents is fixed, e.g., in extreme cases with only one productive agent. Therefore, we propose Resilient Adversarial value Decomposition with Antagonist-Ratios (RADAR). RADAR offers a value decomposition scheme to train competing teams of varying size for improved resilience against arbitrary agent changes. We evaluate RADAR in two cooperative multi-agent domains and show that RADAR achieves better worst case performance w.r.t. arbitrary agent changes than state-of-the-art MARL",
    "volume": "main",
    "checked": true,
    "id": "a4ceb935b4adf688e580d5ca23d4380c04a29789",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17349": {
    "title": "Anytime Heuristic and Monte Carlo Methods for Large-Scale Simultaneous Coalition Structure Generation and Assignment",
    "abstract": "Optimal simultaneous coalition structure generation and assignment is computationally hard. The state-of-the-art can only compute solutions to problems with severely limited input sizes, and no effective approximation algorithms that are guaranteed to yield high-quality solutions are expected to exist. Real-world optimization problems, however, are often characterized by large-scale inputs and the need for generating feasible solutions of high quality in limited time. In light of this, and to make it possible to generate better feasible solutions for difficult large-scale problems efficiently, we present and benchmark several different anytime algorithms that use general-purpose heuristics and Monte Carlo techniques to guide search. We evaluate our methods using synthetic problem sets of varying distribution and complexity. Our results show that the presented algorithms are superior to previous methods at quickly generating near-optimal solutions for small-scale problems, and greatly superior for efficiently finding high-quality solutions for large-scale problems. For example, for problems with a thousand agents and values generated with a uniform distribution, our best approach generates solutions 99.5% of the expected optimal within seconds. For these problems, the state-of-the-art solvers fail to find any feasible solutions at all",
    "volume": "main",
    "checked": true,
    "id": "5bba703b175d20a39b0ed8bd99e11c1bf981c2ba",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17350": {
    "title": "Newton Optimization on Helmholtz Decomposition for Continuous Games",
    "abstract": "Many learning problems involve multiple agents optimizing different interactive functions. In these problems, the standard policy gradient algorithms fail due to the non-stationarity of the setting and the different interests of each agent. In fact, algorithms must take into account the complex dynamics of these systems to guarantee rapid convergence towards a (local) Nash equilibrium. In this paper, we propose NOHD (Newton Optimization on Helmholtz Decomposition), a Newton-like algorithm for multi-agent learning problems based on the decomposition of the dynamics of the system in its irrotational (Potential) and solenoidal (Hamiltonian) component. This method ensures quadratic convergence in purely irrotational systems and pure solenoidal systems. Furthermore, we show that NOHD is attracted to stable fixed points in general multi-agent systems and repelled by strict saddle ones. Finally, we empirically compare the NOHD's performance with that of state-of-the-art algorithms on some bimatrix games and continuous Gridworlds environment",
    "volume": "main",
    "checked": true,
    "id": "964d83cc4da6ef9b60c33e32495fbbe3ee13596e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17351": {
    "title": "Synchronous Dynamical Systems on Directed Acyclic Graphs: Complexity and Algorithms",
    "abstract": "Discrete dynamical systems serve as useful formal models to study  diffusion phenomena in social networks. Motivated by applications  in systems biology, several recent papers have studied algorithmic  and complexity aspects of diffusion problems for dynamical systems  whose underlying graphs are directed, and may contain directed  cycles. Such problems can be regarded as reachability problems in  the phase space of the corresponding dynamical system. We show that  computational intractability results for reachability problems hold  even for dynamical systems on directed acyclic graphs (dags). We  also show that for dynamical systems on dags where each local  function is monotone, the reachability problem can be solved  efficiently",
    "volume": "main",
    "checked": true,
    "id": "2b30ab422207a740a11fd278957b2db6f61abc27",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17352": {
    "title": "Evolutionary Game Theory Squared: Evolving Agents in Endogenously Evolving Zero-Sum Games",
    "abstract": "The predominant paradigm in evolutionary game theory and more generally online learning in games is based on a clear distinction between a population of dynamic agents that interact given a fixed, static game. In this paper, we move away from the artificial divide between dynamic agents and static games, to introduce and analyze a large class of competitive settings where both the agents and the games they play evolve strategically over time. We focus on arguably the most archetypal game-theoretic setting---zero-sum games (as well as network generalizations)---and the most studied evolutionary learning dynamic---replicator, the continuous-time analogue of multiplicative weights. Populations of agents compete against each other in a zero-sum competition that itself evolves adversarially to the current population mixture. Remarkably, despite the chaotic coevolution of agents and games, we prove that the system exhibits a number of regularities. First, the system has conservation laws of an information-theoretic flavor that couple the behavior of all agents and games. Secondly, the system is Poincare recurrent, with effectively all possible initializations of agents and games lying on recurrent orbits that come arbitrarily close to their initial conditions infinitely often. Thirdly, the time-average agent behavior and utility converge to the Nash equilibrium values of the time-average game. Finally, we provide a polynomial time algorithm to efficiently predict this time-average behavior for any such coevolving network game",
    "volume": "main",
    "checked": true,
    "id": "1410f7d9470a24fb4055c6685c2dda758b9d995f",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17353": {
    "title": "Value-Decomposition Multi-Agent Actor-Critics",
    "abstract": "The exploitation of extra state information has been an active research area in multi-agent reinforcement learning (MARL). QMIX represents the joint action-value using a non-negative function approximator and achieves the best performance on the StarCraft II micromanagement testbed, a common MARL benchmark. However, our experiments demonstrate that, in some cases, QMIX performs sub-optimally with the A2C framework, a training paradigm that promotes algorithm training efficiency. To obtain a reasonable trade-off between training efficiency and algorithm performance, we extend value-decomposition to actor-critic methods that are compatible with A2C and propose a novel actor-critic framework, value-decomposition actor-critic (VDAC). We evaluate VDAC on the StarCraft II micromanagement task and demonstrate that the proposed framework improves median performance over other actor-critic methods. Furthermore, we use a set of ablation experiments to identify the key factors that contribute to the performance of VDAC",
    "volume": "main",
    "checked": true,
    "id": "a69482d66ae75bcae753b48a1e1be9c59ceb563c",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17354": {
    "title": "Contract-based Inter-user Usage Coordination in Free-floating Car Sharing",
    "abstract": "We propose a novel distributed user-car matching method based on a contract between users to mitigate the imbalance problem between vehicle distribution and demand in free-floating car sharing. Previous regulation methods involved an incentive system based on the predictions of origin-destination (OD) demand obtained from past usage history. However, the difficulty these methods have in obtaining accurate data limits their applicability. To overcome this drawback, we introduce contract-based coordination among drop-off and pick-up users in which an auction is conducted for drop-off users' intended drop-off locations. We theoretically analyze the proposed method regarding the upper bound of its efficiency. We also compare it with a baseline method and non-regulation scenario on a free-floating car-sharing simulator. The experimental results show that the proposed method achieves a higher social surplus than the existing method",
    "volume": "main",
    "checked": true,
    "id": "6e7033b6e9766dbdc363aa0eeee10c4133e88e30",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17355": {
    "title": "Maintenance of Social Commitments in Multiagent Systems",
    "abstract": "We introduce and formalize a concept of a maintenance commitment, a kind of social commitment characterized by states whose truthhood an agent commits to maintain. This concept of maintenance commitments enables us to capture a richer variety of real-world scenarios than possible using achievement commitments with a temporal condition. By developing a rule-based operational semantics, we study the relationship between agents' achievement and maintenance goals, achievement commitments, and maintenance commitments. We motivate a notion of coherence which captures alignment between an agents' achievement and maintenance cognitive and social constructs, and prove that, under specified conditions, the goals and commitments of both rational agents individually and of a multiagent system are coherent",
    "volume": "main",
    "checked": true,
    "id": "3afe7dacf6e0c8ca7b9197f78858140838adee91",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17356": {
    "title": "Efficient Querying for Cooperative Probabilistic Commitments",
    "abstract": "Multiagent systems can use commitments as the core of a general coordination infrastructure, supporting both cooperative and non-cooperative interactions. Agents whose objectives are aligned, and where one agent can help another achieve greater reward by sacrificing some of its own reward, should choose a cooperative commitment to maximize their joint reward. We present a solution to the problem of how cooperative agents can efficiently find an (approximately) optimal commitment by querying about carefully-selected commitment choices. We prove structural properties of the agents' values as functions of the parameters of the commitment specification, and develop a greedy method for composing a query with provable approximation bounds, which we empirically show can find nearly optimal commitments in a fraction of the time methods that lack our insights require",
    "volume": "main",
    "checked": true,
    "id": "d463e84df408027719b643e954cd08f85239685c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17357": {
    "title": "Coordination Between Individual Agents in Multi-Agent Reinforcement Learning",
    "abstract": "The existing multi-agent reinforcement learning methods (MARL) for determining the coordination between agents focus on either global-level or neighborhood-level coordination between agents. However the problem of coordination between individual agents is remain to be solved. It is crucial for learning an optimal coordinated policy in unknown multi-agent environments to analyze the agent's roles and the correlation between individual agents. To this end, in this paper we propose an agent-level coordination based MARL method. Specifically, it includes two parts in our method. The first is correlation analysis between individual agents based on the Pearson, Spearman, and Kendall correlation coefficients; And the second is an agent-level coordinated training framework where the communication message between weakly correlated agents is dropped out, and a correlation based reward function is built. The proposed method is verified in four mixed cooperative-competitive environments. The experimental results show that the proposed method outperforms the state-of-the-art MARL methods and can measure the correlation between individual agents accurately",
    "volume": "main",
    "checked": true,
    "id": "aca91d1d11ed25602d149e90b565447f118bd12e",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17358": {
    "title": "Explaining A Black-box By Using A Deep Variational Information Bottleneck Approach",
    "abstract": "Interpretable machine learning has gained much attention recently. Briefness and comprehensiveness are necessary in order to provide a large amount of information concisely when explaining a black-box decision system. However, existing interpretable machine learning methods fail to consider briefness and comprehensiveness simultaneously, leading to redundant explanations. We propose the variational information bottleneck for interpretation, VIBI, a system-agnostic interpretable method that provides a brief but comprehensive explanation. VIBI adopts an information theoretic principle, information bottleneck principle, as a criterion for finding such explanations. For each instance, VIBI selects key features that are maximally compressed about an input (briefness), and informative about a decision made by a black-box system on that input (comprehensive). We evaluate VIBI on three datasets and compare with state-of-the-art interpretable machine learning methods in terms of both interpretability and fidelity evaluated by human and quantitative metrics",
    "volume": "main",
    "checked": true,
    "id": "4817e568d9710a497bde7b0ae65c8bf0882ec12b",
    "citation_count": 42
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17359": {
    "title": "Is the Most Accurate AI the Best Teammate? Optimizing AI for Teamwork",
    "abstract": "AI practitioners typically strive to develop the most accurate systems, making an implicit assumption that the AI system will function autonomously. However, in practice, AI systems often are used to provide advice to people in domains ranging from criminal justice and finance to healthcare. In such AI-advised decision making, humans and machines form a team, where the human is responsible for making final decisions. But is the most accurate AI the best teammate? We argue \"not necessarily\" --- predictable performance may be worth a slight sacrifice in AI accuracy. Instead, we argue that AI systems should be trained in a human-centered manner, directly optimized for team performance. We study this proposal for a specific type of human-AI teaming, where the human overseer chooses to either accept the AI recommendation or solve the task themselves. To optimize the team performance for this setting we maximize the team's expected utility, expressed in terms of the quality of the final decision, cost of verifying, and individual accuracies of people and machines. Our experiments with linear and non-linear models on real-world, high-stakes datasets show that the most accuracy AI may not lead to highest team performance and show the benefit of modeling teamwork during training through improvements in expected team utility across datasets, considering parameters such as human skill and the cost of mistakes. We discuss the shortcoming of current optimization approaches beyond well-studied loss functions such as log-loss, and encourage future work on AI optimization problems motivated by human-AI collaboration",
    "volume": "main",
    "checked": true,
    "id": "198838f8b7b504c04214fffb8646d11c6152ba5e",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17360": {
    "title": "TripleTree: A Versatile Interpretable Representation of Black Box Agents and their Environments",
    "abstract": "In explainable artificial intelligence, there is increasing interest in understanding the behaviour of autonomous agents to build trust and validate performance. Modern agent architectures, such as those trained by deep reinforcement learning, are currently so lacking in interpretable structure as to effectively be black boxes, but insights may still be gained from an external, behaviourist perspective. Inspired by conceptual spaces theory, we suggest that a versatile first step towards general understanding is to discretise the state space into convex regions, jointly capturing similarities over the agent's action, value function and temporal dynamics within a dataset of observations. We create such a representation using a novel variant of the CART decision tree algorithm, and demonstrate how it facilitates practical understanding of black box agents through prediction, visualisation and rule-based explanation",
    "volume": "main",
    "checked": true,
    "id": "de70a19dfbe56258149eae5b2e7a6c230c91071c",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17361": {
    "title": "Bayes-TrEx: a Bayesian Sampling Approach to Model Transparency by Example",
    "abstract": "Post-hoc explanation methods are gaining popularity for interpreting, understanding, and debugging neural networks. Most analyses using such methods explain decisions in response to inputs drawn from the test set. However, the test set may have few   examples that trigger some model behaviors, such as high-confidence failures or ambiguous classifications. To address these challenges, we introduce a flexible model inspection framework: Bayes-TrEx. Given a data distribution, Bayes-TrEx finds in-distribution examples which trigger a specified prediction confidence. We demonstrate several use cases of Bayes-TrEx, including revealing highly confident (mis)classifications, visualizing class boundaries via ambiguous examples, understanding novel-class extrapolation behavior, and exposing neural network overconfidence. We use Bayes-TrEx to study classifiers trained on CLEVR, MNIST, and Fashion-MNIST, and we show that this framework enables more flexible holistic model analysis than just inspecting the test set. Code and supplemental material are available at https://github.com/serenabooth/Bayes-TrEx",
    "volume": "main",
    "checked": true,
    "id": "131b8dd9398232a55cab6a7a1b44ebe24161cbe3",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17362": {
    "title": "FIMAP: Feature Importance by Minimal Adversarial Perturbation",
    "abstract": "Instance-based model-agnostic feature importance explanations (LIME, SHAP, L2X) are a popular form of algorithmic transparency. These methods generally return either a weighting or subset of input features as an explanation for the classification of an instance. An alternative literature argues instead that counterfactual instances, which alter the black-box model's classification, provide a more actionable form of explanation. We present Feature Importance by Minimal Adversarial Perturbation (FIMAP), a neural network based approach that unifies feature importance and counterfactual explanations. We show that this approach combines the two paradigms, recovering the output of feature-weighting methods in continuous feature spaces, whilst indicating the direction in which the nearest counterfactuals can be found. Our method also provides an implicit confidence estimate in its own explanations, something existing methods lack. Additionally, FIMAP improves upon the speed of sampling-based methods, such as LIME, by an order of magnitude, allowing for explanation deployment in time-critical applications. We extend our approach to categorical features using a partitioned Gumbel layer and demonstrate its efficacy on standard datasets",
    "volume": "main",
    "checked": true,
    "id": "333cfd191a479fdd87425d75d85d334d9c1b5ff5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17363": {
    "title": "Beyond Class-Conditional Assumption: A Primary Attempt to Combat Instance-Dependent Label Noise",
    "abstract": "Supervised learning under label noise has seen numerous advances recently, while existing theoretical findings and empirical results broadly build up on the class-conditional noise (CCN) assumption that the noise is independent of input features given the true label. In this work, we present a theoretical hypothesis testing and prove that noise in real-world dataset is unlikely to be CCN, which confirms that label noise should depend on the instance and justifies the urgent need to go beyond the CCN assumption.The theoretical results motivate us to study the more general and practical-relevant instance-dependent noise (IDN). To stimulate the development of theory and methodology on IDN, we formalize an algorithm to generate controllable IDN and present both theoretical and empirical evidence to show that IDN is semantically meaningful and challenging. As a primary attempt to combat IDN, we present a tiny algorithm termed self-evolution average label (SEAL), which not only stands out under IDN with various noise fractions, but also improves the generalization on real-world noise benchmark Clothing1M. Our code is released. Notably, our theoretical analysis in Section 2 provides rigorous motivations for studying IDN, which is an important topic that deserves more research attention in future",
    "volume": "main",
    "checked": true,
    "id": "4945fb6bc967179b8d9a19e1b2f87a62720d79c7",
    "citation_count": 29
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17364": {
    "title": "Robustness of Accuracy Metric and its Inspirations in Learning with Noisy Labels",
    "abstract": "For multi-class classification under class-conditional label noise, we prove that the accuracy metric itself can be robust. We concretize this finding's inspiration in two essential aspects: training and validation, with which we address critical issues in learning with noisy labels. For training, we show that maximizing training accuracy on sufficiently many noisy samples yields an approximately optimal classifier. For validation, we prove that a noisy validation set is reliable, addressing the critical demand of model selection in scenarios like hyperparameter-tuning and early stopping. Previously, model selection using noisy validation samples has not been theoretically justified. We verify our theoretical results and additional claims with extensive experiments. We show characterizations of models trained with noisy labels, motivated by our theoretical results, and verify the utility of a noisy validation set by showing the impressive performance of a framework termed noisy best teacher and student (NTS). Our code is released",
    "volume": "main",
    "checked": true,
    "id": "1fbff5f28ac4851011a0c86f72c1c6126a984c07",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17365": {
    "title": "A Unified Taylor Framework for Revisiting Attribution Methods",
    "abstract": "Attribution methods have been developed to understand the decision making process of machine learning models, especially deep neural networks, by assigning importance scores to individual features. Existing attribution methods often built upon empirical intuitions and heuristics. There still lacks a general and theoretical framework that not only can unify these attribution methods, but also theoretically reveal their rationales, fidelity, and limitations. To bridge the gap, in this paper, we propose a Taylor attribution framework and reformulate seven mainstream attribution methods into the framework. Based on reformulations, we analyze the attribution methods in terms of rationale, fidelity, and limitation.  Moreover, We establish three principles for a good attribution in the Taylor attribution framework, i.e., low approximation error, correct contribution assignment, and unbiased baseline selection. Finally, we empirically validate the Taylor reformulations, and reveal a positive correlation between the attribution performance and the number of principles followed by the attribution method via benchmarking on real-world datasets",
    "volume": "main",
    "checked": true,
    "id": "3e1719032cb56039df0c30861ccaac061982bb45",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17366": {
    "title": "Verifiable Machine Ethics in Changing Contexts",
    "abstract": "Many systems proposed for the implementation of ethical reasoning involve an encoding of user values as a set of rules or a model. We consider the question of how changes of context affect these encodings.  We propose the use of a reasoning cycle, in which information about the ethical reasoner's context is imported in a logical form, and we propose that context-specific aspects of an ethical encoding be prefaced by a guard formula. This guard formula should evaluate to true when the reasoner is in the appropriate context and the relevant parts of the reasoner's rule set or model should be updated accordingly. This architecture allows techniques for the model-checking of agent-based autonomous systems to be used to verify that all contexts respect key stakeholder values. We implement this framework using the hybrid ethical reasoning agents system (HERA) and the model-checking agent programming languages (MCAPL) framework",
    "volume": "main",
    "checked": true,
    "id": "6bd9162101cfc4b2221539b8dff283371588d69e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17367": {
    "title": "Epistemic Logic of Know-Who",
    "abstract": "The paper suggests a definition of \"know who\" as a modality using Grove-Halpern semantics of names. It also introduces a logical system that describes the interplay between modalities \"knows who\", \"knows\", and \"for all agents\". The main technical result is a completeness theorem for the proposed system",
    "volume": "main",
    "checked": true,
    "id": "24b8b7f638aae07491d0ddf8644505d20e17d35a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17368": {
    "title": "Agent Incentives: A Causal Perspective",
    "abstract": "We present a framework for analysing agent incentives using causal influence diagrams. We establish that a well-known criterion for value of information is complete. We propose a new graphical criterion for value of control, establishing its soundness and completeness. We also introduce two new concepts for incentive analysis: response incentives indicate which changes in the environment affect an optimal decision, while instrumental control incentives establish whether an agent can influence its utility via a variable X. For both new concepts, we provide sound and complete graphical criteria. We show by example how these results can help with evaluating the safety and fairness of an AI system",
    "volume": "main",
    "checked": true,
    "id": "67a5303464a764453a2435bec453bed1c5ac9c43",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17369": {
    "title": "Individual Fairness in Kidney Exchange Programs",
    "abstract": "Kidney transplant is the preferred method of treatment for patients suffering from kidney failure. However, not all patients can find a donor which matches their physiological characteristics. Kidney exchange programs (KEPs) seek to match such incompatible patient-donor pairs together, usually with the main objective of maximizing the total number of transplants. Since selecting one optimal solution translates to a decision on who receives a transplant, it has a major effect on the lives of patients. The current practice in selecting an optimal solution does not necessarily ensure fairness in the selection process. In this paper, the existence of multiple optimal plans for a KEP is explored as a mean to achieve individual fairness. We propose the use of randomized policies for selecting an optimal solution in which patients' equal opportunity to receive a transplant is promoted. Our approach gives rise to the problem of enumerating all optimal solutions, which we tackle using a hybrid of constraint programming and linear programming. The advantages of our proposed method over the common practice of using the optimal solution obtained by a solver are stressed through computational experiments. Our methodology enables decision makers to fully control KEP outcomes, overcoming any potential bias or vulnerability intrinsic to a deterministic solver",
    "volume": "main",
    "checked": true,
    "id": "5279357625cd5a6bbd54f0e5e0292c6d2dd72c1b",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17370": {
    "title": "Fair Representations by Compression",
    "abstract": "Organizations that collect and sell data face increasing scrutiny for the discriminatory use of data. We propose a novel unsupervised approach to map data into a compressed binary representation independent of sensitive attributes. We show that in an information bottleneck framework, a parsimonious representation should filter out information related to sensitive attributes if they are provided directly to the decoder. Empirical results show that the method achieves state-of-the-art accuracy-fairness trade-off and that explicit control of the entropy of the representation bit stream allows the user to move smoothly and simultaneously along both rate-distortion and rate-fairness curves",
    "volume": "main",
    "checked": true,
    "id": "eeb06f695a71e8923b5d65dd904575828d2cc304",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17371": {
    "title": "Amnesiac Machine Learning",
    "abstract": "The Right to be Forgotten is part of the recently enacted General Data Protection Regulation (GDPR) law that affects any data holder that has data on European Union residents. It gives EU residents the ability to request deletion of their personal data, including training records used to train machine learning models. Unfortunately, Deep Neural Network models are vulnerable to information leaking attacks such as model inversion attacks which extract class information from a trained model and membership inference attacks which determine the presence of an example in a model's training data. If a malicious party can mount an attack and learn private information that was meant to be removed, then it implies that the model owner has not properly protected their user's rights and their models may not be compliant with the GDPR law. In this paper, we present two efficient methods that address this question of how a model owner or data holder may delete personal data from models in such a way that they may not be vulnerable to model inversion and membership inference attacks while maintaining model efficacy. We start by presenting a real-world threat model that shows that simply removing training data is insufficient to protect users. We follow that up with two data removal methods, namely Unlearning and Amnesiac Unlearning, that enable model owners to protect themselves against such attacks while being compliant with regulations. We provide extensive empirical analysis that show that these methods are indeed efficient, safe to apply, effectively remove learned information about sensitive data from trained models while maintaining model efficacy",
    "volume": "main",
    "checked": true,
    "id": "09227e0251dad7b972878720131ddaecfec6c47f",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17372": {
    "title": "On the Verification of Neural ODEs with Stochastic Guarantees",
    "abstract": "We show that Neural ODEs, an emerging class of time-continuous neural networks, can be verified by solving a set of global-optimization problems. For this purpose, we introduce Stochastic Lagrangian Reachability (SLR), an abstraction-based technique for constructing a tight Reachtube (an over-approximation of the set of reachable states over a given time-horizon), and provide stochastic guarantees in the form of confidence intervals for the Reachtube bounds.  SLR inherently avoids the infamous wrapping effect (accumulation of over-approximation errors) by performing local optimization steps to expand safe regions instead of repeatedly forward-propagating them as is done by deterministic reachability methods.  To enable fast local optimizations, we introduce a novel forward-mode adjoint sensitivity method to compute gradients without the need for backpropagation.  Finally, we establish asymptotic and non-asymptotic convergence rates for SLR",
    "volume": "main",
    "checked": true,
    "id": "0033cbb16ea8996520f2e239298070975b3f31ae",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17373": {
    "title": "PenDer: Incorporating Shape Constraints via Penalized Derivatives",
    "abstract": "When deploying machine learning models in the real-world, system designers may wish that models exhibit certain shape behavior, i.e., model outputs follow a particular shape with respect to input features. Trends such as monotonicity, convexity, diminishing or accelerating returns are some of the desired shapes. Presence of these shapes makes the model more interpretable for the system designers, and adequately fair for the customers. We notice that many such common shapes are related to derivatives, and propose a new approach, PenDer (Penalizing Derivatives), which incorporates these shape constraints by penalizing the derivatives. We further present an Augmented Lagrangian Method (ALM) to solve this constrained optimization problem. Experiments on three real-world datasets illustrate that even though both PenDer and state-of-the-art Lattice models achieve similar conformance to shape, PenDer captures better sensitivity of prediction with respect to intended features. We also demonstrate that PenDer achieves better test performance than Lattice while enforcing more desirable shape behavior",
    "volume": "main",
    "checked": true,
    "id": "dba3478cb46874a97e301deb0f20f7692c1f1ae9",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17374": {
    "title": "Visualization of Supervised and Self-Supervised Neural Networks via Attribution Guided Factorization",
    "abstract": "Neural network visualization techniques mark image locations by their relevancy to the network's classification. Existing methods are effective in highlighting the regions that affect the resulting classification the most. However, as we show, these methods are limited in their ability to identify the support for alternative classifications, an effect we name the saliency bias hypothesis. In this work, we integrate two lines of research: gradient-based methods and attribution-based methods, and develop an algorithm that provides per-class explainability.  The algorithm back-projects the per pixel local influence, in a manner that is guided by the local attributions, while correcting for salient features that would otherwise bias the explanation.  In an extensive battery of experiments, we demonstrate the ability of our methods to class-specific visualization, and not just the predicted label. Remarkably, the method obtains state of the art results in benchmarks that are commonly applied to gradient-based methods as well as in those that are employed mostly for evaluating attribution methods. Using a new unsupervised procedure, our method is also successful in demonstrating that self-supervised methods learn semantic information. Our code is available at: https://github.com/shirgur/AGFVisualization",
    "volume": "main",
    "checked": true,
    "id": "c92ccde8efe40d1696dc7acdadaddc923c9d945d",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17375": {
    "title": "Differentially Private Clustering via Maximum Coverage",
    "abstract": "This paper studies the problem of clustering in metric spaces while preserving the privacy of individual data. Specifically, we examine differentially private variants of the k-medians and Euclidean k-means problems. We present polynomial algorithms with constant multiplicative error and lower additive error than the previous state-of-the-art for each problem. Additionally, our algorithms use a clustering algorithm without differential privacy as a black-box. This allows practitioners to control the trade-off between runtime and approximation factor by choosing a suitable clustering algorithm to use",
    "volume": "main",
    "checked": true,
    "id": "c0239d011c8e1e5207a267e7f45602c9977fd8d2",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17376": {
    "title": "Ordered Counterfactual Explanation by Mixed-Integer Linear Optimization",
    "abstract": "Post-hoc explanation methods for machine learning models have been widely used to support decision-making. One of the popular methods is Counterfactual Explanation (CE), also known as Actionable Recourse, which provides a user with a perturbation vector of features that alters the prediction result. Given a perturbation vector, a user can interpret it as an \"action\" for obtaining one's desired decision result. In practice, however, showing only a perturbation vector is often insufficient for users to execute the action. The reason is that if there is an asymmetric interaction among features, such as causality, the total cost of the action is expected to depend on the order of changing features. Therefore, practical CE methods are required to provide an appropriate order of changing features in addition to a perturbation vector. For this purpose, we propose a new framework called Ordered Counterfactual Explanation (OrdCE). We introduce a new objective function that evaluates a pair of an action and an order based on feature interaction. To extract an optimal pair, we propose a mixed-integer linear optimization approach with our objective function. Numerical experiments on real datasets demonstrated the effectiveness of our OrdCE in comparison with unordered CE methods",
    "volume": "main",
    "checked": true,
    "id": "05c96f995a71655074f8af03751e52f8c2ff9ecd",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17377": {
    "title": "On Generating Plausible Counterfactual and Semi-Factual Explanations for Deep Learning",
    "abstract": "There is a growing concern that the recent progress made in AI, especially regarding the predictive competence of deep learning models, will be undermined by a failure to properly explain their operation and outputs. In response to this disquiet, counterfactual explanations have become very popular in eXplainable AI (XAI) due to their asserted computational, psychological, and legal benefits. In contrast however, semi-factuals (which appear to be equally useful) have surprisingly received no attention. Most counterfactual methods address tabular rather than image data, partly because the non-discrete nature of images makes good counterfactuals difficult to define; indeed, generating plausible counterfactual images which lie on the data manifold is also problematic. This paper advances a novel method for generating plausible counterfactuals and semi-factuals for black-box CNN classifiers doing computer vision. The present method, called PlausIble Exceptionality-based Contrastive Explanations (PIECE), modifies all \"exceptional\" features in a test image to be \"normal\" from the perspective of the counterfactual class, to generate plausible counterfactual images. Two controlled experiments compare this method to others in the literature, showing that PIECE generates highly plausible counterfactuals (and the best semi-factuals) on several benchmark measures",
    "volume": "main",
    "checked": true,
    "id": "5e6b2c0a61b008b9b550f4cf388bf118e72c3b7d",
    "citation_count": 27
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17378": {
    "title": "How RL Agents Behave When Their Actions Are Modified",
    "abstract": "Reinforcement learning in complex environments may require supervision to prevent the agent from attempting dangerous actions. As a result of supervisor intervention, the executed action may differ from the action specified by the policy. How does this affect learning? We present the Modified-Action Markov Decision Process, an extension of the MDP model that allows actions to differ from the policy. We analyze the asymptotic behaviours of common reinforcement learning algorithms in this setting and show that they adapt in different ways: some completely ignore modifications while others go to various lengths in trying to avoid action modifications that decrease reward. By choosing the right algorithm, developers can prevent their agents from learning to circumvent interruptions or constraints, and better control agent responses to other kinds of action modification, like self-damage",
    "volume": "main",
    "checked": true,
    "id": "81d612d385aec3839ab53babfa83081221de22b4",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17379": {
    "title": "Outlier Impact Characterization for Time Series Data",
    "abstract": "For time series data, certain types of outliers are intrinsically more harmful for parameter estimation and future predictions than others, irrespective of their frequency. In this paper, for the first time, we study the characteristics of such outliers through the lens of the influence functional from robust statistics. In particular, we consider the input time series as a contaminated process, with the recurring outliers generated from an unknown contaminating process. Then we leverage the influence functional to understand the impact of the contaminating process on parameter estimation. The influence functional results in a multi-dimensional vector that measures the sensitivity of the predictive model to the contaminating process, which can be challenging to interpret especially for models with a large number of parameters. To this end, we further propose a comprehensive single-valued metric (the SIF) to measure outlier impacts on future predictions. It provides a quantitative measure regarding the outlier impacts, which can be used in a variety of scenarios, such as the evaluation of outlier detection methods, the creation of more harmful outliers, etc. The empirical results on multiple real data sets demonstrate the effectivenss of the proposed SIF metric",
    "volume": "main",
    "checked": true,
    "id": "e54f0521300194179f478a11fe0179c084d7f43e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17380": {
    "title": "Interpreting Deep Neural Networks with Relative Sectional Propagation by Analyzing Comparative Gradients and Hostile Activations",
    "abstract": "The clear transparency of Deep Neural Networks (DNNs) is hampered by complex internal structures and nonlinear transformations along deep hierarchies. In this paper, we propose a new attribution method, Relative Sectional Propagation (RSP), for fully decomposing the output predictions with the characteristics of class-discriminative attributions and clear objectness. We carefully revisit some shortcomings of backpropagation-based attribution methods, which are trade-off relations in decomposing DNNs. We define hostile factor as an element that interferes with finding the attributions of the target and propagate it in a distinguishable way to overcome the non-suppressed nature of activated neurons. As a result, it is possible to assign the bi-polar relevance scores of the target (positive) and hostile (negative) attributions while maintaining each attribution aligned with the importance. We also present the purging techniques to prevent the decrement of the gap between the relevance scores of the target and hostile attributions during backward propagation by eliminating the conflicting units to channel attribution map. Therefore, our method makes it possible to decompose the predictions of DNNs with clearer class-discriminativeness and detailed elucidations of activation neurons compared to the conventional attribution methods. In a verified experimental environment, we report the results of the assessments: (i) Pointing Game, (ii) mIoU, and (iii) Model Sensitivity with PASCAL VOC 2007, MS COCO 2014, and ImageNet datasets. The results demonstrate that our method outperforms existing backward decomposition methods, including distinctive and intuitive visualizations",
    "volume": "main",
    "checked": true,
    "id": "7f05d62928e9d316e5375067f673a590836cd43d",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17381": {
    "title": "Ethical Dilemmas in Strategic Games",
    "abstract": "An agent, or a coalition of agents, faces an ethical dilemma between several statements if she is forced to make a conscious choice between which of these statements will be true. This paper proposes to capture ethical dilemmas as a modality in strategic game settings with and without limit on sacrifice and for perfect and imperfect information games. The authors show that the dilemma modality cannot be defined through the earlier proposed blameworthiness modality. The main technical result is a sound and complete axiomatization of the properties of this modality with sacrifice in games with perfect information",
    "volume": "main",
    "checked": true,
    "id": "08862c139bc616021ef4455abb1b139e7e57ac28",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17382": {
    "title": "Comprehension and Knowledge",
    "abstract": "The ability of an agent to comprehend a sentence is tightly connected to the agent's prior experiences and background knowledge. The paper suggests to interpret comprehension as a modality and proposes a complete bimodal logical system that describes an interplay between comprehension and knowledge modalities",
    "volume": "main",
    "checked": true,
    "id": "6328d027618a1247df0780372c695d8f9a658c78",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17383": {
    "title": "Fair Influence Maximization: a Welfare Optimization Approach",
    "abstract": "Several behavioral, social, and public health interventions, such as suicide/HIV prevention or community preparedness against natural disasters, leverage social network information to maximize outreach. Algorithmic influence maximization techniques have been proposed to aid with the choice of ``peer leaders'' or ``influencers'' in such interventions. Yet, traditional algorithms for influence maximization have not been designed with these interventions in mind. As a result, they may disproportionately exclude minority communities from the benefits of the intervention. This has motivated research on fair influence maximization. Existing techniques come with two major drawbacks. First, they require committing to a single fairness measure. Second, these measures are typically imposed as strict constraints leading to undesirable properties such as wastage of resources.  To address these shortcomings, we provide a principled characterization of the properties that a fair influence maximization algorithm should satisfy. In particular, we propose a framework based on social welfare theory, wherein the cardinal utilities derived by each community are aggregated using the isoelastic social welfare functions. Under this framework, the trade-off between fairness and efficiency can be controlled by a single inequality aversion design parameter. We then show under what circumstances our proposed principles can be satisfied by a welfare function. The resulting optimization problem is monotone and submodular and can be solved efficiently with optimality guarantees. Our framework encompasses as special cases leximin and proportional fairness. Extensive experiments on synthetic and real world datasets including a case study on landslide risk management demonstrate the efficacy of the proposed framework",
    "volume": "main",
    "checked": true,
    "id": "06fe543ad9ef9d0c91db0dfa0e6f98904a6bb40a",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17384": {
    "title": "Explaining Convolutional Neural Networks through Attribution-Based Input Sampling and Block-Wise Feature Aggregation",
    "abstract": "As an emerging field in Machine Learning, Explainable AI (XAI) has been offering remarkable performance in interpreting the decisions made by Convolutional Neural Networks (CNNs). To achieve visual explanations for CNNs, methods based on class activation mapping and randomized input sampling have gained great popularity. However, the attribution methods based on these techniques provide lower-resolution and blurry explanation maps that limit their explanation power. To circumvent this issue, visualization based on various layers is sought. In this work, we collect visualization maps from multiple layers of the model based on an attribution-based input sampling technique and aggregate them to reach a fine-grained and complete explanation. We also propose a layer selection strategy that applies to the whole family of CNN-based models, based on which our extraction framework is applied to visualize the last layers of each convolutional block of the model. Moreover, we perform an empirical analysis of the efficacy of derived lower-level information to enhance the represented attributions. Comprehensive experiments conducted on shallow and deep models trained on natural and industrial datasets, using both ground-truth and model-truth based evaluation metrics validate our proposed algorithm by meeting or outperforming the state-of-the-art methods in terms of explanation ability and visual quality, demonstrating that our method shows stability regardless of the size of objects or instances to be explained",
    "volume": "main",
    "checked": true,
    "id": "7a30b3a47c569af89d00baa53021e187ff92fee4",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17385": {
    "title": "Exploring the Vulnerability of Deep Neural Networks: A Study of Parameter Corruption",
    "abstract": "We argue that the vulnerability of model parameters is of crucial value to the study of model robustness and generalization but little research has been devoted to understanding this matter. In this work, we propose an indicator to measure the robustness of neural network parameters by exploiting their vulnerability via parameter corruption. The proposed indicator describes the maximum loss variation in the non-trivial worst-case scenario under parameter corruption. For practical purposes, we give a gradient-based estimation, which is far more effective than random corruption trials that can hardly induce the worst accuracy degradation. Equipped with theoretical support and empirical validation, we are able to systematically investigate the robustness of different model parameters and reveal vulnerability of deep neural networks that has been rarely paid attention to before. Moreover, we can enhance the models accordingly with the proposed adversarial corruption-resistant training, which not only improves the parameter robustness but also translates into accuracy elevation",
    "volume": "main",
    "checked": true,
    "id": "d3db091942ac3c1fe6af69275a318c25d7b4ed11",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17386": {
    "title": "Ethically Compliant Sequential Decision Making",
    "abstract": "Enabling autonomous systems to comply with an ethical theory is critical given their accelerating deployment in domains that impact society. While many ethical theories have been studied extensively in moral philosophy, they are still challenging to implement by developers who build autonomous systems. This paper proposes a novel approach for building ethically compliant autonomous systems that optimize completing a task while following an ethical framework. First, we introduce a definition of an ethically compliant autonomous system and its properties. Next, we offer a range of ethical frameworks for divine command theory, prima facie duties, and virtue ethics. Finally, we demonstrate the accuracy and usability of our approach in a set of autonomous driving simulations and a user study of planning and robotics experts",
    "volume": "main",
    "checked": true,
    "id": "220d40be0c4374b87649fe9c335d3a207dbddccc",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17387": {
    "title": "Improving Robustness to Model Inversion Attacks via Mutual Information Regularization",
    "abstract": "This paper studies defense mechanisms against model inversion (MI) attacks -- a type of privacy attacks aimed at inferring information about the training data distribution given the access to a target machine learning model. Existing defense mechanisms rely on model-specific heuristics or noise injection. While being able to mitigate attacks, existing methods significantly hinder model performance. There remains a question of how to design a defense mechanism that is applicable to a variety of models and achieves better utility-privacy tradeoff. In this paper, we propose the Mutual Information Regularization based Defense (MID) against MI attacks. The key idea is to limit the information about the model input contained in the prediction, thereby limiting the ability of an adversary to infer the private training attributes from the model prediction. Our defense principle is model-agnostic and we present tractable approximations to the regularizer for linear regression, decision trees, and neural networks, which have been successfully attacked by prior work if not attached with any defenses. We present a formal study of MI attacks by devising a rigorous game-based definition and quantifying the associated information leakage. Our theoretical analysis sheds light on the inefficacy of DP in defending against MI attacks, which has been empirically observed in several prior works. Our experiments demonstrate that MID leads to state-of-the-art performance for a variety of MI attacks, target models and datasets",
    "volume": "main",
    "checked": true,
    "id": "7b26823c1acbc10fadd53c3b71da55a95c8ae576",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17388": {
    "title": "Tightening Robustness Verification of Convolutional Neural Networks with Fine-Grained Linear Approximation",
    "abstract": "The robustness of neural networks can be quantitatively indicated by a lower bound within which any perturbation does not alter the original inputs classification result. A certified lower bound is also a criterion to evaluate the performance of robustness verification approaches. In this paper, we present a tighter linear approximation approach for the robustness verification of Convolutional Neural Networks (CNNs). By the tighter approximation, we can tighten the robustness verification of CNNs, i.e., proving they are robust within a larger 10 perturbation distance. Furthermore, our approach is applicable to general sigmoid-like activation functions. We implement DeepCert, the resulting verification toolkit. We evaluate it with open-source benchmarks, including LeNet and the models trained on MNIST and CIFAR. Experimental results show that DeepCert outperforms other state-of-the-art robustness verification tools with at most 286.28% improvement to the certified lower bound and 1566.76 times speedup for the same neural networks",
    "volume": "main",
    "checked": true,
    "id": "dcef28d2d715f1c860aef90e8bc2f3c4223a813d",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17389": {
    "title": "Invertible Concept-based Explanations for CNN Models with Non-negative Concept Activation Vectors",
    "abstract": "Convolutional neural network (CNN) models for computer vision are powerful but lack explainability in their most basic form. This deficiency remains a key challenge when applying CNNs in important domains. Recent work on explanations through feature importance of approximate linear models has moved from input-level features (pixels or segments) to features from mid-layer feature maps in the form of concept activation vectors (CAVs). CAVs contain concept-level information and could be learned via clustering. In this work, we rethink the ACE algorithm of Ghorbani et~al., proposing an alternative invertible concept-based explanation (ICE) framework to overcome its shortcomings. Based on the requirements of fidelity (approximate models to target models) and interpretability (being meaningful to people), we design measurements and evaluate a range of matrix factorization methods with our framework. We find that non-negative concept activation vectors (NCAVs) from non-negative matrix factorization provide superior performance in interpretability and fidelity based on computational and human subject experiments. Our framework provides both local and global concept-level explanations for pre-trained CNN models",
    "volume": "main",
    "checked": true,
    "id": "92902e212cd1408f2bfbefbbb0157abe1b05a18e",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17390": {
    "title": "i-Algebra: Towards Interactive Interpretability of Deep Neural Networks",
    "abstract": "Providing explanations for deep neural networks (DNNs) is essential for their use in domains wherein the interpretability of decisions is a critical prerequisite. Despite the plethora of work on interpreting DNNs, most existing solutions offer interpretability in an ad hoc, one-shot, and static manner, without accounting for the perception, understanding, or response of end-users, resulting in their poor usability in practice. In this paper, we argue that DNN interpretability should be implemented as the interactions between users and models. We present i-Algebra, a first-of-its-kind interactive framework for interpreting DNNs. At its core is a library of atomic, composable operators, which explain model behaviors at varying input granularity, during different inference stages, and from distinct interpretation perspectives. Leveraging a declarative query language, users are enabled to build various analysis tools (e.g., ``drill-down'', ``comparative'', ``what-if'' analysis) via flexibly composing such operators. We prototype i-Algebra and conduct user studies in a set of representative analysis tasks, including inspecting adversarial inputs, resolving model inconsistency, and cleansing contaminated data, all demonstrating its promising usability",
    "volume": "main",
    "checked": true,
    "id": "72719a422ce5adf5a1d244ec5ff3e93474b7d7a4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17391": {
    "title": "Decision-Guided Weighted Automata Extraction from Recurrent Neural Networks",
    "abstract": "Recurrent Neural Networks (RNNs) have demonstrated their effectiveness in learning and processing sequential data (e.g., speech and natural language). However, due to the black-box nature of neural networks, understanding the decision logic of RNNs is quite challenging. Some recent progress has been made to approximate the behavior of an RNN by weighted automata. They provide better interpretability, but still suffer from poor scalability. In this paper, we propose a novel approach to extracting weighted automata with the guidance of a target RNN's decision and context information. In particular, we identify the patterns of RNN's step-wise predictive decisions to instruct the formation of automata states. Further, we propose a state composition method to enhance the context-awareness of the extracted model. Our in-depth evaluations on typical RNN tasks, including language model and classification, demonstrate the effectiveness and advantage of our method over the state-of-the-arts. The evaluation results show that our method can achieve accurate approximation of an RNN even on large-scale tasks",
    "volume": "main",
    "checked": true,
    "id": "acbbcaabaaa7fe2916006f0bf1d92a73e2cc22d7",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17392": {
    "title": "Computing Plan-Length Bounds Using Lengths of Longest Paths",
    "abstract": "We devise a method to exactly compute the length of the longest simple path in factored state spaces, like state spaces encountered in classical planning. Although the complexity of this problem is NEXP-Hard, we show that our method can be used to compute practically useful upper-bounds on lengths of plans. We show that the computed upper-bounds are significantly better than bounds produced by state-of-the-art bounding techniques and that they can be used to improve the SAT-based  planning",
    "volume": "main",
    "checked": true,
    "id": "2c2f88d30d6e545ad736ab3766813af2418ceb92",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17393": {
    "title": "Constrained Risk-Averse Markov Decision Processes",
    "abstract": "We consider the problem of designing policies for Markov decision processes (MDPs) with dynamic coherent risk objectives and constraints. We begin by formulating the problem in a Lagrangian framework. Under the assumption that the risk objectives and constraints can be represented by a Markov risk transition mapping, we propose an optimization-based method to synthesize Markovian policies that lower-bound the constrained risk-averse problem. We demonstrate that the formulated optimization problems are in the form of difference convex programs (DCPs) and can be solved by the disciplined convex-concave programming (DCCP) framework. We show that these results generalize linear programs for constrained MDPs with total discounted expected costs and constraints. Finally, we illustrate the effectiveness of the proposed method with numerical experiments on a rover navigation problem involving conditional-value-at-risk (CVaR) and entropic-value-at-risk (EVaR) coherent risk measures",
    "volume": "main",
    "checked": true,
    "id": "7b313679816e3ce1c7153f27c8ab60e1b4b993b0",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17394": {
    "title": "Contract Scheduling With Predictions",
    "abstract": "Contract scheduling is a general technique that allows to design a system with interruptible capabilities, given an algorithm that is not necessarily interruptible. Previous work on this topic has largely assumed that the interruption is a worst-case deadline that is unknown to the scheduler. In this work, we study the setting in which there is a potentially erroneous prediction concerning the interruption. Specifically, we consider the setting in which the prediction describes the time that the interruption occurs, as well as the setting in which the prediction is obtained as a response to a single or multiple binary queries. For both settings, we investigate tradeoffs between the robustness (i.e., the worst-case performance assuming adversarial prediction) and the consistency (i.e, the performance assuming that the prediction is error-free), both from the side of positive and negative results",
    "volume": "main",
    "checked": true,
    "id": "2e29a6a3be93ffdfe4699f964ca986bfa1d817f4",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17395": {
    "title": "Responsibility Attribution in Parameterized Markovian Models",
    "abstract": "We consider the problem of responsibility attribution in the setting of parametric Markov chains. Given a family of Markov chains over a set of parameters, and a property, responsibility attribution asks how the difference in the value of the property should be attributed to the parameters when they change from one point in the parameter space to another.  We formalize responsibility as path-based attribution schemes studied in cooperative game theory. An attribution scheme in a game determines how a value (a surplus or a cost) is distributed among a set of participants. Path-based attribution schemes include the well-studied Aumann-Shapley and the Shapley-Shubik schemes. In our context, an attribution scheme measures the responsibility of each parameter on the value function of the parametric Markov chain.  We study the decision problem for path-based attribution schemes. Our main technical result is an algorithm for deciding if a path-based attribution scheme for a rational (ratios of polynomials) cost function is over a rational threshold. In particular, it is decidable if the Aumann-Shapley value for a player is at least a given rational number. As a consequence, we show that responsibility attribution is decidable for parametric Markov chains and for a general class of properties that include expectation and variance of discounted sum and long-run average rewards, as well as specifications in temporal logic",
    "volume": "main",
    "checked": true,
    "id": "772b29ad063952d023416cb0af8082daa6f05f42",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17396": {
    "title": "Symbolic Search for Optimal Total-Order HTN Planning",
    "abstract": "Symbolic search has proven to be a useful approach to optimal classical planning. In Hierarchical Task Network (HTN) planning, however, there is little work on optimal planning. One reason for this is that in HTN planning, most algorithms are based on heuristic search, and admissible heuristics have to incorporate the structure of the task network in order to be informative. In this paper, we present a novel approach to optimal (totally-ordered) HTN planning, which is based on symbolic search. An empirical analysis shows that our symbolic approach outperforms the current state of the art for optimal totally-ordered HTN planning",
    "volume": "main",
    "checked": true,
    "id": "f2fa0c85502f92747a19c567979b97bb7afdcc35",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17397": {
    "title": "A Multivariate Complexity Analysis of the Material Consumption Scheduling Problem",
    "abstract": "The NP-hard Material Consumption Scheduling Problem and closely related problems have been thoroughly studied since the 1980's. Roughly speaking, the problem deals with minimizing the makespan when scheduling jobs that consume non-renewable resources. We focus on the single-machine case without preemption: from time to time, the resources of the machine are (partially) replenished, thus allowing for meeting a necessary pre-condition for processing further jobs, each of which having individual resource demands. We initiate a systematic exploration of the parameterized computational complexity landscape of the problem, providing parameterized tractability as well as intractability results. Doing so, we mainly investigate how parameters related to the resource supplies influence the computational complexity. Thereby, we get a deepened understanding of this fundamental scheduling problem",
    "volume": "main",
    "checked": true,
    "id": "96406cd3e9c7be4a48d19fd6249e8267526d19f2",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17398": {
    "title": "General Policies, Representations, and Planning Width",
    "abstract": "It has been observed that in many of the benchmark planning domains, atomic goals can be reached with a simple polynomial exploration procedure, called IW, that runs in time exponential in the problem width. Such problems have indeed a bounded width: a width that does not grow with the number of problem variables and is often no greater than two. Yet, while the notion of width has become part of the state- of-the-art planning algorithms like BFWS, there is still no good explanation for why so many benchmark domains have bounded width. In this work, we address this question by relating bounded width and serialized width to ideas of generalized planning, where general policies aim to solve multiple instances of a planning problem all at once. We show that bounded width is a property of planning domains that admit optimal general policies in terms of features that are explicitly or implicitly represented in the domain encoding. The results are extended to the larger class of domains with bounded serialized width where the general policies do not have to be optimal. The study leads also to a new simple, meaningful, and expressive language for specifying domain serializations in the form of policy sketches which can be used for encoding domain control knowledge by hand or for learning it from traces. The use of sketches and the meaning of the theoretical results are all illustrated through a number of examples",
    "volume": "main",
    "checked": true,
    "id": "6a9d4cbe2f1bcb8f81eb5eb91dd752e2970664ee",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17399": {
    "title": "Successor Feature Sets: Generalizing Successor Representations Across Policies",
    "abstract": "Successor-style representations have many advantages for reinforcement learning: for example, they can help an agent generalize from past experience to new goals, and they have been proposed as explanations of behavioral and neural data from human and animal learners. They also form a natural bridge between model-based and model-free RL methods: like the former they make predictions about future experiences, and like the latter they allow efficient prediction of total discounted rewards. However, successor-style representations are not optimized to generalize across policies: typically, we maintain a limited-length list of policies, and share information among them by representation learning or GPI. Successor-style representations also typically make no provision for gathering information or reasoning about latent variables. To address these limitations, we bring together ideas from predictive state representations, belief space value iteration, successor features, and convex analysis: we develop a new, general successor-style representation, together with a Bellman equation that connects multiple sources of information within this representation, including different latent states, policies, and reward functions. The new representation is highly expressive: for example, it lets us efficiently read off an optimal policy for a new reward function, or a policy that imitates a new demonstration. For this paper, we focus on exact computation of the new representation in small, known environments, since even this restricted setting offers plenty of interesting questions. Our implementation does not scale to large, unknown environments --- nor would we expect it to, since it generalizes POMDP value iteration, which is difficult to scale. However, we believe that future work will allow us to extend our ideas to approximate reasoning in large, unknown environments. We conduct experiments to explore which of the potential barriers to scaling are most pressing",
    "volume": "main",
    "checked": true,
    "id": "b1cad9e721444bf95eb280d39eb324e81d3c86b0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17400": {
    "title": "GLIB: Efficient Exploration for Relational Model-Based Reinforcement Learning via Goal-Literal Babbling",
    "abstract": "We address the problem of efficient exploration for transition model learning in the relational model-based reinforcement learning setting without extrinsic goals or rewards. Inspired by human curiosity, we propose goal-literal babbling (GLIB), a simple and general method for exploration in such problems. GLIB samples relational conjunctive goals that can be understood as specific, targeted effects that the agent would like to achieve in the world, and plans to achieve these goals using the transition model being learned. We provide theoretical guarantees showing that exploration with GLIB will converge almost surely to the ground truth model. Experimentally, we find GLIB to strongly outperform existing methods in both prediction and planning on a range of tasks, encompassing standard PDDL and PPDDL planning benchmarks and a robotic manipulation task implemented in the PyBullet physics simulator. Video: https://youtu.be/F6lmrPT6TOY Code: https://git.io/JIsTB",
    "volume": "main",
    "checked": true,
    "id": "2192fcfbd5040d2bb8d7c7ca7c2138d18534ac9b",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17401": {
    "title": "Robust Finite-State Controllers for Uncertain POMDPs",
    "abstract": "Uncertain partially observable Markov decision processes (uPOMDPs) allow the probabilistic transition and observation functions of standard POMDPs to belong to a so-called uncertainty set.  Such uncertainty, referred to as epistemic uncertainty, captures uncountable sets of probability distributions caused by, for instance, a lack of data available.  We develop an algorithm to compute finite-memory policies for uPOMDPs that robustly satisfy specifications against any admissible distribution.  In general, computing such policies is theoretically and practically intractable.   We provide an efficient solution to this problem in four steps.  (1) We state the underlying problem as a nonconvex optimization problem with infinitely many constraints.   (2) A dedicated dualization scheme yields a dual problem that is still nonconvex but has finitely many constraints.   (3) We linearize this dual problem and (4) solve the resulting finite linear program to obtain locally optimal solutions to the original problem.  The resulting problem formulation is exponentially smaller than those resulting from existing methods.  We demonstrate the applicability of our algorithm using large instances of an aircraft collision-avoidance scenario and a novel spacecraft motion planning case study",
    "volume": "main",
    "checked": true,
    "id": "0c301afaf37865ea90352e7488fcfc83c6a7b192",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17402": {
    "title": "Learning General Planning Policies from Small Examples Without Supervision",
    "abstract": "Generalized planning is concerned with the computation of general policies that solve multiple instances of a planning domain all at once. It has been recently shown that these policies can be computed in two steps: first, a suitable abstraction in the form of a qualitative numerical planning problem (QNP) is learned from sample plans, then the general policies are obtained from the learned QNP using a planner. In this work, we introduce an alternative approach for computing more expressive general policies which does not require sample plans or a QNP planner. The new formulation is very simple and can be cast in terms that are more standard in machine learning: a large but finite pool of features is defined from the predicates in the planning examples using a general grammar, and a small subset of features is sought for separating \"good\" from \"bad\" state transitions, and goals from non-goals. The problems of finding such a \"separating surface\" while labeling the transitions as \"good\" or \"bad\" are jointly addressed as a single combinatorial optimization problem expressed as a Weighted Max-SAT problem. The advantage of looking for the simplest policy in the given feature space that solves the given examples, possibly non-optimally, is that many domains have no general, compact policies that are optimal. The approach yields general policies for a number of benchmark domains",
    "volume": "main",
    "checked": true,
    "id": "42c5c5a8e52e037ceb3e6dfa96fdf134d085d184",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17403": {
    "title": "Revisiting Dominance Pruning in Decoupled Search",
    "abstract": "In classical planning as search, duplicate state pruning is a standard method to avoid unnecessarily handling the same state multiple times. In decoupled search, similar to symbolic search approaches, search nodes, called decoupled states, do not correspond to individual states, but to sets of states. Therefore, duplicate state pruning is less effective in decoupled search, and dominance pruning is employed, taking into account the state sets. We observe that the time required for dominance checking dominates the overall runtime, and propose two ways to tackle this issue. Our main contribution is a stronger variant of dominance checking for optimal planning, where efficiency and pruning power are most crucial. The new variant greatly improves the latter, without incurring a computational overhead. Moreover, we develop three methods that make the dominance check more efficient: exact duplicate checking, which, albeit resulting in weaker pruning, can pay off due to the use of hashing; avoiding the dominance check in non-optimal planning if leaf state spaces are invertible; and exploiting the transitivity of the dominance relation to only check against the relevant subset of visited decoupled states. We show empirically that all our improvements are indeed beneficial in many standard benchmarks",
    "volume": "main",
    "checked": true,
    "id": "4e245d17f57bfbfd97319e6961d8d6f69be38c9b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17404": {
    "title": "Equitable Scheduling on a Single Machine",
    "abstract": "We introduce a natural but seemingly yet unstudied generalization of the problem of scheduling jobs on a single machine so as to minimize the number of tardy jobs. Our generalization lies in simultaneously considering several instances of the problem at once. In particular, we have n clients over a period of m days, where each client has a single job with its own processing time and deadline per day. Our goal is to provide a schedule for each of the m days, so that each client is guaranteed to have their job meet its deadline in at least k",
    "volume": "main",
    "checked": true,
    "id": "2c53677c18fac4f1d129ab345233d2b00a0d2be3",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17405": {
    "title": "Landmark Generation in HTN Planning",
    "abstract": "Landmarks (LMs) are state features that need to be made true or tasks that need to be contained in every solution of a planning problem. They are a valuable source of information in planning and can be exploited in various ways. LMs have been used both in classical and hierarchical planning, but while there is much work in classical planning, the techniques in hierarchical planning are less evolved. We introduce a novel LM generation method for Hierarchical Task Network (HTN) planning and show that it is sound and incomplete. We show that every complete approach is as hard as the co-class of the underlying HTN problem, i.e. coNP-hard for our setting (while our approach is in P). On a widely used benchmark set, our approach finds more than twice the number of landmarks than the approach from the literature. Though our focus is on LM generation, we show that the newly discovered landmarks bear information beneficial for solvers",
    "volume": "main",
    "checked": true,
    "id": "6b1e7b6f881d18a50d472618c00dc1b64a47cb8a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17406": {
    "title": "Endomorphisms of Classical Planning Tasks",
    "abstract": "Detection of redundant operators that can be safely  removed from the planning task is an essential technique  allowing to greatly improve performance of planners.  In this paper, we employ structure-preserving maps on labeled transition  systems (LTSs), namely endomorphisms well known from model theory, in order  to detect redundancy. Computing endomorphisms of an LTS induced by a  planning task is typically infeasible, so we show how to compute some of  them on concise representations of planning tasks such as finite domain  representations and factored LTSs.  We formulate the computation of endomorphisms as a constraint satisfaction  problem (CSP) that can be solved by an off-the-shelf CSP solver.  Finally, we experimentally verify that the  proposed method can find a sizeable number of redundant operators on the  standard benchmark set",
    "volume": "main",
    "checked": true,
    "id": "e3a6d18a6a50565a5dbfe142ae16894e77df7aa5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17407": {
    "title": "Bike-Repositioning Using Volunteers: Crowd Sourcing with Choice Restriction",
    "abstract": "Motivated by the Bike Angels Program in New York's Citi Bike and Boston's Blue Bikes, we study the use of (registered) volunteers to re-position empty bikes for riders in a bike sharing system. We propose a method that can be used to deploy the volunteers in the system, based on the real time distribution of the bikes in different stations. To account for (random) route demand in the network, we solve a related transshipment network design model and construct a sparse structure to restrict the re-balancing activities of the volunteers (concentrating re-balancing activities on essential routes). We also develop a comprehensive simulation model using a threshold-based policy to deploy the volunteers in real time, to test the effect of choice restriction on volunteers (suitably deployed) to re-position bikes. We use the Hubway system in Boston (with 60 stations) to demonstrate that using a sparse structure to concentrate the re-balancing activities of the volunteers, instead of allowing all admissible flows in the system (as in current practice), can reduce the number of re-balancing moves by a huge amount, losing only a small proportion of demand satisfied",
    "volume": "main",
    "checked": true,
    "id": "31e986b2bbbd3f388305d9b7e4ab9da042b392c9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17408": {
    "title": "Branch and Price for Bus Driver Scheduling with Complex Break Constraints",
    "abstract": "This paper presents a Branch and Price approach for a real-life Bus Driver Scheduling problem with a complex set of break constraints. The column generation uses a set partitioning model as master problem and a resource constrained shortest path problem as subproblem. Due to the complex constraints, the branch and price algorithm adopts several novel ideas to improve the column generation in the presence of a high-dimensional subproblem, including exponential arc throttling and a dedicated two-stage dominance algorithm. Evaluation on a publicly available set of benchmark instances shows that the approach provides the first provably optimal solutions for small instances, improving best-known solutions or proving them optimal for 48 out of 50 instances, and yielding an optimality gap of less than 1% for more than half the instances",
    "volume": "main",
    "checked": true,
    "id": "6ca8d663a3986f22b50d49ce182f818317f1639a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17409": {
    "title": "On-line Learning of Planning Domains from Sensor Data in PAL: Scaling up to Large State Spaces",
    "abstract": "We propose an approach to learn an extensional representation of a discrete deterministic planning domain from observations in a continuous space navigated by the agent actions. This is achieved through the use of a perception function providing the likelihood of a real-value observation being in a given state of the planning domain after executing an action. The agent learns an extensional representation of the domain (the set of states, the transitions from states to states caused by actions) and the perception function on-line, while it acts for accomplishing its task. In order to provide a practical approach that can scale up to large state spaces, a \"draft\" intensional (PDDL-based) model of the planning domain is used to guide the exploration of the environment and learn the states and state transitions. The proposed approach uses a novel algorithm to (i) construct the extensional representation of the domain by interleaving symbolic planning in the PDDL intensional representation and search in the state transition graph of the extensional representation; (ii) incrementally refine the intensional representation taking into account information about the actions that the agent cannot execute. An experimental analysis shows that the novel approach can scale up to large state spaces, thus overcoming the limits in scalability of the previous work",
    "volume": "main",
    "checked": true,
    "id": "9dbfe15981311081db7ae576690ed81c1badba92",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17410": {
    "title": "Progression Heuristics for Planning with Probabilistic LTL Constraints",
    "abstract": "Probabilistic planning subject to multi-objective probabilistic temporal logic (PLTL) constraints models the problem of computing safe and robust behaviours for agents in stochastic environments. We present novel admissible heuristics to guide the search for cost-optimal policies for these problems. These heuristics project and decompose LTL formulae obtained by progression to estimate the probability that an extension of a partial policy satisfies the constraints. Their computation with linear programming is integrated with the recent PLTL-dual heuristic search algorithm, enabling more aggressive pruning of regions violating the constraints. Our experiments show that they further widen the scalability gap between heuristic search and verification approaches to these planning problems",
    "volume": "main",
    "checked": true,
    "id": "62fe21096776dd5277a5161e3d22d2eb4b51fe7f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17411": {
    "title": "Bayesian Optimized Monte Carlo Planning",
    "abstract": "Online solvers for partially observable Markov decision processes have difficulty scaling to problems with large action spaces. Monte Carlo tree search with progressive widening attempts to improve scaling by sampling from the action space to construct a policy search tree. The performance of progressive widening search is dependent upon the action sampling policy, often requiring problem-specific samplers. In this work, we present a general method for efficient action sampling based on Bayesian optimization. The proposed method uses a Gaussian process to model a belief over the action-value function and selects the action that will maximize the expected improvement in the optimal action value. We implement the proposed approach in a new online tree search algorithm called Bayesian Optimized Monte Carlo Planning (BOMCP). Several experiments show that BOMCP is better able to scale to large action space POMDPs than existing state-of-the-art tree search solvers",
    "volume": "main",
    "checked": true,
    "id": "108184c22782466c04890a1bff254a7791e93d2d",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17412": {
    "title": "Improved POMDP Tree Search Planning with Prioritized Action Branching",
    "abstract": "Online solvers for partially observable Markov decision processes have difficulty scaling to problems with large action spaces. This paper proposes a method called PA-POMCPOW to sample a subset of the action space that provides varying mixtures of exploitation and exploration for inclusion in a search tree. The proposed method first evaluates the action space according to a score function that is a linear combination of expected reward and expected information gain. The actions with the highest score are then added to the search tree during tree expansion. Experiments show that PA-POMCPOW is able to outperform existing state-of-the-art solvers on problems with large discrete action spaces",
    "volume": "main",
    "checked": true,
    "id": "b2eff44100fbda86e403b78af27722e6e2a6fb72",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17413": {
    "title": "Synthesis of Search Heuristics for Temporal Planning via Reinforcement Learning",
    "abstract": "Automated temporal planning is the problem of synthesizing, starting from a model of a system, a course of actions to achieve a desired goal when temporal constraints, such as deadlines, are present in the problem. Despite considerable successes in the literature, scalability is still a severe limitation for existing planners, especially when confronted with real-world, industrial scenarios. In this paper, we aim at exploiting recent advances in reinforcement learning, for the synthesis of heuristics for temporal planning. Starting from a set of problems of interest for a specific domain, we use a customized reinforcement learning algorithm to construct a value function that is able to estimate the expected reward for as many problems as possible. We use a reward schema that captures the semantics of the temporal planning problem and we show how the value function can be transformed in a planning heuristic for a semi-symbolic heuristic search exploration of the planning model. We show on two case-studies how this method can widen the reach of current temporal planners with encouraging results",
    "volume": "main",
    "checked": true,
    "id": "e6e6da82a45728da81dadd50d03a59ca0eea7185",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17414": {
    "title": "Revealing Hidden Preconditions and Effects of Compound HTN Planning Tasks  A Complexity Analysis",
    "abstract": "In Hierarchical Task Network (HTN) planning, compound tasks need to be refined into executable (primitive) action sequences. In contrast to their primitive counterparts, compound tasks do not specify preconditions or effects. Thus, their implications on the states in which they are applied are not explicitly known: they are \"hidden\" in and depending on the decomposition structure. We formalize several kinds of preconditions and effects that can be inferred for compound tasks in totally ordered HTN domains. As relevant special case we introduce a problem relaxation which admits reasoning about preconditions and effects in polynomial time. We provide procedures for doing so, thereby extending previous work, which could only deal with acyclic models. We prove our procedures to be correct and complete for any totally ordered input domain. These results are embedded into an encompassing complexity analysis of the inference of preconditions and effects of compound tasks, an investigation that has not been made so far",
    "volume": "main",
    "checked": true,
    "id": "d28d2a8b8b1d175da7e141f278460e649b6b6014",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17415": {
    "title": "Faster and Better Simple Temporal Problems",
    "abstract": "In this paper we give a structural characterization and extend the tractability frontier of the Simple Temporal Problem (STP) by defining the class of the Extended Simple Temporal Problem (ESTP), which augments STP with strict inequalities and monotone Boolean formulae on inequations (i.e., formulae involving the operations of conjunction, disjunction and parenthesization). A polynomial-time algorithm is provided to solve ESTP, faster than previous state-of-the-art algorithms for other extensions of STP that had been considered in the literature, all encompassed by ESTP. We show the practical competitiveness of our approach through a proof-of-concept implementation and an experimental evaluation involving also state-of-the-art SMT solvers",
    "volume": "main",
    "checked": true,
    "id": "aaa6691fed4709503f69c3e0e3956e65c222107f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17416": {
    "title": "Latent Independent Excitation for Generalizable Sensor-based Cross-Person Activity Recognition",
    "abstract": "In wearable-sensor-based activity recognition, it is often assumed that the training and test samples follow the same data distribution. This assumption neglects practical scenarios where the activity patterns inevitably vary from person to person. To solve this problem, transfer learning and domain adaptation approaches are often leveraged to reduce the gaps between different participants. Nevertheless, these approaches require additional information (i.e., labeled or unlabeled data, meta-information) from the target domain during the training stage. In this paper, we introduce a novel method named Generalizable Independent Latent Excitation (GILE) for human activity recognition, which greatly enhances the cross-person generalization capability of the model. Our proposed method is superior to existing methods in the sense that it does not require any access to the target domain information. Besides, this novel model can be directly applied to various target domains without re-training or fine-tuning. Specifically, the proposed model learns to automatically disentangle domain-agnostic and domain-specific features, the former of which are expected to be invariant across various persons. To further remove correlations between the two types of features, a novel Independent Excitation mechanism is incorporated in the latent feature space. Comprehensive experimental evaluations are conducted on three benchmark datasets to demonstrate the superiority of the proposed method over the state-of-the-art solutions",
    "volume": "main",
    "checked": true,
    "id": "266a35c51001be877cc970323ba8c65c7ac60811",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17417": {
    "title": "Minimax Regret Optimisation for Robust Planning in Uncertain Markov Decision Processes",
    "abstract": "The parameters for a Markov Decision Process (MDP) often cannot be specified exactly. Uncertain MDPs (UMDPs) capture this model ambiguity by defining sets which the parameters belong to. Minimax regret has been proposed as an  objective for planning in UMDPs to find robust policies which are not overly conservative. In this work, we focus on planning for Stochastic Shortest Path (SSP) UMDPs with uncertain cost and transition functions. We introduce a Bellman equation to compute the regret for a policy. We propose a dynamic programming algorithm that utilises the regret Bellman equation, and show that it optimises minimax regret exactly for UMDPs with independent uncertainties. For coupled uncertainties, we extend our approach to use options to enable a trade off between computation and solution quality. We evaluate our approach on both synthetic and real-world domains, showing that it significantly outperforms existing baselines",
    "volume": "main",
    "checked": true,
    "id": "fd57b053a67826416ec24cea3cf0054770edf897",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17418": {
    "title": "An LP-Based Approach for Goal Recognition as Planning",
    "abstract": "Goal recognition aims to recognize the set of candidate goals that are compatible with the observed behavior of an agent. In this paper, we develop a method based on the operator-counting framework that efficiently computes solutions that satisfy the observations and uses the information generated to solve goal recognition tasks. Our method reasons explicitly about both partial and noisy observations: estimating uncertainty for the former, and satisfying observations given the unreliability of the sensor for the latter. We evaluate our approach empirically over a large data set, analyzing its components on how each can impact the quality of the solutions. In general, our approach is superior to previous methods in terms of agreement ratio, accuracy, and spread. Finally, our approach paves the way for new research on combinatorial optimization to solve goal recognition tasks",
    "volume": "main",
    "checked": true,
    "id": "3e17cd14aca1bd1405d28e673f85fa9c420b30f8",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17419": {
    "title": "Saturated Post-hoc Optimization for Classical Planning",
    "abstract": "Saturated cost partitioning and post-hoc optimization are two powerful cost partitioning algorithms for optimal classical planning. The main idea of saturated cost partitioning is to give each considered heuristic only the fraction of remaining operator costs that it needs to prove its estimates. We show how to apply this idea to post-hoc optimization and obtain a heuristic that dominates the original both in theory and on the IPC benchmarks",
    "volume": "main",
    "checked": true,
    "id": "65a793266aedaeccf883cee50026f12f77a49c5c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17420": {
    "title": "Improved Knowledge Modeling and Its Use for Signaling in Multi-Agent Planning with Partial Observability",
    "abstract": "Collaborative Multi-Agent Planning (MAP) problems with uncertainty and partial observability are often modeled as Dec-POMDPs. Yet, in deterministic domains, Qualitative Dec-POMDPs can scale up to much larger problem sizes. The best current QDec solver (QDec-FP) reduces MAP problems to multiple single-agent problems. In this paper, we describe a planner that uses richer information about agents knowledge to improve upon QDec-FP. With this change, the planner not only scales up to larger problems with more objects, but it can also support signaling, where agents signal information to each other by changing the state of the world",
    "volume": "main",
    "checked": true,
    "id": "9a312bddb3cf8c7ac94f79880526373c58c40ace",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17421": {
    "title": "Planning with Learned Object Importance in Large Problem Instances using Graph Neural Networks",
    "abstract": "Real-world planning problems often involve hundreds or even thousands of objects, straining the limits of modern planners. In this work, we address this challenge by learning to predict a small set of objects that, taken together, would be sufficient for finding a plan. We propose a graph neural network architecture for predicting object importance in a single inference pass, thus incurring little overhead while greatly reducing the number of objects that must be considered by the planner. Our approach treats the planner and transition model as black boxes, and can be used with any off-the-shelf planner. Empirically, across classical planning, probabilistic planning, and robotic task and motion planning, we find that our method results in planning that is significantly faster than several baselines, including other partial grounding strategies and lifted planners. We conclude that learning to predict a sufficient set of objects for a planning problem is a simple, powerful, and general mechanism for planning in large instances. Video: https://youtu.be/FWsVJc2fvCE Code: https://git.io/JIsqX",
    "volume": "main",
    "checked": true,
    "id": "1953f68b785c7ed2a7a61d6bffe4b18f0dff1172",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17422": {
    "title": "Symbolic Search for Oversubscription Planning",
    "abstract": "The objective of optimal oversubscription planning is to find a plan that yields an end state with a maximum utility while keeping plan cost under a certain bound. In practice, the situation occurs whenever a large number of possible, often competing goals of varying value exist, or the resources are not sufficient to achieve all goals. In this paper, we investigate the use of symbolic search for optimal oversubscription planning. Specifically, we show how to apply symbolic forward search to oversubscription planning tasks and prove that our approach is sound, complete and optimal. An empirical analysis shows that our symbolic approach favorably competes with explicit state-space heuristic search, the current state of the art for oversubscription planning",
    "volume": "main",
    "checked": true,
    "id": "d7473164b88ac661480a9f285148af2a92d76204",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17423": {
    "title": "Online Action Recognition",
    "abstract": "Recognition in planning seeks to find agent intentions, goals or activities given a set of observations and a knowledge library (e.g. goal states, plans or domain theories). In this work we introduce the problem of Online Action Recognition. It consists in recognizing, in an open world, the planning action that best explains a partially observable state transition from a knowledge library of first-order STRIPS actions, which is initially empty. We frame this as an optimization problem, and propose two algorithms to address it: Action Unification (AU) and Online Action Recognition through Unification (OARU). The former builds on logic unification and generalizes two input actions using weighted partial MaxSAT. The latter looks for an action within the library that explains an observed transition. If there is such action, it generalizes it making use of AU, building in this way an AU hierarchy. Otherwise, OARU inserts a Trivial Grounded Action (TGA) in the library that explains just that transition. We report results on benchmarks from the International Planning Competition and PDDLGym, where OARU recognizes actions accurately with respect to expert knowledge, and shows real-time performance.",
    "volume": "main",
    "checked": true,
    "id": "e8d0b7101de9530f358dffb84d75ea037b210d2f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17424": {
    "title": "A Complexity-theoretic Analysis of Green Pickup-and-Delivery Problems",
    "abstract": "In a Green Pickup-and-Delivery problem (GPD), vehicles traveling in a transport network achieving pickup-and-delivery tasks are in particular subject to the two \\textit{green} constraints: limited vehicle fuel capacity thus short vehicle traveling range, and limited availability of refueling infrastructure for the vehicles. GPD adds additional but probably insignificant computational complexity to the classic and already NP-hard Pickup-and-Delivery problem and Vehicle Routing Problem. Nevertheless, we demonstrate in this paper an inherent intractability of these green components themselves. More precisely, we show that GPD problems whose total constraints are reduced to almost the green ones only, remain to be NP-complete in the strong sense. We figure out a specifically constrained variant of GPD that, however, is weakly NP-complete -- a practical pseudo-polynomial time algorithm solving the variant problem is identified. Insight obtained from this complexity-theoretic analysis would shed light for a deeper understanding of GPDs, and on better development of heuristics for solving these problems, leading to promisingly many real-world applications",
    "volume": "main",
    "checked": true,
    "id": "66ff30ee41f5714f6abc032b2467dd6412ee25cf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17425": {
    "title": "Faster Stackelberg Planning via Symbolic Search and Information Sharing",
    "abstract": "Stackelberg planning is a recent framework where a leader and a follower each choose a plan in the same planning task, the leader's objective being to maximize plan cost for the follower. This formulation naturally captures security-related (leader=defender, follower=attacker) as well as robustness-related (leader=adversarial event, follower=agent) scenarios. Solving Stackelberg planning tasks requires solving many related planning tasks at the follower level (in the worst case, one for every possible leader plan). Here we introduce new methods to tackle this source of complexity, through sharing information across follower tasks. Our evaluation shows that these methods can significantly reduce both the time needed to solve follower tasks and the number of follower tasks that need to be solved in the first place",
    "volume": "main",
    "checked": true,
    "id": "2f3c8bf60984277f22b30a882d6154fc0548065a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17426": {
    "title": "On the Optimal Efficiency of A* with Dominance Pruning",
    "abstract": "A well known result is that, given a consistent heuristic and no other source of information, A* does expand a minimal number of nodes up to tie-breaking. We extend this analysis for A* with dominance pruning, which exploits a dominance relation to eliminate some nodes during the search. We show that the expansion order of A* is not necessarily optimally efficient when considering dominance pruning with arbitrary dominance relations, but it remains optimally efficient under certain restrictions for the heuristic and dominance relation",
    "volume": "main",
    "checked": true,
    "id": "66eb9a0592f5eace71f96974c142060085c914e8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17427": {
    "title": "Dynamic Automaton-Guided Reward Shaping for Monte Carlo Tree Search",
    "abstract": "Reinforcement learning and planning have been revolutionized in recent years, due in part to the mass adoption of deep convolutional neural networks and the resurgence of powerful methods to refine decision-making policies. However, the problem of sparse reward signals and their representation  remains pervasive in many domains. While various rewardshaping mechanisms and imitation learning approaches have been proposed to mitigate this problem, the use of humanaided artificial rewards introduces human error, sub-optimal behavior, and a greater propensity for reward hacking. In this  paper, we mitigate this by representing objectives as automata in order to define novel reward shaping functions over this structured representation. In doing so, we address the sparse rewards problem within a novel implementation of Monte Carlo Tree Search (MCTS) by proposing a reward shaping function which is updated dynamically to capture statistics on the utility of each automaton transition as it pertains to satisfying the goal of the agent. We further demonstrate that such automaton-guided reward shaping can be utilized to facilitate transfer learning between different environments when the objective is the same",
    "volume": "main",
    "checked": true,
    "id": "23ddceb162d6f8b63a0a17ad9a7036b78f4155d9",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17428": {
    "title": "Asking the Right Questions: Learning Interpretable Action Models Through Query Answering",
    "abstract": "This paper develops a new approach for estimating an interpretable, relational model of a black-box autonomous agent that can plan and act. Our main contributions are a new paradigm for estimating such models using a rudimentary query interface with the agent and a hierarchical querying algorithm that generates an interrogation policy for estimating the agent's internal model in a user-interpretable vocabulary. Empirical evaluation of our approach shows that despite the intractable search space of possible agent models, our approach allows correct and scalable estimation of interpretable agent models for a wide class of black-box autonomous agents. Our results also show that this approach can use predicate classifiers to learn interpretable models of planning agents that represent states as images",
    "volume": "main",
    "checked": true,
    "id": "3772cdcdbaccd8c118fc0870557d1bd9ee01a743",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17429": {
    "title": "Competitive Analysis for Two-Level Ski-Rental Problem",
    "abstract": "In this paper, we study a two-level ski-rental problem. There are multiple commodities, each one can be \"rented\" (paying for on-demand usage) or \"purchased\" (paying for life-time usage). There is also a combo purchase available so that all commodities can be purchased as a combo. Since the usages of the commodities in future are not known in advance, to minimize the overall cost, we design an online algorithm to decide if we rent a commodity, purchase a commodity, or make a combo purchase. We first propose a deterministic online algorithm. It can achieve 3 competitive ratio, which is optimal and tight. Next, we further propose a randomized online algorithm, leading to a e^/(e^-1) competitive ratio, where  is the ratio between the price of a single commodity and the price of combo purchase. Finally, we apply simulation to verify the theoretical competitive ratios and evaluate the actual performance against benchmarks",
    "volume": "main",
    "checked": true,
    "id": "b4d2551574eca4ad85787b8fd950315db0446dec",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17430": {
    "title": "Multi-Decoder Attention Model with Embedding Glimpse for Solving Vehicle Routing Problems",
    "abstract": "We present a novel deep reinforcement learning method to learn construction heuristics for vehicle routing problems. In specific, we propose a Multi-Decoder Attention Model (MDAM) to train multiple diverse policies, which effectively increases the chance of finding good solutions compared with existing methods that train only one policy. A customized beam search strategy is designed to fully exploit the diversity of MDAM. In addition, we propose an Embedding Glimpse layer in MDAM based on the recursive nature of construction, which can improve the quality of each policy by providing more informative embeddings. Extensive experiments on six different routing problems show that our method significantly outperforms the state-of-the-art deep learning based models",
    "volume": "main",
    "checked": true,
    "id": "de741d317507e21d3f7d3f8107d5b685db455aff",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17431": {
    "title": "Group Fairness by Probabilistic Modeling with Latent Fair Decisions",
    "abstract": "Machine learning systems are increasingly being used to make impactful decisions such as loan applications and criminal justice risk assessments, and as such, ensuring fairness of these systems is critical. This is often challenging as the labels in the data are biased. This paper studies learning fair probability distributions from biased data by explicitly modeling a latent variable that represents a hidden, unbiased label. In particular, we aim to achieve demographic parity by enforcing certain independencies in the learned model. We also show that group fairness guarantees are meaningful only if the distribution used to provide those guarantees indeed captures the real-world data. In order to closely model the data distribution, we employ probabilistic circuits, an expressive and tractable probabilistic model, and propose an algorithm to learn them from incomplete data. We show on real-world datasets that our approach not only is a better model of how the data was generated than existing methods but also achieves competitive accuracy. Moreover, we also evaluate our approach on a synthetic dataset in which observed labels indeed come from fair labels but with added bias, and demonstrate that the fair labels are successfully retrieved",
    "volume": "main",
    "checked": true,
    "id": "2399382f0e0fe4e50a10786cd6b304074906d1ee",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17432": {
    "title": "GO Hessian for Expectation-Based Objectives",
    "abstract": "An unbiased low-variance gradient estimator, termed GO gradient, was proposed recently for expectation-based objectives E_q_(y) [f(y)], where the random variable (RV) y may be drawn from a stochastic computation graph (SCG) with continuous (non-reparameterizable) internal nodes and continuous/discrete leaves. Based on the GO gradient, we present for E_q_(y) [f(y)] an unbiased low-variance Hessian estimator, named GO Hessian, which contains the deterministic Hessian as a special case. Considering practical implementation, we reveal that the GO Hessian in expectation obeys the chain rule and is therefore easy-to-use with auto-differentiation and Hessian-vector products, enabling efficient cheap exploitation of curvature information over deep SCGs. As representative examples, we present the GO Hessian for non-reparameterizable gamma and negative binomial RVs/nodes. Leveraging the GO Hessian, we develop a new second-order method for E_q_(y) [f(y)], with challenging experiments conducted to verify its effectiveness and efficiency",
    "volume": "main",
    "checked": true,
    "id": "fc6f2fddd21f0a638ec8cfd26573ce908dc80e3f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17433": {
    "title": "Better Bounds on the Adaptivity Gap of Influence Maximization under Full-adoption Feedback",
    "abstract": "In the influence maximization (IM) problem, we are given a social network and a budget k, and we look for a set of k nodes in the network, called seeds, that maximize the expected number of nodes that are reached by an influence cascade generated by the seeds, according to some stochastic model for influence diffusion. Extensive studies have been done on the IM problem, since his definition by Kempe, Kleinberg, and Tardos (2003). However, most of the work focuses on the non-adaptive version of the problem where all the k seed nodes must be selected before that the cascade starts. In this paper we study the adaptive IM, where the nodes are selected sequentially one by one, and the decision on the i-th seed can be based on the observed cascade produced by the first i-1 seeds. We focus on the full-adoption feedback in which we can observe the entire cascade of each previously selected seed and on the independent cascade model where each edge is associated with an independent probability of diffusing influence. Previous works showed that there are constant upper bounds on the adaptivity gap, which compares the performance of an adaptive algorithm against a non-adaptive one, but the analyses used to prove these bounds only works for specific graph classes such as in-arborescences, out-arborescences, and one-directional bipartite graphs. Our main result is the first sub-linear upper bound that holds for any graph. Specifically, we show that the adaptivity gap is upper-bounded by n+1, where n is the number of nodes in the graph. Moreover we improve over the known upper bound for in-arborescences from 2e/(e-1)3.16 to 2e/(e-1)2.31. Finally, we study -bounded graphs, a class of undirected graphs in which the sum of node degrees higher than two is at most , and show that the adaptivity gap is upper-bounded by +O(1). Moreover, we show that in 0-bounded graphs, i.e. undirected graphs in which each connected component is a path or a cycle, the adaptivity gap is at most 3e/(e-1)3.16. To prove our bounds, we introduce new techniques to relate adaptive policies with non-adaptive ones that might be of their own interest",
    "volume": "main",
    "checked": true,
    "id": "1b74f4ac24524bc221a611425b4c77df0cdf79a5",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17434": {
    "title": "Uncertainty Quantification in CNN Through the Bootstrap of Convex Neural Networks",
    "abstract": "Despite the popularity of Convolutional Neural Networks (CNN), the problem of uncertainty quantification (UQ) of CNN has been largely overlooked. Lack of efficient UQ tools severely limits the application of CNN in certain areas, such as medicine, where prediction uncertainty is critically important. Among the few existing UQ approaches that have been proposed for deep learning, none of them has theoretical consistency that can guarantee the uncertainty quality. To address this issue, we propose a novel bootstrap based framework for the estimation of prediction uncertainty. The inference procedure we use relies on convexified neural networks to establish the theoretical consistency of bootstrap. Our approach has a significantly less computational load than its competitors, as it relies on warm-starts at each bootstrap that avoids refitting the model from scratch. We further explore a novel transfer learning method so our framework can work on arbitrary neural networks. We experimentally demonstrate our approach has a much better performance compared to other baseline CNNs and state-of-the-art methods on various image datasets",
    "volume": "main",
    "checked": true,
    "id": "39b37e6c3e74907ca3bdb778e4e878f205693c53",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17435": {
    "title": "Scalable First-Order Methods for Robust MDPs",
    "abstract": "Robust Markov Decision Processes (MDPs) are a powerful framework for modeling sequential decision making problems with model uncertainty. This paper proposes the first first-order framework for solving robust MDPs. Our algorithm interleaves primal-dual first-order updates with approximate Value Iteration updates. By carefully controlling the tradeoff between the accuracy and cost of Value Iteration updates, we achieve an ergodic convergence rate that is significantly better than classical Value Iteration algorithms in terms of the number of states S and the number of actions A on ellipsoidal and Kullback-Leibler s-rectangular uncertainty sets. In numerical experiments on ellipsoidal uncertainty sets we show that our algorithm is significantly more scalable than state-of-the-art approaches. Our framework is also the first one to solve robust MDPs with s-rectangular KL uncertainty sets",
    "volume": "main",
    "checked": true,
    "id": "2b82e54f1620d95e91a8ab240c8081ff9fa889df",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17436": {
    "title": "High Dimensional Level Set Estimation with Bayesian Neural Network",
    "abstract": "Level Set Estimation (LSE) is an important problem with applications in various fields such as material design, biotechnology, machine operational testing, etc. Existing techniques suffer from the scalability issue, that is, these methods do not work well with high dimensional inputs. This paper proposes novel methods to solve the high dimensional LSE problems using Bayesian Neural Networks. In particular, we consider two types of LSE problems: (1) explicit LSE problem where the threshold level is a fixed user-specified value, and, (2) implicit LSE problem where the threshold level is defined as a percentage of the (unknown) maximum of the objective function. For each problem, we derive the corresponding theoretic information based acquisition function to sample the data points so as to maximally increase the level set accuracy. Furthermore, we also analyse theoretical time complexity of our proposed acquisition functions, and suggest a practical methodology to efficiently tune the network hyper-parameters to achieve high model accuracy. Numerical experiments on both synthetic and real-world datasets show that our proposed methods can achieve better results compared to existing state-of-the-art approaches",
    "volume": "main",
    "checked": true,
    "id": "f7225998cd2c14958701c9c87f5324b88b6237b9",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17437": {
    "title": "A Generative Adversarial Framework for Bounding Confounded Causal Effects",
    "abstract": "Causal inference from observational data is receiving wide applications in many fields. However, unidentifiable situations, where causal effects cannot be uniquely computed from observational data, pose critical barriers to applying causal inference to complicated real applications. In this paper, we develop a bounding method for estimating the average causal effect (ACE) under unidentifiable situations due to hidden confounding based on Pearl's structural causal model.  We propose to parameterize the unknown exogenous random variables and structural equations of a causal model using neural networks and implicit generative models. Then, using an adversarial learning framework, we search the parameter space to explicitly traverse causal models that agree with the given observational distribution, and find those that minimize or maximize the ACE to obtain its lower and upper bounds. The proposed method does not make assumption about the type of structural equations and variables. Experiments using both synthetic and real-world datasets are conducted",
    "volume": "main",
    "checked": true,
    "id": "f8a27911dff2050b9f0a608bad555df8a0ce34d3",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17438": {
    "title": "Estimating Identifiable Causal Effects through Double Machine Learning",
    "abstract": "Identifying causal effects from observational data is a pervasive challenge found throughout the empirical sciences. Very general methods have been developed to decide the identifiability of a causal quantity from a combination of observational data and causal knowledge about the underlying system. In practice, however, there are still challenges to estimating identifiable causal functionals from finite samples. Recently, a method known as double/debiased machine learning (DML) (Chernozhukov et al. 2018) has been proposed to learn parameters leveraging modern machine learning techniques, which is both robust to model misspecification and bias-reducing. Still, DML has only been used for causal estimation in settings when the back-door condition (also known as conditional ignorability) holds. In this paper, we develop a new, general class of estimators for any identifiable causal functionals that exhibit DML properties, which we name DML-ID. In particular, we introduce a complete identification algorithm that returns an influence function (IF) for any identifiable causal functional. We then construct the DML estimator based on the derived IF. We show that DML-ID estimators hold the key properties of debiasedness and doubly robustness. Simulation results corroborate with the theory",
    "volume": "main",
    "checked": true,
    "id": "e61043229980ac73333ec8cb9afd75ecc3694895",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17439": {
    "title": "Relational Boosted Bandits",
    "abstract": "Contextual bandits algorithms have become essential in real-world user interaction problems in recent years. However, these algorithms represent context as attribute value representation, which makes them infeasible for real world domains like social networks, which are inherently relational. We propose Relational Boosted Bandits   (RB2), a contextual bandits algorithm for relational domains based on (relational) boosted trees. RB2 enables us to learn interpretable and explainable models due to the more descriptive nature of the relational representation. We empirically demonstrate the effectiveness and interpretability of RB2 on tasks such as link prediction, relational classification, and recommendation",
    "volume": "main",
    "checked": true,
    "id": "36cfdf79c7140afaeff94f15849ae4774dc7f2c1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17440": {
    "title": "Instrumental Variable-based Identification for Causal Effects using Covariate Information",
    "abstract": "This paper deals with the identification problem of causal effects in randomized trials with noncompliance. In this problem, generally, causal effects are not identifiable and thus have been evaluated under some strict assumptions, or through the bounds. Different from existing studies, we propose novel identification conditions of joint probabilities of potential outcomes, which allow us to derive a consistent estimator of the causal effect. Regarding the identification conditions of joint probabilities of potential outcomes, the assumptions of monotonicity (Pearl, 2009), independence between potential outcomes (Robins & Richardson, 2011), gain equality (Li & Pearl, 2019) and specific functional relationships between cause and effect (Pearl, 2009) have been utilized. In contrast, without such assumptions, the proposed conditions enable us to evaluate joint probabilities of potential outcomes using an instrumental variable and a proxy variable of potential outcomes. The results of this paper extend the range of solvable identification problems in causal inference",
    "volume": "main",
    "checked": true,
    "id": "9a4df35258c73d1151dc2d249be9cbb3fa42d3cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17441": {
    "title": "Learning Continuous High-Dimensional Models using Mutual Information and Copula Bayesian Networks",
    "abstract": "We propose a new framework to learn non-parametric graphical models from continuous observational data.  Our method is based on concepts from information theory in order to discover independences and causality between variables: the conditional and multivariate mutual information (such as \\cite{verny2017learning} for discrete models).  To estimate these quantities, we propose non-parametric estimators relying on the Bernstein copula and that are constructed by exploiting the relation between the mutual information and the copula entropy \\cite{ma2011mutual, belalia2017testing}.  To our knowledge, this relation is only documented for the bivariate case and, for the need of our algorithms, is here extended to the conditional and multivariate mutual information. This framework leads to a new algorithm to learn continuous non-parametric Bayesian network. Moreover, we use this estimator to   speed up the BIC algorithm proposed in \\cite{elidan2010copula} by taking advantage of the decomposition of the likelihood function in a sum of mutual   information \\cite{koller2009probabilistic}. Finally, our method is compared in terms of performances and complexity with other state of the art techniques to learn Copula Bayesian Networks and shows superior results. In particular, it needs less data to recover the true structure and generalizes better on data that are not sampled from Gaussian distributions",
    "volume": "main",
    "checked": true,
    "id": "e69143d71a1a71df0648d91ecd369df1560931d7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17442": {
    "title": "Submodel Decomposition Bounds for Influence Diagrams",
    "abstract": "Influence diagrams (IDs) are graphical models for representing and reasoning with sequential decision-making problems under uncertainty. Limited memory influence diagrams (LIMIDs) model a decision-maker (DM) who forgets the history in the course of making a sequence of decisions. The standard inference task in IDs and LIMIDs is to compute the maximum expected utility (MEU), which is one of the most challenging tasks in graphical models. We present a model decomposition framework in both IDs and LIMIDs, which we call submodel decomposition that generates a tree of single-stage decision problems through a tree clustering scheme. We also develop a valuation algebra over the submodels that leads to a hierarchical message passing algorithm that propagates conditional expected utility functions over a submodel-tree as external messages. We show that the overall complexity is bounded by the maximum tree-width over the submodels, common in graphical model algorithms. Finally, we present a new method for computing upper bounds over a submodel-tree by first exponentiating the utility functions yielding a standard probabilistic graphical model as an upper bound and then applying standard variational upper bounds for the marginal MAP inference, yielding tighter upper bounds compared with state-of-the-art bounding schemes for the MEU task",
    "volume": "main",
    "checked": true,
    "id": "4887823ddab3ae231ece6ed10953d6055830115b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17443": {
    "title": "A New Bounding Scheme for Influence Diagrams",
    "abstract": "Influence diagrams provide a modeling and inference framework for sequential decision problems, representing the probabilistic knowledge by a Bayesian network and the preferences of an agent by utility functions over the random variables and decision variables. Computing the maximum expected utility (MEU) and the optimizing policy is exponential in the constrained induced width and therefore is notoriously difficult for larger models. In this paper, we develop a new bounding scheme for MEU that applies partitioning based approximations on top of the decomposition scheme called a multi-operator cluster DAG for influence diagrams that is more sensitive to the underlying structure of the model than the classical join-tree decomposition of influence diagrams. Our bounding scheme utilizes a cost-shifting mechanism to tighten the bound further. We demonstrate the effectiveness of the proposed scheme on various hard benchmarks",
    "volume": "main",
    "checked": true,
    "id": "480cabaef43a4cebc9b76f32083eaecdec97f630",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17444": {
    "title": "Estimation of Spectral Risk Measures",
    "abstract": "We consider the problem of estimating a spectral risk measure (SRM) from i.i.d. samples, and propose a novel method that is based on numerical integration. We show that our SRM estimate concentrates exponentially, when the underlying distribution has bounded support. Further, we also consider the case when the underlying distribution satisfies an exponential moment bound, which includes sub-Gaussian and subexponential distributions. For these distributions, we derive a concentration bound for our estimation scheme. We validate the theoretical findings on a synthetic setup, and in a vehicular traffic routing application",
    "volume": "main",
    "checked": true,
    "id": "20ab1b5396ce86610301e358e397397bfa0d112e",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17445": {
    "title": "Probabilistic Dependency Graphs",
    "abstract": "We introduce Probabilistic Dependency Graphs (PDGs), a new class of directed graphical models. PDGs can capture inconsistent beliefs in a natural way and are more modular than Bayesian Networks (BNs), in that they make it easier to incorporate new information and restructure the representation. We show by example how PDGs are an especially natural modeling tool. We provide three semantics for PDGs, each of which can be derived from a scoring function (on joint distributions over the variables in the network) that can be viewed as representing a distribution's incompatibility with the PDG. For the PDG corresponding to a BN, this function is uniquely minimized by the distribution the BN represents, showing that PDG semantics extend BN semantics. We show further that factor graphs and their exponential families can also be faithfully represented as PDGs, while there are significant barriers to modeling a PDG with a factor graph",
    "volume": "main",
    "checked": true,
    "id": "343e8db7641a839871fbdd99248ac2f4bc11a77c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17446": {
    "title": "Robust Contextual Bandits via Bootstrapping",
    "abstract": "Upper confidence bound (UCB) based contextual bandit algorithms require one to know the tail property of the reward distribution. Unfortunately, such tail property is usually unknown or difficult to specify in real-world applications. Using a tail property heavier than the ground truth leads to a slow learning speed of the contextual bandit algorithm, while using a lighter one may cause the algorithm to diverge. To address this fundamental problem, we develop an estimator (evaluated from historical rewards) for the contextual bandit UCB based on the multiplier bootstrapping technique. We first establish sufficient conditions under which our estimator converges asymptotically to the ground truth of contextual bandit UCB. We further derive a second order correction for our estimator so as to obtain its confidence level with a finite number of rounds. To demonstrate the versatility of the estimator, we apply it to design a BootLinUCB algorithm for the contextual bandit. We prove that the BootLinUCB has a sub-linear regret upper bound and also conduct extensive experiments to validate its superior performance",
    "volume": "main",
    "checked": true,
    "id": "043f436601ab95cf2e85985ef71e413ef6bceb6f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17447": {
    "title": "Learning the Parameters of Bayesian Networks from Uncertain Data",
    "abstract": "The creation of Bayesian networks often requires the specification of a large number of parameters, making it highly desirable to be able to learn these parameters from historical data. In many cases, such data has uncertainty associated with it, including cases in which this data comes from unstructured analysis or from sensors. When creating diagnosis networks, for example, unstructured analysis algorithms can be run on the historical text descriptions or images of previous cases so as to extract data for learning Bayesian network parameters, but such derived data has inherent uncertainty associated with it due to the nature of such algorithms.   Because of the inability of current Bayesian network parameter learning algorithms to incorporate such uncertainty, common approaches either ignore this uncertainty, thus reducing the resulting accuracy, or completely disregard such data. We present an approach for learning Bayesian network parameters that explicitly incorporates such uncertainty, and which is a natural extension of the Bayesian network formalism. We present a generalization of the Expectation Maximization parameter learning algorithm that enables it to handle any historical data with likelihood-evidence-based uncertainty, as well as an empirical validation demonstrating the improved accuracy and convergence enabled by our approach. We also prove that our extended algorithm maintains the convergence and correctness properties of the original EM algorithm, while explicitly incorporating data uncertainty in the learning process",
    "volume": "main",
    "checked": true,
    "id": "1f2834023db96d465b99f4b3ff91001122aa7fab",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17448": {
    "title": "Polynomial-Time Algorithms for Counting and Sampling Markov Equivalent DAGs",
    "abstract": "Counting and uniform sampling of directed acyclic graphs (DAGs) from a Markov equivalence class are fundamental tasks in graphical causal analysis. In this paper, we show that these tasks can be performed in polynomial time, solving a long-standing open problem in this area. Our algorithms are effective and easily implementable. Experimental results show that the algorithms significantly outperform state-of-the-art methods",
    "volume": "main",
    "checked": true,
    "id": "6b80dea61e74a65b9ab0b0590932a3dc175f1755",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17449": {
    "title": "Bounding Causal Effects on Continuous Outcome",
    "abstract": "We investigate the problem of bounding causal effects from experimental studies in which treatment assignment is randomized but the subject compliance is imperfect. It is well known that under such conditions, the actual causal effects are not point-identifiable due to uncontrollable unobserved confounding. In their seminal work, Balke and Pearl (1994) derived the tightest bounds over the causal effects in this settings by employing an algebra program to derive analytic expressions. However, Pearl's approach assumes the primary outcome to be discrete and finite. Solving such a program could be intractable when high-dimensional context variables are present. In this paper, we present novel non-parametric methods to bound causal effects on the continuous outcome from studies with imperfect compliance. These bounds could be generalized to settings with a high-dimensional context",
    "volume": "main",
    "checked": true,
    "id": "1e3ce576c8ae00f99cb8195d83248921e7f82eb4",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17450": {
    "title": "A Fast Exact Algorithm for the Resource Constrained Shortest Path Problem",
    "abstract": "Resource constrained path finding is a well studied topic in AI, with real-world applications in different areas such as transportation and robotics. This paper introduces several heuristics in the resource constrained path finding context that significantly improve the algorithmic performance of the initialisation phase and the core search. We implement our heuristics on top of a bidirectional A* algorithm and evaluate them on a set of large instances. The experimental results show that, for the first time in the context of constrained path finding, our fast and enhanced algorithm can solve all of the benchmark instances to optimality, and compared to the state of the art algorithms, it can improve existing runtimes by up to four orders of magnitude on large-size network graphs",
    "volume": "main",
    "checked": true,
    "id": "76cf81c91246e11cde6ad4d434b529b63a09cc2d",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17451": {
    "title": "Generalization in Portfolio-Based Algorithm Selection",
    "abstract": "Portfolio-based algorithm selection has seen tremendous practical success over the past two decades. This algorithm configuration procedure works by first selecting a portfolio of diverse algorithm parameter settings, and then, on a given problem instance, using an algorithm selector to choose a parameter setting from the portfolio with strong predicted performance. Oftentimes, both the portfolio and the algorithm selector are chosen using a training set of typical problem instances from the application domain at hand. In this paper, we provide the first provable guarantees for portfolio-based algorithm selection. We analyze how large the training set should be to ensure that the resulting algorithm selector's average performance over the training set is close to its future (expected) performance. This involves analyzing three key reasons why these two quantities may diverge: 1) the learning-theoretic complexity of the algorithm selector, 2) the size of the portfolio, and 3) the learning-theoretic complexity of the algorithm's performance as a function of its parameters. We introduce an end-to-end learning-theoretic analysis of the portfolio construction and algorithm selection together. We prove that if the portfolio is large, overfitting is inevitable, even with an extremely simple algorithm selector. With experiments, we illustrate a tradeoff exposed by our theoretical analysis: as we increase the portfolio size, we can hope to include a well-suited parameter setting for every possible problem instance, but it becomes impossible to avoid overfitting",
    "volume": "main",
    "checked": true,
    "id": "96cf13802df40124a8053530187e2879f6137699",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17452": {
    "title": "Combining Preference Elicitation with Local Search and Greedy Search for Matroid Optimization",
    "abstract": "We propose two incremental preference elicitation methods for interactive preference-based optimization on weighted matroid structures. More precisely, for linear objective (utility) functions, we propose an interactive greedy algorithm interleaving preference queries with the incremental construction of an independent set to obtain an optimal or near-optimal base of a matroid. We also propose an interactive local search algorithm based on sequences of possibly improving exchanges for the same problem. For both algorithms, we provide performance guarantees on the quality of the returned solutions and the number of queries. Our algorithms are tested on the uniform, graphical and scheduling matroids to solve three different problems (committee election, spanning tree, and scheduling problems) and evaluated in terms of computation times, number of queries, and empirical error",
    "volume": "main",
    "checked": true,
    "id": "5f0ffbe98dbf70951fecde8abf1f631bd4c382a5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17453": {
    "title": "f-Aware Conflict Prioritization & Improved Heuristics For Conflict-Based Search",
    "abstract": "Conflict-Based Search (CBS) is a leading two-level algorithm for optimal Multi-Agent Path Finding (MAPF). The main step of CBS is to expand nodes by resolving conflicts (where two agents collide). Choosing the right conflict to resolve can greatly speed up the search. CBS first resolves conflicts where the costs (g-values) of the resulting child nodes are larger than the cost of the node to be split. However, the recent addition of high-level heuristics to CBS and expanding nodes according to f=g+h reduces the relevance of this conflict prioritization method. Therefore, we introduce an expanded categorization of conflicts, which first resolves conflicts where the f-values of the child nodes are larger than the f-value of the node to be split, and present a method for identifying such conflicts. We also enhance all known heuristics for CBS by using information about the cost of resolving certain conflicts, and with only a small computational overhead. Finally, we experimentally demonstrate that both the expanded categorization of conflicts and the improved heuristics contribute to making CBS even more efficient",
    "volume": "main",
    "checked": true,
    "id": "2c212e5fbe53e1bc2ea7459d571f139281f0a38a",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17454": {
    "title": "Parameterized Algorithms for MILPs with Small Treedepth",
    "abstract": "Solving (mixed) integer (linear) programs, (M)I(L)Ps for short, is a fundamental optimisation task with a wide range of applications in artificial intelligence and computer science in general. While hard in general, recent years have brought about vast progress for solving structurally restricted, (non-mixed) ILPs: n-fold, tree-fold, 2-stage stochastic and multi-stage stochastic programs admit efficient algorithms, and all of these special cases are subsumed by the class of ILPs of small treedepth. In this paper, we extend this line of work to the mixed case, by showing an algorithm solving MILP in time f(a,d)poly(n), where a is the largest coefficient of the constraint matrix, d is its treedepth, and n is the number of variables. This is enabled by proving bounds on the denominators (fractionality) of the vertices of bounded-treedepth (non-integer) linear programs. We do so by carefully analysing the inverses of invertible sub-matrices of the constraint matrix. This allows us to afford scaling up the mixed program to the integer grid, and applying the known methods for integer programs. We then trace the limiting boundary of our \"bounded fractionality\" approach both in terms of going beyond MILP (by allowing non-linear objectives) as well as its usefulness for generalising other important known tractable classes of ILP. On the positive side, we show that our result can be generalised from MILP to MIP with piece-wise linear separable convex objectives with integer breakpoints. On the negative side, we show that going even slightly beyond such objectives or considering other natural related tractable classes of ILP leads to unbounded fractionality. Finally, we show that restricting the structure of only the integral variables in the constraint matrix does not yield tractable special cases",
    "volume": "main",
    "checked": true,
    "id": "cb51f9ec601572e2c5e391534b38f689685a8739",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17455": {
    "title": "NuQClq: An Effective Local Search Algorithm for Maximum Quasi-Clique Problem",
    "abstract": "The maximum quasi-clique problem (MQCP) is an important extension of maximum clique problem with wide applications. Recent heuristic MQCP algorithms can hardly solve large and hard graphs effectively. This paper develops an efficient local search algorithm named NuQClq for the MQCP, which has two main ideas. First, we propose a novel vertex selection strategy, which utilizes cumulative saturation information to be a selection criterion when the candidate vertices have equal values on the primary scoring function. Second, a variant of configuration checking named BoundedCC is designed by setting an upper bound for the threshold of forbidding strength. When the threshold value of vertex exceeds the upper bound, we reset its threshold value to increase the diversity of search process. Experiments on a broad range of classic benchmarks and sparse instances show that NuQClq significantly outperforms the state-of-the-art MQCP algorithms for most instances",
    "volume": "main",
    "checked": true,
    "id": "2e6201e954c4f2435bb137b2ce387e5a68a3da1d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17456": {
    "title": "Symmetry Breaking for k-Robust Multi-Agent Path Finding",
    "abstract": "During Multi-Agent Path Finding (MAPF) problems, agentscan be delayed by unexpected events. To address suchsituations recent work describes k-Robust Conflict-BasedSearch (k-CBS): an algorithm that produces coordinated andcollision-free plan that is robust for up tokdelays. In thiswork we introducing a variety of pairwise symmetry break-ing constraints, specific tok-robust planning, that can effi-ciently find compatible and optimal paths for pairs of con-flicting agents. We give a thorough description of the newconstraints and report large improvements to success rate ina range of domains including: (i) classic MAPF benchmarks;(ii) automated warehouse domains and; (iii) on maps fromthe 2019 Flatland Challenge, a recently introduced railwaydomain wherek-robust planning can be fruitfully applied toschedule trains",
    "volume": "main",
    "checked": true,
    "id": "cdcca6a68b10d2672099e16af035f90dd0792d12",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17457": {
    "title": "Escaping Local Optima with Non-Elitist Evolutionary Algorithms",
    "abstract": "Most discrete evolutionary algorithms (EAs) implement elitism,  meaning that they make the biologically implausible assumption  that the fittest individuals never die. While elitism favours  exploitation and ensures that the best seen solutions are not  lost, it has been widely conjectured that non-elitism is  necessary to explore promising fitness valleys without getting  stuck in local optima. Determining when non-elitist EAs  outperform elitist EAs has been one of the most fundamental open  problems in evolutionary computation. A recent analysis of a  non-elitist EA shows that this algorithm does not outperform its  elitist counterparts on the benchmark problem JUMP. We solve this open problem through rigorous runtime analysis of  elitist and non-elitist population-based EAs on a class of  multi-modal problems. We show that with 3-tournament selection  and appropriate mutation rates, the non-elitist EA optimises the  multi-modal problem in expected polynomial time, while an elitist  EA requires exponential time with overwhelmingly high  probability. A key insight in our analysis is the non-linear selection profile  of the tournament selection mechanism which, with appropriate  mutation rates, allows a small sub-population to reside on the  local optimum while the rest of the population explores the  fitness valley. In contrast, we show that the comma-selection  mechanism which does not have this non-linear profile, fails to  optimise this problem in polynomial time. The theoretical analysis is complemented with an empirical  investigation on instances of the set cover problem, showing that  non-elitist EAs can perform better than the elitist ones. We also  provide examples where usage of mutation rates close to the error  thresholds is beneficial when employing non-elitist  population-based EAs",
    "volume": "main",
    "checked": true,
    "id": "14a49ead8a24423c9598e0c792c696fa3f760d4c",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17458": {
    "title": "Pareto Optimization for Subset Selection with Dynamic Partition Matroid Constraints",
    "abstract": "In this study, we consider the subset selection problems with submodular or monotone discrete objective functions under partition matroid constraints where the thresholds are dynamic. We focus on POMC, a simple Pareto optimization approach that has been shown to be effective on such problems. Our analysis departs from singular constraint problems and extends to problems of multiple constraints. We show that previous results of POMC's performance also hold for multiple constraints. Our experimental investigations on random undirected maxcut problems demonstrate POMC's competitiveness against the classical GREEDY algorithm with restart strategy",
    "volume": "main",
    "checked": true,
    "id": "bb150dc58656ab6f495506bee6a187516a430539",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17459": {
    "title": "Theoretical Analyses of Multi-Objective Evolutionary Algorithms on Multi-Modal Objectives",
    "abstract": "Previous theory work on multi-objective evolutionary algorithms considers mostly easy problems that are composed of unimodal objectives. This paper takes a first step towards a deeper understanding of how evolutionary algorithms solve multi-modal multi-objective problems. We propose the OneJumpZeroJump problem, a bi-objective problem with single objectives isomorphic to the classic jump function benchmark. We prove that the simple evolutionary multi-objective optimizer (SEMO) cannot compute the full Pareto front. In contrast, for all problem sizes n and all jump sizes [EQUATION], the global SEMO (GSEMO) covers the Pareto front in ((n-2k)nk) iterations in expectation. To improve the performance, we combine the GSEMO with two approaches, a heavy-tailed mutation operator and a stagnation detection strategy, that showed advantages in single-objective multi-modal problems. Runtime improvements of asymptotic order at least k(k) are shown for both strategies. Our experiments verify the substantial runtime gains already for moderate problem sizes. Overall, these results show that the ideas recently developed for single-objective evolutionary algorithms can be effectively employed also in multi-objective optimization. This Hot-off-the-Press paper summarizes \"Theoretical Analyses of Multi-Objective Evolutionary Algorithms on Multi-Modal Objectives\" by B. Doerr and W. Zheng, which has been accepted for publication in AAAI 2021 [9]",
    "volume": "main",
    "checked": true,
    "id": "9ecc5c23d24948c424020207f0d1bf7cfc93c88e",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17460": {
    "title": "Multi-Objective Submodular Maximization by Regret Ratio Minimization with Theoretical Guarantee",
    "abstract": "Submodular maximization has attracted much attention due to its wide application and attractive property. Previous works mainly considered one single objective function, while there can be multiple ones in practice. As the objectives are usually conflicting, there exists a set of Pareto optimal solutions, attaining different optimal trade-offs among multiple objectives. In this paper, we consider the problem of minimizing the regret ratio in multi-objective submodular maximization, which is to find at most k solutions to approximate the whole Pareto set as well as possible. We propose a new algorithm RRMS by sampling representative weight vectors and solving the corresponding weighted sums of objective functions using some given \\alpha-approximation algorithm for single-objective submodular maximization. We prove that the regret ratio of the output of RRMS is upper bounded by 1-\\alpha+O(\\sqrt{d-1}\\cdot(\\frac{d}{k-d})^{\\frac{1}{d-1}}), where d is the number of objectives. This is the first theoretical guarantee for the situation with more than two objectives. When d=2, it reaches the (1-\\alpha+O(1/k))-guarantee of the only existing algorithm Polytope. Empirical results on the applications of multi-objective weighted maximum coverage and Max-Cut show the superior performance of RRMS over Polytope",
    "volume": "main",
    "checked": true,
    "id": "0ce43f1576466a73472f3adf4bda1ed6cb2a61cb",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17461": {
    "title": "Choosing the Initial State for Online Replanning",
    "abstract": "The need to replan arises in many applications. However, in the context of planning as heuristic search, it raises an annoying problem: if the previous plan is still executing, what should the new plan search take as its initial state? If it were possible to accurately predict how long replanning would take, it would be easy to find the appropriate state at which control will transfer from the previous plan to the new one. But as planning problems can vary enormously in their difficulty, this prediction can be difficult. Many current systems merely use a manually chosen constant duration. In this paper, we show how such ad hoc solutions can be avoided by integrating the choice of the appropriate initial state into the search process itself. The search is initialized with multiple candidate initial states and a time-aware evaluation function is used to prefer plans whose total goal achievement time is minimal. Experimental results show that this approach yields better behavior than either guessing a constant or trying to predict replanning time in advance. By making replanning more effective and easier to implement, this work aids in creating planning systems that can better handle the inevitable exigencies of real-world execution",
    "volume": "main",
    "checked": true,
    "id": "e3148251691d6e0441f355d3046d240d31ed25f8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17462": {
    "title": "OpEvo: An Evolutionary Method for Tensor Operator Optimization",
    "abstract": "Training and inference efficiency of deep neural networks highly rely on the performance of tensor operators on hardware platforms. Manually optimizing tensor operators has limitations in terms of supporting new operators or hardware platforms. Therefore, automatically optimizing device code configurations of tensor operators is getting increasingly attractive. However, current methods for tensor operator optimization usually suffer from poor sample-efficiency due to the combinatorial search space. In this work, we propose a novel evolutionary method, OpEvo, which efficiently explores the search spaces of tensor operators by introducing a topology-aware mutation operation based on q-random walk to leverage the topological structures over the search spaces. Our comprehensive experiment results show that compared with state-of-the-art(SOTA) methods OpEvo can find the best configuration with the lowest variance and least efforts in the number of trials and wall-clock time. All code of this work is available online",
    "volume": "main",
    "checked": true,
    "id": "41c352407d7d7c2b7fa6c5f16e1dc8aecc9b1bfa",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17463": {
    "title": "Efficient Bayesian Network Structure Learning via Parameterized Local Search on Topological Orderings",
    "abstract": "In Bayesian Network Structure Learning (BNSL), we are given a variable set and parent scores for each variable and aim to compute a DAG, called Bayesian network, that maximizes the sum of parent scores, possibly under some structural constraints. Even very restricted special cases of BNSL are computationally hard, and, thus, in practice heuristics such as local search are used. In a typical local search algorithm, we are given some BNSL solution and ask whether there is a better solution within some pre-defined neighborhood of the solution. We study ordering-based local search, where a solution is described via a topological ordering of the variables. We show that given such a topological ordering, we can compute an optimal DAG whose ordering is within inversion distance r in subexponential FPT time; the parameter r allows to balance between solution quality and running time of the local search algorithm. This running time bound can be achieved for BNSL without any structural constraints and for all structural constraints that can be expressed via a sum of weights that are associated with each parent set. We show that for other modification operations on the variable orderings, algorithms with an FPT time for r are unlikely. We also outline the limits of ordering-based local search by showing that it cannot be used for common structural constraints on the moralized graph of the network",
    "volume": "main",
    "checked": true,
    "id": "94a2e73abca47f576aecc4022e51573afdf7a7f7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17464": {
    "title": "Enhancing Balanced Graph Edge Partition with Effective Local Search",
    "abstract": "Graph partition is a key component to achieve workload balance and reduce job completion time in parallel graph processing systems. Among the various partition strategies, edge partition has demonstrated more promising performance in power-law graphs than vertex partition and thereby has been more widely adopted as the default partition strategy by existing graph systems. The graph edge partition problem, which is to split the edge set into multiple balanced parts with the objective of minimizing the total number of copied vertices, has been widely studied from the view of optimization and algorithms. In this paper, we study local search algorithms for this problem to further improve the partition results from existing methods. More specifically, we propose two novel concepts, namely adjustable edges and blocks. Based on these, we develop a greedy heuristic as well as an improved search algorithm utilizing the property of max-flow model. To evaluate the performance of our algorithms, we first provide adequate theoretical analysis in terms of approximation quality. We significantly improve the previous known approximation ratio for this problem. Then we conduct extensive experiments on a large number of benchmark datasets and state-of-the-art edge partition strategies. The results show that our proposed local search framework can further improve the quality of graph partition by a wide margin",
    "volume": "main",
    "checked": true,
    "id": "b7db8bb8309d420e1a0321888d209ae2d1481c55",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17465": {
    "title": "Submodular Span, with Applications to Conditional Data Summarization",
    "abstract": "As an extension to the matroid span problem, we propose the submodular span problem that involves finding a large set of elements with small gain relative to a given query set. We then propose a two-stage Submodular Span Summarization (S3) framework to achieve a form of conditional or query-focused data summarization. The first stage encourages the summary to be relevant to a given query set, and the second stage encourages the final summary to be diverse, thus achieving two important necessities for a good query-focused summary. Unlike previous methods, our framework uses only a single submodular function defined over both data and query. We analyze theoretical properties in the context of both matroids and polymatroids that elucidate when our methods should work well. We find that a scalable approximation algorithm to the polymatroid submodular span problem has good theoretical and empirical properties. We provide empirical and qualitative results on three real-world tasks: conditional multi-document summarization on the DUC 2005-2007 datasets, conditional video summarization on the UT-Egocentric dataset, and conditional image corpus summarization on the ImageNet dataset. We use deep neural networks, specifically a BERT model for text, AlexNet for video frames, and Bi-directional Generative Adversarial Networks (BiGAN) for ImageNet images to help instantiate the submodular functions. The result is a minimally supervised form of conditional summarization that matches or improves over the previous state-of-the-art",
    "volume": "main",
    "checked": true,
    "id": "aa9b3a19ed77362e189f45059f7b8f896eda84e2",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17466": {
    "title": "EECBS: A Bounded-Suboptimal Search for Multi-Agent Path Finding",
    "abstract": "Multi-Agent Path Finding (MAPF), i.e., finding collision-free paths for multiple robots, is important for many applications where small runtimes are necessary, including the kind of automated warehouses operated by Amazon. CBS is a leading two-level search algorithm for solving MAPF optimally. ECBS is a bounded-suboptimal variant of CBS that uses focal search to speed up CBS by sacrificing optimality and instead guaranteeing that the costs of its solutions are within a given factor of optimal. In this paper, we study how to decrease its runtime even further using inadmissible heuristics. Motivated by Explicit Estimation Search (EES), we propose Explicit Estimation CBS (EECBS), a new bounded-suboptimal variant of CBS, that uses online learning to obtain inadmissible estimates of the cost of the solution of each high-level node and uses EES to choose which high-level node to expand next. We also investigate recent improvements of CBS and adapt them to EECBS. We find that EECBS with the improvements runs significantly faster than the state-of-the-art bounded-suboptimal MAPF algorithms ECBS, BCP-7, and eMDD-SAT on a variety of MAPF instances. We hope that the scalability of EECBS enables additional applications for bounded-suboptimal MAPF algorithms",
    "volume": "main",
    "checked": true,
    "id": "0a36a23ec07e9702fc8359a3219cda9f5930d1e3",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17467": {
    "title": "Correlation-Aware Heuristic Search for Intelligent Virtual Machine Provisioning in Cloud Systems",
    "abstract": "The optimization of resource is crucial for the operation of public cloud systems such as Microsoft Azure, as well as servers dedicated to the workloads of large customers such as Microsoft 365. Those optimization tasks often need to take unknown parameters into consideration and can be formulated as Prediction+Optimization problems. This paper proposes a new Prediction+Optimization method named Correlation-Aware Heuristic Search (CAHS) that is capable of accounting for the uncertainty in unknown parameters and delivering effective solutions to difficult optimization problems. We apply this method to solving the predictive virtual machine (VM) provisioning (PreVMP) problem, where the VM provisioning plans are optimized based on the predicted demands of different VM types, to ensure rapid provisions upon customers' requests and to pursue high resource utilization. Unlike the current state-of-the-art PreVMP approaches that assume independence among the demands for different VM types, CAHS incorporates demand correlation when conducting prediction and optimization in a novel and effective way. Our experiments on two public benchmarks and one industrial benchmark demonstrate that CAHS can achieve better performance than its nine state-of-the-art competitors. CAHS has been successfully deployed in Microsoft Azure and significantly improved its performance. The main ideas of CAHS have also been leveraged to improve the efficiency and the reliability of the cloud services provided by Microsoft 365",
    "volume": "main",
    "checked": true,
    "id": "346e3de297015181647ff602c81d7f36fdd115a5",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17468": {
    "title": "Single Player Monte-Carlo Tree Search Based on the Plackett-Luce Model",
    "abstract": "The problem of minimal cost path search is especially difficult when no useful heuristics are available. A common solution is roll-out-based search like Monte Carlo Tree Search (MCTS). However, MCTS is mostly used in stochastic or adversarial environments, with the goal to identify an agent's best next move. For this reason, even though single player versions of MCTS exist, most algorithms, including UCT, are not directly tailored to classical minimal cost path search. We present Plackett-Luce MCTS (PL-MCTS), a path search algorithm based on a probabilistic model over the qualities of successor nodes. We empirically show that PL-MCTS is competitive and often superior to the state of the art",
    "volume": "main",
    "checked": true,
    "id": "e79038eda1a4c1e1209536b4f874d51d05852540",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17469": {
    "title": "Policy-Guided Heuristic Search with Guarantees",
    "abstract": "The use of a policy and a heuristic function for guiding search can be quite effective in adversarial problems, as demonstrated by AlphaGo and its successors, which are based on the PUCT search algorithm. While PUCT can also be used to solve single-agent deterministic problems, it lacks guarantees on its search effort and it can be computationally inefficient in practice. Combining the A* algorithm with a learned heuristic function tends to work better in these domains, but A* and its variants do not use a policy. Moreover, the purpose of using A* is to find solutions of minimum cost, while we seek instead to minimize the search loss (e.g., the number of search steps). LevinTS is guided by a policy and provides guarantees on the number of search steps that relate to the quality of the policy, but it does not make use of a heuristic function. In this work we introduce Policy-guided Heuristic Search (PHS), a novel search algorithm that uses both a heuristic function and a policy and has theoretical guarantees on the search loss that relates to both the quality of the heuristic and of the policy. We show empirically on the sliding-tile puzzle, Sokoban, and a puzzle from the commercial game `The Witness' that PHS enables the rapid learning of both a policy and a heuristic function and compares favorably with A*, Weighted A*, Greedy Best-First Search, LevinTS, and PUCT in terms of number of problems solved and search time in all three domains tested",
    "volume": "main",
    "checked": true,
    "id": "53ae4b740f4a870004f9f840a731a0e051eb2b95",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17470": {
    "title": "Deep Innovation Protection: Confronting the Credit Assignment Problem in Training Heterogeneous Neural Architectures",
    "abstract": "Deep reinforcement learning approaches have shown impressive results in a variety of different domains, however, more complex heterogeneous architectures such as world models require the different neural components to be trained separately instead of end-to-end. While a simple genetic algorithm recently showed end-to-end training is possible, it failed to solve a more complex 3D task. This paper presents a method called Deep Innovation Protection (DIP) that addresses the credit assignment problem in training complex heterogenous neural network models end-to-end for such environments. The main idea behind the approach is to employ multiobjective optimization to temporally reduce the selection pressure on specific components in multi-component network, allowing other components to adapt. We investigate the emergent representations of these evolved networks, which learn to predict properties important for the survival of the agent, without the need for a specific forward-prediction loss",
    "volume": "main",
    "checked": true,
    "id": "52a80c8c7c65eb05212fa5bf4c45f5aaf88e2ee3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17471": {
    "title": "Weighting-based Variable Neighborhood Search for Optimal Camera Placement",
    "abstract": "The optimal camera placement problem (OCP) aims to accomplish surveillance tasks with the minimum number of cameras, which is one of the topics in the GECCO 2020 Competition and can be modeled as the unicost set covering problem (USCP). This paper presents a weighting-based variable neighborhood search (WVNS) algorithm for solving OCP. First, it simplifies the problem instances with four reduction rules based on dominance and independence. Then, WVNS converts the simplified OCP into a series of decision unicost set covering subproblems and tackles them with a fast local search procedure featured by a swap-based neighborhood structure. WVNS employs an efficient incremental evaluation technique and further boosts the neighborhood evaluation by exploiting the dominance and independence features among neighborhood moves. Computational experiments on the 69 benchmark instances introduced in the GECCO 2020 Competition on OCP and USCP show that WVNS is extremely competitive comparing to the state-of-the-art methods. It outperforms or matches several best performing competitors on all instances in both the OCP and USCP tracks of the competition, and its advantage on 15 large-scale instances are over 10%. In addition, WVNS improves the previous best known results for 12 classical benchmark instances in the literature",
    "volume": "main",
    "checked": true,
    "id": "3c6e1d6b759277688087ed0c140446e8fc1d5fe7",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17472": {
    "title": "Multi-Goal Multi-Agent Path Finding via Decoupled and Integrated Goal Vertex Ordering",
    "abstract": "We introduce multi-goal multi agent path finding (MG-MAPF) which generalizes the standard discrete multi-agent path finding (MAPF) problem. While the task in MAPF is to navigate agents in an undirected graph from their starting vertices to one individual goal vertex per agent, MG-MAPF assigns each agent multiple goal vertices and the task is to visit each of them at least once. Solving MG-MAPF not only requires finding collision free paths for individual agents but also determining the order of visiting agent's goal vertices so that common objectives like the sum-of-costs are optimized. We suggest two novel algorithms using different paradigms to address MG-MAPF: a heuristic search-based algorithm called Hamiltonian-CBS (HCBS) and a compilation-based algorithm built using the satisfiability modulo theories (SMT), called SMT-Hamiltonian-CBS (SMT-HCBS)",
    "volume": "main",
    "checked": true,
    "id": "d7e67462f756d2a6b759586bb763e2f3934e6f9b",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17473": {
    "title": "Bayes DistNet - A Robust Neural Network for Algorithm Runtime Distribution Predictions",
    "abstract": "Randomized algorithms are used in many state-of-the-art solvers for constraint satisfaction problems (CSP) and Boolean satisfiability (SAT) problems. For many of these problems, there is no single solver which will dominate others. Having access to the underlying runtime distributions (RTD) of these solvers can allow for better use of algorithm selection, algorithm portfolios, and restart strategies. Previous state-of-the-art methods directly try to predict a fixed parametric distribution that the input instance follows. In this paper, we extend RTD prediction models into the Bayesian setting for the first time. This new model achieves robust predictive performance in the low observation setting, as well as handling censored observations. This technique also allows for richer representations which cannot be achieved by the classical models which restrict their output representations. Our model outperforms the previous state-of-the-art model in settings in which data is scarce, and can make use of censored data such as lower bound time estimates, where that type of data would otherwise be discarded. It can also quantify its uncertainty in its predictions, allowing for algorithm portfolio models to make better informed decisions about which algorithm to run on a particular instance",
    "volume": "main",
    "checked": true,
    "id": "07f4a05faca7e8b7879d7e46820db538434a7e35",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17474": {
    "title": "Learning Branching Heuristics for Propositional Model Counting",
    "abstract": "Propositional model counting, or #SAT, is the problem of computing the number of satisfying assignments of a Boolean formula. Many problems from different application areas, including many discrete probabilistic inference problems, can be translated into model counting problems to be solved by #SAT solvers. Exact #SAT solvers, however, are often not scalable to industrial size instances. In this paper, we present Neuro#, an approach for learning branching heuristics to improve the performance of exact #SAT solvers on instances from a given family of problems. We experimentally show that our method reduces the step count  on similarly distributed held-out instances and generalizes to much larger instances from the same problem family. It is able to achieve these results on a number of different problem families having very different structures.  In addition to step count improvements, Neuro# can also achieve orders of magnitude wall-clock speedups over the vanilla solver on larger instances in some problem families, despite the runtime overhead of querying the model",
    "volume": "main",
    "checked": true,
    "id": "8411a6d999fbb2e422d954f2fbd0489d78c65a7e",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17475": {
    "title": "Accelerated Combinatorial Search for Outlier Detection with Provable Bound on Sub-Optimality",
    "abstract": "Outliers negatively affect the accuracy of data analysis.  In this paper we are concerned with their influence on the accuracy of  Principal Component Analysis (PCA).  Algorithms that attempt to detect outliers and remove them from the data  prior to applying PCA are sometimes called Robust PCA,  or Robust Subspace Recovery algorithms.  We propose a new algorithm for outlier detection that combines two ideas.  The first is \"chunk recursive elimination\" that was used effectively  to accelerate feature selection,  and the second is combinatorial search, in a setting similar to A*.  Our main result is showing how to combine these two ideas.  One variant of our algorithm is guaranteed to compute an optimal solution   according to some natural criteria,   but its running time makes it impractical for large datasets.   Other variants are much faster and come with provable bounds on sub-optimality.  Experimental results show the effectiveness of the proposed approach",
    "volume": "main",
    "checked": true,
    "id": "18dea15ad30c38e4324418761e419494e0cff463",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17476": {
    "title": "Combining Reinforcement Learning with Lin-Kernighan-Helsgaun Algorithm for the Traveling Salesman Problem",
    "abstract": "We address the Traveling Salesman Problem (TSP), a famous NP-hard combinatorial optimization problem. And we propose a variable strategy reinforced approach, denoted as VSR-LKH, which combines three reinforcement learning methods (Q-learning, Sarsa and Monte Carlo) with the well-known TSP algorithm, called Lin-Kernighan-Helsgaun (LKH). VSR-LKH replaces the inflexible traversal operation in LKH, and lets the program learn to make choice at each search step by reinforcement learning. Experimental results on 111 TSP benchmarks from the TSPLIB with up to 85,900 cities demonstrate the excellent performance of the proposed method",
    "volume": "main",
    "checked": true,
    "id": "87fa4e906465fc2d8f8331a3165a9fe3ba05ed91",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17477": {
    "title": "Improving Maximum k-plex Solver via Second-Order Reduction and Graph Color Bounding",
    "abstract": "In a graph, a k-plex is a vertex set in which every vertex is not adjacent to at most k vertices of this set. The maximum k-plex problem, which asks for the largest k-plex from the given graph, is a key primitive in a variety of real-world applications like community detection and so on. In the paper, we develop an exact algorithm, Maplex, for solving this problem in real world graphs practically. Based on the existing first-order and the novel second-order reduction rules, we design a powerful preprocessing method which efficiently removes redundant vertices and edges for Maplex. Also, the graph color heuristic is widely used for overestimating the maximum clique of a graph. For the first time, we generalize this technique for bounding the size of maximum k-plex in Maplex. Experiments are carried out to compare our algorithm with other state-of-the-art solvers on a wide range of publicly available graphs. Maplex outperforms all other algorithms on large real world graphs and is competitive with existing solvers on artificial dense graphs. Finally, we shed light on the effectiveness of each key component of Maplex",
    "volume": "main",
    "checked": true,
    "id": "d7a47519acc45e50b73f4183ed4d0e2f0d181c21",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17478": {
    "title": "GATE: Graph Attention Transformer Encoder for Cross-lingual Relation and Event Extraction",
    "abstract": "Recent progress in cross-lingual relation and event extraction use graph convolutional networks (GCNs) with universal dependency parses to learn language-agnostic sentence representations such that models trained on one language can be applied to other languages. However, GCNs struggle to model words with long-range dependencies or are not directly connected in the dependency tree. To address these challenges, we propose to utilize the self-attention mechanism where we explicitly fuse structural information to learn the dependencies between words with different syntactic distances. We introduce GATE, a Graph Attention Transformer Encoder, and test its cross-lingual transferability on relation and event extraction tasks. We perform experiments on the ACE05 dataset that includes three typologically different languages: English, Chinese, and Arabic. The evaluation results show that GATE outperforms three recently proposed methods by a large margin. Our detailed analysis reveals that due to the reliance on syntactic dependencies, GATE produces robust representations that facilitate transfer across languages",
    "volume": "main",
    "checked": true,
    "id": "9af8f2bba51c76fe7fcc1eec5b57b5445747b5ad",
    "citation_count": 35
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17479": {
    "title": "Empirical Regularization for Synthetic Sentence Pairs in Unsupervised Neural Machine Translation",
    "abstract": "UNMT tackles translation on monolingual corpora in two required languages. Since there is no explicitly cross-lingual signal, pre-training and synthetic sentence pairs are significant to the success of UNMT. In this work, we empirically study the core training procedure of UNMT to analyze the synthetic sentence pairs obtained from back-translation. We introduce new losses to UNMT to regularize the synthetic sentence pairs by jointly training the UNMT objective and the regularization objective. Our comprehensive experiments support that our method can generally improve the performance of currently successful models on three similar pairs {French, German, Romanian} English and one dissimilar pair Russian English with acceptably additional cost",
    "volume": "main",
    "checked": true,
    "id": "44c7c1d2a845811fca211593006ab88bf2168d14",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17480": {
    "title": "Segmentation of Tweets with URLs and its Applications to Sentiment Analysis",
    "abstract": "An important means for disseminating information in social media platforms is by including URLs that point to external sources in user posts. In Twitter, we estimate that about 21% of the daily stream of English-language tweets contain URLs. We notice that NLP tools make little attempt at understanding the relationship between the content of the URL and the text surrounding it in a tweet. In this work, we study the structure of tweets with URLs relative to the content of the Web documents pointed to by the URLs. We identify several segments classes that may appear in a tweet with URLs, such as the title of a Web page and the user's original content. Our goals in this paper are: introduce, define, and analyze the segmentation problem of tweets with URLs, develop an effective algorithm to solve it, and show that our solution can benefit sentiment analysis on Twitter. We also show that the problem is an instance of the block edit distance problem, and thus an NP-hard problem",
    "volume": "main",
    "checked": true,
    "id": "3b001c4708d5634825e14b5c04478b920d677004",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17481": {
    "title": "Unsupervised Opinion Summarization with Content Planning",
    "abstract": "The recent success of deep learning techniques for abstractive summarization is predicated on the availability of large-scale datasets. When summarizing reviews (e.g., for products or movies), such training data is neither available nor can be easily sourced, motivating the development of methods which rely on synthetic datasets for supervised training. We show that explicitly incorporating content planning in a summarization model not only yields output of higher quality, but also allows the creation of synthetic datasets which are more natural, resembling real world document-summary pairs. Our content plans take the form of aspect and sentiment distributions which we induce from data without access to expensive annotations. Synthetic datasets are created by sampling pseudo-reviews from a Dirichlet distribution parametrized by our content planner, while our model generates summaries based on input reviews and induced content plans. Experimental results on three domains show that our approach outperforms competitive models in generating informative, coherent, and fluent summaries that capture opinion consensus",
    "volume": "main",
    "checked": true,
    "id": "ac1154a263a88a0b247c15ebea52992712a379ac",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17482": {
    "title": "Enhancing Scientific Papers Summarization with Citation Graph",
    "abstract": "Previous work for text summarization in scientific domain mainly focused on the content of the input document, but seldom considering its citation network.  However, scientific papers are full of uncommon domain-specific terms, making it almost impossible for the model to understand its true meaning without the help of the relevant research community.  In this paper, we redefine the task of scientific papers summarization by utilizing their citation graph and propose a citation graph-based summarization model CGSum which can incorporate the information of both the source paper and its references.  In addition, we construct a novel scientific papers summarization dataset Semantic Scholar Network (SSN) which contains 141K research papers in different domains and 661K citation relationships. The entire dataset constitutes a large connected citation graph.  Extensive experiments show that our model can achieve competitive performance when compared with the pretrained models even with a simple architecture.  The results also indicates the citation graph is crucial to better understand the content of papers and generate high-quality summaries",
    "volume": "main",
    "checked": true,
    "id": "9791dad11215144aad97bc86a261b926e412cd04",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17483": {
    "title": "Multi-Dimensional Explanation of Target Variables from Documents",
    "abstract": "Automated predictions require explanations to be interpretable by humans. Past work used attention and rationale mechanisms to find words that predict the target variable of a document. Often though, they result in a tradeoff between noisy explanations or a drop in accuracy. Furthermore, rationale methods cannot capture the multi-faceted nature of justifications for multiple targets, because of the non-probabilistic nature of the mask. In this paper, we propose the Multi-Target Masker (MTM) to address these shortcomings. The novelty lies in the soft multi-dimensional mask that models a relevance probability distribution over the set of target variables to handle ambiguities. Additionally, two regularizers guide MTM to induce long, meaningful explanations. We evaluate MTM on two datasets and show, using standard metrics and human annotations, that the resulting masks are more accurate and coherent than those generated by the state-of-the-art methods. Moreover, MTM is the first to also achieve the highest F1 scores for all the target variables simultaneously",
    "volume": "main",
    "checked": true,
    "id": "2d300be18d703f1583716f81c91cf90e9f830c9a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17484": {
    "title": "Joint Semantic Analysis with Document-Level Cross-Task Coherence Rewards",
    "abstract": "Coreference resolution and semantic role labeling are NLP tasks that capture different aspects of semantics, indicating respectively, which expressions refer to the same entity, and what semantic roles expressions serve in the sentence. However, they are often closely interdependent, and both generally necessitate natural language understanding. Do they form a coherent abstract representation of documents? We present a neural network architecture for joint coreference resolution and semantic role labeling for English, and train graph neural networks to model the 'coherence' of the combined shallow semantic graph. Using the resulting coherence score as a reward for our joint semantic analyzer, we use reinforcement learning to encourage global coherence over the document and between semantic annotations. This leads to improvements on both tasks in multiple datasets from different domains, and across a range of encoders of different expressivity, calling, we believe, for a more holistic approach for semantics in NLP",
    "volume": "main",
    "checked": true,
    "id": "506d05bf93b0807ae17ac990584d7aa5895c0f91",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17485": {
    "title": "Segatron: Segment-Aware Transformer for Language Modeling and Understanding",
    "abstract": "Transformers are powerful for sequence modeling. Nearly all state-of-the-art language models and pre-trained language models are based on the Transformer architecture. However, it distinguishes sequential tokens only with the token position index. We hypothesize that better contextual representations can be generated from the Transformer with richer positional information. To verify this, we propose a segment-aware Transformer (Segatron), by replacing the original token position encoding with a combined position encoding of paragraph, sentence, and token. We first introduce the segment-aware mechanism to Transformer-XL, which is a popular Transformer-based language model with memory extension and relative position encoding. We find that our method can further improve the Transformer-XL base model and large model, achieving 17.1 perplexity on the WikiText-103 dataset. We further investigate the pre-training masked language modeling task with Segatron. Experimental results show that BERT pre-trained with Segatron (SegaBERT) can outperform BERT with vanilla Transformer on various NLP tasks, and outperforms RoBERTa on zero-shot sentence representation learning. Our code is available on GitHub",
    "volume": "main",
    "checked": true,
    "id": "320efa53dea3e8f836790682fbd4196132c49749",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17486": {
    "title": "Learning to Copy Coherent Knowledge for Response Generation",
    "abstract": "Knowledge-driven dialog has shown remarkable performance to alleviate the problem of generating uninformative responses in the dialog system. However, incorporating knowledge coherently and accurately into response generation is still far from being solved. Previous works dropped into the paradigm of non-goal-oriented knowledge-driven dialog, they are prone to ignore the effect of dialog goal, which has potential impacts on knowledge exploitation and response generation. To address this problem, this paper proposes a Goal-Oriented Knowledge Copy network, GOKC. Specifically, a goal-oriented knowledge discernment mechanism is designed to help the model discern the knowledge facts that are highly correlated to the dialog goal and the dialog context. Besides, a context manager is devised to copy facts not only from the discerned knowledge but also from the dialog goal and the dialog context, which allows the model to accurately restate the facts in the generated response. The empirical studies are conducted on two benchmarks of goal-oriented knowledge-driven dialog generation. The results show that our model can significantly outperform several state-of-the-art models in terms of both automatic evaluation and human judgments",
    "volume": "main",
    "checked": true,
    "id": "209e0af76a6eb58dd08fa28e578202d80b1e1a8e",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17487": {
    "title": "Contextualized Rewriting for Text Summarization",
    "abstract": "Extractive summarization suffers from irrelevance, redundancy and incoherence. Existing work shows that abstractive rewriting for extractive summaries can improve the conciseness and readability. These rewriting systems consider extracted summaries as the only input, which is relatively focused but can lose important background knowledge. In this paper, we investigate contextualized rewriting, which ingests the entire original document. We formalize contextualized rewriting as a seq2seq problem with group alignments, introducing group tag as a solution to model the alignments, identifying extracted summaries through content-based addressing. Results show that our approach significantly outperforms non-contextualized rewriting systems without requiring reinforcement learning, achieving strong improvements on ROUGE scores upon multiple extractive summarizers",
    "volume": "main",
    "checked": true,
    "id": "3fcc7e3e49a352209db9ae2270182a281a997fca",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17488": {
    "title": "Knowledge-driven Natural Language Understanding of English Text and its Applications",
    "abstract": "Understanding the meaning of a text is a fundamental challenge of natural language understanding (NLU) research. An ideal NLU system should process a language in a way that is not exclusive to a single task or a dataset. Keeping this in mind, we have introduced a novel knowledge driven semantic representation approach for English text. By leveraging the VerbNet lexicon, we are able to map syntax tree of the text to its commonsense meaning represented using basic knowledge primitives. The general purpose knowledge represented from our approach can be used to build any reasoning based NLU system that can also provide justification. We applied this approach to construct two NLU applications that we present here: SQuARE (Semantic-based Question Answering and Reasoning Engine) and StaCACK (Stateful Conversational Agent using Commonsense Knowledge). Both these systems work by ``truly understanding'' the natural language text they process and both provide natural language explanations for their responses while maintaining high accuracy",
    "volume": "main",
    "checked": true,
    "id": "ae3d6eb676079d67068cbef2dcac7bcd220e3803",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17489": {
    "title": "One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline",
    "abstract": "In Text-to-AMR parsing, current state-of-the-art semantic parsers use cumbersome pipelines integrating several different modules or components, and exploit graph recategorization, i.e., a set of content-specific heuristics that are developed on the basis of the training set. However, the generalizability of graph recategorization in an out-of-distribution setting is unclear. In contrast, state-of-the-art AMR-to-Text generation, which can be seen as the inverse to parsing, is based on simpler seq2seq. In this paper, we cast Text-to-AMR and AMR-to-Text as a symmetric transduction task and show that by devising a careful graph linearization and extending a pretrained encoder-decoder model, it is possible to obtain state-of-the-art performances in both tasks using the very same seq2seq approach, i.e., SPRING (Symmetric PaRsIng aNd Generation). Our model does not require complex pipelines, nor heuristics built on heavy assumptions. In fact, we drop the need for graph recategorization, showing that this technique is actually harmful outside of the standard benchmark. Finally, we outperform the previous state of the art on the English AMR 2.0 dataset by a large margin: on Text-to-AMR we obtain an improvement of 3.6 Smatch points, while on AMR-to-Text we outperform the state of the art by 11.2 BLEU points.   We release the software at github.com/SapienzaNLP/spring",
    "volume": "main",
    "checked": true,
    "id": "25e7c9dcc294d77d184c4c1122c8304cdb58c69d",
    "citation_count": 67
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17490": {
    "title": "Benchmarking Knowledge-Enhanced Commonsense Question Answering via Knowledge-to-Text Transformation",
    "abstract": "A fundamental ability of humans is to utilize commonsense knowledge in language understanding and question answering. In recent years, many knowledge-enhanced Commonsense Question Answering (CQA) approaches have been proposed. However, it remains unclear: (1) How far can we get by exploiting external knowledge for CQA? (2) How much potential of knowledge has been exploited in current CQA models? (3) Which are the most promising directions for future CQA? To answer these questions, we benchmark knowledge-enhanced CQA by conducting extensive experiments on multiple standard CQA datasets using a simple and effective knowledge-to-text transformation framework. Experiments show that: (1) Our knowledge-to-text framework is effective and achieves state-of-the-art performance on CommonsenseQA dataset, providing a simple and strong knowledge-enhanced baseline for CQA; (2) The potential of knowledge is still far from being fully exploited in CQA  there is a significant performance gap from current models to our models with golden knowledge; and (3) Context-sensitive knowledge selection, heterogeneous knowledge exploitation, and commonsense-rich language models are promising CQA directions",
    "volume": "main",
    "checked": true,
    "id": "cc1adf2d74d1392cdba5ffa2841bdf9c6bc52bac",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17491": {
    "title": "Multilingual Transfer Learning for QA using Translation as Data Augmentation",
    "abstract": "Prior work on multilingual question answering has mostly focused on using large multilingual pre-trained language models (LM) to perform zero-shot language-wise learning: train a QA model on English and test on other languages. In this work, we explore strategies that improve cross-lingual transfer by bringing the multilingual embeddings closer in the semantic space.   Our first strategy augments the original English training data with machine translation-generated data. This results in a corpus of multilingual silver-labeled QA pairs that is 14 times larger than the original training set. In addition, we propose two novel strategies, language adversarial training and language arbitration framework, which significantly improve the (zero-resource) cross-lingual transfer performance and result in LM embeddings that are less language-variant. Empirically, we show that the proposed models outperform the previous zero-shot baseline on the recently introduced multilingual MLQA and TyDiQA datasets",
    "volume": "main",
    "checked": true,
    "id": "364a25604e054f32924ff08acc234d993da7114f",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17492": {
    "title": "Learning to Rationalize for Nonmonotonic Reasoning with Distant Supervision",
    "abstract": "The black-box nature of neural models has motivated a line of research that aims to generate natural language rationales to explain why a model made certain predictions. Such rationale generation models, to date, have been trained on dataset-specific crowdsourced rationales, but this approach is costly and is not generalizable to new tasks and domains. In this paper, we investigate the extent to which neural models can reason about natural language rationales that explain model predictions, relying only on distant supervision with no additional annotation cost for human-written rationales. We investigate multiple ways to automatically generate rationales using pre-trained language models, neural knowledge models, and distant supervision from related tasks, and train generative models capable of composing explanatory rationales for unseen instances. We demonstrate our approach on the defeasible inference task, a nonmonotonic reasoning task in which an inference may be strengthened or weakened when new information (an update) is introduced. Our model shows promises at generating post-hoc rationales explaining why an inference is more or less likely given the additional information, however, it mostly generates trivial rationales reflecting the fundamental limitations of neural language models. Conversely, the more realistic setup of jointly predicting the update or its type and generating rationale is more challenging, suggesting an important future direction",
    "volume": "main",
    "checked": true,
    "id": "3a1311fbba348a13857f54b92c24be4ee75d1b41",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17493": {
    "title": "Brain Decoding Using fNIRS",
    "abstract": "Brain activation can reflect semantic information elicited by natural words and concepts. Increasing research has been conducted on decoding such neural activation patterns using representational semantic models. However, prior work decoding semantic meaning from neurophysiological responses has been largely limited to ECoG, fMRI, MEG, and EEG techniques, each having its own advantages and limitations. More recently, the functional near infrared spectroscopy (fNIRS) has emerged as an alternative hemodynamic-based approach and possesses a number of strengths. We investigate brain decoding tasks under the help of fNIRS and empirically compare fNIRS with fMRI. Primarily, we find that: 1) like fMRI scans, activation patterns recorded from fNIRS encode rich information for discriminating concepts, but show limits on the possibility of decoding fine-grained semantic clues; 2) fNIRS decoding shows robustness across different brain regions, semantic categories and even subjects; 3) fNIRS has higher accuracy being decoded based on multi-channel patterns as compared to single-channel ones, which is in line with our intuition of the working mechanism of human brain. Our findings prove that fNIRS has the potential to promote a deep integration of NLP and cognitive neuroscience from the perspective of language understanding. We release the largest fNIRS dataset by far to facilitate future research",
    "volume": "main",
    "checked": true,
    "id": "e4549cf0815d711c84c91f5b9f097b8b6f9e6282",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17494": {
    "title": "Extracting Zero-shot Structured Information from Form-like Documents: Pretraining with Keys and Triggers",
    "abstract": "In this paper, we revisit the problem of extracting the values of a given set of key fields from form-like documents. It is the vital step to support many downstream applications, such as knowledge base construction, question answering, document comprehension and so on. Previous studies ignore the semantics of the given keys by considering them only as the class labels, and thus might be incapable to handle zero-shot keys. Meanwhile, although these models often leverage the attention mechanism, the learned features might not reflect the true proxy of explanations on why humans would recognize the value for the key, and thus could not well generalize to new documents. To address these issues, we propose a Key-Aware and Trigger-Aware (KATA) extraction model. With the input key, it explicitly learns two mappings, namely from key representations to trigger representations and then from trigger representations to values. These two mappings might be intrinsic and invariant across different keys and documents. With a large training set automatically constructed based on the Wikipedia data, we pre-train these two mappings. Experiments with the fine-tuning step to two applications show that the proposed model achieves more than 70% accuracy for the extraction of zero-shot keys while previous methods all fail",
    "volume": "main",
    "checked": true,
    "id": "65f6b1a72305ad9fbccda4016dbba75d2276ac7f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17495": {
    "title": "Simple or Complex? Learning to Predict Readability of Bengali Texts",
    "abstract": "Determining the readability of a text is the first step to its simplification. In this paper, we present a readability analysis tool capable of analyzing text written in the Bengali language to provide in-depth information on its readability and complexity. Despite being the 7th most spoken language in the world with 230 million native speakers, Bengali suffers from a lack of fundamental resources for natural language processing. Readability related research of the Bengali language so far can be considered to be narrow and sometimes faulty due to the lack of resources. Therefore, we correctly adopt document-level readability formulas traditionally used for U.S. based education system to the Bengali language with a proper age-to-age comparison. Due to the unavailability of large-scale human-annotated corpora, we further divide the document-level task into sentence-level and experiment with neural architectures, which will serve as a baseline for the future works of Bengali readability prediction. During the process, we present several human-annotated corpora and dictionaries such as a document-level dataset comprising 618 documents with 12 different grade levels, a large-scale sentence-level dataset comprising more than 96K sentences with simple and complex labels, a consonant conjunct count algorithm and a corpus of 341 words to validate the effectiveness of the algorithm, a list of 3,396 easy words, and an updated pronunciation dictionary with more than 67K words. These resources can be useful for several other tasks of this low-resource language",
    "volume": "main",
    "checked": true,
    "id": "0174d608bd44ad7148e1c44612f8f31cfd9f3c42",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17496": {
    "title": "Lexically Constrained Neural Machine Translation with Explicit Alignment Guidance",
    "abstract": "Lexically constrained neural machine translation (NMT), which leverages pre-specified translation to constrain NMT, has practical significance in interactive translation and NMT domain adaption. Previous work either modify the decoding algorithm or train the model on augmented dataset. These methods suffer from either high computational overheads or low copying success rates. In this paper, we investigate Att-Input and Att-Output, two alignment-based constrained decoding methods. These two methods revise the target tokens during decoding based on word alignments derived from encoder-decoder attention weights. Our study shows that Att-Input translates better while Att-Output is more computationally efficient. Capitalizing on both strengths, we further propose EAM-Output by introducing an explicit alignment module (EAM) to a pretrained Transformer. It decodes similarly as EAM-Output, except using alignments derived from the EAM. We leverage the word alignments induced from Att-Input as labels and train the EAM while keeping the parameters of the Transformer frozen. Experiments on WMT16 De-En and WMT16 Ro-En show the effectiveness of our approaches on constrained NMT. In particular, the proposed EAM-Output method consistently outperforms previous approaches in translation quality, with light computational overheads over unconstrained baseline",
    "volume": "main",
    "checked": true,
    "id": "90fd2506e5b7f51f7ffb4c0d90371555a0d66e11",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17497": {
    "title": "Aspect-Level Sentiment-Controllable Review Generation with Mutual Learning Framework",
    "abstract": "Review generation, aiming to automatically generate review text according to the given information, is proposed to assist in the unappealing review writing. However, most of existing methods only consider the overall sentiments of reviews and cannot achieve aspect-level sentiment control. Even though some previous studies attempt to generate aspect-level sentiment-controllable reviews, they usually require large-scale human annotations which are unavailable in the real world. To address this issue, we propose a mutual learning framework to take advantage of unlabeled data to assist the aspect-level sentiment-controllable review generation. The framework consists of a generator and a classifier which utilize confidence mechanism and reconstruction reward to enhance each other. Experimental results show our model can achieve aspect-sentiment control accuracy up to 88% without losing generation quality",
    "volume": "main",
    "checked": true,
    "id": "4cf93bb0ed726ecdf74245dae6a24818b39d7c01",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17498": {
    "title": "Weakly-Supervised Hierarchical Models for Predicting Persuasive Strategies in Good-faith Textual Requests",
    "abstract": "Modeling persuasive language has the potential to better facilitate our decision-making processes. Despite its importance, computational modeling of persuasion is still in its infancy, largely due to the lack of benchmark datasets that can provide quantitative labels of persuasive strategies to expedite this line of research. To this end, we introduce a large-scale multi-domain text corpus for modeling persuasive strategies in good-faith text requests. Moreover, we design a hierarchical weakly-supervised latent variable model that can leverage partially labeled data to predict such associated persuasive strategies for each sentence, where the supervision comes from both the overall document-level labels and very limited sentence-level labels. Experimental results showed that our proposed method outperformed existing semi-supervised baselines significantly. We have publicly released our code at https://github.com/GT-SALT/Persuasion_Strategy_WVAE",
    "volume": "main",
    "checked": true,
    "id": "042c440c049b1d8ba4daeba914d8aa89212ee141",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17499": {
    "title": "A Lightweight Neural Model for Biomedical Entity Linking",
    "abstract": "Biomedical entity linking aims to map biomedical mentions,  such as diseases and drugs, to standard entities in a given  knowledge base. The specific challenge in this context is  that the same biomedical entity can have a wide range of  names, including synonyms, morphological variations, and  names with different word orderings. Recently, BERT-based  methods have advanced the state-of-the-art by allowing for  rich representations of word sequences. However, they often have hundreds of millions of parameters and require  heavy computing resources, which limits their applications  in resource-limited scenarios. Here, we propose a lightweight  neural method for biomedical entity linking, which needs just  a fraction of the parameters of a BERT model and much less  computing resources. Our method uses a simple alignment  layer with attention mechanisms to capture the variations  between mention and entity names. Yet, we show that our  model is competitive with previous work on standard evaluation benchmarks",
    "volume": "main",
    "checked": true,
    "id": "456384ecaacca4cacce6ffc5a087809b2bde92cf",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17500": {
    "title": "Bidirectional Machine Reading Comprehension for Aspect Sentiment Triplet Extraction",
    "abstract": "Aspect sentiment triplet extraction (ASTE), which aims to identify aspects from review sentences along with their corresponding opinion expressions and sentiments, is an emerging task in fine-grained opinion mining. Since ASTE consists of multiple subtasks, including opinion entity extraction, relation detection, and sentiment classification, it is critical and challenging to appropriately capture and utilize the associations among them. In this paper, we transform ASTE task into a multi-turn machine reading comprehension (MTMRC) task and propose a bidirectional MRC (BMRC) framework to address this challenge. Specifically, we devise three types of queries, including non-restrictive extraction queries, restrictive extraction queries and sentiment classification queries, to build the associations among different subtasks. Furthermore, considering that an aspect sentiment triplet can derive from either an aspect or an opinion expression, we design a bidirectional MRC structure. One direction sequentially recognizes aspects, opinion expressions, and sentiments to obtain triplets, while the other direction identifies opinion expressions first, then aspects, and at last sentiments. By making the two directions complement each other, our framework can identify triplets more comprehensively. To verify the effectiveness of our approach, we conduct extensive experiments on four benchmark datasets. The experimental results demonstrate that BMRC achieves state-of-the-art performances",
    "volume": "main",
    "checked": true,
    "id": "13e1a9324351b25de11a102066d804a31963147d",
    "citation_count": 28
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17501": {
    "title": "Empower Distantly Supervised Relation Extraction with Collaborative Adversarial Training",
    "abstract": "With recent advances in distantly supervised (DS) relation extraction (RE), considerable attention is attracted to leverage multi-instance learning (MIL) to distill high-quality supervision from the noisy DS. Here, we go beyond label noise and identify the key bottleneck of DS-MIL to be its low data utilization: as high-quality supervision being refined by MIL, MIL abandons a large amount of training instances, which leads to a low data utilization and hinders model training from having abundant supervision. In this paper, we propose collaborative adversarial training to improve the data utilization, which coordinates virtual adversarial training (VAT) and adversarial training (AT) at different levels. Specifically, since VAT is label-free, we employ the instance-level VAT to recycle instances abandoned by MIL. Besides, we deploy AT at the bag-level to unleash the full potential of the high-quality supervision got by MIL. Our proposed method brings consistent improvements ( 5 absolute AUC score) to the previous state of the art, which verifies the importance of the data utilization issue and the effectiveness of our method",
    "volume": "main",
    "checked": true,
    "id": "b8f8740a12b434fad45d9cc71cdbc85f05fc2e73",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17502": {
    "title": "Reasoning in Dialog: Improving Response Generation by Context Reading Comprehension",
    "abstract": "In multi-turn dialog, utterances do not always take the full form of sentences (Carbonell 1983), which naturally makes understanding the dialog context more difficult. However, it is essential to fully grasp the dialog context to generate a reasonable response. Hence, in this paper, we propose to improve the response generation performance by examining the model's ability to answer a reading comprehension question, where the question is focused on the omitted information in the dialog. Enlightened by the multi-task learning scheme, we propose a joint framework that unifies these two tasks, sharing the same encoder to extract the common and task-invariant features with different decoders to learn task-specific features. To better fusing information from the question and the dialog history in the encoding part, we propose to augment the Transformer architecture with a memory updater, which is designed to selectively store and update the history dialog information so as to support downstream tasks. For the experiment, we employ human annotators to write and examine a large-scale dialog reading comprehension dataset. Extensive experiments are conducted on this dataset, and the results show that the proposed model brings substantial improvements over several strong baselines on both tasks. In this way, we demonstrate that reasoning can indeed help better response generation and vice versa. We release our large-scale dataset for further research",
    "volume": "main",
    "checked": true,
    "id": "bd64364e7f14086545a968b2291e785b75b4368b",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17503": {
    "title": "Meta-Transfer Learning for Low-Resource Abstractive Summarization",
    "abstract": "Neural abstractive summarization has been studied in many pieces of literature and achieves great success with the aid of large corpora. However, when encountering novel tasks, one may not always benefit from transfer learning due to the domain shifting problem, and overfitting could happen without adequate labeled examples. Furthermore, the annotations of abstractive summarization are costly, which often demand domain knowledge to ensure the ground-truth quality. Thus, there are growing appeals for Low-Resource Abstractive Summarization, which aims to leverage past experience to improve the performance with limited labeled examples of target corpus. In this paper, we propose to utilize two knowledge-rich sources to tackle this problem, which are large pre-trained models and diverse existing corpora. The former can provide the primary ability to tackle summarization tasks; the latter can help discover common syntactic or semantic information to improve the generalization ability. We conduct extensive experiments on various summarization corpora with different writing styles and forms. The results demonstrate that our approach achieves the state-of-the-art on 6 corpora in low-resource scenarios, with only 0.7% of trainable parameters compared to previous work",
    "volume": "main",
    "checked": true,
    "id": "b4eb84ca50148be183b6ef235613d6d4b5f2970b",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17504": {
    "title": "Adaptive Prior-Dependent Correction Enhanced Reinforcement Learning for Natural Language Generation",
    "abstract": "Natural language generation (NLG) is an important task with various applications like neural machine translation (NMT) and image captioning. Since deep-learning-based methods have issues of exposure bias and loss inconsistency, reinforcement learning (RL) is widely adopted in NLG tasks recently. But most RL-based methods ignore the deviation ignorance issue, which means the model fails to understand the extent of token-level deviation well. It leads to semantic incorrectness and hampers the agent to perform well. To address the issue, we propose a technique called adaptive prior-dependent correction (APDC) to enhance RL. It leverages the distribution generated by computing the distances between the ground truth and all other words to correct the agent's stochastic policy. Additionally, some techniques on RL are explored to coordinate RL with APDC, which requires a reward estimation at every time step. We find that the RL-based NLG tasks are a special case in RL, where the state transition is deterministic and the afterstate value equals the Q-value at every time step. To utilize such prior knowledge, we estimate the advantage function with the difference of the Q-values which can be estimated by Monte Carlo rollouts. Experiments show that, on three tasks of NLG (NMT, image captioning, abstractive text summarization), our method consistently outperforms the state-of-the-art RL-based approaches on different frequently-used metrics",
    "volume": "main",
    "checked": true,
    "id": "c3f28cf8481e42117a54a243103b38fc3710ba6e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17505": {
    "title": "How Linguistically Fair Are Multilingual Pre-Trained Language Models?",
    "abstract": "Massively multilingual pre-trained language models, such as mBERT and XLM-RoBERTa, have received significant attention in the recent NLP literature for their excellent capability towards crosslingual zero-shot transfer of NLP tasks. This is especially promising because a large number of languages have no or very little labeled data for supervised learning. Moreover, a substantially improved performance on low resource languages without any significant degradation of accuracy for high resource languages lead us to believe that these models will help attain a fairer distribution of language technologies despite the prevalent unfair and extremely skewed distribution of resources across the worlds languages. Nevertheless, these models, and the experimental approaches adopted by the researchers to arrive at those, have been criticised by some for lacking a nuanced and thorough comparison of benefits across languages and tasks. A related and important question that has received little attention is how to choose from a set of models, when no single model significantly outperforms the others on all tasks and languages. As we discuss in this paper, this is often the case, and the choices are usually made without a clear articulation of reasons or underlying fairness assumptions. In this work, we scrutinize the choices made in previous work, and propose a few different strategies for fair and efficient model selection based on the principles of fairness in economics and social choice theory. In particular, we emphasize Rawlsian fairness, which provides an appropriate framework for making fair (with respect to languages, or tasks, or both) choices while selecting multilingual pre-trained language models for a practical or scientific set-up",
    "volume": "main",
    "checked": true,
    "id": "5d52007c26a88b5754962a6600c3f6cc5b34ac30",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17506": {
    "title": "DirectQE: Direct Pretraining for Machine Translation Quality Estimation",
    "abstract": "Machine Translation Quality Estimation (QE) is a task of predicting the quality of machine translations without relying on any reference. Recently, the predictor-estimator framework trains the predictor as a feature extractor, which leverages the extra parallel corpora without QE labels, achieving promising QE performance. However, we argue that there are gaps between the predictor and the estimator in both data quality and training objectives, which preclude QE models from benefiting from a large number of parallel corpora more directly. We propose a novel framework called DirectQE that provides a direct pretraining for QE tasks. In DirectQE, a generator is trained to produce pseudo data that is closer to the real QE data, and a detector is pretrained on these data with novel objectives that are akin to the QE task. Experiments on widely used benchmarks show that DirectQE outperforms existing methods, without using any pretraining models such as BERT. We also give extensive analyses showing how fixing the two gaps contributes to our improvements",
    "volume": "main",
    "checked": true,
    "id": "cefc6e55d53a4c46c9be4074e5803bf5e3b3d8c2",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17507": {
    "title": "We Can Explain Your Research in Layman's Terms: Towards Automating Science Journalism at Scale",
    "abstract": "We propose to study Automating Science Journalism (ASJ), the process of producing a layman's terms summary of a research article, as a new benchmark for long neural abstractive summarization and story generation. Automating science journalism is a challenging task as it requires paraphrasing complex scientific concepts to be grasped by the general public. Thus, we create a specialized dataset that contains scientific papers and their Science Daily press releases. We demonstrate numerous sequence to sequence (seq2seq) applications using Science Daily with the aim of facilitating further research on language generation, which requires extreme paraphrasing and coping with long research articles. We further improve the quality of the press releases using co-training with scientific abstracts of sources or partitioned press releases. Finally, we apply evaluation measures beyond ROUGE and we demonstrate improved performance for our method over strong baselines, which we further confirm by quantitative and qualitative evaluation",
    "volume": "main",
    "checked": true,
    "id": "ac4e70290f02dc89b9dfcf6c6dfb7f49fbc6068c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17508": {
    "title": "Consecutive Decoding for Speech-to-text Translation",
    "abstract": "Speech-to-text translation (ST), which directly translates the source language speech to the target language text, has attracted intensive attention recently. However, the combination of speech recognition and machine translation in a single model poses a heavy burden on the direct cross-modal cross-lingual mapping. To reduce the learning difficulty, we propose COnSecutive Transcription and Translation (COSTT), an integral approach for speech-to-text translation. The key idea is to generate source transcript and target translation text with a single decoder. It benefits the model training so that additional large parallel text corpus can be fully exploited to enhance the speech translation training. Our method is verified on three mainstream datasets, including Augmented LibriSpeech English-French dataset, TED English-German dataset, and TED English-Chinese dataset. Experiments show that our proposed COSTT outperforms the previous state-of-the-art methods. The code is available at https://github.com/dqqcasia/st",
    "volume": "main",
    "checked": true,
    "id": "b23c06dcd89458781de94498522f3624c45bf630",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17509": {
    "title": "Listen, Understand and Translate: Triple Supervision Decouples End-to-end Speech-to-text Translation",
    "abstract": "An end-to-end speech-to-text translation (ST) takes audio in a source language and outputs the text in a target language. Existing methods are limited by the amount of parallel corpus. Can we build a system to fully utilize signals in a parallel ST corpus? We are inspired by human understanding system which is composed of auditory perception and cognitive processing. In this paper, we propose Listen-Understand-Translate, (LUT), a unified framework with triple supervision signals to decouple the end-to-end speech-to-text translation task. LUT is able to guide the acoustic encoder to extract as much information from the auditory input. In addition, LUT utilizes a pre-trained BERT model to enforce the upper encoder to produce as much semantic information as possible, without extra data. We perform experiments on a diverse set of speech translation benchmarks, including Librispeech English-French, IWSLT English-German and TED English-Chinese. Our results demonstrate LUT achieves the state-of-the-art performance, outperforming previous methods. The code is available at https://github.com/dqqcasia/st",
    "volume": "main",
    "checked": true,
    "id": "8efacdc573c47a56f2ef43067f602e61e77688d5",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17510": {
    "title": "MultiTalk: A Highly-Branching Dialog Testbed for Diverse Conversations",
    "abstract": "We study conversational dialog in which there are many possible responses to a given history. We present the MultiTalk Dataset, a corpus of over 320,000 sentences of written conversational dialog that balances a high branching factor (10) with several conversation turns (6) through selective branch continuation. We make multiple contributions to study dialog generation in the highly branching setting. In order to evaluate a diverse set of generations, we propose a simple scoring algorithm, based on bipartite graph matching, to optimally incorporate a set of diverse references. We study multiple language generation tasks at different levels of predictive conversation depth, using textual attributes induced automatically from pretrained classifiers. Our culminating task is a challenging theory of mind problem, a controllable generation task which requires reasoning about the expected reaction of the listener",
    "volume": "main",
    "checked": true,
    "id": "b00674d4e14ef655a16e74a24dfef32664064587",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17511": {
    "title": "Knowledge-aware Leap-LSTM: Integrating Prior Knowledge into Leap-LSTM towards Faster Long Text Classification",
    "abstract": "While widely used in industry, recurrent neural networks (RNNs) are known to have deficiencies in dealing with long sequences (e.g. slow inference, vanishing gradients etc.). Recent research has attempted to accelerate RNN models by developing mechanisms to skip irrelevant words in input. Due to the lack of labelled data, it remains as a challenge to decide which words to skip, especially for low-resource classification tasks. In this paper, we propose Knowledge-AwareLeap-LSTM (KALL), a novel architecture which integrates prior human knowledge (created either manually or automatically) like in-domain keywords, terminologies or lexicons into Leap-LSTM to partially supervise the skipping process. More specifically, we propose a knowledge-oriented cost function for KALL; furthermore, we propose two strategies to integrate the knowledge: (1) the Factored KALL approach involves a keyword indicator as a soft constraint for the skip-ping process, and (2) the Gated KALL enforces the inclusion of keywords while maintaining a differentiable network in training. Experiments on different public datasets show that our approaches are1.1x~2.6x faster than LSTM with better accuracy and 23.6x faster than XLNet in a resource-limited CPU-only environment",
    "volume": "main",
    "checked": true,
    "id": "c461d1399783a11ffe2056f6bc5955703b26ecdd",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17512": {
    "title": "FILTER: An Enhanced Fusion Method for Cross-lingual Language Understanding",
    "abstract": "Large-scale cross-lingual language models (LM), such as mBERT, Unicoder and XLM, have achieved great success in cross-lingual representation learning. However, when applied to zero-shot cross-lingual transfer tasks, most existing methods use only single-language input for LM finetuning, without leveraging the intrinsic cross-lingual alignment between different languages that proves essential for multilingual tasks. In this paper, we propose FILTER, an enhanced fusion method that takes cross-lingual data as input for XLM finetuning. Specifically, FILTER first encodes text input in the source language and its translation in the target language independently in the shallow layers, then performs cross-language fusion to extract multilingual knowledge in the intermediate layers, and finally performs further language-specific encoding. During inference, the model makes predictions based on the text input in the target language and its translation in the source language. For simple tasks such as classification, translated text in the target language shares the same label as the source language. However, this shared label becomes less accurate or even unavailable for more complex tasks such as question answering, NER and POS tagging. To tackle this issue, we further propose an additional KL-divergence self-teaching loss for model training, based on auto-generated soft pseudo-labels for translated text in the target language. Extensive experiments demonstrate that FILTER achieves new state of the art on two challenging multilingual multi-task benchmarks, XTREME and XGLUE",
    "volume": "main",
    "checked": true,
    "id": "738aeff1122e7a10f32b20ab73957f6adb3fadb7",
    "citation_count": 36
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17513": {
    "title": "Rethinking Boundaries: End-To-End Recognition of Discontinuous Mentions with Pointer Networks",
    "abstract": "A majority of research interests in irregular (e.g., nested or discontinuous) named entity recognition (NER) have been paid on nested entities, while discontinuous entities received limited attention. Existing work for discontinuous NER, however, either suffers from decoding ambiguity or predicting using token-level local features. In this work, we present an innovative model for discontinuous NER based on pointer networks, where the pointer simultaneously decides whether a token at each decoding frame constitutes an entity mention and where the next constituent token is. Our model has three major merits compared with previous work: (1) The pointer mechanism is memory-augmented, which enhances the mention boundary detection and interactions between the current decision and prior recognized mentions. (2) The encoder-decoder architecture can linearize the complexity of structure prediction, and thus reduce search costs. (3) The model makes every decision using global information, i.e., by consulting all the input, encoder and previous decoder output in a global view. Experimental results on the CADEC and ShARe13 datasets show that our model outperforms flat and hypergraph models as well as a state-of-the-art transition-based model for discontinuous NER. Further in-depth analysis demonstrates that our model performs well in recognizing various entities including flat, overlapping and discontinuous ones. More crucially, our model is effective on boundary detection, which is the kernel source to NER",
    "volume": "main",
    "checked": true,
    "id": "24f8c6870af78a65929dcf926691e4cbe95d94e6",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17514": {
    "title": "Encoder-Decoder Based Unified Semantic Role Labeling with Label-Aware Syntax",
    "abstract": "Currently the unified semantic role labeling (SRL) that achieves predicate identification and argument role labeling in an end-to-end manner has received growing interests. Recent works show that leveraging the syntax knowledge significantly enhances the SRL performances. In this paper, we investigate a novel unified SRL framework based on the sequence-to-sequence architecture with double enhancement in both the encoder and decoder sides. In the encoder side, we propose a novel label-aware graph convolutional network (LA-GCN) to encode both the syntactic dependent arcs and labels into BERT-based word representations. In the decoder side, we creatively design a pointer-network-based model for detecting predicates, arguments and roles jointly. Our pointer-net decoder is able to make decisions by consulting all the input elements in a global view, and meanwhile it is syntactic-aware by incorporating the syntax information from LA-GCN. Besides, a high-order interacted attention is introduced into the decoder for leveraging previously recognized triplets to help the current decision. Empirical experiments show that our framework significantly outperforms all existing graph-based methods on the CoNLL09 and Universal Proposition Bank datasets. In-depth analysis demonstrates that our model can effectively capture the correlations between syntactic and SRL structures",
    "volume": "main",
    "checked": true,
    "id": "c5a2f957e5323962b5ff15703eeeed08b68f8242",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17515": {
    "title": "End-to-end Semantic Role Labeling with Neural Transition-based Model",
    "abstract": "End-to-end semantic role labeling (SRL) has been received increasing interest. It performs the two subtasks of SRL: predicate identification and argument role labeling, jointly. Recent work is mostly focused on graph-based neural models, while the transition-based framework with neural networks which has been widely used in a number of closely-related tasks, has not been studied for the joint task yet. In this paper, we present the first work of transition-based neural models for end-to-end SRL. Our transition model incrementally discovers all sentential predicates as well as their arguments by a set of transition actions. The actions of the two subtasks are executed mutually for full interactions. Besides, we suggest high-order compositions to extract non-local features, which can enhance the proposed transition model further. Experimental results on CoNLL09 and Universal Proposition Bank show that our final model can produce state-of-the-art performance, and meanwhile keeps highly efficient in decoding. We also conduct detailed experimental analysis for a deep understanding of our proposed model",
    "volume": "main",
    "checked": true,
    "id": "4ec3ad4df9b5b856184def79404312958d9f0fe5",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17516": {
    "title": "Multi-View Feature Representation for Dialogue Generation with Bidirectional Distillation",
    "abstract": "Neural dialogue models suffer from low-quality responses when interacted in practice, demonstrating difficulty in generalization beyond training data. Recently, knowledge distillation has been used to successfully regularize the student by transferring knowledge from the teacher. However, the teacher and the student are trained on the same dataset and tend to learn similar feature representations, whereas the most general knowledge should be found through differences. The finding of general knowledge is further hindered by the unidirectional distillation, as the student should obey the teacher and may discard some knowledge that is truly general but refuted by the teacher. To this end, we propose a novel training framework, where the learning of general knowledge is more in line with the idea of reaching consensus, i.e., finding common knowledge that is beneficial to different yet all datasets through diversified learning partners. Concretely, the training task is divided into a group of subtasks with the same number of students. Each student assigned to one subtask not only is optimized on the allocated subtask but also imitates multi-view feature representation aggregated from other students (i.e., student peers), which induces students to capture common knowledge among different subtasks and alleviates the over-fitting of students on the allocated subtasks. To further enhance generalization, we extend the unidirectional distillation to the bidirectional distillation that encourages the student and its student peers to co-evolve by exchanging complementary knowledge with each other. Empirical results and analysis demonstrate that our training framework effectively improves the model generalization without sacrificing training efficiency",
    "volume": "main",
    "checked": true,
    "id": "a117c412a4b7cd379a43f4090d4f188d73ab5c89",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17517": {
    "title": "More the Merrier: Towards Multi-Emotion and Intensity Controllable Response Generation",
    "abstract": "The focus on conversational systems has recently shifted towards creating engaging agents by inculcating emotions into them. Human emotions are highly complex as humans can express multiple emotions with varying intensity in a single utterance, whereas the conversational agents convey only one emotion in their responses. To infuse human-like behaviour in the agents, we introduce the task of multi-emotion controllable response generation with the ability to express different emotions with varying levels of intensity in an open-domain dialogue system. We introduce a Multiple Emotion Intensity aware Multi-party Dialogue (MEIMD) dataset having 34k conversations taken from 8 different TV Series. We finally propose a Multiple Emotion with Intensity-based Dialogue Generation (MEI-DG) framework. The system employs two novel mechanisms: viz. (i) determining the trade-off between the emotion and generic words,   while focusing on the intensity of the desired emotions; and (ii) computing the amount of emotion left to be expressed, thereby regulating the generation accordingly. The detailed evaluation shows that our proposed approach attains superior performance compared to the baseline models",
    "volume": "main",
    "checked": true,
    "id": "03c09f47492c8b9ea04903f85d68279571f6609d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17518": {
    "title": "LRC-BERT: Latent-representation Contrastive Knowledge Distillation for Natural Language Understanding",
    "abstract": "The pre-training models such as BERT have achieved great results in various natural language processing problems. However, a large number of parameters need significant amounts of memory and the consumption of inference time, which makes it difficult to deploy them on edge devices. In this work, we propose a knowledge distillation method LRC-BERT based on contrastive learning to fit the output of the intermediate layer from the angular distance aspect, which is not considered by the existing distillation methods. Furthermore, we introduce a gradient perturbation-based training architecture in the training phase to increase the robustness of LRC-BERT, which is the first attempt in knowledge distillation. Additionally, in order to better capture the distribution characteristics of the intermediate layer, we design a two-stage training method for the total distillation loss. Finally, by verifying 8 datasets on the General Language Understanding Evaluation (GLUE) benchmark, the performance of the proposed LRC-BERT exceeds the existing state-of-the-art methods, which proves the effectiveness of our method",
    "volume": "main",
    "checked": true,
    "id": "4c3b044cc98def3defc3d562e5c0d811f7b0d200",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17519": {
    "title": "Nested Named Entity Recognition with Partially-Observed TreeCRFs",
    "abstract": "Named entity recognition (NER) is a well-studied task in natural language processing. However, the widely-used sequence labeling framework is difficult to detect entities with nested structures. In this work, we view nested NER as constituency parsing with partially-observed trees and model it with partially-observed TreeCRFs. Specifically, we view all labeled entity spans as observed nodes in a constituency tree, and other spans as latent nodes. With the TreeCRF we achieve a uniform way to jointly model the observed and the latent nodes. To compute the probability of partial trees with partial marginalization, we propose a variant of the Inside algorithm, the Masked Inside algorithm, that supports different inference operations for different nodes (evaluation for the observed, marginalization for the latent, and rejection for nodes incompatible with the observed) with efficient parallelized implementation, thus significantly speeding up training and inference. Experiments show that our approach achieves the state-of-the-art (SOTA) F1 scores on the ACE2004, ACE2005 dataset, and shows comparable performance to SOTA models on the GENIA dataset. We release the code at https://github.com/FranxYao/Partially-Observed-TreeCRFs",
    "volume": "main",
    "checked": true,
    "id": "5dfcc1f19a22c3bc081f2ff4410eb1efc7061838",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17520": {
    "title": "A Theoretical Analysis of the Repetition Problem in Text Generation",
    "abstract": "Text generation tasks, including translation, summarization, language models, and etc. see rapid growth during recent years. Despite the remarkable achievements, the repetition problem has been observed in nearly all text generation models undermining the generation performance extensively. To solve the repetition problem, many methods have been proposed, but there is no existing theoretical analysis to show why this problem happens and how it is resolved. In this paper, we propose a new framework for theoretical analysis for the repetition problem. We first define the Average Repetition Probability (ARP) to characterize the repetition problem quantitatively. Then, we conduct an extensive analysis of the Markov generation model and derive several upper bounds of the average repetition probability with intuitive understanding. We show that most of the existing methods are essentially minimizing the upper bounds explicitly or implicitly. Grounded on our theory, we show that the repetition problem is, unfortunately, caused by the traits of our language itself. One major reason is attributed to the fact that there exist too many words predicting the same word as the subsequent word with high probability. Consequently, it is easy to go back to that word and form repetitions and we dub it as the high inflow problem. Furthermore, we extend our analysis to broader generation models by deriving a concentration bound of the average repetition probability for a general generation model. Finally, based on the theoretical upper bounds, we propose a novel rebalanced encoding approach to alleviate the high inflow problem and thus reducing the upper bound.   The experimental results show that our theoretical framework is applicable in general generation models and our proposed rebalanced encoding approach alleviates the repetition problem significantly in both the translation task and the language modeling task. The source code of this paper can be obtained from https://github.com/fuzihaofzh/repetition-problem-nlg",
    "volume": "main",
    "checked": true,
    "id": "7ade458d52d2dfe997b8a617a6b524bda12a619d",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17521": {
    "title": "Paragraph-level Commonsense Transformers with Recurrent Memory",
    "abstract": "Human understanding of narrative texts requires making commonsense inferences beyond what is stated in the text explicitly. A recent model, COMET, can generate such inferences along several dimensions such as pre- and post-conditions, motivations, and mental states of the participants. However, COMET was trained on short phrases, and is therefore discourse-agnostic. When presented with each sentence of a multi-sentence narrative, it might generate inferences that are inconsistent with the rest of the narrative.  We present the task of discourse-aware commonsense inference. Given a sentence within a narrative, the goal is to generate commonsense inferences along predefined dimensions, while maintaining coherence with the rest of the narrative. Such large-scale paragraph-level annotation is hard to get and costly, so we use available sentence-level annotations to efficiently and automatically construct a distantly supervised corpus.  Using this corpus, we train PARA-COMET, a discourse-aware model that incorporates paragraph-level information to generate coherent commonsense inferences from narratives. PARA-COMET captures both semantic knowledge pertaining to prior world knowledge, and episodic knowledge involving how current events relate to prior and future events in a narrative. Our results confirm that PARA-COMET outperforms the sentence-level baselines, particularly in generating inferences that are both coherent and novel",
    "volume": "main",
    "checked": true,
    "id": "5dfc43bb697acf5eacf8b8a05d78dba8beb0dd42",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17522": {
    "title": "Judgment Prediction via Injecting Legal Knowledge into Neural Networks",
    "abstract": "Legal Judgment Prediction (LJP) is a key problem in legal artificial intelligence, which is aimed to predict a law case's judgment based on a given text describing the facts of the law case. Most of the previous work treats LJP as a text classification task and generally adopts deep neural networks (DNNs) based methods to solve it.  However, existing DNNs based work is data-hungry and hard to explain which legal knowledge is based on to make such a prediction.  Thus, injecting legal knowledge into neural networks to interpret the model and improve performance remains a significant problem.  In this paper, we propose to represent declarative legal knowledge as a set of first-order logic rules and integrate these logic rules into a co-attention network-based model explicitly. The use of logic rules enhances neural networks with explicit logical reason capabilities and makes the model more interpretable. We take the civil loan scenario as a case study and demonstrate the effectiveness of the proposed method through comprehensive experiments and analysis conducted on the collected dataset",
    "volume": "main",
    "checked": true,
    "id": "29032fcf25284fb3de81b0db02e4638d2aafb054",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17523": {
    "title": "Question-Driven Span Labeling Model for AspectOpinion Pair Extraction",
    "abstract": "Aspect term extraction and opinion word extraction are two fundamental subtasks of aspect-based sentiment analysis. The internal relationship between aspect terms and opinion words is typically ignored, and information for the decision-making of buyers and sellers is insufficient. In this paper, we explore an aspectopinion pair extraction (AOPE) task and propose a Question-Driven Span Labeling (QDSL) model to extract all the aspectopinion pairs from user-generated reviews. Specifically, we divide the AOPE task into aspect term extraction (ATE) and aspect-specified opinion extraction (ASOE) subtasks; we first extract all the candidate aspect terms and then the corresponding opinion words given the aspect term. Unlike existing approaches that use the BIO-based tagging scheme for extraction, the QDSL model adopts a span-based tagging scheme and builds a questionanswer-based machine-reading comprehension task for an effective aspectopinion pair extraction. Extensive experiments conducted on three tasks (ATE, ASOE, and AOPE) on four benchmark datasets demonstrate that the proposed method significantly outperforms state-of-the-art approaches",
    "volume": "main",
    "checked": true,
    "id": "eccf59850f2a2433cc546b3e7e278d42825eec15",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17524": {
    "title": "Analogy Training Multilingual Encoders",
    "abstract": "Language encoders encode words and phrases in ways that capture their local semantic relatedness, but are known to be globally inconsistent. Global inconsistency can seemingly be corrected for, in part, by leveraging signals from knowledge bases, but previous results are partial and limited to monolingual English encoders. We extract a large-scale multilingual, multi-word analogy dataset from Wikidata for diagnosing and correcting for global inconsistencies, and then implement a four-way Siamese BERT architecture for grounding multilingual BERT (mBERT) in Wikidata through analogy training. We show that analogy training not only improves the global consistency of mBERT, as well as the isomorphism of language-specific subspaces, but also leads to consistent gains on downstream tasks such as bilingual dictionary induction and sentence retrieval",
    "volume": "main",
    "checked": true,
    "id": "d61509614b158961638256b9f007851f3925fc74",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17525": {
    "title": "Fake it Till You Make it: Self-Supervised Semantic Shifts for Monolingual Word Embedding Tasks",
    "abstract": "The use of language is subject to variation over time as well as across social groups and knowledge domains, leading to differences even in the monolingual scenario. Such variation in word usage is often called lexical semantic change (LSC). The goal of LSC is to characterize and quantify language variations with respect to word meaning, to measure how distinct two language sources are (that is, people or language models). Because there is hardly any data available for such a task, most solutions involve unsupervised methods to align two embeddings and predict semantic change with respect to a distance measure. To that end, we propose a self-supervised approach to model lexical semantic change based on the perturbation of word vectors in the input corpora. We show that our method can be used for the detection of semantic change with any alignment method. Furthermore, it can be used to choose the landmark words to use in alignment and can lead to substantial improvements over the existing techniques for alignment. We illustrate the utility of our techniques using experimental results on three different datasets, involving words with the same or different meanings. Our methods not only provide significant improvements but also can lead to novel findings for the LSC problem",
    "volume": "main",
    "checked": true,
    "id": "99c74738730ed6a46f609e426b6a02119ef6f54e",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17526": {
    "title": "Perception Score: A Learned Metric for Open-ended Text Generation Evaluation",
    "abstract": "Automatic evaluation for open-ended natural language generation tasks remains a challenge. We propose a learned evaluation metric: Perception Score. It utilizes a pre-trained model and considers context information for conditional generation. Perception Score assigns a holistic score along with the uncertainty measurement. We conduct experiments on three open-ended conditional generation tasks and two open-ended unconditional generation tasks. Perception Score achieves state-of-the-art results on all the tasks consistently in terms of correlation with human evaluation scores",
    "volume": "main",
    "checked": true,
    "id": "c21075b86fe0608dee44c11e7667ac5b09cd4b0b",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17527": {
    "title": "DialogBERT: Discourse-Aware Response Generation via Learning to Recover and Rank Utterances",
    "abstract": "Recent advances in pre-trained language models have significantly improved neural response generation. However, existing methods usually view the dialogue context as a linear sequence of tokens and learn to generate the next word through token-level self-attention. Such token-level encoding hinders the exploration of discourse-level coherence among utterances. This paper presents DialogBERT, a novel conversational response generation model that enhances previous PLM-based dialogue models. DialogBERT employs a hierarchical Transformer architecture. To efficiently capture the discourse-level coherence among utterances, we propose two training objectives, including masked utterance regression and distributed utterance order ranking in analogy to the original BERT training. Experiments on three multi-turn conversation datasets show that our approach remarkably outperforms three baselines, such as BART and DialoGPT, in terms of quantitative evaluation. The human evaluation suggests that DialogBERT generates more coherent, informative, and human-like responses than the baselines with significant margins",
    "volume": "main",
    "checked": true,
    "id": "138622fff5cd7c6023a8b874958a0a0c857f9d41",
    "citation_count": 33
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17528": {
    "title": "Read, Retrospect, Select: An MRC Framework to Short Text Entity Linking",
    "abstract": "Entity linking (EL) for the rapidly growing short text (e.g. search queries and news titles) is critical to industrial applications. Most existing approaches relying on adequate context for long text EL are not effective for the concise and sparse short text. In this paper, we propose a novel framework called Multi-turn Multiple-choice Machine reading comprehension (M3) to solve the short text EL from a new perspective: a query is generated for each ambiguous mention exploiting its surrounding context, and an option selection module is employed to identify the golden entity from candidates using the query. In this way, M3 framework sufficiently interacts limited context with candidate entities during the encoding process, as well as implicitly considers the dissimilarities inside the candidate bunch in the selection stage. In addition, we design a two-stage verifier incorporated into M3 to address the commonly existed unlinkable problem in short text. To further consider the topical coherence and interdependence among referred entities, M3 leverages a multi-turn fashion to deal with mentions in a sequence manner by retrospecting historical cues. Evaluation shows that our M3 framework achieves the state-of-the-art performance on five Chinese and English datasets for the real-world short text EL",
    "volume": "main",
    "checked": true,
    "id": "14c121c8975628653cb635a628aa0d38795437ee",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17529": {
    "title": "Label Confusion Learning to Enhance Text Classification Models",
    "abstract": "Representing the true label as one-hot vector is the common practice in training text classification models. However, the one-hot representation may not adequately reflect the relation between the instance and labels, as labels are often not completely independent and instances may relate to multiple labels in practice. The inadequate one-hot representations tend to train the model to be over-confident, which may result in arbitrary prediction and model overfitting, especially for confused datasets (datasets with very similar labels) or noisy datasets (datasets with labeling errors). While training models with label smoothing can ease this problem in some degree, it still fails to capture the realistic relation among labels. In this paper, we propose a novel Label Confusion Model (LCM) as an enhancement component to current popular text classification models. LCM can learn label confusion to capture semantic overlap among labels by calculating the similarity between instance and labels during training and generate a better label distribution to replace the original one-hot label vector, thus improving the final classification performance. Extensive experiments on five text classification benchmark datasets reveal the effectiveness of LCM for several widely used deep learning classification models. Further experiments also verify that LCM is especially helpful for confused or noisy datasets and superior to the label smoothing method",
    "volume": "main",
    "checked": true,
    "id": "e4f70b3f601eacad372426a572e196034ec940be",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17530": {
    "title": "Iterative Utterance Segmentation for Neural Semantic Parsing",
    "abstract": "Neural semantic parsers usually fail to parse long and complex utterances into correct meaning representations, due to the lack of exploiting the principle of compositionality. To address this issue, we present a novel framework for boosting neural semantic parsers via iterative utterance segmentation.  Given an input utterance, our framework iterates between two neural modules: a segmenter for segmenting a span from the utterance, and a parser for mapping the span into a partial meaning representation. Then, these intermediate parsing results are composed into the final meaning representation. One key advantage is that this framework does not require any handcraft templates or additional labeled data for utterance segmentation: we achieve this through proposing a novel training method, in which the parser provides pseudo supervision for the segmenter. Experiments on Geo, ComplexWebQuestions and Formulas show that our framework can consistently improve performances of neural semantic parsers in different domains.  On data splits that require compositional generalization, our framework brings significant accuracy gains: Geo 63.1~81.2, Formulas 59.7~72.7, ComplexWebQuestions 27.1~56.3",
    "volume": "main",
    "checked": true,
    "id": "7344ed64d1717780422fd1d58fae85edc544d180",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17531": {
    "title": "BERT & Family Eat Word Salad: Experiments with Text Understanding",
    "abstract": "In this paper, we study the response of large models from the BERT family to incoherent inputs that should confuse any model that claims to understand natural language. We define simple heuristics to construct such examples. Our experiments show that state-of-the-art models consistently fail to recognize them as ill-formed, and instead produce high confidence predictions on them. As a consequence of this phenomenon, models trained on sentences with randomly permuted word order perform close to state-of-the-art models. To alleviate these issues, we show that if models are explicitly trained to recognize invalid inputs, they can be robust to such attacks without a drop in performance",
    "volume": "main",
    "checked": true,
    "id": "7defc117a11c16fb70bea6cbc0b58e48244992c8",
    "citation_count": 34
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17532": {
    "title": "Sketch and Customize: A Counterfactual Story Generator",
    "abstract": "Recent text generation models are easy to generate relevant and fluent text for the given text, while lack of causal reasoning ability when we change some parts of the given text.  Counterfactual story rewriting is a recently proposed task to test the causal reasoning ability for text generation models, which requires a model to predict the corresponding story ending when the condition is modified to a counterfactual one. Previous works have shown that the traditional sequence-to-sequence model cannot well handle this problem, as it often captures some spurious correlations between the original and counterfactual endings, instead of the causal relations between conditions and endings.  To address this issue, we propose a sketch-and-customize generation model guided by the causality implicated in the conditions and endings. In the sketch stage, a skeleton is extracted by removing words which are conflict to the counterfactual condition, from the original ending. In the customize stage, a generation model is used to fill proper words in the skeleton under the guidance of the counterfactual condition. In this way, the obtained counterfactual ending is both relevant to the original ending and consistent with the counterfactual condition. Experimental results show that the proposed model generates much better endings, as compared with the traditional sequence-to-sequence model",
    "volume": "main",
    "checked": true,
    "id": "9e329bc6d33fa31a8f51563ee632e3962d3f624b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17533": {
    "title": "Self-Attention Attribution: Interpreting Information Interactions Inside Transformer",
    "abstract": "The great success of Transformer-based models benefits from the powerful multi-head self-attention mechanism, which learns token dependencies and encodes contextual information from the input. Prior work strives to attribute model decisions to individual input features with different saliency measures, but they fail to explain how these input features interact with each other to reach predictions. In this paper, we propose a self-attention attribution method to interpret the information interactions inside Transformer. We take BERT as an example to conduct extensive studies. Firstly, we apply self-attention attribution to identify the important attention heads, while others can be pruned with marginal performance degradation. Furthermore, we extract the most salient dependencies in each layer to construct an attribution tree, which reveals the hierarchical interactions inside Transformer. Finally, we show that the attribution results can be used as adversarial patterns to implement non-targeted attacks towards BERT",
    "volume": "main",
    "checked": true,
    "id": "02465d57f63a2d8ed4082136d8e1b7db300105d2",
    "citation_count": 56
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17534": {
    "title": "Humor Knowledge Enriched Transformer for Understanding Multimodal Humor",
    "abstract": "Recognizing humor from a video utterance requires understanding the verbal and non-verbal components as well as incorporating the appropriate context and external knowledge. In this paper, we propose Humor Knowledge enriched Transformer (HKT) that can capture the gist of a multimodal humorous expression by integrating the preceding context and external knowledge. We incorporate humor centric external knowledge into the model by capturing the ambiguity and sentiment present in the language. We encode all the language, acoustic, vision, and humor centric features separately using Transformer based encoders, followed by a cross attention layer to exchange information among them. Our model achieves 77.36% and 79.41% accuracy in humorous punchline detection on UR-FUNNY and MUStaRD datasets -- achieving a new state-of-the-art on both datasets with the margin of 4.93% and 2.94% respectively. Furthermore, we demonstrate that our model can capture interpretable, humor-inducing patterns from all modalities",
    "volume": "main",
    "checked": true,
    "id": "1f2564e03580d5424cbd65f1b7585e19b665784d",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17535": {
    "title": "Synchronous Interactive Decoding for Multilingual Neural Machine Translation",
    "abstract": "To simultaneously translate a source language into multiple different target languages is one of the most common scenarios of multilingual translation. However, existing methods cannot make full use of translation model information during decoding, such as intra-lingual and inter-lingual future information, and therefore may suffer from some issues like the unbalanced outputs. In this paper, we present a new approach for synchronous interactive multilingual neural machine translation (SimNMT), which predicts each target language output simultaneously and interactively using historical and future information of all target languages. Specifically, we first propose a synchronous cross-interactive decoder in which generation of each target output does not only depend on its generated sequences, but also relies on its future information, as well as history and future contexts of other target languages. Then, we present a new interactive multilingual beam search algorithm that enables synchronous interactive decoding of all target languages in a single model. We take two target languages as an example to illustrate and evaluate the proposed SimNMT model on IWSLT datasets. The experimental results demonstrate that our method achieves significant improvements over several advanced NMT and MNMT models",
    "volume": "main",
    "checked": true,
    "id": "1bf0d2d915600c8204505c012f3a56c0c6a2f898",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17536": {
    "title": "Show Me How To Revise: Improving Lexically Constrained Sentence Generation with XLNet",
    "abstract": "Lexically constrained sentence generation allows the incorporation of prior knowledge such as lexical constraints into the output. This technique has been applied to machine translation, and dialog response generation. Previous work usually used Markov Chain Monte Carlo (MCMC) sampling to generate lexically constrained sentences, but they randomly determined the position to be edited and the action to be taken, resulting in many invalid refinements. To overcome this challenge, we used a classifier to instruct the MCMC-based models where and how to refine the candidate sentences. First, we developed two methods to create synthetic data on which the pre-trained model is fine-tuned to obtain a reliable classifier. Next, we proposed a two-step approach, \"Predict and Revise\", for constrained sentence generation. During the predict step, we leveraged the classifier to compute the learned prior for the candidate sentence. During the revise step, we resorted to MCMC sampling to revise the candidate sentence by conducting a sampled action at a sampled position drawn from the learned prior. We compared our proposed models with many strong baselines on two tasks, generating sentences with lexical constraints and text infilling. Experimental results have demonstrated that our proposed model performs much better than the previous work in terms of sentence fluency and diversity. Our code, pre-trained models and Appendix are available at https://github.com/NLPCode/MCMCXLNet",
    "volume": "main",
    "checked": true,
    "id": "507b45c939c123cd6c308ba4258287962efc0cd8",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17537": {
    "title": "Towards Fully Automated Manga Translation",
    "abstract": "We tackle the problem of machine translation of manga, Japanese comics. Manga translation involves two important problems in machine translation: context-aware and multimodal translation. Since text and images are mixed up in an unstructured fashion in Manga, obtaining context from the image is essential for manga translation. However, it is still an open problem how to extract context from image and integrate into MT models. In addition, corpus and benchmarks to train and evaluate such model is currently unavailable. In this paper, we make the following four contributions that establishes the foundation of manga translation research. First, we propose multimodal context-aware translation framework. We are the first to incorporate context information obtained from manga image. It enables us to translate texts in speech bubbles that cannot be translated without using context information (e.g., texts in other speech bubbles, gender of speakers, etc.). Second, for training the model, we propose the approach to automatic corpus construction from pairs of original manga and their translations, by which large parallel corpus can be constructed without any manual labeling. Third, we created a new benchmark to evaluate manga translation. Finally, on top of our proposed methods, we devised a first compleheisive system for fully automated manga translation",
    "volume": "main",
    "checked": true,
    "id": "a8302a61f49bbf1e702d417c4122dfbc729a4985",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17538": {
    "title": "SMART: A Situation Model for Algebra Story Problems via Attributed Grammar",
    "abstract": "Solving algebra story problems remains a challenging task in artificial intelligence, which requires a detailed understanding of real-world situations and a strong mathematical reasoning capability. Previous neural solvers of math word problems directly translate problem texts into equations, lacking an explicit interpretation of the situations, and often fail to handle more sophisticated situations. To address such limits of neural solvers, we introduce the concept of a situation model, which originates from psychology studies to represent the mental states of humans in problem-solving, and propose SMART, which adopts attributed grammar as the representation of situation models for algebra story problems. Specifically, we first train an information extraction module to extract nodes, attributes and relations from problem texts and then generate a parse graph based on a pre-defined attributed grammar. An iterative learning strategy is also proposed to further improve the performance of SMART. To study this task more rigorously, we carefully curate a new dataset named ASP6.6k. Experimental results on ASP6.6k show that the proposed model outperforms all previous neural solvers by a large margin, while preserving much better interpretability. To test these models' generalization capability, we also design an out-of-distribution (OOD) evaluation, in which problems are more complex than those in the training set. Our model exceeds state-of-the-art models by 17% in the OOD evaluation, demonstrating its superior generalization ability",
    "volume": "main",
    "checked": true,
    "id": "593ca71119fb6ee560926d9b304bde095267432d",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17539": {
    "title": "It Takes Two to Empathize: One to Seek and One to Provide",
    "abstract": "Empathy describes the capacity to feel, understand, and emotionally engage with what other people are experiencing. People have recently started to turn to online health communities to seek empathetic support when they undergo difficult situations such as suffering from a life-threatening disease, while others are there to provide empathetic support to those who need it. It is, therefore, important to detect the direction of empathy expressed in natural language. Previous studies only focus on the presence of empathy at a high-level and do not distinguish the direction of empathy that is expressed in textual messages. In this paper, we take one step further in the identification of perceived empathy from text by introducing IEMPATHIZE, a dataset of messages annotated with the direction of empathy exchanged in an online cancer network. We analyze user messages to identify the direction of empathy at a fine-grained level: seeking or providing empathy. Our dataset IEMPATHIZE serves as a challenging benchmark for studying empathy at a fine-grained level",
    "volume": "main",
    "checked": true,
    "id": "32b0473e48a29a63bcbbafb4e8f11c4b0392a660",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17540": {
    "title": "C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot Filling",
    "abstract": "Slot filling, a fundamental module of spoken language understanding, often suffers from insufficient quantity and diversity of training data. To remedy this, we propose a novel Cluster-to-Cluster generation framework for Data Augmentation (DA), named C2C-GenDA. It enlarges the training set by reconstructing existing utterances into alternative expressions while keeping semantic. Different from previous DA works that reconstruct utterances one by one independently, C2C-GenDA jointly encodes multiple existing utterances of the same semantics and simultaneously decodes multiple unseen expressions. Jointly generating multiple new utterances allows to consider the relations between generated instances and encourages diversity. Besides, encoding multiple existing utterances endows C2C with a wider view of existing expressions, helping to reduce generation that duplicates existing data. Experiments on ATIS and Snips datasets show that instances augmented by C2C-GenDA improve slot filling by 7.99 (11.9%) and 5.76 (13.6%) F-scores respectively, when there are only hundreds of training utterances. Code: https://github.com/Sanyuan-Chen/C2C-DA",
    "volume": "main",
    "checked": true,
    "id": "c326c1d6f154bbc9822f900ddcf42f482ec9c611",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17541": {
    "title": "Few-shot Learning for Multi-label Intent Detection",
    "abstract": "In this paper, we study the few-shot multi-label classification for user intent detection. For multi-label intent detection, state-of-the-art work estimates label-instance relevance scores and uses a threshold to select multiple associated intent labels. To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then adapt the thresholds to certain few-shot domains with a calibration based on nonparametric learning. For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refines representations of different classes to be well-separated from each other. Experiments on two datasets show that the proposed model significantly outperforms strong baselines in both one-shot and five-shot settings",
    "volume": "main",
    "checked": true,
    "id": "6c6dc8cfda89fb6f90073cbee1ea82e744477460",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17542": {
    "title": "HARGAN: Heterogeneous Argument Attention Network for Persuasiveness Prediction",
    "abstract": "Argument structure elaborates the relation among claims and premises.   Previous works in persuasiveness prediction do not consider this relation in their architectures.   To take argument structure information into account, this paper proposes an approach to persuasiveness prediction with a novel graph-based neural network model, called heterogeneous argument attention network (HARGAN).  By jointly training on the persuasiveness and stance of the replies, our model achieves the state-of-the-art performance on the ChangeMyView (CMV) dataset for the persuasiveness prediction task.  Experimental results show that the graph setting enables our model to aggregate information across multiple paragraphs effectively.  In the meanwhile, our stance prediction auxiliary task enables our model to identify the viewpoint of each party, and helps our model perform better on the persuasiveness prediction",
    "volume": "main",
    "checked": true,
    "id": "596d7047fc2ef773ce19d96c802bc973263e363d",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17543": {
    "title": "SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete Utterance Restoration",
    "abstract": "Dialogue systems in open domain have achieved great success due to the easily obtained single-turn corpus and the development of deep learning, but the multi-turn scenario is still a challenge because of the frequent coreference and information omission. In this paper, we investigate the incomplete utterance restoration which has brought general improvement over multi-turn dialogue systems in recent studies. Meanwhile, inspired by the autoregression for text generation and the sequence labeling for text editing, we propose a novel semi autoregressive generator (SARG) with the high efficiency and flexibility. Moreover, experiments on Restoration-200k show that our proposed model significantly outperforms the state-of-the-art models in terms of quality and inference speed",
    "volume": "main",
    "checked": true,
    "id": "69c515a62403fcc19125d3a6dd8e878aa5cde604",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17544": {
    "title": "Entity Guided Question Generation with Contextual Structure and Sequence Information Capturing",
    "abstract": "Question generation is a challenging task and has attracted widespread attention in recent years. Although previous studies have made great progress, there are still two main shortcomings: First, previous work did not simultaneously capture the sequence information and structure information hidden in the context, which results in poor results of the generated questions. Second, the generated questions cannot be answered by the given context. To tackle these issues, we propose an entity guided question generation model with contextual structure information and sequence information capturing. We use a Graph Convolutional Network and a Bidirectional Long Short Term Memory Network to capture the structure information and sequence information of the context, simultaneously. In addition, to improve the answerability of the generated questions, we use an entity-guided approach to obtain question type from the answer, and jointly encode the answer and question type. Both automatic and manual metrics show that our model can generate comparable questions with state-of-the-art models. Our code is available at https://github.com/VISLANG-Lab/EGSS",
    "volume": "main",
    "checked": true,
    "id": "647ae2208f4c40b21979ec9a2a877867b659eb6b",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17545": {
    "title": "Story Ending Generation with Multi-Level Graph Convolutional Networks over Dependency Trees",
    "abstract": "As an interesting and challenging task, story ending generation aims at generating a reasonable and coherent ending for a given story context. The key challenge of the task is to comprehend the context sufficiently and capture the hidden logic information effectively, which has not been well explored by most existing generative models. To tackle this issue, we propose a context-aware Multi-level Graph Convolutional Networks over Dependency Parse (MGCN-DP) trees to capture dependency relations and context clues more effectively. We utilize dependency parse trees to facilitate capturing relations and events in the context implicitly, and Multi-level Graph Convolutional Networks to update and deliver the representation crossing levels to obtain richer contextual information. Both automatic and manual evaluations show that our MGCN-DP can achieve comparable performance with state-of-the-art models. Our source code is available at https://github.com/VISLANG-Lab/MLGCN-DP",
    "volume": "main",
    "checked": true,
    "id": "85c92bf6ea10d9ce3993005a869fba4f4ff94993",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17546": {
    "title": "Adaptive Beam Search Decoding for Discrete Keyphrase Generation",
    "abstract": "Keyphrase Generation compresses a document into some highly-summative phrases, which is an important task in natural language processing. Most state-of-the-art adopt greedy search or beam search decoding methods. These two decoding methods generate a large number of duplicated keyphrases and are time-consuming. Moreover, beam search only predicts a fixed number of keyphrases for different documents. In this paper, we propose an adaptive generation model-AdaGM, which is mainly inspired by the importance of the first words in keyphrase generation. In AdaGM, a novel reset state training mechanism is proposed to maximize the difference in the predicted first words. To ensure the discreteness and get an appropriate number of keyphrases according to the content of the document adaptively, we equip beam search with a highly effective filter mechanism. Experiments on five public datasets demonstrate the proposed model can generate marginally less duplicated and more accurate keyphrases. The codes of AdaGM are available at: https://github.com/huangxiaolist/adaGM",
    "volume": "main",
    "checked": true,
    "id": "cdf612e33935a872ab485d7d7d302d64be258a58",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17547": {
    "title": "Distribution Matching for Rationalization",
    "abstract": "The task of rationalization aims to extract pieces of input text as rationales to justify neural network predictions on text classification tasks. By definition, rationales represent key text pieces used for prediction and thus should have similar classification feature distribution compared to the original input text. However, previous methods mainly focused on maximizing the mutual information between rationales and labels while neglecting the relationship between rationales and input text. To address this issue, we propose a novel rationalization method that matches the distributions of rationales and input text in both the feature space and output space. Empirically, the proposed distribution matching approach consistently outperforms previous methods by a large margin. Our data and code are available",
    "volume": "main",
    "checked": true,
    "id": "145cbeaa23e8feba769e74ab2f7ab5b76103bdc1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17548": {
    "title": "Audio-Oriented Multimodal Machine Comprehension via Dynamic Inter- and Intra-modality Attention",
    "abstract": "While Machine Comprehension (MC) has attracted extensive research interests in recent years, existing approaches mainly belong to the category of Machine Reading Comprehension task which mines textual inputs (paragraphs and questions) to predict the answers (choices or text spans). However, there are a lot of MC tasks that accept audio input in addition to the textual input, e.g. English listening comprehension test. In this paper, we target the problem of Audio-Oriented Multimodal Machine Comprehension, and its goal is to answer questions based on the given audio and textual information. To solve this problem, we propose a Dynamic Inter- and Intra-modality Attention (DIIA) model to effectively fuse the two modalities (audio and textual). DIIA can work as an independent component and thus be easily integrated into existing MC models. Moreover, we further develop a Multimodal Knowledge Distillation (MKD) module to enable our multimodal MC model to accurately predict the answers based only on either the text or the audio. As a result, the proposed approach can handle various tasks including: Audio-Oriented Multimodal Machine Comprehension, Machine Reading Comprehension and Machine Listening Comprehension, in a single model, making fair comparisons possible between our model and the existing unimodal MC models. Experimental results and analysis prove the effectiveness of the proposed approaches. First, the proposed DIIA boosts the baseline models by up to 21.08% in terms of accuracy; Second, under the unimodal scenarios, the MKD module allows our multimodal MC model to significantly outperform the unimodal models by up to 18.87%, which are trained and tested with only audio or textual data",
    "volume": "main",
    "checked": true,
    "id": "d844cd7ab3e922a49c0d68f83a9c08bf6566e99b",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17549": {
    "title": "Unsupervised Learning of Discourse Structures using a Tree Autoencoder",
    "abstract": "Discourse information, as postulated by popular discourse theories, such as RST and PDTB, has been shown to improve an increasing number of downstream NLP tasks, showing positive effects and synergies of discourse with important real-world applications. While methods for incorporating discourse become more and more sophisticated, the growing need for robust and general discourse structures has not been sufficiently met by current discourse parsers, usually trained on small scale datasets in a strictly limited number of domains. This makes the prediction for arbitrary tasks noisy and unreliable. The overall resulting lack of high-quality, high-quantity discourse trees poses a severe limitation to further progress.   In order the alleviate this shortcoming, we propose a new strategy to generate tree structures in a task-agnostic, unsupervised fashion by extending a latent tree induction framework with an auto-encoding objective. The proposed approach can be applied to any tree-structured objective, such as syntactic parsing, discourse parsing and others. However, due to the especially difficult annotation process to generate discourse trees, we initially develop a method to generate larger and more diverse discourse treebanks. In this paper we are inferring general tree structures of natural text in multiple domains, showing promising results on a diverse set of tasks",
    "volume": "main",
    "checked": true,
    "id": "2f9b4b450983297628b2970f391481875894acf5",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17550": {
    "title": "Dynamic Hybrid Relation Exploration Network for Cross-Domain Context-Dependent Semantic Parsing",
    "abstract": "Semantic parsing has long been a fundamental problem in natural language processing. Recently, cross-domain context-dependent semantic parsing has become a new focus of research. Central to the problem is the challenge of leveraging contextual information of both natural language queries and database schemas in the interaction history. In this paper, we present a dynamic graph framework that is capable of effectively modelling contextual utterances, tokens, database schemas, and their complicated interaction as the conversation proceeds. The framework employs a dynamic memory decay mechanism that incorporates inductive bias to integrate enriched contextual relation representation, which is further enhanced with a powerful reranking model. At the time of writing, we demonstrate that the proposed framework outperforms all existing models by large margins, achieving new state-of-the-art performance on two large-scale benchmarks, the SParC and CoSQL datasets. Specifically, the model attains a 55.8% question-match and 30.8% interaction-match accuracy on SParC, and a 46.8% question-match and 17.0% interaction-match accuracy on CoSQL",
    "volume": "main",
    "checked": true,
    "id": "becc21ab34a7858e9bec469c9329ddacf39472fa",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17551": {
    "title": "DDRel: A New Dataset for Interpersonal Relation Classification in Dyadic Dialogues",
    "abstract": "Interpersonal language style shifting in dialogues is an interesting and almost instinctive ability of human. Understanding interpersonal relationship from language content is also a crucial step toward further understanding dialogues. Previous work mainly focuses on relation extraction between named entities in texts or within a single dialogue session. In this paper, we propose the task of relation classification of interlocutors based on their dialogues. We crawled movie scripts from IMSDb, and annotated the relation label for each session according to 13 pre-defined relationships. The annotated dataset DDRel consists of 6,300 dyadic dialogue sessions between 694 pairs of speakers with 53,126 utterances in total. We also construct session-level and pair-level relation classification tasks with widely-accepted baselines. The experimental results show that both tasks are challenging for existing models and the dataset will be useful for future research",
    "volume": "main",
    "checked": true,
    "id": "0c52efb0754b3b9af7a87ade7bdd9ca442d78aed",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17552": {
    "title": "Flexible Non-Autoregressive Extractive Summarization with Threshold: How to Extract a Non-Fixed Number of Summary Sentences",
    "abstract": "Sentence-level extractive summarization is a fundamental yet challenging task, and recent powerful approaches prefer to pick sentences sorted by the predicted probabilities until the length limit is reached, a.k.a. ``Top-K Strategy''. This length limit is fixed based on the validation set, resulting in the lack of flexibility. In this work, we propose a more flexible and accurate non-autoregressive method for single document extractive summarization, extracting a non-fixed number of summary sentences without the sorting step. We call our approach ThresSum as it picks sentences simultaneously and individually from the source document when the predicted probabilities exceed a threshold. During training, the model enhances sentence representation through iterative refinement and the intermediate latent variables receive some weak supervision with soft labels, which are generated progressively by adjusting the temperature with a knowledge distillation algorithm. Specifically, the temperature is initialized with high value and drops along with the iteration until a temperature of 1. Experimental results on CNN/DM and NYT datasets have demonstrated the effectiveness of ThresSum, which significantly outperforms BERTSUMEXT with a substantial improvement of 0.74 ROUGE-1 score on CNN/DM. Our source code will be available on Github",
    "volume": "main",
    "checked": true,
    "id": "c542d0d906d0fbf7cd14b24c319f504efb2c35b0",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17553": {
    "title": "EQG-RACE: Examination-Type Question Generation",
    "abstract": "Question Generation (QG) is an essential component of the automatic intelligent tutoring systems, which aims to generate high-quality questions for facilitating the reading practice and assessments. However, existing QG technologies encounter several key issues concerning the biased and unnatural language sources of datasets which are mainly obtained from the Web (e.g. SQuAD). In this paper, we propose an innovative Examination-type Question Generation approach (EQG-RACE) to generate exam-like questions based on a dataset extracted from RACE. Two main strategies are employed in EQG-RACE for dealing with discrete answer information and reasoning among long contexts. A Rough Answer and Key Sentence Tagging scheme is utilized to enhance the representations of input. An Answer-guided Graph Convolutional Network (AG-GCN) is designed to capture structure information in revealing the inter-sentences and intra-sentence relations. Experimental results show a state-of-the-art performance of EQG-RACE, which is apparently superior to the baselines. In addition, our work has established a new QG prototype with a reshaped dataset and QG method, which provides an important benchmark for related research in future work. We will make our data and code publicly available for further research",
    "volume": "main",
    "checked": true,
    "id": "f84b531135acc19191310537065a804c00814cdd",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17554": {
    "title": "Hierarchical Macro Discourse Parsing Based on Topic Segmentation",
    "abstract": "Hierarchically constructing micro (i.e., intra-sentence or inter-sentence) discourse structure trees using explicit boundaries (e.g., sentence and paragraph boundaries) has been proved to be an effective strategy. However, it is difficult to apply this strategy to document-level macro (i.e., inter-paragraph) discourse parsing, the more challenging task, due to the lack of explicit boundaries at the higher level. To alleviate this issue, we introduce a topic segmentation mechanism to detect implicit topic boundaries and then help the document-level macro discourse parser to construct better discourse trees hierarchically. In particular, our parser first splits a document into several sections using the topic boundaries that the topic segmentation detects. Then it builds a smaller and more accurate discourse sub-tree in each section and sequentially forms a whole tree for a document. The experimental results on both Chinese MCDTB and English RST-DT show that our proposed method outperforms the state-of-the-art baselines significantly",
    "volume": "main",
    "checked": true,
    "id": "5c0f536db679417201877f0ce1a9621d5e5b93bd",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17555": {
    "title": "FIXMYPOSE: Pose Correctional Captioning and Retrieval",
    "abstract": "Interest in physical therapy and individual exercises such as yoga/dance has increased alongside the well-being trend, and people globally enjoy such exercises at home/office via video streaming platforms. However, such exercises are hard to follow without expert guidance. Even if experts can help, it is almost impossible to give personalized feedback to every trainee remotely. Thus, automated pose correction systems are required more than ever, and we introduce a new captioning dataset named FixMyPose to address this need. We collect natural language descriptions of correcting a \"current\" pose to look like a \"target\" pose. To support a multilingual setup, we collect descriptions in both English and Hindi. The collected descriptions have interesting linguistic properties such as egocentric relations to the environment objects, analogous references, etc., requiring an understanding of spatial relations and commonsense knowledge about postures. Further, to avoid ML biases, we maintain a balance across characters with diverse demographics, who perform a variety of movements in several interior environments (e.g., homes, offices). From our FixMyPose dataset, we introduce two tasks: the pose-correctional-captioning task and its reverse, the target-pose-retrieval task. During the correctional-captioning task, models must generate the descriptions of how to move from the current to the target pose image, whereas in the retrieval task, models should select the correct target pose given the initial pose and the correctional description. We present strong cross-attention baseline models (uni/multimodal, RL, multilingual) and also show that our baselines are competitive with other models when evaluated on other image-difference datasets. We also propose new task-specific metrics (object-match, body-part-match, direction-match) and conduct human evaluation for more reliable evaluation, and we demonstrate a large human-model performance gap suggesting room for promising future work. Finally, to verify the sim-to-real transfer of our FixMyPose dataset, we collect a set of real images and show promising performance on these images. Data and code are available: https://fixmypose-unc.github.io",
    "volume": "main",
    "checked": true,
    "id": "647120ebe1dbcb9f96aefe4e86cc2809cb351be4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17556": {
    "title": "Self-supervised Pre-training and Contrastive Representation Learning for Multiple-choice Video QA",
    "abstract": "Video Question Answering (VideoQA) requires fine-grained understanding of both video and language modalities to answer the given questions. In this paper, we propose novel training schemes for multiple-choice video question answering with a self-supervised pre-training stage and a supervised contrastive learning in the main stage as an auxiliary learning. In the self-supervised pre-training stage, we transform the original problem format of predicting the correct answer into the one that predicts the relevant question to provide a model with broader contextual inputs without any further dataset or annotation. For contrastive learning in the main stage, we add a masking noise to the input corresponding to the ground-truth answer, and consider the original input of the ground-truth answer as a positive sample, while treating the rest as negative samples. By mapping the positive sample closer to the masked input, we show that the model performance is improved. We further employ locally aligned attention to focus more effectively on the video frames that are particularly relevant to the given corresponding subtitle sentences. We evaluate our proposed model on highly competitive benchmark datasets related to multiple-choice video QA: TVQA, TVQA+, and DramaQA. Experimental results show that our model achieves state-of-the-art performance on all datasets. We also validate our approaches through further analyses",
    "volume": "main",
    "checked": true,
    "id": "40e086bd10391913afb53ac2093a25ae550ba0e4",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17557": {
    "title": "The Gap on Gap: Tackling the Problem of Differing Data Distributions in Bias-Measuring Datasets",
    "abstract": "Diagnostic datasets that can detect biased models are an important prerequisite for bias reduction within natural language processing.  However, undesired patterns in the collected data can make such tests incorrect.  For example, if the feminine subset of a gender-bias-measuring coreference resolution dataset contains sentences with a longer average distance between the pronoun and the correct candidate, an RNN-based model may perform worse on this subset due to long-term dependencies.  In this work, we introduce a theoretically grounded method for weighting test samples to cope with such patterns in the test data.  We demonstrate the method on the GAP dataset for coreference resolution.  We annotate GAP with spans of all personal names and show that examples in the female subset contain more personal names and a longer distance between pronouns and their referents, potentially affecting the bias score in an undesired way.  Using our weighting method, we find the set of weights on the test instances that should be used for coping with these correlations,   and we re-evaluate 16 recently released coreference models",
    "volume": "main",
    "checked": true,
    "id": "2fdb8a6089cab6901e75ff12c63dd8cc1aa152ca",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17558": {
    "title": "SALNet: Semi-supervised Few-Shot Text Classification with Attention-based Lexicon Construction",
    "abstract": "We propose a semi-supervised bootstrap learning framework for few-shot text classification. From a small amount of the initial dataset, our framework obtains a larger set of reliable training data by using the attention weights from an LSTM-based trained classifier. We first train an LSTM-based text classifier from a given labeled dataset using the attention mechanism. Then, we collect a set of words for each class called a lexicon, which is supposed to be a representative set of words for each class based on the attention weights calculated for the classification task. We bootstrap the classifier using the new data that are labeled by the combination of the classifier and the constructed lexicons to improve the prediction accuracy. As a result, our approach outperforms the previous state-of-the-art methods including semi-supervised learning algorithms and pretraining algorithms for few-shot text classification task on four publicly available benchmark datasets. Moreover, we empirically confirm that the constructed lexicons are reliable enough and substantially improve the performance of the original classifier",
    "volume": "main",
    "checked": true,
    "id": "eb23e9a05943f4713bff1640f35ed3c821c93954",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17559": {
    "title": "Multi-SpectroGAN: High-Diversity and High-Fidelity Spectrogram Generation with Adversarial Style Combination for Speech Synthesis",
    "abstract": "While generative adversarial networks (GANs) based neural text-to-speech (TTS) systems have shown significant improvement in neural speech synthesis, there is no TTS system to learn to synthesize speech from text sequences with only adversarial feedback. Because adversarial feedback alone is not sufficient to train the generator, current models still require the reconstruction loss compared with the ground-truth and the generated mel-spectrogram directly. In this paper, we present Multi-SpectroGAN (MSG), which can train the multi-speaker model with only the adversarial feedback by conditioning a self-supervised hidden representation of the generator to a conditional discriminator. This leads to better guidance for generator training. Moreover, we also propose adversarial style combination (ASC) for better generalization in the unseen speaking style and transcript, which can learn latent representations of the combined style embedding from multiple mel-spectrograms. Trained with ASC and feature matching, the MSG synthesizes a high-diversity mel-spectrogram by controlling and mixing the individual speaking styles (e.g., duration, pitch, and energy). The result shows that the MSG synthesizes a high-fidelity mel-spectrogram, which has almost the same naturalness MOS score as the ground-truth mel-spectrogram",
    "volume": "main",
    "checked": true,
    "id": "2989bdc41227742becd0490ac05fdad2bdfec1f4",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17560": {
    "title": "Have We Solved The Hard Problem? Its Not Easy! Contextual Lexical Contrast as a Means to Probe Neural Coherence",
    "abstract": "Lexical cohesion is a fundamental mechanism for text which requires a pair of words to be interpreted as a certain type of lexical relation (e.g., similarity) to understand a coherent context; we refer to such relations as the contextual lexical relation. However, work on lexical cohesion has not modeled context comprehensively in considering lexical relations due to the lack of linguistic resources. In this paper, we take initial steps to address contextual lexical relations by focusing on the contrast relation, as it is a well-known relation though it is more subtle and relatively less resourced. We present a corpus named Cont 2 Lex to make Contextual Lexical Contrast Recognition a computationally feasible task. We benchmark this task with widely-adopted semantic representations; we discover that contextual embeddings (e.g. BERT) generally outperform static embeddings (e.g. Glove), but barely go beyond 70% in accuracy performance. In addition, we nd that all embeddings perform better when CLC occurs within the same sentence, suggesting possible limitations of current computational coherence models. Another intriguing discovery is the improvement of BERT in CLC is largely attributed to its modeling of CLC word pairs co-occurring with other word repetitions. Such observations imply that the progress made in lexical coherence modeling remains relatively primitive even for semantic representations such as BERT that have been empowering numerous standard NLP tasks to approach human benchmarks. Through presenting our corpus and benchmark, we attempt to seed initial discussions and endeavors in advancing semantic representations from modeling syntactic and semantic levels to coherence and discourse levels",
    "volume": "main",
    "checked": true,
    "id": "4e9e329fdf664bbee97b669650edd2b44a9a5629",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17561": {
    "title": "Learning Light-Weight Translation Models from Deep Transformer",
    "abstract": "Recently, deep models have shown tremendous improvements in neural machine translation (NMT). However, systems of this kind are computationally expensive and memory intensive. In this paper, we take a natural step towards learning strong but light-weight NMT systems. We proposed a novel group-permutation based knowledge distillation approach to compressing the deep Transformer model into a shallow model. The experimental results on several benchmarks validate the effectiveness of our method. Our compressed model is 8 times shallower than the deep model, with almost no loss in BLEU. To further enhance the teacher model, we present a Skipping Sub-Layer method to randomly omit sub-layers to introduce perturbation into training, which achieves a BLEU score of 30.63 on English-German newstest2014. The code is publicly available at https://github.com/libeineu/GPKD",
    "volume": "main",
    "checked": true,
    "id": "a817d740f64dcc04734ece08e20e136ccff240e7",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17562": {
    "title": "Improving the Efficiency and Effectiveness for BERT-based Entity Resolution",
    "abstract": "BERT has set a new state-of-the-art performance on entity resolution (ER) task, largely owed to fine-tuning pre-trained language models and the deep pair-wise interaction. Albeit being remarkably effective, it comes with a steep increase in computational cost, as the deep-interaction requires to exhaustively compute every tuple pair to search for co-references. For ER task, it is often prohibitively expensive due to the large cardinality to be matched. To tackle this, we introduce a siamese network structure that independently encodes tuples using BERT but delays the pair-wise interaction via an enhanced alignment network. This siamese structure enables a dedicated blocking module to quickly filter out obviously dissimilar tuple pairs, and thus drastically reduces the cardinality of fine-grained matching. Further, the blocking and entity matching are integrated into a multi-task learning framework for facilitating both tasks. Extensive experiments on multiple datasets demonstrate that our model significantly outperforms state-of-the-art models (including BERT) in both efficiency and effectiveness",
    "volume": "main",
    "checked": true,
    "id": "e1392ce545ecb839e92cf2587161a446c99019e6",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17563": {
    "title": "Multi-view Inference for Relation Extraction with Uncertain Knowledge",
    "abstract": "Knowledge graphs (KGs) are widely used to facilitate relation extraction (RE) tasks. While most previous RE methods focus on leveraging deterministic KGs, uncertain KGs, which assign a confidence score for each relation instance, can provide prior probability distributions of relational facts as valuable external knowledge for RE models. This paper proposes to exploit uncertain knowledge to improve relation extraction. Specifically, we introduce ProBase, an uncertain KG that indicates to what extent a target entity belongs to a concept, into our RE architecture. We then design a novel multi-view inference framework to systematically integrate local context and global knowledge across three views: mention-, entity- and concept-view. The experiment results show that our model achieves competitive performances on both sentence- and document-level relation extraction, which verifies the effectiveness of introducing uncertain knowledge and the multi-view inference framework that we design",
    "volume": "main",
    "checked": true,
    "id": "3c5cf01eba95d2ada27344b26ef9a9393a53cf84",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17564": {
    "title": "Towards Topic-Aware Slide Generation For Academic Papers With Unsupervised Mutual Learning",
    "abstract": "Slides are commonly used to present information and tell stories. In academic and research communities, slides are typically used to summarize findings in accepted papers for presentation in meetings and conferences.  These slides for academic papers usually contain common and essential topics such as major contributions, model design, experiment details and future work. In this paper, we aim to automatically generate slides for academic papers. We first conducted an in-depth analysis of how humans create slides. We then mined frequently used slide topics. Given a topic, our approach extracts relevant sentences in the paper to provide the draft slides. Due to the lack of labeling data, we integrate prior knowledge of ground truth sentences into a log-linear model to create an initial pseudo-target distribution. Two sentence extractors are learned collaboratively and bootstrap the performance of each other. Evaluation results on a labeled test set show that our model can extract more relevant sentences than baseline methods. Human evaluation also shows slides generated by our model can serve as a good basis for preparing the final presentations",
    "volume": "main",
    "checked": true,
    "id": "a32d3a98d18872c5e3ca6a425683c39ebd2c977f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17565": {
    "title": "The Style-Content Duality of Attractiveness: Learning to Write Eye-Catching Headlines via Disentanglement",
    "abstract": "Eye-catching headlines function as the first device to trigger more clicks, bringing reciprocal effect between producers and viewers. Producers can obtain more traffic and profits, and readers can have access to outstanding articles. When generating attractive headlines, it is important to not only capture the attractive content but also follow an eye-catching writtenstyle. In this paper, we propose a Disentanglement-based Attractive Headline Generator (DAHG) that generates headline which captures the attractive content following the attractive style. Concretely, we first devise a disentanglement module to divide the style and content of an attractive prototype headline into latent spaces, with two auxiliary constraints to ensure the two spaces are indeed disentangled. The latent content information is then used to further polish the document representation and help capture the salient part. Finally, the generator takes the polished document as input to generate headline under the guidance of the attractive style. Extensive experiments on the public Kuaibao dataset show that DAHG achieves state-of-the-art performance. Human evaluation also demonstrates that DAHG triggers 22% more clicks than existing models",
    "volume": "main",
    "checked": true,
    "id": "9caceb954c06296e7b8c87735e245c559622ee5d",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17566": {
    "title": "ACT: an Attentive Convolutional Transformer for Efficient Text Classification",
    "abstract": "Recently, Transformer has been demonstrating promising performance in many NLP tasks and showing a trend of replacing Recurrent Neural Network (RNN). Meanwhile, less attention is drawn to Convolutional Neural Network (CNN) due to its weak ability in capturing sequential and long-distance dependencies, although it has excellent local feature extraction capability. In this paper, we introduce an Attentive Convolutional Transformer (ACT) that takes the advantages of both Transformer and CNN for efficient text classification. Specifically, we propose a novel attentive convolution mechanism that utilizes the semantic meaning of convolutional filters attentively to transform text from complex word space to a more informative convolutional filter space where important n-grams are captured. ACT is able to capture both local and global dependencies effectively while preserving sequential information. Experiments on various text classification tasks and detailed analyses show that ACT is a lightweight, fast, and effective universal text classifier, outperforming CNNs, RNNs, and attentive models including Transformer",
    "volume": "main",
    "checked": true,
    "id": "40211ddcc2b2ddf88d7f60bb5ded397c601fe970",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17567": {
    "title": "Quantum-inspired Neural Network for Conversational Emotion Recognition",
    "abstract": "We provide a novel perspective on conversational emotion recognition by drawing an analogy between the task and a complete span of quantum measurement. We characterize different steps of quantum measurement in the process of recognizing speakers' emotions in conversation, and stitch them up with a quantum-like neural network. The quantum-like layers are implemented by complex-valued operations to ensure an authentic adoption of quantum concepts, which naturally enables conversational context modeling and multimodal fusion. We borrow an existing algorithm to learn the complex-valued network weights, so that the quantum-like procedure is conducted in a data-driven manner. Our model is comparable to state-of-the-art approaches on two benchmarking datasets, and provide a quantum view to understand conversational emotion recognition",
    "volume": "main",
    "checked": true,
    "id": "66c73652e3e249666ae4cc3abad0b22533d7dee3",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17568": {
    "title": "HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions",
    "abstract": "Collecting supporting evidence from large corpora of text (e.g., Wikipedia) is of great challenge for open-domain Question Answering (QA). Especially, for multi-hop open-domain QA, scattered evidence pieces are required to be gathered together to support the answer extraction. In this paper, we propose a new retrieval target, hop, to collect the hidden reasoning evidence from Wikipedia for complex question answering. Specifically, the hop in this paper is defined as the combination of a hyperlink and the corresponding outbound link document. The hyperlink is encoded as the mention embedding which models the structured knowledge of how the outbound link entity is mentioned in the textual context, and the corresponding outbound link document is encoded as the document embedding representing the unstructured knowledge within it. Accordingly, we build HopRetriever which retrieves hops over Wikipedia to answer complex questions. Experiments on the HotpotQA dataset demonstrate that HopRetriever outperforms previously published evidence retrieval methods by large margins. Moreover, our approach also yields quantifiable interpretations of the evidence collection process",
    "volume": "main",
    "checked": true,
    "id": "64435711f6542aa6b53e95c6e084a0ccd2ec1c16",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17569": {
    "title": "Merging Statistical Feature via Adaptive Gate for Improved Text Classification",
    "abstract": "Currently, text classification studies mainly focus on training classifiers by using textual input only, or enhancing semantic features by introducing external knowledge (e.g., hand-craft lexicons and domain knowledge). In contrast, some intrinsic statistical features of the corpus, like word frequency and distribution over labels, are not well exploited. Compared with external knowledge, the statistical features are deterministic and naturally compatible with corresponding tasks. In this paper, we propose an Adaptive Gate Network (AGN) to consolidate semantic representation with statistical features selectively. In particular, AGN encodes statistical features through a variational component and merges information via a well-designed valve mechanism. The valve adapts the information flow into the classifier according to the confidence of semantic features in decision making, which can facilitate training a robust classifier and can address the overfitting caused by using statistical features. Extensive experiments on datasets of various scales show that, by incorporating statistical information, AGN can improve the classification performance of CNN, RNN, Transformer, and Bert based models effectively. The experiments also indicate the robustness of AGN against adversarial attacks of manipulating statistical information",
    "volume": "main",
    "checked": true,
    "id": "31948894774ee1e14ca4db9a2deffc53793a4d7f",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17570": {
    "title": "TSQA: Tabular Scenario Based Question Answering",
    "abstract": "Scenario-based question answering (SQA) has attracted an increasing research interest. Compared with the well-studied machine reading comprehension (MRC), SQA is a more challenging task: a scenario may contain not only a textual passage to read but also structured data like tables, i.e., tabular scenario based question answering (TSQA). AI applications of TSQA such as answering multiple-choice questions in high-school exams require synthesizing data in multiple cells and combining tables with texts and domain knowledge to infer answers. To support the study of this task, we construct GeoTSQA. This dataset contains 1k real questions contextualized by tabular scenarios in the geography domain. To solve the task, we extend state-of-the-art MRC methods with TTGen, a novel table-to-text generator. It generates sentences from variously synthesized tabular data and feeds the downstream MRC method with the most useful sentences. Its sentence ranking model fuses the information in the scenario, question, and domain knowledge. Our approach outperforms a variety of strong baseline methods on GeoTSQA",
    "volume": "main",
    "checked": true,
    "id": "084c5afc5b16b0c50c53390f550a13f4ed4c7d3c",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17571": {
    "title": "Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous Rendering Machines",
    "abstract": "End-to-end neural networks have achieved promising performances in natural language generation (NLG). However, they are treated as black boxes and lack interpretability. To address this problem, we propose a novel framework, heterogeneous rendering machines (HRM), that interprets how neural generators render an input dialogue act (DA) into an utterance. HRM consists of a renderer set and a mode switcher. The renderer set contains multiple decoders that vary in both structure and functionality. For every generation step, the mode switcher selects an appropriate decoder from the renderer set to generate an item (a word or a phrase). To verify the effectiveness of our method, we have conducted extensive experiments on 5 benchmark datasets. In terms of automatic metrics (e.g., BLEU), our model is competitive with the current state-of-the-art method. The qualitative analysis shows that our model can interpret the rendering process of neural generators well. Human evaluation also confirms the interpretability of our proposed approach",
    "volume": "main",
    "checked": true,
    "id": "243b7fe83c29da8619548d4e8a2379accdf8334e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17572": {
    "title": "An Efficient Transformer Decoder with Compressed Sub-layers",
    "abstract": "The large attention-based encoder-decoder network (Transformer) has become prevailing recently due to its effectiveness. But the high computation complexity of its decoder raises the inefficiency issue. By examining the mathematic formulation of the decoder, we show that under some mild conditions, the architecture could be simplified by compressing its sub-layers, the basic building block of Transformer, and achieves a higher parallelism. We thereby propose Compressed Attention Network, whose decoder layer consists of only one sub-layer instead of three. Extensive experiments on 14 WMT machine translation tasks show that our model is 1.42x faster with performance on par with a strong baseline. This strong baseline is already 2x faster than the widely used standard baseline without loss in performance",
    "volume": "main",
    "checked": true,
    "id": "46cb1ec4aa7810ab89da259e96f46b5db268193b",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17573": {
    "title": "An Unsupervised Sampling Approach for Image-Sentence Matching Using Document-level Structural Information",
    "abstract": "In this paper, we focus on the problem of unsupervised image-sentence matching. Existing research explores to utilize document-level structural information to sample positive and negative instances for model training. Although the approach achieves positive results, it introduces a sampling bias and fails to distinguish instances with high semantic similarity. To alleviate the bias, we propose a new sampling strategy to select additional intra-document image-sentence pairs as positive or negative samples. Furthermore, to recognize the complex pattern in intra-document samples, we propose a Transformer based model to capture fine-grained features and implicitly construct a graph for each document, where concepts in a document are introduced to bridge the representation learning of images and sentences in the context of a document. Experimental results show the effectiveness of our approach to alleviate the bias and learn well-aligned multimodal representations",
    "volume": "main",
    "checked": true,
    "id": "a70339875036e618579e1156aa8be630364455d1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17574": {
    "title": "Finding Sparse Structures for Domain Specific Neural Machine Translation",
    "abstract": "Neural machine translation often adopts the fine-tuning approach to adapt to specific domains. However, nonrestricted fine-tuning can easily degrade on the general domain and over-fit to the target domain. To mitigate the issue, we propose Prune-Tune, a novel domain adaptation method via gradual pruning. It learns tiny domain-specific sub-networks during fine-tuning on new domains. Prune-Tune alleviates the over-fitting and the degradation problem without model modification. Furthermore, Prune-Tune is able to sequentially learn a single network with multiple disjoint domain-specific sub-networks for multiple domains. Empirical experiment results show that Prune-Tune outperforms several strong competitors in the target domain test set without sacrificing the quality on the general domain in both single and multi-domain settings. The source code and data are available at https://github.com/ohlionel/Prune-Tune",
    "volume": "main",
    "checked": true,
    "id": "e8bf6e0f1a1ea7f7d145cbe8782066a2d977d7e2",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17575": {
    "title": "Infusing Multi-Source Knowledge with Heterogeneous Graph Neural Network for Emotional Conversation Generation",
    "abstract": "The success of emotional conversation systems depends on sufficient perception and appropriate expression of emotions. In a real-world conversation, we firstly instinctively perceive emotions from multi-source information, including the emotion flow of dialogue history, facial expressions, and personalities of speakers, and then express suitable emotions according to our personalities, but these multiple types of information are insufficiently exploited in emotional conversation fields. To address this issue, we propose a heterogeneous graph-based model for emotional conversation generation. Specifically, we design a Heterogeneous Graph-Based Encoder to represent the conversation content (i.e., the dialogue history, its emotion flow, facial expressions, and speakers' personalities) with a heterogeneous graph neural network, and then predict suitable emotions for feedback. After that, we employ an Emotion-Personality-Aware Decoder to generate a response not only relevant to the conversation context but also with appropriate emotions, by taking the encoded graph representations, the predicted emotions from the encoder and the personality of the current speaker as inputs. Experimental results show that our model can effectively perceive emotions from multi-source knowledge and generate a satisfactory response, which significantly outperforms previous state-of-the-art models",
    "volume": "main",
    "checked": true,
    "id": "1ce3dcfea8ac53981085b17cc0466a1908adf6e0",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17576": {
    "title": "Hierarchical Coherence Modeling for Document Quality Assessment",
    "abstract": "Text coherence plays a key role in document quality assessment. Most existing text coherence methods only focus on similarity of adjacent sentences. However, local coherence exists in sentences with broader contexts and diverse rhetoric relations, rather than just adjacent sentences similarity. Besides, the highlevel text coherence is also an important aspect of document quality. To this end, we propose a hierarchical coherence model for document quality assessment. In our model, we implement a local attention mechanism to capture the location semantics, bilinear tensor layer for measure coherence and max-coherence pooling for acquiring high-level coherence. We evaluate the proposed method on two realistic tasks: news quality judgement and automated essay scoring. Experimental results demonstrate the validity and superiority of our work",
    "volume": "main",
    "checked": true,
    "id": "c81eeb8e657476860b1b76c0a9d0024cab61821b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17577": {
    "title": "Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation",
    "abstract": "Human doctors with well-structured medical knowledge can diagnose a disease merely via a few conversations with patients about symptoms. In contrast, existing knowledge-grounded dialogue systems often require a large number of dialogue instances to learn as they fail to capture the correlations between different diseases and neglect the diagnostic experience shared among them. To address this issue, we propose a more natural and practical paradigm, i.e., low-resource medical dialogue generation, which can transfer the diagnostic experience from source diseases to target ones with a handful of data for adaptation. It is capitalized on a commonsense knowledge graph to characterize the prior disease-symptom relations. Besides, we develop a Graph-Evolving Meta-Learning (GEML) framework that learns to evolve the commonsense graph for reasoning disease-symptom correlations in a new disease, which effectively alleviates the needs of a large number of dialogues. More importantly, by dynamically evolving disease-symptom graphs, GEML also well addresses the real-world challenges that the disease-symptom correlations of each disease may vary or evolve along with more diagnostic cases. Extensive experiment results on the CMDD dataset and our newly-collected Chunyu dataset testify the superiority of our approach over state-of-the-art approaches. Besides, our GEML can generate an enriched dialogue-sensitive knowledge graph in an online manner, which could benefit other tasks grounded on knowledge graph",
    "volume": "main",
    "checked": true,
    "id": "2ad565fb0ce9cda15a9e5ce37b5678ec09b134b9",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17578": {
    "title": "Neural Sentence Simplification with Semantic Dependency Information",
    "abstract": "Most previous works on neural sentence simplification exploit seq2seq model to rewrite a sentence without explicitly considering the semantic information of the sentence. This may lead to the semantic deviation of the simplified sentence. In this paper, we leverage semantic dependency graph to aid neural sentence simplification system. We propose a new sentence simplification model with semantic dependency information, called SDISS (as shorthand for Semantic Dependency Information guided Sentence Simplification), which incorporates semantic dependency graph to guide sentence simplification. We evaluate SDISS on three benchmark datasets and it outperforms a number of strong baseline models on the SARI and FKGL metrics. Human evaluation also shows SDISS can produce simplified sentences with better quality",
    "volume": "main",
    "checked": true,
    "id": "0abe0db154f1ce1aea45cbf75f3a36229fff1cba",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17579": {
    "title": "Converse, Focus and Guess - Towards Multi-Document Driven Dialogue",
    "abstract": "We propose a novel task, Multi-Document Driven Dialogue (MD3), in which an agent can guess the target document that the user is interested in by leading a dialogue. To benchmark progress, we introduce a new dataset of GuessMovie, which contains 16,881 documents, each describing a movie, and associated 13,434 dialogues. Further, we propose the MD3 model. Keeping guessing the target document in mind, it converses with the user conditioned on both document engagement and user feedback. In order to incorporate large-scale external documents into the dialogue, it pretrains a document representation which is sensitive to attributes it talks about an object. Then it tracks dialogue state by detecting evolvement of document belief and attribute belief, and finally optimizes dialogue policy in principle of entropy decreasing and reward increasing, which is expected to successfully guess the user's target in a minimum number of turns. Experiments show that our method significantly outperforms several strong baseline methods and is very close to human's performance",
    "volume": "main",
    "checked": true,
    "id": "76cb4a8e7d5340213297945793367a543d6e55b5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17580": {
    "title": "Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts",
    "abstract": "Natural language inference (NLI) is a fundamental NLP task, investigating the entailment relationship between two texts. Popular NLI datasets present the task at sentence-level. While adequate for testing semantic representations, they fall short for testing contextual reasoning over long texts, which is a natural part of the human inference process. We introduce ConTRoL, a new dataset for ConTextual Reasoning over Long texts. Consisting of 8,325 expert-designed \"context-hypothesis\" pairs with gold labels, ConTRoL is a passage-level NLI dataset with a focus on complex contextual reasoning types such as logical reasoning. It is derived from competitive selection and recruitment test (verbal reasoning test) for police recruitment, with expert level quality. Compared with previous NLI benchmarks, the materials in ConTRoL are much more challenging, involving a range of reasoning types. Empirical results show that state-of-the-art language models perform by far worse than educated humans. Our dataset can also serve as a testing-set for downstream tasks like checking the factual correctness of summaries",
    "volume": "main",
    "checked": true,
    "id": "ffbfce72f12aa0be619be5e49698c2657853409f",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17581": {
    "title": "How to Train Your Agent to Read and Write",
    "abstract": "Reading and writing research papers is one of the most privileged abilities that a qualified researcher should master. However, it is difficult for new researchers (e.g., students) to fully grasp this ability. It would be fascinating if we could train an intelligent agent to help people read and summarize papers, and perhaps even discover and exploit the potential knowledge clues to write novel papers. Although there have been existing works focusing on summarizing (i.e., reading) the knowledge in a given text or generating (i.e., writing) a text based on the given knowledge, the ability of simultaneously reading and writing is still under development. Typically, this requires an agent to fully understand the knowledge from the given text materials and generate correct and fluent novel paragraphs, which is very challenging in practice. In this paper, we propose a Deep ReAder-Writer (DRAW) network, which consists of a Reader that can extract knowledge graphs (KGs) from input paragraphs and discover potential knowledge,  a graph-to-text Writer that generates a novel paragraph, and a Reviewer that reviews the generated paragraph from three different aspects. Extensive experiments show that our DRAW network outperforms considered baselines and several state-of-the-art methods on AGENDA and M-AGENDA datasets. Our code and supplementary are released at https://github.com/menggehe/DRAW",
    "volume": "main",
    "checked": true,
    "id": "eae436d899684f2885af7bc68926d490190b6dde",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17582": {
    "title": "Filling the Gap of Utterance-aware and Speaker-aware Representation for Multi-turn Dialogue",
    "abstract": "A multi-turn dialogue is composed of multiple utterances from two or more different speaker roles. Thus utterance- and speaker-aware clues are supposed to be well captured in models. However, in the existing retrieval-based multi-turn dialogue modeling, the pre-trained language models (PrLMs) as encoder represent the dialogues coarsely by taking the pairwise dialogue history and candidate response as a whole, the hierarchical information on either utterance interrelation or speaker roles coupled in such representations is not well addressed. In this work, we propose a novel model to fill such a gap by modeling the effective utterance-aware and speaker-aware representations entailed in a dialogue history. In detail, we decouple the contextualized word representations by masking mechanisms in Transformer-based PrLM, making each word only focus on the words in current utterance, other utterances, two speaker roles (i.e., utterances of sender and utterances of receiver), respectively. Experimental results show that our method boosts the strong ELECTRA baseline substantially in four public benchmark datasets, and achieves various new state-of-the-art performance over previous methods. A series of ablation studies are conducted to demonstrate the effectiveness of our method",
    "volume": "main",
    "checked": true,
    "id": "8f088ede342f2aaaf6de553f4eb741f1585c60c3",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17583": {
    "title": "Towards Faithfulness in Open Domain Table-to-text Generation from an Entity-centric View",
    "abstract": "In open domain table-to-text generation, we notice the unfaithful generation usually contains hallucinated entities which can not be aligned to any input table record. We thus try to evaluate the generation faithfulness with two entity-centric metrics: table record coverage and the ratio of hallucinated entities in text, both of which are shown to have strong agreement with human judgements. Then based on these metrics, we quantitatively analyze the correlation between training data quality and generation fidelity which indicates the potential usage of entity information in faithful generation. Motivated by these findings, we propose two methods for faithful generation: 1) augmented training by incorporating the auxiliary entity information, including both an augmented plan-based model and an unsupervised model and 2) training instance selection based on faithfulness ranking. We show these approaches improve generation fidelity in both full dataset setting and few shot setting by both automatic and human evaluations",
    "volume": "main",
    "checked": true,
    "id": "a8a1ec9fd1ac1a36a256f6b752e21fc2c844cc9c",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17584": {
    "title": "Faster Depth-Adaptive Transformers",
    "abstract": "Depth-adaptive neural networks can dynamically adjust depths according to the hardness of input words, and thus improve efficiency. The main challenge is how to measure such hardness and decide the required depths (i.e., layers) to conduct. Previous works generally build a halting unit to decide whether the computation should continue or stop at each layer. As there is no specific supervision of depth selection, the halting unit may be under-optimized and inaccurate, which results in suboptimal and unstable performance when modeling sentences. In this paper, we get rid of the halting unit and estimate the required depths in advance, which yields a faster depth-adaptive model. Specifically, two approaches are proposed to explicitly measure the hardness of input words and estimate corresponding adaptive depth, namely 1) mutual information (MI) based estimation and 2) reconstruction loss based estimation. We conduct experiments on the text classification task with 24 datasets in various sizes and domains. Results confirm that our approaches can speed up the vanilla Transformer (up to 7x) while preserving high accuracy. Moreover, efficiency and robustness are significantly improved when compared with other depth-adaptive approaches",
    "volume": "main",
    "checked": true,
    "id": "3e4d4963753f8f1b730bb02eb6cd10aaa83ec4a1",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17585": {
    "title": "A Graph Reasoning Network for Multi-turn Response Selection via Customized Pre-training",
    "abstract": "We investigate response selection for multi-turn conversation in retrieval-based chatbots. Existing studies pay more attention to the matching between utterances and responses by calculating the matching score based on learned features, leading to insufficient model reasoning ability. In this paper, we propose a graph- reasoning network (GRN) to address the problem. GRN first conducts pre-training based on ALBERT using next utterance prediction and utterance order prediction tasks specifically devised for response selection. These two customized pre-training tasks can endow our model with the ability of capturing semantical and chronological dependency between utterances. We then fine-tune the model on an integrated network with sequence reasoning and graph reasoning structures. The sequence reasoning module conducts inference based on the highly summarized context vector of utterance-response pairs from the global perspective. The graph reasoning module conducts the reasoning on the utterance-level graph neural network from the local perspective. Experiments on two conversational reasoning datasets show that our model can dramatically outperform the strong baseline methods and can achieve performance which is close to human-level",
    "volume": "main",
    "checked": true,
    "id": "9698cff93ec15e4c92b1fccb2332673ef4074899",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17586": {
    "title": "Generating CCG Categories",
    "abstract": "Previous CCG supertaggers usually predict categories using multi-class classification. Despite their simplicity, internal structures of categories are usually ignored. The rich semantics inside these structures may help us to better handle relations among categories and bring more robustness into existing supertaggers. In this work, we propose to generate categories rather than classify them: each category is decomposed into a sequence of smaller atomic tags, and the tagger aims to generate the correct sequence. We show that with this finer view on categories, annotations of different categories could be shared and interactions with sentence contexts could be enhanced. The proposed category generator is able to achieve state-of-the-art tagging (95.5% accuracy) and parsing (89.8% labeled F1) performances on the standard CCGBank . Further-more, its performances on infrequent (even unseen) categories, out-of-domain texts and low resource language give promising results on introducing generation models to the general CCG analyses",
    "volume": "main",
    "checked": true,
    "id": "38cda3ad2e846c89e8972e8bc637741775499dd3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17587": {
    "title": "CrossNER: Evaluating Cross-Domain Named Entity Recognition",
    "abstract": "Cross-domain named entity recognition (NER) models are able to cope with the scarcity issue of NER samples in target domains. However, most of the existing NER benchmarks lack domain-specialized entity types or do not focus on a certain domain, leading to a less effective cross-domain evaluation. To address these obstacles, we introduce a cross-domain NER dataset (CrossNER), a fully-labeled collection of NER data spanning over five diverse domains with specialized entity categories for different domains. Additionally, we also provide a domain-related corpus since using it to continue pre-training language models (domain-adaptive pre-training) is effective for the domain adaptation. We then conduct comprehensive experiments to explore the effectiveness of leveraging different levels of the domain corpus and pre-training strategies to do domain-adaptive pre-training for the cross-domain task. Results show that focusing on the fractional corpus containing domain-specialized entities and utilizing a more challenging pre-training strategy in domain-adaptive pre-training are beneficial for the NER domain adaptation, and our proposed method can consistently outperform existing cross-domain NER baselines. Nevertheless, experiments also illustrate the challenge of this cross-domain NER task. We hope that our dataset and baselines will catalyze research in the NER domain adaptation area. The code and data are available at https://github.com/zliucr/CrossNER",
    "volume": "main",
    "checked": true,
    "id": "5cb87cd3b1feb8f39e565b1d054d37a3cf38b66c",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17588": {
    "title": "On the Importance of Word Order Information in Cross-lingual Sequence Labeling",
    "abstract": "Cross-lingual models trained on source language tasks possess the capability to directly transfer to target languages. However, since word order variances generally exist in different languages, cross-lingual models that overfit into the word order of the source language could have sub-optimal performance in target languages. In this paper, we hypothesize that reducing the word order information fitted into the models can improve the adaptation performance in target languages. To verify this hypothesis, we introduce several methods to make models encode less word order information of the source language and test them based on cross-lingual word embeddings and the pre-trained multilingual model. Experimental results on three sequence labeling tasks (i.e., part-of-speech tagging, named entity recognition and slot filling tasks) show that reducing word order information injected into the model can achieve better zero-shot cross-lingual performance. Further analysis illustrates that fitting excessive or insufficient word order information into the model results in inferior cross-lingual performance. Moreover, our proposed methods can also be applied to strong cross-lingual models and further improve their performance",
    "volume": "main",
    "checked": true,
    "id": "12cf222b05755a59655a5846f990c2aaf6065086",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17589": {
    "title": "SCRUPLES: A Corpus of Community Ethical Judgments on 32,000 Real-Life Anecdotes",
    "abstract": "As AI systems become an increasing part of people's everyday lives, it becomes ever more important that they understand people's ethical norms. Motivated by descriptive ethics, a field of study that focuses on people's descriptive judgments rather than theoretical prescriptions on morality, we investigate a novel, data-driven approach to machine ethics. We introduce SCRUPLES, the first large-scale dataset with 625,000 ethical judgments over 32,000 real-life anecdotes. Each anecdote recounts a complex ethical situation, often posing moral dilemmas, paired with a distribution of judgments contributed by the community members. Our dataset presents a major challenge to state-of-the-art neural language models, leaving significant room for improvement. However, when presented with simplified moral situations, the results are considerably more promising, suggesting that neural models can effectively learn simpler ethical building blocks. A key take-away of our empirical analysis is that norms are not always clean-cut; many situations are naturally divisive. We present a new method to estimate the best possible performance on such tasks with inherently diverse label distributions, and explore likelihood functions that separate intrinsic from model uncertainty. Data and code are available at https://github.com/allenai/scruples",
    "volume": "main",
    "checked": true,
    "id": "090648f65354977762a4624559e7f7b52ae17f58",
    "citation_count": 40
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17590": {
    "title": "UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark",
    "abstract": "Commonsense AI has long been seen as a near impossible goal---until recently. Now, research interest has sharply increased with an influx of new benchmarks and models. We propose two new ways to evaluate commonsense models, emphasizing their generality on new tasks and building on diverse, recently introduced benchmarks. First, we propose a new multitask benchmark, Rainbow, to promote research on commonsense models that generalize well over multiple tasks and datasets. Second, we propose a novel evaluation, the cost equivalent curve, that sheds new insight on how the choice of source datasets, pretrained language models, and transfer learning methods impacts performance and data efficiency. We perform extensive experiments---over 200 experiments encompassing 4800 models---and report multiple valuable and sometimes surprising findings, e.g., that transfer almost always leads to better or equivalent performance if following a particular recipe, that QA-based commonsense datasets transfer well with each other, while commonsense knowledge graphs do not, and that perhaps counter-intuitively, larger models benefit more from transfer than smaller ones. Last but not least, we introduce a new universal commonsense reasoning model, UNICORN, that establishes new state-of-the-art performance across 8 popular commonsense benchmarks, aNLI (87.3%), CosmosQA (91.8%), HellaSWAG (93.9%), PIQA (90.1%), SocialIQa (83.2%), WinoGrande (86.6%), CycIC (94.0%) and CommonsenseQA (79.3%)",
    "volume": "main",
    "checked": true,
    "id": "21ec9c0f869bdb33b06c7dbc8880169db0397d08",
    "citation_count": 61
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17591": {
    "title": "Span-Based Event Coreference Resolution",
    "abstract": "Motivated by the recent successful application of span-based models to entity-based information extraction tasks, we investigate span-based models for event coreference resolution, focusing on determining (1) whether the successes of span-based models of entity coreference can be extended to event coreference; (2) whether exploiting the dependency between event coreference and the related subtask of trigger detection; and (3) whether automatically computed entity coreference information can benefit span-based event coreference resolution. Empirical results on the standard evaluation dataset provide affirmative answers to all three questions",
    "volume": "main",
    "checked": true,
    "id": "0d7345742e4c3ac99d3dd8087861e6955392276c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17592": {
    "title": "LET: Linguistic Knowledge Enhanced Graph Transformer for Chinese Short Text Matching",
    "abstract": "Chinese short text matching is a fundamental task in natural language processing. Existing approaches usually take Chinese characters or words as input tokens. They have two limitations: 1) Some Chinese words are polysemous, and semantic information is not fully utilized. 2) Some models suffer potential issues caused by word segmentation. Here we introduce HowNet as an external knowledge base and propose a Linguistic knowledge Enhanced graph Transformer (LET) to deal with word ambiguity. Additionally, we adopt the word lattice graph as input to maintain multi-granularity information. Our model is also complementary to pre-trained language models. Experimental results on two Chinese datasets show that our models outperform various typical text matching approaches. Ablation study also indicates that both semantic information and multi-granularity information are important for text matching modeling",
    "volume": "main",
    "checked": true,
    "id": "d8e8e35bf4cf8821ade2d58b34d9ae23a9b08ab2",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17593": {
    "title": "Knowledge-driven Data Construction for Zero-shot Evaluation in Commonsense Question Answering",
    "abstract": "Recent developments in pre-trained neural language modeling have led to leaps in accuracy on common-sense question-answering benchmarks. However, there is increasing concern that models overfit to specific tasks, without learning to utilize external knowledge or perform general semantic reasoning. In contrast, zero-shot evaluations have shown promise as a more robust measure of a models general reasoning abilities. In this paper, we propose a novel neuro-symbolic framework for zero-shot question answering across commonsense tasks. Guided by a set of hypotheses, the framework studies how to transform various pre-existing knowledge resources into a form that is most effective for pre-training models. We vary the set of language models, training regimes, knowledge sources, and data generation strategies, and measure their impact across tasks. Extending on prior work, we devise and compare four constrained distractor-sampling strategies. We provide empirical results across five commonsense question-answering tasks with data generated from five external knowledge resources. We show that, while an individual knowledge graph is better suited for specific tasks, a global knowledge graph brings consistent gains across different tasks. In addition, both preserving the structure of the task as well as generating fair and informative questions help language models learn more effectively",
    "volume": "main",
    "checked": true,
    "id": "18e5fb8cec55a75b288a499c57d77ede541dc049",
    "citation_count": 38
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17594": {
    "title": "Generate Your Counterfactuals: Towards Controlled Counterfactual Generation for Text",
    "abstract": "Machine Learning has seen tremendous growth recently, which has led to a larger adaptation of ML systems for educational assessments, credit risk, healthcare, employment, criminal justice, to name a few. The trustworthiness of ML and NLP systems is a crucial aspect and requires a guarantee that the decisions they make are fair and robust. Aligned with this, we propose a novel framework GYC, to generate a set of exhaustive counterfactual text, which are crucial for testing these ML systems. Our main contributions include a) We introduce GYC, a framework to generate counterfactual samples such that the generation is plausible, diverse, goal-oriented, and effective, b) We generate counterfactual samples, that can direct the generation towards a corresponding \\texttt{condition} such as named-entity tag, semantic role label, or sentiment. Our experimental results on various domains show that GYC generates counterfactual text samples exhibiting the above four properties. GYC generates counterfactuals that can act as test cases to evaluate a model and any text debiasing algorithm",
    "volume": "main",
    "checked": true,
    "id": "03031d20494b9634b27fc5be6bce203a87383343",
    "citation_count": 36
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17595": {
    "title": "Generating Natural Language Attacks in a Hard Label Black Box Setting",
    "abstract": "We study an important and challenging task of attacking natural language processing models in a hard label black box setting. We propose a decision-based attack strategy that crafts high quality adversarial examples on text classification and entailment tasks. Our proposed attack strategy leverages population-based optimization algorithm to craft plausible and semantically similar adversarial examples by observing only the top label predicted by the target model. At each iteration, the optimization procedure allow word replacements that maximizes the overall semantic similarity between the original and the adversarial text. Further, our approach does not rely on using substitute models or any kind of training data. We demonstrate the efficacy of our proposed approach through extensive experimentation and ablation studies on five state-of-the-art target models across seven benchmark datasets. In comparison to attacks proposed in prior literature, we are able to achieve a higher success rate with lower word perturbation percentage that too in a highly restricted setting",
    "volume": "main",
    "checked": true,
    "id": "2ef79342ff22661cd7bc18833049085e6b3501c4",
    "citation_count": 34
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17596": {
    "title": "Bridging Towers of Multi-task Learning with a Gating Mechanism for Aspect-based Sentiment Analysis and Sequential Metaphor Identification",
    "abstract": "Multi-task learning (MTL) has been widely applied in Natural Language Processing. A major task and its associated auxiliary tasks share the same encoder; hence, an MTL encoder can learn the sharing abstract information between the major and auxiliary tasks. Task-specific towers are then employed upon the sharing encoder to learn task-specific information. Previous works demonstrated that exchanging information between task-specific towers yielded extra gains. This is known as soft-parameter sharing MTL. In this paper, we propose a novel gating mechanism for the bridging of MTL towers. Our method is evaluated based on aspect-based sentiment analysis and sequential metaphor identification tasks. The experiments demonstrate that our method can yield better performance than the baselines on both tasks. Based on the same Transformer backbone, we compare our gating mechanism with other information transformation mechanisms, e.g., cross-stitch, attention and vanilla gating. The experiments show that our method also surpasses these baselines",
    "volume": "main",
    "checked": true,
    "id": "ef8ebdc6892648c61c7803a99373a47d96373294",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17597": {
    "title": "A Joint Training Dual-MRC Framework for Aspect Based Sentiment Analysis",
    "abstract": "Aspect based sentiment analysis (ABSA) involves three fundamental subtasks: aspect term extraction, opinion term extraction, and aspect-level sentiment classification. Early works only focused on solving one of these subtasks individually. Some recent work focused on solving a combination of two subtasks, e.g., extracting aspect terms along with sentiment polarities or extracting the aspect and opinion terms pair-wisely. More recently, the triple extraction task has been proposed, i.e., extracting the (aspect term, opinion term, sentiment polarity) triples from a sentence. However, previous approaches fail to solve all subtasks in a unified end-to-end framework. In this paper, we propose a complete solution for ABSA. We construct two machine reading comprehension (MRC) problems, and solve all subtasks by joint training two BERT-MRC models with parameters sharing. We conduct experiments on these subtasks and results on several benchmark datasets demonstrate the effectiveness of our proposed framework, which significantly outperforms existing state-of-the-art methods",
    "volume": "main",
    "checked": true,
    "id": "0e021f936adf979f86812d67f32b090acb07d706",
    "citation_count": 53
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17598": {
    "title": "Variational Inference for Learning Representations of Natural Language Edits",
    "abstract": "Document editing has become a pervasive component of production of information, with version control systems enabling edits to be efficiently stored and applied. In light of this, the task of learning distributed representations of edits has been recently proposed. With this in mind, we propose a novel approach that employs variational inference to learn a continuous latent space of vector representations to capture the underlying semantic information with regard to the document editing process. We achieve this by introducing a latent variable to explicitly model the aforementioned features. This latent variable is then combined with a document representation to guide the generation of an edited-version of this document. Additionally, to facilitate standardized automatic evaluation of edit representations, which has heavily relied on direct human input thus far, we also propose a suite of downstream tasks, PEER, specifically designed to measure the quality of edit representations in the context of natural language processing",
    "volume": "main",
    "checked": true,
    "id": "305cee759c0f62a7568c87754e507d15922f1ade",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17599": {
    "title": "How Robust are Model Rankings : A Leaderboard Customization Approach for Equitable Evaluation",
    "abstract": "Models that top leaderboards often perform unsatisfactorily when deployed in real world applications; this has necessitated rigorous and expensive pre-deployment model testing. A hitherto unexplored facet of model performance is: Are our leaderboards doing equitable evaluation? In this paper, we introduce a task-agnostic method to probe leaderboards by weighting samples based on their 'difficulty' level. We find that leaderboards can be adversarially attacked and top performing models may not always be the best models. We subsequently propose alternate evaluation metrics. Our experiments on 10 models show changes in model ranking and an overall reduction in previously reported performance- thus rectifying the overestimation of AI systems' capabilities. Inspired by behavioral testing principles, we further develop a prototype of a visual analytics tool that enables leaderboard revamping through customization, based on an end user's focus area. This helps users analyze models' strengths and weaknesses, and guides them in the selection of a model best suited for their application scenario. In a user study, members of various commercial product development teams, covering 5 focus areas, find that our prototype reduces pre-deployment development and testing effort by 41% on average",
    "volume": "main",
    "checked": true,
    "id": "656b6de01e9d4ba7e1116bb62d32d76a89078f13",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17600": {
    "title": "Continual Learning for Named Entity Recognition",
    "abstract": "Named Entity Recognition (NER) is a vital task in various NLP applications. However, in many real-world scenarios (e.g., voice-enabled assistants) new named entities are frequently introduced, entailing re-training NER models to support these new entities. Re-annotating the original training data for the new entities could be costly or even impossible when storage limitations or security concerns restrict access to that data, and annotating a new dataset for all of the entities becomes impractical and error-prone as the number of entities increases. To tackle this problem, we introduce a novel Continual Learning approach for NER, which requires new training material to be annotated only for the new entities. To preserve the existing knowledge previously learned by the model, we exploit the Knowledge Distillation (KD) framework, where the existing NER model acts as the teacher for a new NER model (i.e., the student), which learns the new entity by using the new training material and retains knowledge of old entities by imitating the teacher's outputs on this new training set. Our experiments show that this approach allows the student model to ``progressively'' learn to identify new entities without forgetting the previously learned ones. We also present a comparison with multiple strong baselines to demonstrate that our approach is superior for continually updating an NER model",
    "volume": "main",
    "checked": true,
    "id": "f4db6705fd899eaf54f700c0bfcea8801ab52a1b",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17601": {
    "title": "MASKER: Masked Keyword Regularization for Reliable Text Classification",
    "abstract": "Pre-trained language models have achieved state-of-the-art accuracies on various text classification tasks, e.g., sentiment analysis, natural language inference, and semantic textual similarity. However, the reliability of the fine-tuned text classifiers is an often underlooked performance criterion. For instance, one may desire a model that can detect out-of-distribution (OOD) samples (drawn far from training distribution) or be robust against domain shifts. We claim that one central obstacle to the reliability is the over-reliance of the model on a limited number of keywords, instead of looking at the whole context. In particular, we find that (a) OOD samples often contain in-distribution keywords, while (b) cross-domain samples may not always contain keywords; over-relying on the keywords can be problematic for both cases. In light of this observation, we propose a simple yet effective fine-tuning method, coined masked keyword regularization (MASKER), that facilitates context-based prediction. MASKER regularizes the model to reconstruct the keywords from the rest of the words and make low-confidence predictions without enough context. When applied to various pre-trained language models (e.g., BERT, RoBERTa, and ALBERT), we demonstrate that MASKER improves OOD detection and cross-domain generalization without degrading classification accuracy. Code is available at https://github.com/alinlab/MASKER",
    "volume": "main",
    "checked": true,
    "id": "bdfe6051558414589f8b8b2e0fea596833e845bb",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17602": {
    "title": "Disentangled Motif-aware Graph Learning for Phrase Grounding",
    "abstract": "In this paper, we propose a novel graph learning framework for phrase grounding in the image. Developing from the sequential to the dense graph model, existing works capture coarse-grained context but fail to distinguish the diversity of context among phrases and image regions. In contrast, we pay special attention to different motifs implied in the context of the scene graph and devise the disentangled graph network to integrate the motif-aware contextual information into representations. Besides, we adopt interventional strategies at the feature and the structure levels to consolidate and generalize representations. Finally, the cross-modal attention network is utilized to fuse intra-modal features, where each phrase can be computed similarity with regions to select the best-grounded one. We validate the efficiency of disentangled and interventional graph network (DIGN) through a series of ablation studies, and our model achieves state-of-the-art performance on Flickr30K Entities and ReferIt Game benchmarks",
    "volume": "main",
    "checked": true,
    "id": "a83c406324897951013a4128b11b5714bef1f7c5",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17603": {
    "title": "Knowledge-aware Named Entity Recognition with Alleviating Heterogeneity",
    "abstract": "Named Entity Recognition (NER) is a fundamental and important research topic for many downstream NLP tasks, aiming at detecting and classifying named entities (NEs) mentioned in unstructured text into pre-defined categories. Learning from labeled data only is far from enough when it comes to domain-specific or temporally-evolving entities (medical terminologies or restaurant names). Luckily, open-source Knowledge Bases (KBs) (Wikidata and Freebase) contain NEs that are manually labeled with predefined types in different domains, which is potentially beneficial to identify entity boundaries and recognize entity types more accurately.   However, the type system of a domain-specific NER task is typically independent of that of current KBs and thus exhibits heterogeneity issue inevitably, which makes matching between the original NER and KB types (Person in NER potentially matches President in KBs) less likely, or introduces unintended noises without considering domain-specific knowledge (Band in NER should be mapped to Out_of_Entity_Types in the restaurant-related task). To better incorporate and denoise the abundant knowledge in KBs, we propose a new KB-aware NER framework (KaNa), which utilizes type-heterogeneous knowledge to improve NER.  Specifically, for an entity mention along with a set of candidate entities that are linked from KBs, KaNa first uses a type projection mechanism that maps the mention type and entity types into a shared space to homogenize the heterogeneous entity types. Then, based on projected types, a noise detector filters out certain less-confident candidate entities in an unsupervised manner. Finally, the filtered mention-entity pairs are injected into a NER model as a graph to predict answers. The experimental results demonstrate KaNa's state-of-the-art performance on five public benchmark datasets from different domains",
    "volume": "main",
    "checked": true,
    "id": "dcf03c80c7eeac31401f6b39dd4b3d6d025679fd",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17604": {
    "title": "Dialog Policy Learning for Joint Clarification and Active Learning Queries",
    "abstract": "Intelligent systems need to be able to recover from mistakes, resolve uncertainty, and adapt to novel concepts not seen during training. Dialog interaction can enable this by the use of clarifications for correction and resolving uncertainty, and active learning queries to learn new concepts encountered during operation. Prior work on dialog systems has either focused on exclusively learning how to perform clarification/ information seeking, or to perform active learning. In this work, we train a hierarchical dialog policy to jointly perform {\\it both} clarification and active learning in the context of an interactive language-based image retrieval task motivated by an online shopping application, and demonstrate that jointly learning dialog policies for clarification and active learning is more effective than the use of static dialog policies for one or both of these functions",
    "volume": "main",
    "checked": true,
    "id": "551b0d1933254f4f4a47fae81e4990c135ea08eb",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17605": {
    "title": "The Heads Hypothesis: A Unifying Statistical Approach Towards Understanding Multi-Headed Attention in BERT",
    "abstract": "Multi-headed attention heads are a mainstay in transformer-based models. Different methods have been proposed to classify the role of each attention head based on the relations between tokens which have high pair-wise attention. These roles include syntactic (tokens with some syntactic relation), local (nearby tokens), block (tokens in the same sentence) and delimiter (the special [CLS], [SEP] tokens). There are two main challenges with existing methods for classification: (a) there are no standard scores across studies or across functional roles, and (b) these scores are often average quantities measured across sentences without capturing statistical significance. In this work, we formalize a simple yet effective score that generalizes to all the roles of attention heads and employs hypothesis testing on this score for robust inference. This provides us the right lens to systematically analyze attention heads and confidently comment on many commonly posed questions on analyzing the BERT model. In particular, we comment on the co-location of multiple functional roles in the same attention head, the distribution of attention heads across layers, and effect of fine-tuning for specific NLP tasks on these functional roles. The code is made publicly available at https://github.com/iitmnlp/heads-hypothesis",
    "volume": "main",
    "checked": true,
    "id": "dd24067c396f4b5a6500a71101ff1dc8ccb8811f",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17606": {
    "title": "Copy That! Editing Sequences by Copying Spans",
    "abstract": "Neural sequence-to-sequence models are finding increasing use in editing of documents, for example in correcting a text document or repairing source code. In this paper, we argue that common seq2seq models (with a facility to copy single tokens) are not a natural fit for such tasks, as they have to explicitly copy each unchanged token. We present an extension of seq2seq models capable of copying entire spans of the input to the output in one step, greatly reducing the number of decisions required during inference. This extension means that there are now many ways of generating the same output, which we handle by deriving a new objective for training and a variation of beam search for inference that explicitly handles this problem. In our experiments on a range of editing tasks of natural language and source code, we show that our new model consistently outperforms simpler baselines",
    "volume": "main",
    "checked": true,
    "id": "4f985c255a4a0cf76e7bc3c4bd91f16eda0ee9c3",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17607": {
    "title": "Movie Summarization via Sparse Graph Construction",
    "abstract": "We summarize full-length movies by creating shorter videos containing their most informative scenes. We explore the hypothesis that a summary can be created by assembling scenes which are turning points (TPs), i.e., key events in a movie that describe its storyline. We propose a model that identifies TP scenes by building a sparse movie graph that represents relations between scenes and is constructed using multimodal information. According to human judges, the summaries created by our approach are more informative and complete, and receive higher ratings, than the outputs of sequence-based models and general-purpose summarization algorithms. The induced graphs are interpretable, displaying different topology for different movie genres",
    "volume": "main",
    "checked": true,
    "id": "d739bc3eafbac3304be528c706f127dda243dc9c",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17608": {
    "title": "On the Softmax Bottleneck of Recurrent Language Models",
    "abstract": "Recent research has pointed to a limitation of word-level neural language models with softmax outputs. This limitation, known as the softmax bottleneck refers to the inability of these models to produce high-rank log probability (log P) matrices. Various solutions have been proposed to break this bottleneck, including Mixture of Softmaxes, SigSoftmax, and Linear Monotonic Softmax with Piecewise Linear Increasing Functions. They were reported to offer better performance in terms of perplexity on test data. A natural perception from these results is a strong positive correlation between the rank of the log P matrix and the model's performance. In this work, we show via an extensive empirical study that such a correlation is fairly weak and that the high-rank of the log P matrix is neither necessary nor sufficient for better test perplexity. Although our results are empirical, they are established in part via the construction of a rich family of models, which we call Generalized SigSoftmax. They are able to create diverse ranks for the log P matrices. We also present an investigation as to why the proposed solutions achieve better performance",
    "volume": "main",
    "checked": true,
    "id": "e124a92d67362dc32d0518b2522f5ae96970916a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17609": {
    "title": "XL-WSD: An Extra-Large and Cross-Lingual Evaluation Framework for Word Sense Disambiguation",
    "abstract": "Transformer-based architectures brought a breeze of change to Word Sense Disambiguation (WSD), improving models' performances by a large margin.  The fast development of new approaches has been further encouraged by a well-framed evaluation suite for English, which has allowed their performances to be kept track of and compared fairly.  However, other languages have remained largely unexplored, as testing data are available for a few languages only and the evaluation setting is rather matted.  In this paper, we untangle this situation by proposing XL-WSD, a cross-lingual evaluation benchmark for the WSD task featuring sense-annotated development and test sets in 18 languages from six different linguistic families, together with language-specific silver training data.  We leverage XL-WSD datasets to conduct an extensive evaluation of neural and knowledge-based approaches, including the most recent multilingual language models.   Results show that the zero-shot knowledge transfer across languages is a promising research direction within the WSD field, especially when considering low-resourced languages where large pre-trained multilingual models still perform poorly.   We make the evaluation suite and the code for performing the experiments available at https://sapienzanlp.github.io/xl-wsd/",
    "volume": "main",
    "checked": true,
    "id": "b5b7870f1e565eaba21c056e64fcf4a279b4265b",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17610": {
    "title": "ALP-KD: Attention-Based Layer Projection for Knowledge Distillation",
    "abstract": "Knowledge distillation is considered as a training and compression strategy in which two neural networks, namely a teacher and a student, are coupled together during training. The teacher network is supposed to be a trustworthy predictor and the student tries to mimic its predictions. Usually, a student with a lighter architecture is selected so we can achieve compression and yet deliver high-quality results. In such a setting, distillation only happens for final predictions whereas the student could also benefit from teachers supervision for internal components. Motivated by this, we studied the problem of distillation for intermediate layers. Since there might not be a one-to-one alignment between student and teacher layers, existing techniques skip some teacher layers and only distill from a subset of them. This shortcoming directly impacts quality, so we instead propose a combinatorial technique which relies on attention. Our model fuses teacher-side information and takes each layers significance into consideration, then it performs distillation between combined teacher layers and those of the student. Using our technique, we distilled a 12-layer BERT (Devlin et al. 2019) into 6-, 4-, and 2-layer counterparts and evaluated them on GLUE tasks (Wang et al. 2018). Experimental results show that our combinatorial approach is able to outperform other existing techniques",
    "volume": "main",
    "checked": true,
    "id": "e339c5d31ffc7029c1f72d567ac07b4606701c72",
    "citation_count": 35
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17611": {
    "title": "Data Augmentation for Abstractive Query-Focused Multi-Document Summarization",
    "abstract": "The progress in Query-focused Multi-Document Summarization (QMDS) has been limited by the lack of sufficient largescale high-quality training datasets. We present two QMDS training datasets, which we construct using two data augmentation methods: (1) transferring the commonly used single-document CNN/Daily Mail summarization dataset to create the QMDSCNN dataset, and (2) mining search-query logs to create the QMDSIR dataset. These two datasets have complementary properties, i.e., QMDSCNN has real summaries but queries are simulated, while QMDSIR has real queries but simulated summaries. To cover both these real summary and query aspects, we build abstractive end-to-end neural network models on the combined datasets that yield new state-of-the-art transfer results on DUC datasets. We also introduce new hierarchical encoders that enable a more efficient encoding of the query together with multiple documents. Empirical results demonstrate that our data augmentation and encoding methods outperform baseline models on automatic metrics, as well as on human evaluations along multiple attributes",
    "volume": "main",
    "checked": true,
    "id": "161321ef451d658d66b762cba5c202b12260220e",
    "citation_count": 23
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17612": {
    "title": "Revisiting Mahalanobis Distance for Transformer-Based Out-of-Domain Detection",
    "abstract": "Real-life applications, heavily relying on machine learning, such as dialog systems, demand for out-of-domain detection methods. Intent classification models should be equipped with a mechanism to distinguish seen intents from unseen ones so that the dialog agent is capable of rejecting the latter and avoiding undesired behavior. However, despite increasing attention paid to the task, the best practices for out-of-domain intent detection have not yet been fully established.  This paper conducts a thorough comparison of out-of-domain intent detection methods. We prioritize the methods, not requiring access to out-of-domain data during training, gathering of which is extremely time- and labor-consuming due to lexical and stylistic variation of user utterances. We evaluate multiple contextual encoders and methods, proven to be efficient, on three common datasets for intent classification, expanded with out-of-domain utterances. Our main findings show that fine-tuning Transformer-based encoders on in-domain data leads to superior results. Mahalanobis distance, together with utterance representations, derived from Transformer-based encoders, outperform other methods by a wide margin(1-5% in  terms of AUROC) and establish new state-of-the-art results for all datasets.  The broader analysis shows that the reason for success lies in the fact that the fine-tuned Transformer is capable of constructing homogeneous representations of in-domain utterances, revealing geometrical disparity to out of domain utterances. In turn, the Mahalanobis distance captures this disparity easily",
    "volume": "main",
    "checked": true,
    "id": "9de3e6f471552fade7e17daa9f15df4eb92410af",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17613": {
    "title": "Conceptualized and Contextualized Gaussian Embedding",
    "abstract": "Word embedding can represent a word as a point vector or a Gaussian distribution in high-dimensional spaces. Gaussian distribution is innately more expressive than point vector owing to the ability to additionally capture semantic uncertainties of words, and thus can express asymmetric relations among words more naturally (e.g., animal entails cat but not the reverse. However, previous Gaussian embedders neglect inner-word conceptual knowledge and lack tailored Gaussian contextualizer, leading to inferior performance on both intrinsic (context-agnostic) and extrinsic (context-sensitive) tasks. In this paper, we first propose a novel Gaussian embedder which explicitly accounts for inner-word conceptual units (sememes) to represent word semantics more precisely; during learning, we propose Gaussian Distribution Attention over Gaussian representations to adaptively aggregate multiple sememe distributions into a word distribution, which guarantees the Gaussian linear combination property. Additionally, we propose a Gaussian contextualizer to utilize outer-word contexts in a sentence, producing contextualized Gaussian representations for context-sensitive tasks. Extensive experiments on intrinsic and extrinsic tasks demonstrate the effectiveness of the proposed approach, achieving state-of-the-art performance with near 5.00% relative improvement",
    "volume": "main",
    "checked": true,
    "id": "c0977178c19a2c0f56ae06f3bb89cd24a62daf05",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17614": {
    "title": "A Student-Teacher Architecture for Dialog Domain Adaptation Under the Meta-Learning Setting",
    "abstract": "Numerous new dialog domains are being created every day while collecting data for these domains is extremely costly since it involves human interactions. Therefore, it is essential to develop algorithms that can adapt to different domains efficiently when building data-driven dialog models. Most recent research on domain adaption focuses on giving the model a better initialization, rather than optimizing the adaptation process. We propose an efficient domain adaptive task-oriented dialog system model, which incorporates a meta-teacher model to emphasize the different impacts between generated tokens with respect to the context. We first train our base dialog model and meta-teacher model adversarially in a meta-learning setting on rich-resource domains. The meta-teacher learns to quantify the importance of tokens under different contexts across different domains. During adaptation, the meta-teacher guides the dialog model to focus on important tokens in order to achieve better adaptation efficiency. We evaluate our model on two multi-domain datasets, MultiWOZ and Google Schema-Guided Dialogue, and achieve state-of-the-art performance",
    "volume": "main",
    "checked": true,
    "id": "f6a8e04e49c2672fe35b2ab99d01445a4c846001",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17615": {
    "title": "Exploring Auxiliary Reasoning Tasks for Task-oriented Dialog Systems with Meta Cooperative Learning",
    "abstract": "In this paper, we propose a Meta Cooperative Learning (MCL) framework for task-oriented dialog systems (TDSs). Our model consists of an auxiliary KB reasoning task for learning meta KB knowledge, an auxiliary dialogue reasoning task for learning dialogue patterns, and a TDS task (primary task) that aims at not only retrieving accurate entities from KB but also generating natural responses, which are coordinated to achieve collective success in both retrieving accurate KB entities and generating human-like responses via meta learning. Concretely, the dialog generation model amalgamates complementary meta KB and dialog knowledge from two novel auxiliary reasoning tasks that together provide integrated guidance to build a high-quality TDS by adding regularization terms to force primary network to produce similar results to auxiliary networks. While MCL automatically learns appropriate labels for the two auxiliary reasoning tasks from the primary task, without requiring access to any further data. The key idea behind MCL is to use the performance of the primary task, which is trained alongside the auxiliary tasks in one iteration, to improve the auxiliary labels for the next iteration with meta learning. Experimental results on three benchmark datasets show that MCL can generate higher quality responses compared to several strong baselines in terms of both automatic and human evaluations. Code to reproduce the results in this paper is available at: https://github.com/siat-nlp/MCL",
    "volume": "main",
    "checked": true,
    "id": "657edcb784fb9732d53ffd925adb0a41d62aa48b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17616": {
    "title": "Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act Recognition and Sentiment Classification",
    "abstract": "In a dialog system, dialog act recognition and sentiment classification are two correlative tasks to capture speakers intentions, where dialog act and sentiment can indicate the explicit and the implicit intentions separately. The dialog context information (contextual information) and the mutual interaction information are two key factors that contribute to the two related tasks. Unfortunately, none of the existing approaches consider the two important sources of information simultaneously. In this paper, we propose a Co-Interactive Graph Attention Network (Co-GAT) to jointly perform the two tasks. The core module is a proposed co-interactive graph interaction layer where a cross-utterances connection and a cross-tasks connection are constructed and iteratively updated with each other, achieving to consider the two types of information simultaneously. Experimental results on two public datasets show that our model successfully captures the two sources of information and achieve the state-of-the-art performance. In addition, we find that the contributions from the contextual and mutual interaction information do not fully overlap with contextualized word representations (BERT, Roberta, XLNet)",
    "volume": "main",
    "checked": true,
    "id": "af574bff0e9ffd71b0708a22b135012442e33b8d",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17617": {
    "title": "Reinforced History Backtracking for Conversational Question Answering",
    "abstract": "To model the context history in multi-turn conversations has become a critical step towards a better understanding of the user query in question answering systems. To utilize the context history, most existing studies treat the whole context as input, which will inevitably face the following two challenges. First, modeling a long history can be costly as it requires more computation resources. Second, the long context history consists of a lot of irrelevant information that makes it difficult to model appropriate information relevant to the user query. To alleviate these problems, we propose a reinforcement learning based method to capture and backtrack the related conversation history to boost model performance in this paper. Our method seeks to automatically backtrack the history information with the implicit feedback from the model performance. We further consider both immediate and delayed rewards to guide the reinforced backtracking policy. Extensive experiments on a large conversational question answering dataset show that the proposed method can help to alleviate the problems arising from longer context history. Meanwhile, experiments show that the method yields better performance than other strong baselines, and the actions made by the method are insightful",
    "volume": "main",
    "checked": true,
    "id": "e45404a1787b4633058bd53d318ac9b18c7b5d8d",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17618": {
    "title": "Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information",
    "abstract": "Non-autoregressive neural machine translation (NAT) generates each target word in parallel and has achieved promising inference acceleration. However, existing NAT models still have a big gap in translation quality compared to autoregressive neural machine translation models due to the multimodality problem: the target words may come from multiple feasible translations. To address this problem, we propose a novel NAT framework ReorderNAT which explicitly models the reordering information to guide the decoding of NAT. Specially, ReorderNAT utilizes deterministic and non-deterministic decoding strategies that leverage reordering information as a proxy for the final translation to encourage the decoder to choose words belonging to the same translation. Experimental results on various widely-used datasets show that our proposed model achieves better performance compared to most existing NAT models, and even achieves comparable translation quality as autoregressive translation models with a significant speedup",
    "volume": "main",
    "checked": true,
    "id": "0174a1619b23fd74e6295be4d6231a45c0858f08",
    "citation_count": 42
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17619": {
    "title": "Towards Semantics-Enhanced Pre-Training: Can Lexicon Definitions Help Learning Sentence Meanings?",
    "abstract": "Self-supervised pre-training techniques, albeit relying on large amounts of text, have enabled rapid growth in learning language representations for natural language understanding. However, as radically empirical models on sentences, they are subject to the input data distribution, inevitably incorporating data bias and reporting bias, which may lead to inaccurate understanding of sentences. To address this problem, we propose to adopt a human learner's approach: when we cannot make sense of a word in a sentence, we often consult the dictionary for specific meanings; but can the same work for empirical models? In this work, we try to inform the pre-trained masked language models of word meanings for semantics-enhanced pre-training. To achieve a contrastive and holistic view of word meanings, a definition pair of two related words is presented to the masked language model such that the model can better associate a word with its crucial semantic features. Both intrinsic and extrinsic evaluations validate the proposed approach on semantics-orientated tasks, with an almost negligible increase of training data",
    "volume": "main",
    "checked": true,
    "id": "50d30457635943b0c54a2d2fa3aba2635cd44f03",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17620": {
    "title": "Automated Cross-prompt Scoring of Essay Traits",
    "abstract": "The majority of current research in Automated Essay Scoring (AES) focuses on prompt-specific scoring of either the overall quality of an essay or the quality with regards to certain traits. In real-world applications obtaining labelled data for a target essay prompt is often expensive or unfeasible, requiring the AES system to be able to perform well when predicting scores for essays from unseen prompts. As a result, some recent research has been dedicated to cross-prompt AES. However, this line of research has thus far only been concerned with holistic, overall scoring, with no exploration into the scoring of different traits. As users of AES systems often require feedback with regards to different aspects of their writing, trait scoring is a necessary component of an effective AES system. Therefore, to address this need, we introduce a new task named Automated Cross-prompt Scoring of Essay Traits, which requires the model to be trained solely on non-target-prompt essays and to predict the holistic, overall score as well as scores for a number of specific traits for target-prompt essays. This task challenges the model's ability to generalize in order to score essays from a novel domain as well as its ability to represent the quality of essays from multiple different aspects. In addition, we introduce a new, innovative approach which builds on top of a state-of-the-art method for cross-prompt AES. Our method utilizes a trait-attention mechanism and a multi-task architecture that leverages the relationships between each trait to simultaneously predict the overall score and the score of each individual trait. We conduct extensive experiments on the widely used ASAP and ASAP++ datasets and demonstrate that our approach is able to outperform leading prompt-specific trait scoring and cross-prompt AES methods",
    "volume": "main",
    "checked": true,
    "id": "9cc42b014e7204187f802199e1bbb63ea021c1a2",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17621": {
    "title": "Exploring Transfer Learning For End-to-End Spoken Language Understanding",
    "abstract": "Voice Assistants such as Alexa, Siri, and Google Assistant typically use a two-stage Spoken Language Understanding pipeline; first, an Automatic Speech Recognition (ASR) component to process customer speech and generate text transcriptions, followed by a Natural Language Understanding (NLU) component to map transcriptions to an actionable hypothesis. An end-to-end (E2E) system that goes directly from speech to a hypothesis is a more attractive option. These systems were shown to be smaller, faster, and better optimized. However, they require massive amounts of end-to-end training data and in addition, don't take advantage of the already available ASR and NLU training data. In this work, we propose an E2E system that is designed to jointly train on multiple speech-to-text tasks, such as ASR (speech-transcription) and SLU (speech-hypothesis), and text-to-text tasks, such as NLU (text-hypothesis). We call this the Audio-Text All-Task (AT-AT) Model and we show that it beats the performance of E2E models trained on individual tasks, especially ones trained on limited data. We show this result on an internal music dataset and two public datasets, FluentSpeech and SNIPS Audio, where we achieve state-of-the-art results. Since our model can process both speech and text input sequences and learn to predict a target sequence, it also allows us to do zero-shot E2E SLU by training on only text-hypothesis data (without any speech) from a new domain. We evaluate this ability of our model on the Facebook TOP dataset and set a new benchmark for zeroshot E2E performance. We release the audio data collected for the TOP dataset for future research",
    "volume": "main",
    "checked": true,
    "id": "95b650f03b0cee507f6bf53f77d81b77bbc06c36",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17622": {
    "title": "Semantics Altering Modifications for Evaluating Comprehension in Machine Reading",
    "abstract": "Advances in NLP have yielded impressive results for the task of machine reading comprehension (MRC), with approaches having been reported to achieve performance comparable to that of humans. In this paper, we investigate whether state-of-the-art MRC models are able to correctly process Semantics Altering Modifications (SAM): linguistically-motivated phenomena that alter the semantics of a sentence while preserving most of its lexical surface form. We present a method to automatically generate and align challenge sets featuring original and altered examples. We further propose a novel evaluation methodology to correctly assess the capability of MRC systems to process these examples independent of the data they were optimised on, by discounting for effects introduced by domain shift. In a large-scale empirical study, we apply the methodology in order to evaluate extractive MRC models with regard to their capability to correctly process SAM-enriched data. We comprehensively cover 12 different state-of-the-art neural architecture configurations and four training datasets and find that -- despite their well-known remarkable performance -- optimised models consistently struggle to correctly process semantically altered data",
    "volume": "main",
    "checked": true,
    "id": "8c48d08285b78d365741d894aab3bdb2b5ee5dfe",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17623": {
    "title": "Learning from the Best: Rationalizing Predictions by Adversarial Information Calibration",
    "abstract": "Explaining the predictions of AI models is paramount in safety-critical applications, such as in legal or medical domains.  One form of explanation for a prediction is an extractive rationale, i.e., a subset of features of an instance that lead the model to give its prediction on the instance. Previous works on generating extractive rationales usually employ a two-phase model: a selector that selects the most important features (i.e., the rationale) followed by a predictor that makes the prediction based exclusively on the selected features. One disadvantage of these works is that the main signal for learning to select features comes from the comparison of the final answers given by the predictor and the ground-truth answers. In this work, we propose to squeeze more information from the predictor via an information calibration method. More precisely, we train two models jointly: one is a typical neural model that solves the task at hand in an accurate but black-box manner, and the other is a selector-predictor model that additionally produces a rationale for its prediction. The first model is used as a guide to the second model. We use an adversarial-based technique to calibrate the information extracted by the two models such that the difference between them is an indicator of the missed or over-selected features. In addition, for natural language tasks, we propose to use a language-model-based regularizer to encourage the extraction of fluent rationales. Experimental results on a sentiment analysis task as well as on three tasks from the legal domain show the effectiveness of our approach to rationale extraction",
    "volume": "main",
    "checked": true,
    "id": "54c7c7ff7c5ff51f659ad6ad747d505f7d922e0b",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17624": {
    "title": "Nutri-bullets: Summarizing Health Studies by Composing Segments",
    "abstract": "We introduce Nutri-bullets, a multi-document summarization task for health and nutrition. First, we present two datasets of food and health summaries from multiple scientific studies. Furthermore, we propose a novel extract-compose model to solve the problem in the regime of limited parallel data. We explicitly select key spans from several abstracts using a policy network, followed by composing the selected spans to present a summary via a task specific language model. Compared to state-of-the-art methods, our approach leads to more faithful, relevant and diverse summarization -- properties imperative to this application. For instance, on the BreastCancer dataset our approach gets a more than 50% improvement on relevance and faithfulness",
    "volume": "main",
    "checked": true,
    "id": "e52bf4b4f7d5832abe6436441280a27eea7308ed",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17625": {
    "title": "DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition",
    "abstract": "This paper presents our pioneering effort for emotion recognition in conversation (ERC) with pre-trained language models. Unlike regular documents, conversational utterances appear alternately from different parties and are usually organized as hierarchical structures in previous work. Such structures are not conducive to the application of pre-trained language models such as XLNet. To address this issue, we propose an all-in-one XLNet model, namely DialogXL, with enhanced memory to store longer historical context and dialog-aware self-attention to deal with the multi-party structures. Specifically, we first modify the recurrence mechanism of XLNet from segment-level to utterance-level in order to better model the conversational data. Second, we introduce dialog-aware self-attention in replacement of the vanilla self-attention in XLNet to capture useful intra- and inter-speaker dependencies. Extensive experiments are conducted on four ERC benchmarks with mainstream models presented for comparison. The experimental results show that the proposed model outperforms the baselines on all the datasets. Several other experiments such as ablation study and error analysis are also conducted and the results confirm the role of the critical modules of DialogXL",
    "volume": "main",
    "checked": true,
    "id": "bed629bc6ed311418dc8b870a1ee2b79576066b2",
    "citation_count": 47
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17626": {
    "title": "SongMASS: Automatic Song Writing with Pre-training and Alignment Constraint",
    "abstract": "Automatic song writing aims to compose a song (lyric and/or melody) by machine, which is an interesting topic in both academia and industry. In automatic song writing, lyric-to-melody generation and melody-to-lyric generation are two important tasks, both of which usually suffer from the following challenges: 1) the paired lyric and melody data are limited, which affects the generation quality of the two tasks, considering a lot of paired training data are needed due to the weak correlation between lyric and melody; 2) Strict alignments are required between lyric and melody, which relies on specific alignment modeling. In this paper, we propose SongMASS to address the above challenges, which leverages masked sequence to sequence (MASS) pre-training and attention based alignment modeling for lyric-to-melody and melody-to-lyric generation. Specifically, 1) we extend the original sentence-level MASS pre-training to song level to better capture long contextual information in music, and use a separate encoder and decoder for each modality (lyric or melody); 2) we leverage sentence-level attention mask and token-level attention constraint during training to enhance the alignment between lyric and melody. During inference, we use a dynamic programming strategy to obtain the alignment between each word/syllable in lyric and note in melody. We pre-train SongMASS on unpaired lyric and melody datasets, and both objective and subjective evaluations demonstrate that SongMASS generates lyric and melody with significantly better quality than the baseline method",
    "volume": "main",
    "checked": true,
    "id": "dc16126c479b8414fa9683709736865485597107",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17627": {
    "title": "Learning Contextual Representations for Semantic Parsing with Generation-Augmented Pre-Training",
    "abstract": "Most recently, there has been significant interest in learning contextual representations for various NLP tasks, by leveraging large scale text corpora to train powerful language models with self-supervised learning objectives, such as Masked Language Model (MLM). Based on a pilot study, we observe three issues of existing general-purpose language models when they are applied in the text-to-SQL semantic parsers: fail to detect the column mentions in the utterances, to infer the column mentions from the cell values, and to compose target SQL queries when they are complex. To mitigate these issues, we present a model pretraining framework, Generation-Augmented Pre-training (GAP), that jointly learns representations of natural language utterance and table schemas, by leveraging generation models to generate high-quality pre-train data. GAP Model is trained on 2 million utterance-schema pairs and 30K utterance-schema-SQL triples, whose utterances are generated by generation models. Based on experimental results, neural semantic parsers that leverage GAP Model as a representation encoder obtain new state-of-the-art results on both Spider and Criteria-to-SQL benchmarks",
    "volume": "main",
    "checked": true,
    "id": "c75a2ee17056d2b8c14ac25f9f328a09eb4cf040",
    "citation_count": 50
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17628": {
    "title": "A Simple and Effective Self-Supervised Contrastive Learning Framework for Aspect Detection",
    "abstract": "Unsupervised aspect detection (UAD) aims at automatically extracting interpretable aspects and identifying aspect-specific segments (such as sentences) from online reviews. However, recent deep learning based topic models, specifically aspect-based autoencoder, suffer from several problems such as extracting noisy aspects and poorly mapping aspects discovered by models to the aspects of interest. To tackle these challenges, in this paper, we first propose a self-supervised contrastive learning framework and an attention-based model equipped with a novel smooth self-attention (SSA) module for the UAD task in order to learn better representations for aspects and review segments. Secondly, we introduce a high-resolution selective mapping (HRSMap) method to efficiently assign aspects discovered by the model to the aspects of interest. We also propose using a knowledge distillation technique to further improve the aspect detection performance. Our methods outperform several recent unsupervised and weakly supervised approaches on publicly available benchmark user review datasets. Aspect interpretation results show that extracted aspects are meaningful, have a good coverage, and can be easily mapped to aspects of interest. Ablation studies and attention weight visualization also demonstrate effectiveness of SSA and the knowledge distillation method",
    "volume": "main",
    "checked": true,
    "id": "6a10bba32185c1fa11ebc29ef7a3a814198c2b6c",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17629": {
    "title": "Fact-Enhanced Synthetic News Generation",
    "abstract": "The advanced text generation methods have witnessed great success in text summarization, language translation, and synthetic news generation. However, these techniques can be abused to generate disinformation and fake news. To better understand the potential threats of synthetic news, we develop a novel generation method FACTGEN to generate high-quality news content. The majority of existing text generation methods either afford limited supplementary information or lose consistency between the input and output which makes the synthetic news less trustworthy. To address these issues, FACTGEN retrieves external facts to enrich the output and reconstructs the input claim from the generated content to improve the consistency among the input and the output. Experiment results on real-world datasets demonstrate that the generated news contents of FACTGEN are consistent and contain rich facts. We also discuss an effective defending technique to identify these synthetic news pieces if FACTGEN was used to generate fake news",
    "volume": "main",
    "checked": true,
    "id": "5a36dc9dcb2db5e819c0d433efa5bb670f385266",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17630": {
    "title": "Improving Commonsense Causal Reasoning by Adversarial Training and Data Augmentation",
    "abstract": "Determining the plausibility of causal relations between clauses is a commonsense reasoning task that requires complex inference ability. The general approach to this task is to train a large pretrained language model on a specific dataset. However, the available training data for the task is often scarce, which leads to instability of model training or reliance on the shallow features of the dataset. This paper presents a number of techniques for making models more robust in the domain of causal reasoning. Firstly, we perform adversarial training by generating perturbed inputs through synonym substitution. Secondly, based on a linguistic theory of discourse connectives, we perform data augmentation using a discourse parser for detecting causally linked clauses in large text, and a generative language model for generating distractors. Both methods boost model performance on the Choice of Plausible Alternatives (COPA) dataset, as well as on a Balanced COPA dataset, which is a modified version of the original data that has been developed to avoid superficial cues, leading to a more challenging benchmark. We show a statistically significant improvement in performance and robustness on both datasets, even with only a small number of additionally generated data points",
    "volume": "main",
    "checked": true,
    "id": "be5c4cbde12db1c7bb89e3775e41e207aa4f9ed3",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17631": {
    "title": "Re-TACRED: Addressing Shortcomings of the TACRED Dataset",
    "abstract": "TACRED is one of the largest and most widely used sentence-level relation extraction datasets. Proposed models that are evaluated using this dataset consistently set new state-of-the-art performance. However, they still exhibit large error rates despite leveraging external knowledge and unsupervised pretraining on large text corpora. A recent study suggested that this may be due to poor dataset quality. The study observed that over 50% of the most challenging sentences from the development and test sets are incorrectly labeled and account for an average drop of 8% f1-score in model performance. However, this study was limited to a small biased sample of 5k (out of a total of 106k) sentences, substantially restricting the generalizability and broader implications of its findings. In this paper, we address these shortcomings by: (i) performing a comprehensive study over the whole TACRED dataset, (ii) proposing an improved crowdsourcing strategy and deploying it to re-annotate the whole dataset, and (iii) performing a thorough analysis to understand how correcting the TACRED annotations affects previously published results. After verification, we observed that 23.9% of TACRED labels are incorrect. Moreover, evaluating several models on our revised dataset yields an average f1-score improvement of 14.3% and helps uncover significant relationships between the different models (rather than simply offsetting or scaling their scores by a constant factor). Finally, aside from our analysis we also release Re-TACRED, a new completely re-annotated version of the TACRED dataset that can be used to perform reliable evaluation of relation extraction models",
    "volume": "main",
    "checked": true,
    "id": "6b1834da694817f3dfc3c1b48bbe5f9f5fee2854",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17632": {
    "title": "Progressive Multi-task Learning with Controlled Information Flow for Joint Entity and Relation Extraction",
    "abstract": "Multitask learning has shown promising performance in learning multiple related tasks simultaneously, and variants of model architectures have been proposed, especially for supervised classification problems. One goal of multitask learning is to extract a good representation that sufficiently captures the relevant part of the input about the output for each learning task. To achieve this objective, in this paper we design a multitask learning architecture based on the observation that correlations exist between outputs of some related tasks (e.g. entity recognition and relation extraction tasks), and they reflect the relevant features that need to be extracted from the input. As outputs are unobserved, our proposed model exploits task predictions in lower layers of the neural model, also referred to as early predictions in this work. But we control the injection of early predictions to ensure that we extract good task-specific representations for classification. We refer to this model as a Progressive Multitask learning model with Explicit Interactions (PMEI). Extensive experiments on multiple benchmark datasets produce state-of-the-art results on the joint entity and relation extraction task",
    "volume": "main",
    "checked": true,
    "id": "4adc6e782e36fd276d7c57a2ae9b36d3585c35f8",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17633": {
    "title": "RpBERT: A Text-image Relation Propagation-based BERT Model for Multimodal NER",
    "abstract": "Recently multimodal named entity recognition (MNER) has utilized images to improve the accuracy of NER in tweets. However, most of the multimodal methods use attention mechanisms to extract visual clues regardless of whether the text and image are relevant. Practically, the irrelevant text-image pairs account for a large proportion in tweets. The visual clues that are unrelated to the texts will exert uncertain or even negative effects on multimodal model learning. In this paper, we introduce a method of text-image relation propagation into the multimodal BERT model. We integrate soft or hard gates to select visual clues and propose a multitask algorithm to train and validate the effects of relation propagation on the MNER datasets. In the experiments, we deeply analyze the changes in visual attention before and after the use of relation propagation. Our model achieves state-of-the-art performance on the MNER datasets",
    "volume": "main",
    "checked": true,
    "id": "b9ad52b670189658851026e03a33063a1b8d47fe",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17634": {
    "title": "Unsupervised Learning of Deterministic Dialogue Structure with Edge-Enhanced  Graph Auto-Encoder",
    "abstract": "It is important for task-oriented dialogue systems to discover the dialogue structure (i.e. the general dialogue flow) from dialogue corpora automatically. Previous work models dialogue structure by extracting latent states for each utterance first and then calculating the transition probabilities among states. These two-stage methods ignore the contextual information when calculating the probabilities, which makes the transitions between the states ambiguous. This paper proposes a conversational graph (CG) to represent deterministic dialogue structure where nodes and edges represent the utterance and context information respectively. An unsupervised Edge-Enhanced Graph Auto-Encoder (EGAE) architecture is designed to model local-contextual and global-structural information for conversational graph learning. Furthermore, a self-supervised objective is introduced with the response selection task to guide the unsupervised learning of the dialogue structure. Experimental results on several public datasets demonstrate that the novel model outperforms several alternatives in aggregating utterances with similar semantics. The effectiveness of the learned dialogue structured is also verified by more than 5\\% joint accuracy improvement in the downstream task of low resource dialogue state tracking",
    "volume": "main",
    "checked": true,
    "id": "f2f984eab9e50a73462d1817f91a66c6dab15d77",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17635": {
    "title": "VisualMRC: Machine Reading Comprehension on Document Images",
    "abstract": "Recent studies on machine reading comprehension have focused on text-level understanding but have not yet reached the level of human understanding of the visual layout and content of real-world documents. In this study, we introduce a new visual machine reading comprehension dataset, named VisualMRC, wherein given a question and a document image, a machine reads and comprehends texts in the image to answer the question in natural language. Compared with existing visual question answering datasets that contain texts in images, VisualMRC focuses more on developing natural language understanding and generation abilities. It contains 30,000+ pairs of a question and an abstractive answer for 10,000+ document images sourced from multiple domains of webpages. We also introduce a new model that extends existing sequence-to-sequence models, pre-trained with large-scale text corpora, to take into account the visual layout and content of documents. Experiments with VisualMRC show that this model outperformed the base sequence-to-sequence models and a state-of-the-art VQA model. However, its performance is still below that of humans on most automatic evaluation metrics. The dataset will facilitate research aimed at connecting vision and language understanding",
    "volume": "main",
    "checked": true,
    "id": "f05126c1a792ea64a7af0c8c68b03bcddec5b297",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17636": {
    "title": "A Bidirectional Multi-paragraph Reading Model for Zero-shot Entity Linking",
    "abstract": "Recently, a zero-shot entity linking task is introduced to challenge the generalization ability of entity linking models. In this task, mentions must be linked to unseen entities and only the textual information is available. In order to make full use of the documents, previous work has proposed a BERT-based model which can only take fixed length of text as input. However, the key information for entity linking may exist in nearly everywhere of the documents thus the proposed model cannot capture them all. To leverage more textual information and enhance text understanding capability, we propose a bidirectional multi-paragraph reading model for the zero-shot entity linking task. Firstly, the model treats the mention context as a query and matches it with multiple paragraphs of the entity description documents. Then, the mention-aware entity representation obtained from the first step is used as a query to match multiple paragraphs in the document containing the mention through an entity-mention attention mechanism. In particular, a new pre-training strategy is employed to strengthen the representative ability. Experimental results show that our bidirectional model can capture long-range context dependencies and outperform the baseline model by 3-4% in terms of accuracy",
    "volume": "main",
    "checked": true,
    "id": "2ec01a0b6dcf2013e108b7b710754ed93a292622",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17637": {
    "title": "Ideography Leads Us to the Field of Cognition: A Radical-Guided Associative Model for Chinese Text Classification",
    "abstract": "Cognitive psychology research shows that humans have the instinct for abstract thinking, where association plays an essential role in language comprehension. Especially for Chinese, its ideographic writing system allows radicals to trigger semantic association without the need of phonetics. In fact, subconsciously using the associative information guided by radicals is a key for readers to ensure the robustness of semantic understanding. Fortunately, many basic and extended concepts related to radicals are systematically included in Chinese language dictionaries, which leaves a handy but unexplored way for improving Chinese text representation and classification. To this end, we draw inspirations from cognitive principles between ideography and human associative behavior to propose a novel Radical-guided Associative Model (RAM) for Chinese text classification. RAM comprises two coupled spaces, namely Literal Space and Associative Space, which imitates the real process in people's mind when understanding a Chinese text. To be specific, we first devise a serialized modeling structure in Literal Space to thoroughly capture the sequential information of Chinese text. Then, based on the authoritative information provided by Chinese language dictionaries, we design an association module and put forward a strategy called Radical-Word Association to use ideographic radicals as the medium to associate prior concept words in Associative Space. Afterwards, we design an attention module to imitate people's matching and decision between Literal Space and Associative Space, which can balance the importance of each associative words under specific contexts. Finally, extensive experiments on two real-world datasets prove the effectiveness and rationality of RAM, with good cognitive insights for future language modeling",
    "volume": "main",
    "checked": true,
    "id": "da154bf3b663b3543ecbd95de136bce3bf29b2af",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17638": {
    "title": "Learning from My Friends: Few-Shot Personalized Conversation Systems via Social Networks",
    "abstract": "Personalized conversation models (PCMs) generate responses according to speaker preferences. Existing personalized conversation tasks typically require models to extract speaker preferences from user descriptions or their conversation histories, which are scarce for newcomers and inactive users. In this paper, we propose a few-shot personalized conversation task with an auxiliary social network. The task requires models to generate personalized responses for a speaker given a few conversations from the speaker and a social network. Existing methods are mainly designed to incorporate descriptions or conversation histories. Those methods can hardly model speakers with so few conversations or connections between speakers. To better cater for newcomers with few resources, we propose a personalized conversation model (PCM) that learns to adapt to new speakers as well as enabling new speakers to learn from resource-rich speakers. Particularly, based on a meta-learning based PCM, we propose a task aggregator (TA) to collect other speakers' information from the social network. The TA provides prior knowledge of the new speaker in its meta-learning. Experimental results show our methods outperform all baselines in appropriateness, diversity, and consistency with speakers",
    "volume": "main",
    "checked": true,
    "id": "763268af8b1bc54754baa885163385980480521c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17639": {
    "title": "FL-MSRE: A Few-Shot Learning based Approach to Multimodal Social Relation Extraction",
    "abstract": "Social relation extraction (SRE for short), which aims to infer the social relation between two people in daily life, has been demonstrated to be of great value in reality. Existing methods for SRE consider extracting social relation only from unimodal information such as text or image, ignoring the high coupling of multimodal information. Moreover, previous studies overlook the serious unbalance distribution on social relations. To address these issues, this paper proposes FL-MSRE, a few-shot learning based approach to extracting social relations from both texts and face images. Considering the lack of multimodal social relation datasets, this paper also presents three multimodal datasets annotated from four classical masterpieces and corresponding TV series. Inspired by the success of BERT, we propose a strong BERT based baseline to extract social relation from text only. FL-MSRE is empirically shown to outperform the baseline significantly. This demonstrates that using face images benefits text-based SRE. Further experiments also show that using two faces from different images achieves similar performance as from the same image. This means that FL-MSRE is suitable for a wide range of SRE applications where the faces of two people can only be collected from different images",
    "volume": "main",
    "checked": true,
    "id": "cb36a165675613993d9cfbe1a3ec0c5b05ac900b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17640": {
    "title": "KEML: A Knowledge-Enriched Meta-Learning Framework for Lexical Relation Classification",
    "abstract": "Lexical relations describe how concepts are semantically related, in the form of relation triples. The accurate prediction of lexical relations between concepts is challenging, due to the sparsity of patterns indicating the existence of such relations. We propose the Knowledge-Enriched Meta-Learning (KEML) framework to address lexical relation classification. In KEML, the LKB-BERT (Lexical Knowledge Base-BERT) model is first presented to learn concept representations from text corpora, with rich lexical knowledge injected by distant supervision. A probabilistic distribution of auxiliary tasks is defined to increase the model's ability to recognize different types of lexical relations. We further propose a neural classifier integrated with special relation recognition cells, in order to combine meta-learning over the auxiliary task distribution and supervised learning for LRC. Experiments over multiple datasets show KEML outperforms state-of-the-art methods",
    "volume": "main",
    "checked": true,
    "id": "8a6a1ac62b681f4dda5495282b515d111a68cc42",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17641": {
    "title": "Exploring Explainable Selection to Control Abstractive Summarization",
    "abstract": "Like humans, document summarization models can interpret a documents contents in a number of ways. Unfortunately, the neural models of today are largely black boxes that provide little explanation of how or why they generated a summary in the way they did. Therefore, to begin prying open the black box and to inject a level of control into the substance of the final summary, we developed a novel select-and-generate framework that focuses on explainability. By revealing the latent centrality and interactions between sentences, along with scores for novelty and relevance, users are given a window into the choices a model is making and an opportunity to guide those choices in a more desirable direction. A novel pair-wise matrix captures the sentence interactions, centrality and attribute scores, and a mask with tunable attribute thresholds allows the user to control which sentences are likely to be included in the extraction. A sentence-deployed attention mechanism in the abstractor ensures the final summary emphasizes the desired content. Additionally, the encoder is adaptable, supporting both Transformer- and BERT-based configurations. In a series of experiments assessed with ROUGE metrics and two human evaluations, ESCA outperformed eight state-of-the-art models on the CNN/DailyMail and NYT50 benchmark datasets",
    "volume": "main",
    "checked": true,
    "id": "00f75e193720785c99e26958644e7d6d11960daf",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17642": {
    "title": "Encoding Syntactic Knowledge in Transformer Encoder for Intent Detection and Slot Filling",
    "abstract": "We propose a novel Transformer encoder-based architecture with syntactical knowledge encoded for intent detection and slot filling. Specifically, we encode syntactic knowledge into the Transformer encoder by jointly training it to predict syntactic parse ancestors and part-of-speech of each token via multi-task learning. Our model is based on self-attention and feed-forward layers and does not require external syntactic information to be available at inference time. Experiments show that on two benchmark datasets, our models with only two Transformer encoder layers achieve state-of-the-art results. Compared to the previously best performed model without pre-training, our models achieve absolute F1 score and accuracy improvement of 1.59 % and 0.85 % for slot filling and intent detection on the SNIPS dataset, respectively. Our models also achieve absolute F1 score and accuracy improvement of 0.1 % and 0.34 % for slot filling and intent detection on the ATIS dataset, respectively, over the previously best performed model. Furthermore, the visualization of the self-attention weights illustrates the benefits of incorporating syntactic information during training",
    "volume": "main",
    "checked": true,
    "id": "c31839ef4294e8b402a79f64e240deba2bd8dc39",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17643": {
    "title": "Effective Slot Filling via Weakly-Supervised Dual-Model Learning",
    "abstract": "Slot filling is a challenging task in Spoken Language Understanding (SLU). Supervised methods usually require large amounts of annotation to maintain desirable performance. A solution to relieve the heavy dependency on labeled data is to employ bootstrapping, which leverages unlabeled data. However, bootstrapping is known to suffer from semantic drift. We argue that semantic drift can be tackled by exploiting the correlation between slot values (phrases) and their respective types. By using some particular weakly labeled data, namely the plain phrases included in sentences, we propose a weakly-supervised slot filling approach. Our approach trains two models, namely a classifier and a tagger, which can effectively learn from each other on the weakly labeled data. The experimental results demonstrate that our approach achieves better results than standard baselines on multiple datasets, especially in the low-resource setting",
    "volume": "main",
    "checked": true,
    "id": "c9725862c3db213a6ec70b110342f904298af42d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17644": {
    "title": "Tune-In: Training Under Negative Environments with Interference for Attention Networks Simulating Cocktail Party Effect",
    "abstract": "We study the cocktail party problem and propose a novel attention network called Tune-In, abbreviated for training under negative environments with interference. It firstly learns two separate spaces of speaker-knowledge and speech-stimuli based on a shared feature space, where a new block structure is designed as the building block for all spaces, and then cooperatively solves different tasks. Between the two spaces, information is cast towards each other via a novel cross- and dual-attention mechanism, mimicking the bottom-up and top-down processes of a human's cocktail party effect. It turns out that substantially discriminative and generalizable speaker representations can be learnt in severely interfered conditions via our self-supervised training. The experimental results verify this seeming paradox. The learnt speaker embedding has superior discriminative power than a standard speaker verification method; meanwhile, Tune-In achieves remarkably better speech separation performances in terms of SI-SNRi and SDRi consistently in all test modes, and especially at lower memory and computational consumption, than state-of-the-art benchmark systems",
    "volume": "main",
    "checked": true,
    "id": "3e2940964c67d75903e700efe6c60ac6215603df",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17645": {
    "title": "Bridging the Domain Gap: Improve Informal Language Translation via Counterfactual Domain Adaptation",
    "abstract": "Despite the near-human performances already achieved on formal texts such as news articles, neural machine translation still has difficulty in dealing with \"user-generated\" texts that have diverse linguistic phenomena but lack large-scale high-quality parallel corpora. To address this problem, we propose a counterfactual domain adaptation method to better leverage both large-scale source-domain data (formal texts) and small-scale target-domain data (informal texts). Specifically, by considering effective counterfactual conditions (the concatenations of source-domain texts and the target-domain tag), we construct the counterfactual representations to fill the sparse latent space of the target domain caused by a small amount of data, that is, bridging the gap between the source-domain data and the target-domain data. Experiments on English-to-Chinese and Chinese-to-English translation tasks show that our method outperforms the base model that is trained only on the informal corpus by a large margin, and consistently surpasses different baseline methods by +1.12 ~ 4.34 BLEU points on different datasets. Furthermore, we also show that our method achieves competitive performances on cross-domain language translation on four language pairs",
    "volume": "main",
    "checked": true,
    "id": "845ca861cb211fefdb49fd3ec4866dc7e93680c3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17646": {
    "title": "Tracking Interaction States for Multi-Turn Text-to-SQL Semantic Parsing",
    "abstract": "The task of multi-turn text-to-SQL semantic parsing aims to translate natural language utterances in an interaction into SQL queries in order to answer them using a database which normally contains multiple table schemas. Previous studies on this task usually utilized contextual information to enrich utterance representations and to further influence the decoding process. While they ignored to describe and track the interaction states which are determined by history SQL queries and are related with the intent of current utterance. In this paper, two kinds of interaction states are defined based on schema items and SQL keywords separately. A relational graph neural network and a non-linear layer are designed to update the representations of these two states respectively. The dynamic schema-state and SQL-state representations are then utilized to decode the SQL query corresponding to current utterance. Experimental results on the challenging CoSQL dataset demonstrate the effectiveness of our proposed method, which achieves better performance than other published methods on the task leaderboard",
    "volume": "main",
    "checked": true,
    "id": "849a987959193eed1d0ca9303d2ee9c7359b011a",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17647": {
    "title": "Generating Diversified Comments via Reader-Aware Topic Modeling and Saliency Detection",
    "abstract": "Automatic comment generation is a special and challenging task to verify the model ability on news content comprehension and language generation. Comments not only convey salient and interesting information in news articles, but also imply various and different reader characteristics which we treat as the essential clues for diversity. However, most of the comment generation approaches only focus on saliency information extraction, while the reader-aware factors implied by comments are neglected. To address this issue, we propose a unified reader-aware topic modeling and saliency information detection framework to enhance the quality of generated comments. For reader-aware topic modeling, we design a variational generative clustering algorithm for latent semantic learning and topic mining from reader comments. For saliency information detection, we introduce Bernoulli distribution estimating on news content to select saliency information. The obtained topic representations as well as the selected saliency information are incorporated into the decoder to generate diversified and informative comments. Experimental results on three datasets show that our framework outperforms existing baseline methods in terms of both automatic metrics and human evaluation. The potential ethical issues are also discussed in detail",
    "volume": "main",
    "checked": true,
    "id": "8fa1a99cf07c7d79c12620899f0630e8818cff64",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17648": {
    "title": "Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks",
    "abstract": "Adversarial training is the most empirically successful approach in improving the robustness of deep neural networks for image classification. For text classification, however, existing synonym substitution based adversarial attacks are effective but not very efficient to be incorporated into practical text adversarial training. Gradient-based attacks, which are very efficient for images, are hard to be implemented for synonym substitution based text attacks due to the lexical, grammatical and semantic constraints and the discrete text input space. Thereby, we propose a fast text adversarial attack method called Fast Gradient Projection Method (FGPM) based on synonym substitution, which is about 20 times faster than existing text attack methods and could achieve similar attack performance. We then incorporate FGPM with adversarial training and propose a text defense method called Adversarial Training with FGPM enhanced by Logit pairing (ATFL). Experiments show that ATFL could significantly improve the model robustness and block the transferability of adversarial examples",
    "volume": "main",
    "checked": true,
    "id": "2bd24296b8780970ee881d62be9102511b5db99b",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17649": {
    "title": "NaturalConv: A Chinese Dialogue Dataset Towards Multi-turn Topic-driven Conversation",
    "abstract": "In this paper, we propose a Chinese multi-turn topic-driven conversation dataset, NaturalConv, which allows the participants to chat anything they want as long as any element from the topic is mentioned and the topic shift is smooth. Our corpus contains 19.9K conversations from six domains, and 400K utterances with an average turn number of 20.1. These conversations contain in-depth discussions on related topics or widely natural transition between multiple topics. We believe either way is normal for human conversation. To facilitate the research on this corpus, we provide results of several benchmark models. Comparative results show that for this dataset, our current models are not able to provide significant improvement by introducing background knowledge/topic. Therefore, the proposed dataset should be a good benchmark for further research to evaluate the validity and naturalness of multi-turn conversation systems. Our dataset is available at https://ai.tencent.com/ailab/nlp/dialogue/#datasets",
    "volume": "main",
    "checked": true,
    "id": "bd19fb759a2baca8bb9e998e459954b5a1101981",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17650": {
    "title": "Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs",
    "abstract": "Code completion has become an essential component of integrated development environments. Contemporary code completion methods rely on the abstract syntax tree (AST) to generate syntactically correct code. However, they cannot fully capture the sequential and repetitive patterns of writing code and the structural information of the AST. To alleviate these problems, we propose a new code completion approach named CCAG, which models the flattened sequence of a partial AST as an AST graph. CCAG uses our proposed AST Graph Attention Block to capture different dependencies in the AST graph for representation learning in code completion. The sub-tasks of code completion are optimized via multi-task learning in CCAG, and the task balance is automatically achieved using uncertainty without the need to tune task weights. The experimental results show that CCAG has superior performance than state-of-the-art approaches and it is able to provide intelligent code completion",
    "volume": "main",
    "checked": true,
    "id": "560d4747ed94786cf96ef542a1a3f2b9089f0145",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17651": {
    "title": "Robustness to Spurious Correlations in Text Classification via Automatically Generated Counterfactuals",
    "abstract": "Spurious correlations threaten the validity of statistical classifiers. While model accuracy may appear high when the test data is from the same distribution as the training data, it can quickly degrade when the test distribution changes. For example, it has been shown that classifiers perform poorly when humans make minor modifications to change the label of an example. One solution to increase model reliability and generalizability is to identify causal associations between features and classes. In this paper, we propose to train a robust text classifier by augmenting the training data with automatically generated counterfactual data. We first identify likely causal features using a statistical matching approach. Next, we generate counterfactual samples for the original training data by substituting causal features with their antonyms and then assigning opposite labels to the counterfactual samples. Finally, we combine the original data and counterfactual data to train a robust classifier. Experiments on two classification tasks show that a traditional classifier trained on the original data does very poorly on human-generated counterfactual samples (e.g., 10%-37% drop in accuracy). However, the classifier trained on the combined data is more robust and performs well on both the original test data and the counterfactual test data (e.g., 12%-25% increase in accuracy compared with the traditional classifier). Detailed analysis shows that the robust classifier makes meaningful and trustworthy predictions by emphasizing causal features and de-emphasizing non-causal features",
    "volume": "main",
    "checked": true,
    "id": "a5b1169e536b806c2344261ebbbe3d97bc6e1cdb",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17652": {
    "title": "MLE-Guided Parameter Search for Task Loss Minimization in Neural Sequence Modeling",
    "abstract": "Neural autoregressive sequence models are used to generate sequences in a variety of natural language processing (NLP) tasks, where they are evaluated according to sequence-level task losses. These models are typically trained with maximum likelihood estimation, which ignores the task loss, yet empirically performs well as a surrogate objective. Typical approaches to directly optimizing the task loss such as policy gradient and minimum risk training are based around sampling in the sequence space to obtain candidate update directions that are scored based on the loss of a single sequence. In this paper, we develop an alternative method based on random search in the parameter space that leverages access to the maximum likelihood gradient. We propose maximum likelihood guided parameter search (MGS), which samples from a distribution over update directions that is a mixture of random search around the current parameters and around the maximum likelihood gradient, with each direction weighted by its improvement in the task loss. MGS shifts sampling to the parameter space, and scores candidates using losses that are pooled from multiple sequences. Our experiments show that MGS is capable of optimizing sequence-level losses, with substantial reductions in repetition and non-termination in sequence completion, and similar improvements to those of minimum risk training in machine translation",
    "volume": "main",
    "checked": true,
    "id": "459e8c9ce32cc62312813c6704d24cb92a722828",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17653": {
    "title": "Do Response Selection Models Really Know Whats Next? Utterance Manipulation Strategies for Multi-turn Response Selection",
    "abstract": "In this paper, we study the task of selecting the optimal response given a user and system utterance history in retrieval-based multi-turn dialog systems. Recently, pre-trained language models (e.g., BERT, RoBERTa, and ELECTRA) showed significant improvements in various natural language processing tasks. This and similar response selection tasks can also be solved using such language models by formulating the tasks as dialog--response binary classification tasks. Although existing works using this approach successfully obtained state-of-the-art results, we observe that language models trained in this manner tend to make predictions based on the relatedness of history and candidates, ignoring the sequential nature of multi-turn dialog systems. This suggests that the response selection task alone is insufficient for learning temporal dependencies between utterances. To this end, we propose utterance manipulation strategies (UMS) to address this problem. Specifically, UMS consist of several strategies (i.e., insertion, deletion, and search), which aid the response selection model towards maintaining dialog coherence. Further, UMS are self-supervised methods that do not require additional annotation and thus can be easily incorporated into existing approaches. Extensive evaluation across multiple languages and models shows that UMS are highly effective in teaching dialog consistency, which leads to models pushing the state-of-the-art with significant margins on multiple public benchmark datasets",
    "volume": "main",
    "checked": true,
    "id": "20d30b57444fc7c236638a89cfc72e58d0d9f322",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17654": {
    "title": "On Scalar Embedding of Relative Positions in Attention Models",
    "abstract": "Attention with positional encoding has been demonstrated as a powerful component in modern neural network models, such as transformers. However, why positional encoding works well in attention models remains largely unanswered. In this paper, we study the scalar relative positional encoding (SRPE) proposed in the T5 transformer. Such an encoding method has two features. First, it uses a scalar to embed relative positions. Second, the relative positions are bucketized using a fixed heuristic algorithm, and positions in the same bucket share the same embedding. In this work, we show that SRPE in attention has an elegant probabilistic interpretation. More specifically, the positional encoding serves to produce a prior distribution for the attended positions. The resulting attentive distribution can be viewed as a posterior distribution of the attended position given the observed input sequence. Furthermore, we propose a new SRPE (AT5) that adopts a learnable bucketization protocol and automatically adapts to the dependency range specific to the learning task. Empirical studies show that the AT5 achieves superior performance than the T5's SRPE",
    "volume": "main",
    "checked": true,
    "id": "52d01d9f71caf0d021fccb75b75b7d3dfc7460f5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17655": {
    "title": "Evidence Inference Networks for Interpretable Claim Verification",
    "abstract": "Existing approaches construct appropriate interaction models to explore semantic conflicts between claims and relevant articles, which provides practical solutions for interpretable claim verification. However, these conflicts are not necessarily all about questioning the false part of claims, which makes considerable semantic conflicts difficult to be used as evidence to explain the results of claim verification. In this paper, we propose evidence inference networks (EVIN), which focus on the conflicts questioning the core semantics of claims and serve as evidence for interpretable claim verification. Specifically, EVIN first captures the core semantic segments of claims and the users' principal opinions in relevant articles. Then, it finely-grained identifies the semantic conflicts contained in each relevant article from these opinions. Finally, it constructs coherence modeling to match the conflicts that queries the core semantic fragments of claims as explainable evidence. Experiments on two widely used datasets demonstrate that EVIN not only achieves satisfactory performance but also provides explainable evidence for end-users",
    "volume": "main",
    "checked": true,
    "id": "ab4a0fbf1a12c596c4a5c33c1a34cc1e6459eaf0",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17656": {
    "title": "TextGAIL: Generative Adversarial Imitation Learning for Text Generation",
    "abstract": "Generative Adversarial Networks (GANs) for text generation have recently received many criticisms, as they perform worse than their MLE counterparts. We suspect previous text GANs' inferior performance is due to the lack of a reliable guiding signal in their discriminators. To address this problem, we propose a generative adversarial imitation learning framework for text generation that uses large pre-trained language models to provide more reliable reward guidance. As previous text GANs suffer from high variance of gradients, we apply contrastive discriminator, and proximal policy optimization (PPO) to stabilize and improve text generation performance. For evaluation, we conduct experiments on a diverse set of unconditional and conditional text generation tasks. Experimental results show that TextGAIL achieves better performance in terms of both quality and diversity than the MLE baseline. We also validate our intuition that TextGAIL's discriminator demonstrates the capability of providing reasonable rewards with an additional task",
    "volume": "main",
    "checked": true,
    "id": "2ff04294838863ec2d2087cbaa36bac48bf0e555",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17657": {
    "title": "MELINDA: A Multimodal Dataset for Biomedical Experiment Method Classification",
    "abstract": "We introduce a new dataset, MELINDA, for Multimodal biomEdicaL experImeNt methoD clAssification. The dataset is collected in a fully automated distant supervision manner, where the labels are obtained from an existing curated database, and the actual contents are extracted from papers associated with each of the records in the database. We benchmark various state-of-the-art NLP and computer vision models, including unimodal models which only take either caption texts or images as inputs, and multimodal models. Extensive experiments and analysis show that multimodal models, despite outperforming unimodal ones, still need improvements especially on a less-supervised way of grounding visual concepts with languages, and better transferability to low resource domains. We release our dataset and the benchmarks to facilitate future research in multimodal learning, especially to motivate targeted improvements for applications in scientific domains",
    "volume": "main",
    "checked": true,
    "id": "c9074d9719c5ce0dd3a7369dd0749cd08d7f67ed",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17658": {
    "title": "A Controllable Model of Grounded Response Generation",
    "abstract": "Current end-to-end neural conversation models inherently lack the flexibility to impose semantic control in the response generation process, often resulting in uninteresting responses. Attempts to boost informativeness alone come at the expense of factual accuracy, as attested by pretrained language models' propensity to \"hallucinate\" facts. While this may be mitigated by access to background knowledge, there is scant guarantee of relevance and informativeness in generated responses. We propose a framework that we call controllable grounded response generation (CGRG), in which lexical control phrases are either provided by a user or automatically extracted by a control phrase predictor from dialogue context and grounding knowledge. Quantitative and qualitative results show that, using this framework, a transformer based model with a novel inductive attention mechanism, trained on a conversation-like Reddit dataset, outperforms strong generation baselines",
    "volume": "main",
    "checked": true,
    "id": "2f08f268f3594b875be156c3ab1c78f19791d592",
    "citation_count": 45
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17659": {
    "title": "Context-Guided BERT for Targeted Aspect-Based Sentiment Analysis",
    "abstract": "Aspect-based sentiment analysis (ABSA) and Targeted ASBA (TABSA) allow finer-grained inferences about sentiment to be drawn from the same text, depending on context. For example, a given text can have different targets (e.g., neighborhoods) and different aspects (e.g., price or safety), with different sentiment associated with each target-aspect pair. In this paper, we investigate whether adding context to self-attention models improves performance on (T)ABSA. We propose two variants of Context-Guided BERT (CG-BERT) that learn to distribute attention under different contexts. We first adapt a context-aware Transformer to produce a CG-BERT that uses context-guided softmax-attention. Next, we propose an improved Quasi-Attention CG-BERT model that learns a compositional attention that supports subtractive attention. We train both models with pretrained BERT on two (T)ABSA datasets: SentiHood and SemEval-2014 (Task 4). Both models achieve new state-of-the-art results with our QACG-BERT model having the best performance. Furthermore, we provide analyses of the impact of context in the our proposed models. Our work provides more evidence for the utility of adding context-dependencies to pretrained self-attention-based language models for context-based natural language tasks",
    "volume": "main",
    "checked": true,
    "id": "a3b395831496bb50fca43317e320c774900c28b2",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17660": {
    "title": "Does Head Label Help for Long-Tailed Multi-Label Text Classification",
    "abstract": "Multi-label text classification (MLTC) aims to annotate documents with the most relevant labels from a number of candidate labels. In real applications, the distribution of label frequency often exhibits a long tail, i.e., a few labels are associated with a large number of documents (a.k.a. head labels), while a large fraction of labels are associated with a small number of documents (a.k.a. tail labels). To address the challenge of insufficient training data on tail label classification, we propose a Head-to-Tail Network (HTTN) to transfer the meta-knowledge from the data-rich head labels to data-poor tail labels. The meta-knowledge is the mapping from few-shot network parameters to many-shot network parameters, which aims to promote the generalizability of tail classifiers. Extensive experimental results on three benchmark datasets demonstrate that HTTN consistently outperforms the state-of-the-art methods. The code and hyper-parameter settings are released for reproducibility",
    "volume": "main",
    "checked": true,
    "id": "05e02090137d496cefecdea86c7aa43a4feebbc7",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17661": {
    "title": "Adversarial Meta Sampling for Multilingual Low-Resource Speech Recognition",
    "abstract": "Low-resource automatic speech recognition (ASR) is challenging, as the low-resource target language data cannot well train an ASR model. To solve this issue, meta-learning formulates ASR for each source language into many small ASR tasks and meta-learns a model initialization on all tasks from different source languages to access fast adaptation on unseen target languages. However, for different source languages, the quantity and difficulty vary greatly because of their different data scales and diverse phonological systems, which leads to task-quantity and task-difficulty imbalance issues and thus a failure of multilingual meta-learning ASR (MML-ASR). In this work, we solve this problem by developing a novel adversarial meta sampling (AMS) approach to improve MML-ASR. When sampling tasks in MML-ASR, AMS adaptively determines the task sampling probability for each source language. Specifically, for each source language, if the query loss is large, it means that its tasks are not well sampled to train ASR model in terms of its quantity and difficulty and thus should be sampled more frequently for extra learning. Inspired by this fact, we feed the historical task query loss of all source language domain into a network to learn a task sampling policy for adversarially increasing the current query loss of MML-ASR. Thus, the learnt task sampling policy can master the learning situation of each language and thus predicts good task sampling probability for each language for more effective learning. Finally, experiment results on two multilingual datasets show significant performance improvement when applying our AMS on MML-ASR, and also demonstrate the applicability of AMS to other low-resource speech tasks and transfer learning ASR approaches",
    "volume": "main",
    "checked": true,
    "id": "535f1684de5ce59ce2be17e876e55ce9e7692ad9",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17662": {
    "title": "Improving Tree-Structured Decoder Training for Code Generation via Mutual Learning",
    "abstract": "Code generation aims to automatically generate a piece of code given an input natural language utterance. Currently, among dominant models, it is treated as a sequence-to-tree task, where a decoder outputs a sequence of actions corresponding to the pre-order traversal of an Abstract Syntax Tree. However, such a decoder only exploits the pre-order traversal based preceding actions, which are insufficient to ensure correct action predictions. In this paper, we first throughly analyze the context modeling difference between neural code generation models with different traversals based decodings (preorder traversal vs breadth-first traversal), and then propose to introduce a mutual learning framework to jointly train these models. Under this framework, we continuously enhance both two models via mutual distillation, which involves synchronous executions of two one-to-one knowledge transfers at each training step. More specifically, we alternately choose one model as the student and the other as its teacher, and require the student to fit the training data and the action prediction distributions of its teacher. By doing so, both models can fully absorb the knowledge from each other and thus could be improved simultaneously. Experimental results and in-depth analysis on several benchmark datasets demonstrate the effectiveness of our approach. We release our  code at https://github.com/DeepLearnXMU/CGML",
    "volume": "main",
    "checked": true,
    "id": "9ba5501a22f8e2207280abb997bbea12fbf9027a",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17663": {
    "title": "Enabling Fast and Universal Audio Adversarial Attack Using Generative Model",
    "abstract": "Recently, the vulnerability of deep neural network (DNN)-based audio systems to adversarial attacks has obtained increasing attention. However, the existing audio adversarial attacks allow the adversary to possess the entire user's audio input as well as granting sufficient time budget to generate the adversarial perturbations. These idealized assumptions, however, make the existing audio adversarial attacks mostly impossible to be launched in a timely fashion in practice (e.g., playing unnoticeable adversarial perturbations along with user's streaming input). To overcome these limitations, in this paper we propose fast audio adversarial perturbation generator (FAPG), which uses generative model to generate adversarial perturbations for the audio input in a single forward pass, thereby drastically improving the perturbation generation speed. Built on the top of FAPG, we further propose universal audio adversarial perturbation generator (UAPG), a scheme to craft universal adversarial perturbation that can be imposed on arbitrary benign audio input to cause misclassification. Extensive experiments on DNN-based audio systems show that our proposed FAPG can achieve high success rate with up to 214X speedup over the existing audio adversarial attack methods. Also our proposed UAPG generates universal adversarial perturbations that can achieve much better attack performance than the state-of-the-art solutions",
    "volume": "main",
    "checked": true,
    "id": "ddbeddfe4d4afe5d1cf008447a6d657511c1ca76",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17664": {
    "title": "Nystrmformer: A Nystrm-based Algorithm for Approximating Self-Attention",
    "abstract": "Transformers have emerged as a powerful tool for a broad range of natural language processing tasks. A key component that drives the impressive performance of Transformers is the self-attention mechanism that encodes the influence or dependence of other tokens on each specific token. While beneficial, the quadratic complexity of self-attention on the input sequence length has limited its application to longer sequences - a topic being actively studied in the community. To address this limitation, we propose Nystrmformer - a model that exhibits favorable scalability as a function of sequence length. Our idea is based on adapting the Nystrm method to approximate standard self-attention with O(n) complexity. The scalability of Nystrmformer enables application to longer sequences with thousands of tokens. We perform evaluations on multiple downstream tasks on the GLUE benchmark and IMDB reviews with standard sequence length, and find that our Nystrmformer performs comparably, or in a few cases, even slightly better, than standard self-attention. On longer sequence tasks in the Long Range Arena (LRA) benchmark, Nystrmformer performs favorably relative to other efficient self-attention methods. Our code is available at https://github.com/mlpen/Nystromformer",
    "volume": "main",
    "checked": true,
    "id": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85",
    "citation_count": 148
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17665": {
    "title": "Entity Structure Within and Throughout: Modeling Mention Dependencies for Document-Level Relation Extraction",
    "abstract": "Entities, as the essential elements in relation extraction tasks, exhibit certain structure. In this work, we formulate such entity structure as distinctive dependencies between mention pairs. We then propose SSAN, which incorporates these structural dependencies within the standard self-attention mechanism and throughout the overall encoding stage. Specifically, we design two alternative transformation modules inside each self-attention building block to produce attentive biases so as to adaptively regularize its attention flow. Our experiments demonstrate the usefulness of the proposed entity structure and the effectiveness of SSAN. It significantly outperforms competitive baselines, achieving new state-of-the-art results on three popular document-level relation extraction datasets. We further provide ablation and visualization to show how the entity structure guides the model for better relation extraction. Our code is publicly available",
    "volume": "main",
    "checked": true,
    "id": "92a21e9ce3f702d0a2b0d619c4c974bdc8ff23cd",
    "citation_count": 47
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17666": {
    "title": "Learning an Effective Context-Response Matching Model with Self-Supervised Tasks for Retrieval-based Dialogues",
    "abstract": "Building an intelligent dialogue system with the ability to select a proper response according to a multi-turn context is a great challenging task.  Existing studies focus on building a context-response matching model with various neural architectures or pretrained language models (PLMs)  and typically learning with a single response prediction task.  These approaches overlook many potential training signals contained in dialogue data, which might be beneficial for context understanding and produce better features for response prediction.   Besides, the response retrieved from existing dialogue systems supervised by the conventional way  still faces some critical challenges, including incoherence and inconsistency.  To address these issues, in this paper, we propose learning a context-response matching model with auxiliary self-supervised tasks designed for the dialogue data based on pre-trained language models.  Specifically, we introduce four self-supervised tasks including next session prediction, utterance restoration, incoherence detection and consistency discrimination, and jointly train the PLM-based response selection model with these auxiliary tasks in a multi-task manner.   By this means, the auxiliary tasks can guide the learning of the matching model to achieve a better local optimum and select a more proper response.  Experiment results on two benchmarks indicate that the proposed auxiliary self-supervised tasks bring significant improvement for multi-turn response selection in retrieval-based dialogues, and our model achieves new state-of-the-art results on both datasets",
    "volume": "main",
    "checked": true,
    "id": "83649fe41651f12c4ced49e8eead447664b422ec",
    "citation_count": 38
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17667": {
    "title": "Document-Level Relation Extraction with Reconstruction",
    "abstract": "In document-level relation extraction (DocRE), graph structure is generally used to encode relation information in the input document to classify the relation category between each entity pair, and has greatly advanced the DocRE task over the past several years. However, the learned graph representation universally models relation information between all entity pairs regardless of whether there are relationships between these entity pairs. Thus, those entity pairs without relationships disperse the attention of the encoder-classifier DocRE for ones with relationships, which may further hind the improvement of DocRE. To alleviate this issue, we propose a novel encoder-classifier-reconstructor model for DocRE. The reconstructor manages to reconstruct the ground-truth path dependencies from the graph representation, to ensure that the proposed DocRE model pays more attention to encode entity pairs with relationships in the training. Furthermore, the reconstructor is regarded as a relationship indicator to assist relation classification in the inference, which can further improve the performance of DocRE model. Experimental results on a large-scale DocRE dataset show that the proposed model can significantly improve the accuracy of relation extraction on a strong heterogeneous graph-based baseline. The code is publicly available at https://github.com/xwjim/DocRE-Rec",
    "volume": "main",
    "checked": true,
    "id": "1e15de9245be9bf8f11c1270f46fb0195caf240d",
    "citation_count": 34
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17668": {
    "title": "Topic-Aware Multi-turn Dialogue Modeling",
    "abstract": "In the retrieval-based multi-turn dialogue modeling, it remains a challenge to select the most appropriate response according to extracting salient features in context utterances. As a conversation goes on, topic shift at discourse-level naturally happens through the continuous multi-turn dialogue context. However, all known retrieval-based systems are satisfied with exploiting local topic words for context utterance representation but fail to capture such essential global topic-aware clues at discourse-level. Instead of taking topic-agnostic n-gram utterance as processing unit for matching purpose in existing systems, this paper presents a novel topic-aware solution for multi-turn dialogue modeling, which segments and extracts topic-aware utterances in an unsupervised way, so that the resulted model is capable of capturing salient topic shift at discourse-level in need and thus effectively track topic flow during multi-turn conversation. Our topic-aware modeling is implemented by a newly proposed unsupervised topic-aware segmentation algorithm and Topic-Aware Dual-attention Matching (TADAM) Network, which matches each topic segment with the response in a dual cross-attention way. Experimental results on three public datasets show TADAM can outperform the state-of-the-art method, especially by 3.3% on E-commerce dataset that has an obvious topic shift",
    "volume": "main",
    "checked": true,
    "id": "40b1ea56c49751366b05f90f91f98d9d4a12e290",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17669": {
    "title": "A Supervised Multi-Head Self-Attention Network for Nested Named Entity Recognition",
    "abstract": "In recent years, researchers have shown an increased interest in recognizing the overlapping entities that have nested structures. However, most existing models ignore the semantic correlation between words under different entity types. Considering words in sentence play different roles under different entity types, we argue that the correlation intensities of pairwise words in sentence for each entity type should be considered. In this paper, we treat named entity recognition as a multi-class classification of word pairs and design a simple neural model to handle this issue. Our model applies a supervised multi-head self-attention mechanism, where each head corresponds to one entity type, to construct the word-level correlations for each type. Our model can flexibly predict the span type by the correlation intensities of its head and tail under the corresponding type. In addition, we fuse entity boundary detection and entity classification by a multitask learning framework, which can capture the dependencies between these two tasks. To verify the performance of our model, we conduct extensive experiments on both nested and flat datasets. The experimental results show that our model can outperform the previous state-of-the-art methods on multiple tasks without any extra NLP tools or human annotations",
    "volume": "main",
    "checked": true,
    "id": "50f1b5e8a18103bba492fe8987d75a2fbb8a5b4c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17670": {
    "title": "GDPNet: Refining Latent Multi-View Graph for Relation Extraction",
    "abstract": "Relation Extraction (RE) is to predict the relation type of two entities that are mentioned in a piece of text, e.g., a sentence or a dialogue. When the given text is long, it is challenging to identify indicative words for the relation prediction. Recent advances on RE task are from BERT-based sequence modeling and graph-based modeling of relationships among the tokens in the sequence. In this paper, we propose to construct a latent multi-view graph to capture various possible relationships among tokens. We then refine this graph to select important words for relation prediction. Finally, the representation of the refined graph and the BERT-based sequence representation are concatenated for relation extraction. Specifically, in our proposed GDPNet (Gaussian Dynamic Time Warping Pooling Net), we utilize Gaussian Graph Generator (GGG) to generate edges of the multi-view graph. The graph is then refined by Dynamic Time Warping Pooling (DTWPool). On DialogRE and TACRED, we show that GDPNet achieves the best performance on dialogue-level RE, and comparable performance with the state-of-the-arts on sentence-level RE. Our code is available at https://github.com/XueFuzhao/GDPNet",
    "volume": "main",
    "checked": true,
    "id": "c3ee23ae9c6eef53ff8a6ec8169a1ebd25a36b65",
    "citation_count": 32
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17671": {
    "title": "Human-Level Interpretable Learning for Aspect-Based Sentiment Analysis",
    "abstract": "This paper proposes human-interpretable learning of aspect-based sentiment analysis (ABSA), employing the recently introduced Tsetlin Machines (TMs). We attain interpretability by converting the intricate position-dependent textual semantics into binary form, mapping all the features into bag-of-words (BOWs). The binary form BOWs are encoded so that the information on the aspect and context words are nearly lossless for sentiment classification. We further adapt the BOWs as input to the TM, enabling learning of aspect-based sentiment patterns in propositional logic. To evaluate interpretability and accuracy, we conducted experiments on two widely used ABSA datasets of SemEval 2014: Restaurant 14 and Laptop 14. The experiments show how each relevant feature takes part in conjunctive clauses that contain the context information for the corresponding aspect word, demonstrating human-level interpretability. At the same time, the obtained accuracy is competitive with existing neural network models, reaching 78.02% on Restaurant 14 and 73.51% on Laptop 14",
    "volume": "main",
    "checked": true,
    "id": "f1a2a29c6f456e3b9e33fa719003ced4afe33d18",
    "citation_count": 33
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17672": {
    "title": "Style-transfer and Paraphrase: Looking for a Sensible Semantic Similarity Metric",
    "abstract": "The rapid development of such natural language processing tasks as style transfer, paraphrase, and machine translation often calls for the use of semantic similarity metrics. In recent years a lot of methods to measure the semantic similarity of two short texts were developed. This paper provides a comprehensive analysis for more than a dozen of such methods. Using a new dataset of fourteen thousand sentence pairs human-labeled according to their semantic similarity, we demonstrate that none of the metrics widely used in the literature is close enough to human judgment in these tasks. A number of recently proposed metrics provide comparable results, yet Word Mover Distance is shown to be the most reasonable solution to measure semantic similarity in reformulated texts at the moment",
    "volume": "main",
    "checked": true,
    "id": "b21d23b0bf97c42ad558835b4ab5f0ca224f55f4",
    "citation_count": 22
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17673": {
    "title": "Multi-Document Transformer for Personality Detection",
    "abstract": "Personality detection aims to identify the personality traits implied in social media posts. The core of this task is to put together information in multiple scattered posts to depict an overall personality profile for each user. Existing approaches either encode each post individually or assemble posts arbitrarily into a new document that can be encoded sequentially or hierarchically. While the first approach ignores the connection between posts, the second tends to introduce unnecessary post-order bias into posts. In this paper, we propose a multi-document Transformer, namely Transformer-MD, to tackle the above issues. When encoding each post, Transformer-MD allows access to information in the other posts of the user through Transformer-XLs memory tokens which share the same position embedding.Besides, personality is usually defined along different traits and each trait may need to attend to different post information, which has rarely been touched by existing research. To address this concern, we propose a dimension attention mechanism on top of Transformer-MD to obtain trait-specific representations for multi-trait personality detection. We evaluate the proposed model on the Kaggle and Pandora MBTI datasets and the experimental results show that it compares favorably with baseline methods",
    "volume": "main",
    "checked": true,
    "id": "618a636df616a642533f7f07cafa6ce8fe8ea1ba",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17674": {
    "title": "UBAR: Towards Fully End-to-End Task-Oriented Dialog System with GPT-2",
    "abstract": "This paper presents our task-oriented dialog system UBAR which models task-oriented dialogs on a dialog session level.  Specifically, UBAR is acquired by fine-tuning the large pre-trained unidirectional language model GPT-2 on the sequence of the entire dialog session which is composed of user utterance, belief state, database result, system act, and system response of every dialog turn. Additionally, UBAR is evaluated in a more realistic setting, where its dialog context has access to user utterances and all content it generated such as belief states, system acts, and system responses.  Experimental results on the MultiWOZ datasets show that UBAR achieves state-of-the-art performances in multiple settings, improving the combined score of response generation, policy optimization, and end-to-end modeling by 4.7, 3.5, and 9.4 points respectively. Thorough analyses demonstrate that the session-level training sequence formulation and the generated dialog context are essential for UBAR to operate as a fully end-to-end task-oriented dialog system in real life.   We also examine the transfer ability of UBAR to new domains with limited data and provide visualization and a case study to illustrate the advantages of UBAR in modeling on a dialog session level",
    "volume": "main",
    "checked": true,
    "id": "63169665bd592fb818678c47644b29302877d50e",
    "citation_count": 63
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17675": {
    "title": "Open Domain Dialogue Generation with Latent Images",
    "abstract": "We consider grounding open domain dialogues with images. Existing work assumes that both an image and a textual context are available, but image-grounded dialogues by nature are more difficult to obtain than textual dialogues. Thus, we propose learning a response generation model with both image-grounded dialogues and textual dialogues by assuming that the visual scene information at the time of a conversation can be represented by an image, and trying to recover the latent images of the textual dialogues through text-to-image generation techniques. The likelihood of the two types of dialogues is then formulated by a response generator and an image reconstructor that are learned within a conditional variational auto-encoding framework. Empirical studies are conducted in both image-grounded conversation and text-based conversation. In the first scenario, image-grounded dialogues, especially under a low-resource setting, can be effectively augmented by textual dialogues with latent images; while in the second scenario, latent images can enrich the content of responses and at the same time keep them relevant to contexts",
    "volume": "main",
    "checked": true,
    "id": "07411c725cff489da465ed14b99c9d113006aa6c",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17676": {
    "title": "Adversarial Language Games for Advanced Natural Language Intelligence",
    "abstract": "We study the problem of adversarial language games, in which multiple agents with conflicting goals compete with each other via natural language interactions. While adversarial language games are ubiquitous in human activities, little attention has been devoted to this field in natural language processing. In this work, we propose a challenging adversarial language game called Adversarial Taboo as an example, in which an attacker and a defender compete around a target word. The attacker is tasked with inducing the defender to utter the target word invisible to the defender, while the defender is tasked with detecting the target word before being induced by the attacker. In Adversarial Taboo, a successful attacker and defender need to hide or infer the intention, and induce or defend during conversations. This requires several advanced language abilities, such as adversarial pragmatic reasoning and goal-oriented language interactions in open domain, which will facilitate many downstream NLP tasks. To instantiate the game, we create a game environment and a competition platform. Comprehensive experiments on several baseline attack and defense strategies show promising and interesting results, based on which we discuss some directions for future research",
    "volume": "main",
    "checked": true,
    "id": "8a9a798c56fc83858d7ace0352606d73aeaa204d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17677": {
    "title": "Contrastive Triple Extraction with Generative Transformer",
    "abstract": "Triple extraction is an essential task in information extraction for natural language processing and knowledge graph construction. In this paper, we revisit the end-to-end triple extraction task for sequence generation. Since generative triple extraction may struggle to capture long-term dependencies and generate unfaithful triples, we introduce a novel model, contrastive triple extraction with a generative transformer. Specifically, we introduce a single shared transformer module for encoder-decoder-based generation. To generate faithful results, we propose a novel triplet contrastive training object. Moreover, we introduce two mechanisms to further improve model performance (i.e., batch-wise dynamic attention-masking and triple-wise calibration). Experimental results on three datasets (i.e., NYT, WebNLG, and MIE) show that our approach achieves better performance than that of baselines",
    "volume": "main",
    "checked": true,
    "id": "137c719c3e51ed65dcb3a8db373680021b643d45",
    "citation_count": 44
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17678": {
    "title": "Unanswerable Question Correction in Question Answering over Personal Knowledge Base",
    "abstract": "People often encounter situations where they need to recall past experiences from their daily life. In this paper, we aim to construct a question answering system that enables human to query their past experiences over personal knowledge base. Previous works on knowledge base question answering focus on finding answers for answerable questions. In the real world applications, however, people often muddle up facts and ask those questions that cannot be answered with knowledge base. This work presents a novel system consisting of question answering model and question generation model. It not only answers answerable questions, but also corrects unanswerable questions if necessary. Our question answering model recognizes the question that is inconsistent with the state of the personal knowledge base and suggests facts that can form a feasible question. Then, the facts are converted to an answerable question by the question generation model. For refining question, we propose a question generation model based on the reinforcement learning (RL) with question editing mechanism. Experimental results show that our proposed system is effective for correcting unanswerable questions in personal knowledge base question answering",
    "volume": "main",
    "checked": true,
    "id": "e0dfd6821c34911ca0c4052b9899564d603d86b5",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17679": {
    "title": "Simpson's Bias in NLP Training",
    "abstract": "In most machine learning tasks, we evaluate a model M on a given data population S by measuring a population-level metric F(S;M). Examples of such evaluation metric F include precision/recall for (binary) recognition, the F1 score for multi-class classification, and the BLEU metric for language generation. On the other hand, the model M is trained by optimizing a sample-level loss G(S_t; M) at each learning step t, where S_t is a subset of S (a.k.a. the mini-batch). Popular choices of G include cross-entropy loss, the Dice loss, and sentence-level BLEU scores. A fundamental assumption behind this paradigm is that the mean value of the sample-level loss G, if averaged over all possible samples, should effectively represent the population-level metric F of the task, such as, that E[ G(S_t; M) ] ~ F(S; M).  In this paper, we systematically investigate the above assumption in several NLP tasks. We show, both theoretically and experimentally, that some popular designs of the sample-level loss G may be inconsistent with the true population-level metric F of the task, so that models trained to optimize the former can be substantially sub-optimal to the latter, a phenomenon we call it, Simpson's bias, due to its deep connections with the classic paradox known as Simpson's reversal paradox in statistics and social sciences",
    "volume": "main",
    "checked": true,
    "id": "c115e75bd7f17fcf76ad9b1809e445713ff359ff",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17680": {
    "title": "Reinforced Multi-Teacher Selection for Knowledge Distillation",
    "abstract": "In natural language processing (NLP) tasks, slow inference speed and huge footprints in GPU usage remain the bottleneck of applying pre-trained deep models in production. As a popular method for model compression, knowledge distillation transfers knowledge from one or multiple large (teacher) models to a small (student) model. When multiple teacher models are available in distillation, the state-of-the-art methods assign a fixed weight to a teacher model in the whole distillation. Furthermore, most of the existing methods allocate an equal weight to every teacher model. In this paper, we observe that, due to the complexity of training examples and the differences in student model capability, learning differentially from teacher models can lead to better performance of student models distilled. We systematically develop a reinforced method to dynamically assign weights to teacher models for different training instances and optimize the performance of student model. Our extensive experimental results on several NLP tasks clearly verify the feasibility and effectiveness of our approach",
    "volume": "main",
    "checked": true,
    "id": "63c966e28b471551f2d9c7a5b4c639de6c8953b0",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17681": {
    "title": "What's the Best Place for an AI Conference, Vancouver or _______: Why Completing Comparative Questions is Difficult",
    "abstract": "Although large neural language models (LMs) like BERT can be finetuned to yield state-of-the-art results on many NLP tasks, it is often unclear what these models actually learn. Here we study using such LMs to fill in entities in human-authored comparative questions, like ``Which country is older, India or _____?''---i.e., we study the ability of neural LMs to ask (not answer) reasonable questions. We show that accuracy in this fill-in-the-blank task is well-correlated with human judgements of whether a question is reasonable, and that these models can be trained to achieve nearly human-level performance in completing comparative questions in three different subdomains. However, analysis shows that what they learn fails to model any sort of broad notion of which entities are semantically comparable or similar---instead the trained models are very domain-specific, and performance is highly correlated with co-occurrences between specific entities observed in the training set. This is true both for models that are pretrained on general text corpora, as well as models trained on a large corpus of comparison questions. Our study thus reinforces recent results on the difficulty of making claims about a deep model's world knowledge or linguistic competence based on performance on specific benchmark problems. We make our evaluation datasets publicly available to foster future research on complex understanding and reasoning in such models at standards of human interaction",
    "volume": "main",
    "checked": true,
    "id": "8b652c4d7a8d5836925ce0fe28a91dc661778524",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17682": {
    "title": "Probing Product Description Generation via Posterior Distillation",
    "abstract": "In product description generation (PDG), the user-cared aspect is critical for the recommendation system, which can not only improve user's experiences but also obtain more clicks. High-quality customer reviews can be considered as an ideal source to mine user-cared aspects. However, in reality, a large number of new products (known as long-tailed commodities) cannot gather sufficient amount of customer reviews, which brings a big challenge in the product description generation task. Existing works tend to generate the product description solely based on item information, i.e., product attributes or title words, which leads to tedious contents and cannot attract customers effectively. To tackle this problem, we propose an adaptive posterior network based on Transformer architecture that can utilize user-cared information from customer reviews. Specifically, we first extend the self-attentive Transformer encoder to encode product titles and attributes. Then, we apply an adaptive posterior distillation module to utilize useful review information, which integrates user-cared aspects to the generation process. Finally, we apply a Transformer-based decoding phase with copy mechanism to automatically generate the product description. Besides, we also collect a large-scare Chinese product description dataset to support our work and further research in this field. Experimental results show that our model is superior to traditional generative models in both automatic indicators and human evaluation",
    "volume": "main",
    "checked": true,
    "id": "29e815c583f62735821e5fab1c743347e8cb3bcc",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17683": {
    "title": "Meta-Curriculum Learning for Domain Adaptation in Neural Machine Translation",
    "abstract": "Meta-learning has been sufficiently validated to be beneficial for low-resource neural machine translation (NMT). However, we find that meta-trained NMT fails to improve the translation performance of the domain unseen at the meta-training stage. In this paper, we aim to alleviate this issue by proposing a novel meta-curriculum learning for domain adaptation in NMT. During meta-training, the NMT first learns the similar curricula from each domain to avoid falling into a bad local optimum early, and finally learns the curricula of individualities to improve the model robustness for learning domain-specific knowledge. Experimental results on 10 different low-resource domains show that meta-curriculum learning can improve the translation performance of both familiar and unfamiliar domains. All the codes and data are freely available at https://github.com/NLP2CT/Meta-Curriculum",
    "volume": "main",
    "checked": true,
    "id": "b794bafd6e15609fd52bdb5753d9b1b6287a0b8f",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17684": {
    "title": "UWSpeech: Speech to Speech Translation for Unwritten Languages",
    "abstract": "Existing speech to speech translation systems heavily rely on the text of target language: they usually translate source language either to target text and then synthesize target speech from text, or directly to target speech with target text for auxiliary training. However, those methods cannot be applied to unwritten target languages, which have no written text or phoneme available. In this paper, we develop a translation system for unwritten languages, named as UWSpeech, which converts target unwritten speech into discrete tokens with a converter, and then translates source-language speech into target discrete tokens with a translator, and finally synthesizes target speech from target discrete tokens with an inverter. We propose a method called XL-VAE, which enhances vector quantized variational autoencoder (VQ-VAE) with cross-lingual (XL) speech recognition, to train the converter and inverter of UWSpeech jointly. Experiments on Fisher Spanish-English conversation translation dataset show that UWSpeech outperforms direct translation and VQ-VAE baseline by about 16 and 10 BLEU points respectively, which demonstrate the advantages and potentials of UWSpeech",
    "volume": "main",
    "checked": true,
    "id": "b72800358ed41847d181f9a53e88ec9f9f389308",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17685": {
    "title": "Building Interpretable Interaction Trees for Deep NLP Models",
    "abstract": "This paper proposes a method to disentangle and quantify interactions among words that are encoded inside a DNN for natural language processing. We construct a tree to encode salient interactions extracted by the DNN. Six metrics are proposed to analyze properties of interactions between constituents in a sentence. The interaction is defined based on Shapley values of words, which are considered as an unbiased estimation of word contributions to the network prediction. Our method is used to quantify word interactions encoded inside the BERT, ELMo, LSTM, CNN, and Transformer networks. Experimental results have provided a new perspective to understand these DNNs, and have demonstrated the effectiveness of our method",
    "volume": "main",
    "checked": true,
    "id": "8fc27b2f4c118c50e208a563835fd5e52a522980",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17686": {
    "title": "Multi-modal Multi-label Emotion Recognition with Heterogeneous Hierarchical Message Passing",
    "abstract": "As an important research issue in affective computing community, multi-modal emotion recognition has become a hot topic in the last few years. However, almost all existing studies perform multiple binary classification for each emotion with focus on complete time series data. In this paper, we focus on multi-modal emotion recognition in a multi-label scenario. In this scenario, we consider not only the label-to-label dependency, but also the feature-to-label and modality-to-label dependencies. Particularly, we propose a heterogeneous hierarchical message passing network to effectively model above dependencies. Furthermore, we propose a new multi-modal multi-label emotion dataset based on partial time-series content to show predominant generalization of our model. Detailed evaluation demonstrates the effectiveness of our approach",
    "volume": "main",
    "checked": true,
    "id": "cf65400ca1c8865b2b767b59fc5fdb14ddf7fbc5",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17687": {
    "title": "Multi-modal Graph Fusion for Named Entity Recognition with Targeted Visual Guidance",
    "abstract": "Multi-modal named entity recognition (MNER) aims to discover named entities in free text and classify them into pre-defined types with images. However, dominant MNER models do not fully exploit fine-grained semantic correspondences between semantic units of different modalities, which have the potential to refine multi-modal representation learning. To deal with this issue, we propose a unified multi-modal graph fusion (UMGF) approach for MNER. Specifically, we first represent the input sentence and image using a unified multi-modal graph, which captures various semantic relationships between multi-modal semantic units (words and visual objects). Then, we stack multiple graph-based multi-modal fusion layers that iteratively perform semantic interactions to learn node representations. Finally, we achieve an attention-based multi-modal representation for each word and perform entity labeling with a CRF decoder. Experimentation on the two benchmark datasets demonstrates the superiority of our MNER model",
    "volume": "main",
    "checked": true,
    "id": "0d6f36467bebc829717c2fcca856031b51c706b4",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17688": {
    "title": "Accelerating Neural Machine Translation with Partial Word Embedding Compression",
    "abstract": "Large model size and high computational complexity prevent the neural machine translation (NMT) models from being deployed to low resource devices (e.g. mobile phones). Due to the large vocabulary, a large storage memory is required for the word embedding matrix in NMT models, in the meantime, high latency is introduced when constructing the word probability distribution. Based on reusing the word embedding matrix in the softmax layer, it is possible to handle the two problems brought by large vocabulary at the same time. In this paper, we propose Partial Vector Quantization (P-VQ) for NMT models, which can both compress the word embedding matrix and accelerate word probability prediction in the softmax layer. With P-VQ, the word embedding matrix is split into two low dimensional matrices, namely the shared part and the exclusive part. We compress the shared part by vector quantization and leave the exclusive part unchanged to maintain the uniqueness of each word. For acceleration, in the softmax layer, we replace most of the multiplication operations with the efficient looking-up operations based on our compression to reduce the computational complexity. Furthermore, we adopt curriculum learning and compact the word embedding matrix gradually to improve the compression quality. Experimental results on the Chinese-to-English translation task show that our method can reduce 74.35% of parameters of the word embedding and 74.42% of the FLOPs of the softmax layer. Meanwhile, the average BLEU score on the WMT test sets only drops 0.04",
    "volume": "main",
    "checked": true,
    "id": "1949dff192e4d65af3bce36fca0c20c1f2344bf8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17689": {
    "title": "Discovering New Intents with Deep Aligned Clustering",
    "abstract": "Discovering new intents is a crucial task in dialogue systems. Most existing methods are limited in transferring the prior knowledge from known intents to new intents. These methods also have difficulties in providing high-quality supervised signals to learn clustering-friendly features for grouping unlabeled intents. In this work, we propose an effective method (Deep Aligned Clustering) to discover new intents with the aid of limited known intent data. Firstly, we leverage a few labeled known intent samples as prior knowledge to pre-train the model. Then, we perform k-means to produce cluster assignments as pseudo-labels. Moreover, we propose an alignment strategy to tackle the label inconsistency problem during clustering assignments. Finally, we learn the intent representations under the supervision of the aligned pseudo-labels. With an unknown number of new intents, we predict the number of intent categories by eliminating low-confidence intent-wise clusters. Extensive experiments on two benchmark datasets show that our method is more robust and achieves substantial improvements over the state-of-the-art methods",
    "volume": "main",
    "checked": true,
    "id": "00372193b6a5844c274c8d97097589c7d6a412c4",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17690": {
    "title": "Deep Open Intent Classification with Adaptive Decision Boundary",
    "abstract": "Open intent classification is a challenging task in dialogue systems. On the one hand, it should ensure the quality of known intent identification. On the other hand, it needs to detect the open (unknown) intent without prior knowledge. Current models are limited in finding the appropriate decision boundary to balance the performances of both known intents and the open intent. In this paper, we propose a post-processing method to learn the adaptive decision boundary (ADB) for open intent classification. We first utilize the labeled known intent samples to pre-train the model. Then, we automatically learn the adaptive spherical decision boundary for each known class with the aid of well-trained features. Specifically, we propose a new loss function to balance both the empirical risk and the open space risk. Our method does not need open intent samples and is free from modifying the model architecture. Moreover, our approach is surprisingly insensitive with less labeled data and fewer known intents. Extensive experiments on three benchmark datasets show that our method yields significant improvements compared with the state-of-the-art methods",
    "volume": "main",
    "checked": true,
    "id": "25353f47c8699611b6ed008150d75cf54e74d330",
    "citation_count": 28
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17691": {
    "title": "Writing Polishment with Simile: Task, Dataset and A Neural Approach",
    "abstract": "A simile is a figure of speech that directly makes a comparison, showing similarities between two different things, e.g. ``Reading papers can be dull sometimes,like watching grass grow\". Human writers often interpolate appropriate similes into proper locations of the plain text to vivify their writings. However, none of existing work has explored neural simile interpolation, including both locating and generation. In this paper, we propose a new task of Writing Polishment with Simile (WPS) to investigate whether machines are able to polish texts with similes as we human do. Accordingly, we design a two-staged Locate&Gen model based on transformer architecture. Our model firstly locates where the simile interpolation should happen, and then generates a location-specific simile. We also release a large-scale Chinese Simile (CS) dataset containing 5 million similes with context. The experimental results demonstrate the feasibility of WPS task and shed light on the future research directions towards better automatic text polishment",
    "volume": "main",
    "checked": true,
    "id": "1a9c195c97036aeb98cab02081d656ed480198b2",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17692": {
    "title": "Continuous Self-Attention Models with Neural ODE Networks",
    "abstract": "Stacked self-attention models receive widespread attention, due to its ability of capturing global dependency among words. However, the stacking of many layers and components generates huge parameters, leading to low parameter efficiency. In response to this issue, we propose a lightweight architecture named Continuous Self-Attention models with neural ODE networks (CSAODE). In CSAODE, continuous dynamical models (i.e., neural ODEs) are coupled with our proposed self-attention block to form a self-attention ODE solver. This solver continuously calculates and optimizes the hidden states via only one layer of parameters to improve the parameter efficiency. In addition, we design a novel accelerated continuous dynamical model to reduce computing costs, and integrate it in CSAODE. Moreover, since the original self-attention ignores local information, CSAODE makes use of N-gram convolution to encode local representations, and a fusion layer with only two trainable scalars are designed for generating sentence vectors. We perform a series of experiments on text classification, neural language inference (NLI) and text matching tasks. With fewer parameters, CSAODE outperforms state-of-the-art models on text classification tasks (e.g., 1.3% accuracy improved on SUBJ task), and has competitive performances for NLI and text matching tasks as well",
    "volume": "main",
    "checked": true,
    "id": "a95b0b5ddca071540c275a59af9118379be457ce",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17693": {
    "title": "TaLNet: Voice Reconstruction from Tongue and Lip Articulation with Transfer Learning from Text-to-Speech Synthesis",
    "abstract": "This paper presents TaLNet, a model for voice reconstruction with ultrasound tongue and optical lip videos as inputs. TaLNet is based on an encoder-decoder architecture. Separate encoders are dedicated to processing the tongue and lip data streams respectively. The decoder predicts acoustic features conditioned on encoder outputs and speaker codes.To mitigate for having only relatively small amounts of dual articulatory-acoustic data available for training, and since our task here shares with text-to-speech (TTS) the common goal of speech generation, we propose a novel transfer learning strategy to exploit the much larger amounts of acoustic-only data available to train TTS models. For this, a Tacotron 2 TTS model is first trained, and then the parameters of its decoder are transferred to the TaLNet decoder. We have evaluated our approach on an unconstrained multi-speaker voice recovery task. Our results show the effectiveness of both the proposed model and the transfer learning strategy. Speech reconstructed using our proposed method significantly outperformed all baselines (DNN, BLSTM and without transfer learning) in terms of both naturalness and intelligibility. When using an ASR model decoding the recovery speech, the WER of our proposed method is relatively reduced over 30% compared to baselines",
    "volume": "main",
    "checked": true,
    "id": "4eeaf4ee24becd2bb134ac8c1bbdcb1c82ebd462",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17694": {
    "title": "Making the Relation Matters: Relation of Relation Learning Network for Sentence Semantic Matching",
    "abstract": "Sentence semantic matching is one of the fundamental tasks in natural language processing, which requires an agent to determine the semantic relation among input sentences. Recently, deep neural networks have achieved impressive performance in this area, especially BERT. Despite the effectiveness of these models, most of them treat output labels as meaningless one-hot vectors, underestimating the semantic information and guidance of relations that these labels reveal, especially for tasks with a small number of labels. To address this problem, we propose a Relation of Relation Learning Network (R2-Net) for sentence semantic matching. Specifically, we first employ BERT to encode the input sentences from a global perspective. Then a CNN-based encoder is designed to capture keywords and phrase information from a local perspective. To fully leverage labels for better relation information extraction, we introduce a self-supervised relation of relation classification task for guiding R2-Net to consider more about labels. Meanwhile, a triplet loss is employed to distinguish the intra-class and inter-class relations in a finer granularity. Empirical experiments on two sentence semantic matching tasks demonstrate the superiority of our proposed model. As a byproduct, we have released the codes to facilitate other researches",
    "volume": "main",
    "checked": true,
    "id": "78732346553ae992d316c5c5d9c8702bf5756308",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17695": {
    "title": "MERL: Multimodal Event Representation Learning in Heterogeneous Embedding Spaces",
    "abstract": "Previous work has shown the effectiveness of using event representations for tasks such as script event prediction and stock market prediction. It is however still challenging to learn the subtle semantic differences between events based solely on textual descriptions of events often represented as (subject, predicate, object) triples. As an alternative, images offer a more intuitive way of understanding event semantics. We observe that event described in text and in images show different abstraction levels and therefore should be projected onto heterogeneous embedding spaces, as opposed to what have been done in previous approaches which project signals from different modalities onto a homogeneous space. In this paper, we propose a Multimodal Event Representation Learning framework (MERL) to learn event representations based on both text and image modalities simultaneously. Event textual triples are projected as Gaussian density embeddings by a dual-path Gaussian triple encoder, while event images are projected as point embeddings by a visual event component-aware image encoder. Moreover, a novel score function motivated by statistical hypothesis testing is introduced to coordinate two embedding spaces. Experiments are conducted on various multimodal event-related tasks and results show that MERL outperforms a number of unimodal and multimodal baselines, demonstrating the effectiveness of the proposed framework",
    "volume": "main",
    "checked": true,
    "id": "1a384c1867c0d5c1a06337f536c57f8126bad994",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17696": {
    "title": "Future-Guided Incremental Transformer for Simultaneous Translation",
    "abstract": "Simultaneous translation (ST) starts translations synchronously while reading source sentences, and is used in many online scenarios. The previous wait-k policy is concise and achieved good results in ST. However, wait-k policy faces two weaknesses: low training speed caused by the recalculation of hidden states and lack of future source information to guide training. For the low training speed, we propose an incremental Transformer with an average embedding layer (AEL) to accelerate the speed of calculation of the hidden states during training. For future-guided training, we propose a conventional Transformer as the teacher of the incremental Transformer, and try to invisibly embed some future information in the model through knowledge distillation. We conducted experiments on Chinese-English and German-English simultaneous translation tasks and compared with the wait-k policy to evaluate the proposed method. Our method can effectively increase the training speed by about 28 times on average at different k and implicitly embed some predictive abilities in the model, achieving better translation quality than wait-k baseline",
    "volume": "main",
    "checked": true,
    "id": "cc5afa8f1d35ec8fb3179bf760552da496d2838f",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17697": {
    "title": "Semantics-Aware Inferential Network for Natural Language Understanding",
    "abstract": "For natural language understanding tasks, either machine reading comprehension or natural language inference, both semantics-aware and inference are favorable features of the concerned modeling for better understanding performance. Thus we propose a Semantics-Aware Inferential Network (SAIN) to meet such a motivation. Taking explicit contextualized semantics as a complementary input, the inferential module of SAIN enables a series of reasoning steps over semantic clues through an attention mechanism. By stringing these steps, the inferential network effectively learns to perform iterative reasoning which incorporates both explicit semantics and contextualized representations. In terms of well pre-trained language models as front-end encoder, our model achieves significant improvement on 11 tasks including machine reading comprehension and natural language inference",
    "volume": "main",
    "checked": true,
    "id": "a11d30682c950a1240552fce03f79407dc5957be",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17698": {
    "title": "Learning to Check Contract Inconsistencies",
    "abstract": "Contract consistency is important in ensuring the legal validity of the contract. In many scenarios, a contract is written by filling the blanks in a precompiled form. Due to carelessness, two blanks that should be filled with the same (or different) content may be incorrectly filled with different (or same) content. This will result in the issue of contract inconsistencies, which may severely impair the legal validity of the contract. Traditional methods to address this issue mainly rely on manual contract review, which is labor-intensive and costly. In this work, we formulate a novel Contract Inconsistency Checking (CIC) problem, and design an end-to-end framework, called Pair-wise Blank Resolution (PBR), to solve the CIC problem with high accuracy. Our PBR model contains a novel BlankCoder to address the challenge of modeling meaningless blanks. BlankCoder adopts a two-stage attention mechanism that adequately associates a meaningless blank with its relevant descriptions while avoiding the incorporation of irrelevant context words. Experiments conducted on real-world datasets show the promising performance of our method with a balanced accuracy of 94.05% and an F1 score of 90.90% in the CIC problem",
    "volume": "main",
    "checked": true,
    "id": "890c7548aab4152223235eeff6c067bcccd5f54e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17699": {
    "title": "Self-supervised Bilingual Syntactic Alignment for Neural Machine Translation",
    "abstract": "While various neural machine translation (NMT) methods have integrated mono-lingual syntax knowledge into the linguistic representation of sequence-to-sequence, no research is available on aligning the syntactic structures of target language with the corresponding source language syntactic structures. This work shows the first attempt of a source-target bilingual syntactic alignment approach SyntAligner by mutual information maximization-based self-supervised neural deep modeling. Building on the word alignment for NMT, our SyntAligner firstly aligns the syntactic structures of source and target sentences and then maximizes their mutual dependency by introducing a lower bound on their mutual information. In SyntAligner, the syntactic structure of span granularity is represented by transforming source or target word hidden state into a source or target syntactic span vector. A border-sensitive span attention mechanism then captures the correlation between the source and target syntactic span vectors, which also captures the self-attention between span border-words as alignment bias. Lastly, a self-supervised bilingual syntactic mutual information maximization-based learning objective dynamically samples the aligned syntactic spans to maximize their mutual dependency. Experiment results on three typical NMT tasks: WMT'14 English to German, IWSLT'14 German to English, and NC'11 English to French show the SyntAligner effectiveness and universality of syntactic alignment",
    "volume": "main",
    "checked": true,
    "id": "7e729166d7cd6b5550bbaa7e80658b06c2f4afb9",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17700": {
    "title": "Graph-Based Tri-Attention Network for Answer Ranking in CQA",
    "abstract": "In community-based question answering (CQA) platforms, automatic answer ranking for a given question is critical for finding potentially popular answers in early times. The mainstream approaches learn to generate answer ranking scores based on the matching degree between question and answer representations as well as the influence of respondents. However, they encounter two main limitations: (1) Correlations between answers in the same question are often overlooked. (2) Question and respondent representations are built independently of specific answers before affecting answer representations. To address the limitations, we devise a novel graph-based tri-attention network, namely GTAN, which has two innovations. First, GTAN proposes to construct a graph for each question and learn answer correlations from each graph through graph neural networks (GNNs). Second, based on the representations learned from GNNs, an alternating tri-attention method is developed to alternatively build target-aware respondent representations, answer-specific question representations, and context-aware answer representations by attention computation. GTAN finally integrates the above representations to generate answer ranking scores. Experiments on three real-world CQA datasets demonstrate GTAN significantly outperforms state-of-the-art answer ranking methods, validating the rationality of the network architecture",
    "volume": "main",
    "checked": true,
    "id": "18981e60887244d898f00ef60738eaeae1453f76",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17701": {
    "title": "Circles are like Ellipses, or Ellipses are like Circles? Measuring the Degree of Asymmetry of Static and Contextual Word Embeddings and the Implications to Representation Learning",
    "abstract": "Human judgments of word similarity have been a popular method of evaluating the quality of word embedding. But it fails to measure the geometry properties such as asymmetry. For example, it is more natural to say ``Ellipses are like Circles'' than ``Circles are like Ellipses''. Such asymmetry has been observed from the word evocation experiment, where one word is used to recall another. This association data have been understudied for measuring embedding quality. In this paper, we use three well-known evocation datasets for the purpose and study both static embedding as well as contextual embedding, such as BERT. To fight for the dynamic nature of BERT embedding, we probe BERT's conditional probabilities as a language model, using a large number of Wikipedia contexts to derive a theoretically justifiable Bayesian asymmetry score. The result shows that the asymmetry judgment and similarity judgments disagree, and asymmetry judgment aligns with its strong performance on ``extrinsic evaluations''. This is the first time we can show contextual embeddings's strength on intrinsic evaluation, and the asymmetry judgment provides a new perspective to evaluate contextual embedding and new insights for representation learning",
    "volume": "main",
    "checked": true,
    "id": "3e4c16b56dccb1685e8cb0c973242792ce8f8fe3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17702": {
    "title": "Denoising Distantly Supervised Named Entity Recognition via a Hypergeometric Probabilistic Model",
    "abstract": "Denoising is the essential step for distant supervision based named entity recognition. Previous denoising methods are mostly based on instance-level confidence statistics, which ignore the variety of the underlying noise distribution on different datasets and entity types. This makes them difficult to be adapted to high noise rate settings. In this paper, we propose Hypergeometric Learning (HGL), a denoising algorithm for distantly supervised NER that takes both noise distribution and instance-level confidence into consideration. Specifically, during neural network training, we naturally model the noise samples in each batch following a hypergeometric distribution parameterized by the noise-rate. Then each instance in the batch is regarded as either correct or noisy one according to its label confidence derived from previous training step, as well as the noise distribution in this sampled batch. Experiments show that HGL can effectively denoise the weakly-labeled data retrieved from distant supervision, and therefore results in significant improvements on the trained models",
    "volume": "main",
    "checked": true,
    "id": "72857e8f336c53124acd469190f400466d1f7cfd",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17703": {
    "title": "Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes",
    "abstract": "High-quality dialogue-summary paired data is expensive to produce and domain-sensitive, making abstractive dialogue summarization a challenging task. In this work, we propose the first unsupervised abstractive dialogue summarization model for tete-a-tetes (SuTaT). Unlike standard text summarization, a dialogue summarization method should consider the multi-speaker scenario where the speakers have different roles, goals, and language styles. In a tete-a-tete, such as a customer-agent conversation, SuTaT aims to summarize for each speaker by modeling the customer utterances and the agent utterances separately while retaining their correlations. SuTaT consists of a conditional generative module and two unsupervised summarization modules. The conditional generative module contains two encoders and two decoders in a variational autoencoder framework where the dependencies between two latent spaces are captured. With the same encoders and decoders, two unsupervised summarization modules equipped with sentence-level self-attention mechanisms generate summaries without using any annotations. Experimental results show that SuTaT is superior on unsupervised dialogue summarization for both automatic and human evaluations, and is capable of dialogue classification and single-turn conversation generation",
    "volume": "main",
    "checked": true,
    "id": "b4b8ae8cb3b7abaffa242d190b04296f7ed9304b",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17704": {
    "title": "News Content Completion with Location-Aware Image Selection",
    "abstract": "News, as one of the fundamental social media types, typically contains both texts and images. Image selection, which involves choosing appropriate images according to some specified contexts, is crucial for formulating good news. However, it presents two challenges: where to place images and which images to use. The difficulties associated with this where-which problem lie in the fact that news typically contains linguistically rich text that delivers complex information and more than one image. In this paper, we propose a novel end-to-end two-stage framework to address these issues comprehensively. In the first stage, we identify key information in news by using location embeddings, which represent the local contextual information of each candidate location for image insertion. Then, in the second stage, we thoroughly examine the candidate images and select the most context-related ones to insert into each location identified in the first stage. We also introduce three insertion strategies to formulate different scenarios influencing the image selection procedure. Extensive experiments demonstrate the consistent superiority of the proposed framework in image selection",
    "volume": "main",
    "checked": true,
    "id": "b55a03afc6f8e6b27db626a79ff4db00b3881086",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17705": {
    "title": "Retrospective Reader for Machine Reading Comprehension",
    "abstract": "Machine reading comprehension (MRC) is an AI challenge that requires machines to determine the correct answers to questions based on a given passage. MRC systems must not only answer questions when necessary but also tactfully abstain from answering when no answer is available according to the given passage. When unanswerable questions are involved in the MRC task, an essential verification module called verifier is especially required in addition to the encoder, though the latest practice on MRC modeling still mostly benefits from adopting well pre-trained language models as the encoder block by only focusing on the \"reading\". This paper devotes itself to exploring better verifier design for the MRC task with unanswerable questions. Inspired by how humans solve reading comprehension questions, we proposed a retrospective reader (Retro-Reader) that integrates two stages of reading and verification strategies: 1) sketchy reading that briefly investigates the overall interactions of passage and question, and yields an initial judgment; 2) intensive reading that verifies the answer and gives the final prediction. The proposed reader is evaluated on two benchmark MRC challenge datasets SQuAD2.0 and NewsQA, achieving new state-of-the-art results. Significance tests show that our model is significantly better than strong baselines",
    "volume": "main",
    "checked": true,
    "id": "8d00049c345b9c8cc76ea2ea2565f8bb69f6b683",
    "citation_count": 144
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17706": {
    "title": "Dynamic Modeling Cross- and Self-Lattice Attention Network for Chinese NER",
    "abstract": "Word-character lattice models have been proved to be effective for Chinese named entity recognition (NER), in which word boundary information is fused into character sequences for enhancing character representations. However, prior approaches have only used simple methods such as feature concatenation or position encoding to integrate word-character lattice information, but fail to capture fine-grained correlations in word-character spaces. In this paper, we propose DCSAN, a Dynamic Cross- and Self-lattice Attention Network that aims to model dense interactions over word-character lattice structure for Chinese NER. By carefully combining cross-lattice and self-lattice attention modules with gated word-character semantic fusion unit, the network can explicitly capture fine-grained correlations across different spaces (e.g., word-to-character and character-to-character), thus significantly improving model performance. Experiments on four Chinese NER datasets show that DCSAN obtains stateof-the-art results as well as efficiency compared to several competitive approaches",
    "volume": "main",
    "checked": true,
    "id": "7ca77377e5f4a2df9f6a02192f26e81ce19517db",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17707": {
    "title": "A Unified Multi-Task Learning Framework for Joint Extraction of Entities and Relations",
    "abstract": "Joint extraction of entities and relations focuses on detecting entity pairs and their relations simultaneously with a unified model. Based on the extraction order, previous works mainly solve this task through relation-last, relation-first and relation-middle manner. However, these methods still suffer from the template-dependency, non-entity detection and non-predefined relation prediction problem. To overcome these challenges, in this paper, we propose a unified multi-task learning framework to divide the task into three interacted sub-tasks. Specifically, we first introduce the type-attentional method for subject extraction to provide prior type information explicitly. Then, the subject-aware relation prediction is presented to select useful relations based on the combination of global and local semantics. Third, we propose a question generation based QA method for object extraction to obtain diverse queries automatically. Notably, our method detects subjects or objects without relying on NER models and thus it is capable of dealing with the non-entity scenario. Finally, three sub-tasks are integrated into a unified model through parameter sharing. Extensive experiments demonstrate that the proposed framework outperforms all the baseline methods on two benchmark datasets, and further achieve excellent performance for non-predefined relations",
    "volume": "main",
    "checked": true,
    "id": "8758f3c992c49b952d253acc9bdbdf5531616862",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17708": {
    "title": "LIREx: Augmenting Language Inference with Relevant Explanations",
    "abstract": "Natural language explanations (NLEs) are a special form of data annotation in which annotators identify rationales (most significant text tokens) when assigning labels to data instances, and write out explanations for the labels in natural language based on the rationales. NLEs have been shown to capture human reasoning better, but not as beneficial for natural language inference (NLI). In this paper, we analyze two primary flaws in the way NLEs are currently used to train explanation generators for language inference tasks. We find that the explanation generators do not take into account the variability inherent in human explanation of labels, and that the current explanation generation models generate spurious explanations. To overcome these limitations, we propose a novel framework, LIREx, that incorporates both a rationale-enabled explanation generator and an instance selector to select only relevant, plausible NLEs to augment NLI models. When evaluated on the standardized SNLI data set, LIREx achieved an accuracy of 91.87%, an improvement of 0.32 over the baseline and matching the best-reported performance on the data set. It also achieves significantly better performance than previous studies when transferred to the out-of-domain MultiNLI data set. Qualitative analysis shows that LIREx generates flexible, faithful, and relevant NLEs that allow the model to be more robust to spurious explanations. The code is available at https://github.com/zhaoxy92/LIREx",
    "volume": "main",
    "checked": true,
    "id": "2f4ea6e0d2a694020c0c5f14843ad39772e13396",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17709": {
    "title": "Automatic Curriculum Learning With Over-repetition Penalty for Dialogue Policy Learning",
    "abstract": "Dialogue policy learning based on reinforcement learning is difficult to be applied to real users to train dialogue agents from scratch because of the high cost. User simulators, which choose random user goals for the dialogue agent to train on, have been considered as an affordable substitute for real users. However, this random sampling method ignores the law of human learning, making the learned dialogue policy inefficient and unstable. We propose a novel framework, Automatic Curriculum Learning-based Deep Q-Network (ACL-DQN), which replaces the traditional random sampling method with a teacher policy model to realize the dialogue policy for automatic curriculum learning. The teacher model arranges a meaningful ordered curriculum and automatically adjusts it by monitoring the learning progress of the dialogue agent and the over-repetition penalty without any requirement of prior knowledge. The learning progress of the dialogue agent reflects the relationship between the dialogue agent's ability and the sampled goals' difficulty for sample efficiency. The over-repetition penalty guarantees the sampled diversity. Experiments show that the ACL-DQN significantly improves the effectiveness and stability of dialogue tasks with a statistically significant margin. Furthermore, the framework can be further improved by equipping with different curriculum schedules, which demonstrates that the framework has strong generalizability",
    "volume": "main",
    "checked": true,
    "id": "6a60bf27a3d997d373f7536cb6a6c1abf3561e6a",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17710": {
    "title": "Interactive Speech and Noise Modeling for Speech Enhancement",
    "abstract": "Speech enhancement is challenging because of the diversity of background noise types. Most of the existing methods are focused on modelling the speech rather than the noise. In this paper, we propose a novel idea to model speech and noise simultaneously in a two-branch convolutional neural network, namely SN-Net. In SN-Net, the two branches predict speech and noise, respectively. Instead of information fusion only at the final output layer, interaction modules are introduced at several intermediate feature domains between the two branches to benefit each other. Such an interaction can leverage features learned from one branch to counteract the undesired part and restore the missing component of the other and thus enhance their discrimination capabilities. We also design a feature extraction module, namely residual-convolution-and-attention (RA), to capture the correlations along temporal and frequency dimensions for both the speech and the noises. Evaluations on public datasets show that the interaction module plays a key role in simultaneous modeling and the SN-Net outperforms the state-of-the-art by a large margin on various evaluation metrics. The proposed SN-Net also shows superior performance for speaker separation",
    "volume": "main",
    "checked": true,
    "id": "9511b414fb3a32a9442136e6115f9734ab415f46",
    "citation_count": 25
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17711": {
    "title": "Stylized Dialogue Response Generation Using Stylized Unpaired Texts",
    "abstract": "Generating stylized responses is essential to build intelligent and engaging dialogue systems. However, this task is far from well-explored due to the difficulties of rendering a particular style in coherent responses, especially when the target style is embedded only in unpaired texts that cannot be directly used to train the dialogue model. This paper proposes a stylized dialogue generation method that can capture stylistic features embedded in unpaired texts. Specifically, our method can produce dialogue responses that are both coherent to the given context and conform to the target style. In this study, an inverse dialogue model is first introduced to predict possible posts for the input responses. Then this inverse model is used to generate stylized pseudo dialogue pairs based on these stylized unpaired texts. Further, these pseudo pairs are employed to train the stylized dialogue model with a joint training process. A style routing approach is proposed to intensify stylistic features in the decoder. Automatic and manual evaluations on two datasets demonstrate that our method outperforms competitive baselines in producing coherent and style-intensive dialogue responses",
    "volume": "main",
    "checked": true,
    "id": "0f8a14f42b82b35abbe5d97dca14ec9ab6bf34e1",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17712": {
    "title": "Keyword-Guided Neural Conversational Model",
    "abstract": "We study the problem of imposing conversational goals/keywords on open-domain conversational agents, where the agent is required to lead the conversation to a target keyword smoothly and fast. Solving this problem enables the application of conversational agents in many real-world scenarios, e.g., recommendation and psychotherapy. The dominant paradigm for tackling this problem is to 1) train a next-turn keyword classifier, and 2) train a keyword-augmented response retrieval model. However, existing approaches in this paradigm have two limitations: 1) the training and evaluation datasets for next-turn keyword classification are directly extracted from conversations without human annotations, thus, they are noisy and have low correlation with human judgements, and 2) during keyword transition, the agents solely rely on the similarities between word embeddings to move closer to the target keyword, which may not reflect how humans converse. In this paper, we assume that human conversations are grounded on commonsense and propose a keyword-guided neural conversational model that can leverage external commonsense knowledge graphs (CKG) for both keyword transition and response retrieval. Automatic evaluations suggest that commonsense improves the performance of both next-turn keyword prediction and keyword-augmented response retrieval. In addition, both self-play and human evaluations show that our model produces responses with smoother keyword transition and reaches the target keyword faster than competitive baselines",
    "volume": "main",
    "checked": true,
    "id": "3f8fcf49be5ddd4a950325bc055cc2e159596d6f",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17713": {
    "title": "CARE: Commonsense-Aware Emotional Response Generation with Latent Concepts",
    "abstract": "Rationality and emotion are two fundamental elements of humans. Endowing agents with rationality and emotion has been one of the major milestones in AI. However, in the field of conversational AI, most existing models only specialize in one aspect and neglect the other, which often leads to dull or unrelated responses. In this paper, we hypothesize that combining rationality and emotion into conversational agents can improve response quality. To test the hypothesis, we focus on one fundamental aspect of rationality, i.e., commonsense, and propose CARE, a novel model for commonsense-aware emotional response generation. Specifically, we first propose a framework to learn and construct commonsense-aware emotional latent concepts of the response given an input message and a desired emotion. We then propose three methods to collaboratively incorporate the latent concepts into response generation. Experimental results on two large-scale datasets support our hypothesis and show that our model can produce more accurate and commonsense-aware emotional responses and achieve better human ratings than state-of-the-art models that only specialize in one aspect",
    "volume": "main",
    "checked": true,
    "id": "ad1a1f910b53d3465a89220a41af1d7069cbee5b",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17714": {
    "title": "MTAAL: Multi-Task Adversarial Active Learning for Medical Named Entity Recognition and Normalization",
    "abstract": "Automated medical named entity recognition and normalization are fundamental for constructing knowledge graphs and building QA systems. When it comes to medical text, the annotation demands a foundation of expertise and professionalism. Existing methods utilize active learning to reduce costs in corpus annotation, as well as the multi-task learning strategy to model the correlations between different tasks. However, existing models do not take task-specific features for different tasks and diversity of query samples into account. To address these limitations, this paper proposes a multi-task adversarial active learning model for medical named entity recognition and normalization. In our model, the adversarial learning keeps the effectiveness of multi-task learning module and active learning module. The task discriminator eliminates the influence of irregular task-specific features. And the diversity discriminator exploits the heterogeneity between samples to meet the diversity constraint. The empirical results on two medical benchmarks demonstrate the effectiveness of our model against the existing methods",
    "volume": "main",
    "checked": true,
    "id": "3cc19d0e2df1af11a7a62da6533f70865a42ca11",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17715": {
    "title": "A Neural Group-wise Sentiment Analysis Model with Data Sparsity Awareness",
    "abstract": "Sentiment analysis on user-generated content has achieved notable progress by introducing user information to consider each individuals preference and language usage. However, most existing approaches ignore the data sparsity problem, where the content of some users is limited and the model fails to capture discriminative features of users. To address this issue, we hypothesize that users could be grouped together based on their rating biases as well as degree of rating consistency and the knowledge learned from groups could be employed to analyze the users with limited data. Therefore, in this paper, a neural group-wise sentiment analysis model with data sparsity awareness is proposed. The user-centred document representations are generated by incorporating a group-based user encoder. Furthermore, a multi-task learning framework is employed to jointly modelusers rating biases and their degree of rating consistency. One task is vanilla populationlevel sentiment analysis and the other is groupwise sentiment analysis. Experimental results on three real-world datasets show that the proposed approach outperforms some state-of the-art methods. Moreover, model analysis and case study demonstrate its effectiveness of modeling user rating biases and variances",
    "volume": "main",
    "checked": true,
    "id": "db5368664b71c203b1b1aa4e28ef081e9a2eeee7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17716": {
    "title": "EvaLDA: Efficient Evasion Attacks Towards Latent Dirichlet Allocation",
    "abstract": "As one of the most powerful topic models, Latent Dirichlet Allocation (LDA) has been used in a vast range of tasks, including document understanding, information retrieval and peer-reviewer assignment. Despite its tremendous popularity, the security of LDA has rarely been studied. This poses severe risks to security-critical tasks such as sentiment analysis and peer-reviewer assignment that are based on LDA. In this paper, we are interested in knowing whether LDA models are vulnerable to adversarial perturbations of benign document examples during inference time. We formalize the evasion attack to LDA models as an optimization problem and prove it to be NP-hard. We then propose a novel and efficient algorithm, EvaLDA to solve it. We show the effectiveness of EvaLDA via extensive empirical evaluations. For instance, in the NIPS dataset, EvaLDA can averagely promote the rank of a target topic from 10 to around 7 by only replacing 1% of the words with similar words in a victim document. Our work provides significant insights into the power and limitations of evasion attacks to LDA models",
    "volume": "main",
    "checked": true,
    "id": "d30ed44df0156000a343e98258e4515534745923",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17717": {
    "title": "Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling",
    "abstract": "Document-level relation extraction (RE) poses new challenges compared to its sentence-level counterpart. One document commonly contains multiple entity pairs, and one entity pair occurs multiple times in the document associated with multiple possible relations. In this paper, we propose two novel techniques, adaptive thresholding and localized context pooling, to solve the multi-label and multi-entity problems. The adaptive thresholding replaces the global threshold for multi-label classification in the prior work with a learnable entities-dependent threshold. The localized context pooling directly transfers attention from pre-trained language models to locate relevant context that is useful to decide the relation. We experiment on three document-level RE benchmark datasets: DocRED, a recently released large-scale RE dataset, and two datasets CDRand GDA in the biomedical domain. Our ATLOP (Adaptive Thresholding and Localized cOntext Pooling) model achieves an F1 score of 63.4, and also significantly outperforms existing models on both CDR and GDA. We have released our code at https://github.com/wzhouad/ATLOP",
    "volume": "main",
    "checked": true,
    "id": "276d4e2684eeb7fc4df4c619d0de58160dca8b5e",
    "citation_count": 70
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17718": {
    "title": "IsoBN: Fine-Tuning BERT with Isotropic Batch Normalization",
    "abstract": "Fine-tuning pre-trained language models (PTLMs), such as BERT and its better variant RoBERTa, has been a common practice for advancing performance in natural language understanding (NLU) tasks. Recent advance in representation learning shows that isotropic (i.e., unit-variance and uncorrelated) embeddings can significantly improve performance on downstream tasks with faster convergence and better generalization. The isotropy of the pre-trained embeddings in PTLMs, however, is relatively under-explored. In this paper, we analyze the isotropy of the pre-trained [CLS] embeddings of PTLMs with straightforward visualization, and point out two major issues: high variance in their standard deviation, and high correlation between different dimensions. We also propose a new network regularization method, isotropic batch normalization (IsoBN) to address the issues, towards learning more isotropic representations in fine-tuning by dynamically penalizing dominating principal components. This simple yet effective fine-tuning method yields about 1.0 absolute increment on the average of seven NLU tasks",
    "volume": "main",
    "checked": true,
    "id": "2c2cc3decc0d5091965975eb4bb6f5dc802bcbf7",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17719": {
    "title": "An Adaptive Hybrid Framework for Cross-domain Aspect-based Sentiment Analysis",
    "abstract": "Cross-domain aspect-based sentiment analysis aims to utilize the useful knowledge in a source domain to extract aspect terms and predict their sentiment polarities in a target domain. Recently, methods based on adversarial training have been applied to this task and achieved promising results. In such methods, both the source and target data are utilized to learn domain-invariant features through deceiving a domain discriminator. However, the task classifier is only trained on the source data, which causes the aspect and sentiment information lying in the target data can not be exploited by the task classifier. In this paper, we propose an Adaptive Hybrid Framework (AHF) for cross-domain aspect-based sentiment analysis. We integrate pseudo-label based semi-supervised learning and adversarial training in a unified network. Thus the target data can be used not only to align the features via the training of domain discriminator, but also to refine the task classifier. Furthermore, we design an adaptive mean teacher as the semi-supervised part of our network, which can mitigate the effects of noisy pseudo labels generated on the target data. We conduct experiments on four public datasets and the experimental results show that our framework significantly outperforms the state-of-the-art methods",
    "volume": "main",
    "checked": true,
    "id": "34048d8fec3e1f18c20a5047acf3971e33820c00",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17720": {
    "title": "What the Role is vs. What Plays the Role: Semi-Supervised Event Argument Extraction via Dual Question Answering",
    "abstract": "Event argument extraction is an essential task in event extraction, and become particularly challenging in the case of low-resource scenarios. We solve the issues in existing studies under low-resource situations from two sides. From the perspective of the model, the existing methods always suffer from the concern of insufficient parameter sharing and do not consider the semantics of roles, which is not conducive to dealing with sparse data. And from the perspective of the data, most existing methods focus on data generation and data augmentation. However, these methods rely heavily on external resources, which is more laborious to create than obtain unlabeled data. In this paper, we propose DualQA, a novel framework, which models the event argument extraction task as question answering to alleviate the problem of data sparseness and leverage the duality of event argument recognition which is to ask \"What plays the role\", as well as event role recognition which is to ask \"What the role is\", to mutually improve each other.Experimental results on two datasets prove the effectiveness of our approach, especially in extremely low-resource situations",
    "volume": "main",
    "checked": true,
    "id": "3ddb8a7af5172bbac8cf0344b858324ccf724118",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17721": {
    "title": "Clinical Temporal Relation Extraction with Probabilistic Soft Logic Regularization and Global Inference",
    "abstract": "There has been a steady need in the medical community to precisely extract the temporal relations between clinical events. In particular, temporal information can facilitate a variety of downstream applications such as case report retrieval and medical question answering. Existing methods either require expensive feature engineering or are incapable of modeling the global relational dependencies among the events. In this paper, we propose a novel method, Clinical Temporal ReLation Exaction with Probabilistic Soft Logic Regularization and Global Inference (CTRL-PG) to tackle the problem at the document level. Extensive experiments on two benchmark datasets, I2B2-2012 and TB-Dense, demonstrate that CTRL-PG significantly outperforms baseline methods for temporal relation extraction",
    "volume": "main",
    "checked": true,
    "id": "16913a534b1630d33770b392767bb316f4fdb11e",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17722": {
    "title": "Neural Sentence Ordering Based on Constraint Graphs",
    "abstract": "Sentence ordering aims at arranging a list of sentences in the correct order. Based on the observation that sentence order at different distances may rely on different types of information, we devise a new approach based on multi-granular orders between sentences. These orders form multiple constraint graphs, which are then encoded by Graph Isomorphism Networks and fused into sentence representations. Finally, sentence order is determined using the order-enhanced sentence representations. Our experiments on five benchmark datasets show that our method outperforms all existing baselines significantly, achieving a new state-of-the-art performance. The results demonstrate the advantage of considering multiple types of order information and using graph neural networks to integrate sentence content and order information for the task. Our code is available at https://github.com/DaoD/ConstraintGraph4NSO",
    "volume": "main",
    "checked": true,
    "id": "607b61b6b64bec4f97e9e22bc7c670696da9bf91",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17723": {
    "title": "Topic-Oriented Spoken Dialogue Summarization for Customer Service with Saliency-Aware Topic Modeling",
    "abstract": "In a customer service system, dialogue summarization can boost service efficiency by automatically creating summaries for long spoken dialogues in which customers and agents try to address issues about specific topics. In this work, we focus on topic-oriented dialogue summarization, which generates highly abstractive summaries that preserve the main ideas from dialogues. In spoken dialogues, abundant dialogue noise and common semantics could obscure the underlying informative content, making the general topic modeling approaches difficult to apply. In addition, for customer service, role-specific information matters and is an indispensable part of a summary. To effectively perform topic modeling on dialogues and capture multi-role information, in this work we propose a novel topic-augmented two-stage dialogue summarizer (TDS) jointly with a saliency-aware neural topic model (SATM) for topic-oriented summarization of customer service dialogues. Comprehensive studies on a real-world Chinese customer service dataset demonstrated the superiority of our method against several strong baselines",
    "volume": "main",
    "checked": true,
    "id": "4adbbb1c61404fe7235bbe704189167d61368629",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17724": {
    "title": "Unsupervised Summarization for Chat Logs with Topic-Oriented Ranking and Context-Aware Auto-Encoders",
    "abstract": "Automatic chat summarization can help people quickly grasp important information from numerous chat messages. Unlike conventional documents, chat logs usually have fragmented and evolving topics. In addition, these logs contain a quantity of elliptical and interrogative sentences, which make the chat summarization highly context dependent. In this work, we propose a novel unsupervised framework called RankAE to perform chat summarization without employing manually labeled data. RankAE consists of a topic-oriented ranking strategy that selects topic utterances according to centrality and diversity simultaneously, as well as a denoising auto-encoder that is carefully designed to generate succinct but context-informative summaries based on the selected utterances. To evaluate the proposed method, we collect a large-scale dataset of chat logs from a customer service environment and build an annotated set only for model evaluation. Experimental results show that RankAE significantly outperforms other unsupervised methods and is able to generate high-quality summaries in terms of relevance and topic coverage",
    "volume": "main",
    "checked": true,
    "id": "7792683b78807a7c86c508f4f05bdfad38d3fe0a",
    "citation_count": 14
  }
}