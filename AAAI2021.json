{
  "https://ojs.aaai.org/index.php/AAAI/article/view/16071": {
    "title": "The Undergraduate Games Corpus: A Dataset for Machine Perception of Interactive Media",
    "volume": "main",
    "abstract": "Machine perception research primarily focuses on processing static inputs (e.g. images and texts). We are interested in machine perception of interactive media (such as games, apps, and complex web applications) where interactive audience choices have long-term implications for the audience experience. While there is ample research on AI methods for the task of playing games (often just one game at a time), this work is difficult to apply to new and in-development games or to use for non-playing tasks such as similarity-based retrieval or authoring assistance. In response, we contribute a corpus of 755 games and structured metadata, spread across several platforms (Twine, Bitsy, Construct, and Godot), with full source and assets available and appropriately licensed for use and redistribution in research. Because these games were sourced from student projects in an undergraduate game development program, they reference timely themes in their content and represent a variety of levels of design polish rather than only representing past commercial successes. This corpus could accelerate research in understanding interactive media while anchoring that work in freshly-developed games intended as legitimate human experiences (rather than lab-created AI testbeds). We validate the utility of this corpus by setting up the novel task of predicting tags relevant to the player experience from the game source code, showing that representations that better exploit the structure of the media outperform a text-only baseline",
    "checked": true,
    "id": "f7a96c935cd4475699fcf16bf9f07878c931b990",
    "semantic_title": "the undergraduate games corpus: a dataset for machine perception of interactive media",
    "citation_count": 0,
    "authors": [
      "Barrett R. Anderson",
      "Adam M. Smith"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16072": {
    "title": "Efficient Poverty Mapping from High Resolution Remote Sensing Images",
    "volume": "main",
    "abstract": "The combination of high-resolution satellite imagery and machine learning have proven useful in many sustainability-related tasks, including poverty prediction, infrastructure measurement, and forest monitoring. However, the accuracy afforded by high-resolution imagery comes at a cost, as such imagery is extremely expensive to purchase at scale. This creates a substantial hurdle to the efficient scaling and widespread adoption of high-resolution-based approaches. To reduce acquisition costs while maintaining accuracy, we propose a reinforcement learning approach in which free low-resolution imagery is used to dynamically identify where to acquire costly high-resolution images, prior to performing a deep learning task on the high-resolution images. We apply this approach to the task of poverty prediction in Uganda, building on an earlier approach that used object detection to count objects and use these counts to predict poverty. Our approach exceeds previous performance benchmarks on this task while using 80% fewer high-resolution images, and could be useful in many domains that require high-resolution imagery",
    "checked": true,
    "id": "22ae04d51c341487068cb56f76ffb5f10e214679",
    "semantic_title": "efficient poverty mapping from high resolution remote sensing images",
    "citation_count": 20,
    "authors": [
      "Kumar Ayush",
      "Burak Uzkent",
      "Kumar Tanmay",
      "Marshall Burke",
      "David Lobell",
      "Stefano Ermon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16073": {
    "title": "Optimal Kidney Exchange with Immunosuppressants",
    "volume": "main",
    "abstract": "Algorithms for exchange of kidneys is one of the key successful applications in market design, artificial intelligence, and operations research. Potent immunosuppressant drugs suppress the body's ability to reject a transplanted organ up to the point that a transplant across blood- or tissue-type incompatibility becomes possible. In contrast to the standard kidney exchange problem, we consider a setting that also involves the decision about which recipients receive from the limited supply of immunosuppressants that make them compatible with originally incompatible kidneys. We firstly present a general computational framework to model this problem. Our main contribution is a range of efficient algorithms that provide flexibility in terms of meeting meaningful objectives. Motivated by the current reality of kidney exchanges using sophisticated mathematical-programming-based clearing algorithms, we then present a general but scalable approach to optimal clearing with immunosuppression; we validate our approach on realistic data from a large fielded exchange",
    "checked": true,
    "id": "75045b41ed7498ddf2537c8511e7c15d5a0b08e9",
    "semantic_title": "optimal kidney exchange with immunosuppressants",
    "citation_count": 2,
    "authors": [
      "Haris Aziz",
      "√Ågnes Cseh",
      "John P. Dickerson",
      "Duncan C. McElfresh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16074": {
    "title": "TreeCaps: Tree-Based Capsule Networks for Source Code Processing",
    "volume": "main",
    "abstract": "Recently program learning techniques have been proposed to process source code based on syntactical structures (e.g., abstract syntax trees) and/or semantic information (e.g., dependency graphs). While graphs may be better than trees at capturing code semantics, constructing the graphs from code inputs through the semantic analysis of multiple viewpoints can lead to inaccurate noises for a specific software engineering task. Compared to graphs, syntax trees are more precisely defined on the grammar and easier to parse; unfortunately, previous tree-based learning techniques have not been able to learn semantic information from trees to achieve better accuracy than graph-based techniques. We have proposed a new learning technique, named TreeCaps, by fusing together capsule networks with tree-based convolutional neural networks to achieve a learning accuracy higher than some existing graph-based techniques while it is based only on trees. TreeCaps introduces novel variable-to-static routing algorithms into the capsule networks to compensate for the loss of previous routing algorithms. Aside from accuracy, we also find that TreeCaps is the most robust to withstand those semantic-preserving program transformations that change code syntax without modifying the semantics. Evaluated on a large number of Java and C/C++ programs, TreeCaps models outperform prior deep learning models of program source code, in terms of both accuracy and robustness for program comprehension tasks such as code functionality classification and function name prediction. Our implementation is publicly available at: https://github.com/bdqnghi/treecaps",
    "checked": true,
    "id": "11a0bdb1a049eaeae72c38278936c1d599728f87",
    "semantic_title": "treecaps: tree-based capsule networks for source code processing",
    "citation_count": 27,
    "authors": [
      "Nghi D. Q. Bui",
      "Yijun Yu",
      "Lingxiao Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16075": {
    "title": "A Bottom-Up DAG Structure Extraction Model for Math Word Problems",
    "volume": "main",
    "abstract": "Research on automatically solving mathematical word problems (MWP) has a long history. Most recent works adopt Seq2Seq approach to predict the result equations as a sequence of quantities and operators. Although result equations can be written as a sequence, it is essentially a structure. More precisely, it is a Direct Acyclic Graph (DAG) whose leaf nodes are the quantities, and internal and root nodes are arithmetic or comparison operators. In this paper, we propose a novel Seq2DAG approach to extract the equation set directly as a DAG structure. It is extracted in a bottom-up fashion by aggregating quantities and sub-expressions layer by layer iteratively. The advantages of our approach approach are three-fold: it is intrinsically suitable to solve multivariate problems, it always outputs valid structure, and its computation satisfies commutative law for +, x and =. Experimental results on Math23K and DRAW1K demonstrate that our model outperforms state-of-the-art deep learning methods. We also conduct detailed analysis on the results to show the strengths and limitations of our approach",
    "checked": true,
    "id": "4ae6b5ce971c58c1280bc971a1879e6d547c5f8c",
    "semantic_title": "a bottom-up dag structure extraction model for math word problems",
    "citation_count": 23,
    "authors": [
      "Yixuan Cao",
      "Feng Hong",
      "Hongwei Li",
      "Ping Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16076": {
    "title": "Diagnose Like A Pathologist: Weakly-Supervised Pathologist-Tree Network for Slide-Level Immunohistochemical Scoring",
    "volume": "main",
    "abstract": "The immunohistochemistry (IHC) test of biopsy tissue is crucial to develop targeted treatment and evaluate prognosis for cancer patients. The IHC staining slide is usually digitized into the whole-slide image (WSI) with gigapixels for quantitative image analysis. To perform a whole image prediction (e.g., IHC scoring, survival prediction, and cancer grading) from this kind of high-dimensional image, algorithms are often developed based on multi-instance learning (MIL) framework. However, the multi-scale information of WSI and the associations among instances are not well explored in existing MIL based studies. Inspired by the fact that pathologists jointly analyze visual fields at multiple powers of objective for diagnostic predictions, we propose a Pathologist-Tree Network (PTree-Net) to sparsely model the WSI efficiently in multi-scale manner. Specifically, we propose a Focal-Aware Module (FAM) that can approximately estimate diagnosis-related regions with an extractor trained using the thumbnail of WSI. With the initial diagnosis-related regions, we hierarchically model the multi-scale patches in a tree structure, where both the global and local information can be captured. To explore this tree structure in an end-to-end network, we propose a patch Relevance-enhanced Graph Convolutional Network (RGCN) to explicitly model the correlations of adjacent parent-child nodes, accompanied by patch relevance to exploit the implicit contextual information among distant nodes. In addition, tree-based self-supervision is devised to improve representation learning and suppress irrelevant instances adaptively. Extensive experiments are performed on a large-scale IHC HER2 dataset. The ablation study confirms the effectiveness of our design, and our approach outperforms state-of-the-art by a large margin",
    "checked": true,
    "id": "50665b18f9b2072c20dbf9419b290e936ca3a402",
    "semantic_title": "diagnose like a pathologist: weakly-supervised pathologist-tree network for slide-level immunohistochemical scoring",
    "citation_count": 20,
    "authors": [
      "Zhen Chen",
      "Jun Zhang",
      "Shuanlong Che",
      "Junzhou Huang",
      "Xiao Han",
      "Yixuan Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16077": {
    "title": "Modeling the Momentum Spillover Effect for Stock Prediction via Attribute-Driven Graph Attention Networks",
    "volume": "main",
    "abstract": "In finance, the momentum spillovers of listed firms is well acknowledged. Only few studies predicted the trend of one firm in terms of its relevant firms. A common strategy of the pilot work is to adopt graph convolution networks (GCNs) with some predefined firm relations. However, momentum spillovers are propagated via a variety of firm relations, of which the bridging importance varies with time. Restricting to several predefined relations inevitably makes noise and thus misleads stock predictions. In addition, traditional GCNs transfer and aggregate the peer influences without considering the states of both connected firms once a connection is built. Such non-attribute sensibility makes traditional GCNs inappropriate to deal with the attribute-sensitive momentum spillovers of listed firms wherein the abnormal price drop of one firm may not spill over if the trade volume of this decreasing price is small or the prices of the linked firms are undervalued. In this study, we propose an attribute-driven graph attention network (AD-GAT) to address both problems in modeling momentum spillovers. This is achieved by element-wisely multiplying the nonlinear transformation of the attributes of the connected firms with the attributes of the source firm to consider its attribute-sensitive momentum spillovers, and applying the unmasked attention mechanism to infer the general dynamic firm relation from observed market signals fused by a novel tensor-based feature extractor. Experiments on the three-year data of the S&P 500 demonstrate the superiority of the proposed framework over stateof-the-art algorithms, including GCN, eLSTM, and TGC",
    "checked": true,
    "id": "6b8048a62b1d8040eff9d007c2a2b0a5be770049",
    "semantic_title": "modeling the momentum spillover effect for stock prediction via attribute-driven graph attention networks",
    "citation_count": 37,
    "authors": [
      "Rui Cheng",
      "Qing Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16078": {
    "title": "Differentially Private Link Prediction with Protected Connections",
    "volume": "main",
    "abstract": "Link prediction (LP) algorithms propose to each node a ranked list of nodes that are currently non-neighbors, as the most likely candidates for future linkage. Owing to increasing concerns about privacy, users (nodes) may prefer to keep some of their connections protected or private. Motivated by this observation, our goal is to design a differentially private LP algorithm, which trades off between privacy of the protected node-pairs and the link prediction accuracy. More specifically, we first propose a form of differential privacy on graphs, which models the privacy loss only of those node-pairs which are marked as protected. Next, we develop DPLP, a learning to rank algorithm, which applies a monotone transform to base scores from a non-private LP system, and then adds noise. DPLP is trained with a privacy induced ranking loss, which optimizes the ranking utility for a given maximum allowed level of privacy leakage of the protected node-pairs. Under a recently introduced latent node embedding model, we present a formal trade-off between privacy and LP utility. Extensive experiments with several real-life graphs and several LP heuristics show that DPLP can trade off between privacy and predictive performance more effectively than several alternatives",
    "checked": true,
    "id": "2ce1d9a59c5de2a5d48f38f42a7ea693eb061f56",
    "semantic_title": "differentially private link prediction with protected connections",
    "citation_count": 4,
    "authors": [
      "Abir De",
      "Soumen Chakrabarti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16079": {
    "title": "Graph Neural Network to Dilute Outliers for Refactoring Monolith Application",
    "volume": "main",
    "abstract": "Microservices are becoming the defacto design choice for software architecture. It involves partitioning the software components into finer modules such that the development can happen independently. It also provides natural benefits when deployed on the cloud since resources can be allocated dynamically to necessary components based on demand. Therefore, enterprises as part of their journey to cloud, are increasingly looking to refactor their monolith application into one or more candidate microservices; wherein each service contains a group of software entities (e.g., classes) that are responsible for a common functionality. Graphs are a natural choice to represent a software system. Each software entity can be represented as nodes and its dependencies with other entities as links. Therefore, this problem of refactoring can be viewed as a graph based clustering task. In this work, we propose a novel method to adapt the recent advancements in graph neural networks in the context of code to better understand the software and apply them in the clustering task. In that process, we also identify the outliers in the graph which can be directly mapped to top refactor candidates in the software. Our solution is able to improve state-of-the-art performance compared to works from both software engineering and existing graph representation based techniques",
    "checked": true,
    "id": "95f4ed97e39673a1d1c98ba636a69f322177e0d4",
    "semantic_title": "graph neural network to dilute outliers for refactoring monolith application",
    "citation_count": 27,
    "authors": [
      "Utkarsh Desai",
      "Sambaran Bandyopadhyay",
      "Srikanth Tamilselvam"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16080": {
    "title": "KAN: Knowledge-aware Attention Network for Fake News Detection",
    "volume": "main",
    "abstract": "The explosive growth of fake news on social media has drawn great concern both from industrial and academic communities. There has been an increasing demand for fake news detection due to its detrimental effects. Generally, news content is condensed and full of knowledge entities. However, existing methods usually focus on the textual contents and social context, and ignore the knowledge-level relationships among news entities. To address this limitation, in this paper, we propose a novel Knowledge-aware Attention Network (KAN) that incorporates external knowledge from knowledge graph for fake news detection. Firstly, we identify entity mentions in news contents and align them with the entities in knowledge graph. Then, the entities and their contexts are used as external knowledge to provide complementary information. Finally, we design News towards Entities (N-E) attention and News towards Entities and Entity Contexts (N-E^2C) attention to measure the importances of knowledge. Thus, our proposed model can incorporate both semantic-level and knowledge-level representations of news to detect fake news. Experimental results on three public datasets show that our model outperforms the state-of-the-art methods, and also validate the effectiveness of knowledge attention",
    "checked": true,
    "id": "b357470ddbd30729cb39dc88ea76ed08bc5dabb0",
    "semantic_title": "kan: knowledge-aware attention network for fake news detection",
    "citation_count": 41,
    "authors": [
      "Yaqian Dun",
      "Kefei Tu",
      "Chen Chen",
      "Chunyan Hou",
      "Xiaojie Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16081": {
    "title": "When Hashing Met Matching: Efficient Spatio-Temporal Search for Ridesharing",
    "volume": "main",
    "abstract": "Shared on-demand mobility holds immense potential for urban transportation. However, finding ride matches in real-time at urban scale is a very difficult combinatorial optimization problem and mostly heuristic approaches are applied. In this work, we introduce a principled approach to this combinatorial problem. Our approach proceeds by constructing suitable representations for rides and driver routes capturing their essential spatio-temporal aspects in an appropriate vector space, and defining a similarity metric in this space that expresses matching utility. This then lets us mathematically model the problem of finding ride matches as that of Near Neighbor Search (NNS). Exploiting this modeling, we devise a novel spatio-temporal search algorithm for finding ride matches based on the theory of Locality Sensitive Hashing (LSH). Apart from being highly efficient, our algorithm enjoys several practically useful properties and extension possibilities. Experiments with large real-world datasets show that our algorithm consistently outperforms state-of-the-art heuristic methods thereby proving its practical applicability",
    "checked": true,
    "id": "a29867944cf372ea84a00a7f3863686a8119ca29",
    "semantic_title": "when hashing met matching: efficient spatio-temporal search for ridesharing",
    "citation_count": 6,
    "authors": [
      "Chinmoy Dutta"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16082": {
    "title": "Gene Regulatory Network Inference using 3D Convolutional Neural Network",
    "volume": "main",
    "abstract": "Gene regulatory networks (GRNs) consist of gene regulations between transcription factors (TFs) and their target genes. Single-cell RNA sequencing (scRNA-seq) brings both opportunities and challenges to the inference of GRNs. On the one hand, scRNA-seq data reveals statistic information of gene expressions at the single-cell resolution, which is conducive to the construction of GRNs; on the other hand, noises and dropouts pose great difficulties on the analysis of scRNA-seq data, causing low prediction accuracy by traditional methods. In this paper, we propose 3D Co-Expression Matrix Analysis (3DCEMA), which predicts regulatory relationships by classifying 3D co-expression matrices of gene triples using a 3D convolutional neural network. We found that by introducing a third gene as a comparison factor, our method can avoid the disturbance of noises and dropouts, and significantly increase the prediction accuracy of regulations between gene pairs. Compared with other existing GRN inference algorithms on both in-silico datasets and scRNA-Seq datasets, our algorithm based on deep learning shows higher stability and accuracy in the task of GRN inference",
    "checked": true,
    "id": "f7bbc056fb75eb6ce13ea418e11a11c500aac88a",
    "semantic_title": "gene regulatory network inference using 3d convolutional neural network",
    "citation_count": 4,
    "authors": [
      "Yue Fan",
      "Xiuli Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16083": {
    "title": "Universal Trading for Order Execution with Oracle Policy Distillation",
    "volume": "main",
    "abstract": "As a fundamental problem in algorithmic trading, order execution aims at fulfilling a specific trading order, either liquidation or acquirement, for a given instrument. Towards effective execution strategy, recent years have witnessed the shift from the analytical view with model-based market assumptions to model-free perspective, i.e., reinforcement learning, due to its nature of sequential decision optimization. However, the noisy and yet imperfect market information that can be leveraged by the policy has made it quite challenging to build up sample efficient reinforcement learning methods to achieve effective order execution. In this paper, we propose a novel universal trading policy optimization framework to bridge the gap between the noisy yet imperfect market states and the optimal action sequences for order execution. Particularly, this framework leverages a policy distillation method that can better guide the learning of the common policy towards practically optimal execution by an oracle teacher with perfect information to approximate the optimal trading strategy. The extensive experiments have shown significant improvements of our method over various strong baselines, with reasonable trading actions",
    "checked": true,
    "id": "daa92545b0363e1d8ea83e74b47d7f7e9790fa80",
    "semantic_title": "universal trading for order execution with oracle policy distillation",
    "citation_count": 28,
    "authors": [
      "Yuchen Fang",
      "Kan Ren",
      "Weiqing Liu",
      "Dong Zhou",
      "Weinan Zhang",
      "Jiang Bian",
      "Yong Yu",
      "Tie-Yan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16084": {
    "title": "Dual-Octave Convolution for Accelerated Parallel MR Image Reconstruction",
    "volume": "main",
    "abstract": "Magnetic resonance (MR) image acquisition is an inherently prolonged process, whose acceleration by obtaining multiple undersampled images simultaneously through parallel imaging has always been the subject of research. In this paper, we propose the Dual-Octave Convolution (Dual-OctConv), which is capable of learning multi-scale spatial-frequency features from both real and imaginary components, for fast parallel MR image reconstruction. By reformulating the complex operations using octave convolutions, our model shows a strong ability to capture richer representations of MR images, while at the same time greatly reducing the spatial redundancy. More specifically, the input feature maps and convolutional kernels are first split into two components (i.e., real and imaginary), which are then divided into four groups according to their spatial frequencies. Then, our Dual-OctConv conducts intra-group information updating and inter-group information exchange to aggregate the contextual information across different groups. Our framework provides two appealing benefits: (i) it encourages interactions between real and imaginary components at various spatial frequencies to achieve richer representational capacity, and (ii) it enlarges the receptive field by learning multiple spatial-frequency features of both the real and imaginary components. We evaluate the performance of the proposed model on the acceleration of multi-coil MR image reconstruction. Extensive experiments are conducted on an {in vivo} knee dataset under different undersampling patterns and acceleration factors. The experimental results demonstrate the superiority of our model in accelerated parallel MR image reconstruction. Our code is available at: github.com/chunmeifeng/Dual-OctConv",
    "checked": true,
    "id": "52b22ed78e881a80f919965deffbf85db3d9e776",
    "semantic_title": "dual-octave convolution for accelerated parallel mr image reconstruction",
    "citation_count": 20,
    "authors": [
      "Chun-Mei Feng",
      "Zhanyuan Yang",
      "Geng Chen",
      "Yong Xu",
      "Ling Shao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16085": {
    "title": "MIMOSA: Multi-constraint Molecule Sampling for Molecule Optimization",
    "volume": "main",
    "abstract": "Molecule optimization is a fundamental task for accelerating drug discovery, with the goal of generating new valid molecules that maximize multiple drug properties while maintaining similarity to the input molecule. Existing generative models and reinforcement learning approaches made initial success, but still face difficulties in simultaneously optimizing multiple drug properties. To address such challenges, we propose the MultI-constraint MOlecule SAmpling (MIMOSA) approach, a sampling framework to use input molecule as an initial guess and sample molecules from the target distribution. MIMOSA first pretrains two property agnostic graph neural networks (GNNs) for molecule topology and substructure-type prediction, where a substructure can be either atom or single ring. For each iteration, MIMOSA uses the GNNs' prediction and employs three basic substructure operations (add, replace, delete) to generate new molecules and associated weights. The weights can encode multiple constraints including similarity and drug property constraints, upon which we select promising molecules for next iteration. MIMOSA enables flexible encoding of multiple property- and similarity-constraints and can efficiently generate new molecules that satisfy various property constraints and achieved up to 49.1% relative improvement over the best baseline in terms of success rate",
    "checked": true,
    "id": "143f3784064bdb042e580534722a6bb395371daf",
    "semantic_title": "mimosa: multi-constraint molecule sampling for molecule optimization",
    "citation_count": 43,
    "authors": [
      "Tianfan Fu",
      "Cao Xiao",
      "Xinhao Li",
      "Lucas M. Glass",
      "Jimeng Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16086": {
    "title": "ECG ODE-GAN: Learning Ordinary Differential Equations of ECG Dynamics via Generative Adversarial Learning",
    "volume": "main",
    "abstract": "Understanding the dynamics of complex biological and physiological systems has been explored for many years in the form of physically-based mathematical simulators. The behavior of a physical system is often described via ordinary differential equations (ODE), referred to as the dynamics. In the standard case, the dynamics are derived from purely physical considerations. By contrast, in this work we study how the dynamics can be learned by a generative adversarial network which combines both physical and data considerations. As a use case, we focus on the dynamics of the heart signal electrocardiogram (ECG). We begin by introducing a new GAN framework, dubbed ODE-GAN, in which the generator learns the dynamics of a physical system in the form of an ordinary differential equation. Specifically, the generator network receives as input a value at a specific time step, and produces the derivative of the system at that time step. Thus, the ODE-GAN learns purely data-driven dynamics. We then show how to incorporate physical considerations into ODE-GAN. We achieve this through the introduction of an additional input to the ODE-GAN generator: physical parameters, which partially characterize the signal of interest. As we focus on ECG signals, we refer to this new framework as ECG-ODE-GAN. We perform an empirical evaluation and show that generating ECG heartbeats from our learned dynamics improves ECG heartbeat classification",
    "checked": true,
    "id": "efb462bebead45a81b9e51f008fbed89e627e355",
    "semantic_title": "ecg ode-gan: learning ordinary differential equations of ecg dynamics via generative adversarial learning",
    "citation_count": 23,
    "authors": [
      "Tomer Golany",
      "Daniel Freedman",
      "Kira Radinsky"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16087": {
    "title": "Towered Actor Critic For Handling Multiple Action Types In Reinforcement Learning For Drug Discovery",
    "volume": "main",
    "abstract": "Reinforcement learning (RL) has made significant progress in both abstract and real-world domains, but the majority of state-of-the-art algorithms deal only with monotonic actions. However, some applications require agents to reason over different types of actions. Our application simulates reaction-based molecule generation, used as part of the drug discovery pipeline, and includes both uni-molecular and bi-molecular reactions. This paper introduces a novel framework, towered actor critic (TAC), to handle multiple action types. The TAC framework is general in that it is designed to be combined with any existing RL algorithms for continuous action space. We combine it with TD3 to empirically obtain significantly better results than existing methods in the drug discovery setting. TAC is also applied to RL benchmarks in OpenAI Gym and results show that our framework can improve, or at least does not hurt, performance relative to standard TD3",
    "checked": true,
    "id": "3cfe1f9f3e1a6a31e2ec18c8641dbedafd538f8a",
    "semantic_title": "towered actor critic for handling multiple action types in reinforcement learning for drug discovery",
    "citation_count": 7,
    "authors": [
      "Sai Krishna Gottipati",
      "Yashaswi Pathak",
      "Boris Sattarov",
      "  Sahir",
      "Rohan Nuttall",
      "Mohammad Amini",
      "Matthew E. Taylor",
      "Sarath Chandar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16088": {
    "title": "Hierarchical Graph Convolution Network for Traffic Forecasting",
    "volume": "main",
    "abstract": "Traffic forecasting is attracting considerable interest due to its widespread application in intelligent transportation systems. Given the complex and dynamic traffic data, many methods focus on how to establish a spatial-temporal model to express the non-stationary traffic patterns. Recently, the latest Graph Convolution Network (GCN) has been introduced to learn spatial features while the time neural networks are used to learn temporal features. These GCN based methods obtain state-of-the-art performance. However, the current GCN based methods ignore the natural hierarchical structure of traffic systems which is composed of the micro layers of road networks and the macro layers of region networks, in which the nodes are obtained through pooling method and could include some hot traffic regions such as downtown and CBD etc., while the current GCN is only applied on the micro graph of road networks. In this paper, we propose a novel Hierarchical Graph Convolution Networks (HGCN) for traffic forecasting by operating on both the micro and macro traffic graphs. The proposed method is evaluated on two complex city traffic speed datasets. Compared to the latest GCN based methods like Graph WaveNet, the proposed HGCN gets higher traffic forecasting precision with lower computational cost.The website of the code is https://github.com/guokan987/HGCN.git",
    "checked": true,
    "id": "aeea29ad352a04e74b6a4459e7328aa6e904486d",
    "semantic_title": "hierarchical graph convolution network for traffic forecasting",
    "citation_count": 95,
    "authors": [
      "Kan Guo",
      "Yongli Hu",
      "Yanfeng Sun",
      "Sean Qian",
      "Junbin Gao",
      "Baocai Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16089": {
    "title": "Automated Lay Language Summarization of Biomedical Scientific Reviews",
    "volume": "main",
    "abstract": "Health literacy has emerged as a crucial factor in making appropriate health decisions and ensuring treatment outcomes. However, medical jargon and the complex structure of professional language in this domain make health information especially hard to interpret. Thus, there is an urgent unmet need for automated methods to enhance the accessibility of the biomedical literature to the general population. This problem can be framed as a type of translation problem between the language of healthcare professionals, and that of the general public. In this paper, we introduce the novel task of automated generation of lay language summaries of biomedical scientific reviews, and construct a dataset to support the development and evaluation of automated methods through which to enhance the accessibility of the biomedical literature. We conduct analyses of the various challenges in performing this task, including not only summarization of the key points but also explanation of background knowledge and simplification of professional language. We experiment with state-of-the-art summarization models as well as several data augmentation techniques, and evaluate their performance using both automated metrics and human assessment. Results indicate that automatically generated summaries produced using contemporary neural architectures can achieve promising quality and readability as compared with reference summaries developed for the lay public by experts (best ROUGE-L of 50.24 and Flesch-Kincaid readability score of 13.30). We also discuss the limitations of the current effort, providing insights and directions for future work",
    "checked": true,
    "id": "5b4376a0b97a474a4e063768cc4faf20691b7887",
    "semantic_title": "automated lay language summarization of biomedical scientific reviews",
    "citation_count": 34,
    "authors": [
      "Yue Guo",
      "Wei Qiu",
      "Yizhong Wang",
      "Trevor Cohen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16090": {
    "title": "Sub-Seasonal Climate Forecasting via Machine Learning: Challenges, Analysis, and Advances",
    "volume": "main",
    "abstract": "Sub-seasonal forecasting (SSF) focuses on predicting key variables such as temperature and precipitation on the 2-week to 2-month time scale. Skillful SSF would have immense societal value in such areas as agricultural productivity, water resource management, and emergency planning for extreme weather events. However, SSF is considered more challenging than either weather prediction or even seasonal prediction, and is still a largely understudied problem. In this paper, we carefully investigate 10 Machine Learning (ML) approaches to sub-seasonal temperature forecasting over the contiguous U.S. on the SSF dataset we collect, including a variety of climate variables from the atmosphere, ocean, and land. Because of the complicated atmosphere-land-ocean couplings and the limited amount of good quality observational data, SSF imposes a great challenge for ML despite the recent advances in various domains. Our results indicate that suitable ML models, e.g., XGBoost, to some extent, capture the predictability on sub-seasonal time scales and can outperform the climatological baselines, while Deep Learning (DL) models barely manage to match the best results with carefully designed architecture. Besides, our analysis and exploration provide insights on important aspects to improve the quality of sub-seasonal forecasts, e.g., feature representation and model architecture. The SSF dataset and code are released with this paper for use by the broader research community",
    "checked": true,
    "id": "cac3eda036b01ff0c0c6babab25fb77dd8633afb",
    "semantic_title": "sub-seasonal climate forecasting via machine learning: challenges, analysis, and advances",
    "citation_count": 22,
    "authors": [
      "Sijie He",
      "Xinyan Li",
      "Timothy DelSole",
      "Pradeep Ravikumar",
      "Arindam Banerjee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16091": {
    "title": "Compound Word Transformer: Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs",
    "volume": "main",
    "abstract": "To apply neural sequence models such as the Transformers to music generation tasks, one has to represent a piece of music by a sequence of tokens drawn from a finite set of pre-defined vocabulary. Such a vocabulary usually involves tokens of various types. For example, to describe a musical note, one needs separate tokens to indicate the note's pitch, duration, velocity (dynamics), and placement (onset time) along the time grid. While different types of tokens may possess different properties, existing models usually treat them equally, in the same way as modeling words in natural languages. In this paper, we present a conceptually different approach that explicitly takes into account the type of the tokens, such as note types and metric types. And, we propose a new Transformer decoder architecture that uses different feed-forward heads to model tokens of different types. With an expansion-compression trick, we convert a piece of music to a sequence of compound words by grouping neighboring tokens, greatly reducing the length of the token sequences. We show that the resulting model can be viewed as a learner over dynamic directed hypergraphs. And, we employ it to learn to compose expressive Pop piano music of full-song length (involving up to 10K individual tokens per song), both conditionally and unconditionally. Our experiment shows that, compared to state-of-the-art models, the proposed model converges 5 to 10 times faster at training (i.e., within a day on a single GPU with 11 GB memory), and with comparable quality in the generated music",
    "checked": true,
    "id": "eb0931c39904a40c6cb4aa35c9b21d5e3b7dc856",
    "semantic_title": "compound word transformer: learning to compose full-song music over dynamic directed hypergraphs",
    "citation_count": 97,
    "authors": [
      "Wen-Yi Hsiao",
      "Jen-Yu Liu",
      "Yin-Cheng Yeh",
      "Yi-Hsuan Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16092": {
    "title": "Modeling the Compatibility of Stem Tracks to Generate Music Mashups",
    "volume": "main",
    "abstract": "A music mashup combines audio elements from two or more songs to create a new work. To reduce the time and effort required to make them, researchers have developed algorithms that predict the compatibility of audio elements. Prior work has focused on mixing unaltered excerpts, but advances in source separation enable the creation of mashups from isolated stems (e.g., vocals, drums, bass, etc.). In this work, we take advantage of separated stems not just for creating mashups, but for training a model that predicts the mutual compatibility of groups of excerpts, using self-supervised and semi-supervised methods. Specifically, we first produce a random mashup creation pipeline that combines stem tracks obtained via source separation, with key and tempo automatically adjusted to match, since these are prerequisites for high-quality mashups. To train a model to predict compatibility, we use stem tracks obtained from the same song as positive examples, and random combinations of stems with key and/or tempo unadjusted as negative examples. To improve the model and use more data, we also train on \"average\" examples: random combinations with matching key and tempo, where we treat them as unlabeled data as their true compatibility is unknown. To determine whether the combined signal or the set of stem signals is more indicative of the quality of the result, we experiment on two model architectures and train them using semi-supervised learning technique. Finally, we conduct objective and subjective evaluations of the system, comparing them to a standard rule-based system",
    "checked": true,
    "id": "0d64482e679b6819301db5e199de9b43c44b83e1",
    "semantic_title": "modeling the compatibility of stem tracks to generate music mashups",
    "citation_count": 6,
    "authors": [
      "Jiawen Huang",
      "Ju-Chiang Wang",
      "Jordan B. L. Smith",
      "Xuchen Song",
      "Yuxuan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16093": {
    "title": "SDGNN: Learning Node Representation for Signed Directed Networks",
    "volume": "main",
    "abstract": "Network embedding is aimed at mapping nodes in a network into low-dimensional vector representations. Graph Neural Networks (GNNs) have received widespread attention and lead to state-of-the-art performance in learning node representations. However, most GNNs only work in unsigned networks, where only positive links exist. It is not trivial to transfer these models to signed directed networks, which are widely observed in the real world yet less studied. In this paper, we first review two fundamental sociological theories (i.e., status theory and balance theory) and conduct empirical studies on real-world datasets to analyze the social mechanism in signed directed networks. Guided by related socio- logical theories, we propose a novel Signed Directed Graph Neural Networks model named SDGNN to learn node embeddings for signed directed networks. The proposed model simultaneously reconstructs link signs, link directions, and signed directed triangles. We validate our model's effectiveness on five real-world datasets, which are commonly used as the benchmark for signed network embeddings. Experiments demonstrate the proposed model outperforms existing models, including feature-based methods, network embedding methods, and several GNN methods",
    "checked": true,
    "id": "daa75e8bcd0216e6c780fc705c75c54ac604a394",
    "semantic_title": "sdgnn: learning node representation for signed directed networks",
    "citation_count": 42,
    "authors": [
      "Junjie Huang",
      "Huawei Shen",
      "Liang Hou",
      "Xueqi Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16094": {
    "title": "The Causal Learning of Retail Delinquency",
    "volume": "main",
    "abstract": "This paper focuses on the expected difference in borrower's repayment when there is a change in the lender's credit decisions. Classical estimators overlook the confounding effects and hence the estimation error can be magnificent. As such, we propose another approach to construct the estimators such that the error can be greatly reduced. The proposed estimators are shown to be unbiased, consistent, and robust through a combination of theoretical analysis and numerical testing. Moreover, we compare the power of estimating the causal quantities between the classical estimators and the proposed estimators. The comparison is tested across a wide range of models, including linear regression models, tree-based models, and neural network-based models, under different simulated datasets that exhibit different levels of causality, different degrees of nonlinearity, and different distributional properties. Most importantly, we apply our approaches to a large observational dataset provided by a global technology firm that operates in both the e-commerce and the lending business. We find that the relative reduction of estimation error is strikingly substantial if the causal effects are accounted for correctly",
    "checked": true,
    "id": "96bf5991518241aeb910226e8d61f4a7d5a9fd3b",
    "semantic_title": "the causal learning of retail delinquency",
    "citation_count": 4,
    "authors": [
      "Yiyan Huang",
      "Cheuk Hang Leung",
      "Xing Yan",
      "Qi Wu",
      "Nanbo Peng",
      "Dongdong Wang",
      "Zhixiang Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16095": {
    "title": "Deep Portfolio Optimization via Distributional Prediction of Residual Factors",
    "volume": "main",
    "abstract": "Recent developments in deep learning techniques have motivated intensive research in machine learning-aided stock trading strategies. However, since the financial market has a highly non-stationary nature hindering the application of typical data-hungry machine learning methods, leveraging financial inductive biases is important to ensure better sample efficiency and robustness. In this study, we propose a novel method of constructing a portfolio based on predicting the distribution of a financial quantity called residual factors, which is known to be generally useful for hedging the risk exposure to common market factors. The key technical ingredients are twofold. First, we introduce a computationally efficient extraction method for the residual information, which can be easily combined with various prediction algorithms. Second, we propose a novel neural network architecture that allows us to incorporate widely acknowledged financial inductive biases such as amplitude invariance and time-scale invariance. We demonstrate the efficacy of our method on U.S. and Japanese stock market data. Through ablation experiments, we also verify that each individual technique contributes to improving the performance of trading strategies. We anticipate our techniques may have wide applications in various financial problems",
    "checked": true,
    "id": "98898ce8f3a1addb1d2e1e126781b4b765a0e4ca",
    "semantic_title": "deep portfolio optimization via distributional prediction of residual factors",
    "citation_count": 12,
    "authors": [
      "Kentaro Imajo",
      "Kentaro Minami",
      "Katsuya Ito",
      "Kei Nakagawa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16096": {
    "title": "Complex Coordinate-Based Meta-Analysis with Probabilistic Programming",
    "volume": "main",
    "abstract": "With the growing number of published functional magnetic resonance imaging (fMRI) studies, meta-analysis databases and models have become an integral part of brain mapping research. Coordinate-based meta-analysis (CBMA) databases are built by extracting both coordinates of reported peak activations and term associations using natural language processing techniques from neuroimaging studies. Solving term-based queries on these databases makes it possible to obtain statistical maps of the brain related to specific cognitive processes. However, existing tools for analysing CBMA data are limited in their expressivity to propositional logic, restricting the variety of their queries. Moreover, with tools like Neurosynth, term-based queries on multiple terms often lead to power failure, because too few studies from the database contribute to the statistical estimations. We design a probabilistic domain-specific language (DSL) standing on Datalog and one of its probabilistic extensions, CP-Logic, for expressing and solving complex logic-based queries. We show how CBMA databases can be encoded as probabilistic programs. Using the joint distribution of their Bayesian network translation, we show that solutions of queries on these programs compute the right probability distributions of voxel activations. We explain how recent lifted query processing algorithms make it possible to scale to the size of large neuroimaging data, where knowledge compilation techniques fail to solve queries fast enough for practical applications. Finally, we introduce a method for relating studies to terms probabilistically, leading to better solutions for two-term conjunctive queries (CQs) on smaller databases. We demonstrate results for two-term CQs, both on simulated meta-analysis databases and on the widely used Neurosynth database",
    "checked": true,
    "id": "01c8fe7e0fe22a8c8d1496de8808d99c65df7069",
    "semantic_title": "complex coordinate-based meta-analysis with probabilistic programming",
    "citation_count": 1,
    "authors": [
      "Valentin Iovene",
      "Gaston E Zanitti",
      "Demian Wassermann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16097": {
    "title": "Who You Would Like to Share With? A Study of Share Recommendation in Social E-commerce",
    "volume": "main",
    "abstract": "The prosperous development of social e-commerce has spawned diverse recommendation demands, and accompanied a new recommendation paradigm, share recommendation. SigniÔ¨Åcantly different from traditional binary recommendations (e.g., item recommendation and friend recommendation), share recommendation models ternary interactions among „Äà User, Item, Friend „Äâ , which aims to recommend a most likely friend to a user who would like to share a speciÔ¨Åc item, progressively becoming an indispensable service in social e-commerce. Seamlessly integrating the social relations and purchase behaviours, share recommendation improves user stickiness and monetizes the user inÔ¨Çuence, meanwhile encountering three unique challenges: rich heterogeneous information, complex ternary interaction, and asymmetric share action. In this paper, we Ô¨Årst study the share recommendation problem and propose a heterogeneous graph neural network based share recommendation model, called HGSRec. SpeciÔ¨Åcally, HGSRec delicately designs a tripartite heterogeneous GNNs to describe the multifold characteristics of users and items, and then dynamically fuses them via capturing potential ternary dependency with a dual co-attention mechanism, followed by a transitive triplet representation to depict the asymmetry of share action and predict whether share action happens. OfÔ¨Çine experiments demonstrate the superiority of the proposed HGSRec with signiÔ¨Åcant improvements (11.7%-14.5%) over the state-of-the-arts, and online A/B testing on Taobao platform further demonstrates the high industrial practicability and stability of HGSRec",
    "checked": true,
    "id": "dc84ee6eec3d81b8293186eb196db7d239a71c81",
    "semantic_title": "who you would like to share with? a study of share recommendation in social e-commerce",
    "citation_count": 24,
    "authors": [
      "Houye Ji",
      "Junxiong Zhu",
      "Xiao Wang",
      "Chuan Shi",
      "Bai Wang",
      "Xiaoye Tan",
      "Yanghua Li",
      "Shaojian He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16098": {
    "title": "Estimating Calibrated Individualized Survival Curves with Deep Learning",
    "volume": "main",
    "abstract": "In survival analysis, deep learning approaches have been proposed for estimating an individual's probability of survival over some time horizon. Such approaches can capture complex non-linear relationships, without relying on restrictive assumptions regarding the relationship between an individual's characteristics and their underlying survival process. To date, however, these methods have focused primarily on optimizing discriminative performance and have ignored model calibration. Well-calibrated survival curves present realistic and meaningful probabilistic estimates of the true underlying survival process for an individual. However, due to the lack of ground-truth regarding the underlying stochastic process of survival for an individual, optimizing and measuring calibration in survival analysis is an inherently difficult task. In this work, we i) highlight the shortcomings of existing approaches in terms of calibration and ii) propose a new training scheme for optimizing deep survival analysis models that maximizes discriminative performance, subject to good calibration. Compared to state-of-the-art approaches across two publicly available datasets, our proposed training scheme leads to significant improvements in calibration, while maintaining good discriminative performance",
    "checked": true,
    "id": "109f81447b6206c7bd8a0efc48b2c22ff9fc6ca2",
    "semantic_title": "estimating calibrated individualized survival curves with deep learning",
    "citation_count": 7,
    "authors": [
      "Fahad Kamran",
      "Jenna Wiens"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16099": {
    "title": "Deep Contextual Clinical Prediction with Reverse Distillation",
    "volume": "main",
    "abstract": "Healthcare providers are increasingly using machine learning to predict patient outcomes to make meaningful interventions. However, despite innovations in this area, deep learning models often struggle to match performance of shallow linear models in predicting these outcomes, making it difficult to leverage such techniques in practice. In this work, motivated by the task of clinical prediction from insurance claims, we present a new technique called reverse distillation which pretrains deep models by using high-performing linear models for initialization. We make use of the longitudinal structure of insurance claims datasets to develop Self Attention with Reverse Distillation, or SARD, an architecture that utilizes a combination of contextual embedding, temporal embedding and self-attention mechanisms and most critically is trained via reverse distillation. SARD outperforms state-of-the-art methods on multiple clinical prediction outcomes, with ablation studies revealing that reverse distillation is a primary driver of these improvements. Code is available at https://github.com/clinicalml/omop-learn",
    "checked": true,
    "id": "885015a0faa0903f170b9b588a5d1b14660dc20f",
    "semantic_title": "deep contextual clinical prediction with reverse distillation",
    "citation_count": 16,
    "authors": [
      "Rohan Kodialam",
      "Rebecca Boiarsky",
      "Justin Lim",
      "Aditya Sai",
      "Neil Dixit",
      "David Sontag"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16100": {
    "title": "Learning to Stop: Dynamic Simulation Monte-Carlo Tree Search",
    "volume": "main",
    "abstract": "Monte Carlo tree search (MCTS) has achieved state-of-the-art results in many domains such as Go and Atari games when combining with deep neural networks (DNNs). When more simulations are executed, MCTS can achieve higher performance but also requires enormous amounts of CPU and GPU resources. However, not all states require a long searching time to identify the best action that the agent can find. For example, in 19x19 Go and NoGo, we found that for more than half of the states, the best action predicted by DNN remains unchanged even after searching 2 minutes. This implies that a significant amount of resources can be saved if we are able to stop the searching earlier when we are confident with the current searching result. In this paper, we propose to achieve this goal by predicting the uncertainty of the current searching status and use the result to decide whether we should stop searching. With our algorithm, called Dynamic Simulation MCTS (DS-MCTS), we can speed up a NoGo agent trained by AlphaZero 2.5 times faster while maintaining a similar winning rate, which is critical for training and conducting experiments. Also, under the same average simulation count, our method can achieve a 61\\% winning rate against the original program",
    "checked": true,
    "id": "ad038ba73ba8a2b7d855624c7e107e711dd63790",
    "semantic_title": "learning to stop: dynamic simulation monte-carlo tree search",
    "citation_count": 3,
    "authors": [
      "Li-Cheng Lan",
      "Ti-Rong Wu",
      "I-Chen Wu",
      "Cho-Jui Hsieh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16101": {
    "title": "Predicting Livelihood Indicators from Community-Generated Street-Level Imagery",
    "volume": "main",
    "abstract": "Major decisions from governments and other large organizations rely on measurements of the populace's well-being, but making such measurements at a broad scale is expensive and thus infrequent in much of the developing world. We propose an inexpensive, scalable, and interpretable approach to predict key livelihood indicators from public crowd-sourced street-level imagery. Such imagery can be cheaply collected and more frequently updated compared to traditional surveying methods, while containing plausibly relevant information for a range of livelihood indicators. We propose two approaches to learn from the street-level imagery: (1) a method that creates multi-household cluster representations by detecting informative objects and (2) a graph-based approach that captures the relationships between images. By visualizing what features are important to a model and how they are used, we can help end-user organizations understand the models and offer an alternate approach for index estimation that uses cheaply obtained roadway features. By comparing our results against ground data collected in nationally-representative household surveys, we demonstrate the performance of our approach in accurately predicting indicators of poverty, population, and health and its scalability by testing in two different countries, India and Kenya. Our code is available at https://github.com/sustainlab-group/mapillarygcn",
    "checked": true,
    "id": "87db72bfebf9226e338279a452c6638ec0f8ab8a",
    "semantic_title": "predicting livelihood indicators from community-generated street-level imagery",
    "citation_count": 9,
    "authors": [
      "Jihyeon Lee",
      "Dylan Grosz",
      "Burak Uzkent",
      "Sicheng Zeng",
      "Marshall Burke",
      "David Lobell",
      "Stefano Ermon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16102": {
    "title": "Deep Conservation: A Latent-Dynamics Model for Exact Satisfaction of Physical Conservation Laws",
    "volume": "main",
    "abstract": "This work proposes an approach for latent-dynamics learning that exactly enforces physical conservation laws. The method comprises two steps. First, the method computes a low-dimensional embedding of the high-dimensional dynamical-system state using deep convolutional autoencoders. This defines a low-dimensional nonlinear manifold on which the state is subsequently enforced to evolve. Second, the method defines a latent-dynamics model that associates with the solution to a constrained optimization problem. Here, the objective function is defined as the sum of squares of conservation-law violations over control volumes within a finite-volume discretization of the problem; nonlinear equality constraints explicitly enforce conservation over prescribed subdomains of the problem. Under modest conditions, the resulting dynamics model guarantees that the time-evolution of the latent state exactly satisfies conservation laws over the prescribed subdomains",
    "checked": true,
    "id": "02327b889e75a9d86d4351cfea7c17e730d8efa4",
    "semantic_title": "deep conservation: a latent-dynamics model for exact satisfaction of physical conservation laws",
    "citation_count": 42,
    "authors": [
      "Kookjin Lee",
      "Kevin T. Carlberg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16103": {
    "title": "Two-Stream Convolution Augmented Transformer for Human Activity Recognition",
    "volume": "main",
    "abstract": "Recognition of human activities is an important task due to its far-reaching applications such as healthcare system, context-aware applications, and security monitoring. Recently, WiFi based human activity recognition (HAR) is becoming ubiquitous due to its non-invasiveness. Existing WiFi-based HAR methods regard WiFi signals as a temporal sequence of channel state information (CSI), and employ deep sequential models (e.g., RNN, LSTM) to automatically capture channel-over-time features. Although being remarkably effective, they suffer from two major drawbacks. Firstly, the granularity of a single temporal point is blindly elementary for representing meaningful CSI patterns. Secondly, the time-over-channel features are also important, and could be a natural data augmentation. To address the drawbacks, we propose a novel Two-stream Convolution Augmented Human Activity Transformer (THAT) model. Our model proposes to utilize a two-stream structure to capture both time-over-channel and channel-over-time features, and use the multi-scale convolution augmented transformer to capture range-based patterns. Extensive experiments on four real experiment datasets demonstrate that our model outperforms state-of-the-art models in terms of both effectiveness and efficiency",
    "checked": true,
    "id": "a3196e65467b80f4755968923b382e40c02ccb51",
    "semantic_title": "two-stream convolution augmented transformer for human activity recognition",
    "citation_count": 65,
    "authors": [
      "Bing Li",
      "Wei Cui",
      "Wei Wang",
      "Le Zhang",
      "Zhenghua Chen",
      "Min Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16104": {
    "title": "Traffic Flow Prediction with Vehicle Trajectories",
    "volume": "main",
    "abstract": "This paper proposes a spatiotemporal deep learning framework, Trajectory-based Graph Neural Network (TrGNN), that mines the underlying causality of flows from historical vehicle trajectories and incorporates that into road traffic prediction. The vehicle trajectory transition patterns are studied to explicitly model the spatial traffic demand via graph propagation along the road network; an attention mechanism is designed to learn the temporal dependencies based on neighborhood traffic status; and finally, a fusion of multi-step prediction is integrated into the graph neural network design. The proposed approach is evaluated with a real-world trajectory dataset. Experiment results show that the proposed TrGNN model achieves over 5% error reduction when compared with the state-of-the-art approaches across all metrics for normal traffic, and up to 14% for atypical traffic during peak hours or abnormal events. The advantage of trajectory transitions especially manifest itself in inferring high fluctuation of flows as well as non-recurrent flow patterns",
    "checked": true,
    "id": "92a192e9852576bf0618cc6846973af840a48a77",
    "semantic_title": "traffic flow prediction with vehicle trajectories",
    "citation_count": 20,
    "authors": [
      "Mingqian Li",
      "Panrong Tong",
      "Mo Li",
      "Zhongming Jin",
      "Jianqiang Huang",
      "Xian-Sheng Hua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16105": {
    "title": "RevMan: Revenue-aware Multi-task Online Insurance Recommendation",
    "volume": "main",
    "abstract": "Online insurance is a new type of e-commerce with exponential growth. An effective recommendation model that maximizes the total revenue of insurance products listed in multiple customized sales scenarios is crucial for the success of online insurance business. Prior recommendation models are ineffective because they fail to characterize the complex relatedness of insurance products in multiple sales scenarios and maximize the overall conversion rate rather than the total revenue. Even worse, it is impractical to collect training data online for total revenue maximization due to the business logic of online insurance. We propose RevMan, a Revenue-aware Multi-task Network for online insurance recommendation. RevMan adopts an adaptive attention mechanism to allow effective feature sharing among complex insurance products and sales scenarios. It also designs an efficient offline learning mechanism to learn the rank that maximizes the expected total revenue, by reusing training data and model for conversion rate maximization. Extensive offline and online evaluations show that RevMan outperforms the state-of-the-art recommendation systems for e-commerce",
    "checked": true,
    "id": "91d6a9159151f5e7d10843cd574d7c5ecf45e21a",
    "semantic_title": "revman: revenue-aware multi-task online insurance recommendation",
    "citation_count": 7,
    "authors": [
      "Yu Li",
      "Yi Zhang",
      "Lu Gan",
      "Gengwei Hong",
      "Zimu Zhou",
      "Qiang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16106": {
    "title": "MeInGame: Create a Game Character Face from a Single Portrait",
    "volume": "main",
    "abstract": "Many deep learning based 3D face reconstruction methods have been proposed recently, however, few of them have applications in games. Current game character customization systems either require players to manually adjust considerable face attributes to obtain the desired face, or have limited freedom of facial shape and texture. In this paper, we propose an automatic character face creation method that predicts both facial shape and texture from a single portrait, and it can be integrated into most existing 3D games. Although 3D Morphable Face Model (3DMM) based methods can restore accurate 3D faces from single images, the topology of 3DMM mesh is different from the meshes used in most games. To acquire fidelity texture, existing methods require a large amount of face texture data for training, while building such datasets is time-consuming and laborious. Besides, such a dataset collected under laboratory conditions may not generalized well to in-the-wild situations. To tackle these problems, we propose 1) a low-cost facial texture acquisition method, 2) a shape transfer algorithm that can transform the shape of a 3DMM mesh to games, and 3) a new pipeline for training 3D game face reconstruction networks. The proposed method not only can produce detailed and vivid game characters similar to the input portrait, but can also eliminate the influence of lighting and occlusions. Experiments show that our method outperforms state-of-the-art methods used in games. Code and dataset are available at https://github.com/FuxiCV/MeInGame",
    "checked": true,
    "id": "e532172848febb7a0a42b853279ad948a2afdb5b",
    "semantic_title": "meingame: create a game character face from a single portrait",
    "citation_count": 20,
    "authors": [
      "Jiangke Lin",
      "Yi Yuan",
      "Zhengxia Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16107": {
    "title": "Community-Aware Multi-Task Transportation Demand Prediction",
    "volume": "main",
    "abstract": "Transportation demand prediction is of great importance to urban governance and has become an essential function in many online applications. While many efforts have been made for regional transportation demand prediction, predicting the diversified transportation demand for different communities (e.g., the aged, the juveniles) remains an unexplored problem. However, this task is challenging because of the joint influence of spatio-temporal correlation among regions and implicit correlation among different communities. To this end, in this paper, we propose the Multi-task Spatio-Temporal Network with Mutually-supervised Adaptive task grouping (Ada-MSTNet) for community-aware transportation demand prediction. Specifically, we first construct a sequence of multi-view graphs from both spatial and community perspectives, and devise a spatio-temporal neural network to simultaneously capture the sophisticated correlations between regions and communities, respectively. Then, we propose an adaptively clustered multi-task learning module, where the prediction of each region-community specific transportation demand is regarded as distinct task. Moreover, a mutually supervised adaptive task grouping strategy is introduced to softly cluster each task into different task groups, by leveraging the supervision signal from one another graph view. In such a way, Ada-MSTNet is not only able to share common knowledge among highly related communities and regions, but also shield the noise from unrelated tasks in an end-to-end fashion. Finally, extensive experiments on two real-world datasets demonstrate the effectiveness of our approach compared with seven baselines",
    "checked": true,
    "id": "6738bad94c8b65ec02088c9c15f9454fdb56b306",
    "semantic_title": "community-aware multi-task transportation demand prediction",
    "citation_count": 18,
    "authors": [
      "Hao Liu",
      "Qiyu Wu",
      "Fuzhen Zhuang",
      "Xinjiang Lu",
      "Dejing Dou",
      "Hui Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16108": {
    "title": "Asynchronous Stochastic Gradient Descent for Extreme-Scale Recommender Systems",
    "volume": "main",
    "abstract": "Recommender systems are influential for many internet applications. As the size of the dataset provided for a recommendation model grows rapidly, how to utilize such amount of data effectively matters a lot. For a typical Click-Through-Rate(CTR) prediction model, the amount of daily samples can probably be up to hundreds of terabytes, which reaches dozens of petabytes at an extreme-scale when we take several days into consideration. Such data makes it essential to train the model parallelly and continuously. Traditional asynchronous stochastic gradient descent (ASGD) and its variants are proved efficient but often suffer from stale gradients. Hence, the model convergence tends to be worse as more workers are used. Moreover, the existing adaptive optimizers, which are friendly to sparse data, stagger in long-term training due to the significant imbalance between new and accumulated gradients. To address the challenges posed by extreme-scale data, we propose: 1) Staleness normalization and data normalization to eliminate the turbulence of stale gradients when training asynchronously in hundreds and thousands of workers; 2) SWAP, a novel framework for adaptive optimizers to balance the new and historical gradients by taking sampling period into consideration. We implement these approaches in TensorFlow and apply them to CTR tasks in real-world e- commerce scenarios. Experiments show that the number of workers in asynchronous training can be extended to 3000 with guaranteed convergence, and the final AUC is improved by more than 5 percentage",
    "checked": true,
    "id": "fc50a687bb3ee2c39a35304ca42a095460dd8ddd",
    "semantic_title": "asynchronous stochastic gradient descent for extreme-scale recommender systems",
    "citation_count": 0,
    "authors": [
      "Lewis Liu",
      "Kun Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16109": {
    "title": "In-game Residential Home Planning via Visual Context-aware Global Relation Learning",
    "volume": "main",
    "abstract": "In this paper, we propose an effective global relation learning algorithm to recommend an appropriate location of a building unit for in-game customization of residential home complex. Given a construction layout, we propose a visual context-aware graph generation network that learns the implicit global relations among the scene components and infers the location of a new building unit. The proposed network takes as input the scene graph and the corresponding top-view depth image. It provides the location recommendations for a newly added building units by learning an auto-regressive edge distribution conditioned on existing scenes. We also introduce a global graph-image matching loss to enhance the awareness of essential geometry semantics of the site. Qualitative and quantitative experiments demonstrate that the recommended location well reflects the implicit spatial rules of components in the residential estates, and it is instructive and practical to locate the building units in the 3D scene of the complex construction",
    "checked": true,
    "id": "2b446c6ec0ba9a2a81fb70016c675bfb452f8df6",
    "semantic_title": "in-game residential home planning via visual context-aware global relation learning",
    "citation_count": 1,
    "authors": [
      "Lijuan Liu",
      "Yin Yang",
      "Yi Yuan",
      "Tianjia Shao",
      "He Wang",
      "Kun Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16110": {
    "title": "Relational Classification of Biological Cells in Microscopy Images",
    "volume": "main",
    "abstract": "We investigate the relational classification of biological cells in 2D microscopy images. Rather than treating each cell image independently, we investigate whether and how the neighborhood information of a cell can be informative for its prediction. We propose a Relational Long Short-Term Memory (R-LSTM) algorithm, coupled with auto-encoders and convolutional neural networks, that can learn from both annotated and unlabeled microscopy images and that can utilize both the local and neighborhood information to perform an improved classification of biological cells. Experimental results on both synthetic and real datasets show that R-LSTM performs comparable to or better than six baselines",
    "checked": true,
    "id": "bc1de021523d712169c1591d8ce93cfe29185482",
    "semantic_title": "relational classification of biological cells in microscopy images",
    "citation_count": 1,
    "authors": [
      "Ping Liu",
      "Mustafa Bilgic"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16111": {
    "title": "Deep Style Transfer for Line Drawings",
    "volume": "main",
    "abstract": "Line drawings are frequently used to illustrate ideas and concepts in digital documents and presentations. To compose a line drawing, it is common for users to retrieve multiple line drawings from the Internet and combine them as one image. However, different line drawings may have different line styles and are visually inconsistent when put together. In order that the line drawings can have consistent looks, in this paper, we make the first attempt to perform style transfer for line drawings. The key of our design lies in the fact that centerline plays a very important role in preserving line topology and extracting style features. With this finding, we propose to formulate the style transfer problem as a centerline stylization problem and solve it via a novel style-guided image-to-image translation network. Results and statistics show that our method significantly outperforms the existing methods both visually and quantitatively",
    "checked": true,
    "id": "f5eec0ff44d936701e3a769917f03b8a60af9086",
    "semantic_title": "deep style transfer for line drawings",
    "citation_count": 3,
    "authors": [
      "Xueting Liu",
      "Wenliang Wu",
      "Huisi Wu",
      "Zhenkun Wen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16112": {
    "title": "RNA Secondary Structure Representation Network for RNA-proteins Binding Prediction",
    "volume": "main",
    "abstract": "RNA-binding proteins (RBPs) play a significant part in several biological processes in the living cell, such as gene regulation and mRNA localization. Several deep learning methods, especially the model based on convolutional neural network(CNN), have been used to predict the binding sites. However, previous methods fail to represent RNA secondary structure features. The traditional deep learning methods generally transform the RNA secondary structure to a regular matrix that cannot reveal the topological structure information of RNA. To effectively extract the structure features of RNA, we propose an RNA secondary structure representation network (RNASSR-Net) based on graph convolutional neural network (GCN) and convolution neural network (CNN) for RBP binding prediction. RNASSR-Net constructs the graph model derived from the RNA secondary structure to learn the topological properties of RNA. Then, it obtains the spatial importance of each base in RNA with CNN to guide the representation of the RNA secondary structure. Finally, RNASSR-Net combines the structure and sequence features to predict the binding sites. Experimental results demonstrate the proposed method outperforms a few state-of-the-art methods on the benchmark datasets and gets a higher improvement on the small-size data. Besides, the proposed RNASSR-Net is also used to detect the accurate motifs compared with the experimentally verified motifs, which reveals the binding region location and RNA structure interpretation for some biological guidance in the future",
    "checked": true,
    "id": "428a7f685a1bc12e3bfda32ba97f75262e260560",
    "semantic_title": "rna secondary structure representation network for rna-proteins binding prediction",
    "citation_count": 3,
    "authors": [
      "Ziyi Liu",
      "Fulin Luo",
      "Bo Du"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16113": {
    "title": "PANTHER: Pathway Augmented Nonnegative Tensor Factorization for HighER-order Feature Learning",
    "volume": "main",
    "abstract": "Genetic pathways usually encode molecular mechanisms that can inform targeted interventions. It is often challenging for existing machine learning approaches to jointly model genetic pathways (higher-order features) and variants (atomic features), and present to clinicians interpretable models. In order to build more accurate and better interpretable machine learning models for genetic medicine, we introduce Pathway Augmented Nonnegative Tensor factorization for HighER-order feature learning (PANTHER). PANTHER selects informative genetic pathways that directly encode molecular mechanisms. We apply genetically motivated constrained tensor factorization to group pathways in a way that reflects molecular mechanism interactions. We then train a softmax classifier for disease types using the identified pathway groups. We evaluated PANTHER against multiple state-of-the-art constrained tensor/matrix factorization models, as well as group guided and Bayesian hierarchical models. PANTHER outperforms all state-of-the-art comparison models significantly (p<0.05). Our experiments on large scale Next Generation Sequencing (NGS) and whole-genome genotyping datasets also demonstrated wide applicability of PANTHER. We performed feature analysis in predicting disease types, which suggested insights and benefits of the identified pathway groups",
    "checked": true,
    "id": "303149806dc5be379b4c1fc7070092437b3a6ad0",
    "semantic_title": "panther: pathway augmented nonnegative tensor factorization for higher-order feature learning",
    "citation_count": 9,
    "authors": [
      "Yuan Luo",
      "Chengsheng Mao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16114": {
    "title": "Programmatic Strategies for Real-Time Strategy Games",
    "volume": "main",
    "abstract": "Search-based systems have shown to be effective for planning in zero-sum games. However, search-based approaches have important disadvantages. First, the decisions of search algorithms are mostly non-interpretable, which is problematic in domains where predictability and trust are desired such as commercial games. Second, the computational complexity of search-based algorithms might limit their applicability, especially in contexts where resources are shared among other tasks such as graphic rendering. In this work we introduce a system for synthesizing programmatic strategies for a real-time strategy (RTS) game. In contrast with search algorithms, programmatic strategies are more amenable to explanations and tend to be efficient, once the program is synthesized. Our system uses a novel algorithm for simplifying domain-specific languages (DSLs) and a local search algorithm that synthesizes programs with self play. We performed a user study where we enlisted four professional programmers to develop programmatic strategies for mRTS, a minimalist RTS game. Our results show that the programs synthesized by our approach can outperform search algorithms and be competitive with programs written by the programmers",
    "checked": true,
    "id": "c34d71c8eb4d179562d7d658b08b62ff8a587503",
    "semantic_title": "programmatic strategies for real-time strategy games",
    "citation_count": 3,
    "authors": [
      "Julian R. H. Mari√±o",
      "Rubens O. Moraes",
      "Tassiana C. Oliveira",
      "Claudio Toledo",
      "Levi H. S. Lelis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16115": {
    "title": "Capturing Uncertainty in Unsupervised GPS Trajectory Segmentation Using Bayesian Deep Learning",
    "volume": "main",
    "abstract": "Intelligent transportation management requires not only statistical information on users' mobility patterns, but also knowledge of their corresponding transportation modes. While GPS trajectories can be readily obtained from GPS sensors found in modern smartphones and vehicles, these massive geospatial data are neither automatically annotated nor segmented by transportation mode, subsequently complicating transportation mode identification. In addition, predictive uncertainty caused by the learned model parameters or variable noise in GPS sensor readings typically remains unaccounted for. To jointly address the above issues, we propose a Bayesian deep learning framework for unsupervised GPS trajectory segmentation. After unlabeled GPS trajectories are preprocessed into sequences of motion features, they are used in unsupervised training of a channel-calibrated temporal convolutional neural network for timestep-level transportation mode identification. At test time, we approximate variational inference via Monte Carlo dropout sampling, leveraging the mean and variance of the predicted distributions to classify each input timestep and estimate its predictive uncertainty, respectively. The proposed approach outperforms both its non-Bayesian variant and established GPS trajectory segmentation baselines on Microsoft's Geolife dataset without using any labels",
    "checked": true,
    "id": "b40d7a8c86fcfc13c22de33c96aa6f15039263d6",
    "semantic_title": "capturing uncertainty in unsupervised gps trajectory segmentation using bayesian deep learning",
    "citation_count": 4,
    "authors": [
      "Christos Markos",
      "James J. Q. Yu",
      "Richard Yi Da Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16116": {
    "title": "Low-Rank Registration Based Manifolds for Convection-Dominated PDEs",
    "volume": "main",
    "abstract": "We develop an auto-encoder-type nonlinear dimensionality reduction algorithm to enable the construction of reduced order models of systems governed by convection-dominated nonlinear partial differential equations (PDEs), i.e. snapshots of solutions with large Kolmogorov n-width. Although several existing nonlinear manifold learning methods, such as LLE, ISOMAP, MDS, etc., appear as compelling candidates to reduce the dimensionality of such data, most are not applicable to reduced order modeling of PDEs, because: (i) they typically lack a straightforward mapping from the latent space to the high-dimensional physical space, and (ii) the identified latent variables are often difficult to interpret. In our proposed method, these limitations are overcome by training a low-rank diffeomorphic spatio-temporal grid that registers the output sequence of the PDEs on a non-uniform parameter/time-varying grid, such that the Kolmogorov n-width of the mapped data on the learned grid is minimized. We demonstrate the efficacy and interpretability of our proposed approach on several challenging manufactured computer vision-inspired tasks and physical systems",
    "checked": false,
    "id": "84a0669d590df93a8fb99b8bc7bd6d501606bb7b",
    "semantic_title": "physics-aware registration based auto-encoder for convection dominated pdes",
    "citation_count": 20,
    "authors": [
      "Rambod Mojgani",
      "Maciej Balajewicz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16117": {
    "title": "Symbolic Music Generation with Transformer-GANs",
    "volume": "main",
    "abstract": "Autoregressive models using Transformers have emerged as the dominant approach for music generation with the goal of synthesizing minute-long compositions that exhibit large-scale musical structure. These models are commonly trained by minimizing the negative log-likelihood (NLL) of the observed sequence in an autoregressive manner. Unfortunately, the quality of samples from these models tends to degrade significantly for long sequences, a phenomenon attributed to exposure bias. Fortunately, we are able to detect these failures with classifiers trained to distinguish between real and sampled sequences, an observation that motivates our exploration of adversarial losses to complement the NLL objective. We use a pre-trained Span-BERT model for the discriminator of the GAN, which in our experiments helped with training stability. We use the Gumbel-Softmax trick to obtain a differentiable approximation of the sampling process. This makes discrete sequences amenable to optimization in GANs. In addition, we break the sequences into smaller chunks to ensure that we stay within a given memory budget. We demonstrate via human evaluations and a new discriminative metric that the music generated by our approach outperforms a baseline trained with likelihood maximization, the state-of-the-art Music Transformer, and other GANs used for sequence generation. 57% of people prefer music generated via our approach while 43% prefer Music Transformer",
    "checked": true,
    "id": "f07c5c540233b22f0ca154c80c713e2aed3c9606",
    "semantic_title": "symbolic music generation with transformer-gans",
    "citation_count": 33,
    "authors": [
      "Aashiq Muhamed",
      "Liang Li",
      "Xingjian Shi",
      "Suri Yaddanapudi",
      "Wayne Chi",
      "Dylan Jackson",
      "Rahul Suresh",
      "Zachary C. Lipton",
      "Alex J. Smola"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16118": {
    "title": "Bringing UMAP Closer to the Speed of Light with GPU Acceleration",
    "volume": "main",
    "abstract": "The Uniform Manifold Approximation and Projection (UMAP) algorithm has become widely popular for its ease of use, quality of results, and support for exploratory, unsupervised, supervised, and semi-supervised learning. While many algorithms can be ported to a GPU in a simple and direct fashion, such efforts have resulted in inefficent and inaccurate versions of UMAP. We show a number of techniques that can be used to make a faster and more faithful GPU version of UMAP, and obtain speedups of up to 100x in practice. Many of these design choices/lessons are general purpose and may inform the conversion of other graph and manifold learning algorithms to use GPUs. Our implementation has been made publicly available as part of the open source RAPIDS cuML library (https://github.com/rapidsai/cuml)",
    "checked": true,
    "id": "5b17bfb51597d158100ba3f53148f37ac6aaf7c0",
    "semantic_title": "bringing umap closer to the speed of light with gpu acceleration",
    "citation_count": 23,
    "authors": [
      "Corey J. Nolet",
      "Victor Lafargue",
      "Edward Raff",
      "Thejaswi Nanditale",
      "Tim Oates",
      "John Zedlewski",
      "Joshua Patterson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16119": {
    "title": "Deep Just-In-Time Inconsistency Detection Between Comments and Source Code",
    "volume": "main",
    "abstract": "Natural language comments convey key aspects of source code such as implementation, usage, and pre- and post-conditions. Failure to update comments accordingly when the corresponding code is modified introduces inconsistencies, which is known to lead to confusion and software bugs. In this paper, we aim to detect whether a comment becomes inconsistent as a result of changes to the corresponding body of code, in order to catch potential inconsistencies just-in-time, i.e., before they are committed to a code base. To achieve this, we develop a deep-learning approach that learns to correlate a comment with code changes. By evaluating on a large corpus of comment/code pairs spanning various comment types, we show that our model outperforms multiple baselines by significant margins. For extrinsic evaluation, we show the usefulness of our approach by combining it with a comment update model to build a more comprehensive automatic comment maintenance system which can both detect and resolve inconsistent comments based on code changes",
    "checked": true,
    "id": "03b6e258168796f96f1c40d32411bd699b6de922",
    "semantic_title": "deep just-in-time inconsistency detection between comments and source code",
    "citation_count": 22,
    "authors": [
      "Sheena Panthaplackel",
      "Junyi Jessy Li",
      "Milos Gligoric",
      "Raymond J. Mooney"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16120": {
    "title": "XraySyn: Realistic View Synthesis From a Single Radiograph Through CT Priors",
    "volume": "main",
    "abstract": "A radiograph visualizes the internal anatomy of a patient through the use of X-ray, which projects 3D information onto a 2D plane. Hence, radiograph analysis naturally requires physicians to relate their prior knowledge about 3D human anatomy to 2D radiographs. Synthesizing novel radiographic views in a small range can assist physicians in interpreting anatomy more reliably; however, radiograph view synthesis is heavily ill-posed, lacking in paired data, and lacking in differentiable operations to leverage learning-based approaches. To address these problems, we use Computed Tomography (CT) for radiograph simulation and design a differentiable projection algorithm, which enables us to achieve geometrically consistent transformations between the radiography and CT domains. Our method, XraySyn, can synthesize novel views on real radiographs through a combination of realistic simulation and finetuning on real radiographs. To the best of our knowledge, this is the first work on radiograph view synthesis. We show that by gaining an understanding of radiography in 3D space, our method can be applied to radiograph bone extraction and suppression without requiring groundtruth bone labels",
    "checked": true,
    "id": "dbe6bff16563ba3b821f8fd5a93d298d0fd9517a",
    "semantic_title": "xraysyn: realistic view synthesis from a single radiograph through ct priors",
    "citation_count": 6,
    "authors": [
      "Cheng Peng",
      "Haofu Liao",
      "Gina Wong",
      "Jiebo Luo",
      "S. Kevin Zhou",
      "Rama Chellappa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16121": {
    "title": "Pragmatic Code Autocomplete",
    "volume": "main",
    "abstract": "Human language is ambiguous, with intended meanings recovered via pragmatic reasoning in context. Such reliance on context is essential for the efficiency of human communication. Programming languages, in stark contrast, are defined by unambiguous grammars. In this work, we aim to make programming languages more concise by allowing programmers to utilize a controlled level of ambiguity. Specifically, we allow single-character abbreviations for common keywords and identifiers. Our system first proposes a set of strings that can be abbreviated by the user. Using only 100 abbreviations, we observe that a large dataset of Python code can be compressed by 15%, a number that can be improved even further by specializing the abbreviations to a particular code base. We then use a contextualized sequence-to-sequence model to rank potential expansions of inputs that include abbreviations. In an offline reconstruction task our model achieves accuracies ranging from 93% to 99%, depending on the programming language and user settings. The model is small enough to run on a commodity CPU in real-time. We evaluate the usability of our system in a user study, integrating it in Microsoft VSCode, a popular code text editor. We observe that our system performs well and is complementary to traditional autocomplete features",
    "checked": true,
    "id": "2db9df2f4d896f43b05fb6155cce593fd748cf29",
    "semantic_title": "pragmatic code autocomplete",
    "citation_count": 1,
    "authors": [
      "Gabriel Poesia",
      "Noah Goodman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16122": {
    "title": "RareBERT: Transformer Architecture for Rare Disease Patient Identification using Administrative Claims",
    "volume": "main",
    "abstract": "A rare disease is any disease that affects a very small percentage (1 in 1,500) of population. It is estimated that there are nearly 7,000 rare disease affecting 30 million patients in the U. S. alone. Most of the patients suffering from rare diseases experience multiple misdiagnoses and may never be diagnosed correctly. This is largely driven by the low prevalence of the disease that results in a lack of awareness among healthcare providers. There have been efforts from machine learning researchers to develop predictive models to help diagnose patients using healthcare datasets such as electronic health records and administrative claims. Most recently, transformer models have been applied to predict diseases BEHRT, G-BERT and Med-BERT. However, these have been developed specifically for electronic health records (EHR) and have not been designed to address rare disease challenges such as class imbalance, partial longitudinal data capture, and noisy labels. As a result, they deliver poor performance in predicting rare diseases compared with baselines. Besides, EHR datasets are generally confined to the hospital systems using them and do not capture a wider sample of patients thus limiting the availability of sufficient rare dis-ease patients in the dataset. To address these challenges, we introduced an extension of the BERT model tailored for rare disease diagnosis called RareBERT which has been trained on administrative claims datasets. RareBERT extends Med-BERT by including context embedding and temporal reference embedding. Moreover, we introduced a novel adaptive loss function to handle the class imbal-ance. In this paper, we show our experiments on diagnosing X-Linked Hypophosphatemia (XLH), a genetic rare disease. While RareBERT performs significantly better than the baseline models (79.9% AUPRC versus 30% AUPRC for Med-BERT), owing to the transformer architecture, it also shows its robustness in partial longitudinal data capture caused by poor capture of claims with a drop in performance of only 1.35% AUPRC, compared with 12% for Med-BERT and 33.0% for LSTM and 67.4% for boosting trees based baseline",
    "checked": true,
    "id": "66d1f09daff4d3bf4deb3148ce5e080e71d82ca3",
    "semantic_title": "rarebert: transformer architecture for rare disease patient identification using administrative claims",
    "citation_count": 19,
    "authors": [
      "PKS Prakash",
      "Srinivas Chilukuri",
      "Nikhil Ranade",
      "Shankar Viswanathan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16123": {
    "title": "Queue-Learning: A Reinforcement Learning Approach for Providing Quality of Service",
    "volume": "main",
    "abstract": "End-to-end delay is a critical attribute of quality of service (QoS) in application domains such as cloud computing and computer networks. This metric is particularly important in tandem service systems, where the end-to-end service is provided through a chain of services. Service-rate control is a common mechanism for providing QoS guarantees in service systems. In this paper, we introduce a reinforcement learning-based (RL-based) service-rate controller that provides probabilistic upper-bounds on the end-to-end delay of the system, while preventing the overuse of service resources. In order to have a general framework, we use queueing theory to model the service systems. However, we adopt an RL-based approach to avoid the limitations of queueing-theoretic methods. In particular, we use Deep Deterministic Policy Gradient (DDPG) to learn the service rates (action) as a function of the queue lengths (state) in tandem service systems. In contrast to existing RL-based methods that quantify their performance by the achieved overall reward, which could be hard to interpret or even misleading, our proposed controller provides explicit probabilistic guarantees on the end-to-end delay of the system. The evaluations are presented for a tandem queueing system with non-exponential inter-arrival and service times, the results of which validate our controller's capability in meeting QoS constraints",
    "checked": true,
    "id": "fd15384646a386521ee4824c35011bc17e6fa987",
    "semantic_title": "queue-learning: a reinforcement learning approach for providing quality of service",
    "citation_count": 8,
    "authors": [
      "Majid Raeis",
      "Ali Tizghadam",
      "Alberto Leon-Garcia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16124": {
    "title": "Research Reproducibility as a Survival Analysis",
    "volume": "main",
    "abstract": "There has been increasing concern within the machine learning community that we are in a reproducibility crisis. As many have begun to work on this problem, all work we are aware of treat the issue of reproducibility as an intrinsic binary property: a paper is or is not reproducible. Instead, we consider modeling the reproducibility of a paper as a survival analysis problem. We argue that this perspective represents a more accurate model of the underlying meta-science question of reproducible research, and we show how a survival analysis allows us to draw new insights that better explain prior longitudinal data. The data and code can be found at https://github.com/EdwardRaff/Research-Reproducibility-Survival-Analysis",
    "checked": true,
    "id": "9d8b7b2c4e7a006cbaf4418804318647b6a4fe99",
    "semantic_title": "research reproducibility as a survival analysis",
    "citation_count": 14,
    "authors": [
      "Edward Raff"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16125": {
    "title": "DeepPseudo: Pseudo Value Based Deep Learning Models for Competing Risk Analysis",
    "volume": "main",
    "abstract": "Competing Risk Analysis (CRA) aims at the correct estimation of the marginal probability of occurrence of an event in the presence of competing events. Many of the statistical approaches developed for CRA are limited by strong assumptions about the underlying stochastic processes. To overcome these issues and to handle censoring, machine learning approaches for CRA have designed specialized cost functions. However, these approaches are not generalizable, and are computationally expensive. This paper formulates CRA as a cause-specific regression problem and proposes DeepPseudo models, which use simple and effective feed-forward deep neural networks, to predict the cumulative incidence function (CIF) using Aalen-Johansen estimator-based pseudo values. DeepPseudo models capture the time-varying covariate effect on CIF while handling the censored observations. We show how DeepPseudo models can address co-variate dependent censoring by using modified pseudo values. Experiments on real and synthetic datasets demonstrate that our proposed models obtain promising and statistically significant results compared to the state-of-the-art CRA approaches. Furthermore, we show that explainable methods such as Layer-wise Relevance Propagation can be used to interpret the predictions of our DeepPseudo models",
    "checked": true,
    "id": "90821085ac62d12d8849bd23a9d5e13c7229bfe2",
    "semantic_title": "deeppseudo: pseudo value based deep learning models for competing risk analysis",
    "citation_count": 12,
    "authors": [
      "Md Mahmudur Rahman",
      "Koji Matsuo",
      "Shinya Matsuzaki",
      "Sanjay Purushotham"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16126": {
    "title": "CardioGAN: Attentive Generative Adversarial Network with Dual Discriminators for Synthesis of ECG from PPG",
    "volume": "main",
    "abstract": "Electrocardiogram (ECG) is the electrical measurement of cardiac activity, whereas Photoplethysmogram (PPG) is the optical measurement of volumetric changes in blood circulation. While both signals are used for heart rate monitoring, from a medical perspective, ECG is more useful as it carries additional cardiac information. Despite many attempts toward incorporating ECG sensing in smartwatches or similar wearable devices for continuous and reliable cardiac monitoring, PPG sensors are the main feasible sensing solution available. In order to tackle this problem, we propose CardioGAN, an adversarial model which takes PPG as input and generates ECG as output. The proposed network utilizes an attention-based generator to learn local salient features, as well as dual discriminators to preserve the integrity of generated data in both time and frequency domains. Our experiments show that the ECG generated by CardioGAN provides more reliable heart rate measurements compared to the original input PPG, reducing the error from 9.74 beats per minute (measured from the PPG) to 2.89 (measured from the generated ECG)",
    "checked": true,
    "id": "61b661386940a48c1f66a22473e73561de530a01",
    "semantic_title": "cardiogan: attentive generative adversarial network with dual discriminators for synthesis of ecg from ppg",
    "citation_count": 24,
    "authors": [
      "Pritam Sarkar",
      "Ali Etemad"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16127": {
    "title": "Stock Selection via Spatiotemporal Hypergraph Attention Network: A Learning to Rank Approach",
    "volume": "main",
    "abstract": "Quantitative trading and investment decision making are intricate financial tasks that rely on accurate stock selection. Despite advances in deep learning that have made significant progress in the complex and highly stochastic stock prediction problem, modern solutions face two significant limitations. They do not directly optimize the target of investment in terms of profit, and treat each stock as independent from the others, ignoring the rich signals between related stocks' temporal price movements. Building on these limitations, we reformulate stock prediction as a learning to rank problem and propose STHAN-SR, a neural hypergraph architecture for stock selection. The key novelty of our work is the proposal of modeling the complex relations between stocks through a hypergraph and a temporal Hawkes attention mechanism to tailor a new spatiotemporal attention hypergraph network architecture to rank stocks based on profit by jointly modeling stock interdependence and the temporal evolution of their prices. Through experiments on three markets spanning over six years of data, we show that STHAN-SR significantly outperforms state-of-the-art neural stock forecasting methods. We validate our design choices through ablative and exploratory analyses over STHAN-SR's spatial and temporal components and demonstrate its practical applicability",
    "checked": true,
    "id": "4ed91fa585dc4e5cdbfb30b30711104a02f7e43e",
    "semantic_title": "stock selection via spatiotemporal hypergraph attention network: a learning to rank approach",
    "citation_count": 40,
    "authors": [
      "Ramit Sawhney",
      "Shivam Agarwal",
      "Arnav Wadhwa",
      "Tyler Derr",
      "Rajiv Ratn Shah"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16128": {
    "title": "Content Masked Loss: Human-Like Brush Stroke Planning in a Reinforcement Learning Painting Agent",
    "volume": "main",
    "abstract": "The objective of most Reinforcement Learning painting agents is to minimize the loss between a target image and the paint canvas. Human painter artistry emphasizes important features of the target image rather than simply reproducing it. Using adversarial or L2 losses in the RL painting models, although its final output is generally a work of finesse, produces a stroke sequence that is vastly different from that which a human would produce since the model does not have knowledge about the abstract features in the target image. In order to increase the human-like planning of the model without the use of expensive human data, we introduce a new loss function for use with the model's reward function: Content Masked Loss. In the context of robot painting, Content Masked Loss employs an object detection model to extract features which are used to assign higher weight to regions of the canvas that a human would find important for recognizing content. The results, based on 332 human evaluators, show that the digital paintings produced by our Content Masked model show detectable subject matter earlier in the stroke sequence than existing methods without compromising on the quality of the final painting. Our code is available at https://github.com/pschaldenbrand/ContentMaskedLoss",
    "checked": true,
    "id": "1b6978955a78e3b2060ce471d6e7a0c52185c219",
    "semantic_title": "content masked loss: human-like brush stroke planning in a reinforcement learning painting agent",
    "citation_count": 17,
    "authors": [
      "Peter Schaldenbrand",
      "Jean Oh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16129": {
    "title": "StatEcoNet: Statistical Ecology Neural Networks for Species Distribution Modeling",
    "volume": "main",
    "abstract": "This paper focuses on a core task in computational sustainability and statistical ecology: species distribution modeling (SDM). In SDM, the occurrence pattern of a species on a landscape is predicted by environmental features based on observations at a set of locations. At first, SDM may appear to be a binary classification problem, and one might be inclined to employ classic tools (e.g., logistic regression, support vector machines, neural networks) to tackle it. However, wildlife surveys introduce structured noise (especially under-counting) in the species observations. If unaccounted for, these observation errors systematically bias SDMs. To address the unique challenges of SDM, this paper proposes a framework called StatEcoNet. Specifically, this work employs a graphical generative model in statistical ecology to serve as the skeleton of the proposed computational framework and carefully integrates neural networks under the framework. The advantages of StatEcoNet over related approaches are demonstrated on simulated datasets as well as bird species data. Since SDMs are critical tools for ecological science and natural resource management, StatEcoNet may offer boosted computational and analytical powers to a wide range of applications that have significant social impacts, e.g., the study and conservation of threatened species",
    "checked": true,
    "id": "1011fff0d08d3af2c6c6f38426f0bb68e37c3002",
    "semantic_title": "stateconet: statistical ecology neural networks for species distribution modeling",
    "citation_count": 2,
    "authors": [
      "Eugene Seo",
      "Rebecca A. Hutchinson",
      "Xiao Fu",
      "Chelsea Li",
      "Tyler A. Hallman",
      "John Kilbride",
      "W. Douglas Robinson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16130": {
    "title": "Integrating Static and Dynamic Data for Improved Prediction of Cognitive Declines Using Augmented Genotype-Phenotype Representations",
    "volume": "main",
    "abstract": "Alzheimer's Disease (AD) is a chronic neurodegenerative disease that causes severe problems in patients' thinking, memory, and behavior. An early diagnosis is crucial to prevent AD progression; to this end, many algorithmic approaches have recently been proposed to predict cognitive decline. However, these predictive models often fail to integrate heterogeneous genetic and neuroimaging biomarkers and struggle to handle missing data. In this work we propose a novel objective function and an associated optimization algorithm to identify cognitive decline related to AD. Our approach is designed to incorporate dynamic neuroimaging data by way of a participant-specific augmentation combined with multimodal data integration aligned via a regression task. Our approach, in order to incorporate additional side-information, utilizes structured regularization techniques popularized in recent AD literature. Armed with the fixed-length vector representation learned from the multimodal dynamic and static modalities, conventional machine learning methods can be used to predict the clinical outcomes associated with AD. Our experimental results show that the proposed augmentation model improves the prediction performance on cognitive assessment scores for a collection of popular machine learning algorithms. The results of our approach are interpreted to validate existing genetic and neuroimaging biomarkers that have been shown to be predictive of cognitive decline",
    "checked": true,
    "id": "63b77b1147b2e10af86b2661aaa06c791bbadd5d",
    "semantic_title": "integrating static and dynamic data for improved prediction of cognitive declines using augmented genotype-phenotype representations",
    "citation_count": 1,
    "authors": [
      "Hoon Seo",
      "Lodewijk Brand",
      "Hua Wang",
      "Feiping Nie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16131": {
    "title": "GTA: Graph Truncated Attention for Retrosynthesis",
    "volume": "main",
    "abstract": "Retrosynthesis is the task of predicting reactant molecules from a given product molecule and is, important in organic chemistry because the identification of a synthetic path is as demanding as the discovery of new chemical compounds. Recently, the retrosynthesis task has been solved automatically without human expertise using powerful deep learning models. Recent deep models are primarily based on seq2seq or graph neural networks depending on the function of molecular representation, sequence, or graph. Current state-of-the-art models represent a molecule as a graph, but they require joint training with auxiliary prediction tasks, such as the most probable reaction template or reaction center prediction. Furthermore, they require additional labels by experienced chemists, thereby incurring additional cost. Herein, we propose a novel template-free model, i.e., Graph Truncated Attention (GTA), which leverages both sequence and graph representations by inserting graphical information into a seq2seq model. The proposed GTA model masks the self-attention layer using the adjacency matrix of product molecule in the encoder and applies a new loss using atom mapping acquired from an automated algorithm to the cross-attention layer in the decoder. Our model achieves new state-of-the-art records, i.e., exact match top-1 and top-10 accuracies of 51.1% and 81.6% on the USPTO-50k benchmark dataset, respectively, and 46.0% and 70.0% on the USPTO-full dataset, respectively, both without any reaction class information. The GTA model surpasses prior graph-based template-free models by 2% and 7% in terms of the top-1 and top-10 accuracies on the USPTO-50k dataset, respectively, and by over 6% for both the top-1 and top-10 accuracies on the USPTO-full dataset",
    "checked": true,
    "id": "d82a03951796a352dc4442387782c21d2b761480",
    "semantic_title": "gta: graph truncated attention for retrosynthesis",
    "citation_count": 24,
    "authors": [
      "Seung-Woo Seo",
      "You Young Song",
      "June Yong Yang",
      "Seohui Bae",
      "Hankook Lee",
      "Jinwoo Shin",
      "Sung Ju Hwang",
      "Eunho Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16132": {
    "title": "Physics-Informed Deep Learning for Traffic State Estimation: A Hybrid Paradigm Informed By Second-Order Traffic Models",
    "volume": "main",
    "abstract": "Traffic state estimation (TSE) reconstructs the traffic variables (e.g., density or average velocity) on road segments using partially observed data, which is important for traffic managements. Traditional TSE approaches mainly bifurcate into two categories: model-driven and data-driven, and each of them has shortcomings. To mitigate these limitations, hybrid TSE methods, which combine both model-driven and data-driven, are becoming a promising solution. This paper introduces a hybrid framework, physics-informed deep learning (PIDL), to combine second-order traffic flow models and neural networks to solve the TSE problem. PIDL can encode traffic flow models into deep neural networks to regularize the learning process to achieve improved data efficiency and estimation accuracy. We focus on highway TSE with observed data from loop detectors and probe vehicles, using both density and average velocity as the traffic variables. With numerical examples, we show the use of PIDL to solve a popular second-order traffic flow model, i.e., a Greenshields-based Aw-Rascle-Zhang (ARZ) model, and discover the model parameters. We then evaluate the PIDL-based TSE method using the Next Generation SIMulation (NGSIM) dataset. Experimental results demonstrate the proposed PIDL-based approach to outperform advanced baseline methods in terms of data efficiency and estimation accuracy",
    "checked": true,
    "id": "d2a1df992e2112f579a16301b2df78c2fff5cd8e",
    "semantic_title": "physics-informed deep learning for traffic state estimation: a hybrid paradigm informed by second-order traffic models",
    "citation_count": 38,
    "authors": [
      "Rongye Shi",
      "Zhaobin Mo",
      "Xuan Di"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16133": {
    "title": "The LOB Recreation Model: Predicting the Limit Order Book from TAQ History Using an Ordinary Differential Equation Recurrent Neural Network",
    "volume": "main",
    "abstract": "In an order-driven financial market, the price of a financial asset is discovered through the interaction of orders - requests to buy or sell at a particular price - that are posted to the public limit order book (LOB). Therefore, LOB data is extremely valuable for modelling market dynamics. However, LOB data is not freely accessible, which poses a challenge to market participants and researchers wishing to exploit this information. Fortunately, trades and quotes (TAQ) data - orders arriving at the top of the LOB, and trades executing in the market - are more readily available. In this paper, we present the LOB recreation model, a first attempt from a deep learning perspective to recreate the top five price levels of the LOB for small-tick stocks using only TAQ data. Volumes of orders sitting deep in the LOB are predicted by combining outputs from: (1) a history compiler that uses a Gated Recurrent Unit (GRU) module to selectively compile prediction relevant quote history; (2) a market events simulator, which uses an Ordinary Differential Equation Recurrent Neural Network (ODE-RNN) to simulate the accumulation of net order arrivals; and (3) a weighting scheme to adaptively combine the predictions generated by (1) and (2). By the paradigm of transfer learning, the core encoder trained on one stock can be fine-tuned to enable application to other financial assets of the same class with much lower demand on additional data. Comprehensive experiments conducted on two real world intraday LOB datasets demonstrate that the proposed model can efficiently recreate the LOB with high accuracy using only TAQ data as input",
    "checked": true,
    "id": "6980d5939304e09125c9fac7881036ee323bea07",
    "semantic_title": "the lob recreation model: predicting the limit order book from taq history using an ordinary differential equation recurrent neural network",
    "citation_count": 7,
    "authors": [
      "Zijian Shi",
      "Yu Chen",
      "John Cartlidge"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16134": {
    "title": "Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multi-modal Data",
    "volume": "main",
    "abstract": "With the rapid evolution of social media, fake news has become a significant social problem, which cannot be addressed in a timely manner using manual investigation. This has motivated numerous studies on automating fake news detection. Most studies explore supervised training models with different modalities (e.g., text, images, and propagation networks) of news records to identify fake news. However, the performance of such techniques generally drops if news records are coming from different domains (e.g., politics, entertainment), especially for domains that are unseen or rarely-seen during training. As motivation, we empirically show that news records from different domains have significantly different word usage and propagation patterns. Furthermore, due to the sheer volume of unlabelled news records, it is challenging to select news records for manual labelling so that the domain-coverage of the labelled dataset is maximised. Hence, this work: (1) proposes a novel framework that jointly preserves domain-specific and cross-domain knowledge in news records to detect fake news from different domains; and (2) introduces an unsupervised technique to select a set of unlabelled informative news records for manual labelling, which can be ultimately used to train a fake news detection model that performs well for many domains while minimizing the labelling cost. Our experiments show that the integration of the proposed fake news model and the selective annotation approach achieves state-of-the-art performance for cross-domain news datasets, while yielding notable improvements for rarely-appearing domains in news datasets",
    "checked": true,
    "id": "0c107281ab54d0dd4df7539a18afebf6e3478bfb",
    "semantic_title": "embracing domain differences in fake news: cross-domain fake news detection using multi-modal data",
    "citation_count": 55,
    "authors": [
      "Amila Silva",
      "Ling Luo",
      "Shanika Karunasekera",
      "Christopher Leckie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16135": {
    "title": "Oral-3D: Reconstructing the 3D Structure of Oral Cavity from Panoramic X-ray",
    "volume": "main",
    "abstract": "Panoramic X-ray (PX) provides a 2D picture of the patient's mouth in a panoramic view to help dentists observe the invisible disease inside the gum. However, it provides limited 2D information compared with cone-beam computed tomography (CBCT), another dental imaging method that generates a 3D picture of the oral cavity but with more radiation dose and a higher price. Consequently, it is of great interest to reconstruct the 3D structure from a 2D X-ray image, which can greatly explore the application of X-ray imaging in dental surgeries. In this paper, we propose a framework, named Oral-3D, to reconstruct the 3D oral cavity from a single PX image and prior information of the dental arch. Specifically, we first train a generative model to learn the cross-dimension transformation from 2D to 3D. Then we restore the shape of the oral cavity with a deformation module with the dental arch curve, which can be obtained simply by taking a photo of the patient's mouth. To be noted, Oral-3D can restore both the density of bony tissues and the curved mandible surface. Experimental results show that Oral-3D can efficiently and effectively reconstruct the 3D oral structure and show critical information in clinical applications, e.g., tooth pulling and dental implants. To the best of our knowledge, we are the first to explore this domain transformation problem between these two imaging methods",
    "checked": true,
    "id": "276f98e28d9397f5095fe2454edd303d9ffc1b08",
    "semantic_title": "oral-3d: reconstructing the 3d structure of oral cavity from panoramic x-ray",
    "citation_count": 13,
    "authors": [
      "Weinan Song",
      "Yuan Liang",
      "Jiawei Yang",
      "Kun Wang",
      "Lei He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16136": {
    "title": "Traffic Shaping in E-Commercial Search Engine: Multi-Objective Online Welfare Maximization",
    "volume": "main",
    "abstract": "The e-commercial search engine is the primary gateway for customers to find desired products and engage in online shopping. Besides displaying items to optimize for a single objective (i.e., relevance), ranking items needs to satisfy some other business requirements in practice. Recently, traffic shaping was introduced to incorporate multiple objectives in a constrained optimization framework. However, many practical business requirements can not explicitly represented by linear constraints as in the existing work, and this may limit the scalablity of their framework. This paper presents a unified framework from the aspect of multi-objective welfare maximization where we regard all business requirements as objectives to optimize. Our framework can naturally incorporate a wide range of application-driven requirements. In addition to formulating the problem, we design an online traffic splitting algorithm that allows us to flexibly adjust the priorities of different objectives, and it has rigorous theoretical guarantees over the adversarial scenario. We also run experiments on both synthetic and real-world datasets to validate our algorithms",
    "checked": true,
    "id": "e09f71d5a04c5e0b7ea220c01eec87447e4d724b",
    "semantic_title": "traffic shaping in e-commercial search engine: multi-objective online welfare maximization",
    "citation_count": 1,
    "authors": [
      "Liucheng Sun",
      "Chenwei Weng",
      "Chengfu Huo",
      "Weijun Ren",
      "Guochuan Zhang",
      "Xin Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16137": {
    "title": "Fully Exploiting Cascade Graphs for Real-time Forwarding Prediction",
    "volume": "main",
    "abstract": "Real-time forwarding prediction for predicting online contents' popularity is beneficial to various social applications for enhancing interactive social behaviors. Cascade graphs, formed by online contents' propagation, play a vital role in real-time forwarding prediction. Existing cascade graph modeling methods are inadequate to embed cascade graphs that have hub structures and deep cascade paths, or they fail to handle the short-term outbreak of forwarding amount. To this end, we propose a novel real-time forwarding prediction method that includes an effective approach for cascade graph embedding and a short-term variation sensitive method for time-series modeling, making the best of cascade graph features. Using two real world datasets, we demonstrate the significant superiority of the proposed method compared with the state-of-the-art. Our experiments also reveal interesting implications hidden in the performance differences between cascade graph embedding and time-series modeling",
    "checked": true,
    "id": "dcd7579ab8ecfa4ad6ab72b372684dbd437af90f",
    "semantic_title": "fully exploiting cascade graphs for real-time forwarding prediction",
    "citation_count": 23,
    "authors": [
      "Xiangyun Tang",
      "Dongliang Liao",
      "Weijie Huang",
      "Jin Xu",
      "Liehuang Zhu",
      "Meng Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16138": {
    "title": "A Hierarchical Approach to Multi-Event Survival Analysis",
    "volume": "main",
    "abstract": "In multi-event survival analysis, one aims to predict the probability of multiple different events occurring over some time horizon. One typically assumes that the timing of events is drawn from some distribution conditioned on an individual's covariates. However, during training, one does not have access to this distribution, and the natural variation in the observed event times makes the task of survival prediction challenging, on top of the potential interdependence among events. To address this issue, we introduce a novel approach for multi-event survival analysis that models the probability of event occurrence hierarchically at different time scales, using coarse predictions (e.g., monthly predictions) to iteratively guide predictions at finer and finer grained time scales (e.g., daily predictions). We evaluate the proposed approach across several publicly available datasets in terms of both intra-event, inter-individual (global) and intra-individual, inter-event (local) consistency. We show that the proposed method consistently outperforms well-accepted and commonly used approaches to multi-event survival analysis. When estimating survival curves for Alzheimer's disease and mortality, our approach achieves a C-index of 0.91 (95% CI 0.88-0.93) and a local consistency score of 0.97 (95% CI 0.94-0.98) compared to a C-index of 0.75 (95% CI 0.70-0.80) and a local consistency score of 0.94 (95% CI 0.91-0.97) when modeling each event separately. Overall, our approach improves the accuracy of survival predictions by iteratively reducing the original task to a set of nested, simpler subtasks",
    "checked": true,
    "id": "5fa3bec1888184a6e5798853cda9665b014c6a9d",
    "semantic_title": "a hierarchical approach to multi-event survival analysis",
    "citation_count": 9,
    "authors": [
      "Donna Tjandra",
      "Yifei He",
      "Jenna Wiens"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16139": {
    "title": "DeepWriteSYN: On-Line Handwriting Synthesis via Deep Short-Term Representations",
    "volume": "main",
    "abstract": "This study proposes DeepWriteSYN, a novel on-line handwriting synthesis approach via deep short-term representations. It comprises two modules: i) an optional and interchangeable temporal segmentation, which divides the handwriting into short-time segments consisting of individual or multiple concatenated strokes; and ii) the on-line synthesis of those short-time handwriting segments, which is based on a sequence-to-sequence Variational Autoencoder (VAE). The main advantages of the proposed approach are that the synthesis is carried out in short-time segments (that can run from a character fraction to full characters) and that the VAE can be trained on a configurable handwriting dataset. These two properties give a lot of flexibility to our synthesiser, e.g., as shown in our experiments, DeepWriteSYN can generate realistic handwriting variations of a given handwritten structure corresponding to the natural variation within a given population or a given subject. These two cases are developed experimentally for individual digits and handwriting signatures, respectively, achieving in both cases remarkable results. Also, we provide experimental results for the task of on-line signature verification showing the high potential of DeepWriteSYN to improve significantly one-shot learning scenarios. To the best of our knowledge, this is the first synthesis approach capable of generating realistic on-line handwriting in the short term (including handwritten signatures) via deep learning. This can be very useful as a module toward long-term realistic handwriting generation either completely synthetic or as natural variation of given handwriting samples",
    "checked": true,
    "id": "4f5f71882cf26bded7ef941539a746289d5ad27a",
    "semantic_title": "deepwritesyn: on-line handwriting synthesis via deep short-term representations",
    "citation_count": 22,
    "authors": [
      "Ruben Tolosana",
      "Paula Delgado-Santos",
      "Andres Perez-Uribe",
      "Ruben Vera-Rodriguez",
      "Julian Fierrez",
      "Aythami Morales"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16140": {
    "title": "Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale",
    "volume": "main",
    "abstract": "We propose a novel image-to-pencil translation method that could not only generate high-quality pencil sketches but also offer the drawing process. Existing pencil sketch algorithms are based on texture rendering rather than the direct imitation of strokes, making them unable to show the drawing process but only a final result. To address this challenge, we first establish a pencil stroke imitation mechanism. Next, we develop a framework with three branches to guide stroke drawing: the first branch guides the direction of the strokes, the second branch determines the shade of the strokes, and the third branch enhances the details further. Under this framework's guidance, we can produce a pencil sketch by drawing one stroke every time. Our method is fully interpretable. Comparison with existing pencil drawing algorithms shows that our method is superior to others in terms of texture quality, style, and user evaluation. Our code and supplementary material are now available at: https://github.com/TZYSJTU/Sketch-Generation-withDrawing-Process-Guided-by-Vector-Flow-and-Grayscale",
    "checked": true,
    "id": "5f8cc52cdd8859963a9f074cf461f2132a38d346",
    "semantic_title": "sketch generation with drawing process guided by vector flow and grayscale",
    "citation_count": 10,
    "authors": [
      "Zhengyan Tong",
      "Xuanhong Chen",
      "Bingbing Ni",
      "Xiaohang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16141": {
    "title": "PSSM-Distil: Protein Secondary Structure Prediction (PSSP) on Low-Quality PSSM by Knowledge Distillation with Contrastive Learning",
    "volume": "main",
    "abstract": "Protein secondary structure prediction (PSSP) is an essential task in computational biology. To achieve the accurate PSSP, the general and vital feature engineering is to use multiple sequence alignment (MSA) for Position-Specific Scoring Matrix (PSSM) extraction. However, when only low-quality PSSM can be obtained due to poor sequence homology, previous PSSP accuracy (merely around 65%) is far from practical usage for subsequent tasks. In this paper, we propose a novel PSSM-Distil framework for PSSP on low-quality PSSM, which not only enhances the PSSM feature at a lower level but also aligns the feature distribution at a higher level. In practice, the PSSM-Distil first exploits the proteins with high-quality PSSM to achieve a teacher network for PSSP in a full-supervised way. Under the guidance of the teacher network, the low-quality PSSM and corresponding student network with low discriminating capacity are effectively resolved by feature enhancement through EnhanceNet and distribution alignment through knowledge distillation with contrastive learning. Further, our PSSM-Distil supports the input from a pre-trained protein sequence language BERT model to provide auxiliary information, which is designed to address the extremely low-quality PSSM cases, i.e., no homologous sequence. Extensive experiments demonstrate the proposed PSSM-Distil outperforms state-of-the-art models on PSSP by 6% on average and nearly 8% in extremely low-quality cases on public benchmarks, BC40 and CB513",
    "checked": true,
    "id": "78cc2f6958a5338b5fadb7ae1e860c74177e7064",
    "semantic_title": "pssm-distil: protein secondary structure prediction (pssp) on low-quality pssm by knowledge distillation with contrastive learning",
    "citation_count": 10,
    "authors": [
      "Qin Wang",
      "Boyuan Wang",
      "Zhenlei Xu",
      "Jiaxiang Wu",
      "Peilin Zhao",
      "Zhen Li",
      "Sheng Wang",
      "Junzhou Huang",
      "Shuguang Cui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16142": {
    "title": "Commission Fee is not Enough: A Hierarchical Reinforced Framework for Portfolio Management",
    "volume": "main",
    "abstract": "Portfolio management via reinforcement learning is at the forefront of fintech research, which explores how to optimally reallocate a fund into different financial assets over the long term by trial-and-error. Existing methods are impractical since they usually assume each reallocation can be finished immediately and thus ignoring the price slippage as part of the trading cost. To address these issues, we propose a hierarchical reinforced stock trading system for portfolio management (HRPM). Concretely, we decompose the trading process into a hierarchy of portfolio management over trade execution and train the corresponding policies. The high-level policy gives portfolio weights at a lower frequency to maximize the long-term profit and invokes the low-level policy to sell or buy the corresponding shares within a short time window at a higher frequency to minimize the trading cost. We train two levels of policies via a pre-training scheme and an iterative training scheme for data efficiency. Extensive experimental results in the U.S. market and the China market demonstrate that HRPM achieves significant improvement against many state-of-the-art approaches",
    "checked": true,
    "id": "bfff859c8600205c69e79a18e0818ab85fc169e5",
    "semantic_title": "commission fee is not enough: a hierarchical reinforced framework for portfolio management",
    "citation_count": 22,
    "authors": [
      "Rundong Wang",
      "Hongxin Wei",
      "Bo An",
      "Zhouyan Feng",
      "Jun Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16143": {
    "title": "Alternative Baselines for Low-Shot 3D Medical Image Segmentation---An Atlas Perspective",
    "volume": "main",
    "abstract": "Low-shot (one/few-shot) segmentation has attracted increasing attention as it works well with limited annotation. State-of-the-art low-shot segmentation methods on natural images usually focus on implicit representation learning for each novel class, such as learning prototypes, deriving guidance features via masked average pooling, and segmenting using cosine similarity in feature space. We argue that low-shot segmentation on medical images should step further to explicitly learn dense correspondences between images to utilize the anatomical similarity. The core ideas are inspired by the classical practice of multi-atlas segmentation, where the indispensable parts of atlas-based segmentation, i.e., registration, label propagation, and label fusion are unified into a single framework in our work. Specifically, we propose two alternative baselines, i.e., the Siamese-Baseline and Individual-Difference-Aware Baseline, where the former is targeted at anatomically stable structures (such as brain tissues), and the latter possesses a strong generalization ability to organs suffering large morphological variations (such as abdominal organs). In summary, this work sets up a benchmark for low-shot 3D medical image segmentation and sheds light on further understanding of atlas-based few-shot segmentation",
    "checked": false,
    "id": "da135fef642ac229627d64e1ea5d38bb297ad90e",
    "semantic_title": "alternative baselines for low-shot 3d medical image segmentation - an atlas perspective",
    "citation_count": 3,
    "authors": [
      "Shuxin Wang",
      "Shilei Cao",
      "Dong Wei",
      "Cong Xie",
      "Kai Ma",
      "Liansheng Wang",
      "Deyu Meng",
      "Yefeng Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16144": {
    "title": "DeepTrader: A Deep Reinforcement Learning Approach for Risk-Return Balanced Portfolio Management with Market Conditions Embedding",
    "volume": "main",
    "abstract": "Most existing reinforcement learning (RL)-based portfolio management models do not take into account the market conditions, which limits their performance in risk-return balancing. In this paper, we propose DeepTrader, a deep RL method to optimize the investment policy. In particular, to tackle the risk-return balancing problem, our model embeds macro market conditions as an indicator to dynamically adjust the proportion between long and short funds, to lower the risk of market fluctuations, with the negative maximum drawdown as the reward function. Additionally, the model involves a unit to evaluate individual assets, which learns dynamic patterns from historical data with the price rising rate as the reward function. Both temporal and spatial dependencies between assets are captured hierarchically by a specific type of graph structure. Particularly, we find that the estimated causal structure best captures the interrelationships between assets, compared to industry classification and correlation. The two units are complementary and integrated to generate a suitable portfolio which fits the market trend well and strikes a balance between return and risk effectively. Experiments on three well-known stock indexes demonstrate the superiority of DeepTrader in terms of risk-gain criteria",
    "checked": true,
    "id": "0b26cb46675c0b00483c254488c9a14d89eec8e5",
    "semantic_title": "deeptrader: a deep reinforcement learning approach for risk-return balanced portfolio management with market conditions embedding",
    "citation_count": 31,
    "authors": [
      "Zhicheng Wang",
      "Biwei Huang",
      "Shikui Tu",
      "Kun Zhang",
      "Lei Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16145": {
    "title": "Dynamic Gaussian Mixture based Deep Generative Model For Robust Forecasting on Sparse Multivariate Time Series",
    "volume": "main",
    "abstract": "Forecasting on sparse multivariate time series (MTS) aims to model the predictors of future values of time series given their incomplete past, which is important for many emerging applications. However, most existing methods process MTS's individually, and do not leverage the dynamic distributions underlying the MTS's, leading to sub-optimal results when the sparsity is high. To address this challenge, we propose a novel generative model, which tracks the transition of latent clusters, instead of isolated feature representations, to achieve robust modeling. It is characterized by a newly designed dynamic Gaussian mixture distribution, which captures the dynamics of clustering structures, and is used for emitting time series. The generative model is parameterized by neural networks. A structured inference network is also designed for enabling inductive analysis. A gating mechanism is further introduced to dynamically tune the Gaussian mixture distributions. Extensive experimental results on a variety of real-life datasets demonstrate the effectiveness of our method",
    "checked": true,
    "id": "90f292fd8f0f2e321f3829b8cfee7cd7f72ace6e",
    "semantic_title": "dynamic gaussian mixture based deep generative model for robust forecasting on sparse multivariate time series",
    "citation_count": 23,
    "authors": [
      "Yinjun Wu",
      "Jingchao Ni",
      "Wei Cheng",
      "Bo Zong",
      "Dongjin Song",
      "Zhengzhang Chen",
      "Yanchi Liu",
      "Xuchao Zhang",
      "Haifeng Chen",
      "Susan B Davidson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16146": {
    "title": "Automated Symbolic Law Discovery: A Computer Vision Approach",
    "volume": "main",
    "abstract": "One of the most exciting applications of modern artificial intelligence is to automatically discover scientific laws from experimental data. This is not a trivial problem as it involves searching for a complex mathematical relationship over a large set of explanatory variables and operators that can be combined in an infinite number of ways. Inspired by the incredible success of deep learning in computer vision, we tackle this problem by adapting various successful network architectures into the symbolic law discovery pipeline. The novelty of our approach is in (1) encoding the input data as an image with super-resolution, (2) developing an appropriate deep network pipeline, and (3) predicting the importance of each mathematical operator from the relationship image. This allows us to prior the exponentially large search with the predicted importance of the symbolic operators, which can significantly accelerate the discovery process. We apply our model to a variety of plausible relationships---both simulated and from physics and mathematics domains---involving different dimensions and constituents. We show that our model is able to identify the underlying operators from data, achieving a high accuracy and AUC (91% and 0.96 on average resp.) for systems with as many as ten independent variables. Our method significantly outperforms the current state of the art in terms of data fitting (R^2), discovery rate (recovering the true relationship), and succinctness (output formula complexity). The discovered equations can be seen as first drafts of scientific laws that can be helpful to the scientists for (1) hypothesis building, and (2) understanding the complex underlying structure of the studied phenomena. Our approach holds a real promise to help speed up the rate of scientific discovery",
    "checked": true,
    "id": "8951402483e58f6279266ac836a88ad1e445eda6",
    "semantic_title": "automated symbolic law discovery: a computer vision approach",
    "citation_count": 6,
    "authors": [
      "Hengrui Xing",
      "Ansaf Salleb-Aouissi",
      "Nakul Verma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16147": {
    "title": "Hierarchically and Cooperatively Learning Traffic Signal Control",
    "volume": "main",
    "abstract": "Deep reinforcement learning (RL) has been applied to traffic signal control recently and demonstrated superior performance to conventional control methods. However, there are still several challenges we have to address before fully applying deep RL to traffic signal control. Firstly, the objective of traffic signal control is to optimize average travel time, which is a delayed reward in a long time horizon in the context of RL. However, existing work simplifies the optimization by using queue length, waiting time, delay, etc., as immediate reward and presumes these short-term targets are always aligned with the objective. Nevertheless, these targets may deviate from the objective in different road networks with various traffic patterns. Secondly, it remains unsolved how to cooperatively control traffic signals to directly optimize average travel time. To address these challenges, we propose a hierarchical and cooperative reinforcement learning method-HiLight. HiLight enables each agent to learn a high-level policy that optimizes the objective locally by selecting among the sub-policies that respectively optimize short-term targets. Moreover, the high-level policy additionally considers the objective in the neighborhood with adaptive weighting to encourage agents to cooperate on the objective in the road network. Empirically, we demonstrate that HiLight outperforms state-of-the-art RL methods for traffic signal control in real road networks with real traffic",
    "checked": true,
    "id": "7284ae678ab87196d0e0ed393e0796e6772dc7d4",
    "semantic_title": "hierarchically and cooperatively learning traffic signal control",
    "citation_count": 37,
    "authors": [
      "Bingyu Xu",
      "Yaowei Wang",
      "Zhaozhi Wang",
      "Huizhu Jia",
      "Zongqing Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16148": {
    "title": "Deep Partial Rank Aggregation for Personalized Attributes",
    "volume": "main",
    "abstract": "In this paper, we study the problem of how to aggregate pairwise personalized attributes (PA) annotations (e.g., Shoes A is more comfortable than B) from different annotators on the crowdsourcing platforms, which is an emerging topic gaining increasing attention in recent years. Given the crowdsourced annotations, the majority of the traditional literature assumes that all the pairs in the collected dataset are distinguishable. However, this assumption is incompatible with how humans perceive attributes since indistinguishable pairs are ubiquitous for the annotators due to the limitation of human perception. To attack this problem, we propose a novel deep prediction model that could simultaneously detect the indistinguishable pairs and aggregate ranking results for distinguishable pairs. First of all, we represent the pairwise annotations as a multi-graph. Based on such data structure, we propose an end-to-end partial ranking model which consists of a deep backbone architecture and a probabilistic model that captures the generative process of the partial rank annotations. Specifically, to recognize the indistinguishable pairs, the probabilistic model we proposed is equipped with an adaptive perception threshold, where indistinguishable pairs could be automatically detected when the absolute value of the score difference is below the learned threshold. In our empirical studies, we perform a series of experiments on three real-world datasets: LFW-10, Shoes, and Sun. The corresponding results consistently show the superiority of our proposed model",
    "checked": true,
    "id": "6e6a44f0dde431467f8aa484abd6d2fe160812d6",
    "semantic_title": "deep partial rank aggregation for personalized attributes",
    "citation_count": 2,
    "authors": [
      "Qianqian Xu",
      "Zhiyong Yang",
      "Zuyao Chen",
      "Yangbangyan Jiang",
      "Xiaochun Cao",
      "Yuan Yao",
      "Qingming Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16149": {
    "title": "Towards Efficient Selection of Activity Trajectories based on Diversity and Coverage",
    "volume": "main",
    "abstract": "With the prevalence of location based services, activity trajectories are being generated at a rapid pace. The activity trajectory data enriches traditional trajectory data with semantic activities of users, which not only shows where the users have been, but also the preference of users. However, the large volume of data is expensive for people to explore. To address this issue, we study the problem of Diversity-aware Activity Trajectory Selection (DaATS). Given a region of interest for a user, it finds a small number of representative activity trajectories that can provide the user with a broad coverage of different aspects of the region. The problem is challenging in both the efficiency of trajectory similarity computation and subset selection. To tackle the two challenges, we propose a novel solution by: (1) exploiting a deep metric learning method to speedup the similarity computation; and (2) proving that DaATS is an NP-hard problem, and developing an efficient approximation algorithm with performance guarantees. Experiments on two real-world datasets show that our proposal significantly outperforms state-of-the-art baselines",
    "checked": true,
    "id": "e3db5eb9b09842d130ce80f7ba099012c20dc266",
    "semantic_title": "towards efficient selection of activity trajectories based on diversity and coverage",
    "citation_count": 16,
    "authors": [
      "Chengcheng Yang",
      "Lisi Chen",
      "Hao Wang",
      "Shuo Shang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16150": {
    "title": "Minimizing Labeling Cost for Nuclei Instance Segmentation and Classification with Cross-domain Images and Weak Labels",
    "volume": "main",
    "abstract": "Nucleus instance segmentation and classification in histopathological images is an essential prerequisite in pathology diagnosis/prognosis. However, nucleus annotations (e.g., segmentation and labeling) require domain experts, and annotating nuclei at pixel-level is time-consuming and labor-intensive. Moreover, nuclei from different cancer types vary in shapes and appearances. These inter-cancer variations require careful annotations for specific cancer types. Therefore, to minimize the labeling cost, we propose a novel application that considers each cancer type as an individual domain and apply domain adaptation techniques to improve the segmentation/classification performance among different cancer types. Unlike the previous studies that focus on unsupervised or weakly-supervised domain adaptation independently, we would like to discover what kinds of labeling can achieve the most cost-effective domain adaptation performance in nucleus instance segmentation and classification. Specifically, we propose a unified framework that is applicable to different level annotations: no annotations, image-level, and point-level annotations. Cyclic adaptation with pseudo labels and adversarial discriminator are utilized for unsupervised domain alignment. Image-level or point-level annotations are additionally adopted to supervise the nucleus classification and refine the pseudo labels. Experiments demonstrate the effectiveness and efficacy of the proposed framework (jointly using unsupervised and weakly supervised learning) on adapting the segmentation and classification model from one cancer type to 18 other cancer types",
    "checked": true,
    "id": "f9282d8871dd3d87a002ffd6e38eefff65978128",
    "semantic_title": "minimizing labeling cost for nuclei instance segmentation and classification with cross-domain images and weak labels",
    "citation_count": 9,
    "authors": [
      "Siqi Yang",
      "Jun Zhang",
      "Junzhou Huang",
      "Brian  C. Lovell",
      "Xiao Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16151": {
    "title": "Bigram and Unigram Based Text Attack via Adaptive Monotonic Heuristic Search",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) are known to be vulnerable to adversarial images, while their robustness in text classification are rarely studied. Several lines of text attack methods have been proposed in the literature, such as character-level, word-level, and sentence-level attacks. However, it is still a challenge to minimize the number of word distortions necessary to induce misclassification, while simultaneously ensuring the lexical correctness, syntactic correctness, and semantic similarity. In this paper, we propose the Bigram and Unigram based Monotonic Heuristic Search (BU-MHS) method to examine the vulnerability of deep models. Our method has three major merits. Firstly, we propose to attack text documents not only at the unigram word level but also at the bigram level to avoid producing meaningless outputs. Secondly, we propose a hybrid method to replace the input words with both their synonyms and sememe candidates, which greatly enriches potential substitutions compared to only using synonyms. Lastly, we design a search algorithm, i.e., Monotonic Heuristic Search (MHS), to determine the priority of word replacements, aiming to reduce the modification cost in an adversarial attack. We evaluate the effectiveness of BU-MHS on IMDB, AG's News, and Yahoo! Answers text datasets by attacking four state-of-the-art DNNs models. Experimental results show that our BU-MHS achieves the highest attack success rate by changing the smallest number of words compared with other existing models",
    "checked": true,
    "id": "728171df555472656a9d9e2f155c16324fd7cca8",
    "semantic_title": "bigram and unigram based text attack via adaptive monotonic heuristic search",
    "citation_count": 5,
    "authors": [
      "Xinghao Yang",
      "Weifeng Liu",
      "James Bailey",
      "Dacheng Tao",
      "Wei Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16152": {
    "title": "GRASP: Generic Framework for Health Status Representation Learning Based on Incorporating Knowledge from Similar Patients",
    "volume": "main",
    "abstract": "Deep learning models have been applied to many healthcare tasks based on electronic medical records (EMR) data and shown substantial performance. Existing methods commonly embed the records of a single patient into a representation for medical tasks. Such methods learn inadequate representations and lead to inferior performance, especially when the patient's data is sparse or low-quality. Aiming at the above problem, we propose GRASP, a generic framework for healthcare models. For a given patient, GRASP first finds patients in the dataset who have similar conditions and similar results (i.e., the similar patients), and then enhances the representation learning and prognosis of the given patient by leveraging knowledge extracted from these similar patients. GRASP defines similarities with different meanings between patients for different clinical tasks, and finds similar patients with useful information accordingly, and then learns cohort representation to extract valuable knowledge contained in the similar patients. The cohort information is fused with the current patient's representation to conduct final clinical tasks. Experimental evaluations on two real-world datasets show that GRASP can be seamlessly integrated into state-of-the-art models with consistent performance improvements. Besides, under the guidance of medical experts, we verified the findings extracted by GRASP, and the findings are consistent with the existing medical knowledge, indicating that GRASP can generate useful insights for relevant predictions",
    "checked": true,
    "id": "e8ddbcabf0bb3b4e377f1a6d5d766e262264f7a3",
    "semantic_title": "grasp: generic framework for health status representation learning based on incorporating knowledge from similar patients",
    "citation_count": 20,
    "authors": [
      "Chaohe Zhang",
      "Xin Gao",
      "Liantao Ma",
      "Yasha Wang",
      "Jiangtao Wang",
      "Wen Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16153": {
    "title": "Window Loss for Bone Fracture Detection and Localization in X-ray Images with Point-based Annotation",
    "volume": "main",
    "abstract": "Object detection methods are widely adopted for computer-aided diagnosis using medical images. Anomalous findings are usually treated as objects that are described by bounding boxes. Yet, many pathological findings, e.g., bone fractures, cannot be clearly defined by bounding boxes, owing to considerable instance, shape and boundary ambiguities. This makes bounding box annotations, and their associated losses, highly ill-suited. In this work, we propose a new bone fracture detection method for X-ray images, based on a labor effective and flexible annotation scheme suitable for abnormal findings with no clear object-level spatial extents or boundaries. Our method employs a simple, intuitive, and informative point-based annotation protocol to mark localized pathology information. To address the uncertainty in the fracture scales annotated via point(s), we convert the annotations into pixel-wise supervision that uses lower and upper bounds with positive, negative, and uncertain regions. A novel Window Loss is subsequently proposed to only penalize the predictions outside of the uncertain regions. Our method has been extensively evaluated on 4410 pelvic X-ray images of unique patients. Experiments demonstrate that our method outperforms previous state-of-the-art image classification and object detection baselines by healthy margins, with an AUROC of 0.983 and FROC score of 89.6%",
    "checked": true,
    "id": "61ee1f053dc557e3772b5a9d208a28f39418e5ee",
    "semantic_title": "window loss for bone fracture detection and localization in x-ray images with point-based annotation",
    "citation_count": 0,
    "authors": [
      "Xinyu Zhang",
      "Yirui Wang",
      "Chi-Tung Cheng",
      "Le Lu",
      "Adam P. Harrison",
      "Jing Xiao",
      "Chien-Hung Liao",
      "Shun Miao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16154": {
    "title": "A Spatial Regulated Patch-Wise Approach for Cervical Dysplasia Diagnosis",
    "volume": "main",
    "abstract": "Cervical dysplasia diagnosis via visual investigation is a challenging problem. Recent approaches use deep learning techniques to extract features and require the downsampling of high-resolution cervical screening images to smaller sizes for training. Such a reduction may result in the loss of visual details that appear weakly and locally within a cervical image. To overcome this challenge, our work divides an image into patches and then represents it from patch features. We aggregate patch patterns into an image feature in a weighted manner by considering the patch--image label relation. The weights are visualized as a heatmap to explain where the diagnosis results come from. We further introduce a spatial regulator to guide the classifier to focus on the cervix region and to adjust the weight distribution, without requiring any manual annotations of the cervix region. A novel iterative algorithm is designed to refine the regulator, which is able to capture the variations in cervix center locations and shapes. Experiments on an 18-year real-world dataset indicate a minimal of 3.47%, 4.59%, 8.54% improvements over the state-of-the-art in accuracy, F1, and recall measures, respectively",
    "checked": true,
    "id": "7f3a41cd8dfdd09cd2630b2163af2421ada9381b",
    "semantic_title": "a spatial regulated patch-wise approach for cervical dysplasia diagnosis",
    "citation_count": 4,
    "authors": [
      "Ying Zhang",
      "Yifang Yin",
      "Zhenguang Liu",
      "Roger Zimmermann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16155": {
    "title": "Online 3D Bin Packing with Constrained Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "We solve a challenging yet practically useful variant of 3D Bin Packing Problem (3D-BPP). In our problem, the agent has limited information about the items to be packed into a single bin, and an item must be packed immediately after its arrival without buffering or readjusting. The item's placement also subjects to the constraints of order dependence and physical stability. We formulate this online 3D-BPP as a constrained Markov decision process (CMDP). To solve the problem, we propose an effective and easy-to-implement constrained deep reinforcement learning (DRL) method under the actor-critic framework. In particular, we introduce a prediction-and-projection scheme: The agent first predicts a feasibility mask for the placement actions as an auxiliary task and then uses the mask to modulate the action probabilities output by the actor during training. Such supervision and projection facilitate the agent to learn feasible policies very efficiently. Our method can be easily extended to handle lookahead items, multi-bin packing, and item re-orienting. We have conducted extensive evaluation showing that the learned policy significantly outperforms the state-of-the-art methods. A preliminary user study even suggests that our method might attain a human-level performance",
    "checked": true,
    "id": "106ff550db26df62eb8374527246bbd07b033278",
    "semantic_title": "online 3d bin packing with constrained deep reinforcement learning",
    "citation_count": 55,
    "authors": [
      "Hang Zhao",
      "Qijin She",
      "Chenyang Zhu",
      "Yin Yang",
      "Kai Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16156": {
    "title": "DEAR: Deep Reinforcement Learning for Online Advertising Impression in Recommender Systems",
    "volume": "main",
    "abstract": "With the recent prevalence of Reinforcement Learning (RL), there have been tremendous interests in utilizing RL for online advertising in recommendation platforms (e.g., e-commerce and news feed sites). However, most RL-based advertising algorithms focus on optimizing ads' revenue while ignoring the possible negative influence of ads on user experience of recommended items (products, articles and videos). Developing an optimal advertising algorithm in recommendations faces immense challenges because interpolating ads improperly or too frequently may decrease user experience, while interpolating fewer ads will reduce the advertising revenue. Thus, in this paper, we propose a novel advertising strategy for the rec/ads trade-off. To be specific, we develop an RL-based framework that can continuously update its advertising strategies and maximize reward in the long run. Given a recommendation list, we design a novel Deep Q-network architecture that can determine three internally related tasks jointly, i.e., (i) whether to interpolate an ad or not in the recommendation list, and if yes, (ii) the optimal ad and (iii) the optimal location to interpolate. The experimental results based on real-world data demonstrate the effectiveness of the proposed framework",
    "checked": true,
    "id": "94e91560da6e649c2d5eda9e989526697ee3e885",
    "semantic_title": "dear: deep reinforcement learning for online advertising impression in recommender systems",
    "citation_count": 51,
    "authors": [
      "Xiangyu Zhao",
      "Changsheng Gu",
      "Haoshenglun Zhang",
      "Xiwang Yang",
      "Xiaobing Liu",
      "Jiliang Tang",
      "Hui Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16157": {
    "title": "Towards Balanced Defect Prediction with Better Information Propagation",
    "volume": "main",
    "abstract": "Defect prediction, the task of predicting the presence of defects in source code artifacts, has broad application in software development. Defect prediction faces two major challenges, label scarcity, where only a small percentage of code artifacts are labeled, and data imbalance, where the majority of labeled artifacts are non-defective. Moreover, current defect prediction methods ignore the impact of information propagation among code artifacts and this negligence leads to performance degradation. In this paper, we propose DPCAG, a novel model to address the above three issues. We treat code artifacts as nodes in a graph, and learn to propagate influence among neighboring nodes iteratively in an EM framework. DPCAG dynamically adjusts the contributions of each node and selects high-confidence nodes for data augmentation. Experimental results on real-world benchmark datasets show that DPCAG improves performance compare to the state-of-the-art models. In particular, DPCAG achieves substantial performance superiority when measured by Matthews Correlation Coefficient (MCC), a metric that is widely acknowledged to be the most suitable for imbalanced data",
    "checked": true,
    "id": "1a6c541cad9d2851cc5b3c0fcd2421026935af2d",
    "semantic_title": "towards balanced defect prediction with better information propagation",
    "citation_count": 2,
    "authors": [
      "Xianda Zheng",
      "Yuan-Fang Li",
      "Huan Gao",
      "Yuncheng Hua",
      "Guilin Qi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16158": {
    "title": "Many-to-One Distribution Learning and K-Nearest Neighbor Smoothing for Thoracic Disease Identification",
    "volume": "main",
    "abstract": "Chest X-rays are an important and accessible clinical imaging tool for the detection of many thoracic diseases. Over the past decade, deep learning, with a focus on the convolutional neural network (CNN), has become the most powerful computer-aided diagnosis technology for improving disease identification performance. However, training an effective and robust deep CNN usually requires a large amount of data with high annotation quality. For chest X-ray imaging, annotating large-scale data requires professional domain knowledge and is time-consuming. Thus, existing public chest X-ray datasets usually adopt language pattern based methods to automatically mine labels from reports. However, this results in label uncertainty and inconsistency. In this paper, we propose many-to-one distribution learning (MODL) and K-nearest neighbor smoothing (KNNS) methods from two perspectives to improve a single model's disease identification performance, rather than focusing on an ensemble of models. MODL integrates multiple models to obtain a soft label distribution for optimizing the single target model, which can reduce the effects of original label uncertainty. Moreover, KNNS aims to enhance the robustness of the target model to provide consistent predictions on images with similar medical findings. Extensive experiments on the public NIH Chest X-ray and CheXpert datasets show that our model achieves consistent improvements over the state-of-the-art methods",
    "checked": true,
    "id": "cd4a32498f016a257f15c227551fad499ec50f63",
    "semantic_title": "many-to-one distribution learning and k-nearest neighbor smoothing for thoracic disease identification",
    "citation_count": 7,
    "authors": [
      "Yi Zhou",
      "Lei Huang",
      "Tianfei Zhou",
      "Ling Shao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16159": {
    "title": "Probabilistic Programming Bots in Intuitive Physics Game Play",
    "volume": "main",
    "abstract": "Recent findings suggest that humans deploy cognitive mechanism of physics simulation engines to simulate the physics of objects. We propose a framework for bots to deploy probabilistic programming tools for interacting with intuitive physics environments. The framework employs a physics simulation in a probabilistic way to infer about moves performed by an agent in a setting governed by Newtonian laws of motion. However, methods of probabilistic programs can be slow in such setting due to their need to generate many samples. We complement the model with a model-free approach to aid the sampling procedures in becoming more efficient through learning from experience during game playing. We present an approach where combining model-free approaches (a convolutional neural network in our model) and model-based approaches (probabilistic physics simulation) is able to achieve what neither could alone. This way the model outperforms an all model-free or all model-based approach. We discuss a case study showing empirical results of the performance of the model on the game of Flappy Bird",
    "checked": true,
    "id": "b98726c7c2006970366b84388f3fa18e8679eef8",
    "semantic_title": "probabilistic programming bots in intuitive physics game play",
    "citation_count": 0,
    "authors": [
      "Fahad Alhasoun",
      "Sarah Alneghiemish"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16160": {
    "title": "Model-Agnostic Fits for Understanding Information Seeking Patterns in Humans",
    "volume": "main",
    "abstract": "In decision making tasks under uncertainty, humans display characteristic biases in seeking, integrating, and acting upon information relevant to the task. Here, we reexamine data from previous carefully designed experiments, collected at scale, that measured and catalogued these biases in aggregate form. We design deep learning models that replicate these biases in aggregate, while also capturing individual variation in behavior. A key finding of our work is that paucity of data collected from each individual subject can be overcome by sampling large numbers of subjects from the population, while still capturing individual differences. We predict human behavior with high accuracy without making any assumptions about task goals, reward structure, or individual biases, thus providing a model-agnostic fit to human behavior in the task. Such an approach can sidestep potential limitations in modeler-specified inductive biases, and has implications for computational modeling of human cognitive function in general, and of human-AI interfaces in particular",
    "checked": true,
    "id": "bf4f673f7e483c35693f989af7d1fd0b4a3c7861",
    "semantic_title": "model-agnostic fits for understanding information seeking patterns in humans",
    "citation_count": 1,
    "authors": [
      "Soumya Chatterjee",
      "Pradeep Shenoy"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16161": {
    "title": "Apparently Irrational Choice as Optimal Sequential Decision Making",
    "volume": "main",
    "abstract": "In this paper, we propose a normative approach to modeling apparently human irrational decision making (cognitive biases) that makes use of inherently rational computational mechanisms. We view preferential choice tasks as sequential decision making problems and formulate them as Partially Observable Markov Decision Processes (POMDPs). The resulting sequential decision model learns what information to gather about which options, whether to calculate option values or make comparisons between options and when to make a choice. We apply the model to choice problems where context is known to influence human choice, an effect that has been taken as evidence that human cognition is irrational. Our results show that the new model approximates a bounded optimal cognitive policy and makes quantitative predictions that correspond well to evidence about human choice. Furthermore, the model uses context to help infer which option has a maximum expected value while taking into account computational cost and cognitive limits. In addition, it predicts when, and explains why, people stop evidence accumulation and make a decision. We argue that the model provides evidence that apparent human irrationalities are emergent consequences of processes that prefer higher value (rational) policies",
    "checked": true,
    "id": "d46135b704c65396b3d95dae92aaa811cc1f0355",
    "semantic_title": "apparently irrational choice as optimal sequential decision making",
    "citation_count": 5,
    "authors": [
      "Haiyang Chen",
      "Hyung Jin Chang",
      "Andrew Howes"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16162": {
    "title": "Visual Relation Detection using Hybrid Analogical Learning",
    "volume": "main",
    "abstract": "Visual Relation Detection is currently one of the most popular problems for visual understanding. Many deep-learning models are designed for relation detection on images and have achieved impressive results. However, deep-learning models have several serious problems, including poor training-efficiency and lack of understandability. Psychologists have ample evidence that analogy is central in human learning and reasoning, including visual reasoning. This paper introduces a new hybrid system for visual relation detection combining deep-learning models and analogical generalization. Object bounding boxes and masks are detected using deep-learning models and analogical generalization over qualitative representations is used for visual relation detection between object pairs. Experiments on the Visual Relation Detection dataset indicates that our hybrid system gets comparable results on the task and is more training-efficient and explainable than pure deep-learning models",
    "checked": true,
    "id": "82ff28447df9049fa006a62060740b0a538d5d62",
    "semantic_title": "visual relation detection using hybrid analogical learning",
    "citation_count": 0,
    "authors": [
      "Kezhen Chen",
      "Ken Forbus"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16163": {
    "title": "Neural Analogical Matching",
    "volume": "main",
    "abstract": "Analogy is core to human cognition. It allows us to solve problems based on prior experience, it governs the way we conceptualize new information, and it even influences our visual perception. The importance of analogy to humans has made it an active area of research in the broader field of artificial intelligence, resulting in data-efficient models that learn and reason in human-like ways. While cognitive perspectives of analogy and deep learning have generally been studied independently of one another, the integration of the two lines of research is a promising step towards more robust and efficient learning techniques. As part of a growing body of research on such an integration, we introduce the Analogical Matching Network: a neural architecture that learns to produce analogies between structured, symbolic representations that are largely consistent with the principles of Structure-Mapping Theory",
    "checked": true,
    "id": "25b7f92266f09fc9a5bbb438e8f0da71dccbce78",
    "semantic_title": "neural analogical matching",
    "citation_count": 11,
    "authors": [
      "Maxwell Crouse",
      "Constantine Nakos",
      "Ibrahim Abdelaziz",
      "Ken Forbus"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16164": {
    "title": "Interpretable Self-Supervised Facial Micro-Expression Learning to Predict Cognitive State and Neurological Disorders",
    "volume": "main",
    "abstract": "Human behavior is the confluence of output from voluntary and involuntary motor systems. The neural activities that mediate behavior, from individual cells to distributed networks, are in a state of constant flux. Artificial intelligence (AI) research over the past decade shows that behavior, in the form of facial muscle activity, can reveal information about fleeting voluntary and involuntary motor system activity related to emotion, pain, and deception. However, the AI algorithms often lack an explanation for their decisions, and learning meaningful representations requires large datasets labeled by a subject-matter expert. Motivated by the success of using facial muscle movements to classify brain states and the importance of learning from small amounts of data, we propose an explainable self-supervised representation-learning paradigm that learns meaningful temporal facial muscle movement patterns from limited samples. We validate our methodology by carrying out comprehensive empirical study to predict future speech behavior in a real-world dataset of adults who stutter (AWS). Our explainability study found facial muscle movements around the eyes (p<0.001) and lips (p<0.001) differ significantly before producing fluent vs. disfluent speech. Evaluations using the AWS dataset demonstrates that the proposed self-supervised approach achieves a minimum of 2.51% accuracy improvement over fully-supervised approaches",
    "checked": true,
    "id": "91a5ba83acbe9e764501a6f8b2bba461c59c0189",
    "semantic_title": "interpretable self-supervised facial micro-expression learning to predict cognitive state and neurological disorders",
    "citation_count": 9,
    "authors": [
      "Arun Das",
      "Jeffrey Mock",
      "Yufei Huang",
      "Edward Golob",
      "Peyman Najafirad"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16165": {
    "title": "Quantum Cognitively Motivated Decision Fusion for Video Sentiment Analysis",
    "volume": "main",
    "abstract": "Video sentiment analysis as a decision-making process is inherently complex, involving the fusion of decisions from multiple modalities and the so-caused cognitive biases. Inspired by recent advances in quantum cognition, we show that the sentiment judgment from one modality could be incompatible with the judgment from another, i.e., the order matters and they cannot be jointly measured to produce a final decision. Thus the cognitive process exhibits ``quantum-like'' biases that cannot be captured by classical probability theories. Accordingly, we propose a fundamentally new, quantum cognitively motivated fusion strategy for predicting sentiment judgments. In particular, we formulate utterances as quantum superposition states of positive and negative sentiment judgments, and uni-modal classifiers as mutually incompatible observables, on a complex-valued Hilbert space with positive-operator valued measures. Experiments on two benchmarking datasets illustrate that our model significantly outperforms various existing decision level and a range of state-of-the-art content-level fusion approaches. The results also show that the concept of incompatibility allows effective handling of all combination patterns, including those extreme cases that are wrongly predicted by all uni-modal classifiers",
    "checked": true,
    "id": "937379606f581fc3001f9b22a49ef1c1072e8c58",
    "semantic_title": "quantum cognitively motivated decision fusion for video sentiment analysis",
    "citation_count": 13,
    "authors": [
      "Dimitris Gkoumas",
      "Qiuchi Li",
      "Shahram Dehdashti",
      "Massimo Melucci",
      "Yijun Yu",
      "Dawei Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16166": {
    "title": "Towards a Better Understanding of VR Sickness: Physical Symptom Prediction for VR Contents",
    "volume": "main",
    "abstract": "We address the black-box issue of VR sickness assessment (VRSA) by evaluating the level of physical symptoms of VR sickness. For the VR contents inducing the similar VR sickness level, the physical symptoms can vary depending on the characteristics of the contents. Most of existing VRSA methods focused on assessing the overall VR sickness score. To make better understanding of VR sickness, it is required to predict and provide the level of major symptoms of VR sickness rather than overall degree of VR sickness. In this paper, we predict the degrees of main physical symptoms affecting the overall degree of VR sickness, which are disorientation, nausea, and oculomotor. In addition, we introduce a new large-scale dataset for VRSA including 360 videos with various frame rates, physiological signals, and subjective scores. On VRSA benchmark and our newly collected dataset, our approach shows a potential to not only achieve the highest correlation with subjective scores, but also to better understand which symptoms are the main causes of VR sickness",
    "checked": true,
    "id": "afd263ad213f403b491d0e3c3388136725447ea0",
    "semantic_title": "towards a better understanding of vr sickness: physical symptom prediction for vr contents",
    "citation_count": 1,
    "authors": [
      "Hak Gu Kim",
      "Sangmin Lee",
      "Seongyeop Kim",
      "Heoun-taek Lim",
      "Yong Man Ro"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16167": {
    "title": "PHASE: PHysically-grounded Abstract Social Events for Machine Social Perception",
    "volume": "main",
    "abstract": "The ability to perceive and reason about social interactions in the context of physical environments is core to human social intelligence and human-machine cooperation. However, no prior dataset or benchmark has systematically evaluated physically grounded perception of complex social interactions that go beyond short actions, such as high-fiving, or simple group activities, such as gathering. In this work, we create a dataset of physically-grounded abstract social events, PHASE, that resemble a wide range of real-life social interactions by including social concepts such as helping another agent. PHASE consists of 2D animations of pairs of agents moving in a continuous space generated procedurally using a physics engine and a hierarchical planner. Agents have a limited field of view, and can interact with multiple objects, in an environment that has multiple landmarks and obstacles. Using PHASE, we design a social recognition task and a social prediction task. PHASE is validated with human experiments demonstrating that humans perceive rich interactions in the social events, and that the simulated agents behave similarly to humans. As a baseline model, we introduce a Bayesian inverse planning approach, SIMPLE (SIMulation, Planning and Local Estimation), which outperforms state-of-the-art feed-forward neural networks. We hope that PHASE can serve as a difficult new challenge for developing new models that can recognize complex social interactions",
    "checked": true,
    "id": "c360c3f6d57e6dede93b00aa3d9cc0d2791a86c8",
    "semantic_title": "phase: physically-grounded abstract social events for machine social perception",
    "citation_count": 20,
    "authors": [
      "Aviv Netanyahu",
      "Tianmin Shu",
      "Boris Katz",
      "Andrei Barbu",
      "Joshua B. Tenenbaum"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16168": {
    "title": "Riemannian Embedding Banks for Common Spatial Patterns with EEG-based SPD Neural Networks",
    "volume": "main",
    "abstract": "Modeling non-linear data as symmetric positive definite (SPD) matrices on Riemannian manifolds has attracted much attention for various classification tasks. In the context of deep learning, SPD matrix-based Riemannian networks have been shown to be a promising solution for classifying electroencephalogram (EEG) signals, capturing the Riemannian geometry within their structured 2D feature representation. However, existing approaches usually learn spatial-temporal structures in an embedding space for all available EEG signals, and their optimization procedures rely on computationally expensive iterations. Furthermore, these approaches often struggle to encode all of the various types of relationships into a single distance metric, resulting in a loss of generality. To address the above limitations, we propose a Riemannian Embedding Banks method, which divides the problem of common spatial patterns learning in an entire embedding space into K-subproblems and builds one model for each subproblem, to be combined with SPD neural networks. By leveraging the concept of the \"separate to learn\" technology on a Riemannian manifold, REB divides the data and the embedding space into K non-overlapping subsets and learns K separate distance metrics in a Riemannian geometric space instead of the vector space. Then, the learned K non-overlapping subsets are grouped into neurons in the SPD neural network's embedding layer. Experimental results on public EEG datasets demonstrate the superiority of the proposed approach for learning common spatial patterns of EEG signals despite their non-stationary nature, increasing the convergence speed while maintaining generalization",
    "checked": true,
    "id": "613a3b6c80f260e8d086fdbccaffeeb409427b04",
    "semantic_title": "riemannian embedding banks for common spatial patterns with eeg-based spd neural networks",
    "citation_count": 16,
    "authors": [
      "Yoon-Je Suh",
      "Byung Hyung Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16169": {
    "title": "Plug-and-Play Domain Adaptation for Cross-Subject EEG-based Emotion Recognition",
    "volume": "main",
    "abstract": "Human emotion decoding in affective brain-computer interfaces suffers a major setback due to the inter-subject variability of electroencephalography (EEG) signals. Existing approaches usually require amassing extensive EEG data of each new subject, which is prohibitively time-consuming along with poor user experience. To tackle this issue, we divide EEG representations into private components specific to each subject and shared emotional components that are universal to all subjects. According to this representation partition, we propose a plug-and-play domain adaptation method for dealing with the inter-subject variability. In the training phase, subject-invariant emotional representations and private components of source subjects are separately captured by a shared encoder and private encoders. Furthermore, we build one emotion classifier on the shared partition and subjects' individual classifiers on the combination of these two partitions. In the calibration phase, the model only requires few unlabeled EEG data from incoming target subjects to model their private components. Therefore, besides the shared emotion classifier, we have another pipeline to use the knowledge of source subjects through the similarity of private components. In the test phase, we integrate predictions of the shared emotion classifier with those of individual classifiers ensemble after modulation by similarity weights. Experimental results on the SEED dataset show that our model greatly shortens the calibration time within a minute while maintaining the recognition accuracy, all of which make emotion decoding more generalizable and practicable",
    "checked": true,
    "id": "082d2c12f81f860a53fa9b30e855b2a34f27b2ba",
    "semantic_title": "plug-and-play domain adaptation for cross-subject eeg-based emotion recognition",
    "citation_count": 44,
    "authors": [
      "Li-Ming Zhao",
      "Xu Yan",
      "Bao-Liang Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16170": {
    "title": "Localization in the Crowd with Topological Constraints",
    "volume": "main",
    "abstract": "We address the problem of crowd localization, i.e., the prediction of dots corresponding to people in a crowded scene. Due to various challenges, a localization method is prone to spatial semantic errors, i.e., predicting multiple dots within a same person or collapsing multiple dots in a cluttered region. We propose a topological approach targeting these semantic errors. We introduce a topological constraint that teaches the model to reason about the spatial arrangement of dots. To enforce this constraint, we define a persistence loss based on the theory of persistent homology. The loss compares the topographic landscape of the likelihood map and the topology of the ground truth. Topological reasoning improves the quality of the localization algorithm especially near cluttered regions. On multiple public benchmarks, our method outperforms previous localization methods. Additionally, we demonstrate the potential of our method in improving the performance in the crowd counting task",
    "checked": true,
    "id": "e7eefae3477c644364fd18e4172113ddf6b14960",
    "semantic_title": "localization in the crowd with topological constraints",
    "citation_count": 68,
    "authors": [
      "Shahira Abousamra",
      "Minh Hoai",
      "Dimitris Samaras",
      "Chao Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16171": {
    "title": "Deep Event Stereo Leveraged by Event-to-Image Translation",
    "volume": "main",
    "abstract": "Depth estimation in real-world applications requires precise responses to fast motion and challenging lighting conditions. Event cameras use bio-inspired event-driven sensors that provide instantaneous and asynchronous information of pixel-level log intensity changes, which makes them suitable for depth estimation in such challenging conditions. However, as the event cameras primarily provide asynchronous and spatially sparse event data, it is hard to provide accurate dense disparity map in stereo event camera setups - especially in estimating disparities on local structures or edges. In this study, we develop a novel deep event stereo network that reconstructs spatial intensity image features from embedded event streams and leverages the event features using the reconstructed image features to compute dense disparity maps. To this end, we propose a novel event-to-image translation network with a cross-semantic attention mechanism that calculates the global semantic context of the event features for the intensity image reconstruction. In addition, a feature aggregation module is developed for accurate disparity estimation, which modulates the event features with the reconstructed image features by a stacked dilated spatially-adaptive denormalization mechanism. Experimental results reveal that our method can outperform the state-of-the-art methods by significant margins both in quantitative and qualitative measures",
    "checked": true,
    "id": "2db03d59e5825f2a5d00bab95bb515fb05280b8f",
    "semantic_title": "deep event stereo leveraged by event-to-image translation",
    "citation_count": 16,
    "authors": [
      "Soikat Hasan Ahmed",
      "Hae Woong Jang",
      "S M Nadim Uddin",
      "Yong Ju Jung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16172": {
    "title": "Optical Flow Estimation from a Single Motion-blurred Image",
    "volume": "main",
    "abstract": "In most of computer vision applications, motion blur is regarded as an undesirable artifact. However, it has been shown that motion blur in an image may have practical interests in fundamental computer vision problems. In this work, we propose a novel framework to estimate optical flow from a single motion-blurred image in an end-to-end manner. We design our network with transformer networks to learn globally and locally varying motions from encoded features of a motion-blurred input, and decode left and right frame features without explicit frame supervision. A flow estimator network is then used to estimate optical flow from the decoded features in a coarse-to-fine manner. We qualitatively and quantitatively evaluate our model through a large set of experiments on synthetic and real motion-blur datasets. We also provide in-depth analysis of our model in connection with related approaches to highlight the effectiveness and favorability of our approach. Furthermore, we showcase the applicability of the flow estimated by our method on deblurring and moving object segmentation tasks",
    "checked": true,
    "id": "1d0bf18f627903aacb1dee7f7b2b81ca35b581f4",
    "semantic_title": "optical flow estimation from a single motion-blurred image",
    "citation_count": 8,
    "authors": [
      "Dawit Mureja Argaw",
      "Junsik Kim",
      "Francois Rameau",
      "Jae Won Cho",
      "In So Kweon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16173": {
    "title": "Motion-blurred Video Interpolation and Extrapolation",
    "volume": "main",
    "abstract": "Abrupt motion of camera or objects in a scene result in a blurry video, and therefore recovering high quality video requires two types of enhancements: visual enhancement and temporal upsampling. A broad range of research attempted to recover clean frames from blurred image sequences or temporally upsample frames by interpolation, yet there are very limited studies handling both problems jointly. In this work, we present a novel framework for deblurring, interpolating and extrapolating sharp frames from a motion-blurred video in an end-to-end manner. We design our framework by first learning the pixel-level motion that caused the blur from the given inputs via optical flow estimation and then predict multiple clean frames by warping the decoded features with the estimated flows. To ensure temporal coherence across predicted frames and address potential temporal ambiguity, we propose a simple, yet effective flow-based rule. The effectiveness and favorability of our approach are highlighted through extensive qualitative and quantitative evaluations on motion-blurred datasets from high speed videos",
    "checked": true,
    "id": "57ff782643597bbd5be70703320bff63acd50ce8",
    "semantic_title": "motion-blurred video interpolation and extrapolation",
    "citation_count": 14,
    "authors": [
      "Dawit Mureja Argaw",
      "Junsik Kim",
      "Francois Rameau",
      "In So Kweon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16174": {
    "title": "Disentangled Multi-Relational Graph Convolutional Network for Pedestrian Trajectory Prediction",
    "volume": "main",
    "abstract": "Pedestrian trajectory prediction is one of the important tasks required for autonomous navigation and social robots in human environments. Previous studies focused on estimating social forces among individual pedestrians. However, they did not consider the social forces of groups on pedestrians, which results in over-collision avoidance problems. To address this problem, we present a Disentangled Multi-Relational Graph Convolutional Network (DMRGCN) for socially entangled pedestrian trajectory prediction. We first introduce a novel disentangled multi-scale aggregation to better represent social interactions, among pedestrians on a weighted graph. For the aggregation, we construct the multi-relational weighted graphs based on distances and relative displacements among pedestrians. In the prediction step, we propose a global temporal aggregation to alleviate accumulated errors for pedestrians changing their directions. Finally, we apply DropEdge into our DMRGCN to avoid the over-fitting issue on relatively small pedestrian trajectory datasets. Through the effective incorporation of the three parts within an end-to-end framework, DMRGCN achieves state-of-the-art performances on a variety of challenging trajectory prediction benchmarks",
    "checked": true,
    "id": "69bee814d5731fd6f3315c0f2edab5e25fcc79be",
    "semantic_title": "disentangled multi-relational graph convolutional network for pedestrian trajectory prediction",
    "citation_count": 17,
    "authors": [
      "Inhwan Bae",
      "Hae-Gon Jeon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16175": {
    "title": "Dense Events Grounding in Video",
    "volume": "main",
    "abstract": "This paper explores a novel setting of temporal sentence grounding for the first time, dubbed as dense events grounding. Given an untrimmed video and a paragraph description, dense events grounding aims to jointly localize temporal moments of multiple events described in the paragraph. Our main motivating fact is that multiple events to be grounded in a video are often semantically related and temporally coordinated according to their order appearing in the paragraph. This fact sheds light on devising more accurate visual grounding model. In this work, we propose Dense Events Propagation Network (DepNet) for this novel task. DepNet first adaptively aggregates temporal and semantic information of dense events into a compact set through a second-order attention pooling, then selectively propagates the aggregated information to each single event with soft attention. Based on such aggregation-and-propagation mechanism, DepNet can effectively exploit both the temporal order and semantic relations of dense events. We conduct comprehensive experiments on large-scale datasets ActivityNet Captions and TACoS. For fair comparisons, our evaluations include both state-of-art single-event grounding methods and their natural extensions to the dense-events grounding setting implemented by us. All experiments clearly shows the performance superiority of the proposed DepNet by significant margins",
    "checked": true,
    "id": "4935b3a6d4e01e7965faf66ba489fd7772d624fe",
    "semantic_title": "dense events grounding in video",
    "citation_count": 13,
    "authors": [
      "Peijun Bao",
      "Qian Zheng",
      "Yadong Mu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16176": {
    "title": "Context-aware Attentional Pooling (CAP) for Fine-grained Visual Classification",
    "volume": "main",
    "abstract": "Deep convolutional neural networks (CNNs) have shown a strong ability in mining discriminative object pose and parts information for image recognition. For fine-grained recognition, context-aware rich feature representation of object/scene plays a key role since it exhibits a significant variance in the same subcategory and subtle variance among different subcategories. Finding the subtle variance that fully characterizes the object/scene is not straightforward. To address this, we propose a novel context-aware attentional pooling (CAP) that effectively captures subtle changes via sub-pixel gradients, and learns to attend informative integral regions and their importance in discriminating different subcategories without requiring the bounding-box and/or distinguishable part annotations. We also introduce a novel feature encoding by considering the intrinsic consistency between the informativeness of the integral regions and their spatial structures to capture the semantic correlation among them. Our approach is simple yet extremely effective and can be easily applied on top of a standard classification backbone network. We evaluate our approach using six state-of-the-art (SotA) backbone networks and eight benchmark datasets. Our method significantly outperforms the SotA approaches on six datasets and is very competitive with the remaining two",
    "checked": true,
    "id": "48913aecd8da6475d93fae7beb13d7ef939b3d8a",
    "semantic_title": "context-aware attentional pooling (cap) for fine-grained visual classification",
    "citation_count": 43,
    "authors": [
      "Ardhendu Behera",
      "Zachary Wharton",
      "Pradeep R P G Hewage",
      "Asish Bera"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16177": {
    "title": "Appearance-Motion Memory Consistency Network for Video Anomaly Detection",
    "volume": "main",
    "abstract": "Abnormal event detection in the surveillance video is an essential but challenging task, and many methods have been proposed to deal with this problem. The previous methods either only consider the appearance information or directly integrate the results of appearance and motion information without considering their endogenous consistency semantics explicitly. Inspired by the rule humans identify the abnormal frames from multi-modality signals, we propose an Appearance-Motion Memory Consistency Network (AMMC-Net). Our method first makes full use of the prior knowledge of appearance and motion signals to explicitly capture the correspondence between them in the high-level feature space. Then, it combines the multi-view features to obtain a more essential and robust feature representation of regular events, which can significantly increase the gap between an abnormal and a regular event. In the anomaly detection phase, we further introduce a commit error in the latent space joint with the prediction error in pixel space to enhance the detection accuracy. Solid experimental results on various standard datasets validate the effectiveness of our approach",
    "checked": true,
    "id": "08c4fa2132dda85c5f02a88fddfb7f17973f3978",
    "semantic_title": "appearance-motion memory consistency network for video anomaly detection",
    "citation_count": 85,
    "authors": [
      "Ruichu Cai",
      "Hao Zhang",
      "Wen Liu",
      "Shenghua Gao",
      "Zhifeng Hao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16178": {
    "title": "Rethinking Object Detection in Retail Stores",
    "volume": "main",
    "abstract": "The conventional standard for object detection uses a bounding box to represent each individual object instance. However, it is not practical in the industry-relevant applications in the context of warehouses due to severe occlusions among groups of instances of the same categories. In this paper, we propose a new task, i.e., simultaneously object localization and counting, abbreviated as Locount, which requires algorithms to localize groups of objects of interest with the number of instances. However, there does not exist a dataset or benchmark designed for such a task. To this end, we collect a large-scale object localization and counting dataset with rich annotations in retail stores, which consists of 50,394 images with more than 1.9 million object instances in 140 categories. Together with this dataset, we provide a new evaluation protocol and divide the training and testing subsets to fairly evaluate the performance of algorithms for Locount, developing a new benchmark for the Locount task. Moreover, we present a cascaded localization and counting network as a strong baseline, which gradually classifies and regresses the bounding boxes of objects with the predicted numbers of instances enclosed in the bounding boxes, trained in an end-to-end manner. Extensive experiments are conducted on the proposed dataset to demonstrate its significance and the analysis is provided to indicate future directions. Dataset is available at https://isrc.iscas.ac.cn/gitlab/research/locount-dataset",
    "checked": true,
    "id": "16951f0976a6e181d7c6d252e3f04f8005549f93",
    "semantic_title": "rethinking object detection in retail stores",
    "citation_count": 12,
    "authors": [
      "Yuanqiang Cai",
      "Longyin Wen",
      "Libo Zhang",
      "Dawei Du",
      "Weiqiang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16179": {
    "title": "YOLObile: Real-Time Object Detection on Mobile Devices via Compression-Compilation Co-Design",
    "volume": "main",
    "abstract": "The rapid development and wide utilization of object detection techniques have aroused attention on both accuracy and speed of object detectors. However, the current state-of-the-art object detection works are either accuracy-oriented using a large model but leading to high latency or speed-oriented using a lightweight model but sacrificing accuracy. In this work, we propose YOLObile framework, a real-time object detection on mobile devices via compression-compilation co-design. A novel block-punched pruning scheme is proposed for any kernel size. To improve computational efficiency on mobile devices, a GPU-CPU collaborative scheme is adopted along with advanced compiler-assisted optimizations. Experimental results indicate that our pruning scheme achieves 14x compression rate of YOLOv4 with 49.0 mAP. Under our YOLObile framework, we achieve 17 FPS inference speed using GPU on Samsung Galaxy S20. By incorporating our proposed GPU-CPU collaborative scheme, the inference speed is increased to 19.1 FPS, and outperforms the original YOLOv4 by 5x speedup. Source code is at: https://github.com/nightsnack/YOLObile",
    "checked": true,
    "id": "33ed5a8c4a6ec049397f77e493041ff51c91fb6a",
    "semantic_title": "yolobile: real-time object detection on mobile devices via compression-compilation co-design",
    "citation_count": 64,
    "authors": [
      "Yuxuan Cai",
      "Hongjia Li",
      "Geng Yuan",
      "Wei Niu",
      "Yanyu Li",
      "Xulong Tang",
      "Bin Ren",
      "Yanzhi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16180": {
    "title": "Semantic MapNet: Building Allocentric Semantic Maps and Representations from Egocentric Views",
    "volume": "main",
    "abstract": "We study the task of semantic mapping ‚Äì specifically, an embodied agent (a robot or an egocentric AI assistant) is given a tour of a new environment and asked to build an allocentric top-down semantic map (‚Äòwhat is where?') from egocentric observations of an RGB-D camera with known pose (via localization sensors). Importantly, our goal is to build neural episodic memories and spatio-semantic representations of 3D spaces that enable the agent to easily learn subsequent tasks in the same space ‚Äì navigating to objects seen during the tour (‚ÄòFind chair') or answering questions about the space (‚ÄòHow many chairs did you see in the house?'). Towards this goal, we present Semantic MapNet (SMNet), which consists of: (1) an Egocentric Visual Encoder that encodes each egocentric RGB-D frame, (2) a Feature Projector that projects egocentric features to appropriate locations on a floor-plan, (3) a Spatial Memory Tensor of size floor-plan length√ówidth√ófeature-dims that learns to accumulate projected egocentric features, and (4) a Map Decoder that uses the memory tensor to produce semantic top-down maps. SMNet combines the strengths of (known) projective camera geometry and neural representation learning. On the task of semantic mapping in the Matterport3D dataset, SMNet significantly outperforms competitive baselines by 4.01‚àí16.81% (absolute) on mean-IoU and 3.81‚àí19.69% (absolute) on Boundary-F1 metrics. Moreover, we show how to use the spatio-semantic allocentric representations build by SMNet for the task of ObjectNav and Embodied Question Answering. Project page: https://vincentcartillier.github.io/smnet.html",
    "checked": false,
    "id": "32176ebfad512c86f3c9ed22bbacf5a72fcd926b",
    "semantic_title": "semantic mapnet: building allocentric semanticmaps and representations from egocentric views",
    "citation_count": 50,
    "authors": [
      "Vincent Cartillier",
      "Zhile Ren",
      "Neha Jain",
      "Stefan Lee",
      "Irfan Essa",
      "Dhruv Batra"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16181": {
    "title": "Understanding Deformable Alignment in Video Super-Resolution",
    "volume": "main",
    "abstract": "Deformable convolution, originally proposed for the adaptation to geometric variations of objects, has recently shown compelling performance in aligning multiple frames and is increasingly adopted for video super-resolution. Despite its remarkable performance, its underlying mechanism for alignment remains unclear. In this study, we carefully investigate the relation between deformable alignment and the classic flow-based alignment. We show that deformable convolution can be decomposed into a combination of spatial warping and convolution. This decomposition reveals the commonality of deformable alignment and flow-based alignment in formulation, but with a key difference in their offset diversity. We further demonstrate through experiments that the increased diversity in deformable alignment yields better-aligned features, and hence significantly improves the quality of video super-resolution output. Based on our observations, we propose an offset-fidelity loss that guides the offset learning with optical flow. Experiments show that our loss successfully avoids the overflow of offsets and alleviates the instability problem of deformable alignment. Aside from the contributions to deformable alignment, our formulation inspires a more flexible approach to introduce offset diversity to flow-based alignment, improving its performance",
    "checked": true,
    "id": "45ddf05fe644114def892da75999f4c5778abd04",
    "semantic_title": "understanding deformable alignment in video super-resolution",
    "citation_count": 96,
    "authors": [
      "Kelvin C.K. Chan",
      "Xintao Wang",
      "Ke Yu",
      "Chao Dong",
      "Chen Change Loy"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16182": {
    "title": "Deep Metric Learning with Graph Consistency",
    "volume": "main",
    "abstract": "Deep Metric Learning (DML) has been more attractive and widely applied in many computer vision tasks, in which a discriminative embedding is requested such that the image features belonging to the same class are gathered together and the ones belonging to different classes are pushed apart. Most existing works insist to learn this discriminative embedding by either devising powerful pair-based loss functions or hard-sample mining strategies. However, in this paper, we start from an another perspective and propose Deep Consistent Graph Metric Learning (CGML) framework to enhance the discrimination of the learned embedding. It is mainly achieved by rethinking the conventional distance constraints as a graph regularization and then introducing a Graph Consistency regularization term, which intends to optimize the feature distribution from a global graph perspective. Inspired by the characteristic of our defined 'Discriminative Graph', which regards DML from another novel perspective, the Graph Consistency regularization term encourages the sub-graphs randomly sampled from the training set to be consistent. We show that our CGML indeed serves as an efficient technique for learning towards discriminative embedding and is applicable to various popular metric objectives, e.g. Triplet, N-Pair and Binomial losses. This paper empirically and experimentally demonstrates the effectiveness of our graph regularization idea, achieving competitive results on the popular CUB, CARS, Stanford Online Products and In-Shop datasets",
    "checked": true,
    "id": "19a2340ff810deb44789661c130b5e77b26768f0",
    "semantic_title": "deep metric learning with graph consistency",
    "citation_count": 5,
    "authors": [
      "Binghui Chen",
      "Pengyu Li",
      "Zhaoyi Yan",
      "Biao Wang",
      "Lei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16183": {
    "title": "CNN Profiler on Polar Coordinate Images for Tropical Cyclone Structure Analysis",
    "volume": "main",
    "abstract": "Convolutional neural networks (CNN) have achieved great success in analyzing tropical cyclones (TC) with satellite images in several tasks, such as TC intensity estimation. In contrast, TC structure, which is conventionally described by a few parameters estimated subjectively by meteorology specialists, is still hard to be profiled objectively and routinely. This study applies CNN on satellite images to create the entire TC structure profiles, covering all the structural parameters. By utilizing the meteorological domain knowledge to construct TC wind profiles based on historical structure parameters, we provide valuable labels for training in our newly released benchmark dataset. With such a dataset, we hope to attract more attention to this crucial issue among data scientists. Meanwhile, a baseline is established based on a specialized convolutional model operating on polar-coordinates. We discovered that it is more feasible and physically reasonable to extract structural information on polar-coordinates, instead of Cartesian coordinates, according to a TC's rotational and spiral natures. Experimental results on the released benchmark dataset verified the robustness of the proposed model and demonstrated the potential for applying deep learning techniques for this barely developed yet important topic. For codes and implementation details, please visit https://github.com/BoyoChen/TCSA-CNN-profiler",
    "checked": true,
    "id": "7928cdd65449f24e3b5b480ad233c027d7de2b56",
    "semantic_title": "cnn profiler on polar coordinate images for tropical cyclone structure analysis",
    "citation_count": 3,
    "authors": [
      "Boyo Chen",
      "Buo-Fu Chen",
      "Chun Min Hsiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16184": {
    "title": "Commonsense Knowledge Aware Concept Selection For Diverse and Informative Visual Storytelling",
    "volume": "main",
    "abstract": "Visual storytelling is a task of generating relevant and interesting stories for given image sequences. In this work we aim at increasing the diversity of the generated stories while preserving the informative content from the images. We propose to foster the diversity and informativeness of a generated story by using a concept selection module that suggests a set of concept candidates. Then, we utilize a large scale pre-trained model to convert concepts and images into full stories. To enrich the candidate concepts, a commonsense knowledge graph is created for each image sequence from which the concept candidates are proposed. To obtain appropriate concepts from the graph, we propose two novel modules that consider the correlation among candidate concepts and the image-concept correlation. Extensive automatic and human evaluation results demonstrate that our model can produce reasonable concepts. This enables our model to outperform the previous models by a large margin on the diversity and informativeness of the story, while retaining the relevance of the story to the image sequence",
    "checked": true,
    "id": "4cfe344e88d2ae5dbd18507025527bd9a27991ba",
    "semantic_title": "commonsense knowledge aware concept selection for diverse and informative visual storytelling",
    "citation_count": 21,
    "authors": [
      "Hong Chen",
      "Yifei Huang",
      "Hiroya Takamura",
      "Hideki Nakayama"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16185": {
    "title": "Attention-based Multi-Level Fusion Network for Light Field Depth Estimation",
    "volume": "main",
    "abstract": "Depth estimation from Light Field (LF) images is a crucial basis for LF related applications. Since multiple views with abundant information are available, how to effectively fuse features of these views is a key point for accurate LF depth estimation. In this paper, we propose a novel attention-based multi-level fusion network. Combined with the four-branch structure, we design intra-branch fusion strategy and inter-branch fusion strategy to hierarchically fuse effective features from different views. By introducing the attention mechanism, features of views with less occlusions and richer textures are selected inside and between these branches to provide more effective information for depth estimation. The depth maps are finally estimated after further aggregation. Experimental results shows the proposed method achieves state-of-the-art performance in both quantitative and qualitative evaluation, which also ranks first in the commonly used HCI 4D Light Field Benchmark",
    "checked": true,
    "id": "7a2b2338b6ab7481bf111afd6e72e41a69abfa5a",
    "semantic_title": "attention-based multi-level fusion network for light field depth estimation",
    "citation_count": 35,
    "authors": [
      "Jiaxin Chen",
      "Shuo Zhang",
      "Youfang Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16186": {
    "title": "Joint Demosaicking and Denoising in the Wild: The Case of Training Under Ground Truth Uncertainty",
    "volume": "main",
    "abstract": "Image demosaicking and denoising are the two key fundamental steps in digital camera pipelines, aiming to reconstruct clean color images from noisy luminance readings. In this paper, we propose and study Wild-JDD, a novel learning framework for joint demosaicking and denoising in the wild. In contrast to previous works which generally assume the ground truth of training data is a perfect reflection of the reality, we consider here the more common imperfect case of ground truth uncertainty in the wild. We first illustrate its manifestation as various kinds of artifacts including zipper effect, color moire and residual noise. Then we formulate a two-stage data degradation process to capture such ground truth uncertainty, where a conjugate prior distribution is imposed upon a base distribution. After that, we derive an evidence lower bound (ELBO) loss to train a neural network that approximates the parameters of the conjugate prior distribution conditioned on the degraded input. Finally, to further enhance the performance for out-of-distribution input, we design a simple but effective fine-tuning strategy by taking the input as a weakly informative prior. Taking into account ground truth uncertainty, Wild-JDD enjoys good interpretability during optimization. Extensive experiments validate that it outperforms state-of-the-art schemes on joint demosaicking and denoising tasks on both synthetic and realistic raw datasets",
    "checked": true,
    "id": "2396a969d45b13072526758f8a3cb6bc119631b6",
    "semantic_title": "joint demosaicking and denoising in the wild: the case of training under ground truth uncertainty",
    "citation_count": 9,
    "authors": [
      "Jierun Chen",
      "Song Wen",
      "S.-H. Gary Chan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16187": {
    "title": "Spatial-temporal Causal Inference for Partial Image-to-video Adaptation",
    "volume": "main",
    "abstract": "Image-to-video adaptation leverages off-the-shelf learned models in labeled images to help classification in unlabeled videos, thus alleviating the high computation overhead of training a video classifier from scratch. This task is very challenging since there exist two types of domain shifts between images and videos: 1) spatial domain shift caused by static appearance variance between images and video frames, and 2) temporal domain shift caused by the absence of dynamic motion in images. Moreover, for different video classes, these two domain shifts have different effects on the domain gap and should not be treated equally during adaptation. In this paper, we propose a spatial-temporal causal inference framework for image-to-video adaptation. We first construct a spatial-temporal causal graph to infer the effects of the spatial and temporal domain shifts by performing counterfactual causality. We then learn causality-guided bidirectional heterogeneous mappings between images and videos to adaptively reduce the two domain shifts. Moreover, to relax the assumption that the label spaces of the image and video domains are the same by the existing methods, we incorporate class-wise alignment into the learning of image-video mappings to perform partial image-to-video adaptation where the image label space subsumes the video label space. Extensive experiments on several video datasets have validated the effectiveness of our proposed method",
    "checked": true,
    "id": "75c0c655c2ebd6a9a016a65e095beb5b42bb94b2",
    "semantic_title": "spatial-temporal causal inference for partial image-to-video adaptation",
    "citation_count": 9,
    "authors": [
      "Jin Chen",
      "Xinxiao Wu",
      "Yao Hu",
      "Jiebo Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16188": {
    "title": "Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding",
    "volume": "main",
    "abstract": "The prevailing framework for solving referring expression grounding is based on a two-stage process: 1) detecting proposals with an object detector and 2) grounding the referent to one of the proposals. Existing two-stage solutions mostly focus on the grounding step, which aims to align the expressions with the proposals. In this paper, we argue that these methods overlook an obvious mismatch between the roles of proposals in the two stages: they generate proposals solely based on the detection confidence (i.e., expression-agnostic), hoping that the proposals contain all right instances in the expression (i.e., expression-aware). Due to this mismatch, current two-stage methods suffer from a severe performance drop between detected and ground-truth proposals. To this end, we propose Ref-NMS, which is the first method to yield expression-aware proposals at the first stage. Ref-NMS regards all nouns in the expression as critical objects, and introduces a lightweight module to predict a score for aligning each box with a critical object. These scores can guide the NMS operation to filter out the boxes irrelevant to the expression, increasing the recall of critical objects, resulting in a significantly improved grounding performance. Since Ref- NMS is agnostic to the grounding step, it can be easily integrated into any state-of-the-art two-stage method. Extensive ablation studies on several backbones, benchmarks, and tasks consistently demonstrate the superiority of Ref-NMS. Codes are available at: https://github.com/ChopinSharp/ref-nms",
    "checked": true,
    "id": "62ea5fe5ac1795297343b20fbaad9397c0f0b6ff",
    "semantic_title": "ref-nms: breaking proposal bottlenecks in two-stage referring expression grounding",
    "citation_count": 42,
    "authors": [
      "Long Chen",
      "Wenbo Ma",
      "Jun Xiao",
      "Hanwang Zhang",
      "Shih-Fu Chang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16189": {
    "title": "RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning",
    "volume": "main",
    "abstract": "We study unsupervised video representation learning that seeks to learn both motion and appearance features from unlabeled video only, which can be reused for downstream tasks such as action recognition. This task, however, is extremely challenging due to 1) the highly complex spatial-temporal information in videos and 2) the lack of labeled data for training. Unlike representation learning for static images, it is difficult to construct a suitable self-supervised task to effectively model both motion and appearance features. More recently, several attempts have been made to learn video representation through video playback speed prediction. However, it is non-trivial to obtain precise speed labels for the videos. More critically, the learned models may tend to focus on motion patterns and thus may not learn appearance features well. In this paper, we observe that the relative playback speed is more consistent with motion patterns and thus provides more effective and stable supervision for representation learning. Therefore, we propose a new way to perceive the playback speed and exploit the relative speed between two video clips as labels. In this way, we are able to effectively perceive speed and learn better motion features. Moreover, to ensure the learning of appearance features, we further propose an appearance-focused task, where we enforce the model to perceive the appearance difference between two video clips. We show that jointly optimizing the two tasks consistently improves the performance on two downstream tasks (namely, action recognition and video retrieval) w.r.t the increasing pre-training epochs. Remarkably, for action recognition on the UCF101 dataset, we achieve 93.7% accuracy without the use of labeled data for pre-training, which outperforms the ImageNet supervised pre-trained model. Our code, pre-trained models, and supplementary materials can be found at https://github.com/PeihaoChen/RSPNet",
    "checked": true,
    "id": "2336388131b3cb41eb44e927aeac10a1dabbedad",
    "semantic_title": "rspnet: relative speed perception for unsupervised video representation learning",
    "citation_count": 92,
    "authors": [
      "Peihao Chen",
      "Deng Huang",
      "Dongliang He",
      "Xiang Long",
      "Runhao Zeng",
      "Shilei Wen",
      "Mingkui Tan",
      "Chuang Gan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16190": {
    "title": "Dual Distribution Alignment Network for Generalizable Person Re-Identification",
    "volume": "main",
    "abstract": "Domain generalization (DG) offers a preferable real-world setting for Person Re-Identification (Re-ID), which trains a model using multiple source domain datasets and expects it to perform well in an unseen target domain without any model updating. Unfortunately, most DG approaches are designed explicitly for classification tasks, which fundamentally differs from the retrieval task Re-ID. Moreover, existing applications of DG in Re-ID cannot correctly handle the massive variation among Re-ID datasets. In this paper, we identify two fundamental challenges in DG for Person Re-ID: domain-wise variations and identity-wise similarities. To this end, we propose an end-to-end Dual Distribution Alignment Network (DDAN) to learn domain-invariant features with dual-level constraints: the domain-wise adversarial feature learning and the identity-wise similarity enhancement. These constraints effectively reduce the domain-shift among multiple source domains further while agreeing to real-world scenarios. We evaluate our method in a large-scale DG Re-ID benchmark and compare it with various cutting-edge DG approaches. Quantitative results show that DDAN achieves state-of-the-art performance",
    "checked": true,
    "id": "ec0f586a489a5c6ce83e8f39487b541d1bb8b19e",
    "semantic_title": "dual distribution alignment network for generalizable person re-identification",
    "citation_count": 29,
    "authors": [
      "Peixian Chen",
      "Pingyang Dai",
      "Jianzhuang Liu",
      "Feng Zheng",
      "Mingliang Xu",
      "Qi Tian",
      "Rongrong Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16191": {
    "title": "RGB-D Salient Object Detection via 3D Convolutional Neural Networks",
    "volume": "main",
    "abstract": "RGB-D salient object detection (SOD) recently has attracted increasing research interest and many deep learning methods based on encoder-decoder architectures have emerged. However, most existing RGB-D SOD models conduct feature fusion either in the single encoder or the decoder stage, which hardly guarantees sufficient cross-modal fusion ability. In this paper, we make the first attempt in addressing RGB-D SOD through 3D convolutional neural networks. The proposed model, named RD3D, aims at pre-fusion in the encoder stage and in-depth fusion in the decoder stage to effectively promote the full integration of RGB and depth streams. Specifically, RD3D first conducts pre-fusion across RGB and depth modalities through an inflated 3D encoder, and later provides in-depth feature fusion by designing a 3D decoder equipped with rich back-projection paths (RBPP) for leveraging the extensive aggregation ability of 3D convolutions. With such a progressive fusion strategy involving both the encoder and decoder, effective and thorough interaction between the two modalities can be exploited and boost the detection accuracy. Extensive experiments on six widely used benchmark datasets demonstrate that RD3D performs favorably against 14 state-of-the-art RGB-D SOD approaches in terms of four key evaluation metrics. Our code will be made publicly available: https://github.com/PPOLYpubki/RD3D",
    "checked": true,
    "id": "609c315d881f8277991abce44706bfc41129bb2e",
    "semantic_title": "rgb-d salient object detection via 3d convolutional neural networks",
    "citation_count": 83,
    "authors": [
      "Qian Chen",
      "Ze Liu",
      "Yi Zhang",
      "Keren Fu",
      "Qijun Zhao",
      "Hongwei Du"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16192": {
    "title": "Mind-the-Gap! Unsupervised Domain Adaptation for Text-Video Retrieval",
    "volume": "main",
    "abstract": "When can we expect a text-video retrieval system to work effectively on datasets that differ from its training domain? In this work, we investigate this question through the lens of unsupervised domain adaptation in which the objective is to match natural language queries and video content in the presence of domain shift at query-time. Such systems have significant practical applications since they are capable generalising to new data sources without requiring corresponding text annotations. We make the following contributions: (1) We propose the UDAVR (Unsupervised Domain Adaptation for Video Retrieval) benchmark and employ it to study the performance of text-video retrieval in the presence of domain shift. (2) We propose Concept-Aware-Pseudo-Query (CAPQ), a method for learning discriminative and transferable features that bridge these cross-domain discrepancies to enable effective target domain retrieval using source domain supervision. (3) We show that CAPQ outperforms alternative domain adaptation strategies on UDAVR",
    "checked": true,
    "id": "781540a3f6ba1a1525b20d08f219f25f89dd852e",
    "semantic_title": "mind-the-gap! unsupervised domain adaptation for text-video retrieval",
    "citation_count": 11,
    "authors": [
      "Qingchao Chen",
      "Yang Liu",
      "Samuel Albanie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16193": {
    "title": "Local Relation Learning for Face Forgery Detection",
    "volume": "main",
    "abstract": "With the rapid development of facial manipulation techniques, face forgery has received considerable attention in digital media forensics due to security concerns. Most existing methods formulate face forgery detection as a classification problem and utilize binary labels or manipulated region masks as supervision. However, without considering the correlation between local regions, these global supervisions are insufficient to learn a generalized feature and prone to overfitting. To address this issue, we propose a novel perspective of face forgery detection via local relation learning. Specifically, we propose a Multi-scale Patch Similarity Module (MPSM), which measures the similarity between features of local regions and forms a robust and generalized similarity pattern. Moreover, we propose an RGB-Frequency Attention Module (RFAM) to fuse information in both RGB and frequency domains for more comprehensive local feature representation, which further improves the reliability of the similarity pattern. Extensive experiments show that the proposed method consistently outperforms the state-of-the-arts on widely-used benchmarks. Furthermore, detailed visualization shows the robustness and interpretability of our method",
    "checked": true,
    "id": "0e668ffa87695c780546ae29bc9d5bdea00234b8",
    "semantic_title": "local relation learning for face forgery detection",
    "citation_count": 105,
    "authors": [
      "Shen Chen",
      "Taiping Yao",
      "Yang Chen",
      "Shouhong Ding",
      "Jilin Li",
      "Rongrong Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16194": {
    "title": "Deductive Learning for Weakly-Supervised 3D Human Pose Estimation via Uncalibrated Cameras",
    "volume": "main",
    "abstract": "Without prohibitive and laborious 3D annotations, weakly-supervised 3D human pose methods mainly employ the model regularization with geometric projection consistency or geometry estimation from multi-view images. Nevertheless, those approaches explicitly need known parameters of calibrated cameras, exhibiting a limited model generalization in various realistic scenarios. To mitigate this issue, in this paper, we propose a Deductive Weakly-Supervised Learning (DWSL) for 3D human pose machine. Our DWSL firstly learns latent representations on depth and camera pose for 3D pose reconstruction. Since weak supervision usually causes ill-conditioned learning or inferior estimation, our DWSL introduces deductive reasoning to make an inference for the human pose from a view to another and develops a reconstruction loss to demonstrate what the model learns and infers is reliable. This learning by deduction strategy employs the view-transform demonstration and structural rules derived from depth, geometry and angle constraints, which improves the reliability of the model training with weak supervision. On three 3D human pose benchmarks, we conduct extensive experiments to evaluate our proposed method, which achieves superior performance in comparison with state-of-the-art weak-supervised methods. Particularly, our model shows an appealing potential for learning from 2D data captured in dynamic outdoor scenes, which demonstrates promising robustness and generalization in realistic scenarios. Our code is publicly available at https://github.com/Xipeng-Chen/DWSL-3D-pose",
    "checked": true,
    "id": "0bd8bd7d793a36917cc4c27c87c0dce3426f4c03",
    "semantic_title": "deductive learning for weakly-supervised 3d human pose estimation via uncalibrated cameras",
    "citation_count": 4,
    "authors": [
      "Xipeng Chen",
      "Pengxu Wei",
      "Liang Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16195": {
    "title": "A Unified Multi-Scenario Attacking Network for Visual Object Tracking",
    "volume": "main",
    "abstract": "Existing methods of adversarial attacks successfully generate adversarial examples to confuse Deep Neural Networks (DNNs) of image classification and object detection, resulting in wrong predictions. However, these methods are difficult to attack models of video object tracking, because the tracking algorithms could handle sequential information across video frames and the categories of targets tracked are normally unknown in advance. In this paper, we propose a Unified and Effective Network, named UEN, to attack visual object tracking models. There are several appealing characteristics of UEN: (1) UEN could produce various invisible adversarial perturbations according to different attack settings by using only one simple end-to-end network with three ingenious loss function; (2) UEN could generate general visible adversarial patch patterns to attack the advanced trackers in the real-world; (3) Extensive experiments show that UEN is able to attack many state-of-the-art trackers effectively (e.g. SiamRPN-based networks and DiMP) on popular tracking datasets including OTB100, UAV123, and GOT10K, making online real-time attacks possible. The attack results outperform the introduced baseline in terms of attacking ability and attacking efficiency",
    "checked": true,
    "id": "3a8034426fd3fbe74c4c9e4517d69de706065efe",
    "semantic_title": "a unified multi-scenario attacking network for visual object tracking",
    "citation_count": 8,
    "authors": [
      "Xuesong Chen",
      "Canmiao Fu",
      "Feng Zheng",
      "Yong Zhao",
      "Hongsheng Li",
      "Ping Luo",
      "Guo-Jun Qi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16196": {
    "title": "SSD-GAN: Measuring the Realness in the Spatial and Spectral Domains",
    "volume": "main",
    "abstract": "This paper observes that there is an issue of high frequencies missing in the discriminator of standard GAN, and we reveal it stems from downsampling layers employed in the network architecture. This issue makes the generator lack the incentive from the discriminator to learn high-frequency content of data, resulting in a significant spectrum discrepancy between generated images and real images. Since the Fourier transform is a bijective mapping, we argue that reducing this spectrum discrepancy would boost the performance of GANs. To this end, we introduce SSD-GAN, an enhancement of GANs to alleviate the spectral information loss in the discriminator. Specifically, we propose to embed a frequency-aware classifier into the discriminator to measure the realness of the input in both the spatial and spectral domains. With the enhanced discriminator, the generator of SSD-GAN is encouraged to learn high-frequency content of real data and generate exact details. The proposed method is general and can be easily integrated into most existing GANs framework without excessive cost. The effectiveness of SSD-GAN is validated on various network architectures, objective functions, and datasets. Code is available at https://github.com/cyq373/SSD-GAN",
    "checked": true,
    "id": "f93a162eb8014fee3feef6b03cd1dcd057e6a4e5",
    "semantic_title": "ssd-gan: measuring the realness in the spatial and spectral domains",
    "citation_count": 37,
    "authors": [
      "Yuanqi Chen",
      "Ge Li",
      "Cece Jin",
      "Shan Liu",
      "Thomas Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16197": {
    "title": "Multi-Scale Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition",
    "volume": "main",
    "abstract": "Graph convolutional networks have been widely used for skeleton-based action recognition due to their excellent modeling ability of non-Euclidean data. As the graph convolution is a local operation, it can only utilize the short-range joint dependencies and short-term trajectory but fails to directly model the distant joints relations and long-range temporal information that are vital to distinguishing various actions. To solve this problem, we present a multi-scale spatial graph convolution (MS-GC) module and a multi-scale temporal graph convolution (MT-GC) module to enrich the receptive field of the model in spatial and temporal dimensions. Concretely, the MS-GC and MT-GC modules decompose the corresponding local graph convolution into a set of sub-graph convolution, forming a hierarchical residual architecture. Without introducing additional parameters, the features will be processed with a series of sub-graph convolutions, and each node could complete multiple spatial and temporal aggregations with its neighborhoods. The final equivalent receptive field is accordingly enlarged, which is capable of capturing both short- and long-range dependencies in spatial and temporal domains. By coupling these two modules as a basic block, we further propose a multi-scale spatial temporal graph convolutional network (MST-GCN), which stacks multiple blocks to learn effective motion representations for action recognition. The proposed MST-GCN achieves remarkable performance on three challenging benchmark datasets, NTU RGB+D, NTU-120 RGB+D and Kinetics-Skeleton, for skeleton-based action recognition",
    "checked": true,
    "id": "32cf93d32f5ad013752b95b0ab7d64bcb1d3d6ff",
    "semantic_title": "multi-scale spatial temporal graph convolutional network for skeleton-based action recognition",
    "citation_count": 100,
    "authors": [
      "Zhan Chen",
      "Sicheng Li",
      "Bing Yang",
      "Qinghan Li",
      "Hong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16198": {
    "title": "Cascade Network with Guided Loss and Hybrid Attention for Finding Good Correspondences",
    "volume": "main",
    "abstract": "Finding good correspondences is a critical prerequisite in many feature based tasks. Given a putative correspondence set of an image pair, we propose a neural network which finds correct correspondences by a binary-class classifier and estimates relative pose through classified correspondences. First, we analyze that due to the imbalance in the number of correct and wrong correspondences, the loss function has a great impact on the classification results. Thus, we propose a new Guided Loss that can directly use evaluation criterion (Fn-measure) as guidance to dynamically adjust the objective function during training. We theoretically prove that the perfect negative correlation between the Guided Loss and Fn-measure, so that the network is always trained towards the direction of increasing Fn-measure to maximize it. We then propose a hybrid attention block to extract feature, which integrates the Bayesian attentive context normalization (BACN) and channel-wise attention (CA). BACN can mine the prior information to better exploit global context and CA can capture complex channel context to enhance the channel awareness of the network. Finally, based on our Guided Loss and hybrid attention block, a cascade network is designed to gradually optimize the result for more superior performance. Experiments have shown that our network achieves the state-of-the-art performance on benchmark datasets. Our code will be available in https://github.com/wenbingtao/GLHA",
    "checked": true,
    "id": "3aab67fe32c12ae4cdcccdac4f938b3aa0918e45",
    "semantic_title": "cascade network with guided loss and hybrid attention for finding good correspondences",
    "citation_count": 6,
    "authors": [
      "Zhi Chen",
      "Fan Yang",
      "Wenbing Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16199": {
    "title": "Generalizable Representation Learning for Mixture Domain Face Anti-Spoofing",
    "volume": "main",
    "abstract": "Face anti-spoofing approach based on domain generalization (DG) has drawn growing attention due to its robustness for unseen scenarios. Existing DG methods assume that the domain label is known. However, in real-world applications, the collected dataset always contains mixture domains, where the domain label is unknown. In this case, most of existing methods may not work. Further, even if we can obtain the domain label as existing methods, we think this is just a sub-optimal partition. To overcome the limitation, we propose domain dynamic adjustment meta-learning (D$^2$AM) without using domain labels, which iteratively divides mixture domains via discriminative domain representation and trains a generalizable face anti-spoofing with meta-learning. Specifically, we design a domain feature based on Instance Normalization (IN) and propose a domain representation learning module (DRLM) to extract discriminative domain features for clustering. Moreover, to reduce the side effect of outliers on clustering performance, we additionally utilize maximum mean discrepancy (MMD) to align the distribution of sample features to a prior distribution, which improves the reliability of clustering. Extensive experiments show that the proposed method outperforms conventional DG-based face anti-spoofing methods, including those utilizing domain labels. Furthermore, we enhance the interpretability through visualization",
    "checked": true,
    "id": "000194903cb83bd4af714f950d0266382e2772fc",
    "semantic_title": "generalizable representation learning for mixture domain face anti-spoofing",
    "citation_count": 54,
    "authors": [
      "Zhihong Chen",
      "Taiping Yao",
      "Kekai Sheng",
      "Shouhong Ding",
      "Ying Tai",
      "Jilin Li",
      "Feiyue Huang",
      "Xinyu Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16200": {
    "title": "SSPC-Net: Semi-supervised Semantic 3D Point Cloud Segmentation Network",
    "volume": "main",
    "abstract": "Point cloud semantic segmentation is a crucial task in 3D scene understanding. Existing methods mainly focus on employing a large number of annotated labels for supervised semantic segmentation. Nonetheless, manually labeling such large point clouds for the supervised segmentation task is time-consuming. In order to reduce the number of annotated labels, we propose a semi-supervised semantic point cloud segmentation network, named SSPC-Net, where we train the semantic segmentation network by inferring the labels of unlabeled points from the few annotated 3D points. In our method, we first partition the whole point cloud into superpoints and build superpoint graphs to mine the long-range dependencies in point clouds. Based on the constructed superpoint graph, we then develop a dynamic label propagation method to generate the pseudo labels for the unsupervised superpoints. Particularly, we adopt a superpoint dropout strategy to dynamically select the generated pseudo labels. In order to fully exploit the generated pseudo labels of the unsupervised superpoints, we furthermore propose a coupled attention mechanism for superpoint feature embedding. Finally, we employ the cross-entropy loss to train the semantic segmentation network with the labels of the supervised superpoints and the pseudo labels of the unsupervised superpoints. Experiments on various datasets demonstrate that our semisupervised segmentation method can achieve better performance than the current semi-supervised segmentation method with fewer annotated 3D points",
    "checked": true,
    "id": "9fca6fd40a7d653ed4bc8f94736b8f8f8fbc02f0",
    "semantic_title": "sspc-net: semi-supervised semantic 3d point cloud segmentation network",
    "citation_count": 56,
    "authors": [
      "Mingmei Cheng",
      "Le Hui",
      "Jin Xie",
      "Jian Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16201": {
    "title": "Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification",
    "volume": "main",
    "abstract": "Trojan (backdoor) attack is a form of adversarial attack on deep neural networks where the attacker provides victims with a model trained/retrained on malicious data. The backdoor can be activated when a normal input is stamped with a certain pattern called trigger, causing misclassification. Many existing trojan attacks have their triggers being input space patches/objects (e.g., a polygon with solid color) or simple input transformations such as Instagram filters. These simple triggers are susceptible to recent backdoor detection algorithms. We propose a novel deep feature space trojan attack with five characteristics: effectiveness, stealthiness, controllability, robustness and reliance on deep features. We conduct extensive experiments on 9 image classifiers on various datasets including ImageNet to demonstrate these properties and show that our attack can evade state-of-the-art defense",
    "checked": true,
    "id": "2cd35c6e53580d2adf5f693b05d5caa19844c19c",
    "semantic_title": "deep feature space trojan attack of neural networks by controlled detoxification",
    "citation_count": 79,
    "authors": [
      "Siyuan Cheng",
      "Yingqi Liu",
      "Shiqing Ma",
      "Xiangyu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16202": {
    "title": "Graph and Temporal Convolutional Networks for 3D Multi-person Pose Estimation in Monocular Videos",
    "volume": "main",
    "abstract": "Despite the recent progress, 3D multi-person pose estimation from monocular videos is still challenging due to the commonly encountered problem of missing information caused by occlusion, partially out-of-frame target persons, and inaccurate person detection. To tackle this problem, we propose a novel framework integrating graph convolutional networks (GCNs) and temporal convolutional networks (TCNs) to robustly estimate camera-centric multi-person 3D poses that does not require camera parameters. In particular, we introduce a human-joint GCN, which unlike the existing GCN, is based on a directed graph that employs the 2D pose estimator's confidence scores to improve the pose estimation results. We also introduce a human-bone GCN, which models the bone connections and provides more information beyond human joints. The two GCNs work together to estimate the spatial frame-wise 3D poses and can make use of both visible joint and bone information in the target frame to estimate the occluded or missing human-part information. To further refine the 3D pose estimation, we use our temporal convolutional networks (TCNs) to enforce the temporal and human-dynamics constraints. We use a joint-TCN to estimate person-centric 3D poses across frames, and propose a velocity-TCN to estimate the speed of 3D joints to ensure the consistency of the 3D pose estimation in consecutive frames. Finally, to estimate the 3D human poses for multiple persons, we propose a root-TCN that estimates camera-centric 3D poses without requiring camera parameters. Quantitative and qualitative evaluations demonstrate the effectiveness of the proposed method",
    "checked": true,
    "id": "495cae238b305c7d021957405335c4d2a90d5e08",
    "semantic_title": "graph and temporal convolutional networks for 3d multi-person pose estimation in monocular videos",
    "citation_count": 24,
    "authors": [
      "Yu Cheng",
      "Bo Wang",
      "Bo Yang",
      "Robby T. Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16203": {
    "title": "DramaQA: Character-Centered Video Story Understanding with Hierarchical QA",
    "volume": "main",
    "abstract": "Despite recent progress on computer vision and natural language processing, developing a machine that can understand video story is still hard to achieve due to the intrinsic difficulty of video story. Moreover, researches on how to evaluate the degree of video understanding based on human cognitive process have not progressed as yet. In this paper, we propose a novel video question answering (Video QA) task, DramaQA, for a comprehensive understanding of the video story. The DramaQA focuses on two perspectives: 1) Hierarchical QAs as an evaluation metric based on the cognitive developmental stages of human intelligence. 2) Character-centered video annotations to model local coherence of the story. Our dataset is built upon the TV drama \"Another Miss Oh\" and it contains 17,983 QA pairs from 23,928 various length video clips, with each QA pair belonging to one of four difficulty levels. We provide 217,308 annotated images with rich character-centered annotations, including visual bounding boxes, behaviors and emotions of main characters, and coreference resolved scripts. Additionally, we suggest Multi-level Context Matching model which hierarchically understands character-centered representations of video to answer questions. We release our dataset and model publicly for research purposes, and we expect our work to provide a new perspective on video story understanding research",
    "checked": true,
    "id": "4d21241b930b005847cf4350294c61d6c29ccd9f",
    "semantic_title": "dramaqa: character-centered video story understanding with hierarchical qa",
    "citation_count": 29,
    "authors": [
      "Seongho Choi",
      "Kyoung-Woon On",
      "Yu-Jung Heo",
      "Ahjeong Seo",
      "Youwon Jang",
      "Minsu Lee",
      "Byoung-Tak Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16204": {
    "title": "DeepCollaboration: Collaborative Generative and Discriminative Models for Class Incremental Learning",
    "volume": "main",
    "abstract": "An important challenge for neural networks is to learn incrementally, i.e., learn new classes without catastrophic forgetting. To overcome this problem, generative replay technique has been suggested, which can generate samples belonging to learned classes while learning new ones. However, such generative models usually suffer from increased distribution mismatch between the generated and original samples along the learning process. In this work, we propose DeepCollaboration (D-Collab), a collaborative framework of deep generative and discriminative models to solve this problem effectively. We develop a discriminative learning model to incrementally update the latent feature space for continual classification. At the same time, a generative model is introduced to achieve conditional generation using the latent feature distribution produced by the discriminative model. Importantly, the generative and discriminative models are connected through bidirectional training to enforce cycle-consistency of mappings between feature and image domains. Furthermore, a domain alignment module is used to eliminate the divergence between the feature distributions of generated images and real ones. This module together with the discriminative model can perform effective sample mining to facilitate incremental learning. Extensive experiments on several visual recognition datasets show that our system can achieve state-of-the-art performance",
    "checked": true,
    "id": "ad8672256f1ff77b68470f082cde11113e6909dd",
    "semantic_title": "deepcollaboration: collaborative generative and discriminative models for class incremental learning",
    "citation_count": 7,
    "authors": [
      "Bo Cui",
      "Guyue Hu",
      "Shan Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16205": {
    "title": "Split then Refine: Stacked Attention-guided ResUNets for Blind Single Image Visible Watermark Removal",
    "volume": "main",
    "abstract": "Digital watermark is a commonly used technique to protect the copyright of medias. Simultaneously, to increase the robustness of watermark, attacking technique, such as watermark removal, also gets the attention from the community. Previous watermark removal methods require to gain the watermark location from users or train a multi-task network to recover the background indiscriminately. However, when jointly learning, the network performs better on watermark detection than recovering the texture. Inspired by this observation and to erase the visible watermarks blindly, we propose a novel two-stage framework with a stacked attention-guided ResUNets to simulate the process of detection, removal and refinement. In the first stage, we design a multi-task network called SplitNet. It learns the basis features for three sub-tasks altogether while the task-specific features separately use multiple channel attentions. Then, with the predicted mask and coarser restored image, we design RefineNet to smooth the watermarked region with a mask-guided spatial attention. Besides network structure, the proposed algorithm also combines multiple perceptual losses for better quality both visually and numerically. We extensively evaluate our algorithm over four different datasets under various settings and the experiments show that our approach outperforms other state-of-the-art methods by a large margin",
    "checked": true,
    "id": "ae10018d80eabefd7755ca30cefe242c1ed71de1",
    "semantic_title": "split then refine: stacked attention-guided resunets for blind single image visible watermark removal",
    "citation_count": 16,
    "authors": [
      "Xiaodong Cun",
      "Chi-Man Pun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16206": {
    "title": "RSGNet: Relation based Skeleton Graph Network for Crowded Scenes Pose Estimation",
    "volume": "main",
    "abstract": "Despite of the recent great progress on multi-person pose estimation, existing solutions still remain challenging under the condition of \"crowded scenes'', where RGB images capture complex real-world scenes with highly-overlapped people, severe occlusions and diverse postures. In this work, we focus on two main problems: 1) how to design an effective pipeline for crowded scenes pose estimation; and 2) how to equip this pipeline with the ability of relation modeling for interference resolving. To tackle these problems, we propose a new pipeline named Relation based Skeleton Graph Network (RSGNet). Unlike existing works that directly predict joints-of-target by labeling joints-of-interference as false positive, we first encourage all joints to be predicted. And then, a Target-aware Relation Parser (TRP) is designed to model the relation over all predicted joints, resulting in a target-aware encoding. This new pipeline will largely relieve the confusion of the joints estimation model when seeing identical joints with totally distinct labels (e.g., the identical hand exists in two bounding boxes). Furthermore, we introduce a Skeleton Graph Machine (SGM) to model the skeleton-based commonsense knowledge, aiming to estimate the target pose with the constraint of human body structure. Such skeleton-based constraint can help to deal with the challenges in crowded scenes from a reasoning perspective. Solid experiments on pose estimation benchmarks demonstrate that our method outperforms existing state-of-the-art methods",
    "checked": true,
    "id": "5b729da0fcb53adadc583bb4003ae457a5eaa15a",
    "semantic_title": "rsgnet: relation based skeleton graph network for crowded scenes pose estimation",
    "citation_count": 6,
    "authors": [
      "Yan Dai",
      "Xuanhan Wang",
      "Lianli Gao",
      "Jingkuan Song",
      "Heng Tao Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16207": {
    "title": "Voxel R-CNN: Towards High Performance Voxel-based 3D Object Detection",
    "volume": "main",
    "abstract": "Recent advances on 3D object detection heavily rely on how the 3D data are represented, i.e., voxel-based or point-based representation. Many existing high performance 3D detectors are point-based because this structure can better retain precise point positions. Nevertheless, point-level features lead to high computation overheads due to unordered storage. In contrast, the voxel-based structure is better suited for feature extraction but often yields lower accuracy because the input data are divided into grids. In this paper, we take a slightly different viewpoint --- we find that precise positioning of raw points is not essential for high performance 3D object detection and that the coarse voxel granularity can also offer sufficient detection accuracy. Bearing this view in mind, we devise a simple but effective voxel-based framework, named Voxel R-CNN. By taking full advantage of voxel features in a two-stage approach, our method achieves comparable detection accuracy with state-of-the-art point-based models, but at a fraction of the computation cost. Voxel R-CNN consists of a 3D backbone network, a 2D bird-eye-view (BEV) Region Proposal Network, and a detect head. A voxel RoI pooling is devised to extract RoI features directly from voxel features for further refinement. Extensive experiments are conducted on the widely used KITTI Dataset and the more recent Waymo Open Dataset. Our results show that compared to existing voxel-based methods, Voxel R-CNN delivers a higher detection accuracy while maintaining a real-time frame processing rate, i.e., at a speed of 25 FPS on an NVIDIA RTX 2080 Ti GPU. The code is available at https://github.com/djiajunustc/Voxel-R-CNN",
    "checked": true,
    "id": "e216ac339cbb4a8accdc266be8f26b554c37a284",
    "semantic_title": "voxel r-cnn: towards high performance voxel-based 3d object detection",
    "citation_count": 348,
    "authors": [
      "Jiajun Deng",
      "Shaoshuai Shi",
      "Peiwei Li",
      "Wengang Zhou",
      "Yanyong Zhang",
      "Houqiang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16208": {
    "title": "Arbitrary Video Style Transfer via Multi-Channel Correlation",
    "volume": "main",
    "abstract": "Video style transfer is attracting increasing attention from the artificial intelligence community because of its numerous applications, such as augmented reality and animation production. Relative to traditional image style transfer, video style transfer presents new challenges, including how to effectively generate satisfactory stylized results for any specified style while maintaining temporal coherence across frames. Towards this end, we propose a Multi-Channel Correlation network (MCCNet), which can be trained to fuse exemplar style features and input content features for efficient style transfer while naturally maintaining the coherence of input videos to output videos. Specifically, MCCNet works directly on the feature space of style and content domain where it learns to rearrange and fuse style features on the basis of their similarity to content features. The outputs generated by MCC are features containing the desired style patterns that can further be decoded into images with vivid style textures. Moreover, MCCNet is also designed to explicitly align the features to input and thereby ensure that the outputs maintain the content structures and the temporal continuity. To further improve the performance of MCCNet under complex light conditions, we also introduce illumination loss during training. Qualitative and quantitative evaluations demonstrate that MCCNet performs well in arbitrary video and image style transfer tasks. Code is available at https://github.com/diyiiyiii/MCCNet",
    "checked": true,
    "id": "48aaf8d685eafe00d86cce789591dafcdeb53766",
    "semantic_title": "arbitrary video style transfer via multi-channel correlation",
    "citation_count": 82,
    "authors": [
      "Yingying Deng",
      "Fan Tang",
      "Weiming Dong",
      "Haibin Huang",
      "Chongyang Ma",
      "Changsheng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16209": {
    "title": "Similarity Reasoning and Filtration for Image-Text Matching",
    "volume": "main",
    "abstract": "Image-text matching plays a critical role in bridging the vision and language, and great progress has been made by exploiting the global alignment between image and sentence, or local alignments between regions and words. However, how to make the most of these alignments to infer more accurate matching scores is still underexplored. In this paper, we propose a novel Similarity Graph Reasoning and Attention Filtration (SGRAF) network for image-text matching. Specifically, the vector-based similarity representations are firstly learned to characterize the local and global alignments in a more comprehensive manner, and then the Similarity Graph Reasoning (SGR) module relying on one graph convolutional neural network is introduced to infer relation-aware similarities with both the local and global alignments. The Similarity Attention Filtration (SAF) module is further developed to integrate these alignments effectively by selectively attending on the significant and representative alignments and meanwhile casting aside the interferences of non-meaningful alignments. We demonstrate the superiority of the proposed method with achieving state-of-the-art performances on the Flickr30K and MSCOCO datasets, and the good interpretability of SGR and SAF with extensive qualitative experiments and analyses",
    "checked": true,
    "id": "6d864a6659e2c503cd6d28d05593f0603b9a48bd",
    "semantic_title": "similarity reasoning and filtration for image-text matching",
    "citation_count": 152,
    "authors": [
      "Haiwen Diao",
      "Ying Zhang",
      "Lin Ma",
      "Huchuan Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16210": {
    "title": "Spatio-Temporal Difference Descriptor for Skeleton-Based Action Recognition",
    "volume": "main",
    "abstract": "In skeletal representation, intra-frame differences between body joints, as well as inter-frame dynamics between body skeletons contain discriminative information for action recognition. Conventional methods for modeling human skeleton sequences generally depend on motion trajectory and body joint dependency information, thus lacking the ability to identify the inherent differences of human skeletons. In this paper, we propose a spatio-temporal difference descriptor based on a directional convolution architecture that enables us to learn the spatio-temporal differences and contextual dependencies between different body joints simultaneously. The overall model is built on a deep symmetric positive definite (SPD) metric learning architecture designed to learn discriminative manifold features with the well-designed non-linear mapping operation. Experiments on several action datasets show that our proposed method achieves up to 3% accuracy improvement over state-of-the-art methods",
    "checked": true,
    "id": "e870e7a38f01c9d4195a6310d2cb9196456c4de4",
    "semantic_title": "spatio-temporal difference descriptor for skeleton-based action recognition",
    "citation_count": 6,
    "authors": [
      "Chongyang Ding",
      "Kai Liu",
      "Jari Korhonen",
      "Evgeny Belyaev"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16211": {
    "title": "Towards Universal Physical Attacks on Single Object Tracking",
    "volume": "main",
    "abstract": "Recent studies show that small perturbations in video frames could misguide single object trackers. However, such attacks have been mainly designed for digital-domain videos (i.e., perturbation on full images), which makes them practically infeasible to evaluate the adversarial vulnerability of trackers in real-world scenarios. Here we made the first step towards physically feasible adversarial attacks against visual tracking in real scenes with a universal patch to camouflage single object trackers. Fundamentally different from physical object detection, the essence of single object tracking lies in the feature matching between the search image and templates, and we therefore specially design the maximum textural discrepancy (MTD), a resolution-invariant and target location-independent feature de-matching loss. The MTD distills global textural information of the template and search images at hierarchical feature scales prior to performing feature attacks. Moreover, we evaluate two shape attacks, the regression dilation and shrinking, to generate stronger and more controllable attacks. Further, we employ a set of transformations to simulate diverse visual tracking scenes in the wild. Experimental results show the effectiveness of the physically feasible attacks on SiamMask and SiamRPN++ visual trackers both in digital and physical scenes",
    "checked": true,
    "id": "bbc00e0f8a809bd5def5a930004dabb016a1c878",
    "semantic_title": "towards universal physical attacks on single object tracking",
    "citation_count": 24,
    "authors": [
      "Li Ding",
      "Yongwei Wang",
      "Kaiwen Yuan",
      "Minyang Jiang",
      "Ping Wang",
      "Hua Huang",
      "Z. Jane Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16212": {
    "title": "Modeling the Probabilistic Distribution of Unlabeled Data for One-shot Medical Image Segmentation",
    "volume": "main",
    "abstract": "Existing image segmentation networks mainly leverage large-scale labeled datasets to attain high accuracy. However, labeling medical images is very expensive since it requires sophisticated expert knowledge. Thus, it is more desirable to employ only a few labeled data in pursuing high segmentation performance. In this paper, we develop a data augmentation method for one-shot brain magnetic resonance imaging (MRI) image segmentation which exploits only one labeled MRI image (named atlas) and a few unlabeled images. In particular, we propose to learn the probability distributions of deformations (including shapes and intensities) of different unlabeled MRI images with respect to the atlas via 3D variational autoencoders (VAEs). In this manner, our method is able to exploit the learned distributions of image deformations to generate new authentic brain MRI images, and the number of generated samples will be sufficient to train a deep segmentation network. Furthermore, we introduce a new standard segmentation benchmark to evaluate the generalization performance of a segmentation network through a cross-dataset setting (collected from different sources). Extensive experiments demonstrate that our method outperforms the state-of-the-art one-shot medical segmentation methods. Our code has been released at https://github.com/dyh127/Modeling-the-Probabilistic-Distribution-of-Unlabeled-Data",
    "checked": false,
    "id": "d94db8bf218a9ed41d9df8cab81edf5f68162e8c",
    "semantic_title": "modeling the probabilistic distribution of unlabeled data forone-shot medical image segmentation",
    "citation_count": 15,
    "authors": [
      "Yuhang Ding",
      "Xin Yu",
      "Yi Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16213": {
    "title": "Few-Shot Class-Incremental Learning via Relation Knowledge Distillation",
    "volume": "main",
    "abstract": "In this paper, we focus on the challenging few-shot class incremental learning (FSCIL) problem, which requires to transfer knowledge from old tasks to new ones and solves catastrophic forgetting. We propose the exemplar relation distillation incremental learning framework to balance the tasks of old-knowledge preserving and new-knowledge adaptation. First, we construct an exemplar relation graph to represent the knowledge learned by the original network and update gradually for new tasks learning. Then an exemplar relation loss function for discovering the relation knowledge between different classes is introduced to learn and transfer the structural information in relation graph. A large number of experiments demonstrate that relation knowledge does exist in the exemplars and our approach outperforms other state-of-the-art class-incremental learning methods on the CIFAR100, miniImageNet, and CUB200 datasets",
    "checked": true,
    "id": "a1364f6e16db9b2f8938ef9bf5c9e2c80b8089f5",
    "semantic_title": "few-shot class-incremental learning via relation knowledge distillation",
    "citation_count": 72,
    "authors": [
      "Songlin Dong",
      "Xiaopeng Hong",
      "Xiaoyu Tao",
      "Xinyuan Chang",
      "Xing Wei",
      "Yihong Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16214": {
    "title": "MIEHDR CNN: Main Image Enhancement based Ghost-Free High Dynamic Range Imaging using Dual-Lens Systems",
    "volume": "main",
    "abstract": "We study the High Dynamic Range (HDR) imaging problem using two Low Dynamic Range (LDR) images that are shot from dual-lens systems in a single shot time with different exposures. In most of the related HDR imaging methods, the problem is usually solved by Multiple Images Merging, i.e. the final HDR image is fused from pixels of all the input LDR images. However, ghost artifacts can be hardly avoided using this strategy. Instead of directly merging the multiple LDR inputs, we use an indirect way which enhances the main image, i.e. the short exposure image IS, using the long exposure image IL serving as guidance. In detail, we propose a new model, named MIEHDR CNN model, which consists of three subnets, i.e. Soft Warp CNN, 3D Guided Denoising CNN and Fusion CNN. The Soft Warp CNN aligns IL to get the aligned result ILA using the soft exposed result of IS as reference. The 3D Guided Denoising CNN denoises the soft exposed result of IS using ILA as guidance, whose result are fed into the Fusion CNN with IS to get the HDR result. The MIEHDR CNN model is implemented by MindSpore and experimental results show that we can outperform related methods largely and avoid ghost artifacts",
    "checked": true,
    "id": "11c91ad084ec95257b55c38e5fb005ccb6d956dc",
    "semantic_title": "miehdr cnn: main image enhancement based ghost-free high dynamic range imaging using dual-lens systems",
    "citation_count": 5,
    "authors": [
      "Xuan Dong",
      "Xiaoyan Hu",
      "Weixin Li",
      "Xiaojie Wang",
      "Yunhong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16215": {
    "title": "Boosting Image-based Mutual Gaze Detection using Pseudo 3D Gaze",
    "volume": "main",
    "abstract": "Mutual gaze detection, i.e., predicting whether or not two people are looking at each other, plays an important role in understanding human interactions. In this work, we focus on the task of image-based mutual gaze detection, and propose a simple and effective approach to boost the performance by using an auxiliary 3D gaze estimation task during the training phase. We achieve the performance boost without additional labeling cost by training the 3D gaze estimation branch using pseudo 3D gaze labels deduced from mutual gaze labels. By sharing the head image encoder between the 3D gaze estimation and the mutual gaze detection branches, we achieve better head features than learned by training the mutual gaze detection branch alone. Experimental results on three image datasets show that the proposed approach improves the detection performance significantly without additional annotations. This work also introduces a new image dataset that consists of 33.1K pairs of humans annotated with mutual gaze labels in 29.2K images",
    "checked": true,
    "id": "e51cb2c5ce4d42cd410adaa54278e05da54a078a",
    "semantic_title": "boosting image-based mutual gaze detection using pseudo 3d gaze",
    "citation_count": 5,
    "authors": [
      "Bardia Doosti",
      "Ching-Hui Chen",
      "Raviteja Vemulapalli",
      "Xuhui Jia",
      "Yukun Zhu",
      "Bradley Green"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16216": {
    "title": "How to Save your Annotation Cost for Panoptic Segmentation?",
    "volume": "main",
    "abstract": "How to properly reduce the annotation cost for panoptic segmentation? How to leverage and optimize the cost-quality trade-off for training data and model? These questions are key challenges towards a label-efficient and scalable panoptic segmentation system due to its expensive instance/semantic pixel-level annotation requirements. By closely examining different kinds of cheaper labels, we introduce a novel multi-objective framework to automatically determine the allocation of different annotations, so as to reach a better segmentation quality with a lower annotation cost. Specifically, we design a Cost-Quality Balanced Network (CQB-Net) to generate the panoptic segmentation map, which distills the crucial relations between various supervisions including panoptic labels, image-level classification labels, bounding boxes, and the semantic coherence information between the foreground and background. Instead of ad-hoc allocation during training, we formulate the optimization of cost-quality trade-off as a Multi-Objective Optimization Problem (MOOP). We model the marginal quality improvement of each annotation and approximate the Pareto-front to enable a label-efficient allocation ratio. Extensive experiments on COCO benchmark show the superiority of our method, e.g. achieving a segmentation quality of 43.4% compared to 43.0% of OCFusion while saving 2.4x annotation cost",
    "checked": true,
    "id": "7e788ab906c1ef7bea762525c1840e2d3da0067f",
    "semantic_title": "how to save your annotation cost for panoptic segmentation?",
    "citation_count": 4,
    "authors": [
      "Xuefeng Du",
      "ChenHan Jiang",
      "Hang Xu",
      "Gengwei Zhang",
      "Zhenguo Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16217": {
    "title": "DIRV: Dense Interaction Region Voting for End-to-End Human-Object Interaction Detection",
    "volume": "main",
    "abstract": "Recent years, human-object interaction (HOI) detection has achieved impressive advances. However, conventional two-stage methods are usually slow in inference. On the other hand, existing one-stage methods mainly focus on the union regions of interactions, which introduce unnecessary visual information as disturbances to HOI detection. To tackle the problems above, we propose a novel one-stage HOI detection approach DIRV in this paper, based on a new concept called interaction region for the HOI problem. Unlike previous methods, our approach concentrates on the densely sampled interaction regions across different scales for each human-object pair, so as to capture the subtle visual features that is most essential to the interaction. Moreover, in order to compensate for the detection flaws of a single interaction region, we introduce a novel voting strategy that makes full use of those overlapped interaction regions in place of conventional Non-Maximal Suppression (NMS). Extensive experiments on two popular benchmarks: V-COCO and HICO-DET show that our approach outperforms existing state-of-the-arts by a large margin with the highest inference speed and lightest network architecture. Our code is publicly available at www.github.com/MVIG-SJTU/DIRV",
    "checked": true,
    "id": "b3066105ca44e24a47065ad57dc6d4ed8e6b7bd6",
    "semantic_title": "dirv: dense interaction region voting for end-to-end human-object interaction detection",
    "citation_count": 29,
    "authors": [
      "Hao-Shu Fang",
      "Yichen Xie",
      "Dian Shao",
      "Cewu Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16218": {
    "title": "DecAug: Augmenting HOI Detection via Decomposition",
    "volume": "main",
    "abstract": "Human-object interaction (HOI) detection requires a large amount of annotated data. Current algorithms suffer from insufficient training samples and category imbalance within datasets. To increase data efficiency, in this paper, we propose an efficient and effective data augmentation method called DecAug for HOI detection. Based on our proposed object state similarity metric, object patterns across different HOIs are shared to augment local object appearance features without changing their states. Further, we shift spatial correlation between humans and objects to other feasible configurations with the aid of a pose-guided Gaussian Mixture Model while preserving their interactions. Experiments show that our method brings up to 3.3 mAP and 1.6 mAP improvements on V-COCO and HICO-DET dataset for two advanced models. Specifically, interactions with fewer samples enjoy more notable improvement. Our method can be easily integrated into various HOI detection models with negligible extra computational consumption",
    "checked": true,
    "id": "821ddd3782bdd4a6945ac69dc428d47b342256b5",
    "semantic_title": "decaug: augmenting hoi detection via decomposition",
    "citation_count": 8,
    "authors": [
      "Hao-Shu Fang",
      "Yichen Xie",
      "Dian Shao",
      "Yong-Lu Li",
      "Cewu Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16219": {
    "title": "Partially Non-Autoregressive Image Captioning",
    "volume": "main",
    "abstract": "Current state-of-the-art image captioning systems usually generated descriptions autoregressively, i.e., every forward step conditions on the given image and previously produced words. The sequential attribution causes a unavoidable decoding latency. Non-autoregressive image captioning, on the other hand, predicts the entire sentence simultaneously and accelerates the inference process significantly. However, it removes the dependence in a caption and commonly suffers from repetition or missing issues. To make a better trade-off between speed and quality, we introduce a partially non-autoregressive model, named PNAIC, which considers a caption as a series of concatenated word groups. The groups are generated parallelly in global while each word in group is predicted from left to right, and thus the captioner can create multiple discontinuous words concurrently at each time step. More importantly, by incorporating curriculum learning-based training tasks of group length prediction and invalid group deletion, our model is capable of generating accurate captions as well as preventing common incoherent errors. Extensive experiments on MS COCO benchmark demonstrate that our proposed method achieves more than 3.5√ó speedup while maintaining competitive performance",
    "checked": true,
    "id": "ffef9f033a6e7383747e674ca7afacda4188d65e",
    "semantic_title": "partially non-autoregressive image captioning",
    "citation_count": 16,
    "authors": [
      "Zhengcong Fei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16220": {
    "title": "Memory-Augmented Image Captioning",
    "volume": "main",
    "abstract": "Current deep learning-based image captioning systems have been proven to store practical knowledge with their parameters and achieve competitive performances in the public datasets. Nevertheless, their ability to access and precisely manipulate the mastered knowledge is still limited. Besides, providing evidence for decisions and updating memory information are also important yet under explored. Towards this goal, we introduce a memory-augmented method, which extends an existing image caption model by incorporating extra explicit knowledge from a memory bank. Adequate knowledge is recalled according to the similarity distance in the embedding space of history context, and the memory bank can be constructed conveniently from any matched image-text set, e.g., the previous training data. Incorporating such non-parametric memory-augmented method to various captioning baselines, the performance of resulting captioners imporves consistently on the evaluation benchmark. More encouragingly, extensive experiments demonstrate that our approach holds the capability for efficiently adapting to larger training datasets, by simply transferring the memory bank without any additional training",
    "checked": true,
    "id": "d2c10cd2403a7847d4380b68dee2cb29c81f532b",
    "semantic_title": "memory-augmented image captioning",
    "citation_count": 14,
    "authors": [
      "Zhengcong Fei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16221": {
    "title": "Edge-competing Pathological Liver Vessel Segmentation with Limited Labels",
    "volume": "main",
    "abstract": "The microvascular invasion (MVI) is a major prognostic factor in hepatocellular carcinoma, which is one of the malignant tumors with the highest mortality rate. The diagnosis of MVI needs discovering the vessels that contain hepatocellular carcinoma cells and counting their number in each vessel, which depends heavily on experiences of the doctor, is largely subjective and time-consuming. However, there is no algorithm as yet tailored for the MVI detection from pathological images. This paper collects the first pathological liver image dataset containing $522$ whole slide images with labels of vessels, MVI, and hepatocellular carcinoma grades. The first and essential step for the automatic diagnosis of MVI is the accurate segmentation of vessels. The unique characteristics of pathological liver images, such as super-large size, multi-scale vessel, and blurred vessel edges, make the accurate vessel segmentation challenging. Based on the collected dataset, we propose an Edge-competing Vessel Segmentation Network (EVS-Net), which contains a segmentation network and two edge segmentation discriminators. The segmentation network, combined with an edge-aware self-supervision mechanism, is devised to conduct vessel segmentation with limited labeled patches. Meanwhile, two discriminators are introduced to distinguish whether the segmented vessel and background contain residual features in an adversarial manner. In the training stage, two discriminators are devised to compete for the predicted position of edges. Exhaustive experiments demonstrate that, with only limited labeled patches, EVS-Net achieves a close performance of fully supervised methods, which provides a convenient tool for the pathological liver vessel segmentation. Code is publicly available at https://github.com/wang97zh/EVS-Net",
    "checked": true,
    "id": "4e0802df6fb69015d4d066beac985feaafdae6a0",
    "semantic_title": "edge-competing pathological liver vessel segmentation with limited labels",
    "citation_count": 8,
    "authors": [
      "Zunlei Feng",
      "Zhonghua Wang",
      "Xinchao Wang",
      "Xiuming Zhang",
      "Lechao Cheng",
      "Jie Lei",
      "Yuexuan Wang",
      "Mingli Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16222": {
    "title": "Visual Boundary Knowledge Translation for Foreground Segmentation",
    "volume": "main",
    "abstract": "When confronted with objects of unknown types in an image, humans can effortlessly and precisely tell their visual boundaries. This recognition mechanism and underlying generalization capability seem to contrast to state-of-the-art image segmentation networks that rely on large-scale category-aware annotated training samples. In this paper, we make an attempt towards building models that explicitly account for visual boundary knowledge, in hope to reduce the training effort on segmenting unseen categories. Specifically, we investigate a new task termed as Boundary Knowledge Translation (BKT). Given a set of fully labeled categories, BKT aims to translate the visual boundary knowledge learned from the labeled categories, to a set of novel categories, each of which is provided only a few labeled samples. To this end, we propose a Translation Segmentation Network (Trans-Net), which comprises a segmentation network and two boundary discriminators. The segmentation network, combined with a boundary-aware self-supervised mechanism, is devised to conduct foreground segmentation, while the two discriminators work together in an adversarial manner to ensure an accurate segmentation of the novel categories under light supervision. Exhaustive experiments demonstrate that, with only tens of labeled samples as guidance, Trans-Net achieves close results on par with fully supervised methods",
    "checked": true,
    "id": "8083ad13f6966791fa69ededbe0658e27ad2530e",
    "semantic_title": "visual boundary knowledge translation for foreground segmentation",
    "citation_count": 6,
    "authors": [
      "Zunlei Feng",
      "Lechao Cheng",
      "Xinchao Wang",
      "Xiang Wang",
      "Ya Jie Liu",
      "Xiangtong Du",
      "Mingli Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16223": {
    "title": "Learning Complex 3D Human Self-Contact",
    "volume": "main",
    "abstract": "Monocular estimation of three dimensional human self-contact is fundamental for detailed scene analysis including body language understanding and behaviour modeling. Existing 3d reconstruction methods do not focus on body regions in self-contact and consequently recover configurations that are either far from each other or self-intersecting, when they should just touch. This leads to perceptually incorrect estimates and limits impact in those very fine-grained analysis domains where detailed 3d models are expected to play an important role. To address such challenges we detect self-contact and design 3d losses to explicitly enforce it. Specifically, we develop a model for Self-Contact Prediction (SCP), that estimates the body surface signature of self-contact, leveraging the localization of self-contact in the image, during both training and inference. We collect two large datasets to support learning and evaluation: (1) HumanSC3D, an accurate 3d motion capture repository containing 1,032 sequences with 5,058 contact events and 1,246,487 ground truth 3d poses synchronized with images collected from multiple views, and (2) FlickrSC3D, a repository of 3,969 images, containing 25,297 surface-to-surface correspondences with annotated image spatial support. We also illustrate how more expressive 3d reconstructions can be recovered under self-contact signature constraints and present monocular detection of face-touch as one of the multiple applications made possible by more accurate self-contact models",
    "checked": true,
    "id": "bcfe7a84f2cbaef7a292595633c5442c9b71d83e",
    "semantic_title": "learning complex 3d human self-contact",
    "citation_count": 20,
    "authors": [
      "Mihai Fieraru",
      "Mihai Zanfir",
      "Elisabeta Oneata",
      "Alin-Ionut Popa",
      "Vlad Olaru",
      "Cristian Sminchisescu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16224": {
    "title": "Rain Streak Removal via Dual Graph Convolutional Network",
    "volume": "main",
    "abstract": "Deep convolutional neural networks (CNNs) have become dominant in the single image de-raining area. However, most deep CNNs-based de-raining methods are designed by stacking vanilla convolutional layers, which can only be used to model local relations. Therefore, long-range contextual information is rarely considered for this specific task. To address the above problem, we propose a simple yet effective dual graph convolutional network (GCN) for single image rain removal. Specifically, we design two graphs to perform global relational modeling and reasoning. The first GCN is used to explore global spatial relations among pixels in feature maps, while the second GCN models the global relations across the channels. Compared to standard convolutional operations, the proposed two graphs enable the network to extract representations from new dimensions. To achieve the image rain removal, we further embed these two graphs and multi-scale dilated convolution into a symmetrically skip-connected network architecture. Therefore, our dual graph convolutional network is able to well handle complex and spatially long rain streaks by exploring multiple representations, e.g., multi-scale local feature, global spatial coherence and cross-channel correlation. Meanwhile, our model is easy to implement, end-to-end trainable and computationally efficient. Extensive experiments on synthetic and real data demonstrate that our method achieves significant improvements over the recent state-of-the-art methods",
    "checked": true,
    "id": "0794cd16b9c60ffb1f162f37b28005151024253b",
    "semantic_title": "rain streak removal via dual graph convolutional network",
    "citation_count": 54,
    "authors": [
      "Xueyang Fu",
      "Qi Qi",
      "Zheng-Jun Zha",
      "Yurui Zhu",
      "Xinghao Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16225": {
    "title": "CompFeat: Comprehensive Feature Aggregation for Video Instance Segmentation",
    "volume": "main",
    "abstract": "Video instance segmentation is a complex task in which we need to detect, segment, and track each object for any given video. Previous approaches only utilize single-frame features for the detection, segmentation, and tracking of objects and they suffer in the video scenario due to several distinct challenges such as motion blur and drastic appearance change. To eliminate ambiguities introduced by only using single-frame features, we propose a novel comprehensive feature aggregation approach (CompFeat) to refine features atboth frame-level and object-level with temporal and spatial context information. The aggregation process is carefully designed with a new attention mechanism which significantly increases the discriminative power of the learned features. We further improve the tracking capability of our model through a siamese design by incorporating both feature similarities and spatial similarities. Experiments conducted on the YouTube-VIS dataset validate the effectiveness of proposed CompFeat",
    "checked": true,
    "id": "0742b295a4bb83f3e28990e2f87545819dcc9e1a",
    "semantic_title": "compfeat: comprehensive feature aggregation for video instance segmentation",
    "citation_count": 52,
    "authors": [
      "Yang Fu",
      "Linjie Yang",
      "Ding Liu",
      "Thomas S. Huang",
      "Humphrey Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16226": {
    "title": "Deep Metric Learning with Self-Supervised Ranking",
    "volume": "main",
    "abstract": "Deep metric learning aims to learn a deep embedding space, where similar objects are pushed towards together and different objects are repelled against. Existing approaches typically use inter-class characteristics, e.g. class-level information or instance-level similarity, to obtain semantic relevance of data points and get a large margin between different classes in the embedding space. However, the intra-class characteristics, e.g. local manifold structure or relative relationship within the same class, are usually overlooked in the learning process. Hence the data structure cannot be fully exploited and the output embeddings have limitation in retrieval. More importantly, retrieval results lack in a good ranking. This paper presents a novel self-supervised ranking auxiliary framework, which captures intra-class characteristics as well as inter-class characteristics for better metric learning. Our method defines specific transform functions to simulates the local structure change of intra-class in the initial image domain, and formulates a self-supervised learning procedure to fully exploit this property and preserve it in the embedding space. Extensive experiments on three standard benchmarks show that our method significantly improves and outperforms the state-of-the-art methods on the performances of both retrieval and ranking by 2%-4%",
    "checked": true,
    "id": "f1bc6f8ad13a44ed1b6e393055bd510f87f7ca69",
    "semantic_title": "deep metric learning with self-supervised ranking",
    "citation_count": 13,
    "authors": [
      "Zheren Fu",
      "Yan Li",
      "Zhendong Mao",
      "Quan Wang",
      "Yongdong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16227": {
    "title": "A Systematic Evaluation of Object Detection Networks for Scientific Plots",
    "volume": "main",
    "abstract": "Are existing object detection methods adequate for detecting text and visual elements in scientific plots which are arguably different than the objects found in natural images? To answer this question, we train and compare the accuracy of Fast/Faster R-CNN, SSD, YOLO and RetinaNet on the PlotQA dataset with over 220,000 scientific plots. At the standard IOU setting of 0.5, most networks perform well with mAP scores greater than 80% in detecting the relatively simple objects in plots. However, the performance drops drastically when evaluated at a stricter IOU of 0.9 with the best model giving a mAP of 35.70%. Note that such a stricter evaluation is essential when dealing with scientific plots where even minor localisation errors can lead to large errors in downstream numerical inferences. Given this poor performance, we propose minor modifications to existing models by combining ideas from different object detection networks. While this significantly improves the performance, there are still two main issues: (i) performance on text objects which are essential for reasoning is very poor, and (ii) inference time is unacceptably large considering the simplicity of plots. To solve this open problem, we make a series of contributions: (a) an efficient region proposal method based on Laplacian edge detectors, (b) a feature representation of region proposals that includes neighbouring information, (c) a linking component to join multiple region proposals for detecting longer textual objects, and (d) a custom loss function that combines a smooth L1-loss with an IOU-based loss. Combining these ideas, our final model is very accurate at extreme IOU values achieving a mAP of 93.44%@0.9 IOU. Simultaneously, our model is very efficient with an inference time 16x lesser than the current models, including one-stage detectors. Our model also achieves a high accuracy on an extrinsic plot-to-table conversion task with an F1 score of 0.77. With these contributions, we make a definitive progress in object detection for plots and enable further exploration on automated reasoning of plots",
    "checked": true,
    "id": "2b3248ed0bb8531d70fba6afc98ec5730be336d3",
    "semantic_title": "a systematic evaluation of object detection networks for scientific plots",
    "citation_count": 4,
    "authors": [
      "Pritha Ganguly",
      "Nitesh S Methani",
      "Mitesh M. Khapra",
      "Pratyush Kumar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16228": {
    "title": "The Complexity of Object Association in Multiple Object Tracking",
    "volume": "main",
    "abstract": "Object association, i.e., the identification of which observations correspond to the same object, is a central task for the area of multiple object tracking. Two prominent models capturing this task have been introduced in the literature: the Lifted Multicut model and the more recent Lifted Paths model. Here, we carry out a detailed complexity-theoretic study of the problems arising from these two models that is aimed at complementing previous empirical work on object association. We obtain a comprehensive complexity map for both models that takes into account natural restrictions to instances such as possible bounds on the number of frames, number of tracked objects and branching degree, as well as less explicit structural restrictions such as having bounded treewidth. Our results include new fixed-parameter and XP algorithms for the problems as well as hardness proofs which altogether indicate that the Lifted Paths problem exhibits a more favorable complexity behavior than Lifted Multicut",
    "checked": true,
    "id": "7c4e0b27ea1c52ce1ee984da05bdb618590bd0be",
    "semantic_title": "the complexity of object association in multiple object tracking",
    "citation_count": 2,
    "authors": [
      "Robert Ganian",
      "Thekla Hamm",
      "Sebastian Ordyniak"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16229": {
    "title": "Learning Local Neighboring Structure for Robust 3D Shape Representation",
    "volume": "main",
    "abstract": "Mesh is a powerful data structure for 3D shapes. Representation learning for 3D meshes is important in many computer vision and graphics applications. The recent success of convolutional neural networks (CNNs) for structured data (e.g., images) suggests the value of adapting insight from CNN for 3D shapes. However, 3D shape data are irregular since each node's neighbors are unordered. Various graph neural networks for 3D shapes have been developed with isotropic filters or predefined local coordinate systems to overcome the node inconsistency on graphs. However, isotropic filters or predefined local coordinate systems limit the representation power. In this paper, we propose a local structure-aware anisotropic convolutional operation (LSA-Conv) that learns adaptive weighting matrices for each node according to the local neighboring structure and performs shared anisotropic filters. In fact, the learnable weighting matrix is similar to the attention matrix in random synthesizer -- a new Transformer model for natural language processing (NLP). Comprehensive experiments demonstrate that our model produces significant improvement in 3D shape reconstruction compared to state-of-the-art methods",
    "checked": true,
    "id": "153d5f337920b214389f87aa53492e93fbd7e270",
    "semantic_title": "learning local neighboring structure for robust 3d shape representation",
    "citation_count": 13,
    "authors": [
      "Zhongpai Gao",
      "Junchi Yan",
      "Guangtao Zhai",
      "Juyong Zhang",
      "Yiyan Yang",
      "Xiaokang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16230": {
    "title": "Semantic-guided Reinforced Region Embedding for Generalized Zero-Shot Learning",
    "volume": "main",
    "abstract": "Generalized zero-shot Learning (GZSL) aims to recognize images from either seen or unseen domain, mainly by learning a joint embedding space to associate image features with the corresponding category descriptions. Recent methods have proved that localizing important object regions can effectively bridge the semantic-visual gap. However, these are all based on one-off visual localizers, lacking of interpretability and flexibility. In this paper, we propose a novel Semantic-guided Reinforced Region Embedding (SR2E) network that can localize important objects in the long-term interests to construct semantic-visual embedding space. SR2E consists of Reinforced Region Module (R2M) and Semantic Alignment Module (SAM). First, without the annotated bounding box as supervision, R2M encodes the semantic category guidance into the reward and punishment criteria to teach the localizer serialized region searching. Besides, R2M explores different action spaces during the serialized searching path to avoid local optimal localization, which thereby generates discriminative visual features with less redundancy. Second, SAM preserves the semantic relationship into visual features via semantic-visual alignment and designs a domain detector to alleviate the domain confusion. Experiments on four public benchmarks demonstrate that the proposed SR2E is an effective GZSL method with reinforced embedding space, which obtains averaged 6.1% improvements",
    "checked": true,
    "id": "1ae803c0134baa69987510eebc6afcec239fa2f6",
    "semantic_title": "semantic-guided reinforced region embedding for generalized zero-shot learning",
    "citation_count": 19,
    "authors": [
      "Jiannan Ge",
      "Hongtao Xie",
      "Shaobo Min",
      "Yongdong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16231": {
    "title": "Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers",
    "volume": "main",
    "abstract": "Given an input video, its associated audio, and a brief caption, the audio-visual scene aware dialog (AVSD) task requires an agent to indulge in a question-answer dialog with a human about the audio-visual content. This task thus poses a challenging multi-modal representation learning and reasoning scenario, advancements into which could influence several human-machine interaction applications. To solve this task, we introduce a semantics-controlled multi-modal shuffled Transformer reasoning framework, consisting of a sequence of Transformer modules, each taking a modality as input and producing representations conditioned on the input question. Our proposed Transformer variant uses a shuffling scheme on their multi-head outputs, demonstrating better regularization. To encode fine-grained visual information, we present a novel dynamic scene graph representation learning pipeline that consists of an intra-frame reasoning layer producing spatio-semantic graph representations for every frame, and an inter-frame aggregation module capturing temporal cues. Our entire pipeline is trained end-to-end. We present experiments on the benchmark AVSD dataset, both on answer generation and selection tasks. Our results demonstrate state-of-the-art performances on all evaluation metrics",
    "checked": true,
    "id": "a2227c1d2e42776af62d732c7fc8370196c72e3f",
    "semantic_title": "dynamic graph representation learning for video dialog via multi-modal shuffled transformers",
    "citation_count": 28,
    "authors": [
      "Shijie Geng",
      "Peng Gao",
      "Moitreya Chatterjee",
      "Chiori Hori",
      "Jonathan Le Roux",
      "Yongfeng Zhang",
      "Hongsheng Li",
      "Anoop Cherian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16232": {
    "title": "Boundary-Aware Geometric Encoding for Semantic Segmentation of Point Clouds",
    "volume": "main",
    "abstract": "Boundary information plays a significant role in 2D image segmentation, while usually being ignored in 3D point cloud segmentation where ambiguous features might be generated in feature extraction, leading to misclassification in the transition area between two objects. In this paper, firstly, we propose a Boundary Prediction Module (BPM) to predict boundary points. Based on the predicted boundary, a boundary-aware Geometric Encoding Module (GEM) is designed to encode geometric information and aggregate features with discrimination in a neighborhood, so that the local features belonging to different categories will not be polluted by each other. To provide extra geometric information for boundary-aware GEM, we also propose a light-weight Geometric Convolution Operation (GCO), making the extracted features more distinguishing. Built upon the boundary-aware GEM, we build our network and test it on benchmarks like ScanNet v2, S3DIS. Results show our methods can significantly improve the baseline and achieve state-of-the-art performance",
    "checked": true,
    "id": "3f4b0c80346cfb2a8ae224ff2beda943eb00d0e4",
    "semantic_title": "boundary-aware geometric encoding for semantic segmentation of point clouds",
    "citation_count": 23,
    "authors": [
      "Jingyu Gong",
      "Jiachen Xu",
      "Xin Tan",
      "Jie Zhou",
      "Yanyun Qu",
      "Yuan Xie",
      "Lizhuang Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16233": {
    "title": "Analogical Image Translation for Fog Generation",
    "volume": "main",
    "abstract": "Image-to-image translation is to map images from a given style to another given style. While exceptionally successful, current methods assume the availability of training images in both source and target domains, which does not always hold in practice. Inspired by humans' reasoning capability of analogy, we propose analogical image translation (AIT) that exploit the concept of gist, for the first time. Given images of two styles in the source domain: A and A', along with images B of the first style in the target domain, learn a model to translate B to B' in the target domain, such that A:A' :: B:B'. AIT is especially useful for translation scenarios in which training data of one style is hard to obtain but training data of the same two styles in another domain is available. For instance, in the case from normal conditions to extreme, rare conditions, obtaining real training images for the latter case is challenging. However, obtaining synthetic data for both cases is relatively easy. In this work, we aim at adding adverse weather effects, more specifically fog, to images taken in clear weather. To circumvent the challenge of collecting real foggy images, AIT learns the gist of translating synthetic clear-weather to foggy images, followed by adding fog effects onto real clear-weather images, without ever seeing any real foggy image. AIT achieves zero-shot image translation capability, whose effectiveness and benefit are demonstrated by the downstream task of semantic foggy scene understanding",
    "checked": true,
    "id": "dc15dca53e34be8dabb3cd7690612faf3e7dde5a",
    "semantic_title": "analogical image translation for fog generation",
    "citation_count": 10,
    "authors": [
      "Rui Gong",
      "Dengxin Dai",
      "Yuhua Chen",
      "Wen Li",
      "Danda Pani Paudel",
      "Luc Van Gool"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16234": {
    "title": "Temporal ROI Align for Video Object Recognition",
    "volume": "main",
    "abstract": "Video object detection is challenging in the presence of appearance deterioration in certain video frames. Therefore, it is a natural choice to aggregate temporal information from other frames of the same video into the current frame. However, ROI Align, as one of the most core procedures of video detectors, still remains extracting features from a single-frame feature map for proposals, making the extracted ROI features lack temporal information from videos. In this work, considering the features of the same object instance are highly similar among frames in a video, a novel Temporal ROI Align operator is proposed to extract features from other frames feature maps for current frame proposals by utilizing feature similarity. The proposed Temporal ROI Align operator can extract temporal information from the entire video for proposals. We integrate it into single-frame video detectors and other state-of-the-art video detectors, and conduct quantitative experiments to demonstrate that the proposed Temporal ROI Align operator can consistently and significantly boost the performance. Besides, the proposed Temporal ROI Align can also be applied into video instance segmentation",
    "checked": true,
    "id": "a9d7664078f7192e3a88e71cf13cc36ed65d2e8c",
    "semantic_title": "temporal roi align for video object recognition",
    "citation_count": 34,
    "authors": [
      "Tao Gong",
      "Kai Chen",
      "Xinjiang Wang",
      "Qi Chu",
      "Feng Zhu",
      "Dahua Lin",
      "Nenghai Yu",
      "Huamin Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16235": {
    "title": "SMART Frame Selection for Action Recognition",
    "volume": "main",
    "abstract": "Video classification is computationally expensive. In this paper, we address theproblem of frame selection to reduce the computational cost of video classification.Recent work has successfully leveraged frame selection for long, untrimmed videos,where much of the content is not relevant, and easy to discard. In this work, however,we focus on the more standard short, trimmed video classification problem. Weargue that good frame selection can not only reduce the computational cost of videoclassification but also increase the accuracy by getting rid of frames that are hard toclassify. In contrast to previous work, we propose a method that instead of selectingframes by considering one at a time, considers them jointly. This results in a moreefficient selection, where \"good\" frames are more effectively distributed over thevideo, like snapshots that tell a story. We call the proposed frame selection SMARTand we test it in combination with different backbone architectures and on multiplebenchmarks (Kinetics [5], Something-something [14], UCF101 [31]). We showthat the SMART frame selection consistently improves the accuracy compared toother frame selection strategies while reducing the computational cost by a factorof 4 to 10 times. Additionally, we show that when the primary goal is recognitionperformance, our selection strategy can improve over recent state-of-the-art modelsand frame selection strategies on various benchmarks (UCF101, HMDB51 [21],FCVID [17], and ActivityNet [4])",
    "checked": true,
    "id": "7c062be0a5ba96b5d0cd606d2eeacd768845a116",
    "semantic_title": "smart frame selection for action recognition",
    "citation_count": 82,
    "authors": [
      "Shreyank N Gowda",
      "Marcus Rohrbach",
      "Laura Sevilla-Lara"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16236": {
    "title": "Proxy Synthesis: Learning with Synthetic Classes for Deep Metric Learning",
    "volume": "main",
    "abstract": "One of the main purposes of deep metric learning is to construct an embedding space that has well-generalized embeddings on both seen (training) classes and unseen (test) classes. Most existing works have tried to achieve this using different types of metric objectives and hard sample mining strategies with given training data. However, learning with only the training data can be overfitted to the seen classes, leading to the lack of generalization capability on unseen classes. To address this problem, we propose a simple regularizer called Proxy Synthesis that exploits synthetic classes for stronger generalization in deep metric learning. The proposed method generates synthetic embeddings and proxies that work as synthetic classes, and they mimic unseen classes when computing proxy-based losses. Proxy Synthesis derives an embedding space considering class relations and smooth decision boundaries for robustness on unseen classes. Our method is applicable to any proxy-based losses, including softmax and its variants. Extensive experiments on four famous benchmarks in image retrieval tasks demonstrate that Proxy Synthesis significantly boosts the performance of proxy-based losses and achieves state-of-the-art performance. Our implementation is available at github.com/navervision/proxy-synthesis",
    "checked": true,
    "id": "62d0b58d27864b030876006037206d59af85946c",
    "semantic_title": "proxy synthesis: learning with synthetic classes for deep metric learning",
    "citation_count": 28,
    "authors": [
      "Geonmo Gu",
      "Byungsoo Ko",
      "Han-Gyu Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16237": {
    "title": "Interpretable Graph Capsule Networks for Object Recognition",
    "volume": "main",
    "abstract": "Capsule Networks, as alternatives to Convolutional Neural Networks, have been proposed to recognize objects from images. The current literature demonstrates many advantages of CapsNets over CNNs. However, how to create explanations for individual classifications of CapsNets has not been well explored. The widely used saliency methods are mainly proposed for explaining CNN-based classifications; they create saliency map explanations by combining activation values and the corresponding gradients, e.g., Grad-CAM. These saliency methods require a specific architecture of the underlying classifiers and cannot be trivially applied to CapsNets due to the iterative routing mechanism therein. To overcome the lack of interpretability, we can either propose new post-hoc interpretation methods for CapsNets or modifying the model to have build-in explanations. In this work, we explore the latter. Specifically, we propose interpretable Graph Capsule Networks (GraCapsNets), where we replace the routing part with a multi-head attention-based Graph Pooling approach. In the proposed model, individual classification explanations can be created effectively and efficiently. Our model also demonstrates some unexpected benefits, even though it replaces the fundamental part of CapsNets. Our GraCapsNets achieve better classification performance with fewer parameters and better adversarial robustness, when compared to CapsNets. Besides, GraCapsNets also keep other advantages of CapsNets, namely, disentangled representations and affine transformation robustness",
    "checked": true,
    "id": "090ad3927063d2c318e4ce5a344aa253a17746de",
    "semantic_title": "interpretable graph capsule networks for object recognition",
    "citation_count": 21,
    "authors": [
      "Jindong Gu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16238": {
    "title": "Class-Incremental Instance Segmentation via Multi-Teacher Networks",
    "volume": "main",
    "abstract": "Although deep neural networks have achieved amazing results on instance segmentation, they are still ill-equipped when they are required to learn new tasks incrementally. Concretely, they suffer from \"catastrophic forgetting\", an abrupt degradation of performance on old classes with the initial training data missing. Moreover, they are subjected to a negative transfer problem on new classes, which renders the model unable to update its knowledge while preserving the previous knowledge. To address these problems, we propose an incremental instance segmentation method that consists of three networks: Former Teacher Network (FTN), Current Student Network (CSN) and Current Teacher Network (CTN). Specifically, FTN supervises CSN to preserve the previous knowledge, and CTN supervises CSN to adapt to new classes. The supervision of two teacher networks is achieved by a distillation loss function for instances, bounding boxes, and classes. In addition, we adjust the supervision weights of different teacher networks to balance between the knowledge preservation for former classes and the adaption to new classes. Extensive experimental results on PASCAL 2012 SBD and COCO datasets show the effectiveness of the proposed method",
    "checked": true,
    "id": "a747a073e580f3db7b164ef1cbb8dab1c949a445",
    "semantic_title": "class-incremental instance segmentation via multi-teacher networks",
    "citation_count": 13,
    "authors": [
      "Yanan Gu",
      "Cheng Deng",
      "Kun Wei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16239": {
    "title": "EfficientDeRain: Learning Pixel-wise Dilation Filtering for High-Efficiency Single-Image Deraining",
    "volume": "main",
    "abstract": "Single-image deraining is rather challenging due to the unknown rain model. Existing methods often make specific assumptions of the rain model, which can hardly cover many diverse circumstances in the real world, compelling them to employ complex optimization or progressive refinement. This, however, significantly affects these methods' efficiency and effectiveness for many efficiency-critical applications. To fill this gap, in this paper, we regard the single-image deraining as a general image-enhancing problem and originally propose a model-free deraining method, i.e., EfficientDeRain, which is able to process a rainy image within 10 ms (i.e., around 6 ms on average), over 80 times faster than the state-of-the-art method (i.e., RCDNet), while achieving similar de-rain effects. We first propose novel pixel-wise dilation filtering. In particular, a rainy image is filtered with the pixel-wise kernels estimated from a kernel prediction network, by which suitable multi-scale kernels for each pixel can be efficiently predicted. Then, to eliminate the gap between synthetic and real data, we further propose an effective data augmentation method (i.e., RainMix) that helps to train the network for handling real rainy images. We perform a comprehensive evaluation on both synthetic and real-world rainy datasets to demonstrate the effectiveness and efficiency of our method. We release the model and code in https://github.com/tsingqguo/efficientderain.git",
    "checked": true,
    "id": "2fe2871e3e21a7ea79a2efa19d9b596749a8c0c5",
    "semantic_title": "efficientderain: learning pixel-wise dilation filtering for high-efficiency single-image deraining",
    "citation_count": 50,
    "authors": [
      "Qing Guo",
      "Jingyang Sun",
      "Felix Juefei-Xu",
      "Lei Ma",
      "Xiaofei Xie",
      "Wei Feng",
      "Yang Liu",
      "Jianjun Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16240": {
    "title": "Order Regularization on Ordinal Loss for Head Pose, Age and Gaze Estimation",
    "volume": "main",
    "abstract": "Ordinal loss is widely used in solving regression problems with deep learning technologies. Its basic idea is to convert regression to classification while preserving the natural order. However, the order constraint is enforced only by ordinal label implicitly, leading to the real output values not strictly in order. It causes the network to learn separable feature rather than discriminative feature, and possibly overfit on training set. In this paper, we propose order regularization on ordinal loss, which makes the outputs in order by explicitly constraining the ordinal classifiers in order. The proposed method contains two parts, i.e. similar-weights constraint, which reduces the ineffective space between classifiers, and differential-bias constraint, which enforces the decision planes in order and enhances the discrimination power of the classifiers. Experimental results show that our proposed method boosts the performance of original ordinal loss on various regression problems such as head pose, age, and gaze estimation, with significant error reduction of around 5%. Furthermore, our method outperforms the state of the art on all these tasks, with the performance gain of 14.4%, 2.2% and 6.5% on head pose, age and gaze estimation respectively",
    "checked": true,
    "id": "e0ed1b7b7ee65f5891d01e8360743a2fa8a0c2ec",
    "semantic_title": "order regularization on ordinal loss for head pose, age and gaze estimation",
    "citation_count": 6,
    "authors": [
      "Tianchu Guo",
      "Hui Zhang",
      "ByungIn Yoo",
      "Yongchao Liu",
      "Youngjun Kwak",
      "Jae-Joon Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16241": {
    "title": "Decoupled and Memory-Reinforced Networks: Towards Effective Feature Learning for One-Step Person Search",
    "volume": "main",
    "abstract": "The goal of person search is to localize and match query persons from scene images. For high efficiency, one-step methods have been developed to jointly handle the pedestrian detection and identification sub-tasks using a single network. There are two major challenges in the current one-step approaches. One is the mutual interference between the optimization objectives of multiple sub-tasks. The other is the sub-optimal identification feature learning caused by small batch size when end-to-end training. To overcome these problems, we propose a decoupled and memory-reinforced network (DMRNet). Specifically, to reconcile the conflicts of multiple objectives, we simplify the standard tightly coupled pipelines and establish a deeply decoupled multi-task learning framework. Further, we build a memory-reinforced mechanism to boost the identification feature learning. By queuing the identification features of recently accessed instances into a memory bank, the mechanism augments the similarity pair construction for pairwise metric learning. For better encoding consistency of the stored features, a slow-moving average of the network is applied for extracting these features. In this way, the dual networks reinforce each other and converge to robust solution states. Experimentally, the proposed method obtains 93.2% and 46.9% mAP on CUHK-SYSU and PRW datasets, which exceeds all the existing one-step methods",
    "checked": true,
    "id": "77ce3eea92b13de5f5de0a06b8807b9a402a75fb",
    "semantic_title": "decoupled and memory-reinforced networks: towards effective feature learning for one-step person search",
    "citation_count": 25,
    "authors": [
      "Chuchu Han",
      "Zhedong Zheng",
      "Changxin Gao",
      "Nong Sang",
      "Yi Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16242": {
    "title": "Spherical Image Generation from a Single Image by Considering Scene Symmetry",
    "volume": "main",
    "abstract": "Spherical images taken in all directions (360 degrees by 180 degrees) allow the full surroundings of a subject to be represented, providing an immersive experience to viewers. Generating a spherical image from a single normal-field-of-view (NFOV) image is convenient and expands the usage scenarios considerably without relying on a specific panoramic camera or images taken from multiple directions; however, achieving such images remains a challenging and unresolved problem. The primary challenge is controlling the high degree of freedom involved in generating a wide area that includes all directions of the desired spherical image. We focus on scene symmetry, which is a basic property of the global structure of spherical images, such as rotational symmetry, plane symmetry, and asymmetry. We propose a method for generating a spherical image from a single NFOV image and controlling the degree of freedom of the generated regions using the scene symmetry. To estimate and control the scene symmetry using both a circular shift and flip of the latent image features, we incorporate the intensity of the symmetry as a latent variable into conditional variational autoencoders. Our experiments show that the proposed method can generate various plausible spherical images controlled from symmetric to asymmetric, and can reduce the reconstruction errors of the generated images based on the estimated symmetry",
    "checked": true,
    "id": "d8ae38800ffbc424a350e7e37a40a9a6384a7fc0",
    "semantic_title": "spherical image generation from a single image by considering scene symmetry",
    "citation_count": 10,
    "authors": [
      "Takayuki Hara",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16243": {
    "title": "Progressive One-shot Human Parsing",
    "volume": "main",
    "abstract": "Prior human parsing models are limited to parsing humans into classes pre-defined in the training data, which is not flexible to generalize to unseen classes, e.g., new clothing in fashion analysis. In this paper, we propose a new problem named one-shot human parsing (OSHP) that requires to parse human into an open set of reference classes defined by any single reference example. During training, only base classes defined in the training set are exposed, which can overlap with part of reference classes. In this paper, we devise a novel Progressive One-shot Parsing network (POPNet) to address two critical challenges , i.e., testing bias and small sizes. POPNet consists of two collaborative metric learning modules named Attention Guidance Module and Nearest Centroid Module, which can learn representative prototypes for base classes and quickly transfer the ability to unseen classes during testing, thereby reducing testing bias. Moreover, POPNet adopts a progressive human parsing framework that can incorporate the learned knowledge of parent classes at the coarse granularity to help recognize the descendant classes at the fine granularity, thereby handling the small sizes issue. Experiments on the ATR-OS benchmark tailored for OSHP demonstrate POPNet outperforms other representative one-shot segmentation models by large margins and establishes a strong baseline. Source code can be found at https://github.com/Charleshhy/One-shot-Human-Parsing",
    "checked": true,
    "id": "3b51a1c4c270651a09c3688e6f7aa4c2f6b01598",
    "semantic_title": "progressive one-shot human parsing",
    "citation_count": 10,
    "authors": [
      "Haoyu He",
      "Jing Zhang",
      "Bhavani Thuraisingham",
      "Dacheng Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16244": {
    "title": "Consistent-Separable Feature Representation for Semantic Segmentation",
    "volume": "main",
    "abstract": "Cross-entropy loss combined with softmax is one of the most commonly used supervision components in most existing segmentation methods. The softmax loss is typically good at optimizing the inter-class difference, but not good at reducing the intra-class variation, which can be suboptimal for semantic segmentation task. In this paper, we propose a Consistent-Separable Feature Representation Network to model the Consistent-Separable (C-S) features, which are intra-class consistent and inter-class separable, improving the discriminative power of the deep features. Specifically, we develop a Consistent-Separable Feature Learning Module to obtain C-S features through a new loss, called Class-Aware Consistency loss. This loss function is proposed to force the deep features to be consistent among the same class and apart between different classes. Moreover, we design an Adaptive feature Aggregation Module to fuse the C-S features and original features from backbone for the better semantic prediction. We show that compared with various baselines, the proposed method brings consistent performance improvement. Our proposed approach achieves state-of-the-art performance on Cityscapes (82.6% mIoU in test set), ADE20K (46.65% mIoU in validation set), COCO Stuff (41.3% mIoU in validation set) and PASCAL Context (55.9% mIoU in test set)",
    "checked": true,
    "id": "0aff94ad1c6c8581a62e24085dec00193960d809",
    "semantic_title": "consistent-separable feature representation for semantic segmentation",
    "citation_count": 3,
    "authors": [
      "Xingjian He",
      "Jing Liu",
      "Jun Fu",
      "Xinxin Zhu",
      "Jinqiao Wang",
      "Hanqing Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16245": {
    "title": "Error-Aware Density Isomorphism Reconstruction for Unsupervised Cross-Domain Crowd Counting",
    "volume": "main",
    "abstract": "This paper focuses on the unsupervised domain adaptation problem for video-based crowd counting, in which we use labeled data as source domain and unlabelled video data as target domain. It is challenging as there is a huge gap between the source and the target domain and no annotations of samples are available in the target domain. The key issue is how to utilize unlabelled videos in the target domain for knowledge learning and transferring from the source domain. To tackle this problem, we propose a novel Error-aware Density Isomorphism REConstruction Network (EDIREC-Net) for cross-domain crowd counting. EDIREC-Net jointly transfers a pre-trained counting model to target domains using a density isomorphism reconstruction objective and models the reconstruction erroneousness by error reasoning. Specifically, as crowd flows in videos are consecutive, the density maps in adjacent frames turn out to be isomorphic. On this basis, we regard the density isomorphism reconstruction error as a self-supervised signal to transfer the pre-trained counting models to different target domains. Moreover, we leverage an estimation-reconstruction consistency to monitor the density reconstruction erroneousness and suppress unreliable density reconstructions during training. Experimental results on four benchmark datasets demonstrate the superiority of the proposed method and ablation studies investigate the efficiency and robustness. The source code is available at https://github.com/GehenHe/EDIREC-Net",
    "checked": true,
    "id": "cf856bc7f6a432f96ab643f76c529ea4a8f387c5",
    "semantic_title": "error-aware density isomorphism reconstruction for unsupervised cross-domain crowd counting",
    "citation_count": 21,
    "authors": [
      "Yuhang He",
      "Zhiheng Ma",
      "Xing Wei",
      "Xiaopeng Hong",
      "Wei Ke",
      "Yihong Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16246": {
    "title": "DropLoss for Long-Tail Instance Segmentation",
    "volume": "main",
    "abstract": "Long-tailed class distributions are prevalent among the practical applications of object detection and instance segmentation. Prior work in long-tail instance segmentation addresses the imbalance of losses between rare and frequent categories by reducing the penalty for a model incorrectly predicting a rare class label. We demonstrate that the rare categories are heavily suppressed by correct background predictions, which reduces the probability for all foreground categories with equal weight. Due to the relative infrequency of rare categories, this leads to an imbalance that biases towards predicting more frequent categories. Based on this insight, we develop DropLoss -- a novel adaptive loss to compensate for this imbalance without a trade-off between rare and frequent categories. With this loss, we show state-of-the-art mAP across rare, common, and frequent categories on the LVIS dataset. Codes are available at https://github.com/timy90022/DropLoss",
    "checked": true,
    "id": "fee65304d2401d2c4bee5b846b7a9c055843a840",
    "semantic_title": "droploss for long-tail instance segmentation",
    "citation_count": 27,
    "authors": [
      "Ting-I Hsieh",
      "Esther Robb",
      "Hwann-Tzong Chen",
      "Jia-Bin Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16247": {
    "title": "Hand-Model-Aware Sign Language Recognition",
    "volume": "main",
    "abstract": "Hand gestures play a dominant role in the expression of sign language. Current deep-learning based video sign language recognition (SLR) methods usually follow a data-driven paradigm under the supervision of the category label. However, those methods suffer limited interpretability and may encounter the overfitting issue due to limited sign data sources. In this paper, we introduce the hand prior and propose a new hand-model-aware framework for isolated SLR with the modeling hand as the intermediate representation. We first transform the cropped hand sequence into the latent semantic feature. Then the hand model introduces the hand prior and provides a mapping from the semantic feature to the compact hand pose representation. Finally, the inference module enhances the spatio-temporal pose representation and performs the final recognition. Due to the lack of annotation on the hand pose under current sign language datasets, we further guide its learning by utilizing multiple weakly-supervised losses to constrain its spatial and temporal consistency. To validate the effectiveness of our method, we perform extensive experiments on four benchmark datasets, including NMFs-CSL, SLR500, MSASL and WLASL. Experimental results demonstrate that our method achieves state-of-the-art performance on all four popular benchmarks with a notable margin",
    "checked": true,
    "id": "832298578168aacc3fb1433296a63dbfa849ee4e",
    "semantic_title": "hand-model-aware sign language recognition",
    "citation_count": 15,
    "authors": [
      "Hezhen Hu",
      "Wengang Zhou",
      "Houqiang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16248": {
    "title": "Stratified Rule-Aware Network for Abstract Visual Reasoning",
    "volume": "main",
    "abstract": "Abstract reasoning refers to the ability to analyze information, discover rules at an intangible level, and solve problems in innovative ways. Raven's Progressive Matrices (RPM) test is typically used to examine the capability of abstract reasoning. The subject is asked to identify the correct choice from the answer set to fill the missing panel at the bottom right of RPM (e.g., a 3√ó3 matrix), following the underlying rules inside the matrix. Recent studies, taking advantage of Convolutional Neural Networks (CNNs), have achieved encouraging progress to accomplish the RPM test. However, they partly ignore necessary inductive biases of RPM solver, such as order sensitivity within each row/column and incremental rule induction. To address this problem, in this paper we propose a Stratified Rule-Aware Network (SRAN) to generate the rule embeddings for two input sequences. Our SRAN learns multiple granularity rule embeddings at different levels, and incrementally integrates the stratified embedding flows through a gated fusion module. With the help of embeddings, a rule similarity metric is applied to guarantee that SRAN can not only be trained using a tuplet loss but also infer the best answer efficiently. We further point out the severe defects existing in the popular RAVEN dataset for RPM test, which prevent from the fair evaluation of the abstract reasoning ability. To fix the defects, we propose an answer set generation algorithm called Attribute Bisection Tree (ABT), forming an improved dataset named Impartial-RAVEN (I-RAVEN for short). Extensive experiments are conducted on both PGM and I-RAVEN datasets, showing that our SRAN outperforms the state-of-the-art models by a considerable margin",
    "checked": true,
    "id": "a3e9620223f8b00f8950a8d945142b80d401e950",
    "semantic_title": "stratified rule-aware network for abstract visual reasoning",
    "citation_count": 47,
    "authors": [
      "Sheng Hu",
      "Yuqing Ma",
      "Xianglong Liu",
      "Yanlu Wei",
      "Shihao Bai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16249": {
    "title": "VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning",
    "volume": "main",
    "abstract": "It is highly desirable yet challenging to generate image captions that can describe novel objects which are unseen in caption-labeled training data, a capability that is evaluated in the novel object captioning challenge (nocaps). In this challenge, no additional image-caption training data, other than COCO Captions, is allowed for model training. Thus, conventional Vision-Language Pre-training (VLP) methods cannot be applied. This paper presents VIsual VOcabulary pre-training (VIVO) that performs pre-training in the absence of caption annotations. By breaking the dependency of paired image-caption training data in VLP, VIVO can leverage large amounts of paired image-tag data to learn a visual vocabulary. This is done by pre-training a multi-layer Transformer model that learns to align image-level tags with their corresponding image region features. To address the unordered nature of image tags, VIVO uses a Hungarian matching loss with masked tag prediction to conduct pre-training. We validate the effectiveness of VIVO by fine-tuning the pre-trained model for image captioning. In addition, we perform an analysis of the visual-text alignment inferred by our model. The results show that our model can not only generate fluent image captions that describe novel objects, but also identify the locations of these objects. Our single model has achieved new state-of-the-art results on nocaps and surpassed the human CIDEr score",
    "checked": true,
    "id": "7ba268c6d5489dd3b3c08e3642f1385c6235118e",
    "semantic_title": "vivo: visual vocabulary pre-training for novel object captioning",
    "citation_count": 37,
    "authors": [
      "Xiaowei Hu",
      "Xi Yin",
      "Kevin Lin",
      "Lei Zhang",
      "Jianfeng Gao",
      "Lijuan Wang",
      "Zicheng Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16250": {
    "title": "Exploiting Relationship for Complex-scene Image Generation",
    "volume": "main",
    "abstract": "The significant progress on Generative Adversarial Networks (GANs) has facilitated realistic single-object image generation based on language input. However, complex-scene generation (with various interactions among multiple objects) still suffers from messy layouts and object distortions, due to diverse configurations in layouts and appearances. Prior methods are mostly object-driven and ignore their inter-relations that play a significant role in complex-scene images. This work explores relationship-aware complex-scene image generation, where multiple objects are inter-related as a scene graph. With the help of relationships, we propose three major updates in the generation framework. First, reasonable spatial layouts are inferred by jointly considering the semantics and relationships among objects. Compared to standard location regression, we show relative scales and distances serve a more reliable target. Second, since the relations between objects have significantly influenced an object's appearance, we design a relation-guided generator to generate objects reflecting their relationships. Third, a novel scene graph discriminator is proposed to guarantee the consistency between the generated image and the input scene graph. Our method tends to synthesize plausible layouts and objects, respecting the interplay of multiple objects in an image. Experimental results on Visual Genome and HICO-DET datasets show that our proposed method significantly outperforms prior arts in terms of IS and FID metrics. Based on our user study and visual inspection, our method is more effective in generating logical layout and appearance for complex-scenes",
    "checked": true,
    "id": "6a5225f5727eb816a39dd7bcdb69caf69b435cdb",
    "semantic_title": "exploiting relationship for complex-scene image generation",
    "citation_count": 9,
    "authors": [
      "Tianyu Hua",
      "Hongdong Zheng",
      "Yalong Bai",
      "Wei Zhang",
      "Xiao-Ping Zhang",
      "Tao Mei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16251": {
    "title": "Modeling Deep Learning Based Privacy Attacks on Physical Mail",
    "volume": "main",
    "abstract": "Mail privacy protection aims to prevent unauthorized access to hidden content within an envelope since normal paper envelopes are not as safe as we think. In this paper, for the first time, we show that with a well designed deep learning model, the hidden content may be largely recovered without opening the envelope. We start by modeling deep learning-based privacy attacks on physical mail content as learning the mapping from the camera-captured envelope front face image to the hidden content, then we explicitly model the mapping as a combination of perspective transformation, image dehazing and denoising using a deep convolutional neural network, named Neural-STE (See-Through-Envelope). We show experimentally that hidden content details, such as texture and image structure, can be clearly recovered. Finally, our formulation and model allow us to design envelopes that can counter deep learning-based privacy attacks on physical mail",
    "checked": true,
    "id": "3660f26001ff7ed6d2643b6ebbb2a18aa09bbd8a",
    "semantic_title": "modeling deep learning based privacy attacks on physical mail",
    "citation_count": 0,
    "authors": [
      "Bingyao Huang",
      "Ruyi Lian",
      "Dimitris Samaras",
      "Haibin Ling"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16252": {
    "title": "PTN: A Poisson Transfer Network for Semi-supervised Few-shot Learning",
    "volume": "main",
    "abstract": "The predicament in semi-supervised few-shot learning (SSFSL) is to maximize the value of the extra unlabeled data to boost the few-shot learner. In this paper, we propose a Poisson Transfer Network (PTN) to mine the unlabeled information for SSFSL from two aspects. First, the Poisson Merriman‚ÄìBence‚ÄìOsher (MBO) model builds a bridge for the communications between labeled and unlabeled examples. This model serves as a more stable and informative classifier than traditional graph-based SSFSL methods in the message-passing process of the labels. Second, the extra unlabeled samples are employed to transfer the knowledge from base classes to novel classes through contrastive learning. Specifically, we force the augmented positive pairs close while push the negative ones distant. Our contrastive transfer scheme implicitly learns the novel-class embeddings to alleviate the over-fitting problem on the few labeled data. Thus, we can mitigate the degeneration of embedding generality in novel classes. Extensive experiments indicate that PTN outperforms the state-of-the-art few-shot and SSFSL models on miniImageNet and tieredImageNet benchmark datasets",
    "checked": true,
    "id": "35a5fd61a69ee5ad3bc25ed80666ab3038bf3b1c",
    "semantic_title": "ptn: a poisson transfer network for semi-supervised few-shot learning",
    "citation_count": 16,
    "authors": [
      "Huaxi Huang",
      "Junjie Zhang",
      "Jian Zhang",
      "Qiang Wu",
      "Chang Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16253": {
    "title": "Text-Guided Graph Neural Networks for Referring 3D Instance Segmentation",
    "volume": "main",
    "abstract": "This paper addresses a new task called referring 3D instance segmentation, which aims to segment out the target instance in a 3D scene given a query sentence. Previous work on scene understanding has explored visual grounding with natural language guidance, yet the emphasis is mostly constrained on images and videos. We propose a Text-guided Graph Neural Network (TGNN) for referring 3D instance segmentation on point clouds. Given a query sentence and the point cloud of a 3D scene, our method learns to extract per-point features and predicts an offset to shift each point toward its object center. Based on the point features and the offsets, we cluster the points to produce fused features and coordinates for the candidate objects. The resulting clusters are modeled as nodes in a Graph Neural Network to learn the representations that encompass the relation structure for each candidate object. The GNN layers leverage each object's features and its relations with neighbors to generate an attention heatmap for the input sentence expression. Finally, the attention heatmap is used to \"guide\" the aggregation of information from neighborhood nodes. Our method achieves state-of-the-art performance on referring 3D instance segmentation and 3D localization on ScanRefer, Nr3D, and Sr3D benchmarks, respectively",
    "checked": true,
    "id": "5f1913828e30c3070f32c154d2d142ec17e91189",
    "semantic_title": "text-guided graph neural networks for referring 3d instance segmentation",
    "citation_count": 60,
    "authors": [
      "Pin-Hao Huang",
      "Han-Hung Lee",
      "Hwann-Tzong Chen",
      "Tyng-Luh Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16254": {
    "title": "Initiative Defense against Facial Manipulation",
    "volume": "main",
    "abstract": "Benefiting from the development of generative adversarial networks (GAN), facial manipulation has achieved significant progress in both academia and industry recently. It inspires an increasing number of entertainment applications but also incurs severe threats to individual privacy and even political security meanwhile. To mitigate such risks, many countermeasures have been proposed. However, the great majority methods are designed in a passive manner, which is to detect whether the facial images or videos are tampered after their wide propagation. These detection-based methods have a fatal limitation, that is, they only work for ex-post forensics but can not prevent the engendering of malicious behavior. To address the limitation, in this paper, we propose a novel framework of initiative defense to degrade the performance of facial manipulation models controlled by malicious users. The basic idea is to actively inject imperceptible venom into target facial data before manipulation. To this end, we first imitate the target manipulation model with a surrogate model, and then devise a poison perturbation generator to obtain the desired venom. An alternating training strategy are further leveraged to train both the surrogate model and the perturbation generator. Two typical facial manipulation tasks: face attribute editing and face reenactment, are considered in our initiative defense framework. Extensive experiments demonstrate the effectiveness and robustness of our framework in different settings. Finally, we hope this work can shed some light on initiative countermeasures against more adversarial scenarios",
    "checked": true,
    "id": "d71e911dc4baa1168f1c3cb3953cb48987311f1b",
    "semantic_title": "initiative defense against facial manipulation",
    "citation_count": 22,
    "authors": [
      "Qidong Huang",
      "Jie Zhang",
      "Wenbo Zhou",
      "Weiming Zhang",
      "Nenghai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16255": {
    "title": "SnapMix: Semantically Proportional Mixing for Augmenting Fine-grained Data",
    "volume": "main",
    "abstract": "Data mixing augmentation has proved effective in training deep models. Recent methods mix labels mainly according to the mixture proportion of image pixels. Due to the major discriminative information of a fine-grained image usually resides in subtle regions, these methods tend to introduce heavy label noise in fine-grained recognition. We propose Semantically Proportional Mixing (SnapMix) that exploits class activation map (CAM) to lessen the label noise in augmenting fine-grained data. SnapMix generates the target label for a mixed image by estimating its intrinsic semantic composition. This strategy can adapt to asymmetric mixing operations and ensure semantic correspondence between synthetic images and target labels. Experiments show that our method consistently outperforms existing mixed-based approaches regardless of different datasets or network depths. Further, by incorporating the mid-level features, the proposed SnapMix achieves top-level performance, demonstrating its potential to serve as a strong baseline for fine-grained recognition",
    "checked": true,
    "id": "c3379bbe58886d8d66c0be777fc7416415617435",
    "semantic_title": "snapmix: semantically proportional mixing for augmenting fine-grained data",
    "citation_count": 64,
    "authors": [
      "Shaoli Huang",
      "Xinchao Wang",
      "Dacheng Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16256": {
    "title": "A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization",
    "volume": "main",
    "abstract": "Weakly supervised temporal action localization is a challenging vision task due to the absence of ground-truth temporal locations of actions in the training videos. With only video-level supervision during training, most existing methods rely on a Multiple Instance Learning (MIL) framework to predict the start and end frame of each action category in a video. However, the existing MIL-based approach has a major limitation of only capturing the most discriminative frames of an action, ignoring the full extent of an activity. Moreover, these methods cannot model background activity effectively, which plays an important role in localizing foreground activities. In this paper, we present a novel framework named HAM-Net with a hybrid attention mechanism which includes temporal soft, semi-soft and hard attentions to address these issues. Our temporal soft attention module, guided by an auxiliary background class in the classification module, models the background activity by introducing an ``action-ness'' score for each video snippet. Moreover, our temporal semi-soft and hard attention modules, calculating two attention scores for each video snippet, help to focus on the less discriminative frames of an action to capture the full action boundary. Our proposed approach outperforms recent state-of-the-art methods by at least 2.2% mAP at IoU threshold 0.5 on the THUMOS14 dataset, and by at least 1.3% mAP at IoU threshold 0.75 on the ActivityNet1.2 dataset",
    "checked": true,
    "id": "34d67dd7fecbb965143bc59ef8a2806eeed5bfe1",
    "semantic_title": "a hybrid attention mechanism for weakly-supervised temporal action localization",
    "citation_count": 70,
    "authors": [
      "Ashraful Islam",
      "Chengjiang Long",
      "Richard Radke"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16257": {
    "title": "Context-Aware Graph Convolution Network for Target Re-identification",
    "volume": "main",
    "abstract": "Most existing re-identification methods focus on learning robust and discriminative features with deep convolution networks. However, many of them consider content similarity separately and fail to utilize the context information of the query and gallery sets, e.g. probe-gallery and gallery-gallery relations, thus hard samples may not be well solved due to the limited or even misleading information. In this paper, we present a novel Context-Aware Graph Convolution Network (CAGCN), where the probe-gallery relations are encoded into the graph nodes and the graph edge connections are well controlled by the gallery-gallery relations. In this way, hard samples can be addressed with the context information flows among other easy samples during the graph reasoning. Specifically, we adopt an effective hard gallery sampler to obtain high recall for positive samples while keeping a reasonable graph size, which can also weaken the imbalanced problem in training process with low computation complexity. Experiments show that the proposed method achieves state-of-the-art performance on both person and vehicle re-identification datasets in a plug and play fashion with limited overhead",
    "checked": true,
    "id": "423d5effcbd0aac7b047b52a34385bfd4ebd915d",
    "semantic_title": "context-aware graph convolution network for target re-identification",
    "citation_count": 14,
    "authors": [
      "Deyi Ji",
      "Haoran Wang",
      "Hanzhe Hu",
      "Weihao Gan",
      "Wei Wu",
      "Junjie Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16258": {
    "title": "Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network",
    "volume": "main",
    "abstract": "Transformer-based architectures have shown great success in image captioning, where object regions are encoded and then attended into the vectorial representations to guide the caption decoding. However, such vectorial representations only contain region-level information without considering the global information reflecting the entire image, which fails to expand the capability of complex multi-modal reasoning in image captioning. In this paper, we introduce a Global Enhanced Transformer (termed GET) to enable the extraction of a more comprehensive global representation, and then adaptively guide the decoder to generate high-quality captions. In GET, a Global Enhanced Encoder is designed for the embedding of the global feature, and a Global Adaptive Decoder are designed for the guidance of the caption generation. The former models intra- and inter-layer global representation by taking advantage of the proposed Global Enhanced Attention and a layer-wise fusion module. The latter contains a Global Adaptive Controller that can adaptively fuse the global information into the decoder to guide the caption generation. Extensive experiments on MS COCO dataset demonstrate the superiority of our GET over many state-of-the-arts",
    "checked": true,
    "id": "7217b5d8d0fb753532026cc36b0aaa056960c6f8",
    "semantic_title": "improving image captioning by leveraging intra- and inter-layer global representation in transformer network",
    "citation_count": 91,
    "authors": [
      "Jiayi Ji",
      "Yunpeng Luo",
      "Xiaoshuai Sun",
      "Fuhai Chen",
      "Gen Luo",
      "Yongjian Wu",
      "Yue Gao",
      "Rongrong Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16259": {
    "title": "Frequency Consistent Adaptation for Real World Super Resolution",
    "volume": "main",
    "abstract": "Recent deep-learning based Super-Resolution (SR) methods have achieved remarkable performance on images with known degradation. However, these methods always fail in real-world scene, since the Low-Resolution (LR) images after the ideal degradation (e.g., bicubic down-sampling) deviate from real source domain. The domain gap between the LR images and the real-world images can be observed clearly on frequency density, which inspires us to explicitly narrow the undesired gap caused by incorrect degradation. From this point of view, we design a novel Frequency Consistent Adaptation (FCA) that ensures the frequency domain consistency when applying existing SR methods to the real scene. We estimate degradation kernels from unsupervised images and generate the corresponding LR images. To provide useful gradient information for kernel estimation, we propose Frequency Density Comparator (FDC) by distinguishing the frequency density of images on different scales. Based on the domain-consistent LR-HR pairs, we train easy-implemented Convolutional Neural Network (CNN) SR models. Extensive experiments show that the proposed FCA improves the performance of the SR model under real-world setting achieving state-of-the-art results with high fidelity and plausible perception, thus providing a novel effective framework for real-world SR application",
    "checked": true,
    "id": "f3c954bdeae18ca362b9642965f51757e4d37aba",
    "semantic_title": "frequency consistent adaptation for real world super resolution",
    "citation_count": 5,
    "authors": [
      "Xiaozhong Ji",
      "Guangpin Tao",
      "Yun Cao",
      "Ying Tai",
      "Tong Lu",
      "Chengjie Wang",
      "Jilin Li",
      "Feiyue Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16260": {
    "title": "Matching on Sets: Conquer Occluded Person Re-identification Without Alignment",
    "volume": "main",
    "abstract": "Occluded person re-identification (re-ID) is a challenging task as different human parts may become invisible in cluttered scenes, making it hard to match person images of different identities. Most existing methods address this challenge by aligning spatial features of body parts according to semantic information (e.g. human poses) or feature similarities but this approach is complicated and sensitive to noises. This paper presents Matching on Sets (MoS), a novel method that positions occluded person re-ID as a set matching task without requiring spatial alignment. MoS encodes a person image by a pattern set as represented by a `global vector' with each element capturing one specific visual pattern, and it introduces Jaccard distance as a metric to compute the distance between pattern sets and measure image similarity. To enable Jaccard distance over continuous real numbers, we employ minimization and maximization to approximate the operations of intersection and union, respectively. In addition, we design a Jaccard triplet loss that enhances the pattern discrimination and allows to embed set matching into deep neural networks for end-to-end training. In the inference stage, we introduce a conflict penalty mechanism that detects mutually exclusive patterns in the pattern union of image pairs and decreases their similarities accordingly. Extensive experiments over three widely used datasets (Market1501, DukeMTMC and Occluded-DukeMTMC) show that MoS achieves superior re-ID performance. Additionally, it is tolerant of occlusions and outperforms the state-of-the-art by large margins for Occluded-DukeMTMC",
    "checked": true,
    "id": "ac864febb60668e5740cc6c18c169fb82f7d3245",
    "semantic_title": "matching on sets: conquer occluded person re-identification without alignment",
    "citation_count": 41,
    "authors": [
      "Mengxi Jia",
      "Xinhua Cheng",
      "Yunpeng Zhai",
      "Shijian Lu",
      "Siwei Ma",
      "Yonghong Tian",
      "Jian Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16261": {
    "title": "GradingNet: Towards Providing Reliable Supervisions for Weakly Supervised Object Detection by Grading the Box Candidates",
    "volume": "main",
    "abstract": "Weakly-Supervised Object Detection (WSOD) aims at training a model with limited and coarse annotations for precisely locating the regions of objects. Existing works solve the WSOD problem by using a two-stage framework, i.e., generating candidate bounding boxes with weak supervision information and then refining them by directly employing supervised object detection models. However, most of such works mainly focus on the performance boosting of the first stage, while ignoring the better usage of generated candidate bounding boxes. To address this issue, we propose a new two-stage framework for WSOD, named GradingNet, which can make good use of the generated candidate bounding boxes. Specifically, the proposed GradingNet consists of two modules: Boxes Grading Module (BGM) and Informative Boosting Module (IBM). BGM generates proposals of the bounding boxes by using standard one-stage weakly-supervised methods, then utilizes Inclusion Principle to pick out highly-reliable boxes and evaluate the grade of each box. With the above boxes and their grade information, an effective anchor generator and a grade-aware loss are carefully designed to train the IBM. Taking the advantages of the grade information, our GradingNet achieves state-of-the-art performance on COCO, VOC 2007 and VOC 2012 benchmarks",
    "checked": true,
    "id": "158bd3ff67a0f0c69dd55b2bc1e9331094c6ec2e",
    "semantic_title": "gradingnet: towards providing reliable supervisions for weakly supervised object detection by grading the box candidates",
    "citation_count": 12,
    "authors": [
      "Qifei Jia",
      "Shikui Wei",
      "Tao Ruan",
      "Yufeng Zhao",
      "Yao Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16262": {
    "title": "SSN3D: Self-Separated Network to Align Parts for 3D Convolution in Video Person Re-Identification",
    "volume": "main",
    "abstract": "Temporal appearance misalignment is a crucial problem in video person re-identification. The same part of person (e.g. head or hand) appearing on different locations in video sequence weakens its discriminative ability, especially when we apply standard temporal aggregation such as 3D convolution or LSTM. To address this issue, we propose Self-Separated network (SSN) to seek out the same parts in different images. As the name implies, SSN, if trained in an unsupervised strategy, guarantees the selected parts distinct. With a few samples of labeled parts to guide SSN training, this semi-supervised trained SSN seeks out the parts that are human-understandable within a frame and stable across a video snippet. Given the distinct and stable person parts, rather than performing aggregation on features, we then apply 3D convolution across different frames for person re-identification. This SSN + 3D pipeline, dubbed SSN3D, is proved to be efficient through extensive experiments on both synthetic and real data",
    "checked": true,
    "id": "319632a336de42b4c9e1fe3d9e08bcd4fd0c3e5f",
    "semantic_title": "ssn3d: self-separated network to align parts for 3d convolution in video person re-identification",
    "citation_count": 13,
    "authors": [
      "Xiaoke Jiang",
      "Yu Qiao",
      "Junjie Yan",
      "Qichen Li",
      "Wanrong Zheng",
      "Dapeng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16263": {
    "title": "Training Binary Neural Network without Batch Normalization for Image Super-Resolution",
    "volume": "main",
    "abstract": "Recently, binary neural network (BNN) based super-resolution (SR) methods have enjoyed initial success in the SR field. However, there is a noticeable performance gap between the binarized model and the full-precision one. Furthermore, the batch normalization (BN) in binary SR networks introduces floating-point calculations, which is unfriendly to low-precision hardwares. Therefore, there is still room for improvement in terms of model performance and efficiency. Focusing on this issue, in this paper, we first explore a novel binary training mechanism based on the feature distribution, allowing us to replace all BN layers with a simple training method. Then, we construct a strong baseline by combining the highlights of recent binarization methods, which already surpasses the state-of-the-arts. Next, to train highly accurate binarized SR model, we also develop a lightweight network architecture and a multi-stage knowledge distillation strategy to enhance the model representation ability. Extensive experiments demonstrate that the proposed method not only presents advantages of lower computation as compared to conventional floating-point networks but outperforms the state-of-the-art binary methods on the standard SR networks",
    "checked": true,
    "id": "c53f797ff376b4bfc78cbf60d60d4f2733143dba",
    "semantic_title": "training binary neural network without batch normalization for image super-resolution",
    "citation_count": 17,
    "authors": [
      "Xinrui Jiang",
      "Nannan Wang",
      "Jingwei Xin",
      "Keyu Li",
      "Xi Yang",
      "Xinbo Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16264": {
    "title": "What to Select: Pursuing Consistent Motion Segmentation from Multiple Geometric Models",
    "volume": "main",
    "abstract": "Motion segmentation aims at separating motions of different moving objects in a video sequence. Facing the complicated real-world scenes, recent studies reveal that combining multiple geometric models would be a more effective way than just employing a single one. This motivates a new wave of model-fusion based motion segmentation methods. However, the vast majority of models of this kind merely seek consensus in spectral embeddings. We argue that a simple consensus might be insufficient to filter out the harmful information which is either unreliable or semantically unrelated to the segmentation task. Therefore, how to automatically select valuable patterns across multiple models should be regarded as a key challenge here. In this paper, we present a novel geometric-model-fusion framework for motion segmentation, which targets at constructing a consistent affinity matrix across all the geometric models. Specifically, it incorporates the structural information shared by affinity matrices to select those semantically consistent entries. Meanwhile, a multiplicative decomposition scheme is adopted to ensure structural consistency among multiple affinities. To solve this problem, an alternative optimization scheme is proposed, together with a proof of its global convergence. Experiments on four real-world benchmarks show the superiority of the proposed method",
    "checked": true,
    "id": "845a0d220e6c17ab7d6af6cfe7fd22e2206ce59c",
    "semantic_title": "what to select: pursuing consistent motion segmentation from multiple geometric models",
    "citation_count": 2,
    "authors": [
      "Yangbangyan Jiang",
      "Qianqian Xu",
      "Ke Ma",
      "Zhiyong Yang",
      "Xiaochun Cao",
      "Qingming Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16265": {
    "title": "Asynchronous Teacher Guided Bit-wise Hard Mining for Online Hashing",
    "volume": "main",
    "abstract": "Online hashing for streaming data has attracted increasing attention recently. However, most existing algorithms focus on batch inputs and instance-balanced optimization, which is limited in the single datum input case and does not match the dynamic training in online hashing. Furthermore, constantly updating the online model with new-coming samples will inevitably lead to the catastrophic forgetting problem. In this paper, we propose a novel online hashing method to handle the above-mentioned issues jointly, termed Asynchronus Teacher-Guided Bit-wise Hard Mining for Online Hashing. Firstly, to meet the needs of datum-wise online hashing, we design a novel binary codebook that is discriminative to separate different classes. Secondly, we propose a novel semantic loss (termed bit-wise attention loss) to dynamically focus on hard samples of each bit during training. Last but not least, we design a asynchronous knowledge distillation scheme to alleviate the catastrophic forgetting problem, where the teacher model is delaying updated to maintain the old knowledge, guiding the student model learning. Extensive experiments conducted on two public benchmarks demonstrate the favorable performance of our method over the state-of-the-arts",
    "checked": true,
    "id": "944d8ddc77ca215eb23830acf119d5f79917da39",
    "semantic_title": "asynchronous teacher guided bit-wise hard mining for online hashing",
    "citation_count": 2,
    "authors": [
      "Sheng Jin",
      "Qin Zhou",
      "Hongxun Yao",
      "Yao Liu",
      "Xian-Sheng Hua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16266": {
    "title": "Deep Low-Contrast Image Enhancement using Structure Tensor Representation",
    "volume": "main",
    "abstract": "We present a new deep learning framework for low-contrast image enhancement, which trains the network using the multi-exposure sequences rather than explicit ground-truth images. The purpose of our method is to enhance a low-contrast image so as to contain abundant details in various exposure levels. To realize this, we propose to design the loss function using the structure tensor representation, which has been widely used as high-dimensional image contrast. Our loss function penalizes the difference of the structure tensor between the network output and the multi-exposure images in a multi-scale manner. Eventually, the network trained by the loss function produces a high-quality image approximating the overall contrast of the sequence. We provide in-depth analysis on our method and comparison with conventional loss functions. Quantitative and qualitative evaluations demonstrate that the proposed method outperforms the existing state-of-the-art approaches in various benchmarks",
    "checked": true,
    "id": "683686c755981313661f42adfe88bf6414737bb1",
    "semantic_title": "deep low-contrast image enhancement using structure tensor representation",
    "citation_count": 1,
    "authors": [
      "Hyungjoo Jung",
      "Hyunsung Jang",
      "Namkoo Ha",
      "Kwanghoon Sohn"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16267": {
    "title": "Spectral Distribution Aware Image Generation",
    "volume": "main",
    "abstract": "Recent advances in deep generative models for photo-realistic images have led to high quality visual results. Such models learn to generate data from a given training distribution such that generated images can not be easily distinguished from real images by the human eye. Yet, recent work on the detection of such fake images pointed out that they are actually easily distinguishable by artifacts in their frequency spectra. In this paper, we propose to generate images according to the frequency distribution of the real data by employing a spectral discriminator. The proposed discriminator is lightweight, modular and works stably with different commonly used GAN losses. We show that the resulting models can better generate images with realistic frequency spectra, which are thus harder to detect by this cue",
    "checked": true,
    "id": "5e8d57a7a7dafb4e5c82eecc798a0b557478500a",
    "semantic_title": "spectral distribution aware image generation",
    "citation_count": 21,
    "authors": [
      "Steffen Jung",
      "Margret Keuper"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16268": {
    "title": "StarNet: towards Weakly Supervised Few-Shot Object Detection",
    "volume": "main",
    "abstract": "Few-shot detection and classification have advanced significantly in recent years. Yet, detection approaches require strong annotation (bounding boxes) both for pre-training and for adaptation to novel classes, and classification approaches rarely provide localization of objects in the scene. In this paper, we introduce StarNet - a few-shot model featuring an end-to-end differentiable non-parametric star-model detection and classification head. Through this head, the backbone is meta-trained using only image-level labels to produce good features for jointly localizing and classifying previously unseen categories of few-shot test tasks using a star-model that geometrically matches between the query and support images (to find corresponding object instances). Being a few-shot detector, StarNet does not require any bounding box annotations, neither during pre-training nor for novel classes adaptation. It can thus be applied to the previously unexplored and challenging task of Weakly Supervised Few-Shot Object Detection (WS-FSOD), where it attains significant improvements over the baselines. In addition, StarNet shows significant gains on few-shot classification benchmarks that are less cropped around the objects (where object localization is key)",
    "checked": true,
    "id": "3e71a292d79a2d9033e25453197512aa5621fed6",
    "semantic_title": "starnet: towards weakly supervised few-shot object detection",
    "citation_count": 11,
    "authors": [
      "Leonid Karlinsky",
      "Joseph Shtok",
      "Amit Alfassy",
      "Moshe Lichtenstein",
      "Sivan Harary",
      "Eli Schwartz",
      "Sivan Doveh",
      "Prasanna Sattigeri",
      "Rogerio Feris",
      "Alex Bronstein",
      "Raja Giryes"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16269": {
    "title": "Discriminative Region Suppression for Weakly-Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "Weakly-supervised semantic segmentation (WSSS) using image-level labels has recently attracted much attention for reducing annotation costs. Existing WSSS methods utilize localization maps from the classification network to generate pseudo segmentation labels. However, since localization maps obtained from the classifier focus only on sparse discriminative object regions, it is difficult to generate high-quality segmentation labels. To address this issue, we introduce discriminative region suppression (DRS) module that is a simple yet effective method to expand object activation regions. DRS suppresses the attention on discriminative regions and spreads it to adjacent non-discriminative regions, generating dense localization maps. DRS requires few or no additional parameters and can be plugged into any network. Furthermore, we introduce an additional learning strategy to give a self-enhancement of localization maps, named localization map refinement learning. Benefiting from this refinement learning, localization maps are refined and enhanced by recovering some missing parts or removing noise itself. Due to its simplicity and effectiveness, our approach achieves mIoU 71.4% on the PASCAL VOC 2012 segmentation benchmark using only image-level labels. Extensive experiments demonstrate the effectiveness of our approach",
    "checked": true,
    "id": "8cb57f85d52f956f7ed820b0eea925110d5ed3d8",
    "semantic_title": "discriminative region suppression for weakly-supervised semantic segmentation",
    "citation_count": 70,
    "authors": [
      "Beomyoung Kim",
      "Sangeun Han",
      "Junmo Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16270": {
    "title": "Visual Comfort Aware-Reinforcement Learning for Depth Adjustment of Stereoscopic 3D Images",
    "volume": "main",
    "abstract": "Depth adjustment aims to enhance the visual experience of stereoscopic 3D (S3D) images, which accompanied with improving visual comfort and depth perception. For a human expert, the depth adjustment procedure is a sequence of iterative decision making. The human expert iteratively adjusted the depth until he is satisfied with the both levels of visual comfort and the perceived depth. In this work, we present a novel deep reinforcement learning (DRL)-based approach for depth adjustment named VCA-RL (Visual Comfort Aware Reinforcement Learning) to explicitly model human sequential decision making in depth editing operations. We formulate the depth adjustment process as a Markov decision process where actions are defined as camera movement operations to control the distance between the left and right cameras. Our agent is trained based on the guidance of an objective visual comfort assessment metric to learn the optimal sequence of camera movement actions in terms of perceptual aspects in stereoscopic viewing. With extensive experiments and user studies, we show the effectiveness of our VCA-RL model on three different S3D databases",
    "checked": true,
    "id": "959c45ad2f1a24befb0013b7003417a5faf83392",
    "semantic_title": "visual comfort aware-reinforcement learning for depth adjustment of stereoscopic 3d images",
    "citation_count": 4,
    "authors": [
      "Hak Gu Kim",
      "Minho Park",
      "Sangmin Lee",
      "Seongyeop Kim",
      "Yong Man Ro"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16271": {
    "title": "Dual Compositional Learning in Interactive Image Retrieval",
    "volume": "main",
    "abstract": "We present an approach named Dual Composition Network (DCNet) for interactive image retrieval that searches for the best target image for a natural language query and a reference image. To accomplish this task, existing methods have focused on learning a composite representation of the reference image and the text query to be as close to the embedding of the target image as possible. We refer this approach as Composition Network. In this work, we propose to close the loop with Correction Network that models the difference between the reference and target image in the embedding space and matches it with the embedding of the text query. That is, we consider two cyclic directional mappings for triplets of (reference image, text query, target image) by using both Composition Network and Correction Network. We also propose a joint training loss that can further improve the robustness of multimodal representation learning. We evaluate the proposed model on three benchmark datasets for multimodal retrieval: Fashion-IQ, Shoes, and Fashion200K. Our experiments show that our DCNet achieves new state-of-the-art performance on all three datasets, and the addition of Correction Network consistently improves multiple existing methods that are solely based on Composition Network. Moreover, an ensemble of our model won the first place in Fashion-IQ 2020 challenge held in a CVPR 2020 workshop",
    "checked": true,
    "id": "6361a6f8fc2e025907fd1f6a7c9f7171fa2a10aa",
    "semantic_title": "dual compositional learning in interactive image retrieval",
    "citation_count": 40,
    "authors": [
      "Jongseok Kim",
      "Youngjae Yu",
      "Hoeseong Kim",
      "Gunhee Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16272": {
    "title": "End-to-End Differentiable Learning to HDR Image Synthesis for Multi-exposure Images",
    "volume": "main",
    "abstract": "Recently, high dynamic range (HDR) image reconstruction based on the multiple exposure stack from a given single exposure utilizes a deep learning framework to generate high-quality HDR images. These conventional networks focus on the exposure transfer task to reconstruct the multi-exposure stack. Therefore, they often fail to fuse the multi-exposure stack into a perceptually pleasant HDR image as the inversion artifacts occur. We tackle the problem in stack reconstruction-based methods by proposing a novel framework with a fully differentiable high dynamic range imaging (HDRI) process. By explicitly using the loss, which compares the network's output with the ground truth HDR image, our framework enables a neural network that generates the multiple exposure stack for HDRI to train stably. In other words, our differentiable HDR synthesis layer helps the deep neural network to train to create multi-exposure stacks while reflecting the precise correlations between multi-exposure images in the HDRI process. In addition, our network uses the image decomposition and the recursive process to facilitate the exposure transfer task and to adaptively respond to recursion frequency. The experimental results show that the proposed network outperforms the state-of-the-art quantitative and qualitative results in terms of both the exposure transfer tasks and the whole HDRI process",
    "checked": true,
    "id": "70216e8cd6312bfcae3f3639308acf520bcf1492",
    "semantic_title": "end-to-end differentiable learning to hdr image synthesis for multi-exposure images",
    "citation_count": 15,
    "authors": [
      "Junghee Kim",
      "Siyeong Lee",
      "Suk-Ju Kang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16273": {
    "title": "Structured Co-reference Graph Attention for Video-grounded Dialogue",
    "volume": "main",
    "abstract": "A video-grounded dialogue system referred to as the Structured Co-reference Graph Attention (SCGA) is presented for decoding the answer sequence to a question regarding a given video while keeping track of the dialogue context. Although recent efforts have made great strides in improving the quality of the response, performance is still far from satisfactory. The two main challenging issues are as follows: (1) how to deduce co-reference among multiple modalities and (2) how to reason on the rich underlying semantic structure of video with complex spatial and temporal dynamics. To this end, SCGA is based on (1) Structured Co-reference Resolver that performs dereferencing via building a structured graph over multiple modalities, (2) Spatio-temporal Video Reasoner that captures local-to-global dynamics of video via gradually neighboring graph attention. SCGA makes use of pointer network to dynamically replicate parts of the question for decoding the answer sequence. The validity of the proposed SCGA is demonstrated on AVSD@DSTC7 and AVSD@DSTC8 datasets, a challenging video-grounded dialogue benchmarks, and TVQA dataset, a large-scale videoQA benchmark. Our empirical results show that SCGA outperforms other state-of-the-art dialogue systems on both benchmarks, while extensive ablation study and qualitative analysis reveal performance gain and improved interpretability",
    "checked": true,
    "id": "6c20360aa184c3453be59c13e677873509b96669",
    "semantic_title": "structured co-reference graph attention for video-grounded dialogue",
    "citation_count": 13,
    "authors": [
      "Junyeong Kim",
      "Sunjae Yoon",
      "Dahyun Kim",
      "Chang D. Yoo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16274": {
    "title": "Cross-Domain Grouping and Alignment for Domain Adaptive Semantic Segmentation",
    "volume": "main",
    "abstract": "Existing techniques to adapt semantic segmentation networks across source and target domains within deep convolutional neural networks (CNNs) deal with all the samples from the two domains in a global or category-aware manner. They do not consider an inter-class variation within the target domain itself or estimated category, providing the limitation to encode the domains having a multi-modal data distribution. To overcome this limitation, we introduce a learnable clustering module, and a novel domain adaptation framework, called cross-domain grouping and alignment. To cluster the samples across domains with an aim to maximize the domain alignment without forgetting precise segmentation ability on the source domain, we present two loss functions, in particular, for encouraging semantic consistency and orthogonality among the clusters. We also present a loss so as to solve a class imbalance problem, which is the other limitation of the previous methods. Our experiments show that our method consistently boosts the adaptation performance in semantic segmentation, outperforming the state-of-the-arts on various domain adaptation settings",
    "checked": true,
    "id": "b636fb60037af31a1a67e9353e13332771515425",
    "semantic_title": "cross-domain grouping and alignment for domain adaptive semantic segmentation",
    "citation_count": 13,
    "authors": [
      "Minsu Kim",
      "Sunghun Joung",
      "Seungryong Kim",
      "JungIn Park",
      "Ig-Jae Kim",
      "Kwanghoon Sohn"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16275": {
    "title": "Bidirectional RNN-based Few Shot Learning for 3D Medical Image Segmentation",
    "volume": "main",
    "abstract": "Segmentation of organs of interest in 3D medical images is necessary for accurate diagnosis and longitudinal studies. Though recent advances using deep learning have shown success for many segmentation tasks, large datasets are required for high performance and the annotation process is both time consuming and labor intensive. In this paper, we propose a 3D few shot segmentation framework for accurate organ segmentation using limited training samples of the target organ annotation. To achieve this, a U-Net like network is designed to predict segmentation by learning the relationship between 2D slices of support data and a query image, including a bidirectional gated recurrent unit (GRU) that learns consistency of encoded features between adjacent slices. Also, we introduce a transfer learning method to adapt the characteristics of the target image and organ by updating the model before testing with arbitrary support and query data sampled from the support data. We evaluate our proposed model using three 3D CT datasets with annotations of different organs. Our model yielded significantly improved performance over state-of-the-art few shot segmentation models and was comparable to a fully supervised model trained with more target training data",
    "checked": true,
    "id": "149018b4faf1aa1f3250b6821a51cc1a9c2c7a53",
    "semantic_title": "bidirectional rnn-based few shot learning for 3d medical image segmentation",
    "citation_count": 18,
    "authors": [
      "Soopil Kim",
      "Sion An",
      "Philip Chikontwe",
      "Sang Hyun Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16276": {
    "title": "DASZL: Dynamic Action Signatures for Zero-shot Learning",
    "volume": "main",
    "abstract": "There are many realistic applications of activity recognition where the set of potential activity descriptions is combinatorially large. This makes end-to-end supervised training of a recognition system impractical as no training set is practically able to encompass the entire label set. In this paper, we present an approach to fine-grained recognition that models activities as compositions of dynamic action signatures. This compositional approach allows us to reframe fine-grained recognition as zero-shot activity recognition, where a detector is composed \"on the fly\" from simple first-principles state machines supported by deep-learned components. We evaluate our method on the Olympic Sports and UCF101 datasets, where our model establishes a new state of the art under multiple experimental paradigms. We also extend this method to form a unique framework for zero-shot joint segmentation and classification of activities in video and demonstrate the first results in zero- shot decoding of complex action sequences on a widely-used surgical dataset. Lastly, we show that we can use off-the-shelf object detectors to recognize activities in completely de-novo settings with no additional training",
    "checked": true,
    "id": "707b023e6c25ed283f23625bec514da480fb90da",
    "semantic_title": "daszl: dynamic action signatures for zero-shot learning",
    "citation_count": 18,
    "authors": [
      "Tae Soo Kim",
      "Jonathan Jones",
      "Michael Peven",
      "Zihao Xiao",
      "Jin Bai",
      "Yi Zhang",
      "Weichao Qiu",
      "Alan Yuille",
      "Gregory D. Hager"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16277": {
    "title": "Multi-level Distance Regularization for Deep Metric Learning",
    "volume": "main",
    "abstract": "We propose a novel distance-based regularization method for deep metric learning called Multi-level Distance Regularization (MDR). MDR explicitly disturbs a learning procedure by regularizing pairwise distances between embedding vectors into multiple levels that represents a degree of similarity between a pair. In the training stage, the model is trained with both MDR and an existing loss function of deep metric learning, simultaneously; the two losses interfere with the objective of each other, and it makes the learning process difficult. Moreover, MDR prevents some examples from being ignored or overly influenced in the learning process. These allow the parameters of the embedding network to be settle on a local optima with better generalization. Without bells and whistles, MDR with simple Triplet loss achieves the-state-of-the-art performance in various benchmark datasets: CUB-200-2011, Cars-196, Stanford Online Products, and In-Shop Clothes Retrieval. We extensively perform ablation studies on its behaviors to show the effectiveness of MDR. By easily adopting our MDR, the previous approaches can be improved in performance and generalization ability",
    "checked": true,
    "id": "a9d5fd03086cad1196277b1c2507a234db536aba",
    "semantic_title": "multi-level distance regularization for deep metric learning",
    "citation_count": 12,
    "authors": [
      "Yonghyun Kim",
      "Wonpyo Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16278": {
    "title": "Dynamic to Static Lidar Scan Reconstruction Using Adversarially Trained Auto Encoder",
    "volume": "main",
    "abstract": "Accurate reconstruction of static environments from LiDAR scans of scenes containing dynamic objects, which we refer to as Dynamic to Static Translation (DST), is an important area of research in Autonomous Navigation. This problem has been recently explored for visual SLAM, but to the best of our knowledge no work has been attempted to address DST for LiDAR scans. The problem is of critical importance due to wide-spread adoption of LiDAR in Autonomous Vehicles. We show that state-of the art methods developed for the visual domain when adapted for LiDAR scans perform poorly. We develop DSLR, a deep generative model which learns a mapping between dynamic scan to its static counterpart through an adversarially trained autoencoder. Our model yields the first solution for DST on LiDAR that generates static scans without using explicit segmentation labels. DSLR cannot always be applied to real world data due to lack of paired dynamic-static scans. Using Unsupervised Domain Adaptation, we propose DSLR-UDA for transfer to real world data and experimentally show that this performs well in real world settings. Additionally, if segmentation information is available, we extend DSLR to DSLR-Seg to further improve the reconstruction quality. DSLR gives the state of the art performance on simulated and real-world datasets and also shows at least 4√ó improvement. We show that DSLR, unlike the existing baselines, is a practically viable model with its reconstruction quality within the tolerable limits for tasks pertaining to autonomous navigation like SLAM in dynamic environments",
    "checked": false,
    "id": "9105a4d5af54cbea8ff49849abdaffd8917dbdd0",
    "semantic_title": "dslr: dynamic to static lidar scan reconstruction using adversarially trained autoencoder",
    "citation_count": 2,
    "authors": [
      "Prashant Kumar",
      "Sabyasachi Sahoo",
      "Vanshil Shah",
      "Vineetha Kondameedi",
      "Abhinav Jain",
      "Akshaj Verma",
      "Chiranjib Bhattacharyya",
      "Vinay Vishwanath"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16279": {
    "title": "Regularizing Attention Networks for Anomaly Detection in Visual Question Answering",
    "volume": "main",
    "abstract": "For stability and reliability of real-world applications, the robustness of DNNs in unimodal tasks has been evaluated. However, few studies consider abnormal situations that a visual question answering (VQA) model might encounter at test time after deployment in the real-world. In this study, we evaluate the robustness of state-of-the-art VQA models to five different anomalies, including worst-case scenarios, the most frequent scenarios, and the current limitation of VQA models. Different from the results in unimodal tasks, the maximum confidence of answers in VQA models cannot detect anomalous inputs, and post-training of the outputs, such as outlier exposure, is ineffective for VQA models. Thus, we propose an attention-based method, which uses confidence of reasoning between input images and questions and shows much more promising results than the previous methods in unimodal tasks. In addition, we show that a maximum entropy regularization of attention networks can significantly improve the attention-based anomaly detection of the VQA models. Thanks to the simplicity, attention-based anomaly detection and the regularization are model-agnostic methods, which can be used for various cross-modal attentions in the state-of-the-art VQA models. The results imply that cross-modal attention in VQA is important to improve not only VQA accuracy, but also the robustness to various anomalies",
    "checked": true,
    "id": "21f7833c38db29012e082b4ce20bdaa1f9c0e59f",
    "semantic_title": "regularizing attention networks for anomaly detection in visual question answering",
    "citation_count": 9,
    "authors": [
      "Doyup Lee",
      "Yeongjae Cheon",
      "Wook-Shin Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16280": {
    "title": "Weakly-supervised Temporal Action Localization by Uncertainty Modeling",
    "volume": "main",
    "abstract": "Weakly-supervised temporal action localization aims to learn detecting temporal intervals of action classes with only video-level labels. To this end, it is crucial to separate frames of action classes from the background frames (i.e., frames not belonging to any action classes). In this paper, we present a new perspective on background frames where they are modeled as out-of-distribution samples regarding their inconsistency. Then, background frames can be detected by estimating the probability of each frame being out-of-distribution, known as uncertainty, but it is infeasible to directly learn uncertainty without frame-level labels. To realize the uncertainty learning in the weakly-supervised setting, we leverage the multiple instance learning formulation. Moreover, we further introduce a background entropy loss to better discriminate background frames by encouraging their in-distribution (action) probabilities to be uniformly distributed over all action classes. Experimental results show that our uncertainty modeling is effective at alleviating the interference of background frames and brings a large performance gain without bells and whistles. We demonstrate that our model significantly outperforms state-of-the-art methods on the benchmarks, THUMOS'14 and ActivityNet (1.2 & 1.3). Our code is available at https://github.com/Pilhyeon/WTAL-Uncertainty-Modeling",
    "checked": true,
    "id": "73377c17f413d712a96210fe875987b57a2965d1",
    "semantic_title": "weakly-supervised temporal action localization by uncertainty modeling",
    "citation_count": 76,
    "authors": [
      "Pilhyeon Lee",
      "Jinglu Wang",
      "Yan Lu",
      "Hyeran Byun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16281": {
    "title": "Learning Monocular Depth in Dynamic Scenes via Instance-Aware Projection Consistency",
    "volume": "main",
    "abstract": "We present an end-to-end joint training framework that explicitly models 6-DoF motion of multiple dynamic objects, ego-motion, and depth in a monocular camera setup without supervision. Our technical contributions are three-fold. First, we highlight the fundamental difference between inverse and forward projection while modeling the individual motion of each rigid object, and propose a geometrically correct projection pipeline using a neural forward projection module. Second, we design a unified instance-aware photometric and geometric consistency loss that holistically imposes self-supervisory signals for every background and object region. Lastly, we introduce a general-purpose auto-annotation scheme using any off-the-shelf instance segmentation and optical flow models to produce video instance segmentation maps that will be utilized as input to our training pipeline. These proposed elements are validated in a detailed ablation study. Through extensive experiments conducted on the KITTI and Cityscapes dataset, our framework is shown to outperform the state-of-the-art depth and motion estimation methods. Our code, dataset, and models are publicly available",
    "checked": true,
    "id": "c7132e0a96b018bc5a8e769feca5286f053621c1",
    "semantic_title": "learning monocular depth in dynamic scenes via instance-aware projection consistency",
    "citation_count": 43,
    "authors": [
      "Seokju Lee",
      "Sunghoon Im",
      "Stephen Lin",
      "In So Kweon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16282": {
    "title": "Patch-Wise Attention Network for Monocular Depth Estimation",
    "volume": "main",
    "abstract": "In computer vision, monocular depth estimation is the problem of obtaining a high-quality depth map from a two-dimensional image. This map provides information on three-dimensional scene geometry, which is necessary for various applications in academia and industry, such as robotics and autonomous driving. Recent studies based on convolutional neural networks achieved impressive results for this task. However, most previous studies did not consider the relationships between the neighboring pixels in a local area of the scene. To overcome the drawbacks of existing methods, we propose a patch-wise attention method for focusing on each local area. After extracting patches from an input feature map, our module generates attention maps for each local patch, using two attention modules for each patch along the channel and spatial dimensions. Subsequently, the attention maps return to their initial positions and merge into one attention feature. Our method is straightforward but effective. The experimental results on two challenging datasets, KITTI and NYU Depth V2, demonstrate that the proposed method achieves significant performance. Furthermore, our method outperforms other state-of-the-art methods on the KITTI depth estimation benchmark",
    "checked": true,
    "id": "21fde3a3fab044a9b3568c71480764ad93ed1ff1",
    "semantic_title": "patch-wise attention network for monocular depth estimation",
    "citation_count": 40,
    "authors": [
      "Sihaeng Lee",
      "Janghyeon Lee",
      "Byungju Kim",
      "Eojindl Yi",
      "Junmo Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16283": {
    "title": "Semi-Supervised Learning for Multi-Task Scene Understanding by Neural Graph Consensus",
    "volume": "main",
    "abstract": "We address the challenging problem of semi-supervised learning in the context of multiple visual interpretations of the world by finding consensus in a graph of neural networks. Each graph node is a scene interpretation layer, while each edge is a deep net that transforms one layer at one node into another from a different node. During the supervised phase edge networks are trained independently. During the next unsupervised stage edge nets are trained on the pseudo-ground truth provided by consensus among multiple paths that reach the nets' start and end nodes. These paths act as ensemble teachers for any given edge and strong consensus is used for high-confidence supervisory signal. The unsupervised learning process is repeated over several generations, in which each edge becomes a \"student\" and also part of different ensemble \"teachers\" for training other students. By optimizing such consensus between different paths, the graph reaches consistency and robustness over multiple interpretations and generations, in the face of unknown labels. We give theoretical justifications of the proposed idea and validate it on a large dataset. We show how prediction of different representations such as depth, semantic segmentation, surface normals and pose from RGB input could be effectively learned through self-supervised consensus in our graph. We also compare to state-of-the-art methods for multi-task and semi-supervised learning and show superior performance",
    "checked": true,
    "id": "7137189bb80146154b86079c6b4f389d28724983",
    "semantic_title": "semi-supervised learning for multi-task scene understanding by neural graph consensus",
    "citation_count": 8,
    "authors": [
      "Marius Leordeanu",
      "Mihai Cristian P√Ærvu",
      "Dragos Costea",
      "Alina E Marcu",
      "Emil Slusanschi",
      "Rahul Sukthankar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16284": {
    "title": "Static-Dynamic Interaction Networks for Offline Signature Verification",
    "volume": "main",
    "abstract": "Offline signature verification is a challenging issue that is widely used in various fields. Previous approaches model this task as a static feature matching or distance metric problem of two images. In this paper, we propose a novel Static-Dynamic Interaction Network (SDINet) model which introduces sequential representation into static signature images. A static signature image is converted to sequences by assuming pseudo dynamic processes in the static image. A static representation extracting deep features from signature images describes the global information of signatures. A dynamic representation extracting sequential features with LSTM networks characterizes the local information of signatures. A dynamic-to-static attention is learned from the sequences to refine the static features. Through the static-to-dynamic conversion and the dynamic-to-static attention, the static representation and dynamic representation are unified into a compact framework. The proposed method was evaluated on four popular datasets of different languages. The extensive experimental results manifest the strength of our model",
    "checked": true,
    "id": "d0818aaf90c71c7306b1b7c35cf8521b4dd5c215",
    "semantic_title": "static-dynamic interaction networks for offline signature verification",
    "citation_count": 6,
    "authors": [
      "Huan Li",
      "Ping Wei",
      "Ping Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16285": {
    "title": "Proposal-Free Video Grounding with Contextual Pyramid Network",
    "volume": "main",
    "abstract": "The challenge of video grounding - localizing activities in an untrimmed video via a natural language query - is to tackle the semantics of vision and language consistently along the temporal dimension. Most existing proposal-based methods are trapped by computational cost with extensive candidate proposals. In this paper, we propose a novel proposal-free framework named Contextual Pyramid Network (CPNet) to investigate multi-scale temporal correlation in the video. Specifically, we propose a pyramid network to extract 2D contextual correlation maps at different temporal scales (T*T, T/2*T/2, T/4*T/4), where the 2D correlation map (past to current & future to current) is designed to model all the relations of any two moments in the video. In other words, CPNet progressively replenishes the temporal contexts and refines the location of queried activity by enlarging the temporal receptive fields. Finally, we implement a temporal self-attentive regression (i.e., proposal-free regression) to predict the activity boundary from the above hierarchical context-aware 2D correlation maps. Extensive experiments on ActivityNet Captions, Charades-STA, and TACoS datasets demonstrate that our approach outperforms state-of-the-art methods",
    "checked": true,
    "id": "7cb2a218f37c8fcfa91915cfdbba8ed22ef52d12",
    "semantic_title": "proposal-free video grounding with contextual pyramid network",
    "citation_count": 51,
    "authors": [
      "Kun Li",
      "Dan Guo",
      "Meng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16286": {
    "title": "Write-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation",
    "volume": "main",
    "abstract": "In this paper, we propose a novel text-based talking-head video generation framework that synthesizes high-fidelity facial expressions and head motions in accordance with contextual sentiments as well as speech rhythm and pauses. To be specific, our framework consists of a speaker-independent stage and a speaker-specific stage. In the speaker-independent stage, we design three parallel networks to generate animation parameters of the mouth, upper face, and head from texts, separately. In the speaker-specific stage, we present a 3D face model guided attention network to synthesize videos tailored for different individuals. It takes the animation parameters as input and exploits an attention mask to manipulate facial expression changes for the input individuals. Furthermore, to better establish authentic correspondences between visual motions (i.e., facial expression changes and head movements) and audios, we leverage a high-accuracy motion capture dataset instead of relying on long videos of specific individuals. After attaining the visual and audio correspondences, we can effectively train our network in an end-to-end fashion. Extensive experiments on qualitative and quantitative results demonstrate that our algorithm achieves high-quality photo-realistic talking-head videos including various facial expressions and head motions according to speech rhythms and outperforms the state-of-the-art",
    "checked": true,
    "id": "0d2d605d9c35ecb90c8cab3cad444e6f74f7ce27",
    "semantic_title": "write-a-speaker: text-based emotional and rhythmic talking-head generation",
    "citation_count": 40,
    "authors": [
      "Lincheng Li",
      "Suzhen Wang",
      "Zhimeng Zhang",
      "Yu Ding",
      "Yixing Zheng",
      "Xin Yu",
      "Changjie Fan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16287": {
    "title": "Exploiting Learnable Joint Groups for Hand Pose Estimation",
    "volume": "main",
    "abstract": "In this paper, we propose to estimate 3D hand pose by recovering the 3D coordinates of joints in a group-wise manner, where less-related joints are automatically categorized into different groups and exhibit different features. This is different from the previous methods where all the joints are considered holistically and share the same feature. The benefits of our method are illustrated by the principle of multi-task learning (MTL), i.e., by separating less-related joints into different groups (as different tasks), our method learns different features for each of them, therefore efficiently avoids the negative transfer (among less related tasks/groups of joints). The key of our method is a novel binary selector that automatically selects related joints into the same group. We implement such a selector with binary values stochastically sampled from a Concretedistribution, which is constructed using Gumbel softmax on trainable parameters. This enables us to preserve the differentiable property of the whole network. We further exploit features from those less-related groups by carrying out an additional feature fusing scheme among them, to learn more discriminative features. This is realized by implementing multiple 1x1 convolutions on the concatenated features, where each joint group contains a unique 1x1convolution for feature fusion. The detailed ablation analysis and the extensive experiments on several benchmark datasets demonstrate the promising performance of the proposed method over the state-of-the-art (SOTA) methods. Besides, our method achieves top-1 among all the methods that do not exploit the dense 3D shape labels on the most recently released FreiHAND competition at the submission date. The source code and models are available at https://github.com/moranli-aca/LearnableGroups-Hand",
    "checked": true,
    "id": "d2273109e1d58488092651f060acd1b52a7ba431",
    "semantic_title": "exploiting learnable joint groups for hand pose estimation",
    "citation_count": 23,
    "authors": [
      "Moran Li",
      "Yuan Gao",
      "Nong Sang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16288": {
    "title": "RTS3D: Real-time Stereo 3D Detection from 4D Feature-Consistency Embedding Space for Autonomous Driving",
    "volume": "main",
    "abstract": "Although the recent image-based 3D object detection methods using Pseudo-LiDAR representation have shown great capabilities, a notable gap in efficiency and accuracy still exist compared with LiDAR-based methods. Besides, over-reliance on the stand-alone depth estimator, requiring a large number of pixel-wise annotations in the training stage and more computation in the inferencing stage, limits the scaling application in the real world. In this paper, we propose an efficient and accurate 3D object detection method from stereo images, named RTS3D. Different from the 3D occupancy space in the Pseudo-LiDAR similar methods, we design a novel 4D feature-consistent embedding (FCE) space as the intermediate representation of the 3D scene without depth supervision. The FCE space encodes the object's structural and semantic information by exploring the multi-scale feature consistency warped from stereo pair. Furthermore, a semantic-guided RBF (Radial Basis Function) and a structure-aware attention module are devised to reduce the influence of FCE space noise without instance mask supervision. Experiments on KITTI benchmark show that RTS3D is the first true real-time system (FPS>24) for stereo image 3D detection meanwhile achieves 10% improvement in average precision comparing with the previous state-of-the-art method",
    "checked": true,
    "id": "35cffc5bc9f26f0760fdf268151b48d21ab2ae78",
    "semantic_title": "rts3d: real-time stereo 3d detection from 4d feature-consistency embedding space for autonomous driving",
    "citation_count": 22,
    "authors": [
      "Peixuan Li",
      "Shun Su",
      "Huaici Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16289": {
    "title": "Adversarial Pose Regression Network for Pose-Invariant Face Recognitions",
    "volume": "main",
    "abstract": "Face recognition has achieved significant progress in recent years. However, the large pose variation between face images remains a challenge in face recognition. We observe that the pose variation in the hidden feature maps is one of the most critical factors to hinder the representations from being pose-invariant. Based on the observation, we propose an Adversarial Pose Regression Network (APRN) to extract pose-invariant identity representations by disentangling their pose variation in hidden feature maps. To model the pose discriminator in APRN as a regression task in its 3D space, we also propose an Adversarial Regression Loss Function and extend the adversarial learning from classification problems to regression problems in this paper. Our APRN is a plug-and-play structure that can be embedded in other state-of-the-art face recognition algorithms to improve their performance additionally. The experiments show that the proposed APRN consistently and significantly boosts the performance of baseline networks without extra computational costs in the inference phase. APRN achieves comparable or even superior to the state-of-the-art on CFP, Multi-PIE, IJB-A and MegaFace datasets. The code will be released, hoping to nourish our proposals to other computer vision fields",
    "checked": true,
    "id": "7cd304afc74f6b8d7b1bf4eac57b395426fbe1d2",
    "semantic_title": "adversarial pose regression network for pose-invariant face recognitions",
    "citation_count": 2,
    "authors": [
      "Pengyu Li",
      "Biao Wang",
      "Lei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16290": {
    "title": "Category Dictionary Guided Unsupervised Domain Adaptation for Object Detection",
    "volume": "main",
    "abstract": "Unsupervised domain adaption (UDA) is a promising solution to enhance the generalization ability of a model from a source domain to a target domain without manually annotating labels for target data. Recent works in cross-domain object detection mostly resort to adversarial feature adaptation to match the marginal distributions of two domains. However, perfect feature alignment is hard to achieve and is likely to cause negative transfer due to the high complexity of object detection. In this paper, we propose a category dictionary guided (CDG) UDA model for cross-domain object detection, which learns category-specific dictionaries from the source domain to represent the candidate boxes in target domain. The representation residual can be used for not only pseudo label assignment but also quality (e.g., IoU) estimation of the candidate box. A residual weighted self-training paradigm is then developed to implicitly align source and target domains for detection model training. Compared with decision boundary based classifiers such as softmax, the proposed CDG scheme can select more informative and reliable pseudo-boxes. Experimental results on benchmark datasets show that the proposed CDG significantly exceeds the state-of-the-arts in cross-domain object detection",
    "checked": true,
    "id": "5e412cedaa116ed4d1965dc4815ca56969be1be7",
    "semantic_title": "category dictionary guided unsupervised domain adaptation for object detection",
    "citation_count": 29,
    "authors": [
      "Shuai Li",
      "Jianqiang Huang",
      "Xian-Sheng Hua",
      "Lei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16291": {
    "title": "Joint Semantic-geometric Learning for Polygonal Building Segmentation",
    "volume": "main",
    "abstract": "Building extraction from aerial or satellite images has been an important research issue in remote sensing and computer vision domains for decades. Compared with pixel-wise semantic segmentation models that output raster building segmentation map, polygonal building segmentation approaches produce more realistic building polygons that are in the desirable vector format for practical applications. Despite the substantial efforts over recent years, state-of-the-art polygonal building segmentation methods still suffer from several limitations, e.g., (1) relying on a perfect segmentation map to guarantee the vectorization quality; (2) requiring a complex post-processing procedure; (3) generating inaccurate vertices with a fixed quantity, a wrong sequential order, self-intersections, etc. To tackle the above issues, in this paper, we propose a polygonal building segmentation approach and make the following contributions: (1) We design a multi-task segmentation network for joint semantic and geometric learning via three tasks, i.e., pixel-wise building segmentation, multi-class corner prediction, and edge orientation prediction. (2) We propose a simple but effective vertex generation module for transforming the segmentation contour into high-quality polygon vertices. (3) We further propose a polygon refinement network that automatically moves the polygon vertices into more accurate locations. Results on two popular building segmentation datasets demonstrate that our approach achieves significant improvements for both building instance segmentation (with 2% F1-score gain) and polygon vertex prediction (with 6% F1-score gain) compared with current state-of-the-art methods",
    "checked": true,
    "id": "40759bee7b649ad871e2598fd12846b749680e01",
    "semantic_title": "joint semantic-geometric learning for polygonal building segmentation",
    "citation_count": 25,
    "authors": [
      "Weijia Li",
      "Wenqian Zhao",
      "Huaping Zhong",
      "Conghui He",
      "Dahua Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16292": {
    "title": "Generalized Zero-Shot Learning via Disentangled Representation",
    "volume": "main",
    "abstract": "Zero-Shot Learning (ZSL) aims to recognize images belonging to unseen classes that are unavailable in the training process, while Generalized Zero-Shot Learning (GZSL) is a more realistic variant that both seen and unseen classes appear during testing. Most GZSL approaches achieve knowledge transfer based on the features of samples that inevitably contain information irrelevant to recognition, bringing negative influence for the performance. In this work, we propose a novel method, dubbed Disentangled-VAE, which aims to disentangle category-distilling factors and category-dispersing factors from visual as well as semantic features, respectively. In addition, a batch re-combining strategy on latent features is introduced to guide the disentanglement, encouraging the distilling latent features to be more discriminative for recognition. Extensive experiments demonstrate that our method outperforms the state-of-the-art approaches on four challenging benchmark datasets",
    "checked": true,
    "id": "998a949aed017140074c50209dbd583205e99d7b",
    "semantic_title": "generalized zero-shot learning via disentangled representation",
    "citation_count": 42,
    "authors": [
      "Xiangyu Li",
      "Zhe Xu",
      "Kun Wei",
      "Cheng Deng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16293": {
    "title": "Learning Omni-Frequency Region-adaptive Representations for Real Image Super-Resolution",
    "volume": "main",
    "abstract": "Traditional single image super-resolution (SISR) methods that focus on solving single and uniform degradation (i.e., bicubic down-sampling), typically suffer from poor performance when applied into real-world low-resolution (LR) images due to the complicated realistic degradations. The key to solving this more challenging real image super-resolution (RealSR) problem lies in learning feature representations that are both informative and content-aware. In this paper, we propose a Omni-frequency Region-adaptive Network (OR-Net) to address both challenges, here we call features of all low, middle and high frequencies omni-frequency features. Specifically, we start from the frequency perspective and design a Frequency Decomposition (FD) module to separate different frequency components to comprehensively compensate the information lost for real LR image. Then, considering the different regions of real LR image have different frequency information lost, we further design a Region-adaptive Frequency Aggregation (RFA) module by leveraging dynamic convolution and spatial attention to adaptively restore frequency components for different regions. The extensive experiments endorse the high-efficient, effective, and scenario-agnostic nature of our OR-Net for RealSR",
    "checked": true,
    "id": "36fac56c02597f9ea7c9c05419fd7a7109de1056",
    "semantic_title": "learning omni-frequency region-adaptive representations for real image super-resolution",
    "citation_count": 15,
    "authors": [
      "Xin Li",
      "Xin Jin",
      "Tao Yu",
      "Simeng Sun",
      "Yingxue Pang",
      "Zhizheng Zhang",
      "Zhibo Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16294": {
    "title": "Group-Wise Semantic Mining for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "Acquiring sufficient ground-truth supervision to train deep vi- sual models has been a bottleneck over the years due to the data-hungry nature of deep learning. This is exacerbated in some structured prediction tasks, such as semantic segmen- tation, which requires pixel-level annotations. This work ad- dresses weakly supervised semantic segmentation (WSSS), with the goal of bridging the gap between image-level anno- tations and pixel-level segmentation. We formulate WSSS as a novel group-wise learning task that explicitly models se- mantic dependencies in a group of images to estimate more reliable pseudo ground-truths, which can be used for training more accurate segmentation models. In particular, we devise a graph neural network (GNN) for group-wise semantic min- ing, wherein input images are represented as graph nodes, and the underlying relations between a pair of images are char- acterized by an efficient co-attention mechanism. Moreover, in order to prevent the model from paying excessive atten- tion to common semantics only, we further propose a graph dropout layer, encouraging the model to learn more accurate and complete object responses. The whole network is end-to- end trainable by iterative message passing, which propagates interaction cues over the images to progressively improve the performance. We conduct experiments on the popular PAS- CAL VOC 2012 and COCO benchmarks, and our model yields state-of-the-art performance. Our code is available at: https://github.com/Lixy1997/Group-WSSS",
    "checked": true,
    "id": "811bd1dcacf2dcb3d615daa169a07e0c872fe5a7",
    "semantic_title": "group-wise semantic mining for weakly supervised semantic segmentation",
    "citation_count": 67,
    "authors": [
      "Xueyi Li",
      "Tianfei Zhou",
      "Jianwu Li",
      "Yi Zhou",
      "Zhaoxiang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16295": {
    "title": "Inference Fusion with Associative Semantics for Unseen Object Detection",
    "volume": "main",
    "abstract": "We study the problem of object detection when training and test objects are disjoint, i.e. no training examples of the target classes are available. Existing unseen object detection approaches usually combine generic detection frameworks with a single-path unseen classifier, by aligning object regions with semantic class embeddings. In this paper, inspired from human cognitive experience, we propose a simple but effective dual-path detection model that further explores associative semantics to supplement the basic visual-semantic knowledge transfer. We use a novel target-centric multiple-association strategy to establish concept associations, to ensure that the predictor generalized to unseen domain can be learned during training. In this way, through a reasonable inference fusion mechanism, those two parallel reasoning paths can strengthen the correlation between seen and unseen objects, thus improving detection performance. Experiments show that our inductive method can significantly boost the performance by 7.42% over inductive models, and even 5.25% over transductive models on MSCOCO dataset",
    "checked": true,
    "id": "99dc5800efc4d41666ef75f4c1eaf41f0097591f",
    "semantic_title": "inference fusion with associative semantics for unseen object detection",
    "citation_count": 6,
    "authors": [
      "Yanan Li",
      "Pengyang Li",
      "Han Cui",
      "Donghui Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16296": {
    "title": "Deep Unsupervised Image Hashing by Maximizing Bit Entropy",
    "volume": "main",
    "abstract": "Unsupervised hashing is important for indexing huge image or video collections without having expensive annotations available. Hashing aims to learn short binary codes for compact storage and efficient semantic retrieval. We propose an unsupervised deep hashing layer called Bi-Half Net that maximizes entropy of the binary codes. Entropy is maximal when both possible values of the bit are uniformly (half-half) distributed. To maximize bit entropy, we do not add a term to the loss function as this is difficult to optimize and tune. Instead, we design a new parameter-free network layer to explicitly force continuous image features to approximate the optimal half-half bit distribution. This layer is shown to minimize a penalized term of the Wasserstein distance between the learned continuous image features and the optimal half-half bit distribution. Experimental results on the image datasets FLICKR25K, NUS-WIDE, CIFAR-10, MS COCO, MNIST and the video datasets UCF-101 and HMDB-51 show that our approach leads to compact codes and compares favorably to the current state-of-the-art",
    "checked": true,
    "id": "48f33710063f1cdf74abe298245e4cd3834800c9",
    "semantic_title": "deep unsupervised image hashing by maximizing bit entropy",
    "citation_count": 36,
    "authors": [
      "Yunqiang Li",
      "Jan van Gemert"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16297": {
    "title": "Sequential End-to-end Network for Efficient Person Search",
    "volume": "main",
    "abstract": "Person search aims at jointly solving Person Detection and Person Re-identification (re-ID). Existing works have designed end-to-end networks based on Faster R-CNN. However, due to the parallel structure of Faster R-CNN, the extracted features come from the low-quality proposals generated by the Region Proposal Network, rather than the detected high-quality bounding boxes. Person search is a fine-grained task and such inferior features will significantly reduce re-ID performance. To address this issue, we propose a Sequential End-to-end Network (SeqNet) to extract superior features. In SeqNet, detection and re-ID are considered as a progressive process and tackled with two sub-networks sequentially. In addition, we design a robust Context Bipartite Graph Matching (CBGM) algorithm to effectively employ context information as an important complementary cue for person matching. Extensive experiments on two widely used person search benchmarks, CUHK-SYSU and PRW, have shown that our method achieves state-of-the-art results. Also, our model runs at 11.5 fps on a single GPU and can be integrated into the existing end-to-end framework easily",
    "checked": true,
    "id": "b4e86385285941ccba5ef0f9a15bfb5001b883f8",
    "semantic_title": "sequential end-to-end network for efficient person search",
    "citation_count": 46,
    "authors": [
      "Zhengjia Li",
      "Duoqian Miao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16298": {
    "title": "SD-Pose: Semantic Decomposition for Cross-Domain 6D Object Pose Estimation",
    "volume": "main",
    "abstract": "The current leading 6D object pose estimation methods rely heavily on annotated real data, which is highly costly to acquire. To overcome this, many works have proposed to introduce computer-generated synthetic data. However, bridging the gap between the synthetic and real data remains a severe problem. Images depicting different levels of realism/semantics usually have different transferability between the synthetic and real domains. Inspired by this observation, we introduce an approach, SD-Pose, that explicitly decomposes the input image into multi-level semantic representations and then combines the merits of each representation to bridge the domain gap. Our comprehensive analyses and experiments show that our semantic decomposition strategy can fully utilize the different domain similarities of different representations, thus allowing us to outperform the state of the art on modern 6D object pose datasets without accessing any real data during training",
    "checked": true,
    "id": "52387d585d5cd97963f460741fdfa719ff078dc2",
    "semantic_title": "sd-pose: semantic decomposition for cross-domain 6d object pose estimation",
    "citation_count": 4,
    "authors": [
      "Zhigang Li",
      "Yinlin Hu",
      "Mathieu Salzmann",
      "Xiangyang Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16299": {
    "title": "Temporal Pyramid Network for Pedestrian Trajectory Prediction with Multi-Supervision",
    "volume": "main",
    "abstract": "Predicting human motion behavior in a crowd is important for many applications, ranging from the natural navigation of autonomous vehicles to intelligent security systems of video surveillance. All the previous works model and predict the trajectory with a single resolution, which is relatively ineffective and difficult to simultaneously exploit the long-range information (e.g., the destination of the trajectory), and the short-range information (e.g., the walking direction and speed at a certain time) of the motion behavior. In this paper, we propose a temporal pyramid network for pedestrian trajectory prediction through a squeeze modulation and a dilation modulation. Our hierarchical framework builds a feature pyramid with increasingly richer temporal information from top to bottom, which can better capture the motion behavior at various tempos. Furthermore, we propose a coarse-to-fine fusion strategy with multi-supervision. By progressively merging the top coarse features of global context to the bottom fine features of rich local context, our method can fully exploit both the long-range and short-range information of the trajectory. Experimental results on two benchmarks demonstrate the superiority of our method. Our code and models will be available upon acceptance",
    "checked": true,
    "id": "6c240231b06495b8386db604b3db685dd467d502",
    "semantic_title": "temporal pyramid network for pedestrian trajectory prediction with multi-supervision",
    "citation_count": 16,
    "authors": [
      "Rongqin Liang",
      "Yuanman Li",
      "Xia Li",
      "Yi Tang",
      "Jiantao Zhou",
      "Wenbin Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16300": {
    "title": "Query-Memory Re-Aggregation for Weakly-supervised Video Object Segmentation",
    "volume": "main",
    "abstract": "Weakly-supervised video object segmentation (WVOS) is an emerging video task that can track and segment the target given a simple bounding box label. However, existing WVOS methods are still unsatisfied in either speed or accuracy, since they only use the exemplar frame to guide the prediction while they neglect the reference from other frames. To solve the problem, we propose a novel Re-Aggregation based framework, which uses feature matching to efficiently find the target and capture the temporal dependencies from multiple frames to guide the segmentation. Based on a two-stage structure, our framework builds an information-symmetric matching process to achieve robust aggregation. In each stage, we design a Query-Memory Aggregation (QMA) module to gather features from the past frames and make bidirectional aggregation to adaptively weight the aggregated features, which relieves the latent misguidance in unidirectional aggregation. To further exploit the information from different aggregation stages, we propose a novel coarse-fine constraint by using the Cascaded Refinement Module (CRM) to combine the predictions from different stages and further boosts the performance. Experimental results on three benchmarks show that our method achieves the state-of-the-art performance in WVOS (e.g., an overall score of 84.7% on the DAVIS 2016 validation set)",
    "checked": true,
    "id": "9a2687319ed3279f579ece9e49b019ef626b3dc3",
    "semantic_title": "query-memory re-aggregation for weakly-supervised video object segmentation",
    "citation_count": 13,
    "authors": [
      "Fanchao Lin",
      "Hongtao Xie",
      "Yan Li",
      "Yongdong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16301": {
    "title": "Augmented Partial Mutual Learning with Frame Masking for Video Captioning",
    "volume": "main",
    "abstract": "Recent video captioning work improves greatly due to the invention of various elaborate model architectures. If multiple captioning models are combined into a unified framework not only by simple more ensemble, and each model can benefit from each other, the final captioning might be boosted further. Jointly training of multiple model have not been explored in previous works. In this paper, we propose a novel Augmented Partial Mutual Learning (APML) training method where multiple decoders are trained jointly with mimicry losses between different decoders and different input variations. Another problem of training captioning model is the \"one-to-many\" mapping problem which means that one identical video input is mapped to multiple caption annotations. To address this problem, we propose an annotation-wise frame masking approach to convert the \"one-to-many\" mapping to \"one-to-one\" mapping. The experiments performed on MSR-VTT and MSVD datasets demonstrate our proposed algorithm achieves the state-of-the-art performance",
    "checked": true,
    "id": "108076978ed3990ee90cb7b30aa572ca0f9c2518",
    "semantic_title": "augmented partial mutual learning with frame masking for video captioning",
    "citation_count": 15,
    "authors": [
      "Ke Lin",
      "Zhuoxin Gan",
      "Liwei Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16302": {
    "title": "Exploiting Audio-Visual Consistency with Partial Supervision for Spatial Audio Generation",
    "volume": "main",
    "abstract": "Human perceives rich auditory experience with distinct sound heard by ears. Videos recorded with binaural audio particular simulate how human receives ambient sound. However, a large number of videos are with monaural audio only, which would degrade the user experience due to the lack of ambient information. To address this issue, we propose an audio spatialization framework to convert a monaural video into a binaural one exploiting the relationship across audio and visual components. By preserving the left-right consistency in both audio and visual modalities, our learning strategy can be viewed as a self-supervised learning technique, and alleviates the dependency on a large amount of video data with ground truth binaural audio data during training. Experiments on benchmark datasets confirm the effectiveness of our proposed framework in both semi-supervised and fully supervised scenarios, with ablation studies and visualization further support the use of our model for audio spatialization",
    "checked": true,
    "id": "0bcab67058596c6ca5dc5d691c9e1004457063e3",
    "semantic_title": "exploiting audio-visual consistency with partial supervision for spatial audio generation",
    "citation_count": 8,
    "authors": [
      "Yan-Bo Lin",
      "Yu-Chiang Frank Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16303": {
    "title": "Single View Point Cloud Generation via Unified 3D Prototype",
    "volume": "main",
    "abstract": "As 3D point clouds become the representation of choice for multiple vision and graphics applications, such as autonomous driving, robotics, etc., the generation of them by deep neural networks has attracted increasing attention in the research community. Despite the recent success of deep learning models in classification and segmentation, synthesizing point clouds remains challenging, especially from a single image. State-of-the-art (SOTA) approaches can generate a point cloud from a hidden vector, however, they treat 2D and 3D features equally and disregard the rich shape information within the 3D data. In this paper, we address this problem by integrating image features with 3D prototype features. Specifically, we propose to learn a set of 3D prototype features from a real point cloud dataset and dynamically adjust them through the training. These prototypes are then integrated with incoming image features to guide the point cloud generation process. Experimental results show that our proposed method outperforms SOTA methods on single image based 3D reconstruction tasks",
    "checked": true,
    "id": "6b5e2a64632fefab1260751561134112786ca366",
    "semantic_title": "single view point cloud generation via unified 3d prototype",
    "citation_count": 3,
    "authors": [
      "Yu Lin",
      "Yigong Wang",
      "Yi-Fan Li",
      "Zhuoyi Wang",
      "Yang Gao",
      "Latifur Khan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16304": {
    "title": "Self-Supervised Sketch-to-Image Synthesis",
    "volume": "main",
    "abstract": "Imagining a colored realistic image from an arbitrary-drawn sketch is one of human capabilities that we eager machines to mimic. Unlike previous methods that either require the sketch-image pairs or utilize low-quantity detected edges as sketches, we study the exemplar-based sketch-to-image (s2i) synthesis task in a self-supervised learning manner, eliminating the necessity of the paired sketch data. To this end, we first propose an unsupervised method to efficiently synthesize line-sketches for general RGB-only datasets. With the synthetic paired-data, we then present a self-supervised Auto-Encoder (AE) to decouple the content/style features from sketches and RGB-images, and synthesize images both content-faithful to the sketches and style-consistent to the RGB-images. While prior works employ either the cycle-consistence loss or dedicated attentional modules to enforce the content/style fidelity, we show AE's superior performance with pure self-supervisions. To further improve the synthesis quality in high resolution, we also leverage an adversarial network to refine the details of synthetic images. Extensive experiments on $1024^2$ resolution demonstrate a new state-of-art-art performance of the proposed model on CelebA-HQ and Wiki-Art datasets. Moreover, with the proposed sketch generator, the model shows a promising performance on style mixing and style transfer, which the synthesized images are not only style-consistent but also semantically meaningful",
    "checked": true,
    "id": "e5956dc1c3e93a37d80aeb908b8a7e76c2185856",
    "semantic_title": "self-supervised sketch-to-image synthesis",
    "citation_count": 23,
    "authors": [
      "Bingchen Liu",
      "Yizhe Zhu",
      "Kunpeng Song",
      "Ahmed Elgammal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16305": {
    "title": "TIME: Text and Image Mutual-Translation Adversarial Networks",
    "volume": "main",
    "abstract": "Focusing on text-to-image (T2I) generation, we propose Text and Image Mutual-Translation Adversarial Networks (TIME), a lightweight but effective model that jointly learns a T2I generator G and an image captioning discriminator D under the Generative Adversarial Network framework. While previous methods tackle the T2I problem as a uni-directional task and use pre-trained language models to enforce the image--text consistency, TIME requires neither extra modules nor pre-training. We show that the performance of G can be boosted substantially by training it jointly with D as a language model. Specifically, we adopt Transformers to model the cross-modal connections between the image features and word embeddings, and design an annealing conditional hinge loss that dynamically balances the adversarial learning. In our experiments, TIME achieves state-of-the-art (SOTA) performance on the CUB dataset (Inception Score of 4.91 and Fr√©chet Inception Distance of 14.3 on CUB), and shows promising performance on MS-COCO dataset on image captioning and downstream vision-language tasks",
    "checked": true,
    "id": "343178bf426aacc051a8ea547c4189579635ab09",
    "semantic_title": "time: text and image mutual-translation adversarial networks",
    "citation_count": 16,
    "authors": [
      "Bingchen Liu",
      "Kunpeng Song",
      "Yizhe Zhu",
      "Gerard de Melo",
      "Ahmed Elgammal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16306": {
    "title": "SA-BNN: State-Aware Binary Neural Network",
    "volume": "main",
    "abstract": "Binary Neural Networks (BNNs) have received significant attention due to the memory and computation efficiency recently. However, the considerable accuracy gap between BNNs and their full-precision counterparts hinders BNNs to be deployed to resource-constrained platforms. One of the main reasons for the performance gap can be attributed to the frequent weight flip, which is caused by the misleading weight update in BNNs. To address this issue, we propose a state-aware binary neural network (SA-BNN) equipped with the well designed state-aware gradient. Our SA-BNN is inspired by the observation that the frequent weight flip is more likely to occur, when the gradient magnitude for all quantization states {-1,1} is identical. Accordingly, we propose to employ independent gradient coefficients for different states when updating the weights. Furthermore, we also analyze the effectiveness of the state-aware gradient on suppressing the frequent weight flip problem. Experiments on ImageNet show that the proposed SA-BNN outperforms the current state-of-the-arts (e.g., Bi-Real Net) by more than 3% when using a ResNet architecture. Specifically, we achieve 61.7%, 65.5% and 68.7% Top-1 accuracy with ResNet-18, ResNet-34 and ResNet-50 on ImageNet, respectively",
    "checked": true,
    "id": "cbc644f26710b7b2cd96200878ca1c469daf1997",
    "semantic_title": "sa-bnn: state-aware binary neural network",
    "citation_count": 11,
    "authors": [
      "Chunlei Liu",
      "Peng Chen",
      "Bohan Zhuang",
      "Chunhua Shen",
      "Baochang Zhang",
      "Wenrui Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16307": {
    "title": "Spatiotemporal Graph Neural Network based Mask Reconstruction for Video Object Segmentation",
    "volume": "main",
    "abstract": "This paper addresses the task of segmenting class-agnostic objects in semi-supervised setting. Although previous detection based methods achieve relatively good performance, these approaches extract the best proposal by a greedy strategy, which may lose the local patch details outside the chosen candidate. In this paper, we propose a novel spatiotemporal graph neural network (STG-Net) to reconstruct more accurate masks for video object segmentation, which captures the local contexts by utilizing all proposals. In the spatial graph, we treat object proposals of a frame as nodes and represent their correlations with an edge weight strategy for mask context aggregation. To capture temporal information from previous frames, we use a memory network to refine the mask of current frame by retrieving historic masks in a temporal graph. The joint use of both local patch details and temporal relationships allow us to better address the challenges such as object occlusions and missing. Without online learning and fine-tuning, our STG-Net achieves state-of-the-art performance on four large benchmarks, demonstrating the effectiveness of the proposed approach",
    "checked": true,
    "id": "5ec6620a09b1f573fc5351d4d4fe2d5e07ef7f47",
    "semantic_title": "spatiotemporal graph neural network based mask reconstruction for video object segmentation",
    "citation_count": 13,
    "authors": [
      "Daizong Liu",
      "Shuangjie Xu",
      "Xiao-Yang Liu",
      "Zichuan Xu",
      "Wei Wei",
      "Pan Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16308": {
    "title": "F2Net: Learning to Focus on the Foreground for Unsupervised Video Object Segmentation",
    "volume": "main",
    "abstract": "Although deep learning based methods have achieved great progress in unsupervised video object segmentation, difficult scenarios (e.g., visual similarity, occlusions, and appearance changing) are still no well-handled. To alleviate these issues, we propose a novel Focus on Foreground Network (F2Net), which delves into the intra-inter frame details for the foreground objects and thus effectively improve the segmentation performance. Specifically, our proposed network consists of three main parts: Siamese Encoder Module, Center Guiding Appearance Diffusion Module, and Dynamic Information Fusion Module. Firstly, we take a siamese encoder to extract the feature representations of paired frames (reference frame and current frame). Then, a Center Guiding Appearance Diffusion Module is designed to capture the inter-frame feature (dense correspondences between reference frame and current frame), intra-frame feature (dense correspondences in current frame), and original semantic feature of current frame. Different from the Anchor Diffusion Network, we establish a Center Prediction Branch to predict the center location of the foreground object in current frame and leverage the center point information as spatial guidance prior to enhance the inter-frame and intra-frame feature extraction, and thus the feature representation considerably focus on the foreground objects. Finally, we propose a Dynamic Information Fusion Module to automatically select relatively important features through three aforementioned different level features. Extensive experiments on DAVIS, Youtube-object, and FBMS datasets show that our proposed F2Net achieves the state-of-the-art performance with significant improvement",
    "checked": true,
    "id": "69107a71c9533e204790890591a72fda88d4669a",
    "semantic_title": "f2net: learning to focus on the foreground for unsupervised video object segmentation",
    "citation_count": 23,
    "authors": [
      "Daizong Liu",
      "Dongdong Yu",
      "Changhu Wang",
      "Pan Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16309": {
    "title": "Toward Realistic Virtual Try-on Through Landmark Guided Shape Matching",
    "volume": "main",
    "abstract": "Image-based virtual try-on aims to synthesize the customer image with an in-shop clothes image to acquire seamless and natural try-on results, which have attracted increasing attentions. The main procedures of image-based virtual try-on usually consist of clothes image generation and try-on image synthesis, whereas prior arts cannot guarantee satisfying clothes results when facing large geometric changes and complex clothes patterns, which further deteriorates the afterwards try-on results. To address this issue, we propose a novel virtual try-on network based on landmark-guided shape matching (LM-VTON). Specifically, the clothes image generation progressively learns the warped clothes and refined clothes in an end-to-end manner, where we introduce a landmark-based constraint in Thin-Plate Spline (TPS) warping to inject finer deformation constraints around the clothes. The try-on process synthesizes the warped clothes with personal characteristics via a semantic indicator. Qualitative and quantitative experiments on two public datasets validate the superiority of the proposed method, especially for challenging cases such as large geometric changes and complex clothes patterns. Code will be available at https://github.com/lgqfhwy/LM-VTON",
    "checked": true,
    "id": "732d67e7b59aee6ce74fd54d0d1800b8afab32aa",
    "semantic_title": "toward realistic virtual try-on through landmark guided shape matching",
    "citation_count": 7,
    "authors": [
      "Guoqiang Liu",
      "Dan Song",
      "Ruofeng Tong",
      "Min Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16310": {
    "title": "Large Motion Video Super-Resolution with Dual Subnet and Multi-Stage Communicated Upsampling",
    "volume": "main",
    "abstract": "Video super-resolution (VSR) aims at restoring a video in low-resolution (LR) and improving it to higher-resolution (HR). Due to the characteristics of video tasks, it is very important that motion information among frames should be well concerned, summarized and utilized for guidance in a VSR algorithm. Especially, when a video contains large motion, conventional methods easily bring incoherent results or artifacts. In this paper, we propose a novel deep neural network with Dual Subnet and Multi-stage Communicated Upsampling (DSMC) for super-resolution of videos with large motion. We design a new module named U-shaped residual dense network with 3D convolution (U3D-RDN) for fine implicit motion estimation and motion compensation (MEMC) as well as coarse spatial feature extraction. And we present a new Multi-Stage Communicated Upsampling (MSCU) module to make full use of the intermediate results of upsampling for guiding the VSR. Moreover, a novel dual subnet is devised to aid the training of our DSMC, whose dual loss helps to reduce the solution space as well as enhance the generalization ability. Our experimental results confirm that our method achieves superior performance on videos with large motion compared to state-of-the-art methods",
    "checked": true,
    "id": "7fe680686ee6ee17de447c7c1dee52ab45e66f7d",
    "semantic_title": "large motion video super-resolution with dual subnet and multi-stage communicated upsampling",
    "citation_count": 14,
    "authors": [
      "Hongying Liu",
      "Peng Zhao",
      "Zhubo Ruan",
      "Fanhua Shang",
      "Yuanyuan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16311": {
    "title": "FCFR-Net: Feature Fusion based Coarse-to-Fine Residual Learning for Depth Completion",
    "volume": "main",
    "abstract": "Depth completion aims to recover a dense depth map from a sparse depth map with the corresponding color image as input. Recent approaches mainly formulate the depth completion as a one-stage end-to-end learning task, which outputs dense depth maps directly. However, the feature extraction and supervision in one-stage frameworks are insufficient, limiting the performance of these approaches. To address this problem, we propose a novel end-to-end residual learning framework, which formulates the depth completion as a two-stage learning task, i.e., a sparse-to-coarse stage and a coarse-to-fine stage. First, a coarse dense depth map is obtained by a simple CNN framework. Then, a refined depth map is further obtained using a residual learning strategy in the coarse-to-fine stage with coarse depth map and color image as input. Specially, in the coarse-to-fine stage, a channel shuffle extraction operation is utilized to extract more representative features from color image and coarse depth map, and an energy based fusion operation is exploited to effectively fuse these features obtained by channel shuffle operation, thus leading to more accurate and refined depth maps. We achieve SoTA performance in RMSE on KITTI benchmark. Extensive experiments on other datasets future demonstrate the superiority of our approach over current state-of-the-art depth completion approaches",
    "checked": true,
    "id": "1faac3a89e09a75dfdeb27210db7d55128d4119d",
    "semantic_title": "fcfr-net: feature fusion based coarse-to-fine residual learning for depth completion",
    "citation_count": 46,
    "authors": [
      "Lina Liu",
      "Xibin Song",
      "Xiaoyang Lyu",
      "Junwei Diao",
      "Mengmeng Wang",
      "Yong Liu",
      "Liangjun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16312": {
    "title": "Activity Image-to-Video Retrieval by Disentangling Appearance and Motion",
    "volume": "main",
    "abstract": "With the rapid emergence of video data, image-to-video retrieval has attracted much attention. There are two types of image-to-video retrieval: instance-based and activity-based. The former task aims to retrieve videos containing the same main objects as the query image, while the latter focuses on finding the similar activity. Since dynamic information plays a significant role in the video, we pay attention to the latter task to explore the motion relation between images and videos. In this paper, we propose a Motion-assisted Activity Proposal-based Image-to-Video Retrieval (MAP-IVR) approach to disentangle the video features into motion features and appearance features and obtain appearance features from the images. Then, we perform image-to-video translation to improve the disentanglement quality. The retrieval is performed in both appearance and video feature spaces. Extensive experiments demonstrate that our MAP-IVR approach remarkably outperforms the state-of-the-art approaches on two benchmark activity-based video datasets",
    "checked": true,
    "id": "945deb4324ffe267a5093fcc5ed6dec5277cbb65",
    "semantic_title": "activity image-to-video retrieval by disentangling appearance and motion",
    "citation_count": 10,
    "authors": [
      "Liu  Liu",
      "Jiangtong Li",
      "Li Niu",
      "Ruicong Xu",
      "Liqing Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16313": {
    "title": "Adaptive Pattern-Parameter Matching for Robust Pedestrian Detection",
    "volume": "main",
    "abstract": "Pedestrians with challenging patterns, e.g. small scale or heavy occlusion, appear frequently in practical applications like autonomous driving, which remains tremendous obstacle to higher robustness of detectors. Although plenty of previous works have been dedicated to these problems, properly matching patterns of pedestrian and parameters of detector, i.e., constructing a detector with proper parameter sizes for certain pedestrian patterns of different complexity, has been seldom investigated intensively. Pedestrian instances are usually handled equally with the same amount of parameters, which in our opinion is inadequate for those with more difficult patterns and leads to unsatisfactory performance. Thus, we propose in this paper a novel detection approach via adaptive pattern-parameter matching. The input pedestrian patterns, especially the complex ones, are first disentangled into simpler patterns for detection head by Pattern Disentangling Module (PDM) with various receptive fields. Then, Gating Feature Filtering Module (GFFM) dynamically decides the spatial positions where the patterns are still not simple enough and need further disentanglement by the next-level PDM. Cooperating with these two key components, our approach can adaptively select the best matched parameter size for the input patterns according to their complexity. Moreover, to further explore the relationship between parameter sizes and their performance on the corresponding patterns, two parameter selection policies are designed: 1) extending parameter size to maximum, aiming at more difficult patterns for different occlusion types; 2) specializing parameter size by group division, aiming at complex patterns for scale variations. Extensive experiments on two popular benchmarks, Caltech and CityPersons, show that our proposed method achieves superior performance compared with other state-of-the-art methods on subsets of different scales and occlusion types",
    "checked": true,
    "id": "60fe98d9684b347749124e90fd4b5047a80913df",
    "semantic_title": "adaptive pattern-parameter matching for robust pedestrian detection",
    "citation_count": 9,
    "authors": [
      "Mengyin Liu",
      "Chao Zhu",
      "Jun Wang",
      "Xu-Cheng Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16314": {
    "title": "Temporal Segmentation of Fine-gained Semantic Action: A Motion-Centered Figure Skating Dataset",
    "volume": "main",
    "abstract": "Temporal Action Segmentation (TAS) has achieved great success in many fields such as exercise rehabilitation, movie editing, etc. Currently, task-driven TAS is a central topic in human action analysis. However, motion-centered TAS, as an important topic, is little researched due to unavailable datasets. In order to explore more models and practical applications of motion-centered TAS, we introduce a Motion-Centered Figure Skating (MCFS) dataset in this paper. Compared with existing temporal action segmentation datasets, the MCFS dataset is fine-grained semantic, specialized and motion-centered. Besides, RGB-based and Skeleton-based features are provided in the MCFS dataset. Experimental results show that existing state-of-the-art methods are difficult to achieve excellent segmentation results (including accuracy, edit and F1 score) in the MCFS dataset. This indicates that MCFS is a challenging dataset for motion-centered TAS. The latest dataset can be downloaded at https://shenglanliu.github.io/mcfs-dataset/",
    "checked": true,
    "id": "ec1a6acf2615fd931f7f148457f04dcc53201425",
    "semantic_title": "temporal segmentation of fine-gained semantic action: a motion-centered figure skating dataset",
    "citation_count": 8,
    "authors": [
      "Shenglan Liu",
      "Aibin Zhang",
      "Yunheng Li",
      "Jian Zhou",
      "Li Xu",
      "Zhuben Dong",
      "Renhao Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16315": {
    "title": "Learning Hybrid Relationships for Person Re-identification",
    "volume": "main",
    "abstract": "Recently, the relationship among individual pedestrian images and the relationship among pairwise pedestrian images have become attractive for person re-identification (re-ID) as they effectively improve the ability of feature representation. In this paper, we propose a novel method named Hybrid Relationship Network (HRNet) to learn the two types of relationships in a unified framework that makes use of their own advantages. Specifically, for the relationship among individual pedestrian images, we take the features of pedestrian images as the nodes to construct a locally-connected graph, so as to improve the discriminative ability of nodes. Meanwhile, we propose the consistent node constraint to inject the identity information into the graph learning process and guide the information to propagate accurately. As for the relationship among pairwise pedestrian images, we treat the feature differences of pedestrian images as the nodes to construct a fully-connected graph so as to estimate robust similarity of nodes. Furthermore, we propose the inter-graph propagation to alleviate the information loss for the fully-connected graph. Extensive experiments on Market-1501, DukeMTMCreID, CUHK03 and MSMT17 demonstrate that the proposed HRNet outperforms the state-of-the-art methods",
    "checked": true,
    "id": "fe4de83dee3a43440a61da488df4d1a8b58e4674",
    "semantic_title": "learning hybrid relationships for person re-identification",
    "citation_count": 6,
    "authors": [
      "Shuang Liu",
      "Wenmin Huang",
      "Zhong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16316": {
    "title": "Translate the Facial Regions You Like Using Self-Adaptive Region Translation",
    "volume": "main",
    "abstract": "With the progression of Generative Adversarial Networks (GANs), image translation methods has achieved increasingly remarkable performance. However, most available methods can only achieve image level translation, which is unable to precisely control the regions to be translated. In this paper, we propose a novel self-adaptive region translation network (SART) for region-level translation, which uses region-adaptive instance normalization (RIN) and a region matching loss (RML) for this task. We first encode the style and content image for each region with style and content encoder. To translate both shape and texture of the target region, we inject region-adaptive style features into the decoder by RIN. To ensure independent translation among different regions, RML is proposed to measure the similarity between the non-translated/translated regions of content and translated images. Extensive experiments on three publicly available datasets, i.e. Morph, RaFD and CelebAMask-HQ, suggest that our approach demonstrate obvious improvement over state-of-the-art methods like StarGAN, SEAN and FUNIT. Our approach has further advantages in precise control of the regions to be translated. As a result, region level expression changes and step-by-step make-up can be achieved. The video demo is available at (https://youtu.be/DvIdmcR2LEc)",
    "checked": true,
    "id": "f1aebad17f7c82e9d055ad438e58d42a0cd84cfe",
    "semantic_title": "translate the facial regions you like using self-adaptive region translation",
    "citation_count": 5,
    "authors": [
      "Wenshuang Liu",
      "Wenting Chen",
      "Zhanjia Yang",
      "Linlin Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16317": {
    "title": "Subtype-aware Unsupervised Domain Adaptation for Medical Diagnosis",
    "volume": "main",
    "abstract": "Recent advances in unsupervised domain adaptation (UDA) show that transferable prototypical learning presents a powerful means for class conditional alignment, which encourages the closeness of cross-domain class centroids. However, the cross-domain inner-class compactness and the underlying fine-grained subtype structure remained largely underexplored. In this work, we propose to adaptively carry out the fine-grained subtype-aware alignment by explicitly enforcing the class-wise separation and subtype-wise compactness with intermediate pseudo labels. Our key insight is that the unlabeled subtypes of a class can be divergent to one another with different conditional and label shifts, while inheriting the local proximity within a subtype. The cases with or without the prior information on subtype numbers are investigated to discover the underlying subtype structure in an online fashion. The proposed subtype-aware dynamic UDA achieves promising results on a medical diagnosis task",
    "checked": true,
    "id": "3c354b347db3e74f7d7dfd4c8fc5183e3d56b0c7",
    "semantic_title": "subtype-aware unsupervised domain adaptation for medical diagnosis",
    "citation_count": 19,
    "authors": [
      "Xiaofeng Liu",
      "Xiongchang Liu",
      "Bo Hu",
      "Wenxuan Ji",
      "Fangxu Xing",
      "Jun Lu",
      "Jane You",
      "C.-C. Jay Kuo",
      "Georges El Fakhri",
      "Jonghye Woo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16318": {
    "title": "FontRL: Chinese Font Synthesis via Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "Automatic generation of Chinese fonts is a valuable but challenging task in areas of AI and Computer Graphics, mainly due to the huge amount of Chinese characters and their complex glyph structures. In this paper, we propose FontRL, a novel method for Chinese font synthesis by using deep reinforcement learning. Specifically, we first train a deep reinforcement learning model to obtain the Thin-Plate Spline (TPS) transformation that is able to modify the reference stroke skeleton in a mean font style into the skeleton of a required style for each stroke of every unseen Chinese character. Afterwards, we utilize a CNN model to predict the location and scale information of these strokes, and then assemble them to get the skeleton of the corresponding character. Finally, we convert each synthesized character skeleton into the glyph image via an image-to-image translation model. Both quantitative and qualitative experimental results demonstrate the superiority of the proposed FontRL compared to the state of the art. Our code is available at https://github.com/lsflyt-pku/FontRL",
    "checked": true,
    "id": "63b7201a062de0f0c870db614e4a599f41bf145a",
    "semantic_title": "fontrl: chinese font synthesis via deep reinforcement learning",
    "citation_count": 4,
    "authors": [
      "Yitian Liu",
      "Zhouhui Lian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16319": {
    "title": "Hierarchical Information Passing Based Noise-Tolerant Hybrid Learning for Semi-Supervised Human Parsing",
    "volume": "main",
    "abstract": "Deep learning based human parsing methods usually require a large amount of training data to reach high performance. However, it is costly and time-consuming to obtain manually annotated high quality labels for a large scale dataset. To alleviate annotation efforts, we propose a new semi-supervised human parsing method for which we only need a small number of labels for training. First, we generate high quality pseudo labels on unlabeled images using a hierarchical information passing network (HIPN), which reasons human part segmentation in a coarse to fine manner. Furthermore, we develop a noise-tolerant hybrid learning method, which takes advantage of positive and negative learning to better handle noisy pseudo labels. When evaluated on standard human parsing benchmarks, our HIPN achieves a new state-of-the-art performance. Moreover, our noise-tolerant hybrid learning method further improves the performance and outperforms the state-of-the-art semi-supervised method (i.e. GRN) by 4.47 points w.r.t mIoU on the LIP dataset",
    "checked": true,
    "id": "064d4bc44019cfc843ef4575e726a497d7a63587",
    "semantic_title": "hierarchical information passing based noise-tolerant hybrid learning for semi-supervised human parsing",
    "citation_count": 4,
    "authors": [
      "Yunan Liu",
      "Shanshan Zhang",
      "Jian Yang",
      "PongChi Yuen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16320": {
    "title": "Delving into Variance Transmission and Normalization: Shift of Average Gradient Makes the Network Collapse",
    "volume": "main",
    "abstract": "Normalization operations are essential for state-of-the-art neural networks and enable us to train a network from scratch with a large learning rate (LR). We attempt to explain the real effect of Batch Normalization (BN) from the perspective of variance transmission by investigating the relationship between BN and Weights Normalization (WN). In this work, we demonstrate that the problem of the shift of the average gradient will amplify the variance of every convolutional (conv) layer. We propose Parametric Weights Standardization (PWS), a fast and robust to mini-batch size module used for conv filters, to solve the shift of the average gradient. PWS can provide the speed-up of BN. Besides, it has less computation and does not change the output of a conv layer. PWS enables the network to converge fast without normalizing the outputs. This result enhances the persuasiveness of the shift of the average gradient and explains why BN works from the perspective of variance transmission. The code and appendix will be made available on https://github.com/lyxzzz/PWSConv",
    "checked": true,
    "id": "7c5e9932d1fba74668be0365755f441e525ef5c3",
    "semantic_title": "delving into variance transmission and normalization: shift of average gradient makes the network collapse",
    "citation_count": 1,
    "authors": [
      "Yuxiang Liu",
      "Jidong Ge",
      "Chuanyi Li",
      "Jie Gui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16321": {
    "title": "Aggregated Multi-GANs for Controlled 3D Human Motion Prediction",
    "volume": "main",
    "abstract": "Human motion prediction from historical pose sequence is at the core of many applications in machine intelligence. However, in current state-of-the-art methods, the predicted future motion is confined within the same activity. One can neither generate predictions that differ from the current activity, nor manipulate the body parts to explore various future possibilities. Undoubtedly, this greatly limits the usefulness and applicability of motion prediction. In this paper, we propose a generalization of the human motion prediction task in which control parameters can be readily incorporated to adjust the forecasted motion. Our method is compelling in that it enables manipulable motion prediction across activity types and allows customization of the human movement in a variety of fine-grained ways. To this aim, a simple yet effective composite GAN structure, consisting of local GANs for different body parts and aggregated via a global GAN is presented. The local GANs game in lower dimensions, while the global GAN adjusts in high dimensional space to avoid mode collapse. Extensive experiments show that our method outperforms state-of-the-art. The codes are available at https://github.com/herolvkd/AM-GAN",
    "checked": true,
    "id": "d4b3d71fcbdebbf0e2c759a2566b4fe1129ed2a9",
    "semantic_title": "aggregated multi-gans for controlled 3d human motion prediction",
    "citation_count": 30,
    "authors": [
      "Zhenguang Liu",
      "Kedi Lyu",
      "Shuang Wu",
      "Haipeng Chen",
      "Yanbin Hao",
      "Shouling Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16322": {
    "title": "ACSNet: Action-Context Separation Network for Weakly Supervised Temporal Action Localization",
    "volume": "main",
    "abstract": "The object of Weakly-supervised Temporal Action Localization (WS-TAL) is to localize all action instances in an untrimmed video with only video-level supervision. Due to the lack of frame-level annotations during training, current WS-TAL methods rely on attention mechanisms to localize the foreground snippets or frames that contribute to the video-level classification task. This strategy frequently confuse context with the actual action, in the localization result. Separating action and context is a core problem for precise WS-TAL, but it is very challenging and has been largely ignored in the literature. In this paper, we introduce an Action-Context Separation Network (ACSNet) that explicitly takes into account context for accurate action localization. It consists of two branches (i.e., the Foreground-Background branch and the Action-Context branch). The Foreground-Background branch first distinguishes foreground from background within the entire video while the Action-Context branch further separates the foreground as action and context. We associate video snippets with two latent components (i.e., a positive component and a negative component), and their different combinations can effectively characterize foreground, action and context. Furthermore, we introduce extended labels with auxiliary context categories to facilitate the learning of action-context separation. Experiments on THUMOS14 and ActivityNet v1.2/v1.3 datasets demonstrate the ACSNet outperforms existing state-of-the-art WS-TAL methods by a large margin",
    "checked": true,
    "id": "a56089a2b1d9f2ad942dd5ce841d204322bd16dd",
    "semantic_title": "acsnet: action-context separation network for weakly supervised temporal action localization",
    "citation_count": 43,
    "authors": [
      "Ziyi Liu",
      "Le Wang",
      "Qilin Zhang",
      "Wei Tang",
      "Junsong Yuan",
      "Nanning Zheng",
      "Gang Hua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16323": {
    "title": "Weakly Supervised Temporal Action Localization Through Learning Explicit Subspaces for Action and Context",
    "volume": "main",
    "abstract": "Weakly-supervised Temporal Action Localization (WS-TAL) methods learn to localize temporal starts and ends of action instances in a video under only video-level supervision. Existing WS-TAL methods rely on deep features learned for action recognition. However, due to the mismatch between classification and localization, these features cannot distinguish the frequently co-occurring contextual background, i.e., the context, and the actual action instances. We term this challenge action-context confusion, and it will adversely affect the action localization accuracy. To address this challenge, we introduce a framework that learns two feature subspaces respectively for actions and their context. By explicitly accounting for action visual elements, the action instances can be localized more precisely without the distraction from the context. To facilitate the learning of these two feature subspaces with only video-level categorical labels, we leverage the predictions from both spatial and temporal streams for snippets grouping. In addition, an unsupervised learning task is introduced to make the proposed module focus on mining temporal information. The proposed approach outperforms state-of-the-art WS-TAL methods on three benchmarks, i.e., THUMOS14, ActivityNet v1.2 and v1.3 datasets",
    "checked": true,
    "id": "7f0971db4836c49788a440ca7e1fd96f630cc807",
    "semantic_title": "weakly supervised temporal action localization through learning explicit subspaces for action and context",
    "citation_count": 14,
    "authors": [
      "Ziyi Liu",
      "Le Wang",
      "Wei Tang",
      "Junsong Yuan",
      "Nanning Zheng",
      "Gang Hua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16324": {
    "title": "PointINet: Point Cloud Frame Interpolation Network",
    "volume": "main",
    "abstract": "LiDAR point cloud streams are usually sparse in time dimension, which is limited by hardware performance. Generally, the frame rates of mechanical LiDAR sensors are 10 to 20 Hz, which is much lower than other commonly used sensors like cameras. To overcome the temporal limitations of LiDAR sensors, a novel task named Point Cloud Frame Interpolation is studied in this paper. Given two consecutive point cloud frames, Point Cloud Frame Interpolation aims to generate intermediate frame(s) between them. To achieve that, we propose a novel framework, namely Point Cloud Frame Interpolation Network (PointINet). Based on the proposed method, the low frame rate point cloud streams can be upsampled to higher frame rates. We start by estimating bi-directional 3D scene flow between the two point clouds and then warp them to the given time step based on the 3D scene flow. To fuse the two warped frames and generate intermediate point cloud(s), we propose a novel learning-based points fusion module, which simultaneously takes two warped point clouds into consideration. We design both quantitative and qualitative experiments to evaluate the performance of the point cloud frame interpolation method and extensive experiments on two large scale outdoor LiDAR datasets demonstrate the effectiveness of the proposed PointINet. Our code is available at https://github.com/ispc-lab/PointINet.git",
    "checked": true,
    "id": "b7e6377d5d5d42c8b06a197465a281624dca8a4d",
    "semantic_title": "pointinet: point cloud frame interpolation network",
    "citation_count": 17,
    "authors": [
      "Fan Lu",
      "Guang Chen",
      "Sanqing Qu",
      "Zhijun Li",
      "Yinlong Liu",
      "Alois Knoll"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16325": {
    "title": "A Global Occlusion-Aware Approach to Self-Supervised Monocular Visual Odometry",
    "volume": "main",
    "abstract": "Self-Supervised monocular visual odometry (VO) is often cast into a view synthesis problem based on depth and camera pose estimation. One of the key challenges is to accurately and robustly estimate depth with occlusions and moving objects in the scene. Existing methods simply detect and mask out regions of occlusions locally by several convolutional layers, and then perform only partial view synthesis in the rest of the image. However, occlusion and moving object detection is an unsolved problem itself which requires global layout information. Inaccurate detection inevitably results in incorrect depth as well as pose estimation. In this work, instead of locally detecting and masking out occlusions and moving objects, we propose to alleviate their negative effects on monocular VO implicitly but more effectively from two global perspectives. First, a multi-scale non-local attention module, consisting of both intra-stage augmented attention and cascaded across-stage attention, is proposed for robust depth estimation given occlusions, alleviating the impacts of occlusions via global attention modeling. Second, adversarial learning is introduced in view synthesis for monocular VO. Unlike existing methods that use pixel-level losses on the quality of synthesized views, we enforce the synthetic view to be indistinguishable from the real one at the scene-level. Such a global constraint again helps cope with occluded and moving regions. Extensive experiments on the KITTI dataset show that our approach achieves new state-of-the-art in both pose estimation and depth recovery",
    "checked": true,
    "id": "f112e0d301e2481e0ae743bd0b18b4afd7351d5d",
    "semantic_title": "a global occlusion-aware approach to self-supervised monocular visual odometry",
    "citation_count": 4,
    "authors": [
      "Yao Lu",
      "Xiaoli Xu",
      "Mingyu Ding",
      "Zhiwu Lu",
      "Tao Xiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16326": {
    "title": "PC-HMR: Pose Calibration for 3D Human Mesh Recovery from 2D Images/Videos",
    "volume": "main",
    "abstract": "The end-to-end Human Mesh Recovery (HMR) approach has been successfully used for 3D body reconstruction. However, most HMR-based frameworks reconstruct human body by directly learning mesh parameters from images or videos, while lacking explicit guidance of 3D human pose in visual data. As a result, the generated mesh often exhibits incorrect pose for complex activities. To tackle this problem, we propose to exploit 3D pose to calibrate human mesh. Specifically, we develop two novel Pose Calibration frameworks, i.e., Serial PC-HMR and Parallel PC-HMR. By coupling advanced 3D pose estimators and HMR in a serial or parallel manner, these two frameworks can effectively correct human mesh with guidance of a concise pose calibration module. Furthermore, since the calibration module is designed via non-rigid pose transformation, our PC-HMR frameworks can flexibly tackle bone length variations to alleviate misplacement in the calibrated mesh. Finally, our frameworks are based on generic and complementary integration of data-driven learning and geometrical modeling. Via plug-and-play modules, they can be efficiently adapted for both image/video-based human mesh recovery. Additionally, they have no requirement of extra 3D pose annotations in the testing phase, which releases inference difficulties in practice. We perform extensive experiments on the popular benchmarks, i.e., Human3.6M, 3DPW and SURREAL, where our PC-HMR frameworks achieve the SOTA results",
    "checked": true,
    "id": "788bf5e5ac68aafe77564473869a0740280ae813",
    "semantic_title": "pc-hmr: pose calibration for 3d human mesh recovery from 2d images/videos",
    "citation_count": 14,
    "authors": [
      "Tianyu Luan",
      "Yali Wang",
      "Junhao Zhang",
      "Zhe Wang",
      "Zhipeng Zhou",
      "Yu Qiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16327": {
    "title": "DeepDT: Learning Geometry From Delaunay Triangulation for Surface Reconstruction",
    "volume": "main",
    "abstract": "In this paper, a novel learning-based network, named DeepDT, is proposed to reconstruct the surface from Delaunay triangulation of point cloud. DeepDT learns to predict inside/outside labels of Delaunay tetrahedrons directly from a point cloud and corresponding Delaunay triangulation. The local geometry features are first extracted from the input point cloud and aggregated into a graph deriving from the Delaunay triangulation. Then a graph filtering is applied on the aggregated features in order to add structural regularization to the label prediction of tetrahedrons. Due to the complicated spatial relations between tetrahedrons and the triangles, it is impossible to directly generate ground truth labels of tetrahedrons from ground truth surface. Therefore, we propose a multi-label supervision strategy which votes for the label of a tetrahedron with labels of sampling locations inside it. The proposed DeepDT can maintain abundant geometry details without generating overly complex surfaces, especially for inner surfaces of open scenes. Meanwhile, the generalization ability and time consumption of the proposed method is acceptable and competitive compared with the state-of-the-art methods. Experiments demonstrate the superior performance of the proposed DeepDT",
    "checked": true,
    "id": "26a22bded2e64a2e95613a744a9f5ad12b082e1e",
    "semantic_title": "deepdt: learning geometry from delaunay triangulation for surface reconstruction",
    "citation_count": 19,
    "authors": [
      "Yiming Luo",
      "Zhenxing Mi",
      "Wenbing Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16328": {
    "title": "Dual-level Collaborative Transformer for Image Captioning",
    "volume": "main",
    "abstract": "Descriptive region features extracted by object detection networks have played an important role in the recent advancements of image captioning. However, they are still criticized for the lack of contextual information and fine-grained details, which in contrast are the merits of traditional grid features. In this paper, we introduce a novel Dual-Level Collaborative Transformer (DLCT) network to realize the complementary advantages of the two features. Concretely, in DLCT, these two features are first processed by a novel Dual-way Self Attenion (DWSA) to mine their intrinsic properties, where a Comprehensive Relation Attention component is also introduced to embed the geometric information. In addition, we propose a Locality-Constrained Cross Attention module to address the semantic noises caused by the direct fusion of these two features, where a geometric alignment graph is constructed to accurately align and reinforce region and grid features. To validate our model, we conduct extensive experiments on the highly competitive MS-COCO dataset, and achieve new state-of-the-art performance on both local and online test sets, i.e., 133.8% CIDEr on Karpathy split and 135.4% CIDEr on the official split",
    "checked": true,
    "id": "ae7e5a4de962ca4face3bb52b36dfd09db5451d8",
    "semantic_title": "dual-level collaborative transformer for image captioning",
    "citation_count": 138,
    "authors": [
      "Yunpeng Luo",
      "Jiayi Ji",
      "Xiaoshuai Sun",
      "Liujuan Cao",
      "Yongjian Wu",
      "Feiyue Huang",
      "Chia-Wen Lin",
      "Rongrong Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16329": {
    "title": "HR-Depth: High Resolution Self-Supervised Monocular Depth Estimation",
    "volume": "main",
    "abstract": "Self-supervised learning shows great potential in monocular depth estimation, using image sequences as the only source of supervision. Although people try to use the high-resolution image for depth estimation, the accuracy of prediction has not been significantly improved. In this work, we find the core reason comes from the inaccurate depth estimation in large gradient regions, making the bilinear interpolation error gradually disappear as the resolution increases. To obtain more accurate depth estimation in large gradient regions, it is necessary to obtain high-resolution features with spatial and semantic information. Therefore, we present an improved DepthNet, HR-Depth, with two effective strategies: (1) re-design the skip-connection in DepthNet to get better high-resolution features and (2) propose feature fusion Squeeze-and-Excitation(fSE) module to fuse feature more efficiently. Using Resnet-18 as the encoder, HR-Depth surpasses all previous state-of-the-art(SoTA) methods with the least parameters at both high and low resolution. Moreover, previous SoTA methods are based on fairly complex and deep networks with a mass of parameters which limits their real applications. Thus we also construct a lightweight network which uses MobileNetV3 as encoder. Experiments show that the lightweight network can perform on par with many large models like Monodepth2 at high-resolution with only20%parameters. All codes and models will be available at https://github.com/shawLyu/HR-Depth",
    "checked": true,
    "id": "1c7a149cbddff67b48a6c045692fd194b404d4e8",
    "semantic_title": "hr-depth: high resolution self-supervised monocular depth estimation",
    "citation_count": 88,
    "authors": [
      "Xiaoyang Lyu",
      "Liang Liu",
      "Mengmeng Wang",
      "Xin Kong",
      "Lina Liu",
      "Yong Liu",
      "Xinxin Chen",
      "Yi Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16330": {
    "title": "SMIL: Multimodal Learning with Severely Missing Modality",
    "volume": "main",
    "abstract": "A common assumption in multimodal learning is the completeness of training data, i.e., full modalities are available in all training examples. Although there exists research endeavor in developing novel methods to tackle the incompleteness of testing data, e.g., modalities are partially missing in testing examples, few of them can handle incomplete training modalities. The problem becomes even more challenging if considering the case of severely missing, e.g., ninety percent of training examples may have incomplete modalities. For the first time in the literature, this paper formally studies multimodal learning with missing modality in terms of flexibility (missing modalities in training, testing, or both) and efficiency (most training data have incomplete modality). Technically, we propose a new method named SMIL that leverages Bayesian meta-learning in uniformly achieving both objectives. To validate our idea, we conduct a series of experiments on three popular benchmarks: MM-IMDb, CMU-MOSI, and avMNIST. The results prove the state-of-the-art performance of SMIL over existing methods and generative baselines including autoencoders and generative adversarial networks",
    "checked": true,
    "id": "31d20462d35059502ffeb13e1afbba11a81c7d41",
    "semantic_title": "smil: multimodal learning with severely missing modality",
    "citation_count": 89,
    "authors": [
      "Mengmeng Ma",
      "Jian Ren",
      "Long Zhao",
      "Sergey Tulyakov",
      "Cathy Wu",
      "Xi Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16331": {
    "title": "Pyramidal Feature Shrinking for Salient Object Detection",
    "volume": "main",
    "abstract": "Recently, we have witnessed the great progress of salient object detection (SOD), which benefits from the effectiveness of various feature aggregation strategies. However, existing methods usually aggregate the low-level features containing details and the high-level features containing semantics over a large span, which introduces noise into the aggregated features and generate inaccurate saliency map. To address this issue, we propose pyramidal feature shrinking network (PFSNet), which aims to aggregate adjacent feature nodes in pairs with layer-by-layer shrinkage, so that the aggregated features fuse effective details and semantics together and discard interference information. Specifically, pyramidal shrinking decoder (PSD) is proposed to aggregate adjacent features hierarchically in an asymptotic manner. Unlike other methods that aggregate features with significantly different information, this method only focuses on adjacent feature nodes in each layer and shrinks them to a final unique feature node. Besides, we propose adjacent fusion module (AFM) to perform mutual spatial enhancement between the adjacent features so as to dynamically weight the features and adaptively fuse the appropriate information. In addition, scale-aware enrichment module (SEM) based on the features extracted from backbone is utilized to obtain rich scale information and generate diverse initial features with dilated convolutions. Extensive quantitative and qualitative experiments demonstrate that the proposed intuitive framework outperforms 14 state-of-the-art approaches on 5 public datasets",
    "checked": true,
    "id": "f6597669ffea6f47234af09ecbc6adea7e0e9a4f",
    "semantic_title": "pyramidal feature shrinking for salient object detection",
    "citation_count": 65,
    "authors": [
      "Mingcan Ma",
      "Changqun Xia",
      "Jia Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16332": {
    "title": "Learning to Count via Unbalanced Optimal Transport",
    "volume": "main",
    "abstract": "Counting dense crowds through computer vision technology has attracted widespread attention. Most crowd counting datasets use point annotations. In this paper, we formulate crowd counting as a measure regression problem to minimize the distance between two measures with different supports and unequal total mass. Specifically, we adopt the unbalanced optimal transport distance, which remains stable under spatial perturbations, to quantify the discrepancy between predicted density maps and point annotations. An efficient optimization algorithm based on the regularized semi-dual formulation of UOT is introduced, which alternatively learns the optimal transportation and optimizes the density regressor. The quantitative and qualitative results illustrate that our method achieves state-of-the-art counting and localization performance",
    "checked": true,
    "id": "2b95361a59c894721262db66a356decc86f1ef1c",
    "semantic_title": "learning to count via unbalanced optimal transport",
    "citation_count": 40,
    "authors": [
      "Zhiheng Ma",
      "Xing Wei",
      "Xiaopeng Hong",
      "Hui Lin",
      "Yunfeng Qiu",
      "Yihong Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16333": {
    "title": "Scene Graph Embeddings Using Relative Similarity Supervision",
    "volume": "main",
    "abstract": "Scene graphs are a powerful structured representation of the underlying content of images, and embeddings derived from them have been shown to be useful in multiple downstream tasks. In this work, we employ a graph convolutional network to exploit structure in scene graphs and produce image embeddings useful for semantic image retrieval. Different from classification-centric supervision traditionally available for learning image representations, we address the task of learning from relative similarity labels in a ranking context. Rooted within the contrastive learning paradigm, we propose a novel loss function that operates on pairs of similar and dissimilar images and imposes relative ordering between them in embedding space. We demonstrate that this Ranking loss, coupled with an intuitive triple sampling strategy, leads to robust representations that outperform well-known contrastive losses on the retrieval task. In addition, we provide qualitative evidence of how retrieved results that utilize structured scene information capture the global context of the scene, different from visual similarity search",
    "checked": true,
    "id": "3bb090a44596d6396f88d6d31e46105b7f642613",
    "semantic_title": "scene graph embeddings using relative similarity supervision",
    "citation_count": 10,
    "authors": [
      "Paridhi Maheshwari",
      "Ritwick Chaudhry",
      "Vishwa Vinay"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16334": {
    "title": "Few-Shot Lifelong Learning",
    "volume": "main",
    "abstract": "Many real-world classification problems often have classes with very few labeled training samples. Moreover, all possible classes may not be initially available for training, and may be given incrementally. Deep learning models need to deal with this two-fold problem in order to perform well in real-life situations. In this paper, we propose a novel Few-Shot Lifelong Learning (FSLL) method that enables deep learning models to perform lifelong/continual learning on few-shot data. Our method selects very few parameters from the model for training every new set of classes instead of training the full model. This helps in preventing overfitting. We choose the few parameters from the model in such a way that only the currently unimportant parameters get selected. By keeping the important parameters in the model intact, our approach minimizes catastrophic forgetting. Furthermore, we minimize the cosine similarity between the new and the old class prototypes in order to maximize their separation, thereby improving the classification performance. We also show that integrating our method with self-supervision improves the model performance significantly. We experimentally show that our method significantly outperforms existing methods on the miniImageNet, CIFAR-100, and CUB-200 datasets. Specifically, we outperform the state-of-the-art method by an absolute margin of 19.27% for the CUB dataset",
    "checked": true,
    "id": "013ea7e067477ab79c7afb381a0e56a42c417d6b",
    "semantic_title": "few-shot lifelong learning",
    "citation_count": 58,
    "authors": [
      "Pratik Mazumder",
      "Pravendra Singh",
      "Piyush Rai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16335": {
    "title": "CARPe Posterum: A Convolutional Approach for Real-Time Pedestrian Path Prediction",
    "volume": "main",
    "abstract": "Pedestrian path prediction is an essential topic in computer vision and video understanding. Having insight into the movement of pedestrians is crucial for ensuring safe operation in a variety of applications including autonomous vehicles, social robots, and environmental monitoring. Current works in this area utilize complex generative or recurrent methods to capture many possible futures. However, despite the inherent real-time nature of predicting future paths, little work has been done to explore accurate and computationally efficient approaches for this task. To this end, we propose a convolutional approach for real-time pedestrian path prediction, CARPe. It utilizes a variation of Graph Isomorphism Networks in combination with an agile convolutional neural network design to form a fast and accurate path prediction approach. Notable results in both inference speed and prediction accuracy are achieved, improving FPS considerably in comparison to current state-of-the-art methods while delivering competitive accuracy on well-known path prediction datasets",
    "checked": true,
    "id": "01391b4133b722843b45e8634c1b2b5f2f0126d7",
    "semantic_title": "carpe posterum: a convolutional approach for real-time pedestrian path prediction",
    "citation_count": 8,
    "authors": [
      "Matias Mendieta",
      "Hamed Tabkhi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16336": {
    "title": "Dynamic Anchor Learning for Arbitrary-Oriented Object Detection",
    "volume": "main",
    "abstract": "Arbitrary-oriented objects widely appear in natural scenes, aerial photographs, remote sensing images, etc., and thus arbitrary-oriented object detection has received considerable attention. Many current rotation detectors use plenty of anchors with different orientations to achieve spatial alignment with ground truth boxes. Intersection-over-Union (IoU) is then applied to sample the positive and negative candidates for training. However, we observe that the selected positive anchors cannot always ensure accurate detections after regression, while some negative samples can achieve accurate localization. It indicates that the quality assessment of anchors through IoU is not appropriate, and this further leads to inconsistency between classification confidence and localization accuracy. In this paper, we propose a dynamic anchor learning (DAL) method, which utilizes the newly defined matching degree to comprehensively evaluate the localization potential of the anchors and carries out a more efficient label assignment process. In this way, the detector can dynamically select high-quality anchors to achieve accurate object detection, and the divergence between classification and regression will be alleviated. With the newly introduced DAL, we can achieve superior detection performance for arbitrary-oriented objects with only a few horizontal preset anchors. Experimental results on three remote sensing datasets HRSC2016, DOTA, UCAS-AOD as well as a scene text dataset ICDAR 2015 show that our method achieves substantial improvement compared with the baseline model. Besides, our approach is also universal for object detection using horizontal bound box. The code and models are available at https://github.com/ming71/DAL",
    "checked": true,
    "id": "5cc2198ddbbec84f04019b1fd3f02798673dbb91",
    "semantic_title": "dynamic anchor learning for arbitrary-oriented object detection",
    "citation_count": 156,
    "authors": [
      "Qi Ming",
      "Zhiqiang Zhou",
      "Lingjuan Miao",
      "Hongwei Zhang",
      "Linhao Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16337": {
    "title": "Terrace-based Food Counting and Segmentation",
    "volume": "main",
    "abstract": "This paper represents object instance as a terrace, where the height of terrace corresponds to object attention while the evolution of layers from peak to sea level represents the complexity in drawing the finer boundary of an object. A multitask neural network is presented to learn the terrace representation. The attention of terrace is leveraged for instance counting, and the layers provide prior for easy-to-hard pathway of progressive instance segmentation. We study the model for counting and segmentation for a variety of food instances, ranging from Chinese, Japanese to Western food. This paper presents how the terrace model deals with arbitrary shape, size, obscure boundary and occlusion of instances, where other techniques are currently short of",
    "checked": true,
    "id": "0c7058fae2176b23e1d3a3cdd852cc3464e4deee",
    "semantic_title": "terrace-based food counting and segmentation",
    "citation_count": 4,
    "authors": [
      "Huu-Thanh Nguyen",
      "Chong-Wah Ngo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16338": {
    "title": "Embodied Visual Active Learning for Semantic Segmentation",
    "volume": "main",
    "abstract": "We study the task of embodied visual active learning, where an agent is set to explore a 3d environment with the goal to acquire visual scene understanding by actively selecting views for which to request annotation. While accurate on some benchmarks, today's deep visual recognition pipelines tend to not generalize well in certain real-world scenarios, or for unusual viewpoints. Robotic perception, in turn, requires the capability to refine the recognition capabilities for the conditions where the mobile system operates, including cluttered indoor environments or poor illumination. This motivates the proposed task, where an agent is placed in a novel environment with the objective of improving its visual recognition capability. To study embodied visual active learning, we develop a battery of agents - both learnt and pre-specified - and with different levels of knowledge of the environment. The agents are equipped with a semantic segmentation network and seek to acquire informative views, move and explore in order to propagate annotations in the neighbourhood of those views, then refine the underlying segmentation network by online retraining. The trainable method uses deep reinforcement learning with a reward function that balances two competing objectives: task performance, represented as visual recognition accuracy, which requires exploring the environment, and the necessary amount of annotated data requested during active exploration. We extensively evaluate the proposed models using the photorealistic Matterport3D simulator and show that a fully learnt method outperforms comparable pre-specified counterparts, even when requesting fewer annotations",
    "checked": true,
    "id": "f6c397dc04c3e30ed2d6dc8299884db50d70f0b6",
    "semantic_title": "embodied visual active learning for semantic segmentation",
    "citation_count": 16,
    "authors": [
      "David Nilsson",
      "Aleksis Pirinen",
      "Erik G√§rtner",
      "Cristian Sminchisescu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16339": {
    "title": "TDAF: Top-Down Attention Framework for Vision Tasks",
    "volume": "main",
    "abstract": "Human attention mechanisms often work in a top-down manner, yet it is not well explored in vision research. Here, we propose the Top-Down Attention Framework (TDAF) to capture top-down attentions, which can be easily adopted in most existing models. The designed Recursive Dual-Directional Nested Structure in it forms two sets of orthogonal paths, recursive and structural ones, where bottom-up spatial features and top-down attention features are extracted respectively. Such spatial and attention features are nested deeply, therefore, the proposed framework works in a mixed top-down and bottom-up manner. Empirical evidence shows that our TDAF can capture effective stratified attention information and boost performance. ResNet with TDAF achieves 2.0% improvements on ImageNet. For object detection, the performance is improved by 2.7% AP over FCOS. For pose estimation, TDAF improves the baseline by 1.6%. And for action recognition, the 3D-ResNet adopting TDAF achieves improvements of 1.7% accuracy",
    "checked": true,
    "id": "965571810fcb79fdaaed7329ff57b3720508a241",
    "semantic_title": "tdaf: top-down attention framework for vision tasks",
    "citation_count": 5,
    "authors": [
      "Bo Pang",
      "Yizhuo Li",
      "Jiefeng Li",
      "Muchen Li",
      "Hanwen Cao",
      "Cewu Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16340": {
    "title": "Few-shot Font Generation with Localized Style Representations and Factorization",
    "volume": "main",
    "abstract": "Automatic few-shot font generation is a practical and widely studied problem because manual designs are expensive and sensitive to the expertise of designers. Existing few-shot font generation methods aim to learn to disentangle the style and content element from a few reference glyphs, and mainly focus on a universal style representation for each font style. However, such approach limits the model in representing diverse local styles, and thus makes it unsuitable to the most complicated letter system, e.g., Chinese, whose characters consist of a varying number of components (often called ``radical'') with a highly complex structure. In this paper, we propose a novel font generation method by learning localized styles, namely component-wise style representations, instead of universal styles. The proposed style representations enable us to synthesize complex local details in text designs. However, learning component-wise styles solely from reference glyphs is infeasible in the few-shot font generation scenario, when a target script has a large number of components, e.g., over 200 for Chinese. To reduce the number of reference glyphs, we simplify component-wise styles by a product of component factor and style factor, inspired by low-rank matrix factorization. Thanks to the combination of strong representation and a compact factorization strategy, our method shows remarkably better few-shot font generation results (with only 8 reference glyph images) than other state-of-the-arts, without utilizing strong locality supervision, e.g., location of each component, skeleton, or strokes. The source code is available at https://github.com/clovaai/lffont",
    "checked": true,
    "id": "c1308be7b8f20d62bd1ae896f34c0db5c8285bdd",
    "semantic_title": "few-shot font generation with localized style representations and factorization",
    "citation_count": 39,
    "authors": [
      "Song Park",
      "Sanghyuk Chun",
      "Junbum Cha",
      "Bado Lee",
      "Hyunjung Shim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16341": {
    "title": "Learning Disentangled Representation for Fair Facial Attribute Classification via Fairness-aware Information Alignment",
    "volume": "main",
    "abstract": "Although AI systems archive a great success in various societal fields, there still exists a challengeable issue of outputting discriminatory results with respect to protected attributes (e.g., gender and age). The popular approach to solving the issue is to remove protected attribute information in the decision process. However, this approach has a limitation that beneficial information for target tasks may also be eliminated. To overcome the limitation, we propose Fairness-aware Disentangling Variational Auto-Encoder (FD-VAE) that disentangles data representation into three subspaces: 1) Target Attribute Latent (TAL), 2) Protected Attribute Latent (PAL), 3) Mutual Attribute Latent (MAL). On top of that, we propose a decorrelation loss that aligns the overall information into each subspace, instead of removing the protected attribute information. After learning the representation, we re-encode MAL to include only target information and combine it with TAL to perform downstream tasks. In our experiments on CelebA and UTK Face datasets, we show that the proposed method mitigates unfairness in facial attribute classification tasks with respect to gender and age. Ours outperforms previous methods by large margins on two standard fairness metrics, equal opportunity and equalized odds",
    "checked": true,
    "id": "9d02d4d5f4dc33928dc21eae402e5200d1cb2e75",
    "semantic_title": "learning disentangled representation for fair facial attribute classification via fairness-aware information alignment",
    "citation_count": 27,
    "authors": [
      "Sungho Park",
      "Sunhee Hwang",
      "Dohyung Kim",
      "Hyeran Byun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16342": {
    "title": "Vid-ODE: Continuous-Time Video Generation with Neural Ordinary Differential Equation",
    "volume": "main",
    "abstract": "Video generation models often operate under the assumption of fixed frame rates, which leads to suboptimal performance when it comes to handling flexible frame rates (e.g., increasing the frame rate of the more dynamic portion of the video as well as handling missing video frames). To resolve the restricted nature of existing video generation models' ability to handle arbitrary timesteps, we propose continuous-time video generation by combining neural ODE (Vid-ODE) with pixel-level video processing techniques. Using ODE-ConvGRU as an encoder, a convolutional version of the recently proposed neural ODE, which enables us to learn continuous-time dynamics, Vid-ODE can learn the spatio-temporal dynamics of input videos of flexible frame rates. The decoder integrates the learned dynamics function to synthesize video frames at any given timesteps, where the pixel-level composition technique is used to maintain the sharpness of individual frames. With extensive experiments on four real-world video datasets, we verify that the proposed Vid-ODE outperforms state-of-the-art approaches under various video generation settings, both within the trained time range (interpolation) and beyond the range (extrapolation). To the best of our knowledge, Vid-ODE is the first work successfully performing continuous-time video generation using real-world videos",
    "checked": true,
    "id": "58db26d7064d16bd45d2fda6b5ded997f47278e5",
    "semantic_title": "vid-ode: continuous-time video generation with neural ordinary differential equation",
    "citation_count": 28,
    "authors": [
      "Sunghyun  Park",
      "Kangyeol Kim",
      "Junsoo Lee",
      "Jaegul Choo",
      "Joonseok Lee",
      "Sookyung Kim",
      "Edward Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16343": {
    "title": "CHEF: Cross-modal Hierarchical Embeddings for Food Domain Retrieval",
    "volume": "main",
    "abstract": "Despite the abundance of multi-modal data, such as image-text pairs, there has been little effort in understanding the individual entities and their different roles in the construction of these data instances. In this work, we endeavour to discover the entities and their corresponding importance in cooking recipes automatically as a visual-linguistic association problem. More specifically, we introduce a novel cross-modal learning framework to jointly model the latent representations of images and text in the food image-recipe association and retrieval tasks. This model allows one to discover complex functional and hierarchical relationships between images and text, and among textual parts of a recipe including title, ingredients and cooking instructions. Our experiments show that by making use of efficient tree-structured Long Short-Term Memory as the text encoder in our computational cross-modal retrieval framework, we are not only able to identify the main ingredients and cooking actions in the recipe descriptions without explicit supervision, but we can also learn more meaningful feature representations of food recipes, appropriate for challenging cross-modal retrieval and recipe adaption tasks",
    "checked": true,
    "id": "582ff0395d97f3e90003811346c940559cec9a51",
    "semantic_title": "chef: cross-modal hierarchical embeddings for food domain retrieval",
    "citation_count": 10,
    "authors": [
      "Hai X. Pham",
      "Ricardo Guerrero",
      "Vladimir Pavlovic",
      "Jiatong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16344": {
    "title": "Explainable Models with Consistent Interpretations",
    "volume": "main",
    "abstract": "Given the widespread deployment of black box deep neural networks in computer vision applications, the interpretability aspect of these black box systems has recently gained traction. Various methods have been proposed to explain the results of such deep neural networks. However, some recent works have shown that such explanation methods are biased and do not produce consistent interpretations. Hence, rather than introducing a novel explanation method, we learn models that are encouraged to be interpretable given an explanation method. We use Grad-CAM as the explanation algorithm and encourage the network to learn consistent interpretations along with maximizing the log-likelihood of the correct class. We show that our method outperforms the baseline on the pointing game evaluation on ImageNet and MS-COCO datasets respectively. We also introduce new evaluation metrics that penalize the saliency map if it lies outside the ground truth bounding box or segmentation mask, and show that our method outperforms the baseline on these metrics as well. Moreover, our model trained with interpretation consistency generalizes to other explanation algorithms on all the evaluation metrics. The code and models are publicly available",
    "checked": true,
    "id": "13e5c87d143940a40ffcfa750470711c810e7d59",
    "semantic_title": "explainable models with consistent interpretations",
    "citation_count": 17,
    "authors": [
      "Vipin Pillai",
      "Hamed Pirsiavash"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16345": {
    "title": "Dual Adversarial Graph Neural Networks for Multi-label Cross-modal Retrieval",
    "volume": "main",
    "abstract": "Cross-modal retrieval has become an active study field with the expanding scale of multimodal data. To date, most existing methods transform multimodal data into a common representation space where semantic similarities between items can be directly measured across different modalities. However, these methods typically suffer from following limitations: 1) They usually attempt to bridge the modality gap by designing losses in the common representation space which may not be sufficient to eliminate potential heterogeneity of different modalities in the common space. 2) They typically treat labels as independent individuals and ignore label relationships which are important for constructing semantic links between multimodal data. In this work, we propose a novel Dual Adversarial Graph Neural Networks (DAGNN) composed of the dual generative adversarial networks and the multi-hop graph neural networks, which learn modality-invariant and discriminative common representations for cross-modal retrieval. Firstly, we construct the dual generative adversarial networks to project multimodal data into a common representation space. Secondly, we leverage the multi-hop graph neural networks, in which a layer aggregation mechanism is proposed to exploit multi-hop propagation information, to capture the label correlation dependency and learn inter-dependent classifiers. Comprehensive experiments conducted on two cross-modal retrieval benchmark datasets, NUS-WIDE and MIRFlickr, indicate the superiority of DAGNN",
    "checked": true,
    "id": "e7b04687dc41ea7b2b603a0a6149dc258321301a",
    "semantic_title": "dual adversarial graph neural networks for multi-label cross-modal retrieval",
    "citation_count": 32,
    "authors": [
      "Shengsheng Qian",
      "Dizhan Xue",
      "Huaiwen Zhang",
      "Quan Fang",
      "Changsheng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16346": {
    "title": "KGDet: Keypoint-Guided Fashion Detection",
    "volume": "main",
    "abstract": "Locating and classifying clothes, usually referred to as clothing detection, is a fundamental task in fashion analysis. Motivated by the strong structural characteristics of clothes, we pursue a detection method enhanced by clothing keypoints, which is a compact and effective representation of structures. To incorporate the keypoint cues into clothing detection, we design a simple yet effective Keypoint-Guided clothing Detector, named KGDet. Such a detector can fully utilize information provided by keypoints with the following two aspects: i) integrating local features around keypoints to benefit both classification and regression; ii) generating accurate bounding boxes from keypoints. To effectively incorporate local features , two alternative modules are proposed. One is a multi-column keypoint-encoding-based feature aggregation module; the other is a keypoint-selection-based feature aggregation module. With either of the above modules as a bridge, a cascade strategy is introduced to refine detection performance progressively. Thanks to the keypoints, our KGDet obtains superior performance on the DeepFashion2 dataset and the FLD dataset with high efficiency",
    "checked": true,
    "id": "7b12fa153ebcd81e0cd0f8ba2f160da7397ebc30",
    "semantic_title": "kgdet: keypoint-guided fashion detection",
    "citation_count": 1,
    "authors": [
      "Shenhan Qian",
      "Dongze Lian",
      "Binqiang Zhao",
      "Tong Liu",
      "Bohui Zhu",
      "Hai Li",
      "Shenghua Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16347": {
    "title": "Learning Modulated Loss for Rotated Object Detection",
    "volume": "main",
    "abstract": "Popular rotated detection methods usually use five parameters (coordinates of the central point, width, height, and rotation angle) or eight parameters (coordinates of four vertices) to describe the rotated bounding box and l1 loss as the loss function. In this paper, we argue that the aforementioned integration can cause training instability and performance degeneration. The main reason is the discontinuity of loss which is caused by the contradiction between the definition of the rotated bounding box and the loss function. We refer to the above issues as rotation sensitivity error (RSE) and propose a modulated rotation loss to dismiss the discontinuity of loss. The modulated rotation loss can achieve consistent improvement on the five parameter methods and the eight parameter methods. Experimental results using one stage and two stages detectors demonstrate the effectiveness of our loss. The integrated network achieves competitive performances on several benchmarks including DOTA and UCAS AOD. The code is available at https://github.com/yangxue0827/RotationDetection",
    "checked": true,
    "id": "7322a4580299b322223730ca714a0a951788853a",
    "semantic_title": "learning modulated loss for rotated object detection",
    "citation_count": 194,
    "authors": [
      "Wen Qian",
      "Xue Yang",
      "Silong Peng",
      "Junchi Yan",
      "Yue Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16348": {
    "title": "MANGO: A Mask Attention Guided One-Stage Scene Text Spotter",
    "volume": "main",
    "abstract": "Recently end-to-end scene text spotting has become a popular research topic due to its advantages of global optimization and high maintainability in real applications. Most methods attempt to develop various region of interest (RoI) operations to concatenate the detection part and the sequence recognition part into a two-stage text spotting framework. However, in such framework, the recognition part is highly sensitive to the detected results (e.g., the compactness of text contours). To address this problem, in this paper, we propose a novel Mask AttentioN Guided One-stage text spotting framework named MANGO, in which character sequences can be directly recognized without RoI operation. Concretely, a position-aware mask attention module is developed to generate attention weights on each text instance and its characters. It allows different text instances in an image to be allocated on different feature map channels which are further grouped as a batch of instance features. Finally, a lightweight sequence decoder is applied to generate the character sequences. It is worth noting that MANGO inherently adapts to arbitrary-shaped text spotting and can be trained end-to-end with only coarse position information (e.g., rectangular bounding box) and text annotations. Experimental results show that the proposed method achieves competitive and even new state-of-the-art performance on both regular and irregular text spotting benchmarks, i.e., ICDAR 2013, ICDAR 2015, Total-Text, and SCUT-CTW1500",
    "checked": true,
    "id": "e6053e9db1f1c43fa2e075b94164faa99670ad77",
    "semantic_title": "mango: a mask attention guided one-stage scene text spotter",
    "citation_count": 40,
    "authors": [
      "Liang Qiao",
      "Ying Chen",
      "Zhanzhan Cheng",
      "Yunlu Xu",
      "Yi Niu",
      "Shiliang Pu",
      "Fei Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16349": {
    "title": "REFINE: Prediction Fusion Network for Panoptic Segmentation",
    "volume": "main",
    "abstract": "Panoptic segmentation aims at generating pixel-wise class and instance predictions for each pixel in the input image, which is a challenging task and far more complicated than naively fusing the semantic and instance segmentation results. Prediction fusion is therefore important to achieve accurate panoptic segmentation. In this paper, we present REFINE, pREdiction FusIon NEtwork for panoptic segmentation, to achieve high-quality panoptic segmentation by improving cross-task prediction fusion, and within-task prediction fusion. Our single-model ResNeXt-101 with DCN achieves PQ=51.5 on the COCO dataset, surpassing state-of-the-art performance by a convincing margin and is comparable with ensembled models. Our smaller model with a ResNet-50 backbone achieves PQ=44.9, which is comparable with state-of-the-art methods with larger backbones",
    "checked": true,
    "id": "78a79a7cb5f4d39f7a87980ed7c41c5cd7d990cc",
    "semantic_title": "refine: prediction fusion network for panoptic segmentation",
    "citation_count": 9,
    "authors": [
      "Jiawei Ren",
      "Cunjun Yu",
      "Zhongang Cai",
      "Mingyuan Zhang",
      "Chongsong Chen",
      "Haiyu Zhao",
      "Shuai Yi",
      "Hongsheng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16350": {
    "title": "AutoLR: Layer-wise Pruning and Auto-tuning of Learning Rates in Fine-tuning of Deep Networks",
    "volume": "main",
    "abstract": "Existing fine-tuning methods use a single learning rate over all layers. In this paper, first, we discuss that trends of layer-wise weight variations by fine-tuning using a single learning rate do not match the well-known notion that lower-level layers extract general features and higher-level layers extract specific features. Based on our discussion, we propose an algorithm that improves fine-tuning performance and reduces network complexity through layer-wise pruning and auto-tuning of layer-wise learning rates. The proposed algorithm has verified the effectiveness by achieving state-of-the-art performance on the image retrieval benchmark datasets (CUB-200, Cars-196, Stanford online product, and Inshop). Code is available at https://github.com/youngminPIL/AutoLR",
    "checked": true,
    "id": "c65aa75a17eddf50171f048670319082a1780fe8",
    "semantic_title": "autolr: layer-wise pruning and auto-tuning of learning rates in fine-tuning of deep networks",
    "citation_count": 15,
    "authors": [
      "Youngmin Ro",
      "Jin Young Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16351": {
    "title": "DPFPS: Dynamic and Progressive Filter Pruning for Compressing Convolutional Neural Networks from Scratch",
    "volume": "main",
    "abstract": "Filter pruning is a commonly used method for compressing Convolutional Neural Networks (ConvNets), due to its friendly hardware supporting and flexibility. However, existing methods mostly need a cumbersome procedure, which brings many extra hyper-parameters and training epochs. This is because only using sparsity and pruning stages cannot obtain a satisfying performance. Besides, many works do not consider the difference of pruning ratio across different layers. To overcome these limitations, we propose a novel dynamic and progressive filter pruning (DPFPS) scheme that directly learns a structured sparsity network from Scratch. In particular, DPFPS imposes a new structured sparsity-inducing regularization specifically upon the expected pruning parameters in a dynamic sparsity manner. The dynamic sparsity scheme determines sparsity allocation ratios of different layers and a Taylor series based channel sensitivity criteria is presented to identify the expected pruning parameters. Moreover, we increase the structured sparsity-inducing penalty in a progressive manner. This helps the model to be sparse gradually instead of forcing the model to be sparse at the beginning. Our method solves the pruning ratio based optimization problem by an iterative soft-thresholding algorithm (ISTA) with dynamic sparsity. At the end of the training, we only need to remove the redundant parameters without other stages, such as fine-tuning. Extensive experimental results show that the proposed method is competitive with 11 state-of-the-art methods on both small-scale and large-scale datasets (i.e., CIFAR and ImageNet). Specifically, on ImageNet, we achieve a 44.97% pruning ratio of FLOPs by compressing ResNet-101, even with an increase of 0.12% Top-5 accuracy. Our pruned models and codes are released at https://github.com/taoxvzi/DPFPS",
    "checked": true,
    "id": "e820cc6fa49c094da79c28ff2107854fe235bf5f",
    "semantic_title": "dpfps: dynamic and progressive filter pruning for compressing convolutional neural networks from scratch",
    "citation_count": 19,
    "authors": [
      "Xiaofeng Ruan",
      "Yufan Liu",
      "Bing Li",
      "Chunfeng Yuan",
      "Weiming Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16352": {
    "title": "Efficient Certification of Spatial Robustness",
    "volume": "main",
    "abstract": "Recent work has exposed the vulnerability of computer vision models to vector field attacks. Due to the widespread usage of such models in safety-critical applications, it is crucial to quantify their robustness against such spatial transformations. However, existing work only provides empirical robustness quantification against vector field deformations via adversarial attacks, which lack provable guarantees. In this work, we propose novel convex relaxations, enabling us, for the first time, to provide a certificate of robustness against vector field transformations. Our relaxations are model-agnostic and can be leveraged by a wide range of neural network verifiers. Experiments on various network architectures and different datasets demonstrate the effectiveness and scalability of our method",
    "checked": true,
    "id": "0892b242f64779c95eb7dec11c603555573b45c3",
    "semantic_title": "efficient certification of spatial robustness",
    "citation_count": 21,
    "authors": [
      "Anian Ruoss",
      "Maximilian Baader",
      "Mislav Balunoviƒá",
      "Martin Vechev"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16353": {
    "title": "Semantic Grouping Network for Video Captioning",
    "volume": "main",
    "abstract": "This paper considers a video caption generating network referred to as Semantic Grouping Network (SGN) that attempts (1) to group video frames with discriminating word phrases of partially decoded caption and then (2) to decode those semantically aligned groups in predicting the next word. As consecutive frames are not likely to provide unique information, prior methods have focused on discarding or merging repetitive information based only on the input video. The SGN learns an algorithm to capture the most discriminating word phrases of the partially decoded caption and a mapping that associates each phrase to the relevant video frames - establishing this mapping allows semantically related frames to be clustered, which reduces redundancy. In contrast to the prior methods, the continuous feedback from decoded words enables the SGN to dynamically update the video representation that adapts to the partially decoded caption. Furthermore, a contrastive attention loss is proposed to facilitate accurate alignment between a word phrase and video frames without manual annotations. The SGN achieves state-of-the-art performances by outperforming runner-up methods by a margin of 2.1%p and 2.4%p in a CIDEr-D score on MSVD and MSR-VTT datasets, respectively. Extensive experiments demonstrate the effectiveness and interpretability of the SGN",
    "checked": true,
    "id": "f65f7e7273b1496a191e016318600ba8678b50a1",
    "semantic_title": "semantic grouping network for video captioning",
    "citation_count": 76,
    "authors": [
      "Hobin Ryu",
      "Sunghun Kang",
      "Haeyong Kang",
      "Chang D. Yoo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16354": {
    "title": "Audio-Visual Localization by Synthetic Acoustic Image Generation",
    "volume": "main",
    "abstract": "Acoustic images constitute an emergent data modality for multimodal scene understanding. Such images have the peculiarity to distinguish the spectral signature of sounds coming from different directions in space, thus providing richer information than the one derived from mono and binaural microphones. However, acoustic images are typically generated by cumbersome microphone arrays, which are not as widespread as ordinary microphones mounted on optical cameras. To exploit this empowered modality while using standard microphones and cameras we propose to leverage the generation of synthetic acoustic images from common audio-video data for the task of audio-visual localization. The generation of synthetic acoustic images is obtained by a novel deep architecture, based on Variational Autoencoder and U-Net models, which is trained to reconstruct the ground truth spatialized audio data collected by a microphone array, from the associated video and its corresponding monaural audio signal. Namely, the model learns how to mimic what an array of microphones can produce in the same conditions. We assess the quality of the generated synthetic acoustic images on the task of unsupervised sound source localization in a qualitative and quantitative manner, while also considering standard generation metrics. Our model is evaluated by considering both multimodal datasets containing acoustic images, used for the training, and unseen datasets containing just monaural audio signals and RGB frames, showing to reach more accurate localization results as compared to the state of the art",
    "checked": true,
    "id": "e0733d590469f08e0568eee05509e6efbe5d9437",
    "semantic_title": "audio-visual localization by synthetic acoustic image generation",
    "citation_count": 3,
    "authors": [
      "Valentina Sanguineti",
      "Pietro Morerio",
      "Alessio Del Bue",
      "Vittorio Murino"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16355": {
    "title": "Enhanced Regularizers for Attributional Robustness",
    "volume": "main",
    "abstract": "Deep neural networks are the default choice of learning models for computer vision tasks. Extensive work has been carried out in recent years on explaining deep models for vision tasks such as classification. However, recent work has shown that it is possible for these models to produce substantially different attribution maps even when two very similar images are given to the network, raising serious questions about trustworthiness. To address this issue, we propose a robust attribution training strategy to improve attributional robustness of deep neural networks. Our method carefully analyzes the requirements for attributional robustness and introduces two new regularizers that preserve a model's attribution map during attacks. Our method surpasses state-of-the-art attributional robustness methods by a margin of approximately 3% to 9% in terms of attribution robustness measures on several datasets including MNIST, FMNIST, Flower and GTSRB",
    "checked": true,
    "id": "3cf4e173598f38b22882d22b99f880ecb26b0c0e",
    "semantic_title": "enhanced regularizers for attributional robustness",
    "citation_count": 10,
    "authors": [
      "Anindya Sarkar",
      "Anirban Sarkar",
      "Vineeth N Balasubramanian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16356": {
    "title": "Progressive Network Grafting for Few-Shot Knowledge Distillation",
    "volume": "main",
    "abstract": "Knowledge distillation has demonstrated encouraging performances in deep model compression. Most existing approaches, however, require massive labeled data to accomplish the knowledge transfer, making the model compression a cumbersome and costly process. In this paper, we investigate the practical few-shot knowledge distillation scenario, where we assume only a few samples without human annotations are available for each category. To this end, we introduce a principled dual-stage distillation scheme tailored for few-shot data. In the first step, we graft the student blocks one by one onto the teacher, and learn the parameters of the grafted block intertwined with those of the other teacher blocks. In the second step, the trained student blocks are progressively connected and then together grafted onto the teacher network, allowing the learned student blocks to adapt themselves to each other and eventually replace the teacher network. Experiments demonstrate that our approach, with only a few unlabeled samples, achieves gratifying results on CIFAR10,CIFAR100, and ILSVRC-2012. On CIFAR10 and CIFAR100, our performances are even on par with those of knowledge distillation schemes that utilize the full datasets. The source code is available at https://github.com/zju-vipa/NetGraft",
    "checked": true,
    "id": "883ea3b74ec1e26ad20f2c5c94f45e0d6db16364",
    "semantic_title": "progressive network grafting for few-shot knowledge distillation",
    "citation_count": 31,
    "authors": [
      "Chengchao Shen",
      "Xinchao Wang",
      "Youtan Yin",
      "Jie Song",
      "Sihui Luo",
      "Mingli Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16357": {
    "title": "Social-DPF: Socially Acceptable Distribution Prediction of Futures",
    "volume": "main",
    "abstract": "We consider long-term path forecasting problems in crowds, where future sequence trajectories are generated given a short observation. Recent methods for this problem have focused on modeling social interactions and predicting multi-modal futures. However, it is not easy for machines to successfully consider social interactions, such as avoiding collisions while considering the uncertainty of futures under a highly interactive and dynamic scenario. In this paper, we propose a model that incorporates multiple interacting motion sequences jointly and predicts multi-modal socially acceptable distributions of futures. Specifically, we introduce a new aggregation mechanism for social interactions, which selectively models long-term inter-related dynamics between movements in a shared environment through a message passing mechanism. Moreover, we propose a loss function that not only accesses how accurate the estimated distributions of the futures are but also considers collision avoidance. We further utilize mixture density functions to describe the trajectories and learn the multi-modality of future paths. Extensive experiments over several trajectory prediction benchmarks demonstrate that our method is able to forecast socially acceptable distributions in complex scenarios",
    "checked": true,
    "id": "d2c8117a6843fb8a628067c4d15d85f8a8ec4245",
    "semantic_title": "social-dpf: socially acceptable distribution prediction of futures",
    "citation_count": 5,
    "authors": [
      "Xiaodan Shi",
      "Xiaowei Shao",
      "Guangming Wu",
      "Haoran Zhang",
      "Zhiling Guo",
      "Renhe Jiang",
      "Ryosuke Shibasaki"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16358": {
    "title": "Robust Knowledge Transfer via Hybrid Forward on the Teacher-Student Model",
    "volume": "main",
    "abstract": "When adopting deep neural networks for a new vision task, a common practice is to start with fine-tuning some off-the-shelf well-trained network models from the community. Since a new task may require training a different network architecture with new domain data, taking advantage of off-the-shelf models is not trivial and generally requires considerable try-and-error and parameter tuning. In this paper, we denote a well-trained model as a teacher network and a model for the new task as a student network. We aim to ease the efforts of transferring knowledge from the teacher to the student network, robust to the gaps between their network architectures, domain data, and task definitions. Specifically, we propose a hybrid forward scheme in training the teacher-student models, alternately updating layer weights of the student model. The key merit of our hybrid forward scheme is on the dynamical balance between the knowledge transfer loss and task specific loss in training. We demonstrate the effectiveness of our method on a variety of tasks, e.g., model compression, segmentation, and detection, under a variety of knowledge transfer settings",
    "checked": true,
    "id": "e67acfc16e7adca719d568a14a3d8f6f14d8a25f",
    "semantic_title": "robust knowledge transfer via hybrid forward on the teacher-student model",
    "citation_count": 9,
    "authors": [
      "Liangchen Song",
      "Jialian Wu",
      "Ming Yang",
      "Qian Zhang",
      "Yuan Li",
      "Junsong Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16359": {
    "title": "AttaNet: Attention-Augmented Network for Fast and Accurate Scene Parsing",
    "volume": "main",
    "abstract": "Two factors have proven to be very important to the performance of semantic segmentation models: global context and multi-level semantics. However, generating features that capture both factors always leads to high computational complexity, which is problematic in real-time scenarios. In this paper, we propose a new model, called Attention-Augmented Network (AttaNet), to capture both global context and multi-level semantics while keeping the efficiency high. AttaNet consists of two primary modules: Strip Attention Module (SAM) and Attention Fusion Module (AFM). Viewing that in challenging images with low segmentation accuracy, there are a significantly larger amount of vertical strip areas than horizontal ones, SAM utilizes a striping operation to reduce the complexity of encoding global context in the vertical direction drastically while keeping most of contextual information, compared to the non-local approaches. Moreover, AFM follows a cross-level aggregation strategy to limit the computation, and adopts an attention strategy to weight the importance of different levels of features at each pixel when fusing them, obtaining an efficient multi-level representation. We have conducted extensive experiments on two semantic segmentation benchmarks, and our network achieves different levels of speed/accuracy trade-offs on Cityscapes, e.g., 71 FPS/79.9% mIoU, 130 FPS/78.5% mIoU, and 180 FPS/70.1% mIoU, and leading performance on ADE20K as well",
    "checked": true,
    "id": "79e25185f3b03aba9e12cb70c50e79c5da5c1479",
    "semantic_title": "attanet: attention-augmented network for fast and accurate scene parsing",
    "citation_count": 31,
    "authors": [
      "Qi Song",
      "Kangfu Mei",
      "Rui Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16360": {
    "title": "To Choose or to Fuse? Scale Selection for Crowd Counting",
    "volume": "main",
    "abstract": "In this paper, we address the large scale variation problem in crowd counting by taking full advantage of the multi-scale feature representations in a multi-level network. We implement such an idea by keeping the counting error of a patch as small as possible with a proper feature level selection strategy, since a specific feature level tends to perform better for a certain range of scales. However, without scale annotations, it is sub-optimal and error-prone to manually assign the predictions for heads of different scales to specific feature levels. Therefore, we propose a Scale-Adaptive Selection Network (SASNet), which automatically learns the internal correspondence between the scales and the feature levels. Instead of directly using the predictions from the most appropriate feature level as the final estimation, our SASNet also considers the predictions from other feature levels via weighted average, which helps to mitigate the gap between discrete feature levels and continuous scale variation. Since the heads in a local patch share roughly a same scale, we conduct the adaptive selection strategy in a patch-wise style. However, pixels within a patch contribute different counting errors due to the various difficulty degrees of learning. Thus, we further propose a Pyramid Region Awareness Loss (PRA Loss) to recursively select the most hard sub-regions within a patch until reaching the pixel level. With awareness of whether the parent patch is over-estimated or under-estimated, the fine-grained optimization with the PRA Loss for these region-aware hard pixels helps to alleviate the inconsistency problem between training target and evaluation metric. The state-of-the-art results on four datasets demonstrate the superiority of our approach. The code will be available at: https://github.com/TencentYoutuResearch/CrowdCounting-SASNet",
    "checked": true,
    "id": "b5b51d24a7b6ebb71b003f6b64ceb54d8fdf38ee",
    "semantic_title": "to choose or to fuse? scale selection for crowd counting",
    "citation_count": 81,
    "authors": [
      "Qingyu Song",
      "Changan Wang",
      "Yabiao Wang",
      "Ying Tai",
      "Chengjie Wang",
      "Jilin Li",
      "Jian Wu",
      "Jiayi Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16361": {
    "title": "Image Captioning with Context-Aware Auxiliary Guidance",
    "volume": "main",
    "abstract": "Image captioning is a challenging computer vision task, which aims to generate a natural language description of an image. Most recent researches follow the encoder-decoder framework which depends heavily on the previous generated words for the current prediction. Such methods can not effectively take advantage of the future predicted information to learn complete semantics. In this paper, we propose Context-Aware Auxiliary Guidance (CAAG) mechanism that can guide the captioning model to perceive global contexts. Upon the captioning model, CAAG performs semantic attention that selectively concentrates on useful information of the global predictions to reproduce the current generation. To validate the adaptability of the method, we apply CAAG to three popular captioners and our proposal achieves competitive performance on the challenging Microsoft COCO image captioning benchmark, e.g. 132.2 CIDEr-D score on Karpathy split and 130.7 CIDEr-D (c40) score on official online evaluation server",
    "checked": true,
    "id": "4ce5fd3eaea0422c2971111e4d7fe941b64a3c39",
    "semantic_title": "image captioning with context-aware auxiliary guidance",
    "citation_count": 19,
    "authors": [
      "Zeliang Song",
      "Xiaofei Zhou",
      "Zhendong Mao",
      "Jianlong Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16362": {
    "title": "Unsupervised Model Adaptation for Continual Semantic Segmentation",
    "volume": "main",
    "abstract": "We develop an algorithm for adapting a semantic segmentation model that is trained using a labeled source domain to generalize well in an unlabeled target domain. A similar problem has been studied extensively in the unsupervised domain adaptation (UDA) literature, but existing UDA algorithms require access to both the source domain labeled data and the target domain unlabeled data for training a domain agnostic semantic segmentation model. Relaxing this constraint enables a user to adapt pretrained models to generalize in a target domain, without requiring access to source data. To this end, we learn a prototypical distribution for the source domain in an intermediate embedding space. This distribution encodes the abstract knowledge that is learned from the source domain. We then use this distribution for aligning the target domain distribution with the source domain distribution in the embedding space. We provide theoretical analysis and explain conditions under which our algorithm is effective. Experiments on benchmark adaptation tasks demonstrate our method achieves competitive performance even compared with joint UDA approaches",
    "checked": true,
    "id": "2ba1e62fe525da2b5450a3f7811c320950e9f1ba",
    "semantic_title": "unsupervised model adaptation for continual semantic segmentation",
    "citation_count": 43,
    "authors": [
      "Serban Stan",
      "Mohammad Rostami"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16363": {
    "title": "BSN++: Complementary Boundary Regressor with Scale-Balanced Relation Modeling for Temporal Action Proposal Generation",
    "volume": "main",
    "abstract": "Generating human action proposals in untrimmed videos is an important yet challenging task with wide applications. Current methods often suffer from the noisy boundary locations and the inferior quality of confidence scores used for proposal retrieving. In this paper, we present BSN++, a new framework which exploits complementary boundary regressor and relation modeling for temporal proposal generation. First, we propose a novel boundary regressor based on the complementary characteristics of both starting and ending boundary classifiers. Specifically, we utilize the U-shaped architecture with nested skip connections to capture rich contexts and introduce bi-directional boundary matching mechanism to improve boundary precision. Second, to account for the proposal-proposal relations ignored in previous methods, we devise a proposal relation block to which includes two self-attention modules from the aspects of position and channel. Furthermore, we find that there inevitably exists data imbalanced problems in the positive/negative proposals and temporal durations, which harm the model performance on tail distributions. To relieve this issue, we introduce the scale-balanced re-sampling strategy. Extensive experiments are conducted on two popular benchmarks: ActivityNet-1.3 and THUMOS14, which demonstrate that BSN++ achieves the state-of-the-art performance. Not surprisingly, the proposed BSN++ ranked 1st place in the CVPR19 - ActivityNet challenge leaderboard on temporal action localization task",
    "checked": true,
    "id": "1ea2373840d4a5079ecb0132fc47ed37e423bd96",
    "semantic_title": "bsn++: complementary boundary regressor with scale-balanced relation modeling for temporal action proposal generation",
    "citation_count": 79,
    "authors": [
      "Haisheng Su",
      "Weihao Gan",
      "Wei Wu",
      "Yu Qiao",
      "Junjie Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16364": {
    "title": "MangaGAN: Unpaired Photo-to-Manga Translation Based on The Methodology of Manga Drawing",
    "volume": "main",
    "abstract": "Manga is a world popular comic form originated in Japan, which typically employs black-and-white stroke lines and geometric exaggeration to describe humans' appearances, poses, and actions. In this paper, we propose MangaGAN, the first method based on Generative Adversarial Network (GAN) for unpaired photo-to-manga translation. Inspired by the drawing process of experienced manga artists, MangaGAN generates geometric features and converts each facial region into the manga domain with a tailored multi-GANs architecture. For training MangaGAN, we collect a new data-set from a popular manga work with extensive features. To produce high-quality manga faces, we propose a structural smoothing loss to smooth stroke-lines and avoid noisy pixels, and a similarity preserving module to improve the similarity between domains of photo and manga. Extensive experiments show that MangaGAN can produce high-quality manga faces preserving both the facial similarity and manga style, and outperforms other reference methods",
    "checked": true,
    "id": "55f45f009bdf4f8ec0bbf5c1c0da6db0e39508da",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Hao Su",
      "Jianwei Niu",
      "Xuefeng Liu",
      "Qingfeng Li",
      "Jiahe Cui",
      "Ji Wan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16365": {
    "title": "MAMBA: Multi-level Aggregation via Memory Bank for Video Object Detection",
    "volume": "main",
    "abstract": "State-of-the-art video object detection methods maintain a memory structure, either a sliding window or a memory queue, to enhance the current frame using attention mechanisms. However, we argue that these memory structures are not efficient or sufficient because of two implied operations: (1) concatenating all features in memory for enhancement, leading to a heavy computational cost; (2) frame-wise memory updating, preventing the memory from capturing more temporal information. In this paper, we propose a multi-level aggregation architecture via memory bank called MAMBA. Specifically, our memory bank employs two novel operations to eliminate disadvantages of existing methods: (1) light-weight key-set construction which can significantly reduce the computational cost; (2) fine-grained feature-wise updating strategy which enables our method to utilize knowledge from the whole video. To better enhance features from complementary levels, i.e., feature maps and proposals, we further propose a generalized enhancement operation (GEO) to aggregate multi-level features in a unified manner. We conduct extensive evaluations on the challenging ImageNetVID dataset. Compared with existing state-of-the-art methods, our method achieves superior performance in terms of both speed and accuracy. More remarkably, MAMBA achieves mAP of 83.7%/84.6% at 12.6/9.1 FPS with ResNet-101",
    "checked": true,
    "id": "51aac90aab8afb43e8ff20ffe5e6887daad238fa",
    "semantic_title": "mamba: multi-level aggregation via memory bank for video object detection",
    "citation_count": 24,
    "authors": [
      "Guanxiong Sun",
      "Yang Hua",
      "Guosheng Hu",
      "Neil Robertson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16366": {
    "title": "Deep Probabilistic Imaging: Uncertainty Quantification and Multi-modal Solution Characterization for Computational Imaging",
    "volume": "main",
    "abstract": "Computational image reconstruction algorithms generally produce a single image without any measure of uncertainty or confidence. Regularized Maximum Likelihood (RML) and feed-forward deep learning approaches for inverse problems typically focus on recovering a point estimate. This is a serious limitation when working with under-determined imaging systems, where it is conceivable that multiple image modes would be consistent with the measured data. Characterizing the space of probable images that explain the observational data is therefore crucial. In this paper, we propose a variational deep probabilistic imaging approach to quantify reconstruction uncertainty. Deep Probabilistic Imaging (DPI) employs an untrained deep generative model to estimate a posterior distribution of an unobserved image. This approach does not require any training data; instead, it optimizes the weights of a neural network to generate image samples that fit a particular measurement dataset. Once the network weights have been learned, the posterior distribution can be efficiently sampled. We demonstrate this approach in the context of interferometric radio imaging, which is used for black hole imaging with the Event Horizon Telescope, and compressed sensing Magnetic Resonance Imaging (MRI)",
    "checked": true,
    "id": "0260c69e347ad2f47f65d43916425933bbde6b69",
    "semantic_title": "deep probabilistic imaging: uncertainty quantification and multi-modal solution characterization for computational imaging",
    "citation_count": 37,
    "authors": [
      "He Sun",
      "Katherine L. Bouman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16367": {
    "title": "Domain General Face Forgery Detection by Learning to Weight",
    "volume": "main",
    "abstract": "In this paper, we propose a domain-general model, termed learning-to-weight (LTW), that guarantees face detection performance across multiple domains, particularly the target domains that are never seen before. However, various face forgery methods cause complex and biased data distributions, making it challenging to detect fake faces in unseen domains. We argue that different faces contribute differently to a detection model trained on multiple domains, making the model likely to fit domain-specific biases. As such, we propose the LTW approach based on the meta-weight learning algorithm, which configures different weights for face images from different domains. The LTW network can balance the model's generalizability across multiple domains. Then, the meta-optimization calibrates the source domain's gradient enabling more discriminative features to be learned. The detection ability of the network is further improved by introducing an intra-class compact loss. Extensive experiments on several commonly used deepfake datasets to demonstrate the effectiveness of our method in detecting synthetic faces. Code and supplemental material are available at https://github.com/skJack/LTW",
    "checked": true,
    "id": "a4a9e86d06ca2eb6d2e6b17c9948e0e0cbd38815",
    "semantic_title": "domain general face forgery detection by learning to weight",
    "citation_count": 58,
    "authors": [
      "Ke Sun",
      "Hong Liu",
      "Qixiang Ye",
      "Yue Gao",
      "Jianzhuang Liu",
      "Ling Shao",
      "Rongrong Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16368": {
    "title": "Object-Centric Image Generation from Layouts",
    "volume": "main",
    "abstract": "We begin with the hypothesis that a model must be able to understand individual objects and relationships between objects in order to generate complex scenes with multiple objects well. Our layout-to-image-generation method, which we call Object-Centric Generative Adversarial Network (or OC-GAN), relies on a novel Scene-Graph Similarity Module (SGSM). The SGSM learns representations of the spatial relationships between objects in the scene, which lead to our model's improved layout-fidelity. We also propose changes to the conditioning mechanism of the generator that enhance its object instance-awareness. Apart from improving image quality, our contributions mitigate two failure modes in previous approaches: (1) spurious objects being generated without corresponding bounding boxes in the layout, and (2) overlapping bounding boxes in the layout leading to merged objects in images. Extensive quantitative evaluation and ablation studies demonstrate the impact of our contributions, with our model outperforming previous state-of-the-art approaches on both the COCO-Stuff and Visual Genome datasets. Finally, we address an important limitation of evaluation metrics used in previous works by introducing SceneFID -- an object-centric adaptation of the popular Fr√©chet Inception Distance metric, that is better suited for multi-object images",
    "checked": true,
    "id": "198333f1f426224de2f36a3ee2aa48e54cf4ba3e",
    "semantic_title": "object-centric image generation from layouts",
    "citation_count": 59,
    "authors": [
      "Tristan Sylvain",
      "Pengchuan Zhang",
      "Yoshua Bengio",
      "R Devon Hjelm",
      "Shikhar Sharma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16369": {
    "title": "Structure-aware Person Image Generation with Pose Decomposition and Semantic Correlation",
    "volume": "main",
    "abstract": "In this paper we tackle the problem of pose guided person image generation, which aims to transfer a person image from the source pose to a novel target pose while maintaining the source appearance. Given the inefficiency of standard CNNs in handling large spatial transformation, we propose a structure-aware flow based method for high-quality person image generation. Specifically, instead of learning the complex overall pose changes of human body, we decompose the human body into different semantic parts (e.g., head, torso, and legs) and apply different networks to predict the flow fields for these parts separately. Moreover, we carefully design the network modules to effectively capture the local and global semantic correlations of features within and among the human parts respectively. Extensive experimental results show that our method can generate high-quality results under large pose discrepancy and outperforms state-of-the-art methods in both qualitative and quantitative comparisons",
    "checked": true,
    "id": "c764790e6d8ea7c475ecb57f0f8b6f81a34b792b",
    "semantic_title": "structure-aware person image generation with pose decomposition and semantic correlation",
    "citation_count": 12,
    "authors": [
      "Jilin Tang",
      "Yi Yuan",
      "Tianjia Shao",
      "Yong Liu",
      "Mengmeng Wang",
      "Kun Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16370": {
    "title": "Gradient Regularized Contrastive Learning for Continual Domain Adaptation",
    "volume": "main",
    "abstract": "Human beings can quickly adapt to environmental changes by leveraging learning experience. However, adapting deep neural networks to dynamic environments by machine learning algorithms remains a challenge. To better understand this issue, we study the problem of continual domain adaptation, where the model is presented with a labelled source domain and a sequence of unlabelled target domains. The obstacles in this problem are both domain shift and catastrophic forgetting. We propose Gradient Regularized Contrastive Learning (GRCL) to solve the obstacles. At the core of our method, gradient regularization plays two key roles: (1) enforcing the gradient not to harm the discriminative ability of source features which can, in turn, benefit the adaptation ability of the model to target domains; (2) constraining the gradient not to increase the classification loss on old target domains, which enables the model to preserve the performance on old target domains when adapting to an in-coming target domain. Experiments on Digits, DomainNet and Office-Caltech benchmarks demonstrate the strong performance of our approach when compared to the state-of-the-art",
    "checked": true,
    "id": "35f9a09a53d1a5c8b006eb86ea5000f890023143",
    "semantic_title": "gradient regularized contrastive learning for continual domain adaptation",
    "citation_count": 38,
    "authors": [
      "Shixiang Tang",
      "Peng Su",
      "Dapeng Chen",
      "Wanli Ouyang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16371": {
    "title": "Adversarial Training Reduces Information and Improves Transferability",
    "volume": "main",
    "abstract": "Recent results show that features of adversarially trained networks for classification, in addition to being robust, enable desirable properties such as invertibility. The latter property may seem counter-intuitive as it is widely accepted by the community that classification models should only capture the minimal information (features) required for the task. Motivated by this discrepancy, we investigate the dual relationship between Adversarial Training and Information Theory. We show that the Adversarial Training can improve linear transferability to new tasks, from which arises a new trade-off between transferability of representations and accuracy on the source task. We validate our results employing robust networks trained on CIFAR-10, CIFAR-100 and ImageNet on several datasets. Moreover, we show that Adversarial Training reduces Fisher information of representations about the input and of the weights about the task, and we provide a theoretical argument which explains the invertibility of deterministic networks without violating the principle of minimality. Finally, we leverage our theoretical insights to remarkably improve the quality of reconstructed images through inversion",
    "checked": true,
    "id": "08e82ca7906efae2e6bf4b9523c38972e509f96a",
    "semantic_title": "adversarial training reduces information and improves transferability",
    "citation_count": 15,
    "authors": [
      "Matteo Terzi",
      "Alessandro Achille",
      "Marco Maggipinto",
      "Gian Antonio Susto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16372": {
    "title": "Adversarial Turing Patterns from Cellular Automata",
    "volume": "main",
    "abstract": "State-of-the-art deep classifiers are intriguingly vulnerable to universal adversarial perturbations: single disturbances of small magnitude that lead to misclassification of most inputs. This phenomena may potentially result in a serious security problem. Despite the extensive research in this area, there is a lack of theoretical understanding of the structure of these perturbations. In image domain, there is a certain visual similarity between patterns, that represent these perturbations, and classical Turing patterns, which appear as a solution of non-linear partial differential equations and are underlying concept of many processes in nature. In this paper, we provide a theoretical bridge between these two different theories, by mapping a simplified algorithm for crafting universal perturbations to (inhomogeneous) cellular automata, the latter is known to generate Turing patterns. Furthermore, we propose to use Turing patterns, generated by cellular automata, as universal perturbations, and experimentally show that they significantly degrade the performance of deep learning models. We found this method to be a fast and efficient way to create a data-agnostic quasi-imperceptible perturbation in the black-box scenario. The source code is available at https://github.com/NurislamT/advTuring",
    "checked": true,
    "id": "c058af5fcc4935ea78bd557c7fa7876785cc8004",
    "semantic_title": "adversarial turing patterns from cellular automata",
    "citation_count": 4,
    "authors": [
      "Nurislam Tursynbek",
      "Ilya Vilkoviskiy",
      "Maria Sindeeva",
      "Ivan Oseledets"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16373": {
    "title": "Artificial Dummies for Urban Dataset Augmentation",
    "volume": "main",
    "abstract": "Existing datasets for training pedestrian detectors in images suffer from limited appearance and pose variation. The most challenging scenarios are rarely included because they are too difficult to capture due to safety reasons, or they are very unlikely to happen. The strict safety requirements in assisted and autonomous driving applications call for an extra high detection accuracy also in these rare situations. Having the ability to generate people images in arbitrary poses, with arbitrary appearances and embedded in different background scenes with varying illumination and weather conditions, is a crucial component for the development and testing of such applications. The contributions of this paper are three-fold. First, we describe an augmentation method for the controlled synthesis of urban scenes containing people, thus producing rare or never-seen situations. This is achieved with a data generator (called DummyNet) with disentangled control of the pose, the appearance, and the target background scene. Second, the proposed generator relies on novel network architecture and associated loss that takes into account the segmentation of the foreground person and its composition into the background scene. Finally, we demonstrate that the data generated by our DummyNet improve the performance of several existing person detectors across various datasets as well as in challenging situations, such as night-time conditions, where only a limited amount of training data is available. In the setup with only day-time data available, we improve the night-time detector by 17% log-average miss rate over the detector trained with the day-time data only",
    "checked": true,
    "id": "3ff24d04b7964b60dab1f7f8db59ab29f556b34d",
    "semantic_title": "artificial dummies for urban dataset augmentation",
    "citation_count": 8,
    "authors": [
      "Anton√≠n Vobeck√Ω",
      "David Hurych",
      "Michal U≈ôiƒç√°≈ô",
      "Patrick P√©rez",
      "Josef Sivic"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16374": {
    "title": "SCNet: Training Inference Sample Consistency for Instance Segmentation",
    "volume": "main",
    "abstract": "Cascaded architectures have brought significant performance improvement in object detection and instance segmentation. However, there are lingering issues regarding the disparity in the Intersection-over-Union (IoU) distribution of the samples between training and inference. This disparity can potentially exacerbate detection accuracy. This paper proposes an architecture referred to as Sample Consistency Network (SCNet) to ensure that the IoU distribution of the samples at training time is close to that at inference time. Furthermore, SCNet incorporates feature relay and utilizes global contextual information to further reinforce the reciprocal relationships among classifying, detecting, and segmenting sub-tasks. Extensive experiments on the standard COCO dataset reveal the effectiveness of the proposed method over multiple evaluation metrics, including box AP, mask AP, and inference speed. In particular, while running 38\\% faster, the proposed SCNet improves the AP of the box and mask predictions by respectively 1.3 and 2.3 points compared to the strong Cascade Mask R-CNN baseline. Code is available at https://github.com/thangvubk/SCNet",
    "checked": true,
    "id": "3fd1263f5c4dc00e6efc7253b55a4244ac350172",
    "semantic_title": "scnet: training inference sample consistency for instance segmentation",
    "citation_count": 48,
    "authors": [
      "Thang Vu",
      "Haeyong Kang",
      "Chang D. Yoo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16375": {
    "title": "Task-Independent Knowledge Makes for Transferable Representations for Generalized Zero-Shot Learning",
    "volume": "main",
    "abstract": "Generalized Zero-Shot Learning (GZSL) targets recognizing new categories by learning transferable image representations. Existing methods find that, by aligning image representations with corresponding semantic labels, the semantic-aligned representations can be transferred to unseen categories. However, supervised by only seen category labels, the learned semantic knowledge is highly task-specific, which makes image representations biased towards seen categories. In this paper, we propose a novel Dual-Contrastive Embedding Network (DCEN) that simultaneously learns task-specific and task-independent knowledge via semantic alignment and instance discrimination. First, DCEN leverages task labels to cluster representations of the same semantic category by cross-modal contrastive learning and exploring semantic-visual complementarity. Besides task-specific knowledge, DCEN then introduces task-independent knowledge by attracting representations of different views of the same image and repelling representations of different images. Compared to high-level seen category supervision, this instance discrimination supervision encourages DCEN to capture low-level visual knowledge, which is less biased toward seen categories and alleviates the representation bias. Consequently, the task-specific and task-independent knowledge jointly make for transferable representations of DCEN, which obtains averaged 4.1% improvement on four public benchmarks",
    "checked": true,
    "id": "08db45d0e427cdde77cc16307a4d13bcb1cd3d55",
    "semantic_title": "task-independent knowledge makes for transferable representations for generalized zero-shot learning",
    "citation_count": 9,
    "authors": [
      "Chaoqun Wang",
      "Xuejin Chen",
      "Shaobo Min",
      "Xiaoyan Sun",
      "Houqiang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16376": {
    "title": "Efficient Object-Level Visual Context Modeling for Multimodal Machine Translation: Masking Irrelevant Objects Helps Grounding",
    "volume": "main",
    "abstract": "Visual context provides grounding information for multimodal machine translation (MMT). However, previous MMT models and probing studies on visual features suggest that visual information is less explored in MMT as it is often redundant to textual information. In this paper, we propose an Object-level Visual Context modeling framework (OVC) to efficiently capture and explore visual information for multimodal machine translation. With detected objects, the proposed OVC encourages MMT to ground translation on desirable visual objects by masking irrelevant objects in the visual modality. We equip the proposed with an additional object-masking loss to achieve this goal. The object-masking loss is estimated according to the similarity between masked objects and the source texts so as to encourage masking source-irrelevant objects. Additionally, in order to generate vision-consistent target words, we further propose a vision-weighted translation loss for OVC. Experiments on MMT datasets demonstrate that the proposed OVC model outperforms state-of-the-art MMT models and analyses show that masking irrelevant objects helps grounding in MMT",
    "checked": true,
    "id": "db5393275c4be3378cb669ae59014fe8c5c92859",
    "semantic_title": "efficient object-level visual context modeling for multimodal machine translation: masking irrelevant objects helps grounding",
    "citation_count": 20,
    "authors": [
      "Dexin Wang",
      "Deyi Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16377": {
    "title": "Temporal Relational Modeling with Self-Supervision for Action Segmentation",
    "volume": "main",
    "abstract": "Temporal relational modeling in video is essential for human action understanding, such as action recognition and action segmentation. Although Graph Convolution Networks (GCNs) have shown promising advantages in relation reasoning on many tasks, it is still a challenge to apply graph convolution networks on long video sequences effectively. The main reason is that large number of nodes (i.e., video frames) makes GCNs hard to capture and model temporal relations in videos. To tackle this problem, in this paper, we introduce an effective GCN module, Dilated Temporal Graph Reasoning Module (DTGRM), designed to model temporal relations and dependencies between video frames at various time spans. In particular, we capture and model temporal relations via constructing multi-level dilated temporal graphs where the nodes represent frames from different moments in video. Moreover, to enhance temporal reasoning ability of the proposed model, an auxiliary self-supervised task is proposed to encourage the dilated temporal graph reasoning module to find and correct wrong temporal relations in videos. Our DTGRM model outperforms state-of-the-art action segmentation models on three challenging datasets: 50Salads, Georgia Tech Egocentric Activities (GTEA), and the Breakfast dataset. The code is available at https://github.com/redwang/DTGRM",
    "checked": true,
    "id": "b20ccb5e53bcc5e76d05d173149d3926bec952fd",
    "semantic_title": "temporal relational modeling with self-supervision for action segmentation",
    "citation_count": 30,
    "authors": [
      "Dong Wang",
      "Di Hu",
      "Xingjian Li",
      "Dejing Dou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16378": {
    "title": "Towards Robust Visual Information Extraction in Real World: New Dataset and Novel Solution",
    "volume": "main",
    "abstract": "Visual Information Extraction (VIE) has attracted considerable attention recently owing to its various advanced applications such as document understanding, automatic marking and intelligent education. Most existing works decoupled this problem into several independent sub-tasks of text spotting (text detection and recognition) and information extraction, which completely ignored the high correlation among them during optimization. In this paper, we propose a robust Visual Information Extraction System (VIES) towards real-world scenarios, which is an unified end-to-end trainable framework for simultaneous text detection, recognition and information extraction by taking a single document image as input and outputting the structured information. Specifically, the information extraction branch collects abundant visual and semantic representations from text spotting for multimodal feature fusion and conversely, provides higher-level semantic clues to contribute to the optimization of text spotting. Moreover, regarding the shortage of public benchmarks, we construct a fully-annotated dataset called EPHOIE (https://github.com/HCIILAB/EPHOIE), which is the first Chinese benchmark for both text spotting and visual information extraction. EPHOIE consists of 1,494 images of examination paper head with complex layouts and background, including a total of 15,771 Chinese handwritten or printed text instances. Compared with the state-of-the-art methods, our VIES shows significant superior performance on the EPHOIE dataset and achieves a 9.01% F-score gain on the widely used SROIE dataset under the end-to-end scenario",
    "checked": true,
    "id": "43c3ccb02ed34b6f38872bc7d75a85d812ac2746",
    "semantic_title": "towards robust visual information extraction in real world: new dataset and novel solution",
    "citation_count": 37,
    "authors": [
      "Jiapeng Wang",
      "Chongyu Liu",
      "Lianwen  Jin",
      "Guozhi Tang",
      "Jiaxin Zhang",
      "Shuaitao Zhang",
      "Qianying Wang",
      "Yaqiang Wu",
      "Mingxiang Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16379": {
    "title": "Self-Domain Adaptation for Face Anti-Spoofing",
    "volume": "main",
    "abstract": "Although current face anti-spoofing methods achieve promising results under intra-dataset testing, they suffer from poor generalization to unseen attacks. Most existing works adopt domain adaptation (DA) or domain generalization (DG) techniques to address this problem. However, the target domain is often unknown during training which limits the utilization of DA methods. DG methods can conquer this by learning domain invariant features without seeing any target data. However, they fail in utilizing the information of target data. In this paper, we propose a self-domain adaptation framework to leverage the unlabeled test domain data at inference. Specifically, a domain adaptor is designed to adapt the model for test domain. In order to learn a better adaptor, a meta-learning based adaptor learning algorithm is proposed using the data of multiple source domains at the training step. At test time, the adaptor is updated using only the test domain data according to the proposed unsupervised adaptor loss to further improve the performance. Extensive experiments on four public datasets validate the effectiveness of the proposed method",
    "checked": true,
    "id": "454b0859346115812730ab2c6a770765b133521c",
    "semantic_title": "self-domain adaptation for face anti-spoofing",
    "citation_count": 34,
    "authors": [
      "Jingjing Wang",
      "Jingyi Zhang",
      "Ying Bian",
      "Youyi Cai",
      "Chunmao Wang",
      "Shiliang Pu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16380": {
    "title": "Weakly Supervised Deep Hyperspherical Quantization for Image Retrieval",
    "volume": "main",
    "abstract": "Deep quantization methods have shown high efficiency on large-scale image retrieval. However, current models heavily rely on ground-truth information, hindering the application of quantization in label-hungry scenarios. A more realistic demand is to learn from inexhaustible uploaded images that are associated with informal tags provided by amateur users. Though such sketchy tags do not obviously reveal the labels, they actually contain useful semantic information for supervising deep quantization. To this end, we propose Weakly-Supervised Deep Hyperspherical Quantization (WSDHQ), which is the first work to learn deep quantization from weakly tagged images. Specifically, 1) we use word embeddings to represent the tags and enhance their semantic information based on a tag correlation graph. 2) To better preserve semantic information in quantization codes and reduce quantization error, we jointly learn semantics-preserving embeddings and supervised quantizer on hypersphere by employing a well-designed fusion layer and tailor-made loss functions. Extensive experiments show that WSDHQ can achieve state-of-art performance in weakly-supervised compact coding",
    "checked": true,
    "id": "00e332ec098862c764072b5e934bd729858160db",
    "semantic_title": "weakly supervised deep hyperspherical quantization for image retrieval",
    "citation_count": 5,
    "authors": [
      "Jinpeng Wang",
      "Bin Chen",
      "Qiang Zhang",
      "Zaiqiao Meng",
      "Shangsong Liang",
      "Shutao Xia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16381": {
    "title": "Camera-Aware Proxies for Unsupervised Person Re-Identification",
    "volume": "main",
    "abstract": "This paper tackles the purely unsupervised person re-identification (Re-ID) problem that requires no annotations. Some previous methods adopt clustering techniques to generate pseudo labels and use the produced labels to train Re-ID models progressively. These methods are relatively simple but effective. However, most clustering-based methods take each cluster as a pseudo identity class, neglecting the large intra-ID variance caused mainly by the change of camera views. To address this issue, we propose to split each single cluster into multiple proxies and each proxy represents the instances coming from the same camera. These camera-aware proxies enable us to deal with large intra-ID variance and generate more reliable pseudo labels for learning. Based on the camera-aware proxies, we design both intra and inter-camera contrastive learning components for our Re-ID model to effectively learn the ID discrimination ability within and across cameras. Meanwhile, a proxy-balanced sampling strategy is also designed, which facilitates our learning further. Extensive experiments on three large-scale Re-ID datasets show that our proposed approach outperforms most unsupervised methods by a significant margin. Especially, on the challenging MSMT17 dataset, we gain 14.3 percent Rank-1 and 10.2 percent mAP improvements when compared to the second place. Code is available at: https://github.com/Terminator8758/CAP-master",
    "checked": true,
    "id": "155746c016f83aa9fbd5c75828f547f8cbb804e0",
    "semantic_title": "camera-aware proxies for unsupervised person re-identification",
    "citation_count": 94,
    "authors": [
      "Menglin Wang",
      "Baisheng Lai",
      "Jianqiang Huang",
      "Xiaojin Gong",
      "Xian-Sheng Hua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16382": {
    "title": "Unsupervised 3D Learning for Shape Analysis via Multiresolution Instance Discrimination",
    "volume": "main",
    "abstract": "We propose an unsupervised method for learning a generic and efficient shape encoding network for different shape analysis tasks. Our key idea is to jointly encode and learn shape and point features from unlabeled 3D point clouds. For this purpose, we adapt HRNet to octree-based convolutional neural networks for jointly encoding shape and point features with fused multiresolution subnetworks and design a simple-yet-efficient Multiresolution Instance Discrimination (MID) loss for jointly learning the shape and point features. Our network takes a 3D point cloud as input and output both shape and point features. After training, Our network is concatenated with simple task-specific back-ends and fine-tuned for different shape analysis tasks. We evaluate the efficacy and generality of our method with a set of shape analysis tasks, including shape classification, semantic shape segmentation, as well as shape registration tasks. With simple back-ends, our network demonstrates the best performance among all unsupervised methods and achieves competitive performance to supervised methods. For fine-grained shape segmentation on the PartNet dataset, our method even surpasses existing supervised methods by a large margin",
    "checked": true,
    "id": "b91c9c9beeaa0760e383fe702e6df10c51eb0a4c",
    "semantic_title": "unsupervised 3d learning for shape analysis via multiresolution instance discrimination",
    "citation_count": 38,
    "authors": [
      "Peng-Shuai Wang",
      "Yu-Qi Yang",
      "Qian-Fang Zou",
      "Zhirong Wu",
      "Yang Liu",
      "Xin Tong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16383": {
    "title": "PGNet: Real-time Arbitrarily-Shaped Text Spotting with Point Gathering Network",
    "volume": "main",
    "abstract": "The reading of arbitrarily-shaped text has received increasing research attention. However, existing text spotters are mostly built on two-stage frameworks or character-based methods, which suffer from either Non-Maximum Suppression (NMS), Region-of-Interest (RoI) operations, or character-level annotations. In this paper, to address the above problems, we propose a novel fully convolutional Point Gathering Network (PGNet) for reading arbitrarily-shaped text in real-time. The PGNet is a single-shot text spotter, where the pixel-level character classification map is learned with proposed PG-CTC loss avoiding the usage of character-level annotations. With a PG-CTC decoder, we gather high-level character classification vectors from two-dimensional space and decode them into text symbols without NMS and RoI operations involved, which guarantees high efficiency. Additionally, reasoning the relations between each character and its neighbors, a graph refinement module (GRM) is proposed to optimize the coarse recognition and improve the end-to-end performance. Experiments prove that the proposed method achieves competitive accuracy, meanwhile significantly improving the running speed. In particular, in Total-Text, it runs at 46.7 FPS, surpassing the previous spotters with a large margin",
    "checked": true,
    "id": "0ad0205d39af43cbf1cd560152d0f34ef85d56e6",
    "semantic_title": "pgnet: real-time arbitrarily-shaped text spotting with point gathering network",
    "citation_count": 40,
    "authors": [
      "Pengfei Wang",
      "Chengquan Zhang",
      "Fei Qi",
      "Shanshan Liu",
      "Xiaoqiang Zhang",
      "Pengyuan Lyu",
      "Junyu Han",
      "Jingtuo Liu",
      "Errui Ding",
      "Guangming Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16384": {
    "title": "Dynamic Position-aware Network for Fine-grained Image Recognition",
    "volume": "main",
    "abstract": "Most weakly supervised fine-grained image recognition (WFGIR) approaches predominantly focus on learning the discriminative details which contain the visual variances and position clues. The position clues can be indirectly learnt by utilizing context information of discriminative visual content. However, this will cause the selected discriminative regions containing some non-discriminative information introduced by the position clues. These analysis motivate us to directly introduce position clues into visual content to only focus on the visual variances, achieving more precise discriminative region localization. Though important, position modelling usually requires significant pixel/region annotations and therefore is labor-intensive. To address this issue, we propose an end-to-end Dynamic Position-aware Network (DP-Net) to directly incorporate the position clues into visual content and dynamically align them without extra annotations, which eliminates the effect of position information for visual variances of subcategories. In particular, the DP-Net consists of: 1) Position Encoding Module, which learns a set of position-aware parts by directly adding the learnable position information into the horizontal/vertical visual content of images; 2) Position-vision Aligning Module, which dynamically aligns both visual content and learnable position information via performing graph convolution on position-aware parts; 3) Position-vision Reorganization Module, which projects the aligned position clues and visual content into the Euclidean space to construct a position-aware feature maps. Finally, the position-aware feature maps are used which is implicitly applied the aligned visual content and position clues for more accurate discriminative regions localization. Extensive experiments verify that DP-Net yields the best performance under the same settings with most competitive approaches, on CUB Bird, Stanford-Cars, and FGVC Aircraft datasets",
    "checked": true,
    "id": "cf0723eab4c75e5b6bdfeca38aa80e76531aaa1b",
    "semantic_title": "dynamic position-aware network for fine-grained image recognition",
    "citation_count": 19,
    "authors": [
      "Shijie Wang",
      "Haojie Li",
      "Zhihui Wang",
      "Wanli Ouyang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16385": {
    "title": "Co-mining: Self-Supervised Learning for Sparsely Annotated Object Detection",
    "volume": "main",
    "abstract": "Object detectors usually achieve promising results with the supervision of complete instance annotations. However, their performance is far from satisfactory with sparse instance annotations. Most existing methods for sparsely annotated object detection either re-weight the loss of hard negative samples or convert the unlabeled instances into ignored regions to reduce the interference of false negatives. We argue that these strategies are insufficient since they can at most alleviate the negative effect caused by missing annotations. In this paper, we propose a simple but effective mechanism, called Co-mining, for sparsely annotated object detection. In our Co-mining, two branches of a siamese network predict the pseudo-label sets for each other. To enhance multi-view learning and better mine unlabeled instances, the original image and corresponding augmented image are used as the inputs of two branches of the siamese network, respectively. Co-mining can serve as a general training mechanism applied to most of modern object detectors. Experiments are performed on MS COCO dataset with three different sparsely annotated settings using two typical frameworks: anchor-based detector RetinaNet and anchor-free detector FCOS. Experimental results show that our Co-mining with RetinaNet achieves 1.4%‚àº2.1% improvements compared with different baselines and surpasses existing methods under the same sparsely annotated setting",
    "checked": true,
    "id": "eaeaae0a559d0bf48f9a785f856c9ec7138a3eea",
    "semantic_title": "co-mining: self-supervised learning for sparsely annotated object detection",
    "citation_count": 24,
    "authors": [
      "Tiancai Wang",
      "Tong Yang",
      "Jiale Cao",
      "Xiangyu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16386": {
    "title": "Very Important Person Localization in Unconstrained Conditions: A New Benchmark",
    "volume": "main",
    "abstract": "This paper presents a new high-quality dataset for Very Important Person Localization (VIPLoc), named Unconstrained-7k. Generally, current datasets: 1) are limited in scale; 2) built under simple and constrained conditions, where the number of disturbing non-VIPs is not large, the scene is relatively simple, and the face of VIP is always in frontal view and salient. To tackle these problems, the proposed Unconstrained-7k dataset is featured in two aspects. First, it contains over 7,000 annotated images, making it the largest VIPLoc dataset under unconstrained conditions to date. Second, our dataset is collected freely on the Internet, including multiple scenes, where images are in unconstrained conditions. VIPs in the new dataset are in different settings, e.g., large view variation, varying sizes, occluded, and complex scenes. Meanwhile, each image has more persons (> 20), making the dataset more challenging. As a minor contribution, motivated by the observation that VIPs are highly related to not only neighbors but also iconic objects, this paper proposes a Joint Social Relation and Individual Interaction Graph Neural Networks (JSRII-GNN) for VIPLoc. Experiments show that the JSRII-GNN yields competitive accuracy on NCAA (National Collegiate Athletic Association), MS (Multi-scene), and Unconstrained-7k datasets. https://github.com/xiaowang1516/VIPLoc",
    "checked": true,
    "id": "d7fae2c94cf2f9b7601b350db8a0f80b93422a9a",
    "semantic_title": "very important person localization in unconstrained conditions: a new benchmark",
    "citation_count": 4,
    "authors": [
      "Xiao Wang",
      "Zheng Wang",
      "Toshihiko Yamasaki",
      "Wenjun Zeng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16387": {
    "title": "Teacher Guided Neural Architecture Search for Face Recognition",
    "volume": "main",
    "abstract": "Knowledge distillation is an effective tool to compress large pre-trained convolutional neural networks (CNNs) or their ensembles into models applicable to mobile and embedded devices. However, with expected flops or latency, existing methods are hand-crafted heuristics. They propose to pre-define the target student network for knowledge distillation, which may be sub-optimal because it requires much effort to explore a powerful student from the large design space. In this paper, we develop a novel teacher guided neural architecture search method to directly search for a student network with flexible channel and layer sizes. Specifically, we define the search space as the number of the channels/layers, which is sampled based on the probability distribution and is learned by minimizing the search objective of the student network. The maximum probability for the size in each distribution serves as the final searched width and depth of the target student network. Extensive experiments on a variety of face recognition benchmarks have demonstrated the superiority of our method over the state-of-the-art alternatives",
    "checked": true,
    "id": "6591929294e26b330676a7cde4bdfccdd7dd3b84",
    "semantic_title": "teacher guided neural architecture search for face recognition",
    "citation_count": 6,
    "authors": [
      "Xiaobo Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16388": {
    "title": "Deep Multi-Task Learning for Diabetic Retinopathy Grading in Fundus Images",
    "volume": "main",
    "abstract": "Recent years have witnessed the growing interest in disease severity grading, especially for ocular diseases based on fundus images. The existing grading methods are usually trained with high resolution (HR) images. However, the grading performance decreases a lot given low resolution (LR) images, which are common in practice. In this paper, we mainly focus on diabetic retinopathy (DR) grading with LR fundus images. According to our analysis on the DR task, we find that: 1) image super-resolution (ISR) can boost the performance of DR grading and lesion segmentation; 2) the lesion segmentation regions of fundus images are highly consistent with pathological regions for DR grading. Thus, we propose a deep multi-task learning based DR grading (DeepMT-DR) method for LR fundus images, which simultaneously handles the auxiliary tasks of ISR and lesion segmentation. Specifically, based on our findings, we propose a hierarchical deep learning structure that simultaneously processes the low-level task of ISR, the mid-level task of lesion segmentation and the high-level task of DR grading. Moreover, a novel task-aware loss is developed to encourage ISR to focus on the pathological regions for its subsequent tasks: lesion segmentation and DR grading. Extensive experimental results show that our DeepMT-DR method significantly outperforms other state-of-the-art methods for DR grading over two public datasets. In addition, our method achieves comparable performance in two auxiliary tasks of ISR and lesion segmentation",
    "checked": true,
    "id": "22d07522a1ece6d81d34d08abfab73d1962ff081",
    "semantic_title": "deep multi-task learning for diabetic retinopathy grading in fundus images",
    "citation_count": 19,
    "authors": [
      "Xiaofei Wang",
      "Mai Xu",
      "Jicong Zhang",
      "Lai Jiang",
      "Liu Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16389": {
    "title": "Confidence-aware Non-repetitive Multimodal Transformers for TextCaps",
    "volume": "main",
    "abstract": "When describing an image, reading text in the visual scene is crucial to understand the key information. Recent work explores the TextCaps task, i.e. image captioning with reading Optical Character Recognition (OCR) tokens, which requires models to read text and cover them in generated captions. Existing approaches fail to generate accurate descriptions because of their (1) poor reading ability; (2) inability to choose the crucial words among all extracted OCR tokens; (3) repetition of words in predicted captions. To this end, we propose a Confidence-aware Non-repetitive Multimodal Transformers (CNMT) to tackle the above challenges. Our CNMT consists of a reading, a reasoning and a generation modules, in which Reading Module employs better OCR systems to enhance text reading ability and a confidence embedding to select the most noteworthy tokens. To address the issue of word redundancy in captions, our Generation Module includes a repetition mask to avoid predicting repeated word in captions. Our model outperforms state-of-the-art models on TextCaps dataset, improving from 81.0 to 93.0 in CIDEr. Our source code is publicly available",
    "checked": true,
    "id": "4231637c09d5fa8864cdf85256ed45bff0656eec",
    "semantic_title": "confidence-aware non-repetitive multimodal transformers for textcaps",
    "citation_count": 17,
    "authors": [
      "Zhaokai Wang",
      "Renda Bao",
      "Qi Wu",
      "Si Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16390": {
    "title": "Geodesic-HOF: 3D Reconstruction Without Cutting Corners",
    "volume": "main",
    "abstract": "Single-view 3D object reconstruction is a challenging fundamental problem in machine perception, largely due to the morphological diversity of objects in the natural world. In particular, high curvature regions are not always represented accurately by methods trained with common set-based loss functions such as Chamfer Distance, resulting in reconstructions short-circuiting the surface or \"cutting corners.\" To address this issue, we propose an approach to 3D reconstruction that embeds points on the surface of an object into a higher-dimensional space that captures both the original 3D surface as well as geodesic distances between points on the surface of the object. The precise specification of these additional \"lifted\" coordinates ultimately yields useful surface information without requiring excessive additional computation during either training or testing, in comparison with existing approaches. Our experiments show that taking advantage of these learned lifted coordinates yields better performance for estimating surface normals and generating surfaces than using point cloud reconstructions alone. Further, we find that this learned geodesic embedding space provides useful information for applications such as unsupervised object decomposition",
    "checked": true,
    "id": "e7f5a2793ff1eb1581fad2c6b1b28c7cc57bec1a",
    "semantic_title": "geodesic-hof: 3d reconstruction without cutting corners",
    "citation_count": 2,
    "authors": [
      "Ziyun Wang",
      "Eric A. Mitchell",
      "Volkan Isler",
      "Daniel D. Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16391": {
    "title": "C2F-FWN: Coarse-to-Fine Flow Warping Network for Spatial-Temporal Consistent Motion Transfer",
    "volume": "main",
    "abstract": "Human video motion transfer (HVMT) aims to synthesize videos that one person imitates other persons' actions. Although existing GAN-based HVMT methods have achieved great success, they either fail to preserve appearance details due to the loss of spatial consistency between synthesized and exemplary images, or generate incoherent video results due to the lack of temporal consistency among video frames. In this paper, we propose Coarse-to-Fine Flow Warping Network (C2F-FWN) for spatial-temporal consistent HVMT. Particularly, C2F-FWN utilizes coarse-to-fine flow warping and Layout-Constrained Deformable Convolution (LC-DConv) to improve spatial consistency, and employs Flow Temporal Consistency (FTC) Loss to enhance temporal consistency. In addition, provided with multi-source appearance inputs, C2F-FWN can support appearance attribute editing with great flexibility and efficiency. Besides public datasets, we also collected a large-scale HVMT dataset named SoloDance for evaluation. Extensive experiments conducted on our SoloDance dataset and the iPER dataset show that our approach outperforms state-of-art HVMT methods in terms of both spatial and temporal consistency. Source code and the SoloDance dataset are available at https://github.com/wswdx/C2F-FWN",
    "checked": true,
    "id": "6f00163263f974b9d38b5bd399b1ed15d085cecd",
    "semantic_title": "c2f-fwn: coarse-to-fine flow warping network for spatial-temporal consistent motion transfer",
    "citation_count": 13,
    "authors": [
      "Dongxu Wei",
      "Xiaowei Xu",
      "Haibin Shen",
      "Kejie Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16392": {
    "title": "Semantic Consistency Networks for 3D Object Detection",
    "volume": "main",
    "abstract": "Detecting 3D objects from point clouds is a significant yet challenging issue in many applications. While most existing approaches seek to leverage geometric information of point clouds, few studies accommodate the inherent semantic characteristics of each point and the consistency between the geometric and semantic cues. In this work, we propose a novel semantic consistency network (SCNet) driven by a natural principle: the class of a predicted 3D bounding box should be consistent with the classes of all the points inside this box. Specifically, our SCNet consists of a feature extraction structure, a detection decision structure, and a semantic segmentation structure. In inference, the feature extraction and the detection decision structures are used to detect 3D objects. In training, the semantic segmentation structure is jointly trained with the other two structures to produce more robust and applicative model parameters. A novel semantic consistency loss is proposed to regulate the output 3D object boxes and the segmented points to boost the performance. Our model is evaluated on two challenging datasets and achieves comparable results to the state-of-the-art methods",
    "checked": true,
    "id": "7685d32091f5620b059995fcf446b259361e0ee5",
    "semantic_title": "semantic consistency networks for 3d object detection",
    "citation_count": 3,
    "authors": [
      "Wenwen Wei",
      "Ping Wei",
      "Nanning Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16393": {
    "title": "Holistic Multi-View Building Analysis in the Wild with Projection Pooling",
    "volume": "main",
    "abstract": "We address six different classification tasks related to fine-grained building attributes: construction type, number of floors, pitch and geometry of the roof, facade material, and occupancy class. Tackling such a remote building analysis problem became possible only recently due to growing large-scale datasets of urban scenes. To this end, we introduce a new benchmarking dataset, consisting of 49426 images (top-view and street-view) of 9674 buildings. These photos are further assembled, together with the geometric metadata. The dataset showcases various real-world challenges, such as occlusions, blur, partially visible objects, and a broad spectrum of buildings. We propose a new \\emph{projection pooling layer}, creating a unified, top-view representation of the top-view and the side views in a high-dimensional space. It allows us to utilize the building and imagery metadata seamlessly. Introducing this layer improves classification accuracy -- compared to highly tuned baseline models -- indicating its suitability for building analysis",
    "checked": true,
    "id": "8b7bd1173b5796bdb3f96b32c715aa2633fe05e8",
    "semantic_title": "holistic multi-view building analysis in the wild with projection pooling",
    "citation_count": 5,
    "authors": [
      "Zbigniew Wojna",
      "Krzysztof Maziarz",
      "≈Åukasz Jocz",
      "Robert Pa≈Çuba",
      "Robert Kozikowski",
      "Iason Kokkinos"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16394": {
    "title": "Stereopagnosia: Fooling Stereo Networks with Adversarial Perturbations",
    "volume": "main",
    "abstract": "We study the effect of adversarial perturbations of images on the estimates of disparity by deep learning models trained for stereo. We show that imperceptible additive perturbations can significantly alter the disparity map, and correspondingly the perceived geometry of the scene. These perturbations not only affect the specific model they are crafted for, but transfer to models with different architecture, trained with different loss functions. We show that, when used for adversarial data augmentation, our perturbations result in trained models that are more robust, without sacrificing overall accuracy of the model. This is unlike what has been observed in image classification, where adding the perturbed images to the training set makes the model less vulnerable to adversarial perturbations, but to the detriment of overall accuracy. We test our method using the most recent stereo networks and evaluate their performance on public benchmark datasets",
    "checked": true,
    "id": "090e227b01a96340e683a6f661f64c7eb93c3741",
    "semantic_title": "stereopagnosia: fooling stereo networks with adversarial perturbations",
    "citation_count": 19,
    "authors": [
      "Alex Wong",
      "Mukund Mundhra",
      "Stefano Soatto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16395": {
    "title": "Generalising without Forgetting for Lifelong Person Re-Identification",
    "volume": "main",
    "abstract": "Existing person re-identification (Re-ID) methods mostly prepare all training data in advance, while real-world Re-ID data are inherently captured over time or from different locations, which requires a model to be incrementally generalised from sequential learning of piecemeal new data without forgetting what is already learned. In this work, we call this lifelong person Re-ID, characterised by solving a problem of unseen class identification subject to continuous new domain generalisation and adaptation with class imbalanced learning. We formulate a new Generalising without Forgetting method (GwFReID) for lifelong Re-ID and design a comprehensive learning objective that accounts for classification coherence, distribution coherence and representation coherence in a unified framework. This design helps to simultaneously learn new information, distil old knowledge and solve class imbalance, which enables GwFReID to incrementally improve model generalisation without catastrophic forgetting of what is already learned. Extensive experiments on eight Re-ID benchmarks, CIFAR-100 and ImageNet show the superiority of GwFReID over the state-of-the-art methods",
    "checked": true,
    "id": "24d3f71ff6dea01acd60280a17fc69371bdf4943",
    "semantic_title": "generalising without forgetting for lifelong person re-identification",
    "citation_count": 17,
    "authors": [
      "Guile Wu",
      "Shaogang Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16396": {
    "title": "Decentralised Learning from Independent Multi-Domain Labels for Person Re-Identification",
    "volume": "main",
    "abstract": "Deep learning has been successful for many computer vision tasks due to the availability of shared and centralised large-scale training data. However, increasing awareness of privacy concerns poses new challenges to deep learning, especially for human subject related recognition such as person re-identification (Re-ID). In this work, we solve the Re-ID problem by decentralised learning from non-shared private training data distributed at multiple user sites of independent multi-domain label spaces. We propose a novel paradigm called Federated Person Re-Identification (FedReID) to construct a generalisable global model (a central server) by simultaneously learning with multiple privacy-preserved local models (local clients). Specifically, each local client receives global model updates from the server and trains a local model using its local data independent from all the other clients. Then, the central server aggregates transferrable local model updates to construct a generalisable global feature embedding model without accessing local data so to preserve local privacy. This client-server collaborative learning process is iteratively performed under privacy control, enabling FedReID to realise decentralised learning without sharing distributed data nor collecting any centralised data. Extensive experiments on ten Re-ID benchmarks show that FedReID achieves compelling generalisation performance beyond any locally trained models without using shared training data, whilst inherently protects the privacy of each local client. This is uniquely advantageous over contemporary Re-ID methods",
    "checked": true,
    "id": "193a816d4eeacd0935df5614ad36a066b5462fd0",
    "semantic_title": "decentralised learning from independent multi-domain labels for person re-identification",
    "citation_count": 15,
    "authors": [
      "Guile Wu",
      "Shaogang Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16397": {
    "title": "Region-aware Global Context Modeling for Automatic Nerve Segmentation from Ultrasound Images",
    "volume": "main",
    "abstract": "We present a novel deep learning model equipped with a new region-aware global context modeling technique for automatic nerve segmentation from ultrasound images, which is a challenging task due to (1) the large variation and blurred boundaries of targets, (2) the large amount of speckle noise in ultrasound images, and (3) the inherent real-time requirement of this task. It is essential to efficiently capture long-range dependencies by global context modeling for a segmentation network to overcome these challenges. Traditional global context modeling techniques usually explore pixel-aware correlations to establish long-range dependencies, which are usually computation-intensive and greatly degrade time performance. In addition, in this application, pixel-aware modeling may inevitably introduce much speckle noise in the computation and potentially degrade segmentation performance. In this paper, we propose a novel region-aware modeling technique to establish long-range dependencies based on different regions to improve segmentation accuracy while maintaining real-time performance; we call it region-aware pyramid aggregation (RPA) module. In order to adaptively divide the feature maps into a set of semantic-independent regions, we develop an attention mechanism and integrate it into the spatial pyramid network to evaluate the semantic similarity of different regions. We further develop an adaptive pyramid fusion (APF) module to dynamically fuse the multi-level features generated from the decoder to refining the segmentation results. We conducted extensive experiments on a famous public ultrasound nerve image segmentation dataset. Experimental results demonstrate that our method consistently outperforms our rivals in terms of segmentation accuracy. The code is available at https://github.com/jsonliu-szu/RAGCM",
    "checked": true,
    "id": "581cf8bfef6e60685f8326957e783f5e1203c70c",
    "semantic_title": "region-aware global context modeling for automatic nerve segmentation from ultrasound images",
    "citation_count": 11,
    "authors": [
      "Huisi Wu",
      "Jiasheng Liu",
      "Wei Wang",
      "Zhenkun Wen",
      "Jing Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16398": {
    "title": "Precise Yet Efficient Semantic Calibration and Refinement in ConvNets for Real-time Polyp Segmentation from Colonoscopy Videos",
    "volume": "main",
    "abstract": "We propose a novel convolutional neural network (ConvNet) equipped with two new semantic calibration and refinement approaches for automatic polyp segmentation from colonoscopy videos. While ConvNets set state-of-the-are performance for this task, it is still difficult to achieve satisfactory results in a real-time manner, which is a necessity in clinical practice. The main obstacle is the huge semantic gap between high-level features and low-level features, making it difficult to take full advantage of complementary semantic information contained in these hierarchical features. Compared with existing solutions, which either directly aggregate these features without considering the semantic gap or employ sophisticated non-local modeling techniques to refine semantic information by introduce many extra computational costs, the proposed ConvNet is able to more precisely yet efficiently calibrate and refine semantic information for better segmentation performance without increasing model complexity; we call the proposed ConvNet as SCR-Net, which has two key modules. We first propose a semantic calibration module (SCM) to effectively transmit the semantic information from high-level layers to low-level layers by learning the semantic-spatial relations during the training procedure. We then propose a semantic refinement module (SRM) to, based on the features calibrated by SCM, enhance the discrimination capability of the features for targeting objects. Extensive experiments on the Kvasir-SEG dataset demonstrate that the proposed SCR-Net is capable of achieving better segmentation accuracy than state-of-the-art approaches with a faster speed. The proposed techniques are general enough to be applied to similar applications where precise and efficient multi-level feature fusion is critical. The code is available at https://github.com/jiafuz/SCR-Net",
    "checked": true,
    "id": "7ca83bac3e9836d4088101e53bfceddfdeadd7ff",
    "semantic_title": "precise yet efficient semantic calibration and refinement in convnets for real-time polyp segmentation from colonoscopy videos",
    "citation_count": 16,
    "authors": [
      "Huisi Wu",
      "Jiafu Zhong",
      "Wei Wang",
      "Zhenkun Wen",
      "Jing Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16399": {
    "title": "Graph-to-Graph: Towards Accurate and Interpretable Online Handwritten Mathematical Expression Recognition",
    "volume": "main",
    "abstract": "Recent handwritten mathematical expression recognition (HMER) approaches treat the problem as an image-to-markup generation task where the handwritten formula is translated into a sequence (e.g. LaTeX). The encoder-decoder framework is widely used to solve this image-to-sequence problem. However, (i) for structured mathematical formula, the hierarchical structure neither in the formula nor in the markup has been explored adequately. In addition, (ii) existing image-to-markup methods could not explicitly segment mathematical symbols in the formula corresponding to each target markup token. In this paper, we address the above issues by formulating the HMER as a graph-to-graph (G2G) learning problem. Graph is more flexible and general for structure representation and learning compared with image or sequence. At the core of our method lies the embedding of input formula and output markup into graphs on primitives, with Graph Neural Networks (GNN) to explore the structural information, and a novel sub-graph attention mechanism to match primitives in the input and output graphs. We conduct extensive experiments on CROHME datasets to demonstrate the benefits of the proposed G2G model. Our method yields significant improvements over previous SOTA image-to-markup systems. Moreover, it explicitly resolves the symbol segmentation problem while still being trained end-to-end, making the whole system much more accurate and interpretable",
    "checked": true,
    "id": "33db82502829eb176a6fed2d819a9ed8d2bb4c88",
    "semantic_title": "graph-to-graph: towards accurate and interpretable online handwritten mathematical expression recognition",
    "citation_count": 16,
    "authors": [
      "Jin-Wen Wu",
      "Fei Yin",
      "Yan-Ming Zhang",
      "Xu-Yao Zhang",
      "Cheng-Lin Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16400": {
    "title": "Learning Comprehensive Motion Representation for Action Recognition",
    "volume": "main",
    "abstract": "For action recognition learning, 2D CNN-based methods are efficient but may yield redundant features due to applying the same 2D convolution kernel to each frame. Recent efforts attempt to capture motion information by establishing inter-frame connections while still suffering the limited temporal receptive field or high latency. Moreover, the feature enhancement is often only performed by channel or space dimension in action recognition. To address these issues, we first devise a Channel-wise Motion Enhancement (CME) module to adaptively emphasize the channels related to dynamic information with a channel-wise gate vector. The channel gates generated by CME incorporate the information from all the other frames in the video. We further propose a Spatial-wise Motion Enhancement (SME) module to focus on the regions with the critical target in motion, according to the point-to-point similarity between adjacent feature maps. The intuition is that the change of background is typically slower than the motion area. Both CME and SME have clear physical meaning in capturing action clues. By integrating the two modules into the off-the-shelf 2D network, we finally obtain a Comprehensive Motion Representation (CMR) learning method for action recognition, which achieves competitive performance on Something-Something V1 & V2 and Kinetics-400. On the temporal reasoning datasets Something-Something V1 and V2, our method outperforms the current state-of-the-art by 2.3% and 1.9% when using 16 frames as input, respectively",
    "checked": true,
    "id": "e7421b46ff5f0f0b029aef2ad73a1ded6ae313dc",
    "semantic_title": "learning comprehensive motion representation for action recognition",
    "citation_count": 7,
    "authors": [
      "Mingyu Wu",
      "Boyuan Jiang",
      "Donghao Luo",
      "Junchi Yan",
      "Yabiao Wang",
      "Ying Tai",
      "Chengjie Wang",
      "Jilin Li",
      "Feiyue Huang",
      "Xiaokang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16401": {
    "title": "MVFNet: Multi-View Fusion Network for Efficient Video Recognition",
    "volume": "main",
    "abstract": "Conventionally, spatiotemporal modeling network and its complexity are the two most concentrated research topics in video action recognition. Existing state-of-the-art methods have achieved excellent accuracy regardless of the complexity meanwhile efficient spatiotemporal modeling solutions are slightly inferior in performance. In this paper, we attempt to acquire both efficiency and effectiveness simultaneously. First of all, besides traditionally treating H x W x T video frames as space-time signal (viewing from the Height-Width spatial plane), we propose to also model video from the other two Height-Time and Width-Time planes, to capture the dynamics of video thoroughly. Secondly, our model is designed based on 2D CNN backbones and model complexity is well kept in mind by design. Specifically, we introduce a novel multi-view fusion (MVF) module to exploit video dynamics using separable convolution for efficiency. It is a plug-and-play module and can be inserted into off-the-shelf 2D CNNs to form a simple yet effective model called MVFNet. Moreover, MVFNet can be thought of as a generalized video modeling framework and it can specialize to be existing methods such as C2D, SlowOnly, and TSM under different settings. Extensive experiments are conducted on popular benchmarks (i.e., Something-Something V1 & V2, Kinetics, UCF-101, and HMDB-51) to show its superiority. The proposed MVFNet can achieve state-of-the-art performance with 2D CNN's complexity",
    "checked": true,
    "id": "07e0fd1487b8b31d6641c66f67f20e4659e5848e",
    "semantic_title": "mvfnet: multi-view fusion network for efficient video recognition",
    "citation_count": 38,
    "authors": [
      "Wenhao Wu",
      "Dongliang He",
      "Tianwei Lin",
      "Fu Li",
      "Chuang Gan",
      "Errui Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16402": {
    "title": "Anticipating Future Relations via Graph Growing for Action Prediction",
    "volume": "main",
    "abstract": "Predicting actions from partially observed videos is challenging as the partial videos containing incomplete action executions have insufficient discriminative information for classification. Recent progress has been made through enriching the features of the observed video part or generating the features for the unobserved video part, but without explicitly modeling the fine-grained evolution of visual object relations over both space and time. In this paper, we investigate how the interaction and correlation between visual objects evolve and propose a graph growing method to anticipate future object relations from limited video observations for reliable action prediction. There are two tasks in our method. First, we work with spatial-temporal graph neural networks to reason object relations in the observed video part. Then, we synthesize the spatial-temporal relation representation for the unobserved video part via graph node generation and aggregation. These two tasks are jointly learned to enable the anticipated future relation representation informative to action prediction. Experimental results on two action video datasets demonstrate the effectiveness of our method",
    "checked": true,
    "id": "f84e81b3e9b979c1f2da330b101f1aebf23d577f",
    "semantic_title": "anticipating future relations via graph growing for action prediction",
    "citation_count": 10,
    "authors": [
      "Xinxiao Wu",
      "Jianwei Zhao",
      "Ruiqi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16403": {
    "title": "Binaural Audio-Visual Localization",
    "volume": "main",
    "abstract": "Localizing sound sources in a visual scene has many important applications and quite a few traditional or learning-based methods have been proposed for this task. Humans have the ability to roughly localize sound sources within or beyond the range of the vision using their binaural system. However most existing methods use monaural audio, instead of binaural audio, as a modality to help the localization. In addition, prior works usually localize sound sources in the form of object-level bounding boxes in images or videos and evaluate the localization accuracy by examining the overlap between the ground-truth and predicted bounding boxes. This is too rough since a real sound source is often only a part of an object. In this paper, we propose a deep learning method for pixel-level sound source localization by leveraging both binaural recordings and the corresponding videos. Specifically, we design a novel Binaural Audio-Visual Network (BAVNet), which concurrently extracts and integrates features from binaural recordings and videos. We also propose a point-annotation strategy to construct pixel-level ground truth for network training and performance evaluation. Experimental results on Fair-Play and YT-Music datasets demonstrate the effectiveness of the proposed method and show that binaural audio can greatly improve the performance of localizing the sound sources, especially when the quality of the visual information is limited",
    "checked": true,
    "id": "21f36fa303fd70278ff038dc5bbcf2a96c5f018a",
    "semantic_title": "binaural audio-visual localization",
    "citation_count": 9,
    "authors": [
      "Xinyi Wu",
      "Zhenyao Wu",
      "Lili Ju",
      "Song Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16404": {
    "title": "Beating Attackers At Their Own Games: Adversarial Example Detection Using Adversarial Gradient Directions",
    "volume": "main",
    "abstract": "Adversarial examples are input examples that are specifically crafted to deceive machine learning classifiers. State-of-the-art adversarial example detection methods characterize an input example as adversarial either by quantifying the magnitude of feature variations under multiple perturbations or by measuring its distance from estimated benign example distribution. Instead of using such metrics, the proposed method is based on the observation that the directions of adversarial gradients when crafting (new) adversarial examples play a key role in characterizing the adversarial space. Compared to detection methods that use multiple perturbations, the proposed method is efficient as it only applies a single random perturbation on the input example. Experiments conducted on two different databases, CIFAR-10 and ImageNet, show that the proposed detection method achieves, respectively, 97.9% and 98.6% AUC-ROC (on average) on five different adversarial attacks, and outperforms multiple state-of-the-art detection methods. Results demonstrate the effectiveness of using adversarial gradient directions for adversarial example detection",
    "checked": true,
    "id": "df326f0b6d109282f41bc5cc1fbd125437b65341",
    "semantic_title": "beating attackers at their own games: adversarial example detection using adversarial gradient directions",
    "citation_count": 5,
    "authors": [
      "Yuhang Wu",
      "Sunpreet S Arora",
      "Yanhong Wu",
      "Hao Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16405": {
    "title": "Shape-Pose Ambiguity in Learning 3D Reconstruction from Images",
    "volume": "main",
    "abstract": "Learning single-image 3D reconstruction with only 2D images supervision is a promising research topic. The main challenge in image-supervised 3D reconstruction is the shape-pose ambiguity, which means a 2D supervision can be explained by an erroneous 3D shape from an erroneous pose. It will introduce high uncertainty and mislead the learning process. Existed works rely on multi-view images or pose-aware annotations to resolve the ambiguity. In this paper, we propose to resolve the ambiguity without extra pose-aware labels or annotations. Our training data is single-view images from the same object category. To overcome the shape-pose ambiguity, we introduce a pose-independent GAN to learn the category-specific shape manifold from the image collections. With the learned shape space, we resolve the shape-pose ambiguity in original images by training a pseudo pose regressor. Finally, we learn a reconstruction network with both the common re-projection loss and a pose-independent discrimination loss, making the results plausible from all views. Through experiments on synthetic and real image datasets, we demonstrate that our method can perform comparably to existing methods while not requiring any extra pose-aware annotations, making it more applicable and adaptable",
    "checked": true,
    "id": "3f6785d00979183866c2ac76b69c971b165eb6e6",
    "semantic_title": "shape-pose ambiguity in learning 3d reconstruction from images",
    "citation_count": 2,
    "authors": [
      "Yunjie Wu",
      "Zhengxing Sun",
      "Youcheng Song",
      "Yunhan Sun",
      "YiJie Zhong",
      "Jinlong Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16406": {
    "title": "Boundary Proposal Network for Two-stage Natural Language Video Localization",
    "volume": "main",
    "abstract": "We aim to address the problem of Natural Language Video Localization (NLVL) ‚Äî localizing the video segment corresponding to a natural language description in a long and untrimmed video. State-of-the-art NLVL methods are almost in one-stage fashion, which can be typically grouped into two categories: 1) anchor-based approach: it first pre-defines a series of video segment candidates (e.g., by sliding window), and then does classification for each candidate; 2) anchor-free approach: it directly predicts the probabilities for each video frame as a boundary or intermediate frame inside the positive segment. However, both kinds of one-stage approaches have inherent drawbacks: the anchor-based approach is susceptible to the heuristic rules, further limiting the capability of handling videos with variant length. While the anchor-free approach fails to exploit the segment-level interaction thus achieving inferior results. In this paper, we propose a novel Boundary Proposal Network (BPNet), a universal two-stage framework that gets rid of the issues mentioned above. Specifically, in the first stage, BPNet utilizes an anchor-free model to generate a group of high-quality candidate video segments with their boundaries. In the second stage, a visual-language fusion layer is proposed to jointly model the multi-modal interaction between the candidate and the language query, followed by a matching score rating layer that outputs the alignment score for each candidate. We evaluate our BPNet on three challenging NLVL benchmarks (i.e., Charades-STA, TACoS and ActivityNet-Captions). Extensive experiments and ablative studies on these datasets demonstrate that the BPNet outperforms the state-of-the-art methods",
    "checked": true,
    "id": "72bf41fe2eb7ef7bcf70246816f6f2b54fe5f1bf",
    "semantic_title": "boundary proposal network for two-stage natural language video localization",
    "citation_count": 87,
    "authors": [
      "Shaoning Xiao",
      "Long Chen",
      "Songyang Zhang",
      "Wei Ji",
      "Jian Shao",
      "Lu Ye",
      "Jun Xiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16407": {
    "title": "Amodal Segmentation Based on Visible Region Segmentation and Shape Prior",
    "volume": "main",
    "abstract": "Almost all existing amodal segmentation methods make the inferences of occluded regions by using features corresponding to the whole image. This is against the human's amodal perception, where human uses the visible part and the shape prior knowledge of the target to infer the occluded region. To mimic the behavior of human and solve the ambiguity in the learning, we propose a framework, it firstly estimates a coarse visible mask and a coarse amodal mask. Then based on the coarse prediction, our model infers the amodal mask by concentrating on the visible region and utilizing the shape prior in the memory. In this way, features corresponding to background and occlusion can be suppressed for amodal mask estimation. Consequently, the amodal mask would not be affected by what the occlusion is given the same visible regions. The leverage of shape prior makes the amodal mask estimation more robust and reasonable. Our proposed model is evaluated on three datasets. Experiments show that our proposed model outperforms existing state-of-the-art methods. The visualization of shape prior indicates that the category-specific feature in the codebook has certain interpretability. The code is available at https://github.com/YutingXiao/Amodal-Segmentation-Based-on-Visible-Region-Segmentation-and-Shape-Prior",
    "checked": true,
    "id": "447d4008dc08b30a2731d898bfdbc8000c7f5b4a",
    "semantic_title": "amodal segmentation based on visible region segmentation and shape prior",
    "citation_count": 24,
    "authors": [
      "Yuting Xiao",
      "Yanyu Xu",
      "Ziming Zhong",
      "Weixin Luo",
      "Jiawei Li",
      "Shenghua Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16408": {
    "title": "Locate Globally, Segment Locally: A Progressive Architecture With Knowledge Review Network for Salient Object Detection",
    "volume": "main",
    "abstract": "Salient object location and segmentation are two different tasks in salient object detection (SOD). The former aims to globally find the most attractive objects in an image, whereas the latter can be achieved only using local regions that contain salient objects. However, previous methods mainly accomplish the two tasks simultaneously in a simple end-to-end manner, which leads to the ignorance of the differences between them. We assume that the human vision system orderly locates and segments objects, so we propose a novel progressive architecture with knowledge review network (PA-KRN) for SOD. It consists of three parts. (1) A coarse locating module (CLM) that uses body-attention label locates rough areas containing salient objects without boundary details. (2) An attention-based sampler highlights salient object regions with high resolution based on body-attention maps. (3) A fine segmenting module (FSM) finely segments salient objects. The networks applied in CLM and FSM are mainly based on our proposed knowledge review network (KRN) that utilizes the finest feature maps to reintegrate all previous layers, which can make up for the important information that is continuously diluted in the top-down path. Experiments on five benchmarks demonstrate that our single KRN can outperform state-of-the-art methods. Furthermore, our PA-KRN performs better and substantially surpasses the aforementioned methods",
    "checked": true,
    "id": "8284d4a279b5c5107c9c5e1f0580fbff3f7b75da",
    "semantic_title": "locate globally, segment locally: a progressive architecture with knowledge review network for salient object detection",
    "citation_count": 70,
    "authors": [
      "Binwei Xu",
      "Haoran Liang",
      "Ronghua Liang",
      "Peng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16409": {
    "title": "Invariant Teacher and Equivariant Student for Unsupervised 3D Human Pose Estimation",
    "volume": "main",
    "abstract": "We propose a novel method based on teacher-student learning framework for 3D human pose estimation without any 3D annotation or side information. To solve this unsupervised-learning problem, the teacher network adopts pose-dictionary-based modeling for regularization to estimate a physically plausible 3D pose. To handle the decomposition ambiguity in the teacher network, we propose a cycle-consistent architecture promoting a 3D rotation-invariant property to train the teacher network. To further improve the estimation accuracy, the student network adopts a novel graph convolution network for flexibility to directly estimate the 3D coordinates. Another cycle-consistent architecture promoting 3D rotation-equivariant property is adopted to exploit geometry consistency, together with knowledge distillation from the teacher network to improve the pose estimation performance. We conduct extensive experiments on Human3.6M and MPI-INF-3DHP. Our method reduces the 3D joint prediction error by 11.4% compared to state-of-the-art unsupervised methods and also outperforms many weakly-supervised methods that use side information on Human3.6M. Code will be available at https://github.com/sjtuxcx/ITES",
    "checked": true,
    "id": "feeca807fc480d7175d16427531b64ea007b7672",
    "semantic_title": "invariant teacher and equivariant student for unsupervised 3d human pose estimation",
    "citation_count": 8,
    "authors": [
      "Chenxin Xu",
      "Siheng Chen",
      "Maosen Li",
      "Ya Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16410": {
    "title": "Imagine, Reason and Write: Visual Storytelling with Graph Knowledge and Relational Reasoning",
    "volume": "main",
    "abstract": "Visual storytelling is a task of creating a short story based on photo streams. Different from visual captions, stories contain not only factual descriptions, but also imaginary concepts that do not appear in the images. In this paper, we propose a novel imagine-reason-write generation framework (IRW) for visual storytelling, inspired by the logic of humans when they write the story. First, an imagine module is leveraged to learn the imaginative storyline explicitly, improving the coherence and reasonability of the generated story. Second, we employ a reason module to fully exploit the external knowledge (commonsense knowledge base) and task-specific knowledge (scene graph and event graph) with relational reasoning method based on the storyline. In this way, we can effectively capture the most informative commonsense and visual relationships among objects in images, which enhances the diversity and informativeness of the generated story. Finally, we integrate the imaginary concepts and relational knowledge to generate human-like story based on the original semantics of images. Extensive experiments on a benchmark dataset (i.e., VIST) demonstrate that the proposed IRW framework significantly outperforms the state-of-the-art methods across multiple evaluation metrics",
    "checked": true,
    "id": "e560bdec8479c1ca4570a4233ec66bf759a0c6ad",
    "semantic_title": "imagine, reason and write: visual storytelling with graph knowledge and relational reasoning",
    "citation_count": 16,
    "authors": [
      "Chunpu Xu",
      "Min Yang",
      "Chengming Li",
      "Ying Shen",
      "Xiang Ao",
      "Ruifeng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16411": {
    "title": "Self-supervised Multi-view Stereo via Effective Co-Segmentation and Data-Augmentation",
    "volume": "main",
    "abstract": "Recent studies have witnessed that self-supervised methods based on view synthesis obtain clear progress on multi-view stereo (MVS). However, existing methods rely on the assumption that the corresponding points among different views share the same color, which may not always be true in practice. This may lead to unreliable self-supervised signal and harm the final reconstruction performance. To address the issue, we propose a framework integrated with more reliable supervision guided by semantic co-segmentation and data-augmentation. Specially, we excavate mutual semantic from multi-view images to guide the semantic consistency. And we devise effective data-augmentation mechanism which ensures the transformation robustness by treating the prediction of regular samples as pseudo ground truth to regularize the prediction of augmented samples. Experimental results on DTU dataset show that our proposed methods achieve the state-of-the-art performance among unsupervised methods, and even compete on par with supervised methods. Furthermore, extensive experiments on Tanks&Temples dataset demonstrate the effective generalization ability of the proposed method",
    "checked": true,
    "id": "9da0ab9744700e31eef504403ad872cb99ec4fd0",
    "semantic_title": "self-supervised multi-view stereo via effective co-segmentation and data-augmentation",
    "citation_count": 36,
    "authors": [
      "Hongbin Xu",
      "Zhipeng Zhou",
      "Yu Qiao",
      "Wenxiong Kang",
      "Qiuxia Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16412": {
    "title": "Efficient Deep Image Denoising via Class Specific Convolution",
    "volume": "main",
    "abstract": "Deep neural networks have been widely used in image denoising during the past few years. Even though they achieve great success on this problem, they are computationally inefficient which makes them inappropriate to be implemented in mobile devices. In this paper, we propose an efficient deep neural network for image denoising based on pixel-wise classification. Despite using a computationally efficient network cannot effectively remove the noises from any content, it is still capable to denoise from a specific type of pattern or texture. The proposed method follows such a divide and conquer scheme. We first use an efficient U-net to pixel-wisely classify pixels in the noisy image based on the local gradient statistics.Then we replace part of the convolution layers in existing denoising networks by the proposed Class Specific Convolution layers (CSConv) which use different weights for different classes of pixels. Quantitative and qualitative evaluations on public datasets demonstrate that the proposed method can reduce the computational costs without sacrificing the performance compared to state-of-the-art algorithms",
    "checked": true,
    "id": "774640468f3fbbab1891cc02b74166670750e77b",
    "semantic_title": "efficient deep image denoising via class specific convolution",
    "citation_count": 10,
    "authors": [
      "Lu Xu",
      "Jiawei Zhang",
      "Xuanye Cheng",
      "Feng Zhang",
      "Xing Wei",
      "Jimmy Ren"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16413": {
    "title": "Investigate Indistinguishable Points in Semantic Segmentation of 3D Point Cloud",
    "volume": "main",
    "abstract": "This paper investigates the indistinguishable points (difficult to predict label) in semantic segmentation for large-scale 3D point clouds. The indistinguishable points consist of those located in complex boundary, points with similar local textures but different categories, and points in isolate small hard areas, which largely harm the performance of 3D semantic segmentation. To address this challenge, we propose a novel Indistinguishable Area Focalization Network (IAF-Net), which select indistinguishable points adaptively by utilizing the hierarchical semantic features and enhance fine-grained features for points especially those indistinguishable points. We also introduce multi-stage loss to improve the feature representation in a progressive way. Moreover, in order to analyze the segmentation performances of indistinguishable areas, we propose a new evaluation metric called Indistinguishable Points Based Metric (IPBM). Our IAF-Net achieves the state-of-the-art performance on several popular 3D point datasets e.g. S3DIS and ScanNet, and clearly outperform other methods on IPBM. Our code will be available at https://github.com/MingyeXu/IAF-Net",
    "checked": true,
    "id": "251ee18f5d5ff4847b5c9a823b14aca09ddf4e94",
    "semantic_title": "investigate indistinguishable points in semantic segmentation of 3d point cloud",
    "citation_count": 10,
    "authors": [
      "Mingye Xu",
      "Zhipeng Zhou",
      "Junhao Zhang",
      "Yu Qiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16414": {
    "title": "Learning Geometry-Disentangled Representation for Complementary Understanding of 3D Object Point Cloud",
    "volume": "main",
    "abstract": "In 2D image processing, some attempts decompose images into high and low frequency components for describing edge and smooth parts respectively. Similarly, the contour and flat area of 3D objects, such as the boundary and seat area of a chair, describe different but also complementary geometries. However, such investigation is lost in previous deep networks that understand point clouds by directly treating all points or local patches equally. To solve this problem, we propose Geometry-Disentangled Attention Network (GDANet). GDANet introduces Geometry-Disentangle Module to dynamically disentangle point clouds into the contour and flat part of 3D objects, respectively denoted by sharp and gentle variation components. Then GDANet exploits Sharp-Gentle Complementary Attention Module that regards the features from sharp and gentle variation components as two holistic representations, and pays different attentions to them while fusing them respectively with original point cloud features. In this way, our method captures and refines the holistic and complementary 3D geometric semantics from two distinct disentangled components to supplement the local information. Extensive experiments on 3D object classification and segmentation benchmarks demonstrate that GDANet achieves the state-of-the-arts with fewer parameters",
    "checked": true,
    "id": "8eeebb2f74a2a12251442942b619b2846ed5796c",
    "semantic_title": "learning geometry-disentangled representation for complementary understanding of 3d object point cloud",
    "citation_count": 67,
    "authors": [
      "Mutian Xu",
      "Junhao Zhang",
      "Zhipeng Zhou",
      "Mingye Xu",
      "Xiaojuan Qi",
      "Yu Qiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16415": {
    "title": "Searching for Alignment in Face Recognition",
    "volume": "main",
    "abstract": "A standard pipeline of current face recognition frameworks consists of four individual steps: locating a face with a rough bounding box and several fiducial landmarks, aligning the face image using a pre-defined template, extracting representations and comparing. Among them, face detection, landmark detection and representation learning have long been studied and a lot of works have been proposed. As an important step with a big impact on recognition performance, the alignment step has attracted little attention. In this paper, we first explore and highlight the effects of different alignment templates on face recognition. Then, for the first time, we try to automatically search for the optimal template. We construct a well-defined searching space by decomposing the template searching into the crop size and vertical shift, and propose an efficient method Face Alignment Policy Search (FAPS). Besides, a well-designed benchmark is proposed to evaluate the searched policy. Experiments on our proposed benchmark validate the effectiveness of our method to improve the face recognition performance",
    "checked": true,
    "id": "737c1371415c2ea07e9ba63d498e6e68650094a2",
    "semantic_title": "searching for alignment in face recognition",
    "citation_count": 13,
    "authors": [
      "Xiaqing Xu",
      "Qiang Meng",
      "Yunxiao Qin",
      "Jianzhu Guo",
      "Chenxu Zhao",
      "Feng Zhou",
      "Zhen Lei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16416": {
    "title": "GIF Thumbnails: Attract More Clicks to Your Videos",
    "volume": "main",
    "abstract": "With the rapid increase of mobile devices and online media, more and more people prefer posting/viewing videos online. Generally, these videos are presented on video streaming sites with image thumbnails and text titles. While facing huge amounts of videos, a viewer clicks through a certain video with high probability because of its eye-catching thumbnail. However, current video thumbnails are created manually, which is time-consuming and quality-unguaranteed. And static image thumbnails contain very limited information of the corresponding videos, which prevents users from successfully clicking what they really want to view. In this paper, we address a novel problem, namely GIF thumbnail generation, which aims to automatically generate GIF thumbnails for videos and consequently boost their Click-Through-Rate (CTR). Here, a GIF thumbnail is an animated GIF file consisting of multiple segments from the video, containing more information of the target video than a static image thumbnail. To support this study, we build the first GIF thumbnails benchmark dataset that consists of 1070 videos covering a total duration of 69.1 hours, and 5394 corresponding manually-annotated GIFs. To solve this problem, we propose a learning-based automatic GIF thumbnail generation model, which is called Generative Variational Dual-Encoder (GEVADEN). As not relying on any user interaction information (e.g. time-sync comments and real-time view counts), this model is applicable to newly-uploaded/rarely-viewed videos. Experiments on our built dataset show that GEVADEN significantly outperforms several baselines, including video-summarization and highlight-detection based ones. Furthermore, we develop a pilot application of the proposed model on an online video platform with 9814 videos covering 1231 hours, which shows that our model achieves a 37.5% CTR improvement over traditional image thumbnails. This further validates the effectiveness of the proposed model and the promising application prospect of GIF thumbnails",
    "checked": true,
    "id": "d5e4ffa9b18d50e60dc081232c50c54f7ca79c1c",
    "semantic_title": "gif thumbnails: attract more clicks to your videos",
    "citation_count": 6,
    "authors": [
      "Yi Xu",
      "Fan Bai",
      "Yingxuan Shi",
      "Qiuyu Chen",
      "Longwen Gao",
      "Kai Tian",
      "Shuigeng Zhou",
      "Huyang Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16417": {
    "title": "FaceController: Controllable Attribute Editing for Face in the Wild",
    "volume": "main",
    "abstract": "Face attribute editing aims to generate faces with one or multiple desired face attributes manipulated while other details are preserved. Unlike prior works such as GAN inversion which has an expensive reverse mapping process, we propose a simple feed-forward network to generate high-fidelity manipulated faces. By simply employing some existing and easy-obtainable prior information, our method can control, transfer, and edit diverse attributes of faces in the wild. The proposed method can consequently be applied to various applications such as face swapping, face relighting, and makeup transfer. In our method, we decouple identity, expression, pose, and illumination by using 3D priors; separate texture and colors by using region-wise style codes. All the information is embedded into adversarial learning by our identity-style normalization module. Disentanglement losses are proposed to enhance the generator to extract information independently from each attribute. Comprehensive quantitative and qualitative evaluations have been conducted. In a single framework, our method achieves the best or competitive scores on a variety of face applications",
    "checked": true,
    "id": "92d6ad1611df532581a6db1467cc4e78ab290555",
    "semantic_title": "facecontroller: controllable attribute editing for face in the wild",
    "citation_count": 23,
    "authors": [
      "Zhiliang Xu",
      "Xiyu Yu",
      "Zhibin Hong",
      "Zhen Zhu",
      "Junyu Han",
      "Jingtuo Liu",
      "Errui Ding",
      "Xiang Bai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16418": {
    "title": "AnchorFace: An Anchor-based Facial Landmark Detector Across Large Poses",
    "volume": "main",
    "abstract": "Facial landmark localization aims to detect the predefined points of human faces, and the topic has been rapidly improved with the recent development of neural network based methods. However, it remains a challenging task when dealing with faces in unconstrained scenarios, especially with large pose variations. In this paper, we target the problem of facial landmark localization across large poses and address this task based on a split-and-aggregate strategy. To split the search space, we propose a set of anchor templates as references for regression, which well addresses the large variations of face poses. Based on the prediction of each anchor template, we propose to aggregate the results, which can reduce the landmark uncertainty due to the large poses. Overall, our proposed approach, named AnchorFace, obtains state-of-the-art results with extremely efficient inference speed on four challenging benchmarks, i.e. AFLW, 300W, Menpo, and WFLW dataset. Code will be available soon",
    "checked": true,
    "id": "074e1c09266ce3bafe92e2cc1d5ab22199598850",
    "semantic_title": "anchorface: an anchor-based facial landmark detector across large poses",
    "citation_count": 28,
    "authors": [
      "Zixuan Xu",
      "Banghuai Li",
      "Ye Yuan",
      "Miao Geng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16419": {
    "title": "Sparse Single Sweep LiDAR Point Cloud Segmentation via Learning Contextual Shape Priors from Scene Completion",
    "volume": "main",
    "abstract": "LiDAR point cloud analysis is a core task for 3D computer vision, especially for autonomous driving. However, due to the severe sparsity and noise interference in the single sweep LiDAR point cloud, the accurate semantic segmentation is non-trivial to achieve. In this paper, we propose a novel sparse LiDAR point cloud semantic segmentation framework assisted by learned contextual shape priors. In practice, an initial semantic segmentation (SS) of a single sweep point cloud can be achieved by any appealing network and then flows into the semantic scene completion (SSC) module as the input. By merging multiple frames in the LiDAR sequence as supervision, the optimized SSC module has learned the contextual shape priors from sequential LiDAR data, completing the sparse single sweep point cloud to the dense one. Thus, it inherently improves SS optimization through fully end-to-end training. Besides, a Point-Voxel Interaction (PVI) module is proposed to further enhance the knowledge fusion between SS and SSC tasks, i.e., promoting the interaction of incomplete local geometry of point cloud and complete voxel-wise global structure. Furthermore, the auxiliary SSC and PVI modules can be discarded during inference without extra burden for SS. Extensive experiments confirm that our JS3C-Net achieves superior performance on both SemanticKITTI and SemanticPOSS benchmarks, i.e., 4% and 3% improvement correspondingly",
    "checked": true,
    "id": "601ad774f6305f8a78e878665b3623f2239687c5",
    "semantic_title": "sparse single sweep lidar point cloud segmentation via learning contextual shape priors from scene completion",
    "citation_count": 105,
    "authors": [
      "Xu Yan",
      "Jiantao Gao",
      "Jie Li",
      "Ruimao Zhang",
      "Zhen Li",
      "Rui Huang",
      "Shuguang Cui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16420": {
    "title": "Learning Semantic Context from Normal Samples for Unsupervised Anomaly Detection",
    "volume": "main",
    "abstract": "Unsupervised anomaly detection aims to identify data samples that have low probability density from a set of input samples, and only the normal samples are provided for model training. The inference of abnormal regions on the input image requires an understanding of the surrounding semantic context. This work presents a Semantic Context based Anomaly Detection Network, SCADN, for unsupervised anomaly detection by learning the semantic context from the normal samples. To achieve this, we first generate multi-scale striped masks to remove a part of regions from the normal samples, and then train a generative adversarial network to reconstruct the unseen regions. Note that the masks are designed in multiple scales and stripe directions, and various training examples are generated to obtain the rich semantic context . In testing, we obtain an error map by computing the difference between the reconstructed image and the input image for all samples, and infer the abnormal samples based on the error maps. Finally, we perform various experiments on three public benchmark datasets and a new dataset LaceAD collected by us, and show that our method clearly outperforms the current state-of-the-art methods",
    "checked": true,
    "id": "8ee35ed698527d9695c872e3b76715fec4ef69ad",
    "semantic_title": "learning semantic context from normal samples for unsupervised anomaly detection",
    "citation_count": 54,
    "authors": [
      "Xudong Yan",
      "Huaidong Zhang",
      "Xuemiao Xu",
      "Xiaowei Hu",
      "Pheng-Ann Heng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16421": {
    "title": "Non-Autoregressive Coarse-to-Fine Video Captioning",
    "volume": "main",
    "abstract": "It is encouraged to see that progress has been made to bridge videos and natural language. However, mainstream video captioning methods suffer from slow inference speed due to the sequential manner of autoregressive decoding, and prefer generating generic descriptions due to the insufficient training of visual words (e.g., nouns and verbs) and inadequate decoding paradigm. In this paper, we propose a non-autoregressive decoding based model with a coarse-to-fine captioning procedure to alleviate these defects. In implementations, we employ a bi-directional self-attention based network as our language model for achieving inference speedup, based on which we decompose the captioning procedure into two stages, where the model has different focuses. Specifically, given that visual words determine the semantic correctness of captions, we design a mechanism of generating visual words to not only promote the training of scene-related words but also capture relevant details from videos to construct a coarse-grained sentence ``template''. Thereafter, we devise dedicated decoding algorithms that fill in the ``template'' with suitable words and modify inappropriate phrasing via iterative refinement to obtain a fine-grained description. Extensive experiments on two mainstream video captioning benchmarks, i.e., MSVD and MSR-VTT, demonstrate that our approach achieves state-of-the-art performance, generates diverse descriptions, and obtains high inference efficiency",
    "checked": true,
    "id": "7b15217075d63714c421ae8d53197d6e62d4d25a",
    "semantic_title": "non-autoregressive coarse-to-fine video captioning",
    "citation_count": 59,
    "authors": [
      "Bang Yang",
      "Yuexian Zou",
      "Fenglin Liu",
      "Can Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16422": {
    "title": "Learning to Attack Real-World Models for Person Re-identification via Virtual-Guided Meta-Learning",
    "volume": "main",
    "abstract": "Recent advances in person re-identification (re-ID) have led to impressive retrieval accuracy. However, existing re-ID models are challenged by the adversarial examples crafted by adding quasi-imperceptible perturbations. Moreover, re-ID systems face the domain shift issue that training and testing domains are not consistent. In this study, we argue that learning powerful attackers with high universality that works well on unseen domains is an important step in promoting the robustness of re-ID systems. Therefore, we introduce a novel universal attack algorithm called ``MetaAttack'' for person re-ID. MetaAttack can mislead re-ID models on unseen domains by a universal adversarial perturbation. Specifically, to capture common patterns across different domains, we propose a meta-learning scheme to seek the universal perturbation via the gradient interaction between meta-train and meta-test formed by two datasets. We also take advantage of a virtual dataset (PersonX), instead of real ones, to conduct meta-test. This scheme not only enables us to learn with more comprehensive variation factors but also mitigates the negative effects caused by biased factors of real datasets. Experiments on three large-scale re-ID datasets demonstrate the effectiveness of our method in attacking re-ID models on unseen domains. Our final visualization results reveal some new properties of existing re-ID systems, which can guide us in designing a more robust re-ID model. Code and supplemental material are available at \\url{https://github.com/FlyingRoastDuck/MetaAttack_AAAI21}",
    "checked": true,
    "id": "ce8c00ee14b568ec7752f6d4dd18185972f35cf5",
    "semantic_title": "learning to attack real-world models for person re-identification via virtual-guided meta-learning",
    "citation_count": 7,
    "authors": [
      "Fengxiang Yang",
      "Zhun Zhong",
      "Hong Liu",
      "Zheng Wang",
      "Zhiming Luo",
      "Shaozi Li",
      "Nicu Sebe",
      "Shin'ichi Satoh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16423": {
    "title": "Object Relation Attention for Image Paragraph Captioning",
    "volume": "main",
    "abstract": "Image paragraph captioning aims to automatically generate a paragraph from a given image. It is an extension of image captioning in terms of generating multiple sentences instead of a single one, and it is more challenging because paragraphs are longer, more informative, and more linguistically complicated. Because a paragraph consists of several sentences, an effective image paragraph captioning method should generate consistent sentences rather than contradictory ones. It is still an open question how to achieve this goal, and for it we propose a method to incorporate objects' spatial coherence into a language-generating model. For every two overlapping objects, the proposed method concatenates their raw visual features to create two directional pair features and learns weights optimizing those pair features as relation-aware object features for a language-generating model. Experimental results show that the proposed network extracts effective object features for image paragraph captioning and achieves promising performance against existing methods",
    "checked": true,
    "id": "eed6293e9d99332dae29dac714ea38eec354311b",
    "semantic_title": "object relation attention for image paragraph captioning",
    "citation_count": 6,
    "authors": [
      "Li-Chuan Yang",
      "Chih-Yuan Yang",
      "Jane Yung-jen Hsu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16424": {
    "title": "Adversarial Robustness through Disentangled Representations",
    "volume": "main",
    "abstract": "Despite the remarkable empirical performance of deep learning models, their vulnerability to adversarial examples has been revealed in many studies. They are prone to make a susceptible prediction to the input with imperceptible adversarial perturbation. Although recent works have remarkably improved the model's robustness under the adversarial training strategy, an evident gap between the natural accuracy and adversarial robustness inevitably exists. In order to mitigate this problem, in this paper, we assume that the robust and non-robust representations are two basic ingredients entangled in the integral representation. For achieving adversarial robustness, the robust representations of natural and adversarial examples should be disentangled from the non-robust part and the alignment of the robust representations can bridge the gap between accuracy and robustness. Inspired by this motivation, we propose a novel defense method called Deep Robust Representation Disentanglement Network (DRRDN). Specifically, DRRDN employs a disentangler to extract and align the robust representations from both adversarial and natural examples. Theoretical analysis guarantees the mitigation of the trade-off between robustness and accuracy with good disentanglement and alignment performance. Experimental results on benchmark datasets finally demonstrate the empirical superiority of our method",
    "checked": true,
    "id": "0d57359008ef77c0521bd783a8aa1643a7296c09",
    "semantic_title": "adversarial robustness through disentangled representations",
    "citation_count": 20,
    "authors": [
      "Shuo Yang",
      "Tianyu Guo",
      "Yunhe Wang",
      "Chang Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16425": {
    "title": "CPCGAN: A Controllable 3D Point Cloud Generative Adversarial Network with Semantic Label Generating",
    "volume": "main",
    "abstract": "Generative Adversarial Networks (GAN) are good at generating variant samples of complex data distributions. Generating a sample with certain properties is one of the major tasks in the real-world application of GANs. In this paper, we propose a novel generative adversarial network to generate 3D point clouds from random latent codes, named Controllable Point Cloud Generative Adversarial Network(CPCGAN). A two-stage GAN framework is utilized in CPCGAN and a sparse point cloud containing major structural information is extracted as the middle-level information between the two stages. With their help, CPCGAN has the ability to control the generated structure and generate 3D point clouds with semantic labels for points. Experimental results demonstrate that the proposed CPCGAN outperforms state-of-the-art point cloud GANs",
    "checked": true,
    "id": "e12365294cf79c86b1ad262834b5427903caf691",
    "semantic_title": "cpcgan: a controllable 3d point cloud generative adversarial network with semantic label generating",
    "citation_count": 11,
    "authors": [
      "Ximing Yang",
      "Yuan Wu",
      "Kaiyi Zhang",
      "Cheng Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16426": {
    "title": "R3Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object",
    "volume": "main",
    "abstract": "Rotation detection is a challenging task due to the difficulties of locating the multi-angle objects and separating them effectively from the background. Though considerable progress has been made, for practical settings, there still exist challenges for rotating objects with large aspect ratio, dense distribution and category extremely imbalance. In this paper, we propose an end-to-end refined single-stage rotation detector for fast and accurate object detection by using a progressive regression approach from coarse to fine granularity. Considering the shortcoming of feature misalignment in existing refined single-stage detector, we design a feature refinement module to improve detection performance by getting more accurate features. The key idea of feature refinement module is to re-encode the position information of the current refined bounding box to the corresponding feature points through pixel-wise feature interpolation to realize feature reconstruction and alignment. For more accurate rotation estimation, an approximate SkewIoU loss is proposed to solve the problem that the calculation of SkewIoU is not derivable. Experiments on three popular remote sensing public datasets DOTA, HRSC2016, UCAS-AOD as well as one scene text dataset ICDAR2015 show the effectiveness of our approach. The source code is available at https://github.com/Thinklab-SJTU/R3Det_Tensorflow and is also integrated in our open source rotation detection benchmark: https://github.com/yangxue0827/RotationDetection",
    "checked": true,
    "id": "edada2363969e3929366df06aad8a8e9c73ba32f",
    "semantic_title": "r3det: refined single-stage detector with feature refinement for rotating object",
    "citation_count": 446,
    "authors": [
      "Xue Yang",
      "Junchi Yan",
      "Ziming Feng",
      "Tao He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16427": {
    "title": "One-shot Face Reenactment Using Appearance Adaptive Normalization",
    "volume": "main",
    "abstract": "The paper proposes a novel generative adversarial network for one-shot face reenactment, which can animate a single face image to a different pose-and-expression (provided by a driving image) while keeping its original appearance. The core of our network is a novel mechanism called appearance adaptive normalization, which can effectively integrate the appearance information from the input image into our face generator by modulating the feature maps of the generator using the learned adaptive parameters. Furthermore, we specially design a local net to reenact the local facial components (i.e., eyes, nose and mouth) first, which is a much easier task for the network to learn and can in turn provide explicit anchors to guide our face generator to learn the global appearance and pose-and-expression. Extensive quantitative and qualitative experiments demonstrate the significant efficacy of our model compared with prior one-shot methods",
    "checked": true,
    "id": "8de43d288f4eb44cefe6f37642be1cfc1e902bea",
    "semantic_title": "one-shot face reenactment using appearance adaptive normalization",
    "citation_count": 21,
    "authors": [
      "Guangming Yao",
      "Yi Yuan",
      "Tianjia Shao",
      "Shuang Li",
      "Shanqi Liu",
      "Yong Liu",
      "Mengmeng Wang",
      "Kun Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16428": {
    "title": "A Case Study of the Shortcut Effects in Visual Commonsense Reasoning",
    "volume": "main",
    "abstract": "Visual reasoning and question-answering have gathered attention in recent years. Many datasets and evaluation protocols have been proposed; some have been shown to contain bias that allows models to ``cheat'' without performing true, generalizable reasoning. A well-known bias is dependence on language priors (frequency of answers) resulting in the model not looking at the image. We discover a new type of bias in the Visual Commonsense Reasoning (VCR) dataset. In particular we show that most state-of-the-art models exploit co-occurring text between input (question) and output (answer options), and rely on only a few pieces of information in the candidate options, to make a decision. Unfortunately, relying on such superficial evidence causes models to be very fragile. To measure fragility, we propose two ways to modify the validation data, in which a few words in the answer choices are modified without significant changes in meaning. We find such insignificant changes cause models' performance to degrade significantly. To resolve the issue, we propose a curriculum-based masking approach, as a mechanism to perform more robust training. Our method improves the baseline by requiring it to pay attention to the answers as a whole, and is more effective than prior masking strategies",
    "checked": true,
    "id": "7631808b179c2c03030d528ddd1b76356a6a71e9",
    "semantic_title": "a case study of the shortcut effects in visual commonsense reasoning",
    "citation_count": 25,
    "authors": [
      "Keren Ye",
      "Adriana Kovashka"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16429": {
    "title": "Instance Mining with Class Feature Banks for Weakly Supervised Object Detection",
    "volume": "main",
    "abstract": "Recent progress on weakly supervised object detection (WSOD) is characterized by formulating WSOD as a Multiple Instance Learning (MIL) problem and taking online refinement with the selected region proposals from MIL. However, MIL inclines to select the most discriminative part rather than the entire instance as the top-scoring region proposals, which leads to weak localization capability for weakly supervised object detectors. We attribute this problem to the limited intra-class diversity within a single image. Specifically, due to the lack of annotated bounding boxes, the network tends to focus on the most common parts of each class and neglect the diverse parts of objects. To solve the problem, we introduce a novel Instance Mining with Class Feature Banks (IM-CFB) framework, which includes a Class Feature Banks (CFB) module and a Feature Guided Instance Mining (FGIM) algorithm. Concretely, Class Feature Banks (CFB) consist of sub-banks for each class, which are utilized to collect diversity information from a broader view. At the training stage, the RoI features of reliable region proposals are recorded and updated in the CFB. Then, FGIM leverages the features recorded in the CFB to ameliorate the region proposal selection of the MIL branch. Extensive experiments conducted on two publicly available datasets, Pascal VOC 2007 and 2012, demonstrate the effectiveness of our method. More remarkably, our method achieves 54.3% on mAP and 70.7% on CorLoc on Pascal VOC 2007. When further re-trained by a Fast-RCNN detector, we obtain to-date the best reported mAP and CorLoc of 55.8% and 72.2%, respectively",
    "checked": true,
    "id": "77e44853177cbcaa1c5cb4dddc7eef22841e27fa",
    "semantic_title": "instance mining with class feature banks for weakly supervised object detection",
    "citation_count": 27,
    "authors": [
      "Yufei Yin",
      "Jiajun Deng",
      "Wengang Zhou",
      "Houqiang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16430": {
    "title": "Multimodal Fusion via Teacher-Student Network for Indoor Action Recognition",
    "volume": "main",
    "abstract": "Indoor action recognition plays an important role in modern society, such as intelligent healthcare in large mobile cabin hospitals. With the wide usage of depth sensors like Kinect, multimodal information including skeleton and RGB modalities brings a promising way to improve the performance. However, existing methods are either focusing on a single data modality or failed to take the advantage of multiple data modalities. In this paper, we propose a Teacher-Student Multimodal Fusion (TSMF) model that fuses the skeleton and RGB modalities at the model level for indoor action recognition. In our TSMF, we utilize a teacher network to transfer the structural knowledge of the skeleton modality to a student network for the RGB modality. With extensive experiments on two benchmarking datasets: NTU RGB+D and PKU-MMD, results show that the proposed TSMF consistently performs better than state-of-the-art single modal and multimodal methods. It also indicates that our TSMF could not only improve the accuracy of the student network but also significantly improve the ensemble accuracy",
    "checked": true,
    "id": "1eb3f0c05dd4588cff9a3d4e6a0a58dca39c2e9f",
    "semantic_title": "multimodal fusion via teacher-student network for indoor action recognition",
    "citation_count": 11,
    "authors": [
      "Bruce X.B. Yu",
      "Yan Liu",
      "Keith C.C. Chan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16431": {
    "title": "ERNIE-ViL: Knowledge Enhanced Vision-Language Representations through Scene Graphs",
    "volume": "main",
    "abstract": "We propose a knowledge-enhanced approach, ERNIE-ViL, which incorporates structured knowledge obtained from scene graphs to learn joint representations of vision-language. ERNIE-ViL tries to build the detailed semantic connections (objects, attributes of objects and relationships between objects) across vision and language, which are essential to vision-language cross-modal tasks. Utilizing scene graphs of visual scenes, ERNIE-ViL constructs Scene Graph Prediction tasks, i.e., Object Prediction, Attribute Prediction and Relationship Prediction tasks in the pre-training phase. Specifically, these prediction tasks are implemented by predicting nodes of different types in the scene graph parsed from the sentence. Thus, ERNIE-ViL can learn the joint representations characterizing the alignments of the detailed semantics across vision and language. After pre-training on large scale image-text aligned datasets, we validate the effectiveness of ERNIE-ViL on 5 cross-modal downstream tasks. ERNIE-ViL achieves state-of-the-art performances on all these tasks and ranks the first place on the VCR leaderboard with an absolute improvement of 3.7%",
    "checked": false,
    "id": "bc996a4dbf9d4234eacdd0b930a94de1d158e256",
    "semantic_title": "ernie-vil: knowledge enhanced vision-language representations through scene graph",
    "citation_count": 274,
    "authors": [
      "Fei Yu",
      "Jiji Tang",
      "Weichong Yin",
      "Yu Sun",
      "Hao Tian",
      "Hua Wu",
      "Haifeng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16432": {
    "title": "High-Resolution Deep Image Matting",
    "volume": "main",
    "abstract": "Image matting is a key technique for image and video editing and composition. Conventionally, deep learning approaches take the whole input image and an associated trimap to infer the alpha matte using convolutional neural networks. Such approaches set state-of-the-arts in image matting; however, they may fail in real-world matting applications due to hardware limitations, since real-world input images for matting are mostly of very high resolution. In this paper, we propose HDMatt, a first deep learning based image matting approach for high-resolution inputs. More concretely, HDMatt runs matting in a patch-based crop-and-stitch manner for high-resolution inputs with a novel module design to address the contextual dependency and consistency issues between different patches. Compared with vanilla patch-based inference which computes each patch independently, we explicitly model the cross-patch contextual dependency with a newly-proposed Cross-Patch Contextual module (CPC) guided by the given trimap. Extensive experiments demonstrate the effectiveness of the proposed method and its necessity for high-resolution inputs. Our HDMatt approach also sets new state-of-the-art performance on Adobe Image Matting and AlphaMatting benchmarks and produce impressive visual results on more real-world high-resolution images",
    "checked": true,
    "id": "355a59e2957d11966bebad76cf9a7ca992545337",
    "semantic_title": "high-resolution deep image matting",
    "citation_count": 42,
    "authors": [
      "Haichao Yu",
      "Ning Xu",
      "Zilong Huang",
      "Yuqian Zhou",
      "Humphrey Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16433": {
    "title": "CAKES: Channel-wise Automatic KErnel Shrinking for Efficient 3D Networks",
    "volume": "main",
    "abstract": "3D Convolution Neural Networks (CNNs) have been widely applied to 3D scene understanding, such as video analysis and volumetric image recognition. However, 3D networks can easily lead to over-parameterization which incurs expensive computation cost. In this paper, we propose Channel-wise Automatic KErnel Shrinking (CAKES), to enable efficient 3D learning by shrinking standard 3D convolutions into a set of economic operations (e.g., 1D, 2D convolutions). Unlike previous methods, CAKES performs channel-wise kernel shrinkage, which enjoys the following benefits: 1) enabling operations deployed in every layer to be heterogeneous, so that they can extract diverse and complementary information to benefit the learning process; and 2) allowing for an efficient and flexible replacement design, which can be generalized to both spatial-temporal and volumetric data. Further, we propose a new search space based on CAKES, so that the configuration can be determined automatically for simplifying 3D networks. CAKES shows superior performance to other methods with similar model size, and it also achieves comparable performance to state-of-the-art methods with much fewer parameters and computational costs on tasks including 3D medical imaging segmentation and video action recognition. Codes and models are available at https://github.com/yucornetto/CAKES",
    "checked": false,
    "id": "08f985bdde257b0814a93af7d3254023e8d2d067",
    "semantic_title": "cakes: channel-wise automatic kernel shrinking for efficient 3d network",
    "citation_count": 3,
    "authors": [
      "Qihang Yu",
      "Yingwei Li",
      "Jieru Mei",
      "Yuyin Zhou",
      "Alan Yuille"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16434": {
    "title": "Structure-Consistent Weakly Supervised Salient Object Detection with Local Saliency Coherence",
    "volume": "main",
    "abstract": "Sparse labels have been attracting much attention in recent years. However, the performance gap between weakly supervised and fully supervised salient object detection methods is huge, and most previous weakly supervised works adopt complex training methods with many bells and whistles. In this work, we propose a one-round end-to-end training approach for weakly supervised salient object detection via scribble annotations without pre/post-processing operations or extra supervision data. Since scribble labels fail to offer detailed salient regions, we propose a local coherence loss to propagate the labels to unlabeled regions based on image features and pixel distance, so as to predict integral salient regions with complete object structures. We design a saliency structure consistency loss as self-consistent mechanism to ensure consistent saliency maps are predicted with different scales of the same image as input, which could be viewed as a regularization technique to enhance the model generalization ability. Additionally, we design an aggregation module (AGGM) to better integrate high-level features, low-level features and global context information for the decoder to aggregate various information. Extensive experiments show that our method achieves a new state-of-the-art performance on six benchmarks (e.g. for the ECSSD dataset: FŒ≤ = 0.8995, EŒæ = 0.9079 and MAE = 0.0489), with an average gain of 4.60% for F-measure, 2.05% for E-measure and 1.88% for MAE over the previous best performing method on this task. Source code is available at http://github.com/siyueyu/SCWSSOD",
    "checked": true,
    "id": "acafdcd4f53581aa00bf97d15d8ee65a3eb8a591",
    "semantic_title": "structure-consistent weakly supervised salient object detection with local saliency coherence",
    "citation_count": 60,
    "authors": [
      "Siyue Yu",
      "Bingfeng Zhang",
      "Jimin Xiao",
      "Eng Gee Lim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16435": {
    "title": "Fast and Compact Bilinear Pooling by Shifted Random Maclaurin",
    "volume": "main",
    "abstract": "Bilinear pooling has achieved an excellent performance in many computer vision tasks such as fine-grained classification, scene recognition and texture recognition. However, the high-dimension features from bilinear pooling can sometimes be inefficient and prone to over-fitting. Random Maclaurin (RM) is a widely used GPU-friendly approximation method to reduce the dimensionality of bilinear features. However, to achieve good performance, large projection matrices are usually required in practice, making it costly in computation and memory. In this paper, we propose a Shifted Random Maclaurin (SRM) strategy for fast and compact bilinear pooling. With merely negligible extra computational cost, the proposed SRM provides an estimator with a provably smaller variance than RM, which benefits accurate kernel approximation and thus the learning performance. Using a small projection matrix, the proposed SRM achieves a comparable estimation performance as RM based on a large projection matrix, and thus boosts the efficiency. Furthermore, we upgrade the proposed SRM to SRM+ to further improve the efficiency and make the compact bilinear pooling compatible with fast matrix normalization. Fast and Compact Bilinear Network (FCBN) built upon the proposed SRM+ is devised, achieving an end-to-end training. Systematic experiments conducted on four public datasets demonstrate the effectiveness and efficiency of the proposed FCBN",
    "checked": true,
    "id": "eb9294da10ec2dccde30dc132fa114994270162e",
    "semantic_title": "fast and compact bilinear pooling by shifted random maclaurin",
    "citation_count": 11,
    "authors": [
      "Tan Yu",
      "Xiaoyun Li",
      "Ping Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16436": {
    "title": "Simple and Effective Stochastic Neural Networks",
    "volume": "main",
    "abstract": "Stochastic neural networks (SNNs) are currently topical, with several paradigms being actively investigated including dropout, Bayesian neural networks, variational information bottleneck (VIB) and noise regularized learning. These neural network variants impact several major considerations, including generalization, network compression, robustness against adversarial attack and label noise, and model calibration. However, many existing networks are complicated and expensive to train, and/or only address one or two of these practical considerations. In this paper we propose a simple and effective stochastic neural network (SE-SNN) architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability. Compared to existing SNNs, our SE-SNN is simpler to implement and faster to train, and produces state of the art results on network compression by pruning, adversarial defense, learning with label noise, and model calibration",
    "checked": true,
    "id": "9b5f1ce51f070595f429e02bdb3fd6960ef659d8",
    "semantic_title": "simple and effective stochastic neural networks",
    "citation_count": 18,
    "authors": [
      "Tianyuan Yu",
      "Yongxin Yang",
      "Da Li",
      "Timothy Hospedales",
      "Tao Xiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16437": {
    "title": "Learning Visual Context for Group Activity Recognition",
    "volume": "main",
    "abstract": "Group activity recognition aims to recognize an overall activity in a multi-person scene. Previous methods strive to reason on individual features. However, they under-explore the person-specific contextual information, which is significant and informative in computer vision tasks. In this paper, we propose a new reasoning paradigm to incorporate global contextual information. Specifically, we propose two modules to bridge the gap between group activity and visual context. The first is Transformer based Context Encoding (TCE) module, which enhances individual representation by encoding global contextual information to individual features and refining the aggregated information. The second is Spatial-Temporal Bilinear Pooling (STBiP) module. It firstly further explores pairwise relationships for the context encoded individual representation, then generates semantic representations via gated message passing on a constructed spatial-temporal graph. On their basis, we further design a two-branch model that integrates the designed modules into a pipeline. Systematic experiments demonstrate each module's effectiveness on either branch. Visualizations indicate that visual contextual cues can be aggregated globally by TCE. Moreover, our method achieves state-of-the-art results on two widely used benchmarks using only RGB images as input and 2D backbones",
    "checked": true,
    "id": "c72a98400c4d6ac2a26e0dd6506f4e9c4224039f",
    "semantic_title": "learning visual context for group activity recognition",
    "citation_count": 27,
    "authors": [
      "Hangjie Yuan",
      "Dong Ni"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16438": {
    "title": "StrokeGAN: Reducing Mode Collapse in Chinese Font Generation via Stroke Encoding",
    "volume": "main",
    "abstract": "The generation of stylish Chinese fonts is an important problem involved in many applications. Most of existing generation methods are based on the deep generative models, particularly, the generative adversarial networks (GAN) based models. However, these deep generative models may suffer from the mode collapse issue, which significantly degrades the diversity and quality of generated results. In this paper, we introduce a one-bit stroke encoding to capture the key mode information of Chinese characters and then incorporate it into CycleGAN, a popular deep generative model for Chinese font generation. As a result we propose an efficient method called StrokeGAN, mainly motivated by the observation that the stroke encoding contains amount of mode information of Chinese characters. In order to reconstruct the one-bit stroke encoding of the associated generated characters, we introduce a stroke-encoding reconstruction loss imposed on the discriminator. Equipped with such one-bit stroke encoding and stroke-encoding reconstruction loss, the mode collapse issue of CycleGAN can be significantly alleviated, with an improved preservation of strokes and diversity of generated characters. The effectiveness of StrokeGAN is demonstrated by a series of generation tasks over nine datasets with different fonts. The numerical results demonstrate that StrokeGAN generally outperforms the state-of-the-art methods in terms of content and recognition accuracies, as well as certain stroke error, and also generates more realistic characters",
    "checked": true,
    "id": "b98caf7802c9136f1fcb4094519d2cddddf845c8",
    "semantic_title": "strokegan: reducing mode collapse in chinese font generation via stroke encoding",
    "citation_count": 28,
    "authors": [
      "Jinshan Zeng",
      "Qi Chen",
      "Yunxin Liu",
      "Mingwen Wang",
      "Yuan Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16439": {
    "title": "Demodalizing Face Recognition with Synthetic Samples",
    "volume": "main",
    "abstract": "Using data generated by generative adversarial networks or three-dimensional (3D) technology for face recognition training is a theoretically reasonable solution to the problems of unbalanced data distributions and data scarcity. However, due to the modal difference between synthetic data and real data, the direct use of data for training often leads to a decrease in the recognition performance, and the effect of synthetic data on recognition remains ambiguous. In this paper, after observing in experiments that modality information has a fixed form, we propose a demodalizing face recognition training architecture for the first time and provide a feasible method for recognition training using synthetic samples. Specifically, three different demodalizing training methods, from implicit to explicit, are proposed. These methods gradually reveal a generated modality that is difficult to quantify or describe. By removing the modalities of the synthetic data, the performance degradation is greatly alleviated. We validate the effectiveness of our approach on various benchmarks of large-scale face recognition and outperform the previous methods, especially in the low FAR range",
    "checked": true,
    "id": "5a03dd7a5ed0e3708cc2c322ae90fb6f29c9cc5d",
    "semantic_title": "demodalizing face recognition with synthetic samples",
    "citation_count": 6,
    "authors": [
      "Zhonghua Zhai",
      "Pengju Yang",
      "Xiaofeng Zhang",
      "Maji Huang",
      "Haijing Cheng",
      "Xuejun Yan",
      "Chunmao Wang",
      "Shiliang Pu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16440": {
    "title": "EMLight: Lighting Estimation via Spherical Distribution Approximation",
    "volume": "main",
    "abstract": "Illumination estimation from a single image is critical in 3D rendering and it has been investigated extensively in the computer vision and computer graphic research community. On the other hand, existing works estimate illumination by either regressing light parameters or generating illumination maps that are often hard to optimize or tend to produce inaccurate predictions. We propose Earth Mover's Light (EMLight), an illumination estimation framework that leverages a regression network and a neural projector for accurate illumination estimation. We decompose the illumination map into spherical light distribution, light intensity and the ambient term, and define the illumination estimation as a parameter regression task for the three illumination components. Motivated by the Earth Mover's distance, we design a novel spherical mover's loss that guides to regress light distribution parameters accurately by taking advantage of the subtleties of spherical distribution. Under the guidance of the predicted spherical distribution, light intensity and ambient term, the neural projector synthesizes panoramic illumination maps with realistic light frequency. Extensive experiments show that EMLight achieves accurate illumination estimation and the generated relighting in 3D object embedding exhibits superior plausibility and fidelity as compared with state-of-the-art methods",
    "checked": true,
    "id": "9e4e4c56554f5e8e6c43c0475fb72a03f5f2844a",
    "semantic_title": "emlight: lighting estimation via spherical distribution approximation",
    "citation_count": 34,
    "authors": [
      "Fangneng Zhan",
      "Changgong Zhang",
      "Yingchen Yu",
      "Yuan Chang",
      "Shijian Lu",
      "Feiying Ma",
      "Xuansong Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16441": {
    "title": "Universal Adversarial Perturbations Through the Lens of Deep Steganography: Towards a Fourier Perspective",
    "volume": "main",
    "abstract": "The booming interest in adversarial attacks stems from a misalignment between human vision and a deep neural network (DNN), \\ie~a human imperceptible perturbation fools the DNN. Moreover, a single perturbation, often called universal adversarial perturbation (UAP), can be generated to fool the DNN for most images. A similar misalignment phenomenon has also been observed in the deep steganography task, where a decoder network can retrieve a secret image back from a slightly perturbed cover image. We attempt explaining the success of both in a unified manner from the Fourier perspective. We perform task-specific and joint analysis and reveal that (a) frequency is a key factor that influences their performance based on the proposed entropy metric for quantifying the frequency distribution; (b) their success can be attributed to a DNN being highly sensitive to high-frequency content. We also perform feature layer analysis for providing deep insight on model generalization and robustness. Additionally, we propose two new variants of universal perturbations: (1) high-pass UAP (HP-UAP) being less visible to the human eye; (2) Universal Secret Adversarial Perturbation (USAP) that simultaneously achieves attack and hiding",
    "checked": true,
    "id": "4a6b02946fb7311b6bcd512d3c5fef9c082cbb60",
    "semantic_title": "universal adversarial perturbations through the lens of deep steganography: towards a fourier perspective",
    "citation_count": 28,
    "authors": [
      "Chaoning Zhang",
      "Philipp Benz",
      "Adil Karjauv",
      "In So Kweon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16442": {
    "title": "SPIN: Structure-Preserving Inner Offset Network for Scene Text Recognition",
    "volume": "main",
    "abstract": "Arbitrary text appearance poses a great challenge in scene text recognition tasks. Existing works mostly handle with the problem in consideration of the shape distortion, including perspective distortions, line curvature or other style variations. Rectification (i.e., spatial transformers) as the preprocessing stage is one popular approach and extensively studied. However, chromatic difficulties in complex scenes have not been paid much attention on. In this work, we introduce a new learnable geometric-unrelated rectification, Structure-Preserving Inner Offset Network (SPIN), which allows the color manipulation of source data within the network. This differentiable module can be inserted before any recognition architecture to ease the downstream tasks, giving neural networks the ability to actively transform input intensity rather than only the spatial rectification. It can also serve as a complementary module to known spatial transformations and work in both independent and collaborative ways with them. Extensive experiments show the proposed transformation outperforms existing rectification networks and has comparable performance among the state-of-the-arts",
    "checked": true,
    "id": "da76b33644ffa59dd5534830837cc8c1317d7bca",
    "semantic_title": "spin: structure-preserving inner offset network for scene text recognition",
    "citation_count": 16,
    "authors": [
      "Chengwei Zhang",
      "Yunlu Xu",
      "Zhanzhan Cheng",
      "Shiliang Pu",
      "Yi Niu",
      "Fei Wu",
      "Futai Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16443": {
    "title": "Visual Tracking via Hierarchical Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "Visual tracking has achieved great progress due to numerous different algorithms. However, deep trackers based on classification or Siamese network still have their specific limitations. In this work, we show how to teach machines to track a generic object in videos like humans, who can use a few search steps to perform tracking. By constructing a Markov decision process in Deep Reinforcement Learning (DRL), our agents can learn to determine hierarchical decisions on tracking mode and motion estimation. To be specific, our Hierarchical DRL framework is composed of a Siamese-based observation network which models the motion information of an arbitrary target, a policy network for mode switch and an actor-critic network for box regression. This tracking strategy is more in line with human behavior paradigm, and is effective and efficient to cope with fast motion, background clutter and large deformations. Extensive experiments on the GOT-10k, OTB-100, UAV-123, VOT and LaSOT tracking benchmarks, demonstrate that the proposed tracker achieves state-of-the-art performance while running in real-time",
    "checked": true,
    "id": "81d8eb42b13b921ea9fd714c25734c9dc2fe93e2",
    "semantic_title": "visual tracking via hierarchical deep reinforcement learning",
    "citation_count": 13,
    "authors": [
      "Dawei Zhang",
      "Zhonglong Zheng",
      "Riheng Jia",
      "Minglu Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16444": {
    "title": "One for More: Selecting Generalizable Samples for Generalizable ReID Model",
    "volume": "main",
    "abstract": "Current training objectives of existing person Re-IDentification (ReID) models only ensure that the loss of the model decreases on selected training batch, with no regards to the performance on samples outside the batch. It will inevitably cause the model to over-fit the data in the dominant position (e.g., head data in imbalanced class, easy samples or noisy samples). The latest resampling methods address the issue by designing specific criterion to select specific samples that trains the model generalize more on certain type of data (e.g., hard samples, tail data), which is not adaptive to the inconsistent real world ReID data distributions. Therefore, instead of simply presuming on what samples are generalizable, this paper proposes a one-for-more training objective that directly takes the generalization ability of selected samples as a loss function and learn a sampler to automatically select generalizable samples. More importantly, our proposed one-for-more based sampler can be seamlessly integrated into the ReID training framework which is able to simultaneously train ReID models and the sampler in an end-to-end fashion. The experimental results show that our method can effectively improve the ReID model training and boost the performance of ReID models",
    "checked": true,
    "id": "d3af32e0c614e7d141997c900fd3e7f9dc147eed",
    "semantic_title": "one for more: selecting generalizable samples for generalizable reid model",
    "citation_count": 7,
    "authors": [
      "Enwei Zhang",
      "Xinyang Jiang",
      "Hao Cheng",
      "Ancong Wu",
      "Fufu Yu",
      "Ke Li",
      "Xiaowei Guo",
      "Feng Zheng",
      "Weishi Zheng",
      "Xing Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16445": {
    "title": "Ada-Segment: Automated Multi-loss Adaptation for Panoptic Segmentation",
    "volume": "main",
    "abstract": "Panoptic segmentation that unifies instance segmentation and semantic segmentation has recently attracted increasing attention. While most existing methods focus on designing novel architectures, we steer toward a different perspective: performing automated multi-loss adaptation (named Ada-Segment) on the fly to flexibly adjust multiple training losses over the course of training using a controller trained to capture the learning dynamics. This offers a few advantages: it bypasses manual tuning of the sensitive loss combination, a decisive factor for panoptic segmentation; allows to explicitly model the learning dynamics, and reconcile the learning of multiple objectives (up to ten in our experiments); with an end-to-end architecture, it generalizes to different datasets without the need of re-tuning hyperparameters or re-adjusting the training process laboriously. Our Ada-Segment brings 2.7% panoptic quality (PQ) improvement on COCO val split from the vanilla baseline, achieving the state-of-the-art 48.5% PQ on COCO test-dev split and 32.9% PQ on ADE20K dataset. The extensive ablation studies reveal the ever-changing dynamics throughout the training process, necessitating the incorporation of an automated and adaptive learning strategy as presented in this paper",
    "checked": true,
    "id": "8f00eeb1df72e286eaea0ebb3e1b342b763a70dd",
    "semantic_title": "ada-segment: automated multi-loss adaptation for panoptic segmentation",
    "citation_count": 5,
    "authors": [
      "Gengwei Zhang",
      "Yiming Gao",
      "Hang Xu",
      "Hao Zhang",
      "Zhenguo Li",
      "Xiaodan Liang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16446": {
    "title": "SIMPLE: SIngle-network with Mimicking and Point Learning for Bottom-up Human Pose Estimation",
    "volume": "main",
    "abstract": "The practical application requests both accuracy and efficiency on multi-person pose estimation algorithms. But the high accuracy and fast inference speed are dominated by top-down methods and bottom-up methods respectively. To make a better trade-off between accuracy and efficiency, we propose a novel multi-person pose estimation framework, SIngle-network with Mimicking and Point Learning for Bottom-up Human Pose Estimation (SIMPLE). Specifically, in the training process, we enable SIMPLE to mimic the pose knowledge from the high-performance top-down pipeline, which significantly promotes SIMPLE's accuracy while maintaining its high efficiency during inference. Besides, SIMPLE formulates human detection and pose estimation as a unified point learning framework to complement each other in single-network. This is quite different from previous works where the two tasks may interfere with each other. To the best of our knowledge, both mimicking strategy between different method types and unified point learning are firstly proposed in pose estimation. In experiments, our approach achieves the new state-of-the-art performance among bottom-up methods on the COCO, MPII and PoseTrack datasets. Compared with the top-down approaches, SIMPLE has comparable accuracy and faster inference speed",
    "checked": true,
    "id": "5ef4c790ac131150a8f6fbff06305ab079101c16",
    "semantic_title": "simple: single-network with mimicking and point learning for bottom-up human pose estimation",
    "citation_count": 8,
    "authors": [
      "Jiabin Zhang",
      "Zheng Zhu",
      "Jiwen Lu",
      "Junjie Huang",
      "Guan Huang",
      "Jie Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16447": {
    "title": "Enhancing Audio-Visual Association with Self-Supervised Curriculum Learning",
    "volume": "main",
    "abstract": "The recent success of audio-visual representations learning can be largely attributed to their pervasive concurrency property, which can be used as a self-supervision signal and extract correlation information. While most recent works focus on capturing the shared associations between the audio and visual modalities, they rarely consider multiple audio and video pairs at once and pay little attention to exploiting the valuable information within each modality. To tackle this problem, we propose a novel audio-visual representation learning method dubbed self-supervised curriculum learning (SSCL) under the teacher-student learning manner. Specifically, taking advantage of contrastive learning, a two-stage scheme is exploited, which transfers the cross-modal information between teacher and student model as a phased process. The proposed SSCL approach regards the pervasive property of audiovisual concurrency as latent supervision and mutually distills the structure knowledge of visual to audio data. Notably, the SSCL method can learn discriminative audio and visual representations for various downstream applications. Extensive experiments conducted on both action video recognition and audio sound recognition tasks show the remarkably improved performance of the SSCL method compared with the state-of-the-art self-supervised audio-visual representation learning methods",
    "checked": true,
    "id": "261c03a9c904da9cecc48ab07b9859c35cf6aef1",
    "semantic_title": "enhancing audio-visual association with self-supervised curriculum learning",
    "citation_count": 10,
    "authors": [
      "Jingran Zhang",
      "Xing Xu",
      "Fumin Shen",
      "Huimin Lu",
      "Xin Liu",
      "Heng Tao Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16448": {
    "title": "Unsupervised Domain Adaptation for Person Re-identification via Heterogeneous Graph Alignment",
    "volume": "main",
    "abstract": "Unsupervised person re-identification (re-ID) is becoming increasingly popular due to its power in real-world systems such as public security and intelligent transportation systems. However, the person re-ID task is challenged by the problems of data distribution discrepancy across cameras and lack of label information. In this paper, we propose a coarse-to-fine heterogeneous graph alignment (HGA) method to find cross-camera person matches by characterizing the unlabeled data as a heterogeneous graph for each camera. In the coarse-alignment stage, we assign a projection for each camera and utilize an adversarial learning based method to align coarse-grained node groups from different cameras into a shared space, which consequently alleviates the distribution discrepancy between cameras. In the fine-alignment stage, we exploit potential fine-grained node groups in the shared space and introduce conservative alignment loss functions to constrain the graph aligning process, resulting in reliable pseudo labels as learning guidance. The proposed domain adaptation framework not only improves model generalization on target domain, but also facilitates mining and integrating the potential discriminative information across different cameras. Extensive experiments on benchmark datasets demonstrate that the proposed approach outperforms the state-of-the-arts",
    "checked": true,
    "id": "647e5882a0c66783bbabaee47d191478ad2f08ab",
    "semantic_title": "unsupervised domain adaptation for person re-identification via heterogeneous graph alignment",
    "citation_count": 23,
    "authors": [
      "Minying Zhang",
      "Kai Liu",
      "Yidong Li",
      "Shihui Guo",
      "Hongtao Duan",
      "Yimin Long",
      "Yi Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16449": {
    "title": "Proactive Privacy-preserving Learning for Retrieval",
    "volume": "main",
    "abstract": "Deep Neural Networks (DNNs) have recently achieved remarkable performance in image retrieval, yet posing great threats to data privacy. On the one hand, one may misuse a deployed DNNs based system to look up data without consent. On the other hand, organizations or individuals would legally or illegally collect data to train high-performance models outside the scope of legitimate purposes. Unfortunately, less effort has been made to safeguard data privacy against malicious uses of DNNs. In this paper, we propose a data-centric Proactive Privacy-preserving Learning (PPL) algorithm for hashing based retrieval, which achieves the protection purpose by employing a generator to transfer the original data into the adversarial data with quasi-imperceptible perturbations before releasing them. When the data source is infiltrated, the adversarial data can confuse menacing retrieval models to make erroneous predictions. Given that the prior knowledge of malicious models is not available, a surrogate retrieval model is instead introduced acting as a fooling target. The framework is trained by a two-player game conducted between the generator and the surrogate model. More specifically, the generator is updated to enlarge the gap between the adversarial data and the original data, aiming to lower the search accuracy of the surrogate model. On the contrary, the surrogate model is trained with the opposing objective that is to maintain the search performance. As a result, an effective and robust adversarial generator is encouraged. Furthermore, to facilitate an effective optimization, a Gradient Reversal Layer (GRL) module is inserted to connect two models, enabling the two-player game in a one-step learning. Extensive experiments on three widely-used realistic datasets prove the effectiveness of the proposed method",
    "checked": true,
    "id": "29dc41ef9225d4c88e18b831b9ee1f6edda903fd",
    "semantic_title": "proactive privacy-preserving learning for retrieval",
    "citation_count": 6,
    "authors": [
      "Peng-Fei Zhang",
      "Zi Huang",
      "Xin-Shun Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16450": {
    "title": "A Novel Visual Interpretability for Deep Neural Networks by Optimizing Activation Maps with Perturbation",
    "volume": "main",
    "abstract": "Interpretability has been regarded as an essential component for deploying deep neural networks, in which the saliency-based method is one of the most prevailing interpretable approaches since it can generate individually intuitive heatmaps that highlight parts of the input image that are most important to the decision of the deep networks on a particular classification target. However, heatmaps generated by existing methods either contain little information to represent objects (perturbation-based methods) or cannot effectively locate multi-class objects (activation-based approaches). To address this issue, a two-stage framework for visualizing the interpretability of deep neural networks, called Activation Optimized with Perturbation (AOP), is designed to optimize activation maps generated by general activation-based methods with the help of perturbation-based methods. Finally, in order to obtain better explanations for different types of images, we further present an instance of the AOP framework, Smooth Integrated Gradient-based Class Activation Map (SIGCAM), which proposes a weighted GradCAM by applying the feature map as weight coefficients and employs I-GOS to optimize the base-mask generated by weighted GradCAM. Experimental results on common-used benchmarks, including deletion and insertion tests on ImageNet-1k, and pointing game tests on COCO2017, show that the proposed AOP and SIGCAM outperform the current state-of-the-art methods significantly by generating higher quality image-based saliency maps",
    "checked": true,
    "id": "3300be8d4191f98b792a02847ca9876cb436a30c",
    "semantic_title": "a novel visual interpretability for deep neural networks by optimizing activation maps with perturbation",
    "citation_count": 12,
    "authors": [
      "Qinglong Zhang",
      "Lu Rao",
      "Yubin Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16451": {
    "title": "Point Cloud Semantic Scene Completion from RGB-D Images",
    "volume": "main",
    "abstract": "In this paper, we devise a novel semantic completion network, called point cloud semantic scene completion network (PCSSC-Net), for indoor scenes solely based on point clouds. Existing point cloud completion networks still suffer from their inability of fully recovering complex structures and contents from global geometric descriptions neglecting semantic hints. To extract and infer comprehensive information from partial input, we design a patch-based contextual encoder to hierarchically learn point-level, patch-level, and scene-level geometric and contextual semantic information with a divide-and-conquer strategy. Consider that the scene semantics afford a high-level clue of constituting geometry for an indoor scene environment, we articulate a semantics-guided completion decoder where semantics could help cluster isolated points in the latent space and infer complicated scene geometry. Given the fact that real-world scans tend to be incomplete as ground truth, we choose to synthesize scene dataset with RGB-D images and annotate complete point clouds as ground truth for the supervised training purpose. Extensive experiments validate that our new method achieves the state-of-the-art performance, in contrast with the current methods applied to our dataset",
    "checked": true,
    "id": "e9f5fb065ac85696101bd1c87977b406f9bf47aa",
    "semantic_title": "point cloud semantic scene completion from rgb-d images",
    "citation_count": 5,
    "authors": [
      "Shoulong Zhang",
      "Shuai Li",
      "Aimin Hao",
      "Hong Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16452": {
    "title": "Consensus Graph Representation Learning for Better Grounded Image Captioning",
    "volume": "main",
    "abstract": "The contemporary visual captioning models frequently hallucinate objects that are not actually in a scene, due to the visual misclassification or over-reliance on priors that resulting in the semantic inconsistency between the visual information and the target lexical words. The most common way is to encourage the captioning model to dynamically link generated object words or phrases to appropriate regions of the image, i.e., the grounded image captioning (GIC). However, GIC utilizes an auxiliary task (grounding objects) that has not solved the key issue of object hallucination, i.e., the semantic inconsistency. In this paper, we take a novel perspective on the issue above: exploiting the semantic coherency between the visual and language modalities. Specifically, we propose the Consensus Rraph Representation Learning framework (CGRL) for GIC that incorporates a consensus representation into the grounded captioning pipeline. The consensus is learned by aligning the visual graph (e.g., scene graph) to the language graph that consider both the nodes and edges in a graph. With the aligned consensus, the captioning model can capture both the correct linguistic characteristics and visual relevance, and then grounding appropriate image regions further. We validate the effectiveness of our model, with a significant decline in object hallucination (-9% CHAIRi) on the Flickr30k Entities dataset. Besides, our CGRL also evaluated by several automatic metrics and human evaluation, the results indicate that the proposed approach can simultaneously improve the performance of image captioning (+2.9 Cider) and grounding (+2.3 F1LOC})",
    "checked": true,
    "id": "7d1d75e7830a34642508763e3b538a701ee11958",
    "semantic_title": "consensus graph representation learning for better grounded image captioning",
    "citation_count": 35,
    "authors": [
      "Wenqiao Zhang",
      "Haochen Shi",
      "Siliang Tang",
      "Jun Xiao",
      "Qiang Yu",
      "Yueting Zhuang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16453": {
    "title": "BoW Pooling: A Plug-and-Play Unit for Feature Aggregation of Point Clouds",
    "volume": "main",
    "abstract": "Point cloud provides a compact and flexible representation for 3D shapes and recently attracts more and more attention due to the increasing demands in practical applications. The major challenge of handling such irregular data is how to achieve the permutation invariance of points in the input. Most of existing methods extract local descriptors that encode the geometry of local structure, followed by a symmetric function to form a global representation. The max pooling usually serves as the symmetric function and shows slight superiority compared to the average pooling. We argue that some discrimination information is inevitably missing when applying the max pooling across all local descriptors. In this paper, we propose the BoW pooling, a plug-and-play unit to substitute the max pooling. Our BoW pooling analyzes the set of local descriptors statistically and generates a histogram that reflects how the primitives in the dictionary constitute the overall geometry. Extensive experiments demonstrate that the proposed Bow pooling is efficient to improve the performance in point cloud classification, shape retrieval and segmentation tasks and outperforms other existing symmetric functions",
    "checked": true,
    "id": "62b2a7956015d89ddf713301eab111e88a31fbdc",
    "semantic_title": "bow pooling: a plug-and-play unit for feature aggregation of point clouds",
    "citation_count": 5,
    "authors": [
      "Xiang Zhang",
      "Xiao Sun",
      "Zhouhui Lian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16454": {
    "title": "Diverse Knowledge Distillation for End-to-End Person Search",
    "volume": "main",
    "abstract": "Person search aims to localize and identify a specific person from a gallery of images. Recent methods can be categorized into two groups, i.e., two-step and end-to-end approaches. The former views person search as two independent tasks and achieves dominant results using separately trained person detection and re-identification (Re-ID) models. The latter performs person search in an end-to-end fashion. Although the end-to-end approaches yield higher inference efficiency, they largely lag behind those two-step counterparts in terms of accuracy. In this paper, we argue that the gap between the two kinds of methods is mainly caused by the Re-ID sub-networks of end-to-end methods. To this end, we propose a simple yet strong end-to-end network with diverse knowledge distillation to break the bottleneck. We also design a spatial-invariant augmentation to assist model to be invariant to inaccurate detection results. Experimental results on the CUHK-SYSU and PRW datasets demonstrate the superiority of our method against existing approaches -- it achieves on par accuracy with state-of-the-art two-step methods while maintaining high efficiency due to the single joint model. Code is available at: https://git.io/DKD-PersonSearch",
    "checked": true,
    "id": "f46d48e2afc0ec4c397db66557e80f42e765809a",
    "semantic_title": "diverse knowledge distillation for end-to-end person search",
    "citation_count": 28,
    "authors": [
      "Xinyu Zhang",
      "Xinlong Wang",
      "Jia-Wang Bian",
      "Chunhua Shen",
      "Mingyu You"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16455": {
    "title": "Weakly Supervised Semantic Segmentation for Large-Scale Point Cloud",
    "volume": "main",
    "abstract": "Existing methods for large-scale point cloud semantic segmentation require expensive, tedious and error-prone manual point-wise annotation. Intuitively, weakly supervised training is a direct solution to reduce the labeling costs. However, for weakly supervised large-scale point cloud semantic segmentation, too few annotations will inevitably lead to ineffective learning of network. We propose an effective weakly supervised method containing two components to solve the above problem. Firstly, we construct a pretext task, \\textit{i.e.,} point cloud colorization, with a self-supervised training manner to transfer the learned prior knowledge from a large amount of unlabeled point cloud to a weakly supervised network. In this way, the representation capability of the weakly supervised network can be improved by knowledge from a heterogeneous task. Besides, to generative pseudo label for unlabeled data, a sparse label propagation mechanism is proposed with the help of generated class prototypes, which is used to measure the classification confidence of unlabeled point. Our method is evaluated on large-scale point cloud datasets with different scenarios including indoor and outdoor. The experimental results show the large gain against existing weakly supervised methods and comparable results to fully supervised methods",
    "checked": true,
    "id": "cbc760cb2ca8fb3d097bd6166c3820e58ca1a607",
    "semantic_title": "weakly supervised semantic segmentation for large-scale point cloud",
    "citation_count": 42,
    "authors": [
      "Yachao Zhang",
      "Zonghao Li",
      "Yuan Xie",
      "Yanyun Qu",
      "Cuihua Li",
      "Tao Mei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16456": {
    "title": "PC-RGNN: Point Cloud Completion and Graph Neural Network for 3D Object Detection",
    "volume": "main",
    "abstract": "LiDAR-based 3D object detection is an important task for autonomous driving and current approaches suffer from sparse and partial point clouds caused by distant and occluded objects. In this paper, we propose a novel two-stage framework, namely PC-RGNN, which deals with these challenges by two specific solutions. On the one hand, we introduce a point cloud completion module to recover high-quality proposals of dense points and entire view with original structures preserved. On the other hand, a graph neural network module, is designed, which comprehensively captures relations among points by the local-global attention mechanism as well as the multi-scale graph based context aggregation and substantially strengthens encoded features. Extensive experiments on the KITTI benchmark show that the proposed approach outperforms the previous state-of-the-art baselines by remarkable margins, highlighting its effectiveness",
    "checked": true,
    "id": "6452b177ec8c832e388d1dbd60cc4c17b3e007b7",
    "semantic_title": "pc-rgnn: point cloud completion and graph neural network for 3d object detection",
    "citation_count": 34,
    "authors": [
      "Yanan Zhang",
      "Di Huang",
      "Yunhong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16457": {
    "title": "Efficient License Plate Recognition via Holistic Position Attention",
    "volume": "main",
    "abstract": "License plate recognition (LPR) is a fundamental component of various intelligent transportation systems, and is always expected to be accurate and efficient enough in real-world applications. Nowadays, recognition of single character has been sophisticated benefiting from the power of deep learning, and extracting position information for forming a character sequence becomes the main bottleneck of LPR. To tackle this issue, we propose a novel holistic position attention (HPA) in this paper that consists of position network and shared classifier. Specifically, the position network explicitly encodes the character position into the maps of HPA, and then the shared classifier performs the character recognition in a unified and parallel way. Here the extracted features are modulated by the attention maps before feeding into the classifier to yield the final recognition results. Note that our proposed method is end-to-end trainable, character recognition can be concurrently performed, and no post-processing is needed. Thus our LPR system can achieve good effectiveness and efficiency simultaneously. The experimental results on four public datasets, including AOLP, Media Lab, CCPD, and CLPD, well demonstrate the superiority of our method to previous state-of-the-art methods in both accuracy and speed",
    "checked": true,
    "id": "66c37f7cf1461cd44dcc75d0271da0cb9ac6d3bb",
    "semantic_title": "efficient license plate recognition via holistic position attention",
    "citation_count": 5,
    "authors": [
      "Yesheng Zhang",
      "Zilei Wang",
      "Jiafan Zhuang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16458": {
    "title": "Bag of Tricks for Long-Tailed Visual Recognition with Deep Convolutional Neural Networks",
    "volume": "main",
    "abstract": "In recent years, visual recognition on challenging long-tailed distributions, where classes often exhibit extremely imbalanced frequencies, has made great progress mostly based on various complex paradigms (e.g., meta learning). Apart from these complex methods, simple refinements on training procedures also make contributions. These refinements, also called tricks, are minor but effective, such as adjustments in the data distribution or loss functions. However, different tricks might conflict with each other. If users apply these long-tail related tricks inappropriately, it could cause worse recognition accuracy than expected. Unfortunately, there has not been a scientific guideline of these tricks in the literature. In this paper, we first collect existing tricks in long-tailed visual recognition and then perform extensive and systematic experiments, in order to give a detailed experimental guideline and obtain an effective combination of these tricks. Furthermore, we also propose a novel data augmentation approach based on class activation maps for long-tailed recognition, which can be friendly combined with re-sampling methods and shows excellent results. By assembling these tricks scientifically, we can outperform state-of-the-art methods on four long-tailed benchmark datasets, including ImageNet-LT and iNaturalist 2018. Our code is open-source and available at https://github.com/zhangyongshun/BagofTricks-LT",
    "checked": true,
    "id": "36df3b2ce26ebd8460bc1dfd55245efc6a514973",
    "semantic_title": "bag of tricks for long-tailed visual recognition with deep convolutional neural networks",
    "citation_count": 80,
    "authors": [
      "Yongshun Zhang",
      "Xiu-Shen Wei",
      "Boyan Zhou",
      "Jianxin Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16459": {
    "title": "Depth Privileged Object Detection in Indoor Scenes via Deformation Hallucination",
    "volume": "main",
    "abstract": "RGB-D object detection has achieved significant advance, because depth provides complementary geometric information to RGB images. Considering depth images are unavailable in some scenarios, we focus on depth privileged object detection in indoor scenes, where the depth images are only available in the training phase. Under this setting, one prevalent research line is modality hallucination, in which depth image and depth feature are the common choices for hallucinating. In contrast, we choose to hallucinate depth deformation, which is explicit geometric information and efficient to hallucinate. Specifically, we employ the deformable convolution layer with augmented offsets as our deformation module and regard the offsets as geometric deformation, because the offsets enable flexibly sampling over the object and transforming to a canonical shape for ease of detection. In addition, we design a quality-based mechanism to avoid negative transfer of depth deformation. Experimental results and analyses on NYUDv2 and SUN RGB-D demonstrate the effectiveness of our method against the state-of-the-art methods for depth privileged object detection",
    "checked": true,
    "id": "ca9132b955812b2cdc6ab74d1458fcd78c8b4d4f",
    "semantic_title": "depth privileged object detection in indoor scenes via deformation hallucination",
    "citation_count": 5,
    "authors": [
      "Zhijie Zhang",
      "Yan Liu",
      "Junjie Chen",
      "Li Niu",
      "Liqing Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16460": {
    "title": "Learning Flexibly Distributional Representation for Low-quality 3D Face Recognition",
    "volume": "main",
    "abstract": "Due to the superiority of using geometric information, 3D Face Recognition (FR) has achieved great successes. Existing methods focus on high-quality 3D FR which is unpractical in real scenarios. Low-quality 3D FR is a more realistic scenario but the low-quality data are born with heavy noises. Therefore, exploring noise-robust low-quality 3D FR methods becomes an urgent and challenging problem. To solve this issue, in this paper, we propose to learn flexibly distributional representation for low-quality 3D FR. Firstly, we introduce the distributional representation for low-quality 3D faces due to that it can weaken the impact of noises. Generally, the distributional representation of a given 3D face is restricted to a specific distribution such as Gaussian distribution. However, the specific distribution may be not up to describing the complex low-quality face. Therefore, we propose to transform this specific distribution to a flexible one via Continuous Normalizing Flow (CNF), which can get rid of the form limitation. This kind of flexible distribution can approximate the latent distribution of the given noisy face more accurately, which further improves accuracy of low-quality 3D FR. Comprehensive experiments show that our proposed method improves both low-quality and cross-quality 3D FR performances on low-quality benchmarks. Furthermore, the improvements are more remarkable on low-quality 3D faces when the intensity of noise increases which indicate the robustness",
    "checked": true,
    "id": "f34816978c5560250e5f3d6531f7d429bc670b24",
    "semantic_title": "learning flexibly distributional representation for low-quality 3d face recognition",
    "citation_count": 6,
    "authors": [
      "Zihui Zhang",
      "Cuican Yu",
      "Shuang Xu",
      "Huibin Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16461": {
    "title": "IA-GM: A Deep Bidirectional Learning Method for Graph Matching",
    "volume": "main",
    "abstract": "Existing deep learning methods for graph matching(GM) problems usually considered affinity learningto assist combinatorial optimization in a feedforward pipeline, and parameter learning is executed by back-propagating the gradients of the matching loss. Such a pipeline pays little attention to the possible complementary benefit from the optimization layer to the learning component. In this paper, we overcome the above limitation under a deep bidirectional learning framework.Our method circulates the output of the GM optimization layer to fuse with the input for affinity learning. Such direct feedback enhances the input by a feature enrichment and fusion technique, which exploits andintegrates the global matching patterns from the deviation of the similarity permuted by the current matching estimate. As a result, the circulation enables the learning component to benefit from the optimization process, taking advantage of both global feature and the embedding result which is calculated by local propagationthrough node-neighbors. Moreover, circulation consistency induces an unsupervised loss that can be implemented individually or jointly to regularize the supervised loss. Experiments on challenging datasets demonstrate the effectiveness of our methods for both supervised learning and unsupervised learning",
    "checked": true,
    "id": "ca64fd7bafca59d35bfd001f04efd46b9fb79748",
    "semantic_title": "ia-gm: a deep bidirectional learning method for graph matching",
    "citation_count": 9,
    "authors": [
      "Kaixuan Zhao",
      "Shikui Tu",
      "Lei Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16462": {
    "title": "Distribution Adaptive INT8 Quantization for Training CNNs",
    "volume": "main",
    "abstract": "Researches have demonstrated that low bit-width (e.g., INT8) quantization can be employed to accelerate the inference process. It makes the gradient quantization very promising since the backward propagation requires approximately twice more computation than forward one. Due to the variability and uncertainty of gradient distribution, a lot of methods have been proposed to attain training stability. However, most of them ignore the channel-wise gradient distributions and the impact of gradients with different magnitudes, resulting in the degradation of final accuracy. In this paper, we propose a novel INT8 quantization training framework for convolutional neural network to address the above issues. Specifically, we adopt Gradient Vectorized Quantization to quantize the gradient, based on the observation that layer-wise gradients contain multiple distributions along the channel dimension. Then, Magnitude-aware Clipping Strategy is introduced by taking the magnitudes of gradients into consideration when minimizing the quantization error, and we present a theoretical derivation to solve the quantization parameters of different distributions. Experimental results on broad range of computer vision tasks, such as image classification, object detection and video classification, demonstrate that the proposed Distribution Adaptive INT8 Quantization training method has achieved almost lossless training accuracy for different backbones, including ResNet, MobileNetV2, InceptionV3, VGG and AlexNet, which is superior to the state-of-the-art techniques. Moreover, we further implement the INT8 kernel that can accelerate the training iteration more than 200% under the latest Turing architecture, i.e., our method excels on both training accuracy and speed",
    "checked": true,
    "id": "7240d82352e1eea633edc925c0903a72920e642b",
    "semantic_title": "distribution adaptive int8 quantization for training cnns",
    "citation_count": 32,
    "authors": [
      "Kang Zhao",
      "Sida Huang",
      "Pan Pan",
      "Yinghan Li",
      "Yingya Zhang",
      "Zhenyu Gu",
      "Yinghui Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16463": {
    "title": "Context-Guided Adaptive Network for Efficient Human Pose Estimation",
    "volume": "main",
    "abstract": "Although recent work has achieved great progress in human pose estimation (HPE), most methods show limitations in either inference speed or accuracy. In this paper, we propose a fast and accurate end-to-end HPE method, which is specifically designed to overcome the commonly encountered jitter box, defective box and ambiguous box problems of box-based methods, e.g. Mask R-CNN. Concretely, 1) we propose the ROIGuider to aggregate box instance features from all feature levels under the guidance of global context instance information. Further, 2) the proposed Center Line Branch is equipped with a Dichotomy Extended Area algorithm to adaptively expand each instance box area, and Ambiguity Alleviation strategy to eliminate duplicated keypoints. Finally, 3) to achieve efficient multi-scale feature fusion and real-time inference, we design a novel Trapezoidal Network (TNet) backbone. Experimenting on the COCO dataset, our method achieves 68.1 AP at 25.4 fps, and outperforms Mask-RCNN by 8.9 AP at a similar speed. The competitive performance on the HPE and person instance segmentation tasks over the state-of-the-art models show the promise of the proposed method. The source code will be made available at https://github.com/zlcnup/CGANet",
    "checked": true,
    "id": "d68f4e2c382f33552c620c2b6ac065fc4dfad09e",
    "semantic_title": "context-guided adaptive network for efficient human pose estimation",
    "citation_count": 2,
    "authors": [
      "Lei Zhao",
      "Jun Wen",
      "Pengfei Wang",
      "Nenggan Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16464": {
    "title": "ePointDA: An End-to-End Simulation-to-Real Domain Adaptation Framework for LiDAR Point Cloud Segmentation",
    "volume": "main",
    "abstract": "Due to its robust and precise distance measurements, LiDAR plays an important role in scene understanding for autonomous driving. Training deep neural networks (DNNs) on LiDAR data requires large-scale point-wise annotations, which are time-consuming and expensive to obtain. Instead, simulation-to-real domain adaptation (SRDA) trains a DNN using unlimited synthetic data with automatically generated labels and transfers the learned model to real scenarios. Existing SRDA methods for LiDAR point cloud segmentation mainly employ a multi-stage pipeline and focus on feature-level alignment. They require prior knowledge of real-world statistics and ignore the pixel-level dropout noise gap and the spatial feature gap between different domains. In this paper, we propose a novel end-to-end framework, named ePointDA, to address the above issues. Specifically, ePointDA consists of three modules: self-supervised dropout noise rendering, statistics-invariant and spatially-adaptive feature alignment, and transferable segmentation learning. The joint optimization enables ePointDA to bridge the domain shift at the pixel-level by explicitly rendering dropout noise for synthetic LiDAR and at the feature-level by spatially aligning the features between different domains, without requiring the real-world statistics. Extensive experiments adapting from synthetic GTA-LiDAR to real KITTI and SemanticKITTI demonstrate the superiority of ePointDA for LiDAR point cloud segmentation",
    "checked": true,
    "id": "83da7e0bb2adb4a7d7b2d132ffda857e0bbd3841",
    "semantic_title": "epointda: an end-to-end simulation-to-real domain adaptation framework for lidar point cloud segmentation",
    "citation_count": 48,
    "authors": [
      "Sicheng Zhao",
      "Yezhen Wang",
      "Bo Li",
      "Bichen Wu",
      "Yang Gao",
      "Pengfei Xu",
      "Trevor Darrell",
      "Kurt Keutzer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16465": {
    "title": "Robust Lightweight Facial Expression Recognition Network with Label Distribution Training",
    "volume": "main",
    "abstract": "This paper presents an efficiently robust facial expression recognition (FER) network, named EfficientFace, which holds much fewer parameters but more robust to the FER in the wild. Firstly, to improve the robustness of the lightweight network, a local-feature extractor and a channel-spatial modulator are designed, in which the depthwise convolution is employed. As a result, the network is aware of local and global-salient facial features. Then, considering the fact that most emotions occur as combinations, mixtures, or compounds of the basic emotions, we introduce a simple but efficient label distribution learning (LDL) method as a novel training strategy. Experiments conducted on realistic occlusion and pose variation datasets demonstrate that the proposed EfficientFace is robust under occlusion and pose variation conditions. Moreover, the proposed method achieves state-of-the-art results on RAF-DB, CAER-S, and AffectNet-7 datasets with accuracies of 88.36%, 85.87%, and 63.70%, respectively, and a comparable result on the AffectNet-8 dataset with an accuracy of 59.89%. The code is public available at https://github.com/zengqunzhao/EfficientFace",
    "checked": true,
    "id": "fc4f0a2d0a18cb9dba465b1e0e9b14a9b5dee2f9",
    "semantic_title": "robust lightweight facial expression recognition network with label distribution training",
    "citation_count": 83,
    "authors": [
      "Zengqun Zhao",
      "Qingshan Liu",
      "Feng Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16466": {
    "title": "Joint Color-irrelevant Consistency Learning and Identity-aware Modality Adaptation for Visible-infrared Cross Modality Person Re-identification",
    "volume": "main",
    "abstract": "Visible-infrared cross modality person re-identification (VI-ReID) is a core but challenging technology in the 24-hours intelligent surveillance system. How to eliminate the large modality gap lies in the heart of VI-ReID. Conventional methods mainly focus on directly aligning the heterogeneous modalities into the same space. However, due to the unbalanced color information between the visible and infrared images, the features of visible images tend to overfit the clothing color information, which would be harmful to the modality alignment. Besides, these methods mainly align the heterogeneous feature distributions in dataset-level while ignoring the valuable identity information, which may cause the feature misalignment of some identities and weaken the discrimination of features. To tackle above problems, we propose a novel approach for VI-ReID. It learns the color-irrelevant features through the color-irrelevant consistency learning (CICL) and aligns the identity-level feature distributions by the identity-aware modality adaptation (IAMA). The CICL and IAMA are integrated into a joint learning framework and can promote each other. Extensive experiments on two popular datasets SYSU-MM01 and RegDB demonstrate the superiority and effectiveness of our approach against the state-of-the-art methods",
    "checked": true,
    "id": "bc50aa3af1f42a353b3205d5d88f501efafa1f26",
    "semantic_title": "joint color-irrelevant consistency learning and identity-aware modality adaptation for visible-infrared cross modality person re-identification",
    "citation_count": 25,
    "authors": [
      "Zhiwei Zhao",
      "Bin Liu",
      "Qi Chu",
      "Yan Lu",
      "Nenghai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16467": {
    "title": "Robust Multi-Modality Person Re-identification",
    "volume": "main",
    "abstract": "To avoid the illumination limitation in visible person re-identification (Re-ID) and the heterogeneous issue in cross-modality Re-ID, we propose to utilize complementary advantages of multiple modalities including visible (RGB), near infrared (NI) and thermal infrared (TI) ones for robust person Re-ID. A novel progressive fusion network is designed to learn effective multi-modal features from single to multiple modalities and from local to global views. Our method works well in diversely challenging scenarios even in the presence of missing modalities. Moreover, we contribute a comprehensive benchmark dataset, RGBNT201, including 201 identities captured from various challenging conditions, to facilitate the research of RGB-NI-TI multi-modality person Re-ID. Comprehensive experiments on RGBNT201 dataset comparing to the state-of-the-art methods demonstrate the contribution of multi-modality person Re-ID and the effectiveness of the proposed approach, which launch a new benchmark and a new baseline for multi-modality person Re-ID",
    "checked": true,
    "id": "1d382a6ff6f156852375c059381dcd48081bf0f3",
    "semantic_title": "robust multi-modality person re-identification",
    "citation_count": 13,
    "authors": [
      "Aihua Zheng",
      "Zi Wang",
      "Zihan Chen",
      "Chenglong Li",
      "Jin Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16468": {
    "title": "Exploiting Sample Uncertainty for Domain Adaptive Person Re-Identification",
    "volume": "main",
    "abstract": "Many unsupervised domain adaptive (UDA) person ReID approaches combine clustering-based pseudo-label prediction with feature fine-tuning. However, because of domain gap, the pseudo-labels are not always reliable and there are noisy/incorrect labels. This would mislead the feature representation learning and deteriorate the performance. In this paper, we propose to estimate and exploit the credibility of the assigned pseudo-label of each sample to alleviate the influence of noisy labels, by suppressing the contribution of noisy samples. We build our baseline framework using the mean teacher method together with an additional contrastive loss. We have observed that a sample with a wrong pseudo-label through clustering in general has a weaker consistency between the output of the mean teacher model and the student model. Based on this finding, we propose to exploit the uncertainty (measured by consistency levels) to evaluate the reliability of the pseudo-label of a sample and incorporate the uncertainty to re-weight its contribution within various ReID losses, including the ID classification loss per sample, the triplet loss, and the contrastive loss. Our uncertainty-guided optimization brings significant improvement and achieves the state-of-the-art performance on benchmark datasets",
    "checked": true,
    "id": "d477e72f93d8b895fd0ccc38f2a1cc04bf96e3f1",
    "semantic_title": "exploiting sample uncertainty for domain adaptive person re-identification",
    "citation_count": 104,
    "authors": [
      "Kecheng Zheng",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Zhizheng Zhang",
      "Zheng-Jun Zha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16469": {
    "title": "RESA: Recurrent Feature-Shift Aggregator for Lane Detection",
    "volume": "main",
    "abstract": "Lane detection is one of the most important tasks in self-driving. Due to various complex scenarios (e.g., severe occlusion, ambiguous lanes, etc.) and the sparse supervisory signals inherent in lane annotations, lane detection task is still challenging. Thus, it is difficult for the ordinary convolutional neural network (CNN) to train in general scenes to catch subtle lane feature from the raw image. In this paper, we present a novel module named REcurrent Feature-Shift Aggregator (RESA) to enrich lane feature after preliminary feature extraction with an ordinary CNN. RESA takes advantage of strong shape priors of lanes and captures spatial relationships of pixels across rows and columns. It shifts sliced feature map recurrently in vertical and horizontal directions and enables each pixel to gather global information. RESA can conjecture lanes accurately in challenging scenarios with weak appearance clues by aggregating sliced feature map. Moreover, we propose a Bilateral Up-Sampling Decoder that combines coarse-grained and fine-detailed features in the up-sampling stage. It can recover the low-resolution feature map into pixel-wise prediction meticulously. Our method achieves state-of-the-art results on two popular lane detection benchmarks (CULane and Tusimple). Code has been made available at: https://github.com/ZJULearning/resa",
    "checked": true,
    "id": "15154250e0f4536116a8984037bfd062c10fc535",
    "semantic_title": "resa: recurrent feature-shift aggregator for lane detection",
    "citation_count": 99,
    "authors": [
      "Tu Zheng",
      "Hao Fang",
      "Yi Zhang",
      "Wenjian Tang",
      "Zheng Yang",
      "Haifeng Liu",
      "Deng Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16470": {
    "title": "CIA-SSD: Confident IoU-Aware Single-Stage Object Detector From Point Cloud",
    "volume": "main",
    "abstract": "Existing single-stage detectors for locating objects in point clouds often treat object localization and category classification as separate tasks, so the localization accuracy and classification confidence may not well align. To address this issue, we present a new single-stage detector named the Confident IoU-Aware Single-Stage object Detector (CIA-SSD). First, we design the lightweight Spatial-Semantic Feature Aggregation module to adaptively fuse high-level abstract semantic features and low-level spatial features for accurate predictions of bounding boxes and classification confidence. Also, the predicted confidence is further rectified with our designed IoU-aware confidence rectification module to make the confidence more consistent with the localization accuracy. Based on the rectified confidence, we further formulate the Distance-variant IoU-weighted NMS to obtain smoother regressions and avoid redundant predictions. We experiment CIA-SSD on 3D car detection in the KITTI test set and show that it attains top performance in terms of the official ranking metric (moderate AP 80.28%) and above 32 FPS inference speed, outperforming all prior single-stage detectors. The code is available at https://github.com/Vegeta2020/CIA-SSD",
    "checked": true,
    "id": "65a60ace6af2c061d5000688727d712c2755e955",
    "semantic_title": "cia-ssd: confident iou-aware single-stage object detector from point cloud",
    "citation_count": 161,
    "authors": [
      "Wu Zheng",
      "Weiliang Tang",
      "Sijin Chen",
      "Li Jiang",
      "Chi-Wing Fu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16471": {
    "title": "Regional Attention with Architecture-Rebuilt 3D Network for RGB-D Gesture Recognition",
    "volume": "main",
    "abstract": "Human gesture recognition has drawn much attention in the area of computer vision. However, the performance of gesture recognition is always influenced by some gesture-irrelevant factors like the background and the clothes of performers. Therefore, focusing on the regions of hand/arm is important to the gesture recognition. Meanwhile, a more adaptive architecture-searched network structure can also perform better than the block-fixed ones like ResNet since it increases the diversity of features in different stages of the network better. In this paper, we propose a regional attention with architecture-rebuilt 3D network (RAAR3DNet) for gesture recognition. We replace the fixed Inception modules with the automatically rebuilt structure through the network via Neural Architecture Search (NAS), owing to the different shape and representation ability of features in the early, middle, and late stage of the network. It enables the network to capture different levels of feature representations at different layers more adaptively. Meanwhile, we also design a stackable regional attention module called Dynamic-Static Attention (DSA), which derives a Gaussian guidance heatmap and dynamic motion map to highlight the hand/arm regions and the motion information in the spatial and temporal domains, respectively. Extensive experiments on two recent large-scale RGB-D gesture datasets validate the effectiveness of the proposed method and show it outperforms state-of-the-art methods. The codes of our method are available at: https://github.com/zhoubenjia/RAAR3DNet",
    "checked": true,
    "id": "011eb1b8ec239673c288a002d67de28d075f53db",
    "semantic_title": "regional attention with architecture-rebuilt 3d network for rgb-d gesture recognition",
    "citation_count": 12,
    "authors": [
      "Benjia Zhou",
      "Yunan Li",
      "Jun Wan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16472": {
    "title": "Deep Semantic Dictionary Learning for Multi-label Image Classification",
    "volume": "main",
    "abstract": "Compared with single-label image classification, multi-label image classification is more practical and challenging. Some recent studies attempted to leverage the semantic information of categories for improving multi-label image classification performance. However, these semantic-based methods only take semantic information as type of complements for visual representation without further exploitation. In this paper, we present an innovative path towards the solution of the multi-label image classification which considers it as a dictionary learning task. A novel end-to-end model named Deep Semantic Dictionary Learning (DSDL) is designed. In DSDL, an auto-encoder is applied to generate the semantic dictionary from class-level semantics and then such dictionary is utilized for representing the visual features extracted by Convolutional Neural Network (CNN) with label embeddings. The DSDL provides a simple but elegant way to exploit and reconcile the label, semantic and visual spaces simultaneously via conducting the dictionary learning among them. Moreover, inspired by iterative optimization of traditional dictionary learning, we further devise a novel training strategy named Alternately Parameters Update Strategy (APUS) for optimizing DSDL, which alternately optimizes the representation coefficients and the semantic dictionary in forward and backward propagation. Extensive experimental results on three popular benchmarks demonstrate that our method achieves promising performances in comparison with the state-of-the-arts. Our codes and models have been released",
    "checked": true,
    "id": "a3c07082b420c9d8b4864124b68ae7b256a0ae91",
    "semantic_title": "deep semantic dictionary learning for multi-label image classification",
    "citation_count": 34,
    "authors": [
      "Fengtao Zhou",
      "Sheng Huang",
      "Yun Xing"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16473": {
    "title": "Model Uncertainty Guides Visual Object Tracking",
    "volume": "main",
    "abstract": "Model object trackers largely rely on the online learning of a discriminative classifier from potentially diverse sample frames. However, noisy or insufficient amounts of samples can deteriorate the classifiers' performance and cause tracking drift. Furthermore, alterations such as occlusion and blurring can cause the target to be lost. In this paper, we make several improvements aimed at tackling uncertainty and improving robustness in object tracking. Our first and most important contribution is to propose a sampling method for the online learning of object trackers based on uncertainty adjustment: our method effectively selects representative sample frames to feed the discriminative branch of the tracker, while filtering out noise samples. Furthermore, to improve the robustness of the tracker to various challenging scenarios, we propose a novel data augmentation procedure, together with a specific improved backbone architecture. All our improvements fit together in one model, which we refer to as the Uncertainty Adjusted Tracker (UATracker), and can be trained in a joint and end-to-end fashion. Experiments on the LaSOT, UAV123, OTB100 and VOT2018 benchmarks demonstrate that our UATracker outperforms state-of-the-art real-time trackers by significant margins",
    "checked": true,
    "id": "fe5e0b7bbb8cbb3bdc3b955cc942b5f3d76274f0",
    "semantic_title": "model uncertainty guides visual object tracking",
    "citation_count": 5,
    "authors": [
      "Lijun Zhou",
      "Antoine Ledent",
      "Qintao Hu",
      "Ting Liu",
      "Jianlin Zhang",
      "Marius Kloft"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16474": {
    "title": "Optimizing Information Theory Based Bitwise Bottlenecks for Efficient Mixed-Precision Activation Quantization",
    "volume": "main",
    "abstract": "Recent researches on information theory shed new light on the continuous attempts to open the black box of neural signal encoding. Inspired by the problem of lossy signal compression for wireless communication, this paper presents a Bitwise Bottleneck approach for quantizing and encoding neural network activations. Based on the rate-distortion theory, the Bitwise Bottleneck attempts to determine the most significant bits in activation representation by assigning and approximating the sparse coefficients associated with different bits. Given the constraint of a limited average code rate, the bottleneck minimizes the distortion for optimal activation quantization in a flexible layer-by-layer manner. Experiments over ImageNet and other datasets show that, by minimizing the quantization distortion of each layer, the neural network with bottlenecks achieves the state-of-the-art accuracy with low-precision activation. Meanwhile, by reducing the code rate, the proposed method can improve the memory and computational efficiency by over six times compared with the deep neural network with standard single-precision representation. The source code is available on GitHub: https://github.com/CQUlearningsystemgroup/BitwiseBottleneck",
    "checked": true,
    "id": "72164cce8cee40d3bfeff22e1c565c8ce9c352ff",
    "semantic_title": "optimizing information theory based bitwise bottlenecks for efficient mixed-precision activation quantization",
    "citation_count": 0,
    "authors": [
      "Xichuan Zhou",
      "Kui Liu",
      "Cong Shi",
      "Haijun Liu",
      "Ji Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16475": {
    "title": "Inferring Camouflaged Objects by Texture-Aware Interactive Guidance Network",
    "volume": "main",
    "abstract": "Camouflaged objects, similar to the background, show indefinable boundaries and deceptive textures, which increases the difficulty of detection task and makes the model rely on features with more information. Herein, we design a texture label to facilitate our network for accurate camouflaged object segmentation. Motivated by the complementary relationship between texture labels and camouflaged object labels, we propose an interactive guidance framework named TINet, which focuses on finding the indefinable boundary and the texture difference by progressive interactive guidance. It maximizes the guidance effect of refined multi-level texture cues on segmentation. Specifically, texture perception decoder (TPD) makes a comprehensive analysis of texture information in multiple scales. Feature interaction guidance decoder (FGD) interactively refines multi-level features of camouflaged object detection and texture detection level by level. Holistic perception decoder (HPD) enhances FGD results by multi-level holistic perception. In addition, we propose a boundary weight map to help the loss function pay more attention to the object boundary. Sufficient experiments conducted on COD and SOD datasets demonstrate that the proposed method performs favorably against 23 state-of-the-art methods",
    "checked": true,
    "id": "43e4bb7ab85eab07b785de49cb51275047b7af97",
    "semantic_title": "inferring camouflaged objects by texture-aware interactive guidance network",
    "citation_count": 39,
    "authors": [
      "Jinchao Zhu",
      "Xiaoyu Zhang",
      "Shuo Zhang",
      "Junnan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16476": {
    "title": "Simple is not Easy: A Simple Strong Baseline for TextVQA and TextCaps",
    "volume": "main",
    "abstract": "Texts appearing in daily scenes that can be recognized by OCR (Optical Character Recognition) tools contain significant information, such as street name, product brand and prices. Two tasks -- text-based visual question answering and text-based image captioning, with a text extension from existing vision-language applications, are catching on rapidly. To address these problems, many sophisticated multi-modality encoding frameworks (such as heterogeneous graph structure) are being used. In this paper, we argue that a simple attention mechanism can do the same or even better job without any bells and whistles. Under this mechanism, we simply split OCR token features into separate visual- and linguistic-attention branches, and send them to a popular Transformer decoder to generate answers or captions. Surprisingly, we find this simple baseline model is rather strong -- it consistently outperforms state-of-the-art (SOTA) models on two popular benchmarks, TextVQA and all three tasks of ST-VQA, although these SOTA models use far more complex encoding mechanisms. Transferring it to text-based image captioning, we also surpass the TextCaps Challenge 2020 winner. We wish this work to set the new baseline for these two OCR text related applications and to inspire new thinking of multi-modality encoder design. Code is available at https://github.com/ZephyrZhuQi/ssbaseline",
    "checked": true,
    "id": "952edddbb3438072312756762be1bfde287e1497",
    "semantic_title": "simple is not easy: a simple strong baseline for textvqa and textcaps",
    "citation_count": 38,
    "authors": [
      "Qi Zhu",
      "Chenyu Gao",
      "Peng Wang",
      "Qi Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16477": {
    "title": "Fooling Thermal Infrared Pedestrian Detectors in Real World Using Small Bulbs",
    "volume": "main",
    "abstract": "Thermal infrared detection systems play an important role in many areas such as night security, autonomous driving, and body temperature detection. They have the unique advantages of passive imaging, temperature sensitivity and penetration. But the security of these systems themselves has not been fully explored, which poses risks in applying these systems. We propose a physical attack method with small bulbs on a board against the state of-the-art pedestrian detectors. Our goal is to make infrared pedestrian detectors unable to detect real-world pedestrians. Towards this goal, we Ô¨Årst showed that it is possible to use two kinds of patches to attack the infrared pedestrian detector based on YOLOv3. The average precision (AP) dropped by 64.12% in the digital world, while a blank board with the same size caused the AP to drop by 29.69% only. After that, we designed and manufactured a physical board and successfully attacked YOLOv3 in the real world. In recorded videos, the physical board caused AP of the target detector to drop by 34.48%, while a blank board with the same size caused the AP to drop by 14.91% only. With the ensemble attack techniques, the designed physical board had good transferability to unseen detectors",
    "checked": true,
    "id": "e019b8845413df345dcf5f6adb1d92cfd5cc4376",
    "semantic_title": "fooling thermal infrared pedestrian detectors in real world using small bulbs",
    "citation_count": 39,
    "authors": [
      "Xiaopei Zhu",
      "Xiao Li",
      "Jianmin Li",
      "Zheyao Wang",
      "Xiaolin Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16478": {
    "title": "ASHF-Net: Adaptive Sampling and Hierarchical Folding Network for Robust Point Cloud Completion",
    "volume": "main",
    "abstract": "Estimating the complete 3D point cloud from an incomplete one lies at the core of many vision and robotics applications. Existing methods typically predict the complete point cloud based on the global shape representation extracted from the incomplete input. Although they could predict the overall shape of 3D objects, they are incapable of generating structure details of objects. Moreover, the partial input point sets obtained from range scans are often sparse, noisy and non-uniform, which largely hinder shape completion. In this paper, we propose an adaptive sampling and hierarchical folding network (ASHF-Net) for robust 3D point cloud completion. Our main contributions are two-fold. First, we propose a denoising auto-encoder with an adaptive sampling module, aiming at learning robust local region features that are insensitive to noise. Second, we propose a hierarchical folding decoder with the gated skip-attention and multi-resolution completion goal to effectively exploit the local structure details of partial inputs. We also design a KL regularization term to evenly distribute the generated points. Extensive experiments demonstrate that our method outperforms existing state-of-the-art methods on multiple 3D point cloud completion benchmarks",
    "checked": true,
    "id": "0073d247c6903593d98a6ea573100f58ef08328c",
    "semantic_title": "ashf-net: adaptive sampling and hierarchical folding network for robust point cloud completion",
    "citation_count": 8,
    "authors": [
      "Daoming Zong",
      "Shiliang Sun",
      "Jing Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16479": {
    "title": "New Length Dependent Algorithm for Maximum Satisfiability Problem",
    "volume": "main",
    "abstract": "In this paper, we study the computational complexity of the Maximum Satisfiability problem in terms of the length L of a given formula. We present an algorithm with running time O(1.0927^L), hence, improving the previously known best upper bound O(1.1058^L) developed more than 20 years ago by Bansal and Raman. Theoretically speaking, our algorithm increases the length of solvable formulas by 13.3% (compare this to the recent breakthrough result for Maximum Satisfiability problem with respect to the number of clauses by Xu et al. in 2019 giving a 7.5% improvement). Besides, we propose a significantly simpler algorithm with running time O(1.1049^L). The algorithm outperforms Bansal's and Raman's algorithm in simplicity and running time",
    "checked": true,
    "id": "009ea465496db5f5abd90fd9b3ad4a6a36a5edd6",
    "semantic_title": "new length dependent algorithm for maximum satisfiability problem",
    "citation_count": 3,
    "authors": [
      "Vasily Alferov",
      "Ivan Bliznets"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16480": {
    "title": "Online Search with Maximum Clearance",
    "volume": "main",
    "abstract": "We study the setting in which a mobile searcher must locate a hidden target in a bounded or unbounded search domain, with no information about the hider's position. In particular, we consider online search, in which the performance of the search strategy is evaluated by its worst case competitive ratio. We introduce a multi-criteria search problem in which the searcher has a budget on its allotted search time, and the objective is to design strategies that are competitively efficient, respect the budget, and maximize the total searched ground. We give analytically optimal strategies for the line and the star domains, and efficient heuristics for general networks",
    "checked": true,
    "id": "bfe12b505e0a0d07ed7e88241669c065d004e00c",
    "semantic_title": "online search with maximum clearance",
    "citation_count": 0,
    "authors": [
      "Spyros Angelopoulos",
      "Malachi Voss"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16481": {
    "title": "Counting Maximal Satisfiable Subsets",
    "volume": "main",
    "abstract": "Given an unsatisfiable set of constraints F, a maximal satisfiable subset (MSS) is a maximal subset of constraints C ‚äÜ F such that C is satisfiable. Over the past two decades, the steady improvement in runtime performance of algorithms for finding MSS has led to an increased adoption of MSS-based techniques in wide variety of domains. Motivated by the progress in finding an MSS, the past decade has witnessed a surge of interest in design of algorithmic techniques to enumerate all the MSSes, which has subsequently led to discovery of new applications utilizing enumeration of MSSes. The development of techniques for finding and enumeration of MSSes mirrors a similar phenomenon of finding and enumeration of SAT solutions in the early 2000s, which subsequently motivated design of algorithmic techniques for model counting. In a similar spirit, we undertake study to investigate the feasibility of MSS counting techniques. In particular, the focus point of our investigation is to answer whether one can design efficient MSS counting techniques that do not rely on explicit MSS enumeration. The primary contribution of this work is an affirmative answer to the above question. Our tool, CountMSS, uses a novel architecture of a wrapper W and a remainder R such that the desired MSS count can be expressed as |W| ‚àí |R|. CountMSS relies on the advances in projected model counting to efficiently compute |W| and |R|. Our empirical evaluation demonstrates that CountMSS is able to scale to instances clearly beyond the reach of enumeration-based techniques",
    "checked": true,
    "id": "f9234ce567d234d1438939dd30a3cc72ea3bf741",
    "semantic_title": "counting maximal satisfiable subsets",
    "citation_count": 5,
    "authors": [
      "Jaroslav Bend√≠k",
      "Kuldeep S. Meel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16482": {
    "title": "Learning To Scale Mixed-Integer Programs",
    "volume": "main",
    "abstract": "Many practical applications require the solution of numerically challenging linear programs (LPs) and mixed integer programs (MIPs). Scaling is a widely used preconditioning technique that aims at reducing the error propagation of the involved linear systems, thereby improving the numerical behavior of the dual simplex algorithm and, consequently, LP-based branch-and-bound. A reliable scaling method often makes the difference whether these problems can be solved correctly or not. In this paper, we investigate the use of machine learning to choose at the beginning of the solution process between two common scaling methods: Standard scaling and Curtis-Reid scaling. The latter often, but not always, leads to a more robust solution process, but may suffer from longer solution times. Rather than training for overall solution time, we propose to use the attention level of a MIP solution process as a learning label. We evaluate the predictive power of a random forest approach and a linear regressor that learns the (square-root of the) difference in attention level. It turns out that the resulting classification not only reduces various types of numerical errors by large margins, but it also improves the performance of the dual simplex algorithm. The learned model has been implemented within the FICO Xpress MIP solver and it is used by default since release 8.9, May 2020, to determine the scaling algorithm Xpress applies before solving an LP or a MIP",
    "checked": true,
    "id": "b04d81729a81f77078c8fd12b1f2ad210094dbe5",
    "semantic_title": "learning to scale mixed-integer programs",
    "citation_count": 5,
    "authors": [
      "Timo Berthold",
      "Gregor Hendel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16483": {
    "title": "A SAT-based Resolution of Lam's Problem",
    "volume": "main",
    "abstract": "In 1989, computer searches by Lam, Thiel, and Swiercz experimentally resolved Lam's problem from projective geometry‚Äîthe long-standing problem of determining if a projective plane of order ten exists. Both the original search and an independent verification in 2011 discovered no such projective plane. However, these searches were each performed using highly specialized custom-written code and did not produce nonexistence certificates. In this paper, we resolve Lam's problem by translating the problem into Boolean logic and use satisfiability (SAT) solvers to produce nonexistence certificates that can be verified by a third party. Our work uncovered consistency issues in both previous searches‚Äîhighlighting the difficulty of relying on special-purpose search code for nonexistence results",
    "checked": true,
    "id": "cb392d0364323c2b7b6ade3ec5878829f3db7364",
    "semantic_title": "a sat-based resolution of lam's problem",
    "citation_count": 7,
    "authors": [
      "Curtis Bright",
      "Kevin K. H. Cheung",
      "Brett Stevens",
      "Ilias Kotsireas",
      "Vijay Ganesh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16484": {
    "title": "Combining Reinforcement Learning and Constraint Programming for Combinatorial Optimization",
    "volume": "main",
    "abstract": "Combinatorial optimization has found applications in numerous fields, from aerospace to transportation planning and economics. The goal is to find an optimal solution among a finite set of possibilities. The well-known challenge one faces with combinatorial optimization is the state-space explosion problem: the number of possibilities grows exponentially with the problem size, which makes solving intractable for large problems. In the last years, deep reinforcement learning (DRL) has shown its promise for designing good heuristics dedicated to solve NP-hard combinatorial optimization problems. However, current approaches have an important shortcoming: they only provide an approximate solution with no systematic ways to improve it or to prove optimality. In another context, constraint programming (CP) is a generic tool to solve combinatorial optimization problems. Based on a complete search procedure, it will always find the optimal solution if we allow an execution time large enough. A critical design choice, that makes CP non-trivial to use in practice, is the branching decision, directing how the search space is explored. In this work, we propose a general and hybrid approach, based on DRL and CP, for solving combinatorial optimization problems. The core of our approach is based on a dynamic programming formulation, that acts as a bridge between both techniques. We experimentally show that our solver is efficient to solve three challenging problems: the traveling salesman problem with time windows, the 4-moments portfolio optimization problem, and the 0-1 knapsack problem. Results obtained show that the framework introduced outperforms the stand-alone RL and CP solutions, while being competitive with industrial solvers",
    "checked": true,
    "id": "6eaeb3687648b8fc8fd23667fa4a66bf49fdba2f",
    "semantic_title": "combining reinforcement learning and constraint programming for combinatorial optimization",
    "citation_count": 80,
    "authors": [
      "Quentin Cappart",
      "Thierry Moisan",
      "Louis-Martin Rousseau",
      "Isabeau Pr√©mont-Schwarz",
      "Andre A. Cire"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16485": {
    "title": "Necessary and Sufficient Conditions for Avoiding Reopenings in Best First Suboptimal Search with General Bounding Functions",
    "volume": "main",
    "abstract": "Recent work introduced XDP and XUP priority functions for best-first bounded-suboptimal search that do not need to perform state re-expansions as long as the search heuristic is consistent. However, that work had several limitations that are rectified here. This paper analyzes the sufficiency and necessity of the conditions used to formulate XDP and XUP. The analysis presents a simpler proof and generalizes the result in three aspects: (1) the priority function no longer has to be differentiable everywhere, (2) the quality of the solution does not have to be bounded by a constant factor, and (3) directed graphs are handled correctly. These results allow the introduction of more priority functions, such as piecewise linear functions, and more variants of bounded-suboptimal search, such as constant suboptimality. Several new priority functions are presented in this paper that, according to empirical results, can significantly outperform existing approaches including XDP",
    "checked": true,
    "id": "297956965fd461da0a1cd113602a1cf7fa86d023",
    "semantic_title": "necessary and sufficient conditions for avoiding reopenings in best first suboptimal search with general bounding functions",
    "citation_count": 5,
    "authors": [
      "Jingwei Chen",
      "Nathan R. Sturtevant"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16486": {
    "title": "A Sharp Leap from Quantified Boolean Formula to Stochastic Boolean Satisfiability Solving",
    "volume": "main",
    "abstract": "Stochastic Boolean Satisfiability (SSAT) is a powerful representation for the concise encoding of quantified decision problems with uncertainty. While it shares commonalities with quantified Boolean formula (QBF) satisfiability and has the same PSPACE-complete complexity, SSAT solving tends to be more challenging as it involves expensive model counting, a.k.a. Sharp-SAT. To date, SSAT solvers, especially those imposing no restrictions on quantification levels, remain much lacking. In this paper, we present a new SSAT solver based on the framework of clause selection and cube distribution previously proposed for QBF solving. With model counting integrated and learning techniques strengthened, our solver is general and effective. Experimental results demonstrate the overall superiority of the proposed algorithm in both solving performance and memory usage compared to the state-of-the-art solvers on a number of benchmark formulas",
    "checked": true,
    "id": "b1b5da54f9c625664aabfcbfabafc94f5b4bb8b0",
    "semantic_title": "a sharp leap from quantified boolean formula to stochastic boolean satisfiability solving",
    "citation_count": 8,
    "authors": [
      "Pei-Wei Chen",
      "Yu-Ching Huang",
      "Jie-Hong R. Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16487": {
    "title": "An Improved Upper Bound for SAT",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4c08526c25b3e40d29666af2a641d540a0110e80",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Huairui Chu",
      "Mingyu Xiao",
      "Zhe Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16488": {
    "title": "Solving Infinite-Domain CSPs Using the Patchwork Property",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ff9197552f7f5c254380fc3d56e6f80a4f81968f",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Konrad K Dabrowski",
      "Peter Jonsson",
      "Sebastian Ordyniak",
      "George Osipov"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16489": {
    "title": "Disjunctive Temporal Problems under Structural Restrictions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5d46d378bc80d363c85ae90c6e2714c2d74e86f3",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Konrad K Dabrowski",
      "Peter Jonsson",
      "Sebastian Ordyniak",
      "George Osipov"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16490": {
    "title": "Optimal Decision Trees for Nonlinear Metrics",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2a2e69db2538b6e1394285d454ec93a0ce479417",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Emir Demiroviƒá",
      "Peter J. Stuckey"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16491": {
    "title": "Teaching the Old Dog New Tricks: Supervised Learning with Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1a7eb33e95f3c85acf1c5941de5c4dd856e0c152",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Fabrizio Detassis",
      "Michele Lombardi",
      "Michela Milano"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16492": {
    "title": "Cutting to the Core of Pseudo-Boolean Optimization: Combining Core-Guided Search with Cutting Planes Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "02eb66325ae688080a5d6ef491ba9cf6f8def4fc",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Jo Devriendt",
      "Stephan Gocht",
      "Emir Demiroviƒá",
      "Jakob Nordstr√∂m",
      "Peter J. Stuckey"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16493": {
    "title": "Optimising Automatic Calibration of Electric Muscle Stimulation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eef25c79fe49121fccb09c6c4924241fa83139ca",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Graeme Gange",
      "Jarrod Knibbe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16494": {
    "title": "Certifying Parity Reasoning Efficiently Using Pseudo-Boolean Proofs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d8bf3c1b99d2d3eeab9df88a92f0097eef3bb291",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Stephan Gocht",
      "Jakob Nordstr√∂m"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16495": {
    "title": "Finding Diverse Trees, Paths, and More",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "52b406248d83f53b966702092dec2094f0975e0c",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Tesshu Hanaka",
      "Yasuaki Kobayashi",
      "Kazuhiro Kurita",
      "Yota Otachi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16496": {
    "title": "Scalable Verification of Quantized Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5b91fa48408ecc07c317b3b33c752ebc76b8f433",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Thomas A. Henzinger",
      "Mathias Lechner",
      "ƒêorƒëe ≈Ωikeliƒá"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16497": {
    "title": "Integrated Optimization of Bipartite Matching and Its Stochastic Behavior: New Formulation and Approximation Algorithm via Min-cost Flow Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6a421bad10387e63285a4ff78e9c434b13bcaa32",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Yuya Hikima",
      "Yasunori Akagi",
      "Hideaki Kim",
      "Masahiro Kohjima",
      "Takeshi Kurashima",
      "Hiroyuki Toda"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16498": {
    "title": "A Scalable Two Stage Approach to Computing Optimal Decision Sets",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a9b19f9e7805f278e3105b4f7bc5c914f860bd0b",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Alexey Ignatiev",
      "Edward Lam",
      "Peter J. Stuckey",
      "Joao Marques-Silva"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16499": {
    "title": "Smooth Convex Optimization Using Sub-Zeroth-Order Oracles",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c4e70288f3e9e1a47ed51f0a25818f5f1e19a2e3",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Mustafa O. Karabag",
      "Cyrus Neary",
      "Ufuk Topcu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16500": {
    "title": "Binary Matrix Factorisation via Column Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "36cfa2d70fd575ddca8e70dea2d0f6a63defe790",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Reka A. Kovacs",
      "Oktay Gunluk",
      "Raphael A. Hauser"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16501": {
    "title": "Backdoor Decomposable Monotone Circuits and Propagation Complete Encodings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e0b22adf4863ac0ef59dfede1ec082ee1a3f8187",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Petr Kuƒçera",
      "Petr Savick√Ω"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16502": {
    "title": "On Continuous Local BDD-Based Search for Hybrid SAT Solving",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "27bea15cfbfadf2c20795e0fa02dd6afd611c557",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Anastasios Kyrillidis",
      "Moshe Vardi",
      "Zhiwei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16503": {
    "title": "The Power of Literal Equivalence in Model Counting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5c937cc544f4fb052659ece6068144a40e81f5b9",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Yong Lai",
      "Kuldeep S. Meel",
      "Roland H. C. Yap"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16504": {
    "title": "Parallel Constraint Acquisition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7e5bb68a25983f7add643f34ae4f250ba5814eae",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Nadjib Lazaar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16505": {
    "title": "Towards More Practical and Efficient Automatic Dominance Breaking",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "82a6fc9028ec6c2d27ec1b90e73d7d60bc0547ae",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Jimmy H.M. Lee",
      "Allen Z. Zhong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16506": {
    "title": "Dependency Stochastic Boolean Satisfiability: A Logical Formalism for NEXPTIME Decision Problems with Uncertainty",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "494cc5a2d0a7fbf00160d98374a21acda2bd0689",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Nian-Ze Lee",
      "Jie-Hong R. Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16507": {
    "title": "Satisfiability and Algorithms for Non-uniform Random k-SAT",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4cfbc0c529134014cb5611f7c9eb9c80ef37b891",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Oleksii Omelchenko",
      "Andrei Bulatov"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16508": {
    "title": "Turbocharging Treewidth-Bounded Bayesian Network Structure Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4e67c8bc646bbe59f0e030dec45ffc87630b231c",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Vaidyanathan Peruvemba Ramaswamy",
      "Stefan Szeider"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16509": {
    "title": "SAT-based Decision Tree Learning for Large Data Sets",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eaec75c3494c65c277e717de0f1838015350df15",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Andre Schidler",
      "Stefan Szeider"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16510": {
    "title": "LCollision: Fast Generation of Collision-Free Human Poses using Learned Non-Penetration Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3f1db35aa06afeff6bf2f00ae85a8ceb1febf27e",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Qingyang Tan",
      "Zherong Pan",
      "Dinesh Manocha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16511": {
    "title": "Symmetric Component Caching for Model Counting on Combinatorial Instances",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "473bc283b625f6d21c4905ed33a293cd2c135ec6",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Timothy van Bremen",
      "Vincent Derkinderen",
      "Shubham Sharma",
      "Subhajit Roy",
      "Kuldeep S. Meel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16512": {
    "title": "Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "20400881f50e5f199467a605e7f301fb1f369982",
    "semantic_title": "",
    "citation_count": 45,
    "authors": [
      "Giulia Zarpellon",
      "Jason Jo",
      "Andrea Lodi",
      "Yoshua Bengio"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16513": {
    "title": "Extreme k-Center Clustering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "59fec9507b847ec9d4211db685ea2bf2d9f467f4",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "MohammadHossein Bateni",
      "Hossein Esfandiari",
      "Manuela Fischer",
      "Vahab Mirrokni"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16514": {
    "title": "Beyond Low-frequency Information in Graph Convolutional Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fbc136c8c81cd89206dc0fcb54e16bd98df83b62",
    "semantic_title": "",
    "citation_count": 166,
    "authors": [
      "Deyu Bo",
      "Xiao Wang",
      "Chuan Shi",
      "Huawei Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16515": {
    "title": "Graph Heterogeneous Multi-Relational Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b6931c0a58963dbe628a13456bf38b5a27307232",
    "semantic_title": "",
    "citation_count": 54,
    "authors": [
      "Chong Chen",
      "Weizhi Ma",
      "Min Zhang",
      "Zhaowei Wang",
      "Xiuqiang He",
      "Chenyang Wang",
      "Yiqun Liu",
      "Shaoping Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16516": {
    "title": "Efficient Optimal Selection for Composited Advertising Creatives with Tree Structure",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4f18ac7e54d4d24c7e7c6e23cd134a2f2c0c4a66",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Jin Chen",
      "Tiezheng Ge",
      "Gangwei Jiang",
      "Zhiqiang Zhang",
      "Defu Lian",
      "Kai Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16517": {
    "title": "Revisiting Consistent Hashing with Bounded Loads",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "06bba5249442ca695201a1c4e376162ec8d6ede1",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "John Chen",
      "Benjamin Coleman",
      "Anshumali Shrivastava"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16518": {
    "title": "A User-Adaptive Layer Selection Framework for Very Deep Sequential Recommender Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b64f0016a9748f55bb50fc7a6e4cde9a3158d7b1",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Lei Chen",
      "Fajie Yuan",
      "Jiaxi Yang",
      "Xiang Ao",
      "Chengming Li",
      "Min Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16519": {
    "title": "Leveraging Table Content for Zero-shot Text-to-SQL with Meta-Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6a6c55c1736fcc8c2fc761e751b9e50f5d32e1a4",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Yongrui Chen",
      "Xinnan Guo",
      "Chaojie Wang",
      "Jian Qiu",
      "Guilin Qi",
      "Meng Wang",
      "Huiying Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16520": {
    "title": "Towards Faster Deep Collaborative Filtering via Hierarchical Decision Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7235bfcee140991668353393f7daf85e4742baee",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Yu Chen",
      "Sinno Jialin Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16521": {
    "title": "Deep Transfer Tensor Decomposition with Orthogonal Constraint for Recommender Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b3914d487ff59eb0f996ace5ef1d2819d04ce73d",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Zhengyu Chen",
      "Ziqing Xu",
      "Donglin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16522": {
    "title": "PASSLEAF: A Pool-bAsed Semi-Supervised LEArning Framework for Uncertain Knowledge Graph Embedding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3646e2947827c0a9314443e5cbb15575fafaf4ba",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Zhu-Mu Chen",
      "Mi-Yen Yeh",
      "Tei-Wei Kuo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16523": {
    "title": "Graph Neural Network-Based Anomaly Detection in Multivariate Time Series",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "21d2742e38f7167354dafcf7f565d3894b31d008",
    "semantic_title": "",
    "citation_count": 194,
    "authors": [
      "Ailin Deng",
      "Bryan Hooi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16524": {
    "title": "A Hybrid Bandit Framework for Diversified Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e8318bcda63a89c1fa186f17b0fab5d0a4fff1cb",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Qinxu Ding",
      "Yong Liu",
      "Chunyan Miao",
      "Fei Cheng",
      "Haihong Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16525": {
    "title": "Estimating the Number of Induced Subgraphs from Incomplete Data and Neighborhood Queries",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f1a53696fea1812e4bf9a9994937068a7dbcee97",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dimitris Fotakis",
      "Thanasis Pittas",
      "Stratis Skoulakis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16526": {
    "title": "Neural Latent Space Model for Dynamic Networks and Temporal Knowledge Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "179b1d82704839b17ed03fb20653494ab067ecbe",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Tony Gracious",
      "Shubham Gupta",
      "Arun Kanthali",
      "Rui M. Castro",
      "Ambedkar Dukkipati"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16527": {
    "title": "Exploiting Behavioral Consistence for Universal User Representation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cff8fc77bd7d860a1f9c910ef85e471b00c8b2fb",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Jie Gu",
      "Feng Wang",
      "Qinghui Sun",
      "Zhiquan Ye",
      "Xiaoxiao Xu",
      "Jingmin Chen",
      "Jun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16528": {
    "title": "NeuralAC: Learning Cooperation and Competition Effects for Match Outcome Prediction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "62c5ad80264d6f8db1446b5d1517167a1091dd42",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Yin Gu",
      "Qi Liu",
      "Kai Zhang",
      "Zhenya Huang",
      "Runze Wu",
      "Jianrong Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16529": {
    "title": "Joint Air Quality and Weather Prediction Based on Multi-Adversarial Spatiotemporal Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ed360bb72d67d7ae7aae80841137cb9cb34d6978",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Jindong Han",
      "Hao Liu",
      "Hengshu Zhu",
      "Hui Xiong",
      "Dejing Dou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16530": {
    "title": "GAN Ensemble for Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3e0a7244028e303c94a33d824848d1a9555f4785",
    "semantic_title": "",
    "citation_count": 32,
    "authors": [
      "Xu Han",
      "Xiaohui Chen",
      "Li-Ping Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16531": {
    "title": "Complete Closed Time Intervals-Related Patterns Mining",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "68a3887bcdb2cb807d4f41d963b6867a53cb9697",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Omer David Harel",
      "Robert Moskovitch"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16532": {
    "title": "Online Learning in Variable Feature Spaces under Incomplete Supervision",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f3b31ed7f41ff441092ab9ddcb9ab69d43b85ab9",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Yi He",
      "Xu Yuan",
      "Sheng Chen",
      "Xindong Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16533": {
    "title": "Knowledge-aware Coupled Graph Neural Network for Social Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c68ccdc85c8616f0bc78b0fb9df1d581429fe691",
    "semantic_title": "",
    "citation_count": 75,
    "authors": [
      "Chao Huang",
      "Huance Xu",
      "Yong Xu",
      "Peng Dai",
      "Lianghao Xia",
      "Mengyin Lu",
      "Liefeng Bo",
      "Hao Xing",
      "Xiaoping Lai",
      "Yanfang Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16534": {
    "title": "Graph-Enhanced Multi-Task Learning of Multi-Level Transition Dynamics for Session-based Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a73a64da2e46139db821b40ee753028f7b77a7c8",
    "semantic_title": "",
    "citation_count": 37,
    "authors": [
      "Chao Huang",
      "Jiahui Chen",
      "Lianghao Xia",
      "Yong Xu",
      "Peng Dai",
      "Yanqing Chen",
      "Liefeng Bo",
      "Jiashu Zhao",
      "Jimmy Xiangji Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16535": {
    "title": "Anomaly Attribution with Likelihood Compensation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d3e7dcff522432fec10ef05b4c315947deeb1466",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Tsuyoshi Id√©",
      "Amit Dhurandhar",
      "Ji≈ô√≠ Navr√°til",
      "Moninder Singh",
      "Naoki Abe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16536": {
    "title": "LREN: Low-Rank Embedded Network for Sample-Free Hyperspectral Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "883c5791a627d5bf679da1b5f871ff0d51792c6d",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Kai Jiang",
      "Weiying Xie",
      "Jie Lei",
      "Tao Jiang",
      "Yunsong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16537": {
    "title": "On Estimating Recommendation Evaluation Metrics under Sampling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0b3b2bc7b23c27a1d774c6e42f13c3574175d8ae",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Ruoming Jin",
      "Dong Li",
      "Benjamin Mudrak",
      "Jing Gao",
      "Zhi Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16538": {
    "title": "Randomized Generation of Adversary-aware Fake Knowledge Graphs to Combat Intellectual Property Theft",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2dff51bd603d3e8c4ceb377b1ab7c96b92117105",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Snow Kang",
      "Cristian Molinaro",
      "Andrea Pugliese",
      "V. S. Subrahmanian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16539": {
    "title": "PREMERE: Meta-Reweighting via Self-Ensembling for Point-of-Interest Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "084b10e890d07802936fc7f9dfa6d03bdbee3b9a",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Minseok Kim",
      "Hwanjun Song",
      "Doyoung Kim",
      "Kijung Shin",
      "Jae-Gil Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16540": {
    "title": "Disposable Linear Bandits for Online Recommendations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2e5c5b38b9ea1898b05837ad7f6729aab4816056",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Melda Korkut",
      "Andrew Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16541": {
    "title": "Hierarchical Negative Binomial Factorization for Recommender Systems on Implicit Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "74503d5a3985a9513b9fe22f1b228b93348a7c50",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li-Yen Kuo",
      "Ming-Syan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16542": {
    "title": "Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "24cff2aafcd66e1b7be4f647e478e8e73cf410a5",
    "semantic_title": "",
    "citation_count": 173,
    "authors": [
      "Mengzhang Li",
      "Zhanxing Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16543": {
    "title": "Rejection Sampling for Weighted Jaccard Similarity Revisited",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "279f6380deec7404abb45fd5e72c95d44f804976",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Xiaoyun Li",
      "Ping Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16544": {
    "title": "GraphMSE: Efficient Meta-path Selection in Semantically Aligned Feature Space for Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "587455ffed0462366710d941d5382584faf1360d",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Yi Li",
      "Yilun Jin",
      "Guojie Song",
      "Zihao Zhu",
      "Chuan Shi",
      "Yiming Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16545": {
    "title": "Cross-Oilfield Reservoir Classification via Multi-Scale Sensor Knowledge Transfer",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "51753e98aaf7fd24f5a29224e0443c3281325b59",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Zhi Li",
      "Zhefeng Wang",
      "Zhicheng Wei",
      "Xiangguang Zhou",
      "Yijun Wang",
      "Baoxing Huai",
      "Qi Liu",
      "Nicholas Jing Yuan",
      "Renbin Gong",
      "Enhong Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16546": {
    "title": "FedRec++: Lossless Federated Recommendation with Explicit Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9d31c7747e6435417ef18e7b45dddf1b32087781",
    "semantic_title": "",
    "citation_count": 31,
    "authors": [
      "Feng Liang",
      "Weike Pan",
      "Zhong Ming"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16547": {
    "title": "HMS: A Hierarchical Solver with Dependency-Enhanced Understanding for Math Word Problem",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "680b0467861a70be41c31e4f2415fe5e2958fbc0",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Xin Lin",
      "Zhenya Huang",
      "Hongke Zhao",
      "Enhong Chen",
      "Qi Liu",
      "Hao Wang",
      "Shijin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16548": {
    "title": "Pre-training Context and Time Aware Location Embeddings from Spatial-Temporal Trajectories for User Next Location Prediction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ac285bc39e1378448bdfd4c14eb55dd0d30e82c2",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Yan Lin",
      "Huaiyu Wan",
      "Shengnan Guo",
      "Youfang Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16549": {
    "title": "Noninvasive Self-attention for Side Information Fusion in Sequential Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "93cef0465c9632c0f8de1a48c7014b4d20813b85",
    "semantic_title": "",
    "citation_count": 41,
    "authors": [
      "Chang Liu",
      "Xiaoguang Li",
      "Guohao Cai",
      "Zhenhua Dong",
      "Hong Zhu",
      "Lifeng Shang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16550": {
    "title": "Visual Pivoting for (Unsupervised) Entity Alignment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "083b2d08cfce5cf397a965c29168c78eb1ddb1cb",
    "semantic_title": "",
    "citation_count": 43,
    "authors": [
      "Fangyu Liu",
      "Muhao Chen",
      "Dan Roth",
      "Nigel Collier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16551": {
    "title": "Relative and Absolute Location Embedding for Few-Shot Node Classification on Graph",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "96631435fd2c2326244f5b766dde9e617f7d9da6",
    "semantic_title": "",
    "citation_count": 39,
    "authors": [
      "Zemin Liu",
      "Yuan Fang",
      "Chenghao Liu",
      "Steven C.H. Hoi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16552": {
    "title": "Learning to Pre-train Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "94497472eecb7530a2b75c564548c540ebd61e9b",
    "semantic_title": "",
    "citation_count": 42,
    "authors": [
      "Yuanfu Lu",
      "Xunqiang Jiang",
      "Yuan Fang",
      "Chuan Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16553": {
    "title": "Knowledge-Enhanced Top-K Recommendation in Poincar√© Ball",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ac00f701ea57ba2f588895c31a098928d080f1aa",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Chen Ma",
      "Liheng Ma",
      "Yingxue Zhang",
      "Haolun Wu",
      "Xue Liu",
      "Mark Coates"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16554": {
    "title": "Communicative Message Passing for Inductive Relation Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f0e9a5611cb444e9131001f3afee984031aae057",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Sijie Mai",
      "Shuangjia Zheng",
      "Yuedong Yang",
      "Haifeng Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16555": {
    "title": "Learning Accurate and Interpretable Decision Rule Sets from Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0a38fde11e33d0f448a8c7ff3a50a54f77af5a23",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Litao Qiao",
      "Weijia Wang",
      "Bill Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16556": {
    "title": "Robust Spatio-Temporal Purchase Prediction via Deep Meta Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "431f056e7c6fa68e47bb5c2117127e75f4d8651c",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Huiling Qin",
      "Songyu Ke",
      "Xiaodu Yang",
      "Haoran Xu",
      "Xianyuan Zhan",
      "Yu Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16557": {
    "title": "U-BERT: Pre-training User Representations for Improved Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8baedb6c558bfea8ad9c17404f58b77368476a0f",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Zhaopeng Qiu",
      "Xian Wu",
      "Jingyue Gao",
      "Wei Fan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16558": {
    "title": "DocParser: Hierarchical Document Structure Parsing from Renderings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "adcb8fe66d08e6187f51ecbf4443523870a4b799",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Johannes Rausch",
      "Octavio Martinez",
      "Fabian Bissig",
      "Ce Zhang",
      "Stefan Feuerriegel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16559": {
    "title": "Knowledge-Driven Distractor Generation for Cloze-Style Multiple Choice Questions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6556bb283669a6cbe218926d4607787de9a76ac5",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Siyu Ren",
      "Kenny Q. Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16560": {
    "title": "Group Testing on a Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1e32a124869c9ce07f4a405dc3d8a46c8d8936e4",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arlei Silva",
      "Ambuj Singh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16561": {
    "title": "Detecting Beneficial Feature Interactions for Recommender Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eed0738fe4f6670750876219bcea40ed21389451",
    "semantic_title": "",
    "citation_count": 33,
    "authors": [
      "Yixin Su",
      "Rui Zhang",
      "Sarah Erfani",
      "Zhenghua Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16562": {
    "title": "A Hybrid Probabilistic Approach for Table Understanding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4d6ae639850441b259ec261497f7a55838f9132a",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Kexuan Sun",
      "Harsha Rayudu",
      "Jay Pujara"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16563": {
    "title": "Hyperbolic Variational Graph Neural Network for Modeling Dynamic Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6afee340e997b2f9bd728be6505a4ad786030b3e",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Li Sun",
      "Zhongbao Zhang",
      "Jiawei Zhang",
      "Feiyang Wang",
      "Hao Peng",
      "Sen Su",
      "Philip  S. Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16564": {
    "title": "Dynamic Memory based Attention Network for Sequential Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "30b335f0bb84989173e916d655f0c766ea7e172c",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Qiaoyu Tan",
      "Jianwei Zhang",
      "Ninghao Liu",
      "Xiao Huang",
      "Hongxia Yang",
      "Jingren Zhou",
      "Xia Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16565": {
    "title": "GaussianPath:A Bayesian Multi-Hop Reasoning Framework for Knowledge Graph Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7070e2eae96b9602032f9874e18f82d384301f07",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Guojia Wan",
      "Bo Du"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16566": {
    "title": "GSNet: Learning Spatial-Temporal Correlations from Geographical and Semantic Aspects for Traffic Accident Risk Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e90e84a100391c2d65e4852b7ff7e92e7ae026f3",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Beibei Wang",
      "Youfang Lin",
      "Shengnan Guo",
      "Huaiyu Wan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16567": {
    "title": "Reinforced Imitative Graph Representation Learning for Mobile User Profiling: An Adversarial Training Perspective",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8f110a359fa3e58102cc2a91cdaf50709a36c955",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Dongjie Wang",
      "Pengyang Wang",
      "Kunpeng Liu",
      "Yuanchun Zhou",
      "Charles E Hughes",
      "Yanjie Fu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16568": {
    "title": "Coupling Macro-Sector-Micro Financial Indicators for Learning Stock Representations with Less Uncertainty",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "49d9cd5d2e3e5cebcf51d2e4233ad3a8d69f0d4f",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Guifeng Wang",
      "Longbing Cao",
      "Hongke Zhao",
      "Qi Liu",
      "Enhong Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16569": {
    "title": "Reinforcement Learning with a Disentangled Universal Value Function for Item Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "67768af907a3bc7afbe04bfff8377da8da648501",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Kai Wang",
      "Zhene Zou",
      "Qilin Deng",
      "Jianrong Tao",
      "Runze Wu",
      "Changjie Fan",
      "Liang Chen",
      "Peng Cui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16570": {
    "title": "Learning to Recommend from Sparse Data via Generative User Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a12338cd4fd4b45e86eca285617c6da5f63aa7ff",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Wenlin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16571": {
    "title": "How Do We Move: Modeling Human Movement with System Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "09805e85dc93d06efe50b1276a09cdff2dbfe19b",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Hua Wei",
      "Dongkuan Xu",
      "Junjie Liang",
      "Zhenhui (Jessie) Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16572": {
    "title": "Learning to Truncate Ranked Lists for Information Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "62166a8d00d1a135272b29dad4a0e1989317aea0",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Chen Wu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Yixing Fan",
      "Yanyan Lan",
      "Xueqi Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16573": {
    "title": "Fairness-aware News Recommendation with Decomposed Adversarial Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a61854cb81538a2edd667d84b6127d6b8b4501b2",
    "semantic_title": "",
    "citation_count": 61,
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Xiting Wang",
      "Yongfeng Huang",
      "Xing Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16574": {
    "title": "Hybrid-order Stochastic Block Model",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "09cd304ea26fc9d14745b45f63439e878cabf89a",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Xunxun Wu",
      "Chang-Dong Wang",
      "Pengfei Jiao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16575": {
    "title": "Inductive Graph Neural Networks for Spatiotemporal Kriging",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "05500d98799ba93d6a37479bf75fd2a7d21a8b53",
    "semantic_title": "",
    "citation_count": 49,
    "authors": [
      "Yuankai Wu",
      "Dingyi Zhuang",
      "Aurelie Labbe",
      "Lijun Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16576": {
    "title": "Knowledge-Enhanced Hierarchical Graph Transformer Network for Multi-Behavior Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "90b1ffb667528ca1aa62bb2f843f95290ab04f35",
    "semantic_title": "",
    "citation_count": 61,
    "authors": [
      "Lianghao Xia",
      "Chao Huang",
      "Yong Xu",
      "Peng Dai",
      "Xiyue Zhang",
      "Hongsheng Yang",
      "Jian Pei",
      "Liefeng Bo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16577": {
    "title": "AttnMove: History Enhanced Trajectory Recovery via Attentional Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e5c303d73b7ce89f880fecb1dc6943a2359385a0",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Tong Xia",
      "Yunhan Qi",
      "Jie Feng",
      "Fengli Xu",
      "Funing Sun",
      "Diansheng Guo",
      "Yong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16578": {
    "title": "Self-Supervised Hypergraph Convolutional Networks for Session-based Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4097852d10cb6e0bb25f76142f85d7654eb89bc5",
    "semantic_title": "",
    "citation_count": 162,
    "authors": [
      "Xin Xia",
      "Hongzhi Yin",
      "Junliang Yu",
      "Qinyong Wang",
      "Lizhen Cui",
      "Xiangliang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16579": {
    "title": "A General Offline Reinforcement Learning Framework for Interactive Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bfef39ab7421dd3bcbb75662a9be5cdcf8bd475d",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Teng Xiao",
      "Donglin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16580": {
    "title": "Hierarchical Reinforcement Learning for Integrated Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5649537c0597f26f51b6af2c177db0779f4320f0",
    "semantic_title": "",
    "citation_count": 41,
    "authors": [
      "Ruobing Xie",
      "Shaoliang Zhang",
      "Rui Wang",
      "Feng Xia",
      "Leyu Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16581": {
    "title": "Out-of-Town Recommendation with Travel Intention Modeling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eb10b623a76dae8d69bc5f551cd02e51218dba5e",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Haoran Xin",
      "Xinjiang Lu",
      "Tong Xu",
      "Hao Liu",
      "Jingjing Gu",
      "Dejing Dou",
      "Hui Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16582": {
    "title": "Towards Consumer Loan Fraud Detection: Graph Neural Networks with Role-Constrained Conditional Random Field",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "64918015af5da1554cd547de9401f620c14d1fa5",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Bingbing Xu",
      "Huawei Shen",
      "Bingjie Sun",
      "Rong An",
      "Qi Cao",
      "Xueqi Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16583": {
    "title": "Transformer-Style Relational Reasoning with Dynamic Memory Updating for Temporal Network Modeling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ece43ea9b5d92c2c788864f5e40bca5487e820b8",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Dongkuan Xu",
      "Junjie Liang",
      "Wei Cheng",
      "Hua Wei",
      "Haifeng Chen",
      "Xiang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16584": {
    "title": "A Unified Pretraining Framework for Passage Ranking and Expansion",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e1b6f95c9dc486eac74f1e20fdc12290d0617c3b",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Ming Yan",
      "Chenliang Li",
      "Bin Bi",
      "Wei Wang",
      "Songfang Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16585": {
    "title": "Dynamic Knowledge Graph Alignment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "37c48eed3f6219f0ef55428613fba5a05471abd1",
    "semantic_title": "",
    "citation_count": 36,
    "authors": [
      "Yuchen Yan",
      "Lihui Liu",
      "Yikun Ban",
      "Baoyu Jing",
      "Hanghang Tong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16586": {
    "title": "Rethinking Graph Regularization for Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "85d1efae8697a0ff6fb29bba4874dfe50e75ee8d",
    "semantic_title": "",
    "citation_count": 32,
    "authors": [
      "Han Yang",
      "Kaili Ma",
      "James Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16587": {
    "title": "Capturing Delayed Feedback in Conversion Rate Prediction via Elapsed-Time Sampling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "037f56d79a5e82866f9527f9764a1d227ba35e14",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Jia-Qi Yang",
      "Xiang Li",
      "Shuguang Han",
      "Tao Zhuang",
      "De-Chuan Zhan",
      "Xiaoyi Zeng",
      "Bin Tong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16588": {
    "title": "Why Do Attributes Propagate in Graph Convolutional Neural Networks?",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a39193f071efed10af6704133061c15818a27edc",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Liang Yang",
      "Chuan Wang",
      "Junhua Gu",
      "Xiaochun Cao",
      "Bingxin Niu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16589": {
    "title": "Relaxed Clustered Hawkes Process for Student Procrastination Modeling in MOOCs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0b560f4e4fdf18d05c8d02ca16e9165ddf30179c",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Mengfan Yao",
      "Siqian Zhao",
      "Shaghayegh Sahebi",
      "Reza Feyzi Behnagh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16590": {
    "title": "Interpretable Clustering on Dynamic Graphs with Recurrent Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6ce84baa6d38997b7d3576d3e0e779ceff5aadec",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Yuhang Yao",
      "Carlee Joe-Wong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16591": {
    "title": "Coupled Layer-wise Graph Convolution for Transportation Demand Prediction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c5826aec6709f12940307d67bf5ea21ed71da974",
    "semantic_title": "",
    "citation_count": 41,
    "authors": [
      "Junchen Ye",
      "Leilei Sun",
      "Bowen Du",
      "Yanjie Fu",
      "Hui Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16592": {
    "title": "Deep Graph-neighbor Coherence Preserving Network for Unsupervised Cross-modal Hashing",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "25a18d1757b1e971f8aa4db7b3883d9f88d71491",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Yu",
      "Hao Zhou",
      "Yibing Zhan",
      "Dacheng Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16593": {
    "title": "Dual Sparse Attention Network For Session-based Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "01d033d69873846bf347b75050840cd748f5ed20",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Jiahao Yuan",
      "Zihan Song",
      "Mingyou Sun",
      "Xiaoling Wang",
      "Wayne Xin Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16594": {
    "title": "Self-Supervised Prototype Representation Learning for Event-Based Corporate Profiling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "59fbfabf9db9148f18f505673b2a188cbfc77519",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Zixuan Yuan",
      "Hao Liu",
      "Renjun Hu",
      "Denghui Zhang",
      "Hui Xiong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16595": {
    "title": "AugSplicing: Synchronized Behavior Detection in Streaming Tensors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1e55852a0471a4ce554a141f13bd8c36e2f2f661",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Jiabao Zhang",
      "Shenghua Liu",
      "Wenting Hou",
      "Siddharth Bhatia",
      "Huawei Shen",
      "Wenjian Yu",
      "Xueqi Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16596": {
    "title": "Taxonomy Completion via Triplet Matching Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "76be63767799fa50357fab6516b668960b67aa78",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Jieyu Zhang",
      "Xiangchen Song",
      "Ying Zeng",
      "Jiaze Chen",
      "Jiaming Shen",
      "Yuning Mao",
      "Lei Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16597": {
    "title": "Tripartite Collaborative Filtering with Observability and Selection for Debiasing Rating Estimation on Missing-Not-at-Random Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d6a33396c564b489a81c8793a61ab15f31b1f49",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Qi Zhang",
      "Longbing Cao",
      "Chongyang Shi",
      "Liang Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16598": {
    "title": "Generalized Relation Learning with Semantic Correlation Awareness for Link Prediction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "258d015243ba2f396f4094aa401ea38b6a423984",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Yao Zhang",
      "Xu Zhang",
      "Jun Wang",
      "Hongru Liang",
      "Wenqiang Lei",
      "Zhe Sun",
      "Adam Jatowt",
      "Zhenglu Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16599": {
    "title": "A Graph-based Relevance Matching Model for Ad-hoc Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "37023fc7bcd987e795a3842795a3e72863139f67",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Yufeng Zhang",
      "Jinghao Zhang",
      "Zeyu Cui",
      "Shu Wu",
      "Liang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16600": {
    "title": "Heterogeneous Graph Structure Learning for Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6e2bfca21d3c2bacb578b288148c3c1795b8c205",
    "semantic_title": "",
    "citation_count": 73,
    "authors": [
      "Jianan Zhao",
      "Xiao Wang",
      "Chuan Shi",
      "Binbin Hu",
      "Guojie Song",
      "Yanfang Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16601": {
    "title": "Cold-start Sequential Recommendation via Meta Learner",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e33f0602a6712d7d37e9b826842158007e7f102a",
    "semantic_title": "",
    "citation_count": 30,
    "authors": [
      "Yujia Zheng",
      "Siyi Liu",
      "Zekun Li",
      "Shu Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16602": {
    "title": "Overcoming Catastrophic Forgetting in Graph Neural Networks with Experience Replay",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8afb82f6c2a48f5ff6f9c70de3594e4a14c11b93",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Fan Zhou",
      "Chengtai Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16603": {
    "title": "Modeling Heterogeneous Relations across Multiple Modes for Potential Crowd Flow Prediction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ba7b80fd765b3326dbc5f8cb7692f5b40ee25a10",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Qiang Zhou",
      "Jingjing Gu",
      "Xinjiang Lu",
      "Fuzhen Zhuang",
      "Yanchao Zhao",
      "Qiuhong Wang",
      "Xiao Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16604": {
    "title": "Learning from History: Modeling Temporal Knowledge Graphs with Sequential Copy-Generation Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "40cfa0263e7d39d4a61cfcb844a5093c8c283152",
    "semantic_title": "",
    "citation_count": 75,
    "authors": [
      "Cunchao Zhu",
      "Muhao Chen",
      "Changjun Fan",
      "Guangquan Cheng",
      "Yan Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16605": {
    "title": "Adversarial Directed Graph Embedding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d4677ce389c1c1ef02c7d4e206d902c4f51bdb3",
    "semantic_title": "",
    "citation_count": 23,
    "authors": [
      "Shijie Zhu",
      "Jianxin Li",
      "Hao Peng",
      "Senzhang Wang",
      "Lifang He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16606": {
    "title": "Relation-Aware Neighborhood Matching Model for Entity Alignment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cfcb0c89fb540d7b21cdf4c2dcc6e646c8978d95",
    "semantic_title": "",
    "citation_count": 35,
    "authors": [
      "Yao Zhu",
      "Hongzhi Liu",
      "Zhonghai Wu",
      "Yingpeng Du"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16607": {
    "title": "Argument Mining Driven Analysis of Peer-Reviews",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ecfac0d377db229d58bc88698ad3bfd4b384ef37",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Michael Fromm",
      "Evgeniy Faerman",
      "Max Berrendorf",
      "Siddharth Bhargava",
      "Ruoxia Qi",
      "Yao Zhang",
      "Lukas Dennert",
      "Sophia Selle",
      "Yang Mao",
      "Thomas Seidl"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16608": {
    "title": "Uncovering Latent Biases in Text: Method and Application to Peer Review",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cc19de8d0782917098029ed20261cbe0b0c62bf5",
    "semantic_title": "",
    "citation_count": 23,
    "authors": [
      "Emaad Manzoor",
      "Nihar B. Shah"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16609": {
    "title": "A Market-Inspired Bidding Scheme for Peer Review Paper Assignment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c6c18ad62f39060e2547a0b683525e83312d0700",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Reshef Meir",
      "J√©r√¥me Lang",
      "Julien Lesca",
      "Nicholas Mattei",
      "Natan Kaminsky"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16610": {
    "title": "A Novice-Reviewer Experiment to Address Scarcity of Qualified Reviewers in Large Conferences",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f136a0fdc2065485c83396ae41d431395de51af4",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Ivan Stelmakh",
      "Nihar B. Shah",
      "Aarti Singh",
      "Hal Daum√© III"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16611": {
    "title": "Catch Me if I Can: Detecting Strategic Behaviour in Peer Assessment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b0894f5c914cd90cc3b3e16b15bec11efe317b14",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Ivan Stelmakh",
      "Nihar B. Shah",
      "Aarti Singh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16612": {
    "title": "Savable but Lost Lives when ICU Is Overloaded: a Model from 733 Patients in Epicenter Wuhan, China",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "23f626e34e1a661490950aad6c3267ffb0e88875",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Tingting Dan",
      "Yang Li",
      "Ziwei Zhu",
      "Xijie Chen",
      "Wuxiu Quan",
      "Yu Hu",
      "Guihua Tao",
      "Lei Zhu",
      "Jijin Zhu",
      "Hongmin Cai",
      "Hanchun Wen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16613": {
    "title": "Persistence of Anti-vaccine Sentiment in Social Networks Through Strategic Interactions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "225a67952c8e373d3dd3f1ef27a07121b47c4374",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "A S M Ahsan-Ul Haque",
      "Mugdha Thakur",
      "Matthew Bielskas",
      "Achla Marathe",
      "Anil Vullikanti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16614": {
    "title": "Automated Model Design and Benchmarking of Deep Learning Models for COVID-19 Detection with Chest CT Scans",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3bf6f158e287ae8b296b5233f3586240600a6bf2",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Xin He",
      "Shihao Wang",
      "Xiaowen Chu",
      "Shaohuai Shi",
      "Jiangping Tang",
      "Xin Liu",
      "Chenggang Yan",
      "Jiyong Zhang",
      "Guiguang Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16615": {
    "title": "STELAR: Spatio-temporal Tensor Factorization with Latent Epidemiological Regularization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "16b63ce2e436678c38a8be9c76737d8e70e62af0",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Nikos Kargas",
      "Cheng Qian",
      "Nicholas D. Sidiropoulos",
      "Cao Xiao",
      "Lucas M. Glass",
      "Jimeng Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16616": {
    "title": "Transfer Graph Neural Networks for Pandemic Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "279febfb9e479f8d927067762d89197ee507c495",
    "semantic_title": "",
    "citation_count": 58,
    "authors": [
      "George Panagopoulos",
      "Giannis Nikolentzos",
      "Michalis Vazirgiannis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16617": {
    "title": "MiniSeg: An Extremely Minimum Network for Efficient COVID-19 Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "47fdce2b3b27819d61525247bc3de34f2d157983",
    "semantic_title": "",
    "citation_count": 105,
    "authors": [
      "Yu Qiu",
      "Yun Liu",
      "Shijie Li",
      "Jing Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16618": {
    "title": "Steering a Historical Disease Forecasting Model Under a Pandemic: Case of Flu and COVID-19",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "74fcf647c952d01b1888f2330a3f81a5dfa5c4dd",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Alexander Rodr√≠guez",
      "Nikhil Muralidhar",
      "Bijaya Adhikari",
      "Anika Tabassum",
      "Naren Ramakrishnan",
      "B. Aditya Prakash"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16619": {
    "title": "Gaining Insight into SARS-CoV-2 Infection and COVID-19 Severity Using Self-supervised Edge Features and Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6fe2e8b464a53e29cff47e57215ddfe9674dd0b0",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Arijit Sehanobish",
      "Neal Ravindra",
      "David van Dijk"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16620": {
    "title": "Context Matters: Graph-based Self-supervised Representation Learning for Medical Images",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "76d2a53b3e6c8db7a0139e0e4da671f5b0846bf4",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Li Sun",
      "Ke Yu",
      "Kayhan Batmanghelich"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16621": {
    "title": "Tracking Disease Outbreaks from Sparse Data with Bayesian Inference",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0c5cb45cecab8d242357d2a0f3400c682595d0a2",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Bryan Wilder",
      "Michael Mina",
      "Milind Tambe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16622": {
    "title": "C-Watcher: A Framework for Early Detection of High-Risk Neighborhoods Ahead of COVID-19 Outbreak",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3e0ee08039f771f6e53cad8a02bff37ca26a4c6d",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Congxi Xiao",
      "Jingbo Zhou",
      "Jizhou Huang",
      "An Zhuo",
      "Ji Liu",
      "Haoyi Xiong",
      "Dejing Dou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16623": {
    "title": "Conversational Neuro-Symbolic Commonsense Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d5771c13307a00b79a8d9d7ddcc2defe2c495a9",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Forough Arabshahi",
      "Jennifer Lee",
      "Mikayla Gawarecki",
      "Kathryn Mazaitis",
      "Amos Azaria",
      "Tom Mitchell"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16624": {
    "title": "Interpretable Actions: Controlling Experts with Understandable Commands",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dfd4244e29ea49b7f9e67fb837c3d70ae402e793",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shumeet Baluja",
      "David Marwood",
      "Michele Covell"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16625": {
    "title": "Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-shot Commonsense Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9fa9d5dd481400b2f3904b33d542d70a6affccb9",
    "semantic_title": "",
    "citation_count": 67,
    "authors": [
      "Antoine Bosselut",
      "Ronan Le Bras",
      "Yejin Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16626": {
    "title": "Aligning Artificial Neural Networks and Ontologies towards Explainable AI",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9b942b8060d5cf0f54fef27c46efc1d78c23aa2d",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Manuel de Sousa Ribeiro",
      "Jo√£o Leite"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16627": {
    "title": "Planning from Pixels in Atari with Learned Symbolic Representations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a8f80b8f5cd4be2da9b8e4b9931135f16cbaa5c8",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Andrea Dittadi",
      "Frederik K. Drachmann",
      "Thomas Bolander"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16628": {
    "title": "Learning Game-Theoretic Models of Multiagent Trajectories Using Implicit Layers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "17a985a233ae582158cf5a956c84b913cbcc1b02",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Philipp Geiger",
      "Christoph-Nikolas Straehle"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16629": {
    "title": "Learning by Fixing: Solving Math Word Problems with Weak Supervision",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "edaafec59b651d503ac7c8a86f8e2335273e1f7a",
    "semantic_title": "",
    "citation_count": 34,
    "authors": [
      "Yining Hong",
      "Qing Li",
      "Daniel Ciao",
      "Siyuan Huang",
      "Song-Chun Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16630": {
    "title": "Answering Complex Queries in Knowledge Graphs with Bidirectional Sequence Encoders",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cd1dffa09c8163b3544a3f19d061ec76749a1e72",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Bhushan Kotnis",
      "Carolin Lawrence",
      "Mathias Niepert"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16631": {
    "title": "Self-Supervised Self-Supervision by Combining Deep Learning and Probabilistic Logic",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "90b0f25fc073ce818563002b5481bd52efac944c",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Hunter Lang",
      "Hoifung Poon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16632": {
    "title": "Explaining Neural Matrix Factorization with Gradient Rollback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8ceb6cf2d5788afd2188cd26822a7652f5fd590b",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Carolin Lawrence",
      "Timo Sztyler",
      "Mathias Niepert"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16633": {
    "title": "A Scalable Reasoning and Learning Approach for Neural-Symbolic Stream Fusion",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a9f205a46a4d65e7f50c149d8ed9898111a4dc29",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Danh Le-Phuoc",
      "Thomas Eiter",
      "Anh Le-Tuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16634": {
    "title": "Recognizing and Verifying Mathematical Equations using Multiplicative Differential Neural Units",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d969066d1dff7203055a493daaa3af8c490bf58e",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Ankur Mali",
      "Alexander G. Ororbia",
      "Daniel Kifer",
      "C. Lee Giles"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16635": {
    "title": "A Unified Framework for Planning with Learned Neural Network Transition Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cc4294064134d32a075048a43be698ce6832cfab",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Buser Say"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16636": {
    "title": "Classification by Attention: Scene Graph Classification with Prior Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a5661066faa0f28a61f238e860fb14a9057acf6b",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Sahand Sharifzadeh",
      "Sina Moayed Baharlou",
      "Volker Tresp"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16637": {
    "title": "Differentiable Inductive Logic Programming for Structured Examples",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0eb56e56b07a4e89e5e77e6172be635c827ff17e",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Hikaru Shindo",
      "Masaaki Nishino",
      "Akihiro Yamamoto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16638": {
    "title": "Encoding Human Domain Knowledge to Warm Start Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5e3712e84884e28b41f6ca775db786b4c66976b4",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Andrew Silva",
      "Matthew Gombolay"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16639": {
    "title": "Neural-Symbolic Integration: A Compositional Perspective",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d6e349e385ed1765e4063bd820e2f541ee93b89",
    "semantic_title": "",
    "citation_count": 31,
    "authors": [
      "Efthymia Tsamoura",
      "Timothy Hospedales",
      "Loizos Michael"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16640": {
    "title": "Adaptive Teaching of Temporal Logic Formulas to Preference-based Learners",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6289cdaf5d8fd566f8b01ebdce4d93c2744400a1",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Xu",
      "Yuxin Chen",
      "Ufuk Topcu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16641": {
    "title": "Double Oracle Algorithm for Computing Equilibria in Continuous Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0a3f967b10838b19cbcf595d27b14ef711f89df1",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Luk√°≈° Adam",
      "Rostislav Horƒç√≠k",
      "Tom√°≈° Kasl",
      "Tom√°≈° Kroupa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16642": {
    "title": "A Few Queries Go a Long Way: Information-Distortion Tradeoffs in Matching",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0c0b3ddf4cad06449e76deac89702d4ae472f909",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Georgios Amanatidis",
      "Georgios Birmpas",
      "Aris Filos-Ratsikas",
      "Alexandros A. Voudouris"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16643": {
    "title": "Representative Proxy Voting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2ae4ab85f221ff83615b435975bd2a962df867f2",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Elliot Anshelevich",
      "Zack Fitzsimmons",
      "Rohit Vaish",
      "Lirong Xia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16644": {
    "title": "Forming Better Stable Solutions in Group Formation Games Inspired by Internet Exchange Points (IXPs)",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cd5631e12fc741998addfd35e2ee637b27d03bc8",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elliot Anshelevich",
      "Wennan Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16645": {
    "title": "Achieving Envy-freeness and Equitability with Monetary Transfers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "efaa1bb26c224d355611b5b1710731564da29716",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Haris Aziz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16646": {
    "title": "Proportionally Representative Participatory Budgeting with Ordinal Preferences",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2889190d818cc8f192e91797808991c9f96c829e",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Haris Aziz",
      "Barton E. Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16647": {
    "title": "Fair and Truthful Mechanisms for Dichotomous Valuations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a8301e6372f4276e2d7db4f61855abcc5f8b1c0b",
    "semantic_title": "",
    "citation_count": 42,
    "authors": [
      "Moshe Babaioff",
      "Tomer Ezra",
      "Uriel Feige"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16648": {
    "title": "Bayesian Persuasion under Ex Ante and Ex Post Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5369aea45e605281968cceea144b04a8a3de6832",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Yakov Babichenko",
      "Inbal Talgam-Cohen",
      "Konstantin Zabarnyi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16649": {
    "title": "Defending against Contagious Attacks on a Network with Resource Reallocation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a01152175fde708abaedad4fcb6d018d71d7e56e",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Rufan Bai",
      "Haoxing Lin",
      "Xinyu Yang",
      "Xiaowei Wu",
      "Minming Li",
      "Weijia Jia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16650": {
    "title": "Achieving Proportionality up to the Maximin Item with Indivisible Goods",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6c140b85f5720df59fc5709bf3d3f1bbf738d2f8",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Artem Baklanov",
      "Pranav Garimidi",
      "Vasilis Gkatzelis",
      "Daniel Schoepflin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16651": {
    "title": "The Price of Connectivity in Fair Division",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "37d5587839cbe908858903e0a8b639456a66e016",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Xiaohui Bei",
      "Ayumi Igarashi",
      "Xinhang Lu",
      "Warut Suksompong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16652": {
    "title": "Dividing a Graphical Cake",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2260aef18efdd391080d4aa810948b316e60dbdf",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Xiaohui Bei",
      "Warut Suksompong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16653": {
    "title": "Maximin Fairness with Mixed Divisible and Indivisible Goods",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "24ad786bc8d7f34d1fca449f9ae8eb0cbb961e77",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Xiaohui Bei",
      "Shengxin Liu",
      "Xinhang Lu",
      "Hongao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16654": {
    "title": "Protecting the Protected Group: Circumventing Harmful Fairness",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "01568d72f87012233c7ecf2952b2abfa4b22fffb",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Omer Ben-Porat",
      "Fedor Sandomirskiy",
      "Moshe Tennenholtz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16655": {
    "title": "Selfish Creation of Social Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f89f716e305635fdaa67fa2f75050cbe73313c1e",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Davide Bil√≤",
      "Tobias Friedrich",
      "Pascal Lenzner",
      "Stefanie Lowski",
      "Anna Melnichenko"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16656": {
    "title": "On the Complexity of Finding Justifications for Collective Decisions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4ef3a8660bc4aadc7ea6205eebf49dc51d2ede0c",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Arthur Boixel",
      "Ronald de Haan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16657": {
    "title": "Preserving Condorcet Winners under Strategic Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "efd278ed3ecea58aa5f35bddcf0d55296d77d545",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Sirin Botan",
      "Ulle Endriss"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16658": {
    "title": "Reaching Individually Stable Coalition Structures in Hedonic Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0b0405370edb654fbc3dfe786e7a65465c9c0ec8",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Felix Brandt",
      "Martin Bullinger",
      "Ana√´lle Wilczynski"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16659": {
    "title": "Reinforcement Learning of Sequential Price Mechanisms",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e90ee8f27d98ae7500b0c27c0ada78fb0ba046ab",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Gianluca Brero",
      "Alon Eden",
      "Matthias Gerstgrasser",
      "David Parkes",
      "Duncan Rheingans-Yoo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16660": {
    "title": "Margin of Victory in Tournaments: Structural and Experimental Results",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7191c84fc3a92b57cbb5d5cf57738a0e27240759",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Markus Brill",
      "Ulrike Schmidt-Kraepelin",
      "Warut Suksompong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16661": {
    "title": "Welfare Guarantees in Schelling Segregation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "85acdfee72c487de549394060162584beca9e8cd",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Martin Bullinger",
      "Warut Suksompong",
      "Alexandros A. Voudouris"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16662": {
    "title": "Persuading Voters in District-based Elections",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "097638237894cbf9a56675f746a2eb207aeba883",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Matteo Castiglioni",
      "Nicola Gatti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16663": {
    "title": "Signaling in Bayesian Network Congestion Games: the Subtle Power of Symmetry",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "85f10fc6261e2ed11728101ec2f8f7bc26b650d3",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Matteo Castiglioni",
      "Andrea Celli",
      "Alberto Marchesi",
      "Nicola Gatti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16664": {
    "title": "Computing Quantal Stackelberg Equilibrium in Extensive-Form Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a1600c90aa2255a7d3bf6a34348dae9b0fae4e8c",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Jakub ƒåern√Ω",
      "Viliam Lis√Ω",
      "Branislav Bo≈°ansk√Ω",
      "Bo An"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16665": {
    "title": "Fair and Efficient Allocations under Subadditive Valuations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8567bb211aee04e86221dcf8bb743bc84468a0f8",
    "semantic_title": "",
    "citation_count": 23,
    "authors": [
      "Bhaskar Ray Chaudhury",
      "Jugal Garg",
      "Ruta Mehta"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16666": {
    "title": "Scalable Equilibrium Computation in Multi-agent Influence Games on Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c6ca8fce8a8002bb506d28cbca6eb18250daf2c4",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Fotini Christia",
      "Michael Curry",
      "Constantinos Daskalakis",
      "Erik Demaine",
      "John P. Dickerson",
      "MohammadTaghi Hajiaghayi",
      "Adam Hesterberg",
      "Marina Knittel",
      "Aidan Milliff"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16667": {
    "title": "Proportional Representation under Single-Crossing Preferences Revisited",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "33d740382f3fe21e006a556afa4d9bc628cf86be",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Andrei Costin Constantinescu",
      "Edith Elkind"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16668": {
    "title": "Computational Analyses of the Electoral College: Campaigning Is Hard But Approximately Manageable",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f3f3467c363e1a304f208feac0961bfcbf0a286e",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Sina Dehghani",
      "Hamed Saleh",
      "Saeed Seddighin",
      "Shang-Hua Teng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16669": {
    "title": "Model-sharing Games: Analyzing Federated Learning Under Voluntary Participation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2e07f2c430f3df00d0a037d594435e0239fdf345",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Kate Donahue",
      "Jon Kleinberg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16670": {
    "title": "On Fair Division under Heterogeneous Matroid Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "aa5f58e9d5cad87629bd40c09465087eec2f9c63",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Amitay Dror",
      "Michal Feldman",
      "Erel Segal-Halevi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16671": {
    "title": "PoA of Simple Auctions with Interdependent Values",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ca80110f3551b88f7c74d5b417215563e85e3294",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Alon Eden",
      "Michal Feldman",
      "Inbal Talgam-Cohen",
      "Ori Zviran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16672": {
    "title": "Mind the Gap: Cake Cutting With Separation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "777b4b7a3088ffdb5de03e2e9d0fca77624aabc9",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Edith Elkind",
      "Erel Segal-Halevi",
      "Warut Suksompong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16673": {
    "title": "United for Change: Deliberative Coalition Formation to Change the Status Quo",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5ab039f93b2400488e3baf99db7041d912331750",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Edith Elkind",
      "Davide Grossi",
      "Ehud Shapiro",
      "Nimrod Talmon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16674": {
    "title": "Incentivizing Truthfulness Through Audits in Strategic Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b142858a6d839ded612b9c04e84c8a96f0b665c8",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Andrew Estornell",
      "Sanmay Das",
      "Yevgeniy Vorobeychik"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16675": {
    "title": "Almost Envy-freeness, Envy-rank, and Nash Social Welfare Matchings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e8d90f8fdc2ff9ff24faee07fb3bd718f688a28b",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Alireza Farhadi",
      "MohammadTaghi Hajiaghayi",
      "Mohamad Latifian",
      "Masoud Seddighin",
      "Hadi Yami"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16676": {
    "title": "Faster Game Solving via Predictive Blackwell Approachability: Connecting Regret Matching and Mirror Descent",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7a9043a0b2686445e7da328408c370833da56476",
    "semantic_title": "",
    "citation_count": 34,
    "authors": [
      "Gabriele Farina",
      "Christian Kroer",
      "Tuomas Sandholm"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16677": {
    "title": "Bandit Linear Optimization for Sequential Decision Making and Extensive-Form Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4963715eebd852c264a920678cfd6a3cb9ba2af1",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Gabriele Farina",
      "Robin Schmucker",
      "Tuomas Sandholm"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16678": {
    "title": "Model-Free Online Learning in Unknown Sequential Decision Making Problems and Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b852447404447e897e9c2d111609dd18625b03cf",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Gabriele Farina",
      "Tuomas Sandholm"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16679": {
    "title": "Simultaneous 2nd Price Item Auctions with No-Underbidding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "210631482791c5a4ebe8ec8772c0003637206fe9",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Michal Feldman",
      "Galia Shabtai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16680": {
    "title": "Convergence Analysis of No-Regret Bidding Algorithms in Repeated Auctions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5a3e6c92d902ea33ea73373e9b900fabc03f1452",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Zhe Feng",
      "Guru Guruganesh",
      "Christopher Liaw",
      "Aranyak Mehta",
      "Abhishek Sethi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16681": {
    "title": "Condorcet Relaxation In Spatial Voting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3b46e8efe7cab5f2ed95530de0b9f85d74c98cad",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arnold Filtser",
      "Omrit Filtser"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16682": {
    "title": "Present-Biased Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a548c2c462039f84b393fb131c91aec84f11df15",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Fedor V. Fomin",
      "Pierre Fraigniaud",
      "Petr A. Golovach"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16683": {
    "title": "Efficient Truthful Scheduling and Resource Allocation through Monitoring",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5b1efd39e12a0883b697febaa2bcbd6de3fa19c1",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Dimitris Fotakis",
      "Piotr Krysta",
      "Carmine Ventre"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16684": {
    "title": "Infinite-Dimensional Fisher Markets: Equilibrium, Duality and Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "03c67180a1c3c85b6f9bc23c49a59158ad1a6c1f",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Yuan Gao",
      "Christian Kroer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16685": {
    "title": "Fair and Efficient Online Allocations with Normalized Valuations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "31402765433d62d3f6081e1a117162615a964511",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Vasilis Gkatzelis",
      "Alexandros Psomas",
      "Xizhi Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16686": {
    "title": "An Analysis of Approval-Based Committee Rules for 2D-Euclidean Elections",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4235af78c5b356c11f81c7064b029cbb1c723055",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Micha≈Ç T. Godziszewski",
      "Pawe≈Ç Batko",
      "Piotr Skowron",
      "Piotr Faliszewski"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16687": {
    "title": "Aggregating Binary Judgments Ranked by Accuracy",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "776555716806327ebc9ff1460ef612a5cd7f4ead",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Halpern",
      "Gregory Kehne",
      "Dominik Peters",
      "Ariel D. Procaccia",
      "Nisarg Shah",
      "Piotr Skowron"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16688": {
    "title": "District-Fair Participatory Budgeting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1b161370739624f0f6f68786b928130b8960d5ce",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "D Ellis Hershkowitz",
      "Anson Kahng",
      "Dominik Peters",
      "Ariel D. Procaccia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16689": {
    "title": "Fair and Efficient Allocations under Lexicographic Preferences",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "765d39b6a6c937a7ad4ec6a74376faa3e864616a",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Hadi Hosseini",
      "Sujoy Sikdar",
      "Rohit Vaish",
      "Lirong Xia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16690": {
    "title": "Necessarily Optimal One-Sided Matchings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "89dbed197cfee471bae7c387a821c1b9076acd02",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Hadi Hosseini",
      "Vijay Menon",
      "Nisarg Shah",
      "Sujoy Sikdar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16691": {
    "title": "Computing the Proportional Veto Core",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "325a5a83a4e9eef029ac482320c043d1f613030e",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Egor Ianovski",
      "Aleksei Y. Kondratev"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16692": {
    "title": "Multi-Scale Games: Representing and Solving Games on Networks with Group Structure",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1bb82e8e8163eab88a366886fc99b94232e35944",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Kun Jin",
      "Yevgeniy Vorobeychik",
      "Mingyan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16693": {
    "title": "Multi-Party Campaigning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8603bdce63eeb51eb935f379532d71996a94a8d5",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martin Kouteck√Ω",
      "Nimrod Talmon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16694": {
    "title": "Classification with Strategically Withheld Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0f395654e69cd2e063a6ef221fb66fb46e68cefd",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Anilesh K. Krishnaswamy",
      "Haoming Li",
      "David Rein",
      "Hanrui Zhang",
      "Vincent Conitzer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16695": {
    "title": "On the PTAS for Maximin Shares in an Indivisible Mixed Manna",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d6fc4a7ef2dc4616b5ce700b50c355048ad620df",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Rucha Kulkarni",
      "Ruta Mehta",
      "Setareh Taki"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16696": {
    "title": "Evolution Strategies for Approximate Solution of Bayesian Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d473ff103565d8c76e0cbfa33bdd4b0db1cbb23f",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Zun Li",
      "Michael P. Wellman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16697": {
    "title": "Safe Search for Stackelberg Equilibria in Extensive-Form Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0c3c71c63153063afb08ecb67e9682b1b13e83fa",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Chun Kai Ling",
      "Noam Brown"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16698": {
    "title": "Budget Feasible Mechanisms Over Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d7dfd442f9c6250b234d6f323417464dfaa26375",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Xiang Liu",
      "Weiwei Wu",
      "Minming Li",
      "Wanyuan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16699": {
    "title": "On the Approximation of Nash Equilibria in Sparse Win-Lose Multi-player Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "af373323824286e8bad31b2d72ff7a0c3543e81f",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Zhengyang Liu",
      "Jiawei Li",
      "Xiaotie Deng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16700": {
    "title": "Trembling-Hand Perfection and Correlation in Sequential Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c8994263e4961526b6aeb8e42ef03e4b79534638",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Alberto Marchesi",
      "Nicola Gatti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16701": {
    "title": "Complexity and Algorithms for Exploiting Quantal Opponents in Large Two-Player Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e0eeb63ce173987e1ff296bf8deab404d1af5158",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "David Milec",
      "Jakub ƒåern√Ω",
      "Viliam Lis√Ω",
      "Bo An"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16702": {
    "title": "Hindsight and Sequential Rationality of Correlated Play",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "886ed15d25615e51dff6c453c116a0b394d332ee",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Dustin Morrill",
      "Ryan D'Orazio",
      "Reca Sarfati",
      "Marc Lanctot",
      "James R Wright",
      "Amy R Greenwald",
      "Michael Bowling"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16703": {
    "title": "On Fair and Efficient Allocations of Indivisible Goods",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f50f62a4e70b0d7337d18b73fbb5c305f5289957",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Aniket Murhekar",
      "Jugal Garg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16704": {
    "title": "Coalition Formation in Multi-defender Security Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4aaee2dafc878bfacef7f99af99336a5763ce326",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Dolev Mutzari",
      "Jiarui Gan",
      "Sarit Kraus"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16705": {
    "title": "Majority Opinion Diffusion in Social Networks: An Adversarial Approach",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4ca5253650a863ab001e0f4da85881080dec9caa",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Ahad N. Zehmakan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16706": {
    "title": "Fair and Efficient Allocations with Limited Demands",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "09090858189ce5409f02ccfb669c69596334f64b",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Sushirdeep Narayana",
      "Ian A. Kash"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16707": {
    "title": "Scarce Societal Resource Allocation and the Price of (Local) Justice",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b64075ecb778621dd2b57acac029743a3b55597d",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Quan Nguyen",
      "Sanmay Das",
      "Roman Garnett"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16708": {
    "title": "From Behavioral Theories to Econometrics: Inferring Preferences of Human Agents from Data on Repeated Interactions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0b4c7e44e5e5d507b55efafdd5a76d85284f1451",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Gali Noti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16709": {
    "title": "Preference Elicitation as Average-Case Sorting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d6fc4fff91f3b84f2742529de6a5383471968102",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dominik Peters",
      "Ariel D. Procaccia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16710": {
    "title": "Market-Based Explanations of Collective Decisions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d5e09422963dc8db76b6c2424cd8786c1602f95",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Dominik Peters",
      "Grzegorz Pierczy≈Ñski",
      "Nisarg Shah",
      "Piotr Skowron"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16711": {
    "title": "A Permutation-Equivariant Neural Network Architecture For Auction Design",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "235669b26e809b6f57633425bdb92906dd10fe60",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Jad Rahme",
      "Samy Jelassi",
      "Joan Bruna",
      "S. Matthew Weinberg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16712": {
    "title": "Estimating Œ±-Rank by Maximizing Information Gain",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b799181859a25cc4c60f93249464accae91e6189",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Tabish Rashid",
      "Cheng Zhang",
      "Kamil Ciosek"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16713": {
    "title": "Online Posted Pricing with Unknown Time-Discounted Valuations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "be8c1fa8bc4181b345cb56cc7cbbc32e289ca94b",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Giulia Romano",
      "Gianluca Tartaglia",
      "Alberto Marchesi",
      "Nicola Gatti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16714": {
    "title": "The Maximin Support Method: An Extension of the D'Hondt Method to Approval-Based Multiwinner Elections",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f7f83205efea8c56b0671329618d02ba342bf600",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Luis S√°nchez-Fern√°ndez",
      "Norberto Fern√°ndez Garc√≠a",
      "Jes√∫s A. Fisteus",
      "Markus Brill"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16715": {
    "title": "Solution Concepts in Hierarchical Games Under Bounded Rationality With Applications to Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1b1f3c807974fb9d99a09ea1d44ba1cb6324be2c",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Atrisha Sarkar",
      "Krzysztof Czarnecki"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16716": {
    "title": "Modeling Voters in Multi-Winner Approval Voting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "15931520cce546bbf19b4cebeb4161c4debeabe7",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Jaelle Scheuerman",
      "Jason Harman",
      "Nicholas Mattei",
      "K. Brent Venable"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16717": {
    "title": "Coupon Design in Advertising Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "87fd9c9db4067b71a459b559c08c02ebe57ee443",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiran Shen",
      "Pingzhong Tang",
      "Xun Wang",
      "Yadong Xu",
      "Xiwang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16718": {
    "title": "Restricted Domains of Dichotomous Preferences with Possibly Incomplete Information",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "89f24fbc114126ed3b3f26ab7a04116e0220f710",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Zoi Terzopoulou",
      "Alexander Karpov",
      "Svetlana Obraztsova"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16719": {
    "title": "Facility's Perspective to Fair Facility Location Problems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "46fc13b90ab786538564cf04f723ad02448ecf7d",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Chenhao Wang",
      "Xiaoying Wu",
      "Minming Li",
      "Hau Chan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16720": {
    "title": "The Smoothed Complexity of Computing Kemeny and Slater Rankings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a35c6813578f8723d7e3200a87f35e23896bb21c",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Lirong Xia",
      "Weiqiang Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16721": {
    "title": "If You Like Shapley Then You'll Love the Core",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "02e32987366c1ebfcc56d7c2ab822473e4c9032e",
    "semantic_title": "",
    "citation_count": 30,
    "authors": [
      "Tom Yan",
      "Ariel D. Procaccia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16722": {
    "title": "A Model of Winners Allocation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c5e2d5f879778c62621c19f8fb71bac216ce93a3",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongjie  Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16723": {
    "title": "Targeted Negative Campaigning: Complexity and Approximations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bec0e6092cbda41024c320d307828435d86bab77",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "‚Ä™Avishai Zagoury‚Ä¨‚Äè",
      "Orgad Keller",
      "Avinatan Hassidim",
      "Noam Hazon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16724": {
    "title": "Finding and Certifying (Near-)Optimal Strategies in Black-Box Extensive-Form Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1d225e48891bebf985e29c9608d1074dd7b28e2c",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Brian Hu Zhang",
      "Tuomas Sandholm"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16725": {
    "title": "Automated Mechanism Design for Classification with Partial Verification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a6ada139344a996f398e1c7441e524b6a875be9c",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Hanrui Zhang",
      "Yu Cheng",
      "Vincent Conitzer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16726": {
    "title": "Incentive-Aware PAC Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0042bf7e39f93314621a924c1a0c4bf0d6d686f7",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Hanrui Zhang",
      "Vincent Conitzer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16727": {
    "title": "Classification with Few Tests through Self-Selection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f4f01097096b6e0d6c13bf3f95d921cde52ae2ea",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Hanrui Zhang",
      "Yu Cheng",
      "Vincent Conitzer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16728": {
    "title": "Computing Ex Ante Coordinated Team-Maxmin Equilibria in Zero-Sum Multiplayer Extensive-Form Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "19b08d257228cf340f1153b6b5cc0d44a4ffa98c",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Youzhi Zhang",
      "Bo An",
      "Jakub ƒåern√Ω"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16729": {
    "title": "Power in Liquid Democracy",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "301e6db1e7dcc8fe47431c4bf947061aa51a218e",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Yuzhe Zhang",
      "Davide Grossi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16730": {
    "title": "Learning from Crowds by Modeling Common Confusions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "11c6d0851152b6bec34726be40d90bea8d8a90f0",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Zhendong Chu",
      "Jing Ma",
      "Hongning Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16731": {
    "title": "Time to Transfer: Predicting and Evaluating Machine-Human Chatting Handoff",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5f5e1a745358981dc2953d2d1718c552eda9adc9",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Jiawei Liu",
      "Zhe Gao",
      "Yangyang Kang",
      "Zhuoren Jiang",
      "Guoxiu He",
      "Changlong Sun",
      "Xiaozhong Liu",
      "Wei Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16732": {
    "title": "Teaching Active Human Learners",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "549544ab6be9232481c5d7abf8fd01f7319135de",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Zizhe Wang",
      "Hailong Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16733": {
    "title": "Automated Storytelling via Causal, Commonsense Plot Ordering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4e0af5f4944c16e3ae49b3c96cce7f81989c30f8",
    "semantic_title": "",
    "citation_count": 43,
    "authors": [
      "Prithviraj Ammanabrolu",
      "Wesley Cheung",
      "William Broniec",
      "Mark O. Riedl"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16734": {
    "title": "MARTA: Leveraging Human Rationales for Explainable Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0e6338c992b6b72da05cb783f4d422ebf0462451",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Ines Arous",
      "Ljiljana Dolamic",
      "Jie Yang",
      "Akansha Bhardwaj",
      "Giuseppe Cuccu",
      "Philippe Cudr√©-Mauroux"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16735": {
    "title": "Human Uncertainty Inference via Deterministic Ensemble Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bfaec827c8874cc9a2f245fd06e6edd7e66679d9",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujin Cha",
      "Sang Wan Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16736": {
    "title": "Learning to Sit: Synthesizing Human-Chair Interactions via Hierarchical Control",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ed580995e4a51424d8f1a20f5b64200fe227c2cd",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Yu-Wei Chao",
      "Jimei Yang",
      "Weifeng Chen",
      "Jia Deng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16737": {
    "title": "User Driven Model Adjustment via Boolean Rule Explanations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d6d5d2d1a7f0351e4d4b31be95a21588bcbd133",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Elizabeth M. Daly",
      "Massimiliano Mattetti",
      "√ñznur Alkan",
      "Rahul Nair"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16738": {
    "title": "Classification Under Human Assistance",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4125a8bb23c65dbe6cfbe2470343f6d3929d1fe2",
    "semantic_title": "",
    "citation_count": 23,
    "authors": [
      "Abir De",
      "Nastaran Okati",
      "Ali Zarezade",
      "Manuel Gomez Rodriguez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16739": {
    "title": "Wasserstein Distributionally Robust Inverse Multiobjective Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eef710d6b72b22914a1dbd7ac4048fa8af8a047f",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Chaosheng Dong",
      "Bo Zeng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16740": {
    "title": "Illuminating Mario Scenes in the Latent Space of a Generative Adversarial Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "aa79cd3983e6cfd877a830eb3e55a8ded425fe28",
    "semantic_title": "",
    "citation_count": 44,
    "authors": [
      "Matthew C. Fontaine",
      "Ruilin Liu",
      "Ahmed Khalifa",
      "Jignesh Modi",
      "Julian Togelius",
      "Amy K. Hoover",
      "Stefanos Nikolaidis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16741": {
    "title": "ActionBert: Leveraging User Actions for Semantic Understanding of User Interfaces",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0285688c1a07e49a663d0f49ef39370fbd00d3aa",
    "semantic_title": "",
    "citation_count": 32,
    "authors": [
      "Zecheng He",
      "Srinivas Sunkara",
      "Xiaoxue Zang",
      "Ying Xu",
      "Lijuan Liu",
      "Nevan Wichers",
      "Gabriel Schubiner",
      "Ruby Lee",
      "Jindong Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16742": {
    "title": "Goal Blending for Responsive Shared Autonomy in a Navigating Vehicle",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "355e7bbedf75e1b2663a1abc54d7c3fd920d9640",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-Sian Jiang",
      "Garrett Warnell",
      "Peter Stone"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16743": {
    "title": "Contrastive Adversarial Learning for Person Independent Facial Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "35c52f5792d3454cf6d628bf420af7f5190e864c",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Daeha Kim",
      "Byung Cheol Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16744": {
    "title": "AI-Assisted Scientific Data Collection with Iterative Human Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4c57085514bb76df8aac9b5e22c5611c88fe93ab",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Travis Mandel",
      "James Boyd",
      "Sebastian J. Carter",
      "Randall H. Tanaka",
      "Taishi Nammoto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16745": {
    "title": "Improving the Performance-Compatibility Tradeoff with Personalized Objective Functions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dc8c9b980b761e4136929b452a7797d429375ddf",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Jonathan Martinez",
      "Kobi Gal",
      "Ece Kamar",
      "Levi H. S. Lelis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16746": {
    "title": "Indecision Modeling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "85f24a03b710d304b1daf8658fc66a926c52c371",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Duncan C. McElfresh",
      "Lok Chan",
      "Kenzie Doyle",
      "Walter Sinnott-Armstrong",
      "Vincent Conitzer",
      "Jana Schaich Borg",
      "John P. Dickerson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16747": {
    "title": "Narrative Plan Generation with Self-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c4a00c3d61b3656afcde10ba0341e12b3ff54065",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Mihai Polceanu",
      "Julie Porteous",
      "Alan Lindsay",
      "Marc Cavazza"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16748": {
    "title": "Uncertain Graph Neural Networks for Facial Action Unit Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "872138459871198199aa517df1a7fef112f29497",
    "semantic_title": "",
    "citation_count": 38,
    "authors": [
      "Tengfei Song",
      "Lisha Chen",
      "Wenming Zheng",
      "Qiang Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16749": {
    "title": "Learning Rewards From Linguistic Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9c49a2178134517701befea536400c01a1cdefe7",
    "semantic_title": "",
    "citation_count": 24,
    "authors": [
      "Theodore R. Sumers",
      "Mark K. Ho",
      "Robert D. Hawkins",
      "Karthik Narasimhan",
      "Thomas L. Griffiths"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16750": {
    "title": "Bounded Risk-Sensitive Markov Games: Forward Policy Design and Inverse Reward Learning with Iterative Reasoning and Cumulative Prospect Theory",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "48a7146f79422443b0352233b6e97caad4835ffb",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Ran Tian",
      "Liting Sun",
      "Masayoshi Tomizuka"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16751": {
    "title": "Content Learning with Structure-Aware Writing: A Graph-Infused Dual Conditional Variational Autoencoder for Automatic Storytelling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d2aeba4084b3b70d200f6c48f44d3ec0d87fa6b7",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Meng-Hsuan Yu",
      "Juntao Li",
      "Zhangming Chan",
      "Rui Yan",
      "Dongyan Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16752": {
    "title": "A Continual Learning Framework for Uncertainty-Aware Interactive Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1637f1b07c033a37725c0e045f105d1e370dbfb8",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Ervine Zheng",
      "Qi Yu",
      "Rui Li",
      "Pengcheng Shi",
      "Anne Haake"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16753": {
    "title": "Inferring Emotion from Large-scale Internet Voice Data: A Semi-supervised Curriculum Augmentation based Deep Learning Approach",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "72e9d0af53346177932bbb14bd9760085bc48212",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Suping Zhou",
      "Jia Jia",
      "Zhiyong Wu",
      "Zhihan Yang",
      "Yanfeng Wang",
      "Wei Chen",
      "Fanbo Meng",
      "Shuo Huang",
      "Jialie Shen",
      "Xiaochuan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16754": {
    "title": "Automatic Generation of Flexible Plans via Diverse Temporal Planning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c2a54fe5cff534bfde1e0e4980cce9776b3c84dc",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yotam Amitai",
      "Ayal Taitler",
      "Erez Karpas"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16755": {
    "title": "BT Expansion: a Sound and Complete Algorithm for Behavior Planning of Intelligent Robots with Behavior Trees",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "38e1a02dff6f8df48ad7c16ba5da80b5f6354c97",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Zhongxuan Cai",
      "Minglong Li",
      "Wanrong Huang",
      "Wenjing Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16756": {
    "title": "I3DOL: Incremental 3D Object Learning without Catastrophic Forgetting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e175fbed816f04a36030f53b0ce926a1f4f47ac9",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Jiahua Dong",
      "Yang Cong",
      "Gan Sun",
      "Bingtao Ma",
      "Lichen Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16757": {
    "title": "Enabling Fast Instruction-Based Modification of Learned Robot Skills",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "630c9f9aa7eb3c2a724bd5416093796b511c758b",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Tyler Frasca",
      "Bradley Oosterveld",
      "Meia Chita-Tegmark",
      "Matthias Scheutz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16758": {
    "title": "Consistent Right-Invariant Fixed-Lag Smoother with Application to Visual Inertial SLAM",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a59e2b07e8b2d58a4bb0e1f3ca641139fd5e59e0",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Jianzhu Huai",
      "Yukai Lin",
      "Yuan Zhuang",
      "Min Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16759": {
    "title": "Supervised Training of Dense Object Nets using Optimal Descriptors for Industrial Robotic Applications",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d6737d207aa0af9e5dd056e5ec1b9ece6c9cea77",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Andras Gabor Kupcsik",
      "Markus Spies",
      "Alexander Klein",
      "Marco Todescato",
      "Nicolai Waniek",
      "Philipp Schillinger",
      "Mathias B√ºrger"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16760": {
    "title": "DenserNet: Weakly Supervised Visual Localization Using Multi-Scale Feature Aggregation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "06f9e3ac57f4ffa3e50614c85599cf85b9695f84",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Dongfang Liu",
      "Yiming Cui",
      "Liqi Yan",
      "Christos Mousas",
      "Baijian Yang",
      "Yingjie Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16761": {
    "title": "Learning Intuitive Physics with Multimodal Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8c71b2a8d622463f17ee1e38b71e1bc5296174fd",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Sahand Rezaei-Shoshtari",
      "Francois R. Hogan",
      "Michael Jenkin",
      "David Meger",
      "Gregory Dudek"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16762": {
    "title": "SCAN: A Spatial Context Attentive Network for Joint Multi-Agent Intent Prediction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "597c78770a25216e998e79d3265495d98f66d2b0",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Jasmine  Sekhon",
      "Cody Fleming"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16763": {
    "title": "IDOL: Inertial Deep Orientation-Estimation and Localization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "db7b3a85b6a3676b86627b1b5ae45373b2d066b7",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Scott Sun",
      "Dennis Melamed",
      "Kris Kitani"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16764": {
    "title": "Differentiable Fluids with Solid Coupling for Learning and Control",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ccbaf40ac70e0c1812910048816b0dcd3332cd97",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Tetsuya Takahashi",
      "Junbang Liang",
      "Yi-Ling Qiao",
      "Ming C. Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16765": {
    "title": "CMAX++ : Leveraging Experience in Planning and Execution using Inaccurate Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4490dc4e270fc708a6106a69f055177b0b391c2f",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Anirudh Vemula",
      "J. Andrew Bagnell",
      "Maxim Likhachev"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16766": {
    "title": "Generative Partial Visual-Tactile Fused Object Clustering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "36fb293613254db235088892b10f588c4fca4a4e",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Tao Zhang",
      "Yang Cong",
      "Gan Sun",
      "Jiahua Dong",
      "Yuyang Liu",
      "Zhengming Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16767": {
    "title": "VMLoc: Variational Fusion For Learning-Based Multimodal Camera Localization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "49619def5dfb5d52f729f3b733402c336aada869",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Kaichen Zhou",
      "Changhao Chen",
      "Bing Wang",
      "Muhamad Risqi U. Saputra",
      "Niki Trigoni",
      "Andrew Markham"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16768": {
    "title": "Argumentation Frameworks with Strong and Weak Constraints: Semantics and Complexity",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f75c659cc62fdee3008614097facab2030869743",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Gianvincenzo Alfano",
      "Sergio Greco",
      "Francesco Parisi",
      "Irina Trubitsyna"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16769": {
    "title": "A General Setting for Gradual Semantics Dealing with Similarity",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "aebb4cb19539b0ddc0a282fa877f3da552019b1f",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Leila Amgoud",
      "Victor David"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16770": {
    "title": "Living Without Beth and Craig: Definitions and Interpolants in Description Logics with Nominals and Role Inclusions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f57d832293b2efc9b32fcd0dbfd28bf62bd44264",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Alessandro Artale",
      "Jean Christoph Jung",
      "Andrea Mazzullo",
      "Ana Ozaki",
      "Frank Wolter"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16771": {
    "title": "Equivalent Causal Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c27dc3a88373955935d80f7c851578e645d6529d",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Sander Beckers"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16772": {
    "title": "The Counterfactual NESS Definition of Causation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1fe30f24b9529f757047fab297e2d5fd72b145e4",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Sander Beckers"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16773": {
    "title": "Network Satisfaction for Symmetric Relation Algebras with a Flexible Atom",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5e87cc954f66df7e916b2ee352312d5f17d8e604",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Manuel Bodirsky",
      "Simon Kn√§uer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16774": {
    "title": "Conditional Inference under Disjunctive Rationality",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b66bebd41b059637378c0a6171ca9b32b7789139",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Richard Booth",
      "Ivan Varzinczak"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16775": {
    "title": "Algebra of Modular Systems: Containment and Equivalence",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f0ceefde2ce7290da473b1e11a652985e508ccc5",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrei Bulatov",
      "Eugenia Ternovska"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16776": {
    "title": "Certifying Top-Down Decision-DNNF Compilers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "208177504c8775dfe28ecf400ea0a9fbb7c12718",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Florent Capelli",
      "Jean-Marie Lagniez",
      "Pierre Marquis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16777": {
    "title": "Contextual Conditional Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a59137682b5f27e574b497883f82955f0c082699",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Giovanni Casini",
      "Thomas Meyer",
      "Ivan Varzinczak"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16778": {
    "title": "Preferred Explanations for Ontology-Mediated Queries under Existential Rules",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ed2162571dc97e976dd2c2c87dbb5fab6fe6d232",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "ƒ∞smail ƒ∞lkan Ceylan",
      "Thomas Lukasiewicz",
      "Enrico Malizia",
      "Cristian Molinaro",
      "Andrius Vaicenaviƒçius"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16779": {
    "title": "Topology-Aware Correlations Between Relations for Inductive Link Prediction in Knowledge Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "aa6f095df55e5eddf849deaa279aa6fc2fd6e290",
    "semantic_title": "",
    "citation_count": 40,
    "authors": [
      "Jiajun Chen",
      "Huarui He",
      "Feng Wu",
      "Jie Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16780": {
    "title": "A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "052cdf7abebc62789f13daf00a34b2a3e83bbf10",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Maxwell Crouse",
      "Ibrahim Abdelaziz",
      "Bassem Makni",
      "Spencer Whitehead",
      "Cristina Cornelio",
      "Pavan Kapanipathi",
      "Kavitha Srinivas",
      "Veronika Thost",
      "Michael Witbrock",
      "Achille Fokoue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16781": {
    "title": "Recursion in Abstract Argumentation is Hard --- On the Complexity of Semantics Based on Weak Admissibility",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "259f44f153efc65f2ae980cbc9c13bcdb2973174",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wolfgang Dvo≈ô√°k",
      "Markus Ulbricht",
      "Stefan Woltran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16782": {
    "title": "The Complexity Landscape of Claim-Augmented Argumentation Frameworks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f656b1155fa2a78c5e971576fa9bc4ff34e42e60",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Wolfgang Dvo≈ô√°k",
      "Alexander Gre√üler",
      "Anna Rapberger",
      "Stefan Woltran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16783": {
    "title": "On the Complexity of Sum-of-Products Problems over Semirings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8daae53ad9f080dbf9fde476cb96c17977762feb",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Thomas Eiter",
      "Rafael Kiesel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16784": {
    "title": "Treewidth-Aware Complexity in ASP: Not all Positive Cycles are Equally Hard",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "16c2e88c28874cb372e946c7c749fe577f275eaa",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Jorge Fandinno",
      "Markus Hecher"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16785": {
    "title": "SMT-based Safety Checking of Parameterized Multi-Agent Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b3dd44b6cedf217b6968296596efd82e7fd04deb",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Paolo Felli",
      "Alessandro Gianola",
      "Marco Montali"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16786": {
    "title": "A Simple Framework for Cognitive Planning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fe57ba8e833d8ca52b53e93cfb863c47e2bcc595",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Jorge Luis Fernandez Davila",
      "Dominique Longin",
      "Emiliano Lorini",
      "Fr√©d√©ric Maris"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16787": {
    "title": "Answering Regular Path Queries Under Approximate Semantics in Lightweight Description Logics",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5c989d2bf3064dd77d8f09a87801e672cfa15b3e",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oliver Fern√°ndez Gil",
      "Anni-Yasmin Turhan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16788": {
    "title": "Knowledge-Base Degrees of Inconsistency: Complexity and Counting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b1ae6a0fb5c8763db633b67918a0cbc6f739771e",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Johannes K. Fichte",
      "Markus Hecher",
      "Arne Meier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16789": {
    "title": "Constraint Logic Programming for Real-World Test Laboratory Scheduling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "322cc7745d6a5ba3bb4e129aa25273a52b2368e7",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Tobias Geibinger",
      "Florian Mischek",
      "Nysret Musliu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16790": {
    "title": "Mining EL Bases with Adaptable Role Depth",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "45c9507bfab80ac31dad215f06ce0fdc29fc11b1",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Ricardo Guimar√£es",
      "Ana Ozaki",
      "Cosimo Persia",
      "Baris Sertkaya"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16791": {
    "title": "REM-Net: Recursive Erasure Memory Network for Commonsense Evidence Refinement",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1d20cceb02fdf51c84e79e93c0d6c93c62017474",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Yinya Huang",
      "Meng Fang",
      "Xunlin Zhan",
      "Qingxing Cao",
      "Xiaodan Liang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16792": {
    "title": "(Comet-) Atomic 2020: On Symbolic and Neural Commonsense Knowledge Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f8a22859230e0ccafefc020dccc66b5a646fe0ac",
    "semantic_title": "",
    "citation_count": 180,
    "authors": [
      "Jena D. Hwang",
      "Chandra Bhagavatula",
      "Ronan Le Bras",
      "Jeff Da",
      "Keisuke Sakaguchi",
      "Antoine Bosselut",
      "Yejin Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16793": {
    "title": "Commonsense Knowledge Augmentation for Low-Resource Languages via Adversarial Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "efd2fdb0c1e38129c72168a64c2426f10489d65b",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Bosung Kim",
      "Juae Kim",
      "Youngjoong Ko",
      "Jungyun Seo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16794": {
    "title": "Parameterized Logical Theories",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4a99ed8f8ef38947498395fc16817410d58f35d7",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangzhen Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16795": {
    "title": "Learning Term Embeddings for Lexical Taxonomies",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ab390fc1019751ea29526476bf65dd152fe3d1d8",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Jingping Liu",
      "Menghui Wang",
      "Chao Wang",
      "Jiaqing Liang",
      "Lihan Chen",
      "Haiyun Jiang",
      "Yanghua Xiao",
      "Yunwen Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16796": {
    "title": "KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "997887cff41577752dc832e9475d5bb22c265093",
    "semantic_title": "",
    "citation_count": 87,
    "authors": [
      "Ye Liu",
      "Yao Wan",
      "Lifang He",
      "Hao Peng",
      "Philip  S. Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16797": {
    "title": "Parameterized Complexity of Logic-Based Argumentation in Schaefer's Framework",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2cf1a7e8caafb07dffe7ab939b01511e0785a28b",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Yasir Mahmood",
      "Arne Meier",
      "Johannes Schmidt"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16798": {
    "title": "Ranking Sets of Defeasible Elements in Preferential Approaches to Structured Argumentation: Postulates, Relations, and Characterizations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "781d7a4f84384bde688864d364c98e6a0feae3fd",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Jan Maly",
      "Johannes P. Wallner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16799": {
    "title": "GENSYNTH: Synthesizing Datalog Programs without Language Bias",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "18bb1574af20159952ada909b88891d57ab6ef85",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Jonathan Mendelson",
      "Aaditya Naik",
      "Mukund Raghothaman",
      "Mayur Naik"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16800": {
    "title": "Parameterized Complexity of Small Decision Tree Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "257c931655aec35969e99c58cb769f74637f7000",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Sebastian Ordyniak",
      "Stefan Szeider"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16801": {
    "title": "Interpreting Neural Networks as Quantitative Argumentation Frameworks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "38fcd223d3a335b2f38c0f58b0d1a86968ee7fb1",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Nico Potyka"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16802": {
    "title": "ChronoR: Rotation Based Temporal Knowledge Graph Embedding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4e52607397a96fb2104a99c570c9cec29c9ca519",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Ali Sadeghian",
      "Mohammadreza Armandpour",
      "Anthony Colas",
      "Daisy Zhe Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16803": {
    "title": "Quantification of Resource Production Incompleteness",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7b0f32c186ca55432ac9b257c7b041b7ec613e29",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yakoub Salhi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16804": {
    "title": "Stratified Negation in Datalog with Metric Temporal Operators",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c730812d07de71f50157fa8d64430912609a5c93",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "David J Tena Cucala",
      "Przemys≈Çaw A Wa≈Çƒôga",
      "Bernardo Cuenca Grau",
      "Egor Kostylev"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16805": {
    "title": "Strong Explanations in Abstract Argumentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e1e458c7e560c7cc41bd9fdaabb612d780d59cd2",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Markus Ulbricht",
      "Johannes P. Wallner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16806": {
    "title": "On the Tractability of SHAP Explanations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bd6ea16e34c7c4821061fc700cc719a8a44bf8c4",
    "semantic_title": "",
    "citation_count": 66,
    "authors": [
      "Guy Van den Broeck",
      "Anton Lykov",
      "Maximilian Schleich",
      "Dan Suciu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16807": {
    "title": "On Exploiting Hitting Sets for Model Reconciliation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "718989861c2f72751b710caa0b7471e16991ba8d",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Stylianos Loukas Vasileiou",
      "Alessandro Previti",
      "William Yeoh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16808": {
    "title": "Focused Inference and System P",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9363210990df8ee5644c20f89a05692c69662b2d",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Marco Wilhelm",
      "Gabriele Kern-Isberner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16809": {
    "title": "On-the-fly Synthesis for LTL over Finite Traces",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "31bc036140ef9868ef68fcae013bcaed50dab1c5",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Shengping Xiao",
      "Jianwen Li",
      "Shufang Zhu",
      "Yingying Shi",
      "Geguang Pu",
      "Moshe Vardi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16810": {
    "title": "Testing Independence Between Linear Combinations for Causal Discovery",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d52fa1f2d446891bf1e3e5081304ef8a76854778",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Hao Zhang",
      "Kun Zhang",
      "Shuigeng Zhou",
      "Jihong Guan",
      "Ji Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16811": {
    "title": "SWIFT: Scalable Wasserstein Factorization for Sparse Nonnegative Tensors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "136693087a38ef12e1510d4a1eef44fbb79e90b1",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Ardavan Afshar",
      "Kejing Yin",
      "Sherry Yan",
      "Cheng Qian",
      "Joyce Ho",
      "Haesun Park",
      "Jimeng Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16812": {
    "title": "DART: Adaptive Accept Reject Algorithm for Non-Linear Combinatorial Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ba589ce23fde1490b54646879fb2e9b3635e8228",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Mridul Agarwal",
      "Vaneet Aggarwal",
      "Abhishek Kumar Umrawal",
      "Chris Quinn"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16813": {
    "title": "Improved Worst-Case Regret Bounds for Randomized Least-Squares Value Iteration",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d28c8c16323dec5e93baf82f6c1374ba7e01d99f",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Priyank Agrawal",
      "Jinglin Chen",
      "Nan Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16814": {
    "title": "Semi-supervised Sequence Classification through Change Point Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1e58c9d1153d2f25d94b3a12b785bd7abe43bd1c",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Nauman Ahad",
      "Mark A. Davenport"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16815": {
    "title": "Learning Invariant Representations using Inverse Contrastive Loss",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8d131e78fd5cc6f347730c14b5ef6ee34e18e22a",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Aditya Kumar Akash",
      "Vishnu  Suresh Lokhande",
      "Sathya N. Ravi",
      "Vikas Singh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16816": {
    "title": "Learned Bi-Resolution Image Coding using Generalized Octave Convolutions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "20ab457294795a47471f1c56522591012c09167a",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Mohammad Akbari",
      "Jie Liang",
      "Jingning Han",
      "Chengjie Tu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16817": {
    "title": "Deep Bayesian Quadrature Policy Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2087626f72a47e1cae54e9ff9a10ecb26c3d1832",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Ravi Tej Akella",
      "Kamyar Azizzadenesheli",
      "Mohammad Ghavamzadeh",
      "Animashree Anandkumar",
      "Yisong Yue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16818": {
    "title": "eTREE: Learning Tree-structured Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ac944fb86af10007e0f9ca0df5d8b6203cf593d1",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Faisal M. Almutairi",
      "Yunlong Wang",
      "Dong Wang",
      "Emily Zhao",
      "Nicholas D. Sidiropoulos"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16819": {
    "title": "Does Explainable Artificial Intelligence Improve Human Decision-Making?",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e7411483b88a977ff046f444800d808135535f65",
    "semantic_title": "",
    "citation_count": 40,
    "authors": [
      "Yasmeen Alufaisan",
      "Laura R. Marusich",
      "Jonathan Z. Bakdash",
      "Yan Zhou",
      "Murat Kantarcioglu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16820": {
    "title": "Decentralized Multi-Agent Linear Bandits with Safety Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "17e65ef9d81727671cc75280ee30a5e219c2956d",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Sanae Amani",
      "Christos Thrampoulidis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16821": {
    "title": "Computing an Efficient Exploration Basis for Learning with Univariate Polynomial Features",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "95f8054c68a49c921eba783806f3418dab057f25",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Chaitanya Amballa",
      "Manu K. Gupta",
      "Sanjay P. Bhat"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16822": {
    "title": "Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "777873ef6d23c2cdd7dfd6c4834eb56769a25bb1",
    "semantic_title": "",
    "citation_count": 76,
    "authors": [
      "Elad Amrani",
      "Rami Ben-Ari",
      "Daniel Rotman",
      "Alex Bronstein"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16823": {
    "title": "An Enhanced Advising Model in Teacher-Student Framework using State Categorization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "63058875fdbcccc1ca84232eccc343ef19de685c",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Daksh Anand",
      "Vaibhav Gupta",
      "Praveen Paruchuri",
      "Balaraman Ravindran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16824": {
    "title": "On Lipschitz Regularization of Convolutional Layers using Toeplitz Matrix Theory",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3f75dc69849ac5c5ba4c5b86bd1e6418a4f0dea3",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Alexandre Araujo",
      "Benjamin Negrevergne",
      "Yann Chevaleyre",
      "Jamal Atif"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16825": {
    "title": "The Tractability of SHAP-Score-Based Explanations for Classification over Deterministic and Decomposable Boolean Circuits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "48fbef01f1548bb73f38381fb8ca20392e311961",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Marcelo Arenas",
      "Pablo Barcel√≥",
      "Leopoldo Bertossi",
      "Mika√´l Monet"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16826": {
    "title": "TabNet: Attentive Interpretable Tabular Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "efbd8e7a45cac8f025ba8a4de95b492d8d392c95",
    "semantic_title": "",
    "citation_count": 387,
    "authors": [
      "Sercan √ñ. Arik",
      "Tomas Pfister"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16827": {
    "title": "Robust Model Compression Using Deep Hypotheses",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "51e40a7f14794e82bc903e21ce9f87cabe54bc52",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Omri Armstrong",
      "Ran Gilad-Bachrach"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16828": {
    "title": "Deep Radial-Basis Value Functions for Continuous Control",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "09a9cae0503a3a354b420e5bcecdd432283435cc",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Kavosh Asadi",
      "Neev Parikh",
      "Ronald E. Parr",
      "George D. Konidaris",
      "Michael L. Littman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16829": {
    "title": "DecAug: Out-of-Distribution Generalization via Decomposed Feature Representation and Semantic Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6ea5701aa2ec72cdcddea6b1695e8c2192328261",
    "semantic_title": "",
    "citation_count": 33,
    "authors": [
      "Haoyue Bai",
      "Rui Sun",
      "Lanqing Hong",
      "Fengwei Zhou",
      "Nanyang Ye",
      "Han-Jia Ye",
      "S.-H. Gary Chan",
      "Zhenguo Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16830": {
    "title": "Correlative Channel-Aware Fusion for Multi-View Time Series Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6582fb0e0f67ede2541fd1d3aa54437f05482a1c",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Yue Bai",
      "Lichen Wang",
      "Zhiqiang Tao",
      "Sheng Li",
      "Yun Fu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16831": {
    "title": "Deterministic Mini-batch Sequencing for Training Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0fec66a519228662055cad9b23596f5461261ce3",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Subhankar Banerjee",
      "Shayok Chakraborty"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16832": {
    "title": "Relative Variational Intrinsic Control",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1a7471fb3d324a074bda8a7530e9e7749329cef9",
    "semantic_title": "",
    "citation_count": 24,
    "authors": [
      "Kate Baumli",
      "David Warde-Farley",
      "Steven Hansen",
      "Volodymyr Mnih"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16833": {
    "title": "A Theory of Independent Mechanisms for Extrapolation in Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "622109cdeb83f7cbdbc8fe126a985f27a671c3df",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Michel Besserve",
      "Remy Sun",
      "Dominik Janzing",
      "Bernhard Sch√∂lkopf"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16834": {
    "title": "ExGAN: Adversarial Generation of Extreme Samples",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a0e447a465a8b4729c976214368c172d2b272959",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Siddharth Bhatia",
      "Arjit Jain",
      "Bryan Hooi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16835": {
    "title": "Ordinal Historical Dependence in Graphical Event Models with Tree Representations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "83a40aa5e96d6301481599354ccc01a6823c8691",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debarun Bhattacharjya",
      "Tian Gao",
      "Dharmashankar Subramanian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16836": {
    "title": "Characterizing the Loss Landscape in Non-Negative Matrix Factorization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ee2cd9462a37fb861d894fda13df3efbc3abdcb5",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Johan Bjorck",
      "Anmol Kabra",
      "Kilian Q. Weinberger",
      "Carla Gomes"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16837": {
    "title": "Understanding Decoupled and Early Weight Decay",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cdba52cdc8dcadd8964591170d41bdeeef2355c8",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Johan Bjorck",
      "Kilian Q. Weinberger",
      "Carla Gomes"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16838": {
    "title": "Communication-Aware Collaborative Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "178e8d695fd3d72c914f35e52da9164e33d68b49",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Avrim Blum",
      "Shelby Heinecke",
      "Lev Reyzin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16839": {
    "title": "Stochastic Precision Ensemble: Self-Knowledge Distillation for Quantized Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "261aa442c219e6a388642d51834740bdb863a30a",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Yoonho Boo",
      "Sungho Shin",
      "Jungwook Choi",
      "Wonyong Sung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16840": {
    "title": "Fast Training of Provably Robust Neural Networks by SingleProp",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3e34b4f2f27f77eb2670958ef6ec8c758173db3b",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Akhilan Boopathy",
      "Lily Weng",
      "Sijia Liu",
      "Pin-Yu Chen",
      "Gaoyuan Zhang",
      "Luca Daniel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16841": {
    "title": "Sample-Specific Output Constraints for Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ab9ea01d28a330c1cbc96763c7273066a51eadab",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Mathis Brosowsky",
      "Florian Keck",
      "Olaf D√ºnkel",
      "Marius Z√∂llner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16842": {
    "title": "Fairness, Semi-Supervised Learning, and More: A General Framework for Clustering with Stochastic Pairwise Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "624ab31f34150e80e7429428f6ab8ae0e47b1358",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Brian Brubach",
      "Darshan Chakrabarti",
      "John P. Dickerson",
      "Aravind Srinivasan",
      "Leonidas Tsepenekas"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16843": {
    "title": "Improving Ensemble Robustness by Collaboratively Promoting and Demoting Adversarial Robustness",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6cfaa925c881ba5aa8efe8980a9ebe6509f0ddaa",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Anh Tuan Bui",
      "Trung Le",
      "He Zhao",
      "Paul Montague",
      "Olivier deVel",
      "Tamas Abraham",
      "Dinh Phung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16844": {
    "title": "Cascade Size Distributions: Why They Matter and How to Compute Them Efficiently",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2e2d33a224f1569f071286e13dbf8c00a1291287",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Rebekka Burkholz",
      "John Quackenbush"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16845": {
    "title": "Exploiting Diverse Characteristics and Adversarial Ambivalence for Domain Adaptive Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0b315769840a70e21427ab705947802e1c54a319",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Bowen Cai",
      "Huan Fu",
      "Rongfei Jia",
      "Binqiang Zhao",
      "Hua Li",
      "Yinghui Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16846": {
    "title": "Time Series Domain Adaptation via Sparse Associative Structure Alignment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "10d557c31213ec81ac61444ab91a879c2cdaad58",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Ruichu Cai",
      "Jiawei Chen",
      "Zijian Li",
      "Wei Chen",
      "Keli Zhang",
      "Junjian Ye",
      "Zhuozhang Li",
      "Xiaoyan Yang",
      "Zhenjie Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16847": {
    "title": "A Blind Block Term Decomposition of High Order Tensors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d45a47904d9de515103f2a6f6fbe29a48bb67f9",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Yunfeng Cai",
      "Ping Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16848": {
    "title": "Open-Set Recognition with Gaussian Mixture Variational Autoencoders",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dc304d97a36168a0c888e9668fa29937fcb2e009",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Alexander Cao",
      "Yuan Luo",
      "Diego Klabjan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16849": {
    "title": "Provably Secure Federated Learning against Malicious Clients",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c63e954296cf71c46fb2808e7bfaab0c3f635385",
    "semantic_title": "",
    "citation_count": 56,
    "authors": [
      "Xiaoyu Cao",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16850": {
    "title": "Dual Quaternion Knowledge Graph Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d947d696b55a3cca1010a4b61b561efc496fae4b",
    "semantic_title": "",
    "citation_count": 57,
    "authors": [
      "Zongsheng Cao",
      "Qianqian Xu",
      "Zhiyong Yang",
      "Xiaochun Cao",
      "Qingming Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16851": {
    "title": "Counterfactual Explanations for Oblique Decision Trees:Exact, Efficient Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b7a607f3ae3baf44b14ffa3a1dfe86a3e0a1b7e6",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Miguel  √Å. Carreira-Perpi√±√°n",
      "Suryabhan Singh Hada"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16852": {
    "title": "Curriculum Labeling: Revisiting Pseudo-Labeling for Semi-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "39e0a6bceec1fe851128c47fedf35a2d4f22b332",
    "semantic_title": "",
    "citation_count": 76,
    "authors": [
      "Paola Cascante-Bonilla",
      "Fuwen Tan",
      "Yanjun Qi",
      "Vicente Ordonez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16853": {
    "title": "Frivolous Units: Wider Networks Are Not Really That Wide",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "361996e4fbbabe5ef028c85d7ab9e4213e5c777c",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Stephen Casper",
      "Xavier Boix",
      "Vanessa D'Amario",
      "Ling Guo",
      "Martin Schrimpf",
      "Kasper Vinken",
      "Gabriel Kreiman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16854": {
    "title": "Automated Clustering of High-dimensional Data with a Feature Weighted Mean Shift Algorithm",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a2feed9d8658fe1cba0e7410af3aae06a85e8d18",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Saptarshi Chakraborty",
      "Debolina Paul",
      "Swagatam Das"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16855": {
    "title": "High-Confidence Off-Policy (or Counterfactual) Variance Estimation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d0725bed339ae51ed7867a7300e8ebe1a3e667d",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Yash Chandak",
      "Shiv Shankar",
      "Philip S. Thomas"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16856": {
    "title": "A Multi-step-ahead Markov Conditional Forward Model with Cube Perturbations for Extreme Weather Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "03771ace1d3a6b3eece6d1f9e8fd8fd004bd15d8",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chia-Yuan Chang",
      "Cheng-Wei Lu",
      "Chuan-Ju Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16857": {
    "title": "Extending Multi-Sense Word Embedding to Phrases and Sentences for Unsupervised Semantic Applications",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a6f3505451d9ec1099871804cb342e93d1fd6cb3",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Haw-Shiuan Chang",
      "Amol Agrawal",
      "Andrew McCallum"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16858": {
    "title": "On Online Optimization: Dynamic Regret Analysis of Strongly Convex and Smooth Problems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a4ef878021090b4dc01b1503dda1a19e99077936",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Ting-Jui Chang",
      "Shahin Shahrampour"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16859": {
    "title": "Provable Benefits of Overparameterization in Model Compression: From Double Descent to Pruning Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5f5c11163e6dce7c92908bc0fe3d131d754f5b88",
    "semantic_title": "",
    "citation_count": 34,
    "authors": [
      "Xiangyu Chang",
      "Yingcong Li",
      "Samet Oymak",
      "Christos Thrampoulidis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16860": {
    "title": "Differentially Private Decomposable Submodular Maximization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ffeaf679ecfbb70b9a22dfd640990d10bcc5cdc5",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Anamay Chaturvedi",
      "Huy L√™ Nguy·ªÖn",
      "Lydia Zakynthinou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16861": {
    "title": "Using Hindsight to Anchor Past Knowledge in Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "680f1bf7c3635e87d4064a2757ec0d68c01d69f3",
    "semantic_title": "",
    "citation_count": 110,
    "authors": [
      "Arslan Chaudhry",
      "Albert Gordo",
      "Puneet Dokania",
      "Philip Torr",
      "David Lopez-Paz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16862": {
    "title": "Deep Verifier Networks: Verification of Deep Discriminative Models with Deep Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7f5fc9db054e5bf6da0cec0da3bb0a47766623b7",
    "semantic_title": "",
    "citation_count": 40,
    "authors": [
      "Tong Che",
      "Xiaofeng Liu",
      "Site Li",
      "Yubin Ge",
      "Ruixiang Zhang",
      "Caiming Xiong",
      "Yoshua Bengio"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16863": {
    "title": "Scalable and Explainable 1-Bit Matrix Completion via Graph Signal Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "99994bea16edd732b6c4c266a669e10f38c9dc3d",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Chao Chen",
      "Dongsheng Li",
      "Junchi Yan",
      "Hanchi Huang",
      "Xiaokang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16864": {
    "title": "Addressing Action Oscillations through Learning Policy Inertia",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7cface53d4a081d209c74d953bfadd2e6bf030a5",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Chen Chen",
      "Hongyao Tang",
      "Jianye Hao",
      "Wulong Liu",
      "Zhaopeng Meng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16865": {
    "title": "Cross-Layer Distillation with Semantic Calibration",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e3dbe8d2e8d045ae5a8cfa52a520f3aa31a35a21",
    "semantic_title": "",
    "citation_count": 97,
    "authors": [
      "Defang Chen",
      "Jian-Ping Mei",
      "Yuan Zhang",
      "Can Wang",
      "Zhe Wang",
      "Yan Feng",
      "Chun Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16866": {
    "title": "Distributed Ranking with Communications: Approximation Analysis and Applications",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "29cfdbe098db7c296fbbd82c46bac815ac27ffd5",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hong Chen",
      "Yingjie Wang",
      "Yulong Wang",
      "Feng Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16867": {
    "title": "THOR, Trace-based Hardware-driven Layer-Oriented Natural Gradient Descent Computation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "431b7a2790b97c3e2165cc1a571f09f749ef1274",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Mengyun Chen",
      "Kaixin Gao",
      "Xiaolei Liu",
      "Zidong Wang",
      "Ningxi Ni",
      "Qian Zhang",
      "Lei  Chen",
      "Chao Ding",
      "Zhenghai Huang",
      "Min Wang",
      "Shuangling Wang",
      "Fan Yu",
      "Xinyuan Zhao",
      "Dachuan Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16868": {
    "title": "Neural Relational Inference with Efficient Message Passing Mechanisms",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "36d1934e8f6e5b16696aa22968d4a78790e6bf4d",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Siyuan Chen",
      "Jiahai Wang",
      "Guoqing Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16869": {
    "title": "Fitting the Search Space of Weight-sharing NAS with Graph Convolutional Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9535d8cef8bf4c251cb2b7439b773863cd0a2448",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Xin Chen",
      "Lingxi Xie",
      "Jun Wu",
      "Longhui Wei",
      "Yuhui Xu",
      "Qi Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16870": {
    "title": "Deep Spiking Neural Network with Neural Oscillation and Spike-Phase Information",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bd8876db69b685aa0db120410fc9ea1b79c7a870",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Yi Chen",
      "Hong Qu",
      "Malu Zhang",
      "Yuchen Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16871": {
    "title": "HyDRA: Hypergradient Data Relevance Analysis for Interpreting Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "75b928590b745c701515b5604dcfd162481687d7",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Yuanyuan Chen",
      "Boyang Li",
      "Han Yu",
      "Pengcheng Wu",
      "Chunyan Miao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16872": {
    "title": "NASGEM: Neural Architecture Search via Graph Embedding Method",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8d58ba4e876cdcc3fc9debf9b5a9e5262b87c49a",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Hsin-Pai Cheng",
      "Tunhou Zhang",
      "Yixing Zhang",
      "Shiyu Li",
      "Feng Liang",
      "Feng Yan",
      "Meng Li",
      "Vikas Chandra",
      "Hai Li",
      "Yiran Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16873": {
    "title": "Neighborhood Consensus Networks for Unsupervised Multi-view Outlier Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1e84b20fbf0ee69bdfad2c57115cac049d84e933",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Li Cheng",
      "Yijie Wang",
      "Xinwang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16874": {
    "title": "Self-Progressing Robust Training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "73aa94064c4c2e592ddad579c51960c5838828b8",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Minhao Cheng",
      "Pin-Yu Chen",
      "Sijia Liu",
      "Shiyu Chang",
      "Cho-Jui Hsieh",
      "Payel Das"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16875": {
    "title": "Continuous-Time Attention for Sequential Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ef392f264f49d3ee5ff9796270806a4636599271",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Jen-Tzung Chien",
      "Yi-Hsiang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16876": {
    "title": "Transfer Learning for Efficient Iterative Safety Validation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0b4f819fd568a7830aaaff56d0007bb8b608fb98",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Anthony Corso",
      "Mykel J. Kochenderfer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16877": {
    "title": "Computationally Tractable Riemannian Manifolds for Graph Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4fd4dd869b3d5e83ff3f666f50f85d7a05cc0493",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Calin Cruceru",
      "Gary Becigneul",
      "Octavian-Eugen Ganea"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16878": {
    "title": "Cost-aware Graph Generation: A Deep Bayesian Optimization Approach",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "90c70191c5cb5b91d56b3e6bbb86ad8f4a2dfd0d",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxu Cui",
      "Bo Yang",
      "Bingyi Sun",
      "Jiming Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16879": {
    "title": "Type-augmented Relation Prediction in Knowledge Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7c2e539af1d2eca07ee15b9202f90f2800df6bcc",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Zijun Cui",
      "Pavan Kapanipathi",
      "Kartik Talamadupula",
      "Tian Gao",
      "Qiang Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16880": {
    "title": "The Value-Improvement Path: Towards Better Representations for Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c035d3bd325fd374f4f4a2c3a9b6aa8483d64c66",
    "semantic_title": "",
    "citation_count": 41,
    "authors": [
      "Will Dabney",
      "Andr√© Barreto",
      "Mark Rowland",
      "Robert Dadashi",
      "John Quan",
      "Marc G. Bellemare",
      "David Silver"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16881": {
    "title": "Loop Estimator for Discounted Values in Markov Reward Processes",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6a3cd40b02d310faf807338949132ea148e12315",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Falcon Z. Dai",
      "Matthew R. Walter"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16882": {
    "title": "Differentially Private Stochastic Coordinate Descent",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "35336721707c159452bd529cd369379323cd1e63",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Georgios Damaskinos",
      "Celestine Mendler-D√ºnner",
      "Rachid Guerraoui",
      "Nikolaos Papandreou",
      "Thomas Parnell"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16883": {
    "title": "Generalized Adversarially Learned Inference",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0fb1d1d6466fad4c566249008265f0b0a215ea4a",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Yatin Dandi",
      "Homanga Bharadhwaj",
      "Abhishek Kumar",
      "Piyush Rai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16884": {
    "title": "Sample-Efficient L0-L2 Constrained Structure Learning of Sparse Ising Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "07a93b02a355035b5fb466c3e3e8f5dfafc288e0",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Antoine Dedieu",
      "Miguel L√°zaro-Gredilla",
      "Dileep George"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16885": {
    "title": "Learning with Retrospection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ca73f80bd7f2865cbd63f7345efd24f8d0d0a29a",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Xiang Deng",
      "Zhongfei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16886": {
    "title": "Mercer Features for Efficient Combinatorial Bayesian Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0fe589d100806afdaaff574e76616242ad9f13da",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Aryan Deshwal",
      "Syrine Belakaria",
      "Janardhan Rao Doppa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16887": {
    "title": "Differentially Private and Communication Efficient Collaborative Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cdbe63c788b496b2b3cbea4bf1c5314d74fe6784",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Jiahao Ding",
      "Guannan Liang",
      "Jinbo Bi",
      "Miao Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16888": {
    "title": "Knowledge Refinery: Learning from Decoupled Label",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b151ae6e84b973f90350223ae1f22740efcb0e7c",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Qianggang Ding",
      "Sifan Wu",
      "Tao Dai",
      "Hao Sun",
      "Jiadong Guo",
      "Zhang-Hua Fu",
      "Shutao Xia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16889": {
    "title": "Semi-Supervised Learning with Variational Bayesian Inference and Maximum Uncertainty Regularization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "02df2a42cd616820b668adf92e37f6afed302281",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Kien Do",
      "Truyen Tran",
      "Svetha Venkatesh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16890": {
    "title": "Residual Shuffle-Exchange Networks for Fast Processing of Long Sequences",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "93948a2aac559fcaf4314f8f472a0f122f465411",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Andis Draguns",
      "Emƒ´ls Ozoli≈Ü≈°",
      "Agris ≈†ostaks",
      "Matƒ´ss Apinis",
      "Karlis Freivalds"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16891": {
    "title": "A One-Size-Fits-All Solution to Conservative Bandit Problems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ae90ae196284e210385d2847e9e02b11014cd5ff",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Yihan Du",
      "Siwei Wang",
      "Longbo Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16892": {
    "title": "Combinatorial Pure Exploration with Full-Bandit or Partial Linear Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "329a658cbbd1894c8ea0a828fe1a9cb890003237",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Yihan Du",
      "Yuko Kuroki",
      "Wei Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16893": {
    "title": "Knowledge Refactoring for Inductive Program Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ce423bce21a71eb89905bad7bde4000f2b51ba66",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Sebastijan Dumancic",
      "Tias Guns",
      "Andrew Cropper"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16894": {
    "title": "Semi-Supervised Metric Learning: A Deep Resurrection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8bc65edb4eaef2d4443ff08406980920d5219ff8",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Ujjal Kr Dutta",
      "Mehrtash Harandi",
      "C Chandra Shekhar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16895": {
    "title": "Reinforcement Learning with Trajectory Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8e79043b89f007bd81d65244345b50f7bff7fca9",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Yonathan Efroni",
      "Nadav Merlis",
      "Shie Mannor"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16896": {
    "title": "The Parameterized Complexity of Clustering Incomplete Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8318d55656d4a2b4a1a0b4541cf9e13c14917dfe",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Eduard Eiben",
      "Robert Ganian",
      "Iyad Kanj",
      "Sebastian Ordyniak",
      "Stefan Szeider"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16897": {
    "title": "Learning Prediction Intervals for Model Performance",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "69d439ffa9da071ed163736a9ce1e306404653e4",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Benjamin Elder",
      "Matthew Arnold",
      "Anupama Murthi",
      "Ji≈ô√≠ Navr√°til"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16898": {
    "title": "Adaptive Gradient Methods for Constrained Convex Optimization and Variational Inequalities",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8856c69999b5293c68c3d34dc584618f8e09275f",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Alina Ene",
      "Huy L. Nguyen",
      "Adrian Vladu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16899": {
    "title": "Projection-Free Bandit Optimization with Privacy Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "80329da8202dba48a5eab5455ee1e6976723cb8e",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Alina Ene",
      "Huy L. Nguyen",
      "Adrian Vladu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16900": {
    "title": "Learning to Cascade: Confidence Calibration for Improving the Accuracy and Computational Cost of Cascade Inference Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4b001c535aa5fdac765005641542e8710300bd7d",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Shohei Enomoro",
      "Takeharu Eda"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16901": {
    "title": "Regret Bounds for Batched Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2c9c8df8e097ff06ae5741ad35f520110f264549",
    "semantic_title": "",
    "citation_count": 33,
    "authors": [
      "Hossein Esfandiari",
      "Amin Karbasi",
      "Abbas Mehrabian",
      "Vahab Mirrokni"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16902": {
    "title": "Almost Linear Time Density Level Set Estimation via DBSCAN",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eb23a57f5ab32ebeeab74bdb6c7afb25ebd57ba4",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Hossein Esfandiari",
      "Vahab Mirrokni",
      "Peilin Zhong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16903": {
    "title": "Deep Graph Spectral Evolution Networks for Graph Topological Evolution",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bb4b5ae14d4c22771136ed4630c9c47b055950b2",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Negar Etemadyrad",
      "Qingzhe Li",
      "Liang Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16904": {
    "title": "Adversarial Training and Provable Robustness: A Tale of Two Objectives",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1e2b41a9db99311c880b3fdfac21324a475280f9",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Jiameng Fan",
      "Wenchao Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16905": {
    "title": "Learning a Gradient-free Riemannian Optimizer on Tangent Spaces",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f50997fe182793a8a31114c88f6a5dafb7e990f5",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Xiaomeng Fan",
      "Zhi Gao",
      "Yuwei Wu",
      "Yunde Jia",
      "Mehrtash Harandi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16906": {
    "title": "Learning to Reweight with Deep Interactions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d4fd57a3b1e857a16b70ba7325b246d3b3b8bb75",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Yang Fan",
      "Yingce Xia",
      "Lijun Wu",
      "Shufang Xie",
      "Weiqing Liu",
      "Jiang Bian",
      "Tao Qin",
      "Xiang-Yang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16907": {
    "title": "Deep Switching Auto-Regressive Factorization: Application to Time Series Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ab9c2121338151dfd0056666135cc5113b4809d6",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Amirreza Farnoosh",
      "Bahar Azari",
      "Sarah Ostadabbas"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16908": {
    "title": "UAG: Uncertainty-aware Attention Graph Neural Network for Defending Adversarial Attacks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9bf050287e0cd8df167cc345878335fc5a8d045e",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Boyuan Feng",
      "Yuke Wang",
      "Yufei Ding"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16909": {
    "title": "SHOT-VAE: Semi-supervised Deep Generative Models With Label-aware ELBO Approximations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e06e573edffdc741c2e9e232b7ee6ee87229cfe1",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Hao-Zhe Feng",
      "Kezhi Kong",
      "Minghao Chen",
      "Tianye Zhang",
      "Minfeng Zhu",
      "Wei Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16910": {
    "title": "Learning to Augment for Data-scarce Domain BERT Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "53c1be1795a93ce3f9f74daafc043a70623c5406",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Lingyun Feng",
      "Minghui Qiu",
      "Yaliang Li",
      "Hai-Tao Zheng",
      "Ying Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16911": {
    "title": "Collaborative Group Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7109c1be12710d543776b79ccb8a0870b65db775",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Shaoxiong Feng",
      "Hongshen Chen",
      "Xuancheng Ren",
      "Zhuoye Ding",
      "Kan Li",
      "Xu Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16912": {
    "title": "Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ad01c1c8838d266235dab06b4974cebc8a88f269",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Christian Fiedler",
      "Carsten W. Scherer",
      "Sebastian Trimpe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16913": {
    "title": "Few-Shot One-Class Classification via Meta-Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f42f87e4015f1aad3ed464b47c8644214b41748c",
    "semantic_title": "",
    "citation_count": 24,
    "authors": [
      "Ahmed Frikha",
      "Denis Krompa√ü",
      "Hans-Georg K√∂pken",
      "Volker Tresp"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16914": {
    "title": "Towards Effective Context for Meta-Reinforcement Learning: an Approach based on Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "77be65bb396cb6309b6d03023c5f71203b3a39ea",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Haotian Fu",
      "Hongyao Tang",
      "Jianye Hao",
      "Chen Chen",
      "Xidong Feng",
      "Dong Li",
      "Wulong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16915": {
    "title": "Agreement-Discrepancy-Selection: Active Learning with Progressive Distribution Alignment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ad721b510a709bf914f233f7b36cf5c88459f8ab",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Mengying Fu",
      "Tianning Yuan",
      "Fang Wan",
      "Songcen Xu",
      "Qixiang Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16916": {
    "title": "Generalize a Small Pre-trained Model to Arbitrarily Large TSP Instances",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "50eec8da1acc52a7c4a0a2c527d7696a41bbdc22",
    "semantic_title": "",
    "citation_count": 58,
    "authors": [
      "Zhang-Hua Fu",
      "Kai-Bin Qiu",
      "Hongyuan Zha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16917": {
    "title": "HiGAN: Handwriting Imitation Conditioned on Arbitrary-Length Texts and Disentangled Styles",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2d1c4c63398c333413d9a4e16b10dc0dc9e00b36",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Ji Gan",
      "Weiqiang Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16918": {
    "title": "Diffusion Network Inference from Partial Observations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a30cc9c82469b0a63f0351c93f86df1ab5949579",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Ting Gan",
      "Keqi Han",
      "Hao Huang",
      "Shi Ying",
      "Yunjun Gao",
      "Zongpeng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16919": {
    "title": "Stabilizing Q Learning Via Soft Mellowmax Operator",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bf591da059e692cb5c2f1d6130e22fcb2fde6f54",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Yaozhong Gan",
      "Zhe Zhang",
      "Xiaoyang Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16920": {
    "title": "On the Convergence of Communication-Efficient Local SGD for Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d33bb29be6bb247041b12c704d150e3e4e1afa1",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Hongchang Gao",
      "An Xu",
      "Heng Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16921": {
    "title": "A Trace-restricted Kronecker-Factored Approximation to Natural Gradient",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6b3d345d309bf0ffb1076e5ac34462103413af72",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Kaixin Gao",
      "Xiaolei Liu",
      "Zhenghai Huang",
      "Min Wang",
      "Zidong Wang",
      "Dachuan Xu",
      "Fan Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16922": {
    "title": "Addressing Domain Gap via Content Invariant Representation for Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3a6e7065b3ef718d3064bcb294359db2a5585dd9",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Li Gao",
      "Lefei Zhang",
      "Qian Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16923": {
    "title": "Increasing Iterate Averaging for Solving Saddle-Point Problems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4199214350e269f674eda392a8a44a8746fac846",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Yuan Gao",
      "Christian Kroer",
      "Donald Goldfarb"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16924": {
    "title": "Uncertainty-Aware Multi-View Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "30531856e51ad6a51044f4766e896e792bb8a0a2",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Yu Geng",
      "Zongbo Han",
      "Changqing Zhang",
      "Qinghua Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16925": {
    "title": "Justicia: A Stochastic SAT Approach to Formally Verify Fairness",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "09203d11e98d69d11c25a10fbdc00731e62a31ad",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Bishwamittra Ghosh",
      "Debabrota Basu",
      "Kuldeep S. Meel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16926": {
    "title": "The Importance of Modeling Data Missingness in Algorithmic Fairness: A Causal Perspective",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3e2822475a8669ffedd282de12f2e247e6a2b266",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Naman Goel",
      "Alfonso Amayuelas",
      "Amit Deshpande",
      "Amit Sharma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16927": {
    "title": "Attribute-Guided Adversarial Training for Robustness to Natural Perturbations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "58604b3f4337d96ab2f160730976c5ef4e3ee3a1",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Tejas Gokhale",
      "Rushil Anirudh",
      "Bhavya Kailkhura",
      "Jayaraman J. Thiagarajan",
      "Chitta Baral",
      "Yezhou Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16928": {
    "title": "Efficient On-Chip Learning for Optical Neural Networks Through Power-Aware Sparse Zeroth-Order Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "25eb8d25f640615f2874ccf46b5c35e5fccf25ad",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Jiaqi Gu",
      "Chenghao Feng",
      "Zheng Zhao",
      "Zhoufeng Ying",
      "Ray T. Chen",
      "David Z. Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16929": {
    "title": "Attentive Neural Point Processes for Event Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "096fb613da4642aae8094e5081514446fdfb34ae",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Yulong Gu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16930": {
    "title": "Revisiting Iterative Back-Translation from the Perspective of Compositional Generalization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "df66fcd3fd4f0d55bd96528cddb0e2f08ddb3385",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Yinuo Guo",
      "Hualei Zhu",
      "Zeqi Lin",
      "Bei Chen",
      "Jian-Guang Lou",
      "Dongmei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16931": {
    "title": "Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b74c5b7c97ded089caa481964207ba5e0e65b659",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Umang Gupta",
      "Aaron M Ferber",
      "Bistra Dilkina",
      "Greg Ver Steeg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16932": {
    "title": "Towards Reusable Network Components by Learning Compatible Representations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "35db0fb0eab669b45173bf2f22565efa4e7253e4",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Michael Gygli",
      "Jasper Uijlings",
      "Vittorio Ferrari"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16933": {
    "title": "High-Dimensional Bayesian Optimization via Tree-Structured Additive Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "196645bfb3207053c19db2be845cecbb50ca95ed",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Eric Han",
      "Ishank Arora",
      "Jonathan Scarlett"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16934": {
    "title": "Explanation Consistency Training: Facilitating Consistency-Based Semi-Supervised Learning with Interpretability",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2f88acd32214ffd870d461d62b204903a50ec70b",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Tao Han",
      "Wei-Wei Tu",
      "Yu-Feng Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16935": {
    "title": "DeepSynth: Automata Synthesis for Automatic Task Segmentation in Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6ebeef3f32f0e1e67bded9362dacc01d12bee5c3",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Mohammadhosein Hasanbeig",
      "Natasha Yogananda Jeppu",
      "Alessandro Abate",
      "Tom Melham",
      "Daniel Kroening"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16936": {
    "title": "Liquid Time-constant Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1b9a07702cd346673b4c5e798d2256157fab1d3f",
    "semantic_title": "",
    "citation_count": 49,
    "authors": [
      "Ramin Hasani",
      "Mathias Lechner",
      "Alexander Amini",
      "Daniela Rus",
      "Radu Grosu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16937": {
    "title": "Learning with Safety Constraints: Sample Complexity of Reinforcement Learning for Constrained MDPs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0c9bc8f25d03287b32b56f9c6d14078c5fb2155f",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Aria HasanzadeZonuzy",
      "Archana Bura",
      "Dileep Kalathil",
      "Srinivas Shakkottai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16938": {
    "title": "Analysing the Noise Model Error for Realistic Noisy Label Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c95403947e6f15b12bbfd7448b9476cddccf19eb",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Michael A. Hedderich",
      "Dawei Zhu",
      "Dietrich Klakow"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16939": {
    "title": "Provably Good Solutions to the Knapsack Problem via Neural Networks of Bounded Size",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "05e95fdf43e627fb1827ee3e21c35f0ebf0b3ba2",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Christoph Hertrich",
      "Martin Skutella"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16940": {
    "title": "Scaling-Up Robust Gradient Descent Techniques",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9c2ad8c8501079a10bddbde5d432e73542c2afc8",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Matthew J. Holland"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16941": {
    "title": "Learning Model-Based Privacy Protection under Budget Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c398f8a81d10c0d582dfae6d7896870d0acd6d82",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Junyuan Hong",
      "Haotao Wang",
      "Zhangyang Wang",
      "Jiayu  Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16942": {
    "title": "Graph Game Embedding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "028137830e4a383192c21dd349420ffe83d6ec5c",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Xiaobin Hong",
      "Tong Zhang",
      "Zhen Cui",
      "Yuge Huang",
      "Pengcheng Shen",
      "Shaoxin Li",
      "Jian Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16943": {
    "title": "Topology Distance: A Topology-Based Approach for Evaluating Generative Adversarial Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "57b4ca6091d0f10bd42ba3ba87fbe5d90eaea6d9",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Danijela Horak",
      "Simiao Yu",
      "Gholamreza Salimi-Khorshidi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16944": {
    "title": "Storage Fit Learning with Feature Evolvable Streams",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "38e76887033f85efa63eed48159d191cbf536a27",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Bo-Jian Hou",
      "Yu-Hu Yan",
      "Peng Zhao",
      "Zhi-Hua Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16945": {
    "title": "Reinforcement Learning Based Multi-Agent Resilient Control: From Deep Neural Networks to an Adaptive Law",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "775a61ba50311ec65d3f01d410608f37e68ba545",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Jian Hou",
      "Fangyuan Wang",
      "Lili Wang",
      "Zhiyong Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16946": {
    "title": "Slimmable Generative Adversarial Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d5605ee4c28027f8845d5d7505445c7a5c2df6a",
    "semantic_title": "",
    "citation_count": 24,
    "authors": [
      "Liang Hou",
      "Zehuan Yuan",
      "Lei Huang",
      "Huawei Shen",
      "Xueqi Cheng",
      "Changhu Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16947": {
    "title": "Disentangled Representation Learning in Heterogeneous Information Network for Large-scale Android Malware Detection in the COVID-19 Era and Beyond",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ffb780edd4527cc39cee0eb34cd8ba539eaac54a",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Shifu Hou",
      "Yujie Fan",
      "Mingxuan Ju",
      "Yanfang Ye",
      "Wenqiang Wan",
      "Kui Wang",
      "Yinming Mei",
      "Qi Xiong",
      "Fudong Shao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16948": {
    "title": "Gaussian Process Priors for View-Aware Inference",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bee2b3c7cdb5da193e1a418ae7c0f6b70dc3f468",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Yuxin Hou",
      "Ari Heljakka",
      "Arno Solin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16949": {
    "title": "Boosting Multi-task Learning Through Combination of Task Labels - with Applications in ECG Phenotyping",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1b6ea0aff166a38e845689723a14b3596fb786fe",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Ming-En Hsieh",
      "Vincent Tseng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16950": {
    "title": "OPQ: Compressing Deep Neural Networks with One-shot Pruning-Quantization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7b16367b575d951a98f1762d8f45d7c0eb840581",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Peng Hu",
      "Xi Peng",
      "Hongyuan Zhu",
      "Mohamed M. Sabry Aly",
      "Jie Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16951": {
    "title": "Multi-scale Graph Fusion for Co-saliency Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f04cee8ce9819084648c90d2b3360595fb4ba38d",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Rongyao Hu",
      "Zhenyun Deng",
      "Xiaofeng Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16952": {
    "title": "Continual Learning by Using Information of Each Class Holistically",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d8a3986ebff641415995e3c462c7cf5fb4b3819c",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Wenpeng Hu",
      "Qi Qin",
      "Mengyu Wang",
      "Jinwen Ma",
      "Bing Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16953": {
    "title": "Predictive Adversarial Learning from Positive and Unlabeled Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d9117676a586c92b3e2a4747823cf8aa8dc798c2",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Wenpeng Hu",
      "Ran Le",
      "Bing Liu",
      "Feng Ji",
      "Jinwen Ma",
      "Dongyan Zhao",
      "Rui Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16954": {
    "title": "Multidimensional Uncertainty-Aware Evidential Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "432b8b15d12af9860c662cb4e0a767b1bcd023d4",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Yibo Hu",
      "Yuzhe Ou",
      "Xujiang Zhao",
      "Jin-Hee Cho",
      "Feng Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16955": {
    "title": "Adversarial Defence by Diversified Simultaneous Training of Deep Ensembles",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3ceb1fda6d7db93da419b583ce77da3cb40ac899",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Bo Huang",
      "Zhiwei Ke",
      "Yi Wang",
      "Wei Wang",
      "Linlin Shen",
      "Feng Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16956": {
    "title": "Accelerating Continuous Normalizing Flow with Trajectory Polynomial Regularization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3c8a110d71ef3132431288aee05b189e206d6ea9",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Han-Hsien Huang",
      "Mi-Yen Yeh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16957": {
    "title": "Attributes-Guided and Pure-Visual Attention Alignment for Few-Shot Recognition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "177a57cc39fced688c938a7f29ba251cc747b15e",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Siteng Huang",
      "Min Zhang",
      "Yachen Kang",
      "Donglin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16958": {
    "title": "Learning to Reweight Imaginary Transitions for Model-Based Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5b201baf0b648781ef5c23d5f4344fb19504eb95",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Wenzhen Huang",
      "Qiyue Yin",
      "Junge Zhang",
      "Kaiqi Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16959": {
    "title": "ACMo: Angle-Calibrated Moment Methods for Stochastic Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "efe0af196c18abea1db1e28b7c78dd30c4437585",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Xunpeng Huang",
      "Runxin Xu",
      "Hao Zhou",
      "Zhe Wang",
      "Zhengyang Liu",
      "Lei Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16960": {
    "title": "Personalized Cross-Silo Federated Learning on Non-IID Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "679237737ab2392a87a1f3c44d62b2e37f36bf01",
    "semantic_title": "",
    "citation_count": 195,
    "authors": [
      "Yutao Huang",
      "Lingyang Chu",
      "Zirui Zhou",
      "Lanjun Wang",
      "Jiangchuan Liu",
      "Jian Pei",
      "Yong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16961": {
    "title": "Reward-Biased Maximum Likelihood Estimation for Linear Stochastic Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5a29de624baa172236f3f544f3c5726293fe9399",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Yu-Heng Hung",
      "Ping-Chun Hsieh",
      "Xi Liu",
      "P. R. Kumar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16962": {
    "title": "Large Batch Optimization for Deep Learning Using New Complete Layer-Wise Adaptive Rate Scaling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b89644114c1e6f4133e5f459000b92e06ab7c7d0",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Zhouyuan Huo",
      "Bin Gu",
      "Heng Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16963": {
    "title": "Accurate and Robust Feature Importance Estimation under Distribution Shifts",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ecc6260cc1efc878c70bf5753d67e1a11b42627a",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Jayaraman J. Thiagarajan",
      "Vivek Narayanaswamy",
      "Rushil Anirudh",
      "Peer-Timo Bremer",
      "Andreas Spanias"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16964": {
    "title": "Variance Penalized On-Policy and Off-Policy Actor-Critic",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "08e7fda8b3077db9dbf7630ff5424582909a002a",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Arushi Jain",
      "Gandharv Patil",
      "Ayush Jain",
      "Khimya Khetarpal",
      "Doina Precup"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16965": {
    "title": "Constructing a Fair Classifier with Generated Fair Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "da62e18ef9808523f7678a5f6eb7d45ff54298d7",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Taeuk Jang",
      "Feng Zheng",
      "Xiaoqian Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16966": {
    "title": "Neural Utility Functions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "384b56b7b609a3966a6c02f8259b94e6f0f3e5de",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Porter Jenkins",
      "Ahmad Farag",
      "J. Stockton Jenkins",
      "Huaxiu Yao",
      "Suhang Wang",
      "Zhenhui Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16967": {
    "title": "IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "335a732095c8ffa27eed4513220a7c80066213df",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Insu Jeon",
      "Wonkwang Lee",
      "Myeongjang Pyeon",
      "Gunhee Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16968": {
    "title": "Active Bayesian Assessment of Black-Box Classifiers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "85ce98791b72c5c4d7ece02393a894c9c39da2f7",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Disi Ji",
      "Robert L. Logan",
      "Padhraic Smyth",
      "Mark Steyvers"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16969": {
    "title": "Show, Attend and Distill: Knowledge Distillation via Attention-based Feature Matching",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e9f0b81fe2f7f47a68d2d87fc1747d739cdbcd05",
    "semantic_title": "",
    "citation_count": 56,
    "authors": [
      "Mingi Ji",
      "Byeongho Heo",
      "Sungrae Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16970": {
    "title": "Dynamic Multi-Context Attention Networks for Citation Forecasting of Scientific Publications",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "22d00771c3e2af85ffd79f1038ae6dac30377c03",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Taoran Ji",
      "Nathan Self",
      "Kaiqun Fu",
      "Zhiqian Chen",
      "Naren Ramakrishnan",
      "Chang-Tien Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16971": {
    "title": "Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5d15dfc3be39915a03c8d50172694613929144cf",
    "semantic_title": "",
    "citation_count": 63,
    "authors": [
      "Jinyuan Jia",
      "Xiaoyu Cao",
      "Neil Zhenqiang Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16972": {
    "title": "Clustering Ensemble Meets Low-rank Tensor Approximation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "841dfc6985668e78fcc2e44e19788d2ab9c6307e",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Yuheng Jia",
      "Hui Liu",
      "Junhui Hou",
      "Qingfu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16973": {
    "title": "Action Candidate Based Clipped Double Q-learning for Discrete and Continuous Action Tasks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3b1b9d7926dfc2c34cc63095b3e50915ded4d307",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Haobo Jiang",
      "Jin Xie",
      "Jian Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16974": {
    "title": "LightXML: Transformer with Dynamic Negative Sampling for High-Performance Extreme Multi-label Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a0cd055650dc69d671b52b7f979d3f1bbfacda4b",
    "semantic_title": "",
    "citation_count": 54,
    "authors": [
      "Ting Jiang",
      "Deqing Wang",
      "Leilei Sun",
      "Huayi Yang",
      "Zhengyang Zhao",
      "Fuzhen Zhuang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16975": {
    "title": "Temporal-Logic-Based Reward Shaping for Continuing Reinforcement Learning Tasks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "691c36c2ca85b6b7e412b79ade52c9a58d988018",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Yuqian Jiang",
      "Suda Bharadwaj",
      "Bo Wu",
      "Rishi Shah",
      "Ufuk Topcu",
      "Peter Stone"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16976": {
    "title": "Power up! Robust Graph Convolutional Network via Graph Powering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7a0ed8ac6832505aafb94f6a30f4ac831aac0444",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Ming Jin",
      "Heng Chang",
      "Wenwu Zhu",
      "Somayeh Sojoudi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16977": {
    "title": "Balanced Open Set Domain Adaptation via Centroid Alignment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "96a1d152ab112b56a05c21ed1f693d17e0a4050d",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Mengmeng Jing",
      "Jingjing Li",
      "Lei Zhu",
      "Zhengming Ding",
      "Ke Lu",
      "Yang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16978": {
    "title": "Linearly Replaceable Filters for Deep Network Channel Pruning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6e030866df9920344b82fccf858868b06edb12fb",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Donggyu Joo",
      "Eojindl Yi",
      "Sunghyun Baek",
      "Junmo Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16979": {
    "title": "A Sample-Efficient Algorithm for Episodic Finite-Horizon MDP with Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4b7af6632be8f790f68ed2d5f02914ee4c6ce681",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Krishna C. Kalagarla",
      "Rahul Jain",
      "Pierluigi Nuzzo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16980": {
    "title": "Winning Lottery Tickets in Deep Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "12ff508431c627fa01aaaf5779d68b6336dec5d3",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Neha Mukund Kalibhat",
      "Yogesh Balaji",
      "Soheil Feizi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16981": {
    "title": "Exploration via State influence Modeling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7c2bb6d3e9a154335d9af5c7298b587ac15945bd",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Yongxin Kang",
      "Enmin Zhao",
      "Kai Li",
      "Junliang Xing"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16982": {
    "title": "Deep Probabilistic Canonical Correlation Analysis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3a154fe557fc218188e456745e15bc22be32482c",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Mahdi Karami",
      "Dale Schuurmans"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16983": {
    "title": "Learning Generalized Relational Heuristic Networks for Model-Agnostic Planning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6fc0c9e19db469eec8250862a108bfae118bf2b4",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Rushang Karia",
      "Siddharth Srivastava"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16984": {
    "title": "A Recipe for Global Convergence Guarantee in Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "221956bc9885749aa070f32af002cc0c02a49c97",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Kenji Kawaguchi",
      "Qingyun Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16985": {
    "title": "Bayesian Dynamic Mode Decomposition with Variational Matrix Factorization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5dc1a03d0ae0328302c213a1068b7550894d5c5d",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Takahiro Kawashima",
      "Hayaru Shouno",
      "Hideitsu Hino"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16986": {
    "title": "Improving Fairness and Privacy in Selection Problems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "90e70eb36e3ad7192ee958efb925b404408b94a4",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Mohammad Mahdi Khalili",
      "Xueru Zhang",
      "Mahed Abroshan",
      "Somayeh Sojoudi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16987": {
    "title": "A Flexible Framework for Communication-Efficient Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "239a5598deb4fa3c99c62a3a4dceec95bce69cb4",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Sarit Khirirat",
      "Sindri Magn√∫sson",
      "Arda Aytekin",
      "Mikael Johansson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16988": {
    "title": "GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "199ac333b1ff37917d1ab4a2e2002d9605b3db1e",
    "semantic_title": "",
    "citation_count": 78,
    "authors": [
      "Krishnateja Killamsetty",
      "Durga Sivasubramanian",
      "Ganesh Ramakrishnan",
      "Rishabh Iyer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16989": {
    "title": "Understanding Catastrophic Overfitting in Single-step Adversarial Training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "21b192d3d4f092fdc06c8dd799d86fb83b3099cf",
    "semantic_title": "",
    "citation_count": 42,
    "authors": [
      "Hoki Kim",
      "Woojin Lee",
      "Jaewook Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16990": {
    "title": "Counterfactual Fairness with Disentangled Causal Effect Variational Autoencoder",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a7bb20f6d5d07c2043712f9b17aa1150aedec362",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Hyemi Kim",
      "Seungjae Shin",
      "JoonHo Jang",
      "Kyungwoo Song",
      "Weonyoung Joo",
      "Wanmo Kang",
      "Il-Chul Moon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16991": {
    "title": "Split-and-Bridge: Adaptable Class Incremental Learning within a Single Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "55c5ef153d0cd05ab3051d67db72fa3d7a55f690",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Jong-Yeong Kim",
      "Dong-Wan Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16992": {
    "title": "DPM: A Novel Training Method for Physics-Informed Neural Networks in Extrapolation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bba8eaa382df676e5b6bc68e5e634c3252cc8420",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Jungeun Kim",
      "Kookjin Lee",
      "Dongeun Lee",
      "Sheo Yon Jhin",
      "Noseong Park"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16993": {
    "title": "Kernel-convoluted Deep Neural Networks with Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "46bfb0a8ed89d71d0ec3ae9b535b831dc91fe8a2",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minjin Kim",
      "Young-geun Kim",
      "Dongha Kim",
      "Yongdai Kim",
      "Myunghee Cho Paik"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16994": {
    "title": "Neural Sequence-to-grid Module for Learning Symbolic Rules",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2c0a266f9cb88bb914c138ece0deaab8cf528f78",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Segwang Kim",
      "Hyoungwook Nam",
      "Joonyoung Kim",
      "Kyomin Jung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16995": {
    "title": "Visual Concept Reasoning Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fab4598dc40ee5840196dd2c85e62f1238f11a48",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Taesup Kim",
      "Sungwoong Kim",
      "Yoshua Bengio"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16996": {
    "title": "Sparsity Aware Normalization for GANs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "48e714e7f7e98e62596704eea3950f9341517db2",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Idan Kligvasser",
      "Tomer Michaeli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16997": {
    "title": "HINT: Hierarchical Invertible Neural Transport for Density Estimation and Bayesian Inference",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1c3d659e9459bb8aad72390d2b340e051add6dac",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Jakob Kruse",
      "Gianluca Detommaso",
      "Ullrich K√∂the",
      "Robert Scheichl"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16998": {
    "title": "Nearly Linear-Time, Parallelizable Algorithms for Non-Monotone Submodular Maximization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "52c5836ddd2249839bdf17568e9434ae1c88ac96",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Alan Kuhnle"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/16999": {
    "title": "Asynchronous Optimization Methods for Efficient Training of Deep Neural Networks with Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "80afd4f0a8c036504cd4730f9d389b732b9d43e2",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Vyacheslav Kungurtsev",
      "Malcolm Egan",
      "Bapi Chatterjee",
      "Dan Alistarh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17000": {
    "title": "Positions, Channels, and Layers: Fully Generalized Non-Local Network for Singer Identification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fbb14447bb10a87215fd9cbd40976b225999f8b7",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "I-Yuan Kuo",
      "Wen-Li Wei",
      "Jen-Chun  Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17001": {
    "title": "MolGrow: A Graph Normalizing Flow for Hierarchical Molecular Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6bcc0ca39c6d120b6a7e8ab0d7e988e577403ab8",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Maksim Kuznetsov",
      "Daniil Polykovskiy"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17002": {
    "title": "Compressing Deep Convolutional Neural Networks by Stacking Low-dimensional Binary Convolution Filters",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bbace99bbe05345c2b2bbe35fdb9007bab398228",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Weichao Lan",
      "Liang Lan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17003": {
    "title": "Hypothesis Disparity Regularized Mutual Information Maximization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "721c1e4b889b09ec2dc5c52a80340fec52a02f89",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Qicheng Lao",
      "Xiang Jiang",
      "Mohammad Havaei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17004": {
    "title": "Query Training: Learning a Worse Model to Infer Better Marginals in Undirected Graphical Models with Hidden Variables",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4c8ac6887c7dd6397598aeedb3edfa0b2b9c5153",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Miguel L√°zaro-Gredilla",
      "Wolfgang Lehrach",
      "Nishad Gothoskar",
      "Guangyao Zhou",
      "Antoine Dedieu",
      "Dileep George"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17005": {
    "title": "Metrics and Continuity in Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d6d2183c79c226129805652c0195cf39896ce8a0",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Charline Le Lan",
      "Marc G. Bellemare",
      "Pablo Samuel Castro"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17006": {
    "title": "Lipschitz Lifelong Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "207c7b8ea8f94463383a089e4f7f24b64503f9c0",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Erwan Lecarpentier",
      "David Abel",
      "Kavosh Asadi",
      "Yuu Jinnai",
      "Emmanuel Rachelson",
      "Michael L. Littman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17007": {
    "title": "Norm-Based Generalisation Bounds for Deep Multi-Class Convolutional Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b806ffeea0b172755824b210dbeccf2b2ae714b2",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Antoine Ledent",
      "Waleed Mustafa",
      "Yunwen Lei",
      "Marius Kloft"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17008": {
    "title": "Learnable Dynamic Temporal Pooling for Time Series Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "803a1fed191ad3eb79eb3c073900b31e7e5ad0a9",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Dongha Lee",
      "Seonghyeon Lee",
      "Hwanjo Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17009": {
    "title": "Interpretable Embedding Procedure Knowledge Transfer via Stacked Principal Component Analysis and Graph Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "48e02bfbb5d1b69deee0e324e824a1f310f86172",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Seunghyun Lee",
      "Byung Cheol Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17010": {
    "title": "Unsupervised Domain Adaptation for Semantic Segmentation by Content Transfer",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "11de73205f632acb422de5cadae7ed4571595bf5",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Suhyeon Lee",
      "Junhyuk Hyun",
      "Hongje Seong",
      "Euntai Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17011": {
    "title": "Memory and Computation-Efficient Kernel SVM via Binary Embedding and Ternary Model Coefficients",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "64b3a220d31b4b33e50a7c1bc60235c2eed6868b",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Zijian Lei",
      "Liang Lan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17012": {
    "title": "Enhancing Parameter-Free Frank Wolfe with an Extra Subproblem",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fde3ce79d4866297a27600ccb22321f80537cb1d",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Bingcong Li",
      "Lingda Wang",
      "Georgios B. Giannakis",
      "Zhizhen Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17013": {
    "title": "Unsupervised Active Learning via Subspace Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "48d67498e37ee6b164f6d8d7d50f403e01b59723",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Changsheng Li",
      "Kaihang Mao",
      "Lingyan Liang",
      "Dongchun Ren",
      "Wei Zhang",
      "Ye Yuan",
      "Guoren Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17014": {
    "title": "LRSC: Learning Representations for Subspace Clustering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ebe4c587de2e1820b9f42e6b246126b33c5d26ed",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Changsheng Li",
      "Chen Yang",
      "Bo Liu",
      "Ye Yuan",
      "Guoren Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17015": {
    "title": "GoT: a Growing Tree Model for Clustering Ensemble",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4ee1cb44701e9211acb4d972fd8abbcc3e509adb",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Feijiang Li",
      "Yuhua Qian",
      "Jieting Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17016": {
    "title": "VSQL: Variational Shadow Quantum Learning for Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a24934da43ebc507be35b7a6facc5d4c71f505a3",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Guangxi Li",
      "Zhixin Song",
      "Xin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17017": {
    "title": "High Fidelity GAN Inversion via Prior Multi-Subspace Feature Composition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3a2042de18e9b5d2d6c130d5072e2cef921b8d5e",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanyue Li",
      "Qianfen Jiao",
      "Sheng Qian",
      "Si Wu",
      "Hau-San Wong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17018": {
    "title": "ShapeNet: A Shapelet-Neural Network Approach for Multivariate Time Series Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "be818bd3db1928dcfe24f23ee7afaa09545f9a61",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Guozhong Li",
      "Byron Choi",
      "Jianliang Xu",
      "Sourav S Bhowmick",
      "Kwok-Pan Chun",
      "Grace Lai-Hung Wong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17019": {
    "title": "A Bayesian Approach for Subset Selection in Contextual Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ed247312f1188a44c7f05fc9392879d90b727275",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Jialian Li",
      "Chao Du",
      "Jun Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17020": {
    "title": "Self-Paced Two-dimensional PCA",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "464e75d95841b43eb33e0308fa5924aa202e5fb4",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Jiangxin Li",
      "Zhao Kang",
      "Chong Peng",
      "Wenyu Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17021": {
    "title": "Learning Intact Features by Erasing-Inpainting for Few-shot Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "43eb7fd1cc8247483e6c5bd6b0f154eb2fdc63a3",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Junjie Li",
      "Zilei Wang",
      "Xiaoming Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17022": {
    "title": "Token-Aware Virtual Adversarial Training in Natural Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fe9cd5bcca161289b0e3da0f49114dcccf62eaa1",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Linyang Li",
      "Xipeng Qiu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17023": {
    "title": "Synergetic Learning of Heterogeneous Temporal Sequences for Multi-Horizon Probabilistic Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "41de3027e358b39597faa646e8c2baf7ed58cb8c",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Longyuan Li",
      "Jihai Zhang",
      "Junchi Yan",
      "Yaohui Jin",
      "Yunhao Zhang",
      "Yanjie Duan",
      "Guangjian Tian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17024": {
    "title": "Bayesian Distributional Policy Gradients",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "db5ec14be596e3c52cd2fa29473927cb70239973",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Luchen Li",
      "A. Aldo Faisal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17025": {
    "title": "Learning Graph Neural Networks with Approximate Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "be62a12d7c1dd77157164a0cbc448dc5c0e2db96",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Qunwei  Li",
      "Shaofeng Zou",
      "Wenliang Zhong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17026": {
    "title": "Multi-View Representation Learning with Manifold Smoothness",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bebc1c153acf764db685975eb88bedcd3911a5b0",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Shu Li",
      "Wei Wang",
      "Wen-Tao Li",
      "Pan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17027": {
    "title": "Bi-Classifier Determinacy Maximization for Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fdb6bbec092061d6d4729e016f3277795170adaf",
    "semantic_title": "",
    "citation_count": 42,
    "authors": [
      "Shuang Li",
      "Fangrui Lv",
      "Binhui Xie",
      "Chi Harold Liu",
      "Jian Liang",
      "Chen Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17028": {
    "title": "Sublinear Classical and Quantum Algorithms for General Matrix Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3a69cf4992a77daf4d4e6dba6544e4f6a090a401",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Tongyang Li",
      "Chunhao Wang",
      "Shouvanik Chakrabarti",
      "Xiaodi Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17029": {
    "title": "A Free Lunch for Unsupervised Domain Adaptive Object Detection without Source Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8bd4264cc4e4644e9ff5beff466cceb4a3325e90",
    "semantic_title": "",
    "citation_count": 59,
    "authors": [
      "Xianfeng Li",
      "Weijie Chen",
      "Di Xie",
      "Shicai Yang",
      "Peng Yuan",
      "Shiliang Pu",
      "Yueting Zhuang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17030": {
    "title": "Improving Adversarial Robustness via Probabilistically Compact Loss with Logit Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2ed004ed273bcf3cf33d37f4c6952ed68b55bb4b",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Xin Li",
      "Xiangrui Li",
      "Deng Pan",
      "Dongxiao Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17031": {
    "title": "MFES-HB: Efficient Hyperband with Multi-Fidelity Quality Measurements",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "185ab6081f702d65573e7a151a417ba8b16fc816",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Yang Li",
      "Yu Shen",
      "Jiawei Jiang",
      "Jinyang Gao",
      "Ce Zhang",
      "Bin Cui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17032": {
    "title": "Learned Extragradient ISTA with Interpretable Residual Structures for Sparse Coding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c7b448b094e3d136e6676de794faf0e4b25b3070",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Yangyang Li",
      "Lin Kong",
      "Fanhua Shang",
      "Yuanyuan Liu",
      "Hongying Liu",
      "Zhouchen Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17033": {
    "title": "One-shot Graph Neural Architecture Search with Dynamic Search Space",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9425619f07e553624140f6f1207cc0d56159d290",
    "semantic_title": "",
    "citation_count": 23,
    "authors": [
      "Yanxi Li",
      "Zean Wen",
      "Yunhe Wang",
      "Chang Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17034": {
    "title": "Scheduled Sampling in Vision-Language Pretraining with Decoupled Encoder-Decoder Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "04dee7bfed6af7e18cf8dcfc639de105120a3f6e",
    "semantic_title": "",
    "citation_count": 30,
    "authors": [
      "Yehao Li",
      "Yingwei Pan",
      "Ting Yao",
      "Jingwen Chen",
      "Tao Mei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17035": {
    "title": "Online Optimal Control with Affine Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "23c7a7af699ef6caf1783c4e161f8d2325d5c3f4",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Yingying Li",
      "Subhro Das",
      "Na Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17036": {
    "title": "TRQ: Ternary Neural Networks With Residual Quantization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ae93b52e32df91f4aeb21b045d4b234e75543967",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Yue Li",
      "Wenrui Ding",
      "Chunlei Liu",
      "Baochang Zhang",
      "Guodong Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17037": {
    "title": "Contrastive Clustering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d52ee822014835fcd5a4992c94579d9f95673d55",
    "semantic_title": "",
    "citation_count": 203,
    "authors": [
      "Yunfan Li",
      "Peng Hu",
      "Zitao Liu",
      "Dezhong Peng",
      "Joey Tianyi Zhou",
      "Xi Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17038": {
    "title": "Longitudinal Deep Kernel Gaussian Process Regression",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "03c1349c35a36c4fb7984d8f94e34af25ec96019",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Junjie Liang",
      "Yanting Wu",
      "Dongkuan Xu",
      "Vasant G Honavar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17039": {
    "title": "Large Norms of CNN Layers Do Not Hurt Adversarial Robustness",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2f513ef015d7ed4c1340ea92797d8af21b456431",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Youwei Liang",
      "Dong Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17040": {
    "title": "Doubly Residual Neural Decoder: Towards Low-Complexity High-Performance Channel Decoding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ee935013cfc1758892e982541dda854e2c8e5ec8",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Siyu Liao",
      "Chunhua Deng",
      "Miao Yin",
      "Bo Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17041": {
    "title": "From Label Smoothing to Label Relaxation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9c4cad2cc63b56de94057a463b6f4cb6d6a21c26",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Julian Lienen",
      "Eyke H√ºllermeier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17042": {
    "title": "Sample Selection for Universal Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a61d49e7aca4208c596ad261b760fe644dec58d1",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Omri Lifshitz",
      "Lior Wolf"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17043": {
    "title": "Class-Attentive Diffusion Network for Semi-Supervised Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "471064962a5db3803faf6c6581b488aea41e02e0",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Jongin Lim",
      "Daeho Um",
      "Hyung Jin Chang",
      "Dae Ung Jo",
      "Jin Young Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17044": {
    "title": "Auto-Encoding Transformations in Reparameterized Lie Groups for Unsupervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1a9eda9311471faf1a46e170b5b843eb7772af84",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Feng Lin",
      "Haohang Xu",
      "Houqiang Li",
      "Hongkai Xiong",
      "Guo-Jun Qi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17045": {
    "title": "Multi-Proxy Wasserstein Classifier for Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d1023fa9ca56316055902aeb25591778d5b6d868",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Benlin Liu",
      "Yongming Rao",
      "Jiwen Lu",
      "Jie Zhou",
      "Cho-Jui Hsieh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17046": {
    "title": "TransTailor: Pruning the Pre-trained Model for Improved Transfer Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4e28880fdfea67e411fb7184e656d1471f293f76",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Bingyan Liu",
      "Yifeng Cai",
      "Yao Guo",
      "Xiangqun Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17047": {
    "title": "Learning a Few-shot Embedding Model with Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "46c35cc5e488ff72a256ab4e73d21702487b83b7",
    "semantic_title": "",
    "citation_count": 59,
    "authors": [
      "Chen Liu",
      "Yanwei Fu",
      "Chengming Xu",
      "Siqian Yang",
      "Jilin Li",
      "Chengjie Wang",
      "Li Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17048": {
    "title": "Unchain the Search Space with Hierarchical Differentiable Architecture Search",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b0cb2cf5aba4d07fe152e9eaa3e1008fbb099a0a",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Guanting Liu",
      "Yujie Zhong",
      "Sheng Guo",
      "Matthew R. Scott",
      "Weilin Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17049": {
    "title": "Overcoming Catastrophic Forgetting in Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e41a28daa05cc955e00690c20a3fa15ba2d11cdc",
    "semantic_title": "",
    "citation_count": 38,
    "authors": [
      "Huihui Liu",
      "Yiding Yang",
      "Xinchao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17050": {
    "title": "Stable Adversarial Learning under Distributional Shifts",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "649cbe47d71abe69833ee1135945adb1cb3b71a8",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Jiashuo Liu",
      "Zheyan Shen",
      "Peng Cui",
      "Linjun Zhou",
      "Kun Kuang",
      "Bo Li",
      "Yishi Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17051": {
    "title": "Hierarchical Multiple Kernel Clustering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "213ffd7c51242db1428d2261c229dcafb14be674",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Jiyuan Liu",
      "Xinwang Liu",
      "Siwei Wang",
      "Sihang Zhou",
      "Yuexiang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17052": {
    "title": "Dynamically Grown Generative Adversarial Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8b33fd37b4615ebdcf234955c1fdbd726bfa4f4f",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Lanlan Liu",
      "Yuting Zhang",
      "Jia Deng",
      "Stefano Soatto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17053": {
    "title": "FLAME: Differentially Private Federated Learning in the Shuffle Model",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "50781751a97cbf7ccddb0a4860d04fc550d01f7c",
    "semantic_title": "",
    "citation_count": 40,
    "authors": [
      "Ruixuan Liu",
      "Yang Cao",
      "Hong Chen",
      "Ruoyang Guo",
      "Masatoshi Yoshikawa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17054": {
    "title": "Post-training Quantization with Multiple Points: Mixed Precision without Mixed Precision",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "41151f89079f1c52761751b2392a40458c6a896d",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Xingchao Liu",
      "Mao Ye",
      "Dengyong Zhou",
      "Qiang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17055": {
    "title": "Train a One-Million-Way Instance Classifier for Unsupervised Visual Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ae815a8510a7bf888d0ec10c6b50c6f4472bfc57",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Yu Liu",
      "Lianghua Huang",
      "Pan Pan",
      "Bin Wang",
      "Yinghui Xu",
      "Rong Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17056": {
    "title": "ROSITA: Refined BERT cOmpreSsion with InTegrAted techniques",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "76ef68c7c2410b503e5f1d43ca0c3d6764f72de1",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Yuanxin Liu",
      "Zheng Lin",
      "Fengcheng Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17057": {
    "title": "Task Aligned Generative Meta-learning for Zero-shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9214ef6db735d2b8cb115c8e04e869e21803fdb9",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Zhe Liu",
      "Yun Li",
      "Lina Yao",
      "Xianzhi Wang",
      "Guodong Long"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17058": {
    "title": "Learning from eXtreme Bandit Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "675da5104616f4b869f7a71d10270f736cc79a24",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Romain Lopez",
      "Inderjit S. Dhillon",
      "Michael I. Jordan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17059": {
    "title": "Improving Causal Discovery By Optimal Bayesian Network Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "15c1f24e4b7460cab3f0c7ba2c56b9b440c75286",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Ni Y Lu",
      "Kun Zhang",
      "Changhe Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17060": {
    "title": "Stochastic Graphical Bandits with Adversarial Corruptions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "94a49625bba0e205ac844d60eff65c5a1c218bd2",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Shiyin Lu",
      "Guanghui Wang",
      "Lijun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17061": {
    "title": "Stochastic Bandits with Graph Feedback in Non-Stationary Environments",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "520270af8684ae84c5bb8be529fd84c94203751d",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Shiyin Lu",
      "Yao Hu",
      "Lijun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17062": {
    "title": "Decentralized Policy Gradient Descent Ascent for Safe Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d59d3eb12f58ddf10eed0a6bf4a46a8ee6d8c548",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Songtao Lu",
      "Kaiqing Zhang",
      "Tianyi Chen",
      "Tamer Ba≈üar",
      "Lior Horesh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17063": {
    "title": "Tailoring Embedding Function to Heterogeneous Few-Shot Tasks by Global and Local Feature Adaptors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "31f5f944b61b3478e2c3d383810737a26eb55d1c",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Su Lu",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17064": {
    "title": "PULNS: Positive-Unlabeled Learning with Effective Negative Sample Selector",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4c487f774990b76228de42c30a1fa9be722257c0",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Chuan Luo",
      "Pu Zhao",
      "Chen Chen",
      "Bo Qiao",
      "Chao Du",
      "Hongyu Zhang",
      "Wei Wu",
      "Shaowei Cai",
      "Bing He",
      "Saravanakumar Rajmohan",
      "Qingwei Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17065": {
    "title": "Revisiting Co-Occurring Directions: Sharper Analysis and Efficient Algorithm for Sparse Matrices",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "93d83c2ae447a2f4944b1b18e3b537cbc1d0f018",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Luo Luo",
      "Cheng Chen",
      "Guangzeng Xie",
      "Haishan Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17066": {
    "title": "Semi-supervised Medical Image Segmentation through Dual-task Consistency",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "19e55508e0ca39e0c92c89e47ce6f356f05c54b5",
    "semantic_title": "",
    "citation_count": 137,
    "authors": [
      "Xiangde Luo",
      "Jieneng Chen",
      "Tao Song",
      "Guotai Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17067": {
    "title": "Adaptive Knowledge Driven Regularization for Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8f7854d172fab854f8ca62a756ad3eec7941c9c8",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Zhaojing Luo",
      "Shaofeng Cai",
      "Can Cui",
      "Beng Chin Ooi",
      "Yang Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17068": {
    "title": "Multi-Domain Multi-Task Rehearsal for Lifelong Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "22e06fa904f2022b63954a08543df4a2da63059e",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Fan Lyu",
      "Shuai Wang",
      "Wei Feng",
      "Zihan Ye",
      "Fuyuan Hu",
      "Song Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17069": {
    "title": "On the Adequacy of Untuned Warmup for Adaptive Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2a48d2b673689e4434fc6b86965ca2a91bb40103",
    "semantic_title": "",
    "citation_count": 34,
    "authors": [
      "Jerry Ma",
      "Denis Yarats"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17070": {
    "title": "Learning Representations for Incomplete Time Series Clustering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "437f3a2e01fd10a2ae8448969ae5a5b46b738d81",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Qianli Ma",
      "Chuxin Chen",
      "Sen Li",
      "Garrison W. Cottrell"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17071": {
    "title": "Joint-Label Learning by Dual Augmentation for Time Series Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1de2db9bacf1658219ee50ff173bd436ddd5a967",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Qianli Ma",
      "Zhenjing Zheng",
      "Jiawei Zheng",
      "Sen Li",
      "Wanqing Zhuang",
      "Garrison W. Cottrell"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17072": {
    "title": "Unsupervised Learning of Graph Hierarchical Abstractions with Differentiable Coarsening and Optimal Transport",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "40484fb2739a5169950a4b59e33f03297525b668",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Tengfei Ma",
      "Jie Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17073": {
    "title": "Sequential Attacks on Kalman Filter-based Forward Collision Warning Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "92c6ab0a11680f1cf8a4a2b5f2070c2b2486465d",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Yuzhe Ma",
      "Jon A Sharp",
      "Ruizhe Wang",
      "Earlence Fernandes",
      "Xiaojin Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17074": {
    "title": "Exact Reduction of Huge Action Spaces in General Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8769e44ab5d1c04435f895e9c97b4bcf752bb913",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Sultan J. Majeed",
      "Marcus Hutter"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17075": {
    "title": "Composite Adversarial Attacks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2afc07df53deb068d5daf538e84d447224e37a7d",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Xiaofeng Mao",
      "Yuefeng Chen",
      "Shuhui Wang",
      "Hang Su",
      "Yuan He",
      "Hui Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17076": {
    "title": "Deep Mutual Information Maximin for Cross-Modal Clustering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "795f78b67aa157df2614679b220fa976fb9dfce6",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Yiqiao Mao",
      "Xiaoqiang Yan",
      "Qiang Guo",
      "Yangdong Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17077": {
    "title": "Searching for Machine Learning Pipelines Using a Context-Free Grammar",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ded7f03f7952bc4d9bdcccef5ddf00664b4f2bda",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Radu Marinescu",
      "Akihiro Kishimoto",
      "Parikshit Ram",
      "Ambrish Rawat",
      "Martin Wistuba",
      "Paulito P. Palmes",
      "Adi Botea"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17078": {
    "title": "Scalable Graph Networks for Particle Simulations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "56f6708f22cbedcc1c600d78408bfbb46669d483",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Karolis Martinkus",
      "Aurelien Lucchi",
      "Nathana√´l Perraudin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17079": {
    "title": "Infinite Gaussian Mixture Modeling with an Improved Estimation of the Number of Clusters",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "096c0cc633e179cec92bd9abfcba459dbecd2c2b",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Avi Matza",
      "Yuval Bistritz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17080": {
    "title": "Exacerbating Algorithmic Bias through Fairness Attacks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f29bb1e3f5e98a6887c2414a2036858a076a5915",
    "semantic_title": "",
    "citation_count": 34,
    "authors": [
      "Ninareh Mehrabi",
      "Muhammad Naveed",
      "Fred Morstatter",
      "Aram Galstyan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17081": {
    "title": "Physarum Powered Differentiable Linear Programming Layers and Applications",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "02ae998667e48ccd0b110dfe86f7ec7c3187356d",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Zihang Meng",
      "Sathya N. Ravi",
      "Vikas Singh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17082": {
    "title": "Lenient Regret for Multi-Armed Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e13633617cd72d0b155a48b0abf7018ad93b3b7c",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Nadav Merlis",
      "Shie Mannor"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17083": {
    "title": "Policy Optimization as Online Learning with Mediator Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ac6b3d3d85d0cdfdff34c522ad8c3e1677d2f5a1",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Alberto Maria Metelli",
      "Matteo Papini",
      "Pierluca D'Oro",
      "Marcello Restelli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17084": {
    "title": "Consistency and Finite Sample Behavior of Binary Class Probability Estimation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "061751124f59decf1802a313141004f7baab6bdf",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Alexander Mey",
      "Marco Loog"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17085": {
    "title": "Discovering Fully Oriented Causal Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cfbefb5d92e1715db4a0e8db4c43fe421a4e6ac4",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Osman A Mian",
      "Alexander Marx",
      "Jilles Vreeken"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17086": {
    "title": "Generative Semi-supervised Learning for Multivariate Time Series Imputation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1fe4590e1807c61fc416612966010123036db3e7",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Xiaoye Miao",
      "Yangyang Wu",
      "Jun Wang",
      "Yunjun Gao",
      "Xudong Mao",
      "Jianwei Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17087": {
    "title": "A General Class of Transfer Learning Regression without Implementation Cost",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "31e417ba28c22220a6bc2eaf95a6911c4b1450d4",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Shunya Minami",
      "Song Liu",
      "Stephen Wu",
      "Kenji Fukumizu",
      "Ryo Yoshida"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17088": {
    "title": "Scheduling of Time-Varying Workloads Using Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dc9baba1d35cb7ff174c0f294166052cad415aac",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Shanka Subhra Mondal",
      "Nikhil Sheoran",
      "Subrata Mitra"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17089": {
    "title": "Improved Mutual Information Estimation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1bdc343c451a01286c31a5dc76d442742a055c12",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Youssef Mroueh",
      "Igor Melnyk",
      "Pierre Dognin",
      "Jarret Ross",
      "Tom Sercu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17090": {
    "title": "Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c117a59fdad8ebf857d01082612093e9e6aa676e",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Keerthiram Murugesan",
      "Mattia Atzeni",
      "Pavan Kapanipathi",
      "Pushkar Shukla",
      "Sadhana Kumaravel",
      "Gerald Tesauro",
      "Kartik Talamadupula",
      "Mrinmaya Sachan",
      "Murray Campbell"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17091": {
    "title": "Task-Agnostic Exploration via Policy Gradient of a Non-Parametric State Entropy Estimate",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7e1b6ff0525e61c75c636982b400a3a9576b10e0",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Mirco Mutti",
      "Lorenzo Pratissoli",
      "Marcello Restelli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17092": {
    "title": "Elastic Consistency: A Practical Consistency Model for Distributed Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b35560e24f4bbc0e0934cd7bc81bdd32add7cddb",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Giorgi Nadiradze",
      "Ilia Markov",
      "Bapi Chatterjee",
      "Vyacheslav Kungurtsev",
      "Dan Alistarh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17093": {
    "title": "Game of Gradients: Mitigating Irrelevant Clients in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0dfd85b4a7d544d147ddcb02bfb12ad13c69ea93",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Lokesh Nagalapatti",
      "Ramasuri Narayanam"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17094": {
    "title": "Objective-Based Hierarchical Clustering of Deep Embedding Vectors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e723eca7e014b67c28d74605a60cb7d7ae5955eb",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Stanislav Naumov",
      "Grigory Yaroslavtsev",
      "Dmitrii Avdiukhin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17095": {
    "title": "5* Knowledge Graph Embeddings with Projective Transformations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3edceae594b88563bcda0db2502b23b3d0d076b1",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Mojtaba Nayyeri",
      "Sahar Vahdati",
      "Can Aykul",
      "Jens Lehmann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17096": {
    "title": "Advice-Guided Reinforcement Learning in a non-Markovian Environment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4a5cbc5e734130c9aac28c6195f8c2b1ec305654",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Daniel Neider",
      "Jean-Raphael Gaglione",
      "Ivan Gavran",
      "Ufuk Topcu",
      "Bo Wu",
      "Zhe Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17097": {
    "title": "Clinical Risk Prediction with Temporal Probabilistic Asymmetric Multi-Task Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4e9dcfe17312d8a4a6092afc36b37348923de347",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "A. Tuan Nguyen",
      "Hyewon Jeong",
      "Eunho Yang",
      "Sung Ju Hwang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17098": {
    "title": "Modular Graph Transformer Networks for Multi-Label Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "69a1943e13863b3273d6d8b37fcf4ac066ae0866",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Hoang D. Nguyen",
      "Xuan-Son Vu",
      "Duc-Trong Le"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17099": {
    "title": "Differentially Private k-Means via Exponential Mechanism and Max Cover",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7f4ad49b255bbd468edf1749e8a9008565987e55",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Huy L. Nguyen",
      "Anamay Chaturvedi",
      "Eric Z Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17100": {
    "title": "Minimum Robust Multi-Submodular Cover for Fairness",
    "volume": "main",
    "abstract": "In this paper, we study a novel problem, Minimum Robust Multi-Submodular Cover for Fairness (MinRF), as follows: given a ground set V; m monotone submodular functions f_1,...,f_m; m thresholds T_1,...,T_m and a non-negative integer r; MinRF asks for the smallest set S such that f_i(S \\ X) ‚â• T_i for all i ‚àà [m] and |X| ‚â§ r. We prove that MinRF is inapproximable within (1- Œµ) ln m; and no algorithm, taking fewer than exponential number of queries in term of r, is able to output a feasible set to MinRF with high certainty. Three bicriteria approximation algorithms with performance guarantees are proposed: one for r = 0, one for r = 1, and one for general r. We further investigate our algorithms' performance in two applications of MinRF, Information Propagation for Multiple Groups and Movie Recommendation for Multiple Users. Our algorithms have shown to outperform baseline heuristics in both solution quality and the number of queries in most cases",
    "checked": true,
    "id": "6ec2c2700ad7f3065899ae98028f7b35a9607fe3",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Lan N. Nguyen",
      "My T. Thai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17101": {
    "title": "Temporal Latent Auto-Encoder: A Method for Probabilistic Multivariate Time Series Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "da90d057c5a4379ae3b27f3e9d2bb7b37288a654",
    "semantic_title": "",
    "citation_count": 23,
    "authors": [
      "Nam Nguyen",
      "Brian Quanz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17102": {
    "title": "An Information-Theoretic Framework for Unifying Active Learning Problems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c55349c6f4e93eb4ab4c1d2a3167a0c52f2bc3ba",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Quoc Phong Nguyen",
      "Bryan Kian Hsiang Low",
      "Patrick Jaillet"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17103": {
    "title": "Top-k Ranking Bayesian Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b94836849283be9ef77fc818e6098bb720b7ad69",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Quoc Phong Nguyen",
      "Sebastian Tay",
      "Bryan Kian Hsiang Low",
      "Patrick Jaillet"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17104": {
    "title": "Distributional Reinforcement Learning via Moment Matching",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "572c890478b96e3be80bf1b72013ecf06ccf486b",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Thanh Nguyen-Tang",
      "Sunil Gupta",
      "Svetha Venkatesh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17105": {
    "title": "Precision-based Boosting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e1570dc30fb2d0f42f522a25c8307beb9e1c299a",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Mohammad Hossein Nikravan",
      "Marjan Movahedan",
      "Sandra Zilles"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17106": {
    "title": "Improving Model Robustness by Adaptively Correcting Perturbation Levels with Active Queries",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "683e27268a9551d1ec1b20070a3a1d4a2ea4a72e",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Kun-Peng Ning",
      "Lue Tao",
      "Songcan Chen",
      "Sheng-Jun Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17107": {
    "title": "Learning of Structurally Unambiguous Probabilistic Grammars",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5f32c39de3f36834994d1eab701c791f04b8aabf",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Dolav Nitay",
      "Dana Fisman",
      "Michal Ziv-Ukelson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17108": {
    "title": "RT3D: Achieving Real-Time Execution of 3D Convolutional Neural Networks on Mobile Devices",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2ea24183f37578404d455dccc816a7088b0d0f99",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Wei Niu",
      "Mengshu Sun",
      "Zhengang Li",
      "Jou-An Chen",
      "Jiexiong Guan",
      "Xipeng Shen",
      "Yanzhi Wang",
      "Sijia Liu",
      "Xue Lin",
      "Bin Ren"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17109": {
    "title": "Warm Starting CMA-ES for Hyperparameter Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "73d75652588d1f58349d0cd03d0c40e59cd92cf0",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Masahiro Nomura",
      "Shuhei Watanabe",
      "Youhei Akimoto",
      "Yoshihiko Ozaki",
      "Masaki Onishi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17110": {
    "title": "Inverse Reinforcement Learning From Like-Minded Teachers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0da646add1af224d36eb16a63687317db97ec982",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Ritesh Noothigattu",
      "Tom Yan",
      "Ariel D. Procaccia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17111": {
    "title": "Multinomial Logit Contextual Bandits: Provable Optimality and Practicality",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ce3f88059a43aaa1badbec553970debc9b24e985",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Min-hwan Oh",
      "Garud Iyengar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17112": {
    "title": "Learning Deep Generative Models for Queuing Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "de849838b3b97f3e7bcc41726238dc12507688f3",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Cesar Ojeda",
      "Kostadin Cvejoski",
      "Bodgan Georgiev",
      "Christian Bauckhage",
      "Jannis Schuecker",
      "Ramses J. Sanchez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17113": {
    "title": "OT-Flow: Fast and Accurate Continuous Normalizing Flows via Optimal Transport",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1528a5a17af90fee30ca24ee8c77498d7dcacc83",
    "semantic_title": "",
    "citation_count": 73,
    "authors": [
      "Derek Onken",
      "Samy Wu Fung",
      "Xingjian Li",
      "Lars Ruthotto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17114": {
    "title": "FC-GAGA: Fully Connected Gated Graph Architecture for Spatio-Temporal Traffic Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2e2439c70d811cbbb64aa8ea7bb6442efef67d55",
    "semantic_title": "",
    "citation_count": 33,
    "authors": [
      "Boris  N. Oreshkin",
      "Arezou Amini",
      "Lucy Coyle",
      "Mark Coates"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17115": {
    "title": "Meta-Learning Framework with Applications to Zero-Shot Time-Series Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2e6a8914745319cae682b807a6b4ae470b08c54a",
    "semantic_title": "",
    "citation_count": 37,
    "authors": [
      "Boris  N. Oreshkin",
      "Dmitri Carpov",
      "Nicolas Chapados",
      "Yoshua Bengio"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17116": {
    "title": "Augmented Experiment in Material Engineering Using Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7e11d26bb62115c2ef6513f784c62c2585d31f63",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Aomar Osmani",
      "Massinissa Hamidi",
      "Salah Bouhouche"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17117": {
    "title": "Second Order Techniques for Learning Time-series with Structural Breaks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c9691c1c6801ea60b4b7e6b82c59b11770518f74",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Takayuki Osogami"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17118": {
    "title": "Defending against Backdoors in Federated Learning with Robust Learning Rate",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3c0bce697a7a91c32966b8255df5780eac0e1238",
    "semantic_title": "",
    "citation_count": 33,
    "authors": [
      "Mustafa Safa Ozdayi",
      "Murat Kantarcioglu",
      "Yulia R. Gel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17119": {
    "title": "Robustness Guarantees for Mode Estimation with an Application to Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "df0d4e6036dd0679ae238c6352eeb7f77aab9076",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aldo Pacchiano",
      "Heinrich Jiang",
      "Michael I. Jordan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17120": {
    "title": "Disentangled Information Bottleneck",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "925792be475b1297e75b9193a78b6c063a790799",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Ziqi Pan",
      "Li Niu",
      "Jianfu Zhang",
      "Liqing Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17121": {
    "title": "NASTransfer: Analyzing Architecture Transferability in Large Scale Neural Architecture Search",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c0152b279dca4bd11811e6edcfe110670dac6667",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Rameswar Panda",
      "Michele Merler",
      "Mayoore S Jaiswal",
      "Hui Wu",
      "Kandan Ramakrishnan",
      "Ulrich Finkler",
      "Chun-Fu Richard Chen",
      "Minsik Cho",
      "Rogerio Feris",
      "David Kung",
      "Bishwaranjan Bhattacharjee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17122": {
    "title": "Robust Reinforcement Learning: A Case Study in Linear Quadratic Regulation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "79da145c480aca3aedca05b4daf44ebf1789ca90",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Bo Pang",
      "Zhong-Ping Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17123": {
    "title": "Tempered Sigmoid Activations for Deep Learning with Differential Privacy",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7290945147946bc5ac06ec010e07d027e306d6aa",
    "semantic_title": "",
    "citation_count": 87,
    "authors": [
      "Nicolas Papernot",
      "Abhradeep Thakurta",
      "Shuang Song",
      "Steve Chien",
      "√ölfar Erlingsson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17124": {
    "title": "Vector Quantized Bayesian Neural Network Inference for Data Streams",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6bb14b13338c1d06f5035c8ae4cf3f9f70a457a0",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Namuk Park",
      "Taekyu Lee",
      "Songkuk Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17125": {
    "title": "Maximum Roaming Multi-Task Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3cecf284fa2cbfbb12dd7f45187e6a47a7496fad",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Lucas Pascal",
      "Pietro Michiardi",
      "Xavier Bost",
      "Benoit Huet",
      "Maria A. Zuluaga"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17126": {
    "title": "Fast PCA in 1-D Wasserstein Spaces via B-splines Representation and Metric Projection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "44e04dd0dee8284a14a8d037837125defdc76f4e",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Matteo Pegoraro",
      "Mario Beraha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17127": {
    "title": "AutoDropout: Learning Dropout Patterns to Regularize Deep Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ef8854a62e05c8e741894166689a9cd8352a1df0",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Hieu Pham",
      "Quoc Le"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17128": {
    "title": "Fast Multi-view Discrete Clustering with Anchor Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0942a3f881415ae6325403dc9f27206acd6d2354",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Qianyao Qiang",
      "Bin Zhang",
      "Fei Wang",
      "Feiping Nie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17129": {
    "title": "Relation-aware Graph Attention Model with Adaptive Self-adversarial Training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d81869fc4c0d1a0da90262cc6ed146e592aba7e",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Xiao Qin",
      "Nasrullah Sheikh",
      "Berthold Reinwald",
      "Lingfei Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17130": {
    "title": "Uncertainty-Aware Policy Optimization: A Robust, Adaptive Trust Region Approach",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b29ef3794829d56ce139a8d02aa88c307d045ed3",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "James Queeney",
      "Ioannis Ch. Paschalidis",
      "Christos G. Cassandras"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17131": {
    "title": "Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5bd07b7b023b68d8f6d50716afbced6fc35369f9",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Edward Raff",
      "William Fleshman",
      "Richard Zak",
      "Hyrum S. Anderson",
      "Bobby Filar",
      "Mark McLean"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17132": {
    "title": "Online DR-Submodular Maximization: Minimizing Regret and Constraint Violation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "030686e9926e2947ae9ce7906e6b25c9d6998d11",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Prasanna Raut",
      "Omid Sadeghi",
      "Maryam Fazel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17133": {
    "title": "Improving Generative Moment Matching Networks with Distribution Partition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ed6fc9a2c9c5ed669a846fca86a0538ae93205d4",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Yong Ren",
      "Yucen Luo",
      "Jun Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17134": {
    "title": "Multiple Kernel Clustering with Kernel k-Means Coupled Graph Tensor Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d22f1ac208adbc0463c5ea0ef2210e7f4f392bc9",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Zhenwen Ren",
      "Quansen Sun",
      "Dong Wei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17135": {
    "title": "Robust Fairness Under Covariate Shift",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4f160697d01b4afe12366c165f1326dd90c05bc1",
    "semantic_title": "",
    "citation_count": 42,
    "authors": [
      "Ashkan Rezaei",
      "Anqi Liu",
      "Omid Memarrast",
      "Brian D. Ziebart"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17136": {
    "title": "Shuffling Recurrent Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1e31c3e42b4d0ba9ed1a13c0d8df962b72b0df7c",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Michael Rotman",
      "Lior Wolf"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17137": {
    "title": "Why Adversarial Interaction Creates Non-Homogeneous Patterns: A Pseudo-Reaction-Diffusion Model for Turing Instability",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "58448e841fbbd48f0a430f32aa27163cbf35a0c3",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Litu Rout"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17138": {
    "title": "Adversarial Permutation Guided Node Representations for Link Prediction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7ba03ffe68cbdb0e43c3c1f2c0bd3f2adb7e33fd",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Indradyumna Roy",
      "Abir De",
      "Soumen Chakrabarti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17139": {
    "title": "Visual Transfer For Reinforcement Learning Via Wasserstein Domain Confusion",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ca96857a584bab75c5bf8225357a6197fb5892b3",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Josh Roy",
      "George D. Konidaris"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17140": {
    "title": "Anytime Inference with Distilled Hierarchical Neural Ensembles",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2a8e72636abda540afdfe1925ba6cfdc612b920a",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Adria Ruiz",
      "Jakob Verbeek"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17141": {
    "title": "Inverse Reinforcement Learning with Explicit Policy Estimates",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9fa8b2b70160791e0d3bad62788fbbdf32068995",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Navyata Sanghvi",
      "Shinnosuke Usami",
      "Mohit Sharma",
      "Joachim Groeger",
      "Kris Kitani"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17142": {
    "title": "A Deeper Look at the Hessian Eigenspectrum of Deep Neural Networks and its Applications to Regularization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0aa575ebb8cfe9a2b1e71f0d4219fde7b9907132",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Adepu Ravi Sankar",
      "Yash Khasbage",
      "Rahul  Vigneswaran",
      "Vineeth N Balasubramanian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17143": {
    "title": "AdvantageNAS: Efficient Neural Architecture Search with Credit Assignment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "32c5a0f2f7788fd20970affc260139beb208e86f",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Rei Sato",
      "Jun Sakuma",
      "Youhei Akimoto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17144": {
    "title": "Active Feature Selection for the Mutual Information Criterion",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dfa6e7e6e77528085a683bed033fa73b5c767173",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Shachar Schnapp",
      "Sivan Sabato"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17145": {
    "title": "Learning Precise Temporal Point Event Detection with Misaligned Labels",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2cecfcd9aadf69ae7263a57da12079c602c62748",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julien Schroeter",
      "Kirill Sidorov",
      "David Marshall"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17146": {
    "title": "Multi-type Disentanglement without Adversarial Training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a75364b0de5bb4da4d54d58d14699e724c422caa",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Lei Sha",
      "Thomas Lukasiewicz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17147": {
    "title": "Uncertainty-Matching Graph Neural Networks to Defend Against Poisoning Attacks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "400389ca8b23ff77fa9ee96717fe6447df7469af",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Uday Shankar Shanthamallu",
      "Jayaraman J. Thiagarajan",
      "Andreas Spanias"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17148": {
    "title": "Right for Better Reasons: Training Differentiable Models by Constraining their Influence Functions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "43d13cd464f4a49b3b4d3669dedcfb3261aa7aed",
    "semantic_title": "",
    "citation_count": 24,
    "authors": [
      "Xiaoting Shao",
      "Arseny Skryagin",
      "Wolfgang Stammer",
      "Patrick Schramowski",
      "Kristian Kersting"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17149": {
    "title": "Meta-Learning Effective Exploration Strategies for Contextual Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f3800bae40691c553893c688465ea4ac45c59ccb",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Amr Sharaf",
      "Hal Daum√© III"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17150": {
    "title": "Membership Privacy for Machine Learning Models Through Knowledge Transfer",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7750e0f88603992999b8079fb624b83a0f508741",
    "semantic_title": "",
    "citation_count": 37,
    "authors": [
      "Virat Shejwalkar",
      "Amir Houmansadr"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17151": {
    "title": "Theoretically Principled Deep RL Acceleration via Nearest Neighbor Function Approximation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "073a3856c867de94aeeb49732d0ee8dfc3149306",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Junhong Shen",
      "Lin F. Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17152": {
    "title": "Time Series Anomaly Detection with Multiresolution Ensemble Decoding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9862891fcfebd3f4ec25e15e26717daada4bd805",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Lifeng Shen",
      "Zhongzhong Yu",
      "Qianli Ma",
      "James T. Kwok"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17153": {
    "title": "STL-SGD: Speeding Up Local SGD with Stagewise Communication Period",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8ac8bc1db6dfb793b0905e966bd8e2fc1fa59650",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Shuheng Shen",
      "Yifei Cheng",
      "Jingchang Liu",
      "Linli Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17154": {
    "title": "PDO-eS2CNNs: Partial Differential Operator Based Equivariant Spherical CNNs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1226aabf0df82894c54a427ea5da5d176e90c80f",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Zhengyang Shen",
      "Tiancheng Shen",
      "Zhouchen Lin",
      "Jinwen Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17155": {
    "title": "Partial Is Better Than All: Revisiting Fine-tuning Strategy for Few-shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7bb3a96078c854f03d6e9c2032ad6efe6873d974",
    "semantic_title": "",
    "citation_count": 43,
    "authors": [
      "Zhiqiang Shen",
      "Zechun Liu",
      "Jie Qin",
      "Marios Savvides",
      "Kwang-Ting Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17156": {
    "title": "Federated Multi-Armed Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "19531ac63010c70607e2ea7d6c2f2d282d7a0eb8",
    "semantic_title": "",
    "citation_count": 39,
    "authors": [
      "Chengshuai Shi",
      "Cong Shen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17157": {
    "title": "Raven's Progressive Matrices Completion with Latent Gaussian Process Priors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d826b6e3b8efe68ff5ca9d493fa209127b52d8ac",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Fan Shi",
      "Bin Li",
      "Xiangyang Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17158": {
    "title": "Improved Penalty Method via Doubly Stochastic Gradients for Bilevel Hyperparameter Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "72819e56b779ecdeae811f36e60b446b04d32394",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Wanli Shi",
      "Bin Gu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17159": {
    "title": "Online Class-Incremental Continual Learning with Adversarial Shapley Value",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0a0b75fc5a75b2d37c5c90923400a5463d8e9dfd",
    "semantic_title": "",
    "citation_count": 71,
    "authors": [
      "Dongsub Shim",
      "Zheda Mai",
      "Jihwan Jeong",
      "Scott Sanner",
      "Hyunwoo Kim",
      "Jongseong Jang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17160": {
    "title": "Scalable Affinity Propagation for Massive Datasets",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "96b8fa41d2ed94176d8466c860c41febba93a9d2",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Hiroaki Shiokawa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17161": {
    "title": "Interpretable Sequence Classification via Discrete Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dbcb1a868328b1c2d60627b8e3ebf52932972d2b",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Maayan Shvo",
      "Andrew C. Li",
      "Rodrigo Toro Icarte",
      "Sheila A. McIlraith"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17162": {
    "title": "Towards Domain Invariant Single Image Dehazing",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d3faa88ddedd47d5d2acb05a706dc5c6f5d14743",
    "semantic_title": "",
    "citation_count": 31,
    "authors": [
      "Pranjay Shyam",
      "Kuk-Jin Yoon",
      "Kyung-Soo Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17163": {
    "title": "DIBS: Diversity Inducing Information Bottleneck in Model Ensembles",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "99fbd94538d9568a04196e055d286ffae32cf58f",
    "semantic_title": "",
    "citation_count": 24,
    "authors": [
      "Samarth Sinha",
      "Homanga Bharadhwaj",
      "Anirudh Goyal",
      "Hugo Larochelle",
      "Animesh Garg",
      "Florian Shkurti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17164": {
    "title": "Differential Spectral Normalization (DSN) for PDE Discovery",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ead459eb90207bffa704fc861adada2bca23a6dd",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Chi Chiu So",
      "Tsz On Li",
      "Chufang Wu",
      "Siu Pang Yung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17165": {
    "title": "UNIPoint: Universally Approximating Point Processes Intensities",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2e22b7920526000aeb8f1b2ad187f9ac17dfa099",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Alexander Soen",
      "Alexander Mathews",
      "Daniel Grixti-Cheng",
      "Lexing Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17166": {
    "title": "Solving Common-Payoff Games with Approximate Policy Iteration",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cdcd7ba7438f3f4510ddebcca6b6307953c6fe68",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Samuel Sokota",
      "Edward Lockhart",
      "Finbarr Timbers",
      "Elnaz Davoodi",
      "Ryan D'Orazio",
      "Neil Burch",
      "Martin Schmid",
      "Michael Bowling",
      "Marc Lanctot"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17167": {
    "title": "Improving Gradient Flow with Unrolled Highway Expectation Maximization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "39a3bc57da3e8507ee0d60f074ae135aa2f649a3",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chonghyuk Song",
      "Eunseok Kim",
      "Inwook Shim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17168": {
    "title": "Implicit Kernel Attention",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a32ed7f632e087c92ecd8f7a1080cba23aa6ea99",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Kyungwoo Song",
      "Yohan Jung",
      "Dongjun Kim",
      "Il-Chul Moon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17169": {
    "title": "Error-Correcting Output Codes with Ensemble Diversity for Robust Learning in Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6eb8bf42193296d57ae04cb01383844927909211",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Yang Song",
      "Qiyu Kang",
      "Wee Peng Tay"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17170": {
    "title": "Hierarchical Relational Inference",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "52e4325fca11a95ea8385274a0720329af460d65",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Aleksandar Staniƒá",
      "Sjoerd van Steenkiste",
      "J√ºrgen Schmidhuber"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17171": {
    "title": "`Less Than One'-Shot Learning: Learning N Classes From M < N Samples",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e3ceaf1fbb353493be6b203d76bc00c9fd92fb37",
    "semantic_title": "",
    "citation_count": 31,
    "authors": [
      "Ilia Sucholutsky",
      "Matthias Schonlau"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17172": {
    "title": "HiABP: Hierarchical Initialized ABP for Unsupervised Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "07fd98342daef3d0ee13357962890beabececb46",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiankai Sun",
      "Rui Liu",
      "Bolei Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17173": {
    "title": "Stability and Generalization of Decentralized Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "02bde59697f537813276dc86ee9d963c3bdd2452",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Tao Sun",
      "Dongsheng Li",
      "Bao Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17174": {
    "title": "TempLe: Learning Template of Transitions for Sample Efficient Multi-task RL",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "00133d41d5ecef1a9d046d2b92bb2a23a335cb7c",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Yanchao Sun",
      "Xiangyu Yin",
      "Furong Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17175": {
    "title": "PAC Learning of Causal Trees with Latent Variables",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6e2047ee30fb09cf62775ef9e476415904936c99",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Prasad Tadepalli",
      "Stuart J. Russell"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17176": {
    "title": "Learning Dynamics Models with Stable Invariant Sets",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3e917b66419016b75c624abc426d2a537598fae4",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Naoya Takeishi",
      "Yoshinobu Kawahara"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17177": {
    "title": "Near-Optimal Regret Bounds for Contextual Combinatorial Semi-Bandits with Linear Payoff Functions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2b7f6ace2f62bbe4ce5452e6c56db4f13379d38d",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Kei Takemura",
      "Shinji Ito",
      "Daisuke Hatano",
      "Hanna Sumita",
      "Takuro Fukunaga",
      "Naonori Kakimura",
      "Ken-ichi Kawarabayashi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17178": {
    "title": "Explicitly Modeled Attention Maps for Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "59eccbe007ccf92172499db8420c12ea0933e24b",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Andong Tan",
      "Duc Tam Nguyen",
      "Maximilian Dax",
      "Matthias Nie√üner",
      "Thomas Brox"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17179": {
    "title": "Proxy Graph Matching with Proximal Matching Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ed64d4c2b158c791c4a1639766c31f87746345e5",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Hao-Ru Tan",
      "Chuang Wang",
      "Si-Tong Wu",
      "Tie-Qiang Wang",
      "Xu-Yao Zhang",
      "Cheng-Lin Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17180": {
    "title": "Strategy and Benchmark for Converting Deep Q-Networks to Event-Driven Spiking Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6a106a837c87c73d1fac65b095a27e13d17b4476",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Weihao Tan",
      "Devdhar Patel",
      "Robert Kozma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17181": {
    "title": "Empowering Adaptive Early-Exit Inference with Latency Awareness",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a0b4a132169ad8d5983db9914ae9895f0b8efa28",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Xinrui Tan",
      "Hongjia Li",
      "Liming Wang",
      "Xueqing Huang",
      "Zhen Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17182": {
    "title": "Foresee then Evaluate: Decomposing Value Estimation with Latent Future Prediction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8830afc72b0d7cf65fdd08dcc0033d2d25d4c832",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Hongyao Tang",
      "Zhaopeng Meng",
      "Guangyong Chen",
      "Pengfei Chen",
      "Chen Chen",
      "Yaodong Yang",
      "Luo Zhang",
      "Wulong Liu",
      "Jianye Hao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17183": {
    "title": "Gradient Descent Averaging and Primal-dual Averaging for Strongly Convex Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "09fac8aae6e8a1238dfdd72f4a8b8947f719b520",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Wei Tao",
      "Wei Li",
      "Zhisong Pan",
      "Qing Tao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17184": {
    "title": "Evolutionary Approach for AutoAugment Using the Thermodynamical Genetic Algorithm",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dec3eb5cf7b4b9913e0075dad47cd8696183d04d",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Akira Terauchi",
      "Naoki Mori"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17185": {
    "title": "Semi-Supervised Knowledge Amalgamation for Sequence Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0dd0bc246775e667da10a38867dfa4d975c055aa",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Jidapa Thadajarassiri",
      "Thomas Hartvigsen",
      "Xiangnan Kong",
      "Elke A Rundensteiner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17186": {
    "title": "Online Non-Monotone DR-Submodular Maximization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "65cb0863d4690f4f716e8b96af989997394554e9",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Nguy·ªÖn Kim Th·∫Øng",
      "Abhinav Srivastav"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17187": {
    "title": "Detecting Adversarial Examples from Sensitivity Inconsistency of Spatial-Transform Domain",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a77dd2f328c39fe39be95f5185c555ff68efe5fe",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Jinyu Tian",
      "Jiantao Zhou",
      "Yuanman Li",
      "Jia Duan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17188": {
    "title": "Towards Trustworthy Predictions from Deep Neural Networks with Fast Adversarial Calibration",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d3b1cfec88ff61e495a5aeec3e8126651c2472cb",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Christian Tomani",
      "Florian Buettner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17189": {
    "title": "Meta Learning for Causal Direction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "738cde0911f9155ee7940fe1a8062311799dde7d",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Jean-Fran√ßois Ton",
      "Dino Sejdinovic",
      "Kenji Fukumizu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17190": {
    "title": "Learning Compositional Sparse Gaussian Processes with a Shrinkage Prior",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4522d04e6dff6e05e83e4c595dffd8176711da4d",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anh Tong",
      "Toan M Tran",
      "Hung Bui",
      "Jaesik Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17191": {
    "title": "Characterizing Deep Gaussian Processes via Nonlinear Recurrence Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8724ccf443b1690778e10c03ef3e8bf1961fa3e8",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Anh Tong",
      "Jaesik Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17192": {
    "title": "Iterative Bounding MDPs: Learning Interpretable Policies via Non-Interpretable Methods",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fff58c6686a95bbe6fda8ad9ea0cbb4ab017ac78",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Nicholay Topin",
      "Stephanie Milani",
      "Fei Fang",
      "Manuela Veloso"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17193": {
    "title": "Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "824fc6d70a1f88063fde107432116ca15889d99e",
    "semantic_title": "",
    "citation_count": 38,
    "authors": [
      "Cuong Tran",
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17194": {
    "title": "Learning Adjustment Sets from Observational and Limited Experimental Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2b60d9738666bca5baa91284014459db7950cab5",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Sofia Triantafillou",
      "Greg Cooper"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17195": {
    "title": "*-CFQ: Analyzing the Scalability of Machine Learning on a Compositional Task",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d3edc20ed4a07195f3663abc0ead4220266fd75b",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Dmitry Tsarkov",
      "Tibor Tihon",
      "Nathan Scales",
      "Nikola Momchev",
      "Danila Sinopalnikov",
      "Nathanael Sch√§rli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17196": {
    "title": "Toward Robust Long Range Policy Transfer",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "335f33b9fbbfd0a7da6eb36af4942829d1104ffb",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Wei-Cheng Tseng",
      "Jin-Siang Lin",
      "Yao-Min Feng",
      "Min Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17197": {
    "title": "Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "af7698add52507d441541fcd4da998b7e84a7b52",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Russell Tsuchida",
      "Tim Pearce",
      "Chris van der Heide",
      "Fred Roosta",
      "Marcus Gallagher"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17198": {
    "title": "Deep Fusion Clustering Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "21a5c402b9ca4374b20c737f4b0cce3fe38472e0",
    "semantic_title": "",
    "citation_count": 44,
    "authors": [
      "Wenxuan Tu",
      "Sihang Zhou",
      "Xinwang Liu",
      "Xifeng Guo",
      "Zhiping Cai",
      "En Zhu",
      "Jieren Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17199": {
    "title": "ESCAPED: Efficient Secure and Private Dot Product Framework for Kernel-based Machine Learning Algorithms with Applications in Healthcare",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8cddbe7e863a387ade384c0bb5b9e8f5d9f29326",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Ali Burak √únal",
      "Mete Akg√ºn",
      "Nico Pfeifer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17200": {
    "title": "Expected Eligibility Traces",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "51b3c8ca6cacce955a431b8d780143aa0b59ecb5",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Hado van Hasselt",
      "Sephora Madjiheurem",
      "Matteo Hessel",
      "David Silver",
      "Andr√© Barreto",
      "Diana Borsa"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17201": {
    "title": "Continual General Chunking Problem and SyncMap",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "733714daeba69d89e34f80569cb79cbf329e7340",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Danilo Vasconcellos Vargas",
      "Toshitake Asabuki"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17202": {
    "title": "Gated Linear Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "28ea0a93390300c662795b3d1bd4d0aea85c2779",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Joel Veness",
      "Tor Lattimore",
      "David Budden",
      "Avishkar Bhoopchand",
      "Christopher Mattern",
      "Agnieszka Grabska-Barwinska",
      "Eren Sezener",
      "Jianan Wang",
      "Peter Toth",
      "Simon Schmitt",
      "Marcus Hutter"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17203": {
    "title": "GraphMix: Improved Training of GNNs for Semi-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "21e280d67da995dd682f888aa20be11b96afd2e7",
    "semantic_title": "",
    "citation_count": 52,
    "authors": [
      "Vikas Verma",
      "Meng Qu",
      "Kenji Kawaguchi",
      "Alex Lamb",
      "Yoshua Bengio",
      "Juho Kannala",
      "Jian Tang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17204": {
    "title": "PID-Based Approach to Adversarial Attacks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "06659aaedb5d294f7281b2a28dcb517de360c73a",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Chen Wan",
      "Biaohua Ye",
      "Fangjun  Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17205": {
    "title": "Nearest Neighbor Classifier Embedded Network for Active Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "108231372947678333059f7a493edbce7097bcab",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Fang Wan",
      "Tianning Yuan",
      "Mengying Fu",
      "Xiangyang Ji",
      "Qingming Huang",
      "Qixiang Ye"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17206": {
    "title": "Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b09d52bcbea21b3428f8eb4de16c1461d937842f",
    "semantic_title": "",
    "citation_count": 63,
    "authors": [
      "Sheng Wan",
      "Shirui Pan",
      "Jian Yang",
      "Chen Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17207": {
    "title": "Approximate Multiplication of Sparse Matrices with Limited Space",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ba9c1a0b1d1eed095e2614cfe831510ff26eb919",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Yuanyu Wan",
      "Lijun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17208": {
    "title": "Projection-free Online Learning in Dynamic Environments",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "17f97d67a1f35b9aea888c22d9deb23f658799ea",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Yuanyu Wan",
      "Bo Xue",
      "Lijun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17209": {
    "title": "Projection-free Online Learning over Strongly Convex Sets",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "279da76413430f1c777dde6dd7375b0e2ab14caa",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Yuanyu Wan",
      "Lijun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17210": {
    "title": "Multi-View Information-Bottleneck Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f7c86725504c7864dd9caef2ae1946b7e49a1e5b",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Zhibin Wan",
      "Changqing Zhang",
      "Pengfei Zhu",
      "Qinghua Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17211": {
    "title": "Semi-Supervised Node Classification on Graphs: Markov Random Fields vs. Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "48299646b03df5ed39a3e83a5bbd5c103b2591c4",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Binghui Wang",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17212": {
    "title": "Quantum Exploration Algorithms for Multi-Armed Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "51de5bf0b4c55380d8c86bdefd861e444629ee33",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Daochen Wang",
      "Xuchen You",
      "Tongyang Li",
      "Andrew M. Childs"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17213": {
    "title": "Learning from Noisy Labels with Complementary Loss Functions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4298e66ceb6f13bdd95de164a08a4b88a704cee6",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Deng-Bao Wang",
      "Yong Wen",
      "Lujia Pan",
      "Min-Ling Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17214": {
    "title": "Debiasing Evaluations That Are Biased by Evaluations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7488429131b8970425a66f3410920d98ff6e9c36",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Jingyan Wang",
      "Ivan Stelmakh",
      "Yuting Wei",
      "Nihar B. Shah"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17215": {
    "title": "Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7270be2fab5fcdb59c325c0fbc8370351956aa22",
    "semantic_title": "",
    "citation_count": 40,
    "authors": [
      "Jinpeng Wang",
      "Yuting Gao",
      "Ke Li",
      "Jianguo Hu",
      "Xinyang Jiang",
      "Xiaowei Guo",
      "Rongrong Ji",
      "Xing Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17216": {
    "title": "Consistency Regularization with High-dimensional Non-adversarial Source-guided Perturbation for Unsupervised Domain Adaptation in Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2f52bb6d47360e531692dfa3ed8c46e8f7d6cc37",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Kaihong Wang",
      "Chenhongyi Yang",
      "Margrit Betke"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17217": {
    "title": "Embedding Heterogeneous Networks into Hyperbolic Space Without Meta-path",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "45ecb2782d80e53dfdc20b6b727b4a968ace29be",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Lili Wang",
      "Chongyang Gao",
      "Chenghan Huang",
      "Ruibo Liu",
      "Weicheng Ma",
      "Soroush Vosoughi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17218": {
    "title": "Adversarial Linear Contextual Bandits with Graph-Structured Side Observations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2ffbf836e0392fd3d4b6e4842b6d727f187e79bf",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Lingda Wang",
      "Bingcong Li",
      "Huozhi Zhou",
      "Georgios B. Giannakis",
      "Lav R. Varshney",
      "Zhizhen Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17219": {
    "title": "Addressing Class Imbalance in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2f970d898fead11c2504ba8f19e2ac919510a56b",
    "semantic_title": "",
    "citation_count": 72,
    "authors": [
      "Lixu Wang",
      "Shichao Xu",
      "Xiao Wang",
      "Qi Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17220": {
    "title": "Contrastive Transformation for Self-supervised Correspondence Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "367b424aed91745cf79c1d29670b16a64a31967a",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Ning Wang",
      "Wengang Zhou",
      "Houqiang Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17221": {
    "title": "Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fde5afcab0731d751bb1ecca773b9bca7914db53",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Qizhou Wang",
      "Bo Han",
      "Tongliang Liu",
      "Gang Niu",
      "Jian Yang",
      "Chen Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17222": {
    "title": "Learning with Group Noise",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ccbcacc4fcde0eebcf27a774a874db7d1b391319",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Qizhou Wang",
      "Jiangchao Yao",
      "Chen Gong",
      "Tongliang Liu",
      "Mingming Gong",
      "Hongxia Yang",
      "Bo Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17223": {
    "title": "Adaptive Verifiable Training Using Pairwise Class Similarity",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f77eded7672b3c18a4126ae72483eeb7505624ac",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Shiqi Wang",
      "Kevin Eykholt",
      "Taesung Lee",
      "Jiyong Jang",
      "Ian Molloy"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17224": {
    "title": "Adaptive Algorithms for Multi-armed Bandit with Composite and Anonymous Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "18d873fb28e3e454bbd9e536fde78058bbfdaf7e",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Siwei Wang",
      "Haoyun Wang",
      "Longbo Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17225": {
    "title": "Harmonized Dense Knowledge Distillation Training for Multi-Exit Architectures",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "38fc2a215f1ba02e6f80ea1b3102c2011180d96e",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Xinglu Wang",
      "Yingming Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17226": {
    "title": "Tied Block Convolution: Leaner and Better CNNs with Shared Thinner Filters",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8de987b2baafd4a873351528787c60fb9af77e97",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Xudong Wang",
      "Stella X. Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17227": {
    "title": "Deep Recurrent Belief Propagation Network for POMDPs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "482ec6471fd65cde1e11c40ed2442f51e6e42b0a",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Yuhui Wang",
      "Xiaoyang Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17228": {
    "title": "Data-Free Knowledge Distillation with Soft Targeted Transfer Set Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3827fb3155c316a01b0e42877177dcf3fcf8df05",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Zi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17229": {
    "title": "Incremental Embedding Learning via Zero-Shot Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "773aab0cf44aab244b989963da30db914437b97a",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Kun Wei",
      "Cheng Deng",
      "Xu Yang",
      "Maosen Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17230": {
    "title": "Gene Regulatory Network Inference as Relaxed Graph Matching",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "085ddeb9b1fe0747d111461823e6344dffe582da",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Deborah Weighill",
      "Marouen Ben Guebila",
      "Camila Lopes-Ramos",
      "Kimberly Glass",
      "John Quackenbush",
      "John Platig",
      "Rebekka Burkholz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17231": {
    "title": "Unified Tensor Framework for Incomplete Multi-view Clustering and Missing-view Inferring",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4e40105fc2b8dba251ed8c6239436e6dd12c3f78",
    "semantic_title": "",
    "citation_count": 30,
    "authors": [
      "Jie Wen",
      "Zheng Zhang",
      "Zhao Zhang",
      "Lei Zhu",
      "Lunke Fei",
      "Bob Zhang",
      "Yong Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17232": {
    "title": "Learning Set Functions that are Sparse in Non-Orthogonal Fourier Bases",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2568a27d17413e84b777cffa1e0a0f21de7f1b12",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Chris Wendler",
      "Andisheh Amrollahi",
      "Bastian Seifert",
      "Andreas Krause",
      "Markus P√ºschel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17233": {
    "title": "BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "013a741927569ae9b40875a9e58d2c5ba6dbb3a8",
    "semantic_title": "",
    "citation_count": 166,
    "authors": [
      "Colin White",
      "Willie Neiswanger",
      "Yash Savani"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17234": {
    "title": "Peer Collaborative Learning for Online Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a7058717ce5d37094fed32147d3b98d0edc0df16",
    "semantic_title": "",
    "citation_count": 52,
    "authors": [
      "Guile Wu",
      "Shaogang Gong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17235": {
    "title": "Self-Supervised Attention-Aware Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "38537de90fda155cd10794c42dd6e14602b2fa77",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Haiping Wu",
      "Khimya Khetarpal",
      "Doina Precup"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17236": {
    "title": "Training Spiking Neural Networks with Accumulated Spiking Flow",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4caeb73d69f0090776eda00b89aafde99dc4c48d",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Hao Wu",
      "Yueyi Zhang",
      "Wenming Weng",
      "Yongting Zhang",
      "Zhiwei Xiong",
      "Zheng-Jun Zha",
      "Xiaoyan Sun",
      "Feng Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17237": {
    "title": "Fast and Scalable Adversarial Training of Kernel SVM via Doubly Stochastic Gradients",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eebc33c1a194f9f094a6073da896309ad922e9c7",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Huimin Wu",
      "Zhengmian Hu",
      "Bin Gu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17238": {
    "title": "Fine-grained Generalization Analysis of Vector-Valued Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7f163523a2f604256bdb53dc7629420d1e1defc2",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Liang Wu",
      "Antoine Ledent",
      "Yunwen Lei",
      "Marius Kloft"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17239": {
    "title": "Frugal Optimization for Cost-related Hyperparameters",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4604b009bcf82385493055a0d59eec416eba7a3c",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Qingyun Wu",
      "Chi Wang",
      "Silu Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17240": {
    "title": "Federated Block Coordinate Descent Scheme for Learning Global and Personalized Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a231cad82f3ab7f0121c7750229d9fc48ee253b1",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Ruiyuan Wu",
      "Anna Scaglione",
      "Hoi-To Wai",
      "Nurullah Karakoc",
      "Kari Hreinsson",
      "Wing-Kin Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17241": {
    "title": "Curriculum-Meta Learning for Order-Robust Continual Relation Extraction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1b92ee2694a044b3555ad1c68d7c120fc275f3e6",
    "semantic_title": "",
    "citation_count": 38,
    "authors": [
      "Tongtong Wu",
      "Xuekai Li",
      "Yuan-Fang Li",
      "Gholamreza Haffari",
      "Guilin Qi",
      "Yujin Zhu",
      "Guoqiang Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17242": {
    "title": "Fractal Autoencoders for Feature Selection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5851119cb4487011aa38b08d7a029e68929c5a46",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Xinxing Wu",
      "Qiang Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17243": {
    "title": "Neural Architecture Search as Sparse Supernet",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0c5627fb5bc540e4f93a725cd6c8e23152887aff",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Yan Wu",
      "Aoming Liu",
      "Zhiwu Huang",
      "Siwei Zhang",
      "Luc Van Gool"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17244": {
    "title": "Learning to Purify Noisy Labels via Meta Soft Label Corrector",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "13a494cac1a4f2035bf541a43fb5600b102bfd9e",
    "semantic_title": "",
    "citation_count": 24,
    "authors": [
      "Yichen Wu",
      "Jun Shu",
      "Qi Xie",
      "Qian Zhao",
      "Deyu Meng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17245": {
    "title": "Near-Optimal MNL Bandits Under Risk Criteria",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3101d0360cab5007b2cae2ff79c21fb03cb58ce3",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Guangyu Xi",
      "Chao Tao",
      "Yuan Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17246": {
    "title": "Communication-Efficient Frank-Wolfe Algorithm for Nonconvex Decentralized Distributed Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "18140e61c2242369c7f960d4f1344110911fe498",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Wenhan Xian",
      "Feihu Huang",
      "Heng Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17247": {
    "title": "Physics-constrained Automatic Feature Engineering for Predictive Modeling in Materials Science",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "270809df0b5a0f582e3d6a2bb681cda5d5b2d14a",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Ziyu Xiang",
      "Mingzhou Fan",
      "Guillermo V√°zquez Tovar",
      "William Trehern",
      "Byung-Jun Yoon",
      "Xiaofeng Qian",
      "Raymundo Arroyave",
      "Xiaoning Qian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17248": {
    "title": "Distant Transfer Learning via Deep Random Walk",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2c15eed6944d33f6209fe03c8d32d2d6a1e66354",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Qiao Xiao",
      "Yu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17249": {
    "title": "Learning Cycle-Consistent Cooperative Networks via Alternating MCMC Teaching for Unsupervised Cross-Domain Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e8266aa7606217305c25720c839d9742f60360ac",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Jianwen Xie",
      "Zilong Zheng",
      "Xiaolin Fang",
      "Song-Chun Zhu",
      "Ying Nian Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17250": {
    "title": "Learning Energy-Based Model with Variational Auto-Encoder as Amortized Sampler",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "114fee31a3038d5d217dd41a18262928211f60b9",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Jianwen Xie",
      "Zilong Zheng",
      "Ping Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17251": {
    "title": "Domain Adaptation In Reinforcement Learning Via Latent Unified State Representation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "691ba1236f38905fc6e540409787514228e874ab",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Jinwei Xing",
      "Takashi Nagata",
      "Kexin Chen",
      "Xinyun Zou",
      "Emre Neftci",
      "Jeffrey L. Krichmar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17252": {
    "title": "Non-asymptotic Convergence of Adam-type Reinforcement Learning Algorithms under Markovian Sampling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "71c0ca7dbce40ef1ac621e33324b1737b658d8b6",
    "semantic_title": "",
    "citation_count": 24,
    "authors": [
      "Huaqing Xiong",
      "Tengyu Xu",
      "Yingbin Liang",
      "Wei  Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17253": {
    "title": "Variational Disentanglement for Rare Event Modeling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f5f196dce229939f4bfc0f6541295da2bc6f272e",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Zidi Xiu",
      "Chenyang Tao",
      "Michael Gao",
      "Connor Davis",
      "Benjamin A. Goldstein",
      "Ricardo Henao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17254": {
    "title": "Step-Ahead Error Feedback for Distributed Training with Compressed Gradient",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "46780b67ec795d143750bcba94406928c6973488",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "An Xu",
      "Zhouyuan Huo",
      "Heng Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17255": {
    "title": "Isolation Graph Kernel",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a687250a507a08351d938fbf634d11c229682b58",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Bi-Cun Xu",
      "Kai Ming Ting",
      "Yuan Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17256": {
    "title": "Multi-Task Recurrent Modular Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "18bb3bbeffe2b00378342a876d3de4ed695c57b4",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Dongkuan Xu",
      "Wei Cheng",
      "Xin Dong",
      "Bo Zong",
      "Wenchao Yu",
      "Jingchao Ni",
      "Dongjin Song",
      "Xuchao Zhang",
      "Haifeng Chen",
      "Xiang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17257": {
    "title": "Learning Graphons via Structured Gromov-Wasserstein Barycenters",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "29d52d1457677a259977113579a3d39b5345bd6d",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Hongteng Xu",
      "Dixin Luo",
      "Lawrence Carin",
      "Hongyuan Zha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17258": {
    "title": "Towards Generalized Implementation of Wasserstein Distance in GANs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b0494d7e8759990dae712bf5a9b44950e6b480c1",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Minkai Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17259": {
    "title": "Towards Feature Space Adversarial Attack by Style Perturbation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "07968742c9ae269e0023a7540b0a7e51bbc7f29a",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Qiuling Xu",
      "Guanhong Tao",
      "Siyuan Cheng",
      "Xiangyu Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17260": {
    "title": "MUFASA: Multimodal Fusion Architecture Search for Electronic Health Records",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "513a73c77b652a89a916673318d03caf801bea69",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Zhen Xu",
      "David R. So",
      "Andrew  M. Dai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17261": {
    "title": "Deep Frequency Principle Towards Understanding Why Deeper Learning Is Faster",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2ac5861a63c8747133c05fde44436fedc939651d",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Zhiqin John Xu",
      "Hanxu Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17262": {
    "title": "Rethinking Bi-Level Optimization in Neural Architecture Search: A Gibbs Sampling Perspective",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "63065d6a88e7cf10de5200e7a682ff8b2e998caa",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Chao Xue",
      "Xiaoxing Wang",
      "Junchi Yan",
      "Yonggang Hu",
      "Xiaokang Yang",
      "Kewei Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17263": {
    "title": "Toward Understanding the Influence of Individual Clients in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ee83845e674589bb2f243876bffcc8608592bfd6",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Yihao Xue",
      "Chaoyue Niu",
      "Zhenzhe Zheng",
      "Shaojie Tang",
      "Chengfei Lyu",
      "Fan Wu",
      "Guihai Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17264": {
    "title": "Adversarial Partial Multi-Label Learning with Label Disambiguation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f799f7affe7337f1fdd78d342ff5d4a2690b338c",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Yan Yan",
      "Yuhong Guo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17265": {
    "title": "Near Lossless Transfer Learning for Spiking Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9d8f774e1a4bfdb5a1f411419d7156a634d496e4",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Zhanglu Yan",
      "Jun Zhou",
      "Weng-Fai Wong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17266": {
    "title": "DeHiB: Deep Hidden Backdoor Attack on Semi-supervised Learning via Adversarial Perturbation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dc5d70b48a04a6e9c3310e6fda30748a37031d0c",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Zhicong Yan",
      "Gaolei Li",
      "Yuan TIan",
      "Jun Wu",
      "Shenghong Li",
      "Mingzhe Chen",
      "H. Vincent Poor"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17267": {
    "title": "Robust Bandit Learning with Imperfect Context",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "386a40c178c4c737a6aff32f815a790417de7814",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Jianyi Yang",
      "Shaolei Ren"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17268": {
    "title": "Hierarchical Graph Capsule Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cce173204b1ea9f41635bd7efa81c4ca2d8b7dfd",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Jinyu Yang",
      "Peilin Zhao",
      "Yu Rong",
      "Chaochao Yan",
      "Chunyuan Li",
      "Hehuan Ma",
      "Junzhou Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17269": {
    "title": "FracBits: Mixed Precision Quantization via Fractional Bit-Widths",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5bbb9dfc449f77a8c95de0bdd4a70fd96953308e",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Linjie Yang",
      "Qing Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17270": {
    "title": "On Convergence of Gradient Expected Sarsa(Œª)",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "21fa92e012b6575064dfbd304e67673e7a8f16cc",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Long Yang",
      "Gang Zheng",
      "Yu Zhang",
      "Qian Zheng",
      "Pengfei Li",
      "Gang Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17271": {
    "title": "Sample Complexity of Policy Gradient Finding Second-Order Stationary Points",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f2f6502c85228c2dc69f712798f2aba54241d7d6",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Long Yang",
      "Qian Zheng",
      "Gang Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17272": {
    "title": "WCSAC: Worst-Case Soft Actor Critic for Safety-Constrained Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5b2370ebd3439ff60ea64a0c8db88fea2dd86a9c",
    "semantic_title": "",
    "citation_count": 46,
    "authors": [
      "Qisong Yang",
      "Thiago D. Sim√£o",
      "Simon H Tindemans",
      "Matthijs  T. J. Spaan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17273": {
    "title": "Characterizing the Evasion Attackability of Multi-label Classifiers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "af6b7679f847bdae78e0c2e0a400ddee80dfbd47",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Zhuo Yang",
      "Yufei Han",
      "Xiangliang Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17274": {
    "title": "SeCo: Exploring Sequence Supervision for Unsupervised Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7b4741f8e6667664f1b21c390830b2022eca2da0",
    "semantic_title": "",
    "citation_count": 68,
    "authors": [
      "Ting Yao",
      "Yiheng Zhang",
      "Zhaofan Qiu",
      "Yingwei Pan",
      "Tao Mei"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17275": {
    "title": "ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "20438e2a38a0c4723fbd9de50b44b7335f6f43cb",
    "semantic_title": "",
    "citation_count": 115,
    "authors": [
      "Zhewei Yao",
      "Amir Gholami",
      "Sheng Shen",
      "Mustafa Mustafa",
      "Kurt Keutzer",
      "Michael Mahoney"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17276": {
    "title": "Improving Sample Efficiency in Model-Free Reinforcement Learning from Images",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "88dd6594c9ddd4c4bb7f9b407b162e283907f4f3",
    "semantic_title": "",
    "citation_count": 238,
    "authors": [
      "Denis Yarats",
      "Amy Zhang",
      "Ilya Kostrikov",
      "Brandon Amos",
      "Joelle Pineau",
      "Rob Fergus"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17277": {
    "title": "Task Cooperation for Semi-Supervised Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ffa89c1bc4c853f87f84ceb6c354c64ead20b688",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Han-Jia Ye",
      "Xin-Chun Li",
      "De-Chuan Zhan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17278": {
    "title": "Amata: An Annealing Mechanism for Adversarial Training Acceleration",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "085f82a273239242fd511037daf0a84e7e52810b",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Nanyang Ye",
      "Qianxiao Li",
      "Xiao-Yun Zhou",
      "Zhanxing Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17279": {
    "title": "Sequential Generative Exploration Model for Partially Observable Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "31d1cc6aa3a04bc524b40b089087c8ccffab35df",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Haiyan Yin",
      "Jianda Chen",
      "Sinno Jialin Pan",
      "Sebastian Tschiatschek"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17280": {
    "title": "Enhanced Audio Tagging via Multi- to Single-Modal Teacher-Student Mutual Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "900c91fac3dac1051cba81c08b9a337fa6820aef",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Yifang Yin",
      "Harsh Shrivastava",
      "Ying Zhang",
      "Zhenguang Liu",
      "Rajiv Ratn Shah",
      "Roger Zimmermann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17281": {
    "title": "Image-to-Image Retrieval by Learning Similarity between Scene Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2e0570df4e56d51be58b53166e853d848ef767af",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Sangwoong Yoon",
      "Woo Young Kang",
      "Sungwook Jeon",
      "SeongEun Lee",
      "Changjin Han",
      "Jonghun Park",
      "Eun-Sol Kim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17282": {
    "title": "Learning Interpretable Models for Coupled Networks Under Domain Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "aae7a9c2c8a7ac351295026cca85251a87330fa3",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongyuan You",
      "Sikun Lin",
      "Ambuj Singh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17283": {
    "title": "Identity-aware Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "44b9f16ba417b90e2e7c42f9074378dd06415809",
    "semantic_title": "",
    "citation_count": 94,
    "authors": [
      "Jiaxuan You",
      "Jonathan M Gomes-Selman",
      "Rex Ying",
      "Jure Leskovec"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17284": {
    "title": "How Does Data Augmentation Affect Privacy in Machine Learning?",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "590327cab07ae5d5fcc46e7f781b7223b6a92a3a",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Da Yu",
      "Huishuai Zhang",
      "Wei Chen",
      "Jian Yin",
      "Tie-Yan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17285": {
    "title": "DAST: Unsupervised Domain Adaptation in Semantic Segmentation Based on Discriminator Attention and Self-Training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c411daf84fe2429437634ca90236b30e45389467",
    "semantic_title": "",
    "citation_count": 37,
    "authors": [
      "Fei Yu",
      "Mo Zhang",
      "Hexin Dong",
      "Sheng Hu",
      "Bin Dong",
      "Li Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17286": {
    "title": "Any-Precision Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "36562c6788e3d5c56ae5db738170ca32b04b6d50",
    "semantic_title": "",
    "citation_count": 30,
    "authors": [
      "Haichao Yu",
      "Haoxiang Li",
      "Humphrey Shi",
      "Thomas S. Huang",
      "Gang Hua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17287": {
    "title": "Personalized Adaptive Meta Learning for Cold-start User Preference Prediction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "449e9f36d28c24a240f463b26abfda2dcf33ce17",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Runsheng Yu",
      "Yu Gong",
      "Xu He",
      "Yu Zhu",
      "Qingwen Liu",
      "Wenwu Ou",
      "Bo An"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17288": {
    "title": "Measuring Dependence with Matrix-based Entropy Functional",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "efa10c8d7e628341997ab07a5feb99b03db4dc17",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Shujian Yu",
      "Francesco Alesiani",
      "Xi Yu",
      "Robert Jenssen",
      "Jose Principe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17289": {
    "title": "Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "897937116ac0645e7d8f0d539b68545a6116191f",
    "semantic_title": "",
    "citation_count": 93,
    "authors": [
      "Wenmeng Yu",
      "Hua Xu",
      "Ziqi Yuan",
      "Jiele Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17290": {
    "title": "Knowledge-Guided Object Discovery with Acquired Deep Impressions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3b574ba610553a622e70877a2571b05a74aea595",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Jinyang Yuan",
      "Bin Li",
      "Xiangyang Xue"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17291": {
    "title": "Curse or Redemption? How Data Heterogeneity Affects the Robustness of Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "60153b7dddb861048f16ec07a9067c47261c6178",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Syed Zawad",
      "Ahsan Ali",
      "Pin-Yu Chen",
      "Ali Anwar",
      "Yi Zhou",
      "Nathalie Baracaldo",
      "Yuan Tian",
      "Feng Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17292": {
    "title": "Are Adversarial Examples Created Equal? A Learnable Weighted Minimax Risk for Robustness under Non-uniform Attacks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eef656a1683e9ea18a40a3a858b085101a088d8d",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Huimin Zeng",
      "Chen Zhu",
      "Tom Goldstein",
      "Furong Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17293": {
    "title": "Contrastive Self-supervised Learning for Graph Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2297049be3eb050bf4dbe27e353669f91702ff08",
    "semantic_title": "",
    "citation_count": 62,
    "authors": [
      "Jiaqi Zeng",
      "Pengtao Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17294": {
    "title": "Data-driven Competitive Algorithms for Online Knapsack and Set Cover",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b0a3d2672d5a8f5370703861ea5d49d6436ab512",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Ali Zeynali",
      "Bo Sun",
      "Mohammad Hajiesmaili",
      "Adam Wierman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17295": {
    "title": "A Hybrid Stochastic Gradient Hamiltonian Monte Carlo Method",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1a1a797efaeaf78d065b105906170356348fcbb8",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Chao Zhang",
      "Zhijian Li",
      "Zebang Shen",
      "Jiahao Xie",
      "Hui Qian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17296": {
    "title": "CloudLSTM: A Recurrent Neural Model for Spatiotemporal Point-cloud Stream Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f6f5e8e057207dffa01363dae38b35037454d7a4",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Chaoyun Zhang",
      "Marco Fiore",
      "Iain Murray",
      "Paul Patras"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17297": {
    "title": "Exploration by Maximizing Renyi Entropy for Reward-Free RL Framework",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0a58dedfa7dc8a2bf7b90a4de9e6000b54c2d55b",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Chuheng Zhang",
      "Yuanying Cai",
      "Longbo Huang",
      "Jian Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17298": {
    "title": "Efficient Folded Attention for Medical Image Reconstruction and Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "34c390f3cfa193d56537974af0910944b64c7226",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Hang Zhang",
      "Jinwei Zhang",
      "Rongguang Wang",
      "Qihao Zhang",
      "Pascal Spincemaille",
      "Thanh D. Nguyen",
      "Yi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17299": {
    "title": "Interpreting Multivariate Shapley Interactions in DNNs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c996d77b109899ce22429ba02d7d59c74885349f",
    "semantic_title": "",
    "citation_count": 23,
    "authors": [
      "Hao Zhang",
      "Yichen Xie",
      "Longjie Zheng",
      "Die Zhang",
      "Quanshi Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17300": {
    "title": "Sample Efficient Reinforcement Learning with REINFORCE",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "305e04357a7e16292fad7248426e7cf4f51c93a9",
    "semantic_title": "",
    "citation_count": 42,
    "authors": [
      "Junzi Zhang",
      "Jongho Kim",
      "Brendan O'Donoghue",
      "Stephen Boyd"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17301": {
    "title": "Secure Bilevel Asynchronous Vertical Federated Learning with Backward Updating",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "05f689772fb1ae5a47b5089b2c38f9b53156d285",
    "semantic_title": "",
    "citation_count": 36,
    "authors": [
      "Qingsong Zhang",
      "Bin Gu",
      "Cheng Deng",
      "Heng Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17302": {
    "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "11d558cf04914a19068338705526593fe7fb6cd3",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Shangtong Zhang",
      "Bo Liu",
      "Shimon Whiteson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17303": {
    "title": "Deep Wasserstein Graph Discriminant Learning for Graph Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f6ea57c9cea1a56150e25b1deb8b2031914f7855",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Tong Zhang",
      "Yun Wang",
      "Zhen Cui",
      "Chuanwei Zhou",
      "Baoliang Cui",
      "Haikuan Huang",
      "Jian Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17304": {
    "title": "Treatment Effect Estimation with Disentangled Latent Factors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a63b454f24967f9f3b77f4343e0e0b3d7702989e",
    "semantic_title": "",
    "citation_count": 33,
    "authors": [
      "Weijia Zhang",
      "Lin Liu",
      "Jiuyong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17305": {
    "title": "Regret Bounds for Online Kernel Selection in Continuous Kernel Space",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "afce7a70d647819db76e44632737a380d8a49874",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Xiao Zhang",
      "Shizhong Liao",
      "Jun Xu",
      "Ji-Rong Wen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17306": {
    "title": "The Sample Complexity of Teaching by Reinforcement on Q-Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "33f4ce2451f3c4cd2ae8ffa6c33650460d1e920f",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Xuezhou Zhang",
      "Shubham Bharti",
      "Yuzhe Ma",
      "Adish Singla",
      "Xiaojin Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17307": {
    "title": "Partial-Label and Structure-constrained Deep Coupled Factorization Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e77f542230e003f92c9efa34794c8ecfc3e2df34",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Yan Zhang",
      "Zhao Zhang",
      "Yang Wang",
      "Zheng Zhang",
      "Li Zhang",
      "Shuicheng Yan",
      "Meng Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17308": {
    "title": "Memory-Gated Recurrent Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d8ff0e190ca20c7158675312fc71cd75c6b5270",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Yaquan Zhang",
      "Qi Wu",
      "Nanbo Peng",
      "Min Dai",
      "Jing Zhang",
      "Hu Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17309": {
    "title": "Towards Enabling Learnware to Handle Unseen Jobs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f7122e126ca474442c462d12ebac1c434c4ab326",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Yu-Jie Zhang",
      "Yu-Hu Yan",
      "Peng Zhao",
      "Zhi-Hua Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17310": {
    "title": "Exploiting Unlabeled Data via Partial Label Assignment for Multi-Class Semi-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "415bd000214f5b35cc5454bf3dabc9a206babe23",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Zhen-Ru Zhang",
      "Qian-Wen Zhang",
      "Yunbo Cao",
      "Min-Ling Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17311": {
    "title": "Looking Wider for Better Adaptive Representation in Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "78cd8bcd57084d34e07ccb79f6ee25c02fd651f6",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Jiabao Zhao",
      "Yifan Yang",
      "Xin Lin",
      "Jing Yang",
      "Liang He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17312": {
    "title": "Distilling Localization for Self-Supervised Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f9e9ddec468c1c240a1a8c192e74d485d97205bd",
    "semantic_title": "",
    "citation_count": 37,
    "authors": [
      "Nanxuan Zhao",
      "Zhirong Wu",
      "Rynson W.H. Lau",
      "Stephen Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17313": {
    "title": "Exploratory Machine Learning with Unknown Unknowns",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4a6488c432f6ba6cc5ca578ab12e10f7bd1f2ef1",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Peng Zhao",
      "Yu-Jie Zhang",
      "Zhi-Hua Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17314": {
    "title": "Efficient Classification with Adaptive KNN",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d86b805219b9281fb091cbe1e5b0887018f14819",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Puning Zhao",
      "Lifeng Lai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17315": {
    "title": "Data Augmentation for Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "27d5be9322d71b6fd2faa8a6b87250127a12c0cf",
    "semantic_title": "",
    "citation_count": 173,
    "authors": [
      "Tong Zhao",
      "Yozen Liu",
      "Leonardo Neves",
      "Oliver Woodford",
      "Meng Jiang",
      "Neil Shah"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17316": {
    "title": "Augmenting Policy Learning with Routines Discovered from a Single Demonstration",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c9af30358358b15d05ce72a86ec5f0ce883afdc6",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Zelin Zhao",
      "Chuang Gan",
      "Jiajun Wu",
      "Xiaoxiao Guo",
      "Joshua B. Tenenbaum"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17317": {
    "title": "Improved Consistency Regularization for GANs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b31fdc82691b36e22b2ba15846a7a757061da4fa",
    "semantic_title": "",
    "citation_count": 88,
    "authors": [
      "Zhengli Zhao",
      "Sameer Singh",
      "Honglak Lee",
      "Zizhao Zhang",
      "Augustus Odena",
      "Han Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17318": {
    "title": "Flow-based Generative Models for Learning Manifold to Manifold Mappings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5c5df399a570954be5985c3e38c2544f2bc3a9a1",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Xingjian Zhen",
      "Rudrasis Chakraborty",
      "Liu Yang",
      "Vikas Singh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17319": {
    "title": "Meta Label Correction for Noisy Label Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "96c6f34594279844ca8fd901649fa06491ef822c",
    "semantic_title": "",
    "citation_count": 74,
    "authors": [
      "Guoqing Zheng",
      "Ahmed Hassan Awadallah",
      "Susan Dumais"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17320": {
    "title": "Going Deeper With Directly-Trained Larger Spiking Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a31ca77b2c76c56775c3b75264f72879712058b4",
    "semantic_title": "",
    "citation_count": 126,
    "authors": [
      "Hanle Zheng",
      "Yujie Wu",
      "Lei Deng",
      "Yifan Hu",
      "Guoqi Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17321": {
    "title": "Fully-Connected Tensor Network Decomposition and Its Application to Higher-Order Tensor Completion",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "515fc0f3f40d5f65135cb394cdc1f3cc7160a224",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Yu-Bang Zheng",
      "Ting-Zhu Huang",
      "Xi-Le Zhao",
      "Qibin Zhao",
      "Tai-Xiang Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17322": {
    "title": "How Does the Combined Risk Affect the Performance of Unsupervised Domain Adaptation Approaches?",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c66aa46cdf3e748c4176c4c99bdc829ec31a0f29",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Li Zhong",
      "Zhen Fang",
      "Feng Liu",
      "Jie Lu",
      "Bo Yuan",
      "Guangquan Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17323": {
    "title": "Multi-task Learning by Leveraging the Semantic Information",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8233ace0b3594482bf72adda98081755a0d890d4",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Fan Zhou",
      "Brahim Chaib-draa",
      "Boyu Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17324": {
    "title": "MetaAugment: Sample-Aware Data Augmentation Policy Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "951f0cd7a4b43623cb4ad7a4a6215ae0113eb0ab",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Fengwei Zhou",
      "Jiawei Li",
      "Chuanlong Xie",
      "Fei Chen",
      "Lanqing Hong",
      "Rui Sun",
      "Zhenguo Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17325": {
    "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "35a9749df07a2ab97c51af4d260b095b00da7676",
    "semantic_title": "",
    "citation_count": 751,
    "authors": [
      "Haoyi Zhou",
      "Shanghang Zhang",
      "Jieqi Peng",
      "Shuai Zhang",
      "Jianxin Li",
      "Hui Xiong",
      "Wancai Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17326": {
    "title": "Inverse Reinforcement Learning with Natural Language Goals",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "40848d6a0157d04e2d92576abe6923e8a6370108",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Li Zhou",
      "Kevin Small"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17327": {
    "title": "Tri-level Robust Clustering Ensemble with Multiple Graph Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "661ffe3fcb3ca15e33b038841c4a3fb4d80a3ff1",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Peng Zhou",
      "Liang Du",
      "Yi-Dong Shen",
      "Xuejun Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17328": {
    "title": "Fairness in Forecasting and Learning Linear Dynamical Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "14abedc428a06f596e810fd5a6bcdea1ff28fc19",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Quan Zhou",
      "Jakub Marecek",
      "Robert N. Shorten"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17329": {
    "title": "Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust Performance",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "396964033168f89b460fad047b3279926340b3ca",
    "semantic_title": "",
    "citation_count": 35,
    "authors": [
      "Shibo Zhou",
      "Xiaohua Li",
      "Ying Chen",
      "Sanjeev T. Chandrasekaran",
      "Arindam Sanyal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17330": {
    "title": "Local Differential Privacy for Bayesian Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6fcf884343bfac0d4680133b51c558c6a4e0bf35",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Xingyu Zhou",
      "Jian Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17331": {
    "title": "A Primal-Dual Online Algorithm for Online Matching Problem in Dynamic Environments",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b2c738ba34e5e6e446e10748495f96865e53b848",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-Hang Zhou",
      "Peng Hu",
      "Chen Liang",
      "Huan Xu",
      "Guangda Huzhang",
      "Yinfu Feng",
      "Qing Da",
      "Xinshang Wang",
      "An-Xiang Zeng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17332": {
    "title": "Graph Neural Networks with Heterophily",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "33b75e9094968c060238d54f1026dbc3c8ab66f7",
    "semantic_title": "",
    "citation_count": 113,
    "authors": [
      "Jiong Zhu",
      "Ryan A. Rossi",
      "Anup Rao",
      "Tung Mai",
      "Nedim Lipka",
      "Nesreen K. Ahmed",
      "Danai Koutra"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17333": {
    "title": "Bias and Variance of Post-processing in Differential Privacy",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cdd9f0bfb13105ad20514cc6ed60a575d4f311ba",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Keyu Zhu",
      "Pascal Van Hentenryck",
      "Ferdinando Fioretto"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17334": {
    "title": "Self-correcting Q-learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b4e343afbf23f6e6671861ac2b676f843866f5a8",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Rong Zhu",
      "Mattia Rigotti"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17335": {
    "title": "An Efficient Algorithm for Deep Stochastic Contextual Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "31be2191f11491128bc35069e31a7693deb707e2",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tan Zhu",
      "Guannan Liang",
      "Chunjiang Zhu",
      "Haining Li",
      "Jinbo Bi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17336": {
    "title": "Variational Fair Clustering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0bd3aefd036cdd59186011a7cd2ae80c6173805c",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Imtiaz Masud Ziko",
      "Jing Yuan",
      "Eric Granger",
      "Ismail Ben Ayed"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17337": {
    "title": "Learning Task-Distribution Reward Shaping with Meta-Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "30a41fffb0138af4c8dfab7f5f92fb3c9ea427ad",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Haosheng Zou",
      "Tongzheng Ren",
      "Dong Yan",
      "Hang Su",
      "Jun Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17338": {
    "title": "Improving Continuous-time Conflict Based Search",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "28717af484aebd6e172db0b1a18d358275dbdcd4",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Anton Andreychuk",
      "Konstantin Yakovlev",
      "Eli Boyarski",
      "Roni Stern"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17339": {
    "title": "Inference-Based Deterministic Messaging For Multi-Agent Communication",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dae58679fd79f9abc240d885ada7020a30e91509",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Varun Bhatt",
      "Michael Buro"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17340": {
    "title": "Scalable and Safe Multi-Agent Motion Planning with Nonlinear Dynamics and Bounded Disturbances",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "62a90d3f5f2a607faa182f5aa51cb83954191ce9",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Jingkai Chen",
      "Jiaoyang Li",
      "Chuchu Fan",
      "Brian C. Williams"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17341": {
    "title": "Learning to Resolve Conflicts for Multi-Agent Path Finding with Conflict-Based Search",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c6a24e9ef8d78128c78406dd33597ad080ce2772",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Taoan Huang",
      "Sven Koenig",
      "Bistra Dilkina"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17342": {
    "title": "The Influence of Memory in Multi-Agent Consensus",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "91fb87478890a563e22a3eb78635969262045e9f",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Kohan Marzag√£o",
      "Luciana Basualdo Bonatto",
      "Tiago Madeira",
      "Marcelo Matheus Gauy",
      "Peter McBurney"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17343": {
    "title": "Exploration-Exploitation in Multi-Agent Learning: Catastrophe Theory Meets Game Theory",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6ddc6b09d3da565fa75b5e08c581fb2f71b8638b",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Stefanos Leonardos",
      "Georgios Piliouras"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17344": {
    "title": "Lifelong Multi-Agent Path Finding in Large-Scale Warehouses",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dc6219278e481591b478904a755fbcb1db675399",
    "semantic_title": "",
    "citation_count": 73,
    "authors": [
      "Jiaoyang Li",
      "Andrew Tinka",
      "Scott Kiesel",
      "Joseph W. Durham",
      "T. K. Satish Kumar",
      "Sven Koenig"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17345": {
    "title": "Dec-SGTS: Decentralized Sub-Goal Tree Search for Multi-Agent Coordination",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0ec809a051293a0a39b23a26403412ed8b73ab3e",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minglong Li",
      "Zhongxuan Cai",
      "Wenjing Yang",
      "Lixia Wu",
      "Yinghui Xu",
      "Ji Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17346": {
    "title": "Expected Value of Communication for Planning in Ad Hoc Teamwork",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "347c796de71a86724354c751bd95f6df9eaa4d6d",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "William Macke",
      "Reuth Mirsky",
      "Peter Stone"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17347": {
    "title": "Time-Independent Planning for Multiple Moving Agents",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1cd62f72f0854a7ff9ffd577754ab09cd7a208b5",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Keisuke Okumura",
      "Yasumasa Tamura",
      "Xavier D√©fago"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17348": {
    "title": "Resilient Multi-Agent Reinforcement Learning with Adversarial Value Decomposition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a4ceb935b4adf688e580d5ca23d4380c04a29789",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Thomy Phan",
      "Lenz Belzner",
      "Thomas Gabor",
      "Andreas Sedlmeier",
      "Fabian Ritz",
      "Claudia Linnhoff-Popien"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17349": {
    "title": "Anytime Heuristic and Monte Carlo Methods for Large-Scale Simultaneous Coalition Structure Generation and Assignment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5bba703b175d20a39b0ed8bd99e11c1bf981c2ba",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Fredrik Pr√§ntare",
      "Herman Appelgren",
      "Fredrik Heintz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17350": {
    "title": "Newton Optimization on Helmholtz Decomposition for Continuous Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "964d83cc4da6ef9b60c33e32495fbbe3ee13596e",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Giorgia Ramponi",
      "Marcello Restelli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17351": {
    "title": "Synchronous Dynamical Systems on Directed Acyclic Graphs: Complexity and Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2b30ab422207a740a11fd278957b2db6f61abc27",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Daniel J. Rosenkrantz",
      "Madhav Marathe",
      "S. S. Ravi",
      "Richard E. Stearns"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17352": {
    "title": "Evolutionary Game Theory Squared: Evolving Agents in Endogenously Evolving Zero-Sum Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1410f7d9470a24fb4055c6685c2dda758b9d995f",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Stratis Skoulakis",
      "Tanner Fiez",
      "Ryann Sim",
      "Georgios Piliouras",
      "Lillian Ratliff"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17353": {
    "title": "Value-Decomposition Multi-Agent Actor-Critics",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a69482d66ae75bcae753b48a1e1be9c59ceb563c",
    "semantic_title": "",
    "citation_count": 34,
    "authors": [
      "Jianyu Su",
      "Stephen Adams",
      "Peter Beling"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17354": {
    "title": "Contract-based Inter-user Usage Coordination in Free-floating Car Sharing",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6e7033b6e9766dbdc363aa0eeee10c4133e88e30",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kentaro Takahira",
      "Shigeo Matsubara"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17355": {
    "title": "Maintenance of Social Commitments in Multiagent Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3afe7dacf6e0c8ca7b9197f78858140838adee91",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Pankaj Telang",
      "Munindar P. Singh",
      "Neil Yorke-Smith"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17356": {
    "title": "Efficient Querying for Cooperative Probabilistic Commitments",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d463e84df408027719b643e954cd08f85239685c",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Qi Zhang",
      "Edmund H. Durfee",
      "Satinder Singh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17357": {
    "title": "Coordination Between Individual Agents in Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "aca91d1d11ed25602d149e90b565447f118bd12e",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Yang Zhang",
      "Qingyu Yang",
      "Dou An",
      "Chengwei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17358": {
    "title": "Explaining A Black-box By Using A Deep Variational Information Bottleneck Approach",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4817e568d9710a497bde7b0ae65c8bf0882ec12b",
    "semantic_title": "",
    "citation_count": 53,
    "authors": [
      "Seojin Bang",
      "Pengtao Xie",
      "Heewook Lee",
      "Wei Wu",
      "Eric Xing"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17359": {
    "title": "Is the Most Accurate AI the Best Teammate? Optimizing AI for Teamwork",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "198838f8b7b504c04214fffb8646d11c6152ba5e",
    "semantic_title": "",
    "citation_count": 46,
    "authors": [
      "Gagan Bansal",
      "Besmira Nushi",
      "Ece Kamar",
      "Eric Horvitz",
      "Daniel S. Weld"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17360": {
    "title": "TripleTree: A Versatile Interpretable Representation of Black Box Agents and their Environments",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "de70a19dfbe56258149eae5b2e7a6c230c91071c",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Tom Bewley",
      "Jonathan Lawry"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17361": {
    "title": "Bayes-TrEx: a Bayesian Sampling Approach to Model Transparency by Example",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "131b8dd9398232a55cab6a7a1b44ebe24161cbe3",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Serena Booth",
      "Yilun Zhou",
      "Ankit Shah",
      "Julie Shah"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17362": {
    "title": "FIMAP: Feature Importance by Minimal Adversarial Perturbation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "333cfd191a479fdd87425d75d85d334d9c1b5ff5",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Matt Chapman-Rounds",
      "Umang Bhatt",
      "Erik Pazos",
      "Marc-Andre Schulz",
      "Konstantinos Georgatzis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17363": {
    "title": "Beyond Class-Conditional Assumption: A Primary Attempt to Combat Instance-Dependent Label Noise",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4945fb6bc967179b8d9a19e1b2f87a62720d79c7",
    "semantic_title": "",
    "citation_count": 44,
    "authors": [
      "Pengfei Chen",
      "Junjie Ye",
      "Guangyong Chen",
      "Jingwei Zhao",
      "Pheng-Ann Heng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17364": {
    "title": "Robustness of Accuracy Metric and its Inspirations in Learning with Noisy Labels",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1fbff5f28ac4851011a0c86f72c1c6126a984c07",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Pengfei Chen",
      "Junjie Ye",
      "Guangyong Chen",
      "Jingwei Zhao",
      "Pheng-Ann Heng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17365": {
    "title": "A Unified Taylor Framework for Revisiting Attribution Methods",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3e1719032cb56039df0c30861ccaac061982bb45",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Huiqi Deng",
      "Na Zou",
      "Mengnan Du",
      "Weifu Chen",
      "Guocan Feng",
      "Xia Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17366": {
    "title": "Verifiable Machine Ethics in Changing Contexts",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6bd9162101cfc4b2221539b8dff283371588d69e",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Louise A. Dennis",
      "Martin Mose Bentzen",
      "Felix Lindner",
      "Michael Fisher"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17367": {
    "title": "Epistemic Logic of Know-Who",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "24b8b7f638aae07491d0ddf8644505d20e17d35a",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Sophia Epstein",
      "Pavel Naumov"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17368": {
    "title": "Agent Incentives: A Causal Perspective",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "67a5303464a764453a2435bec453bed1c5ac9c43",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Tom Everitt",
      "Ryan Carey",
      "Eric D. Langlois",
      "Pedro A. Ortega",
      "Shane Legg"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17369": {
    "title": "Individual Fairness in Kidney Exchange Programs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5279357625cd5a6bbd54f0e5e0292c6d2dd72c1b",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Golnoosh Farnadi",
      "William St-Arnaud",
      "Behrouz Babaki",
      "Margarida Carvalho"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17370": {
    "title": "Fair Representations by Compression",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eeb06f695a71e8923b5d65dd904575828d2cc304",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Xavier Gitiaux",
      "Huzefa Rangwala"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17371": {
    "title": "Amnesiac Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "09227e0251dad7b972878720131ddaecfec6c47f",
    "semantic_title": "",
    "citation_count": 45,
    "authors": [
      "Laura Graves",
      "Vineel Nagisetty",
      "Vijay Ganesh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17372": {
    "title": "On the Verification of Neural ODEs with Stochastic Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0033cbb16ea8996520f2e239298070975b3f31ae",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Sophie Grunbacher",
      "Ramin Hasani",
      "Mathias Lechner",
      "Jacek Cyranka",
      "Scott A. Smolka",
      "Radu Grosu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17373": {
    "title": "PenDer: Incorporating Shape Constraints via Penalized Derivatives",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dba3478cb46874a97e301deb0f20f7692c1f1ae9",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Akhil Gupta",
      "Lavanya Marla",
      "Ruoyu Sun",
      "Naman Shukla",
      "Arinbj√∂rn Kolbeinsson"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17374": {
    "title": "Visualization of Supervised and Self-Supervised Neural Networks via Attribution Guided Factorization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c92ccde8efe40d1696dc7acdadaddc923c9d945d",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Shir Gur",
      "Ameen Ali",
      "Lior Wolf"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17375": {
    "title": "Differentially Private Clustering via Maximum Coverage",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c0239d011c8e1e5207a267e7f45602c9977fd8d2",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Matthew Jones",
      "Huy L. Nguyen",
      "Thy D Nguyen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17376": {
    "title": "Ordered Counterfactual Explanation by Mixed-Integer Linear Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "05c96f995a71655074f8af03751e52f8c2ff9ecd",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Kentaro Kanamori",
      "Takuya Takagi",
      "Ken Kobayashi",
      "Yuichi Ike",
      "Kento Uemura",
      "Hiroki Arimura"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17377": {
    "title": "On Generating Plausible Counterfactual and Semi-Factual Explanations for Deep Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5e6b2c0a61b008b9b550f4cf388bf118e72c3b7d",
    "semantic_title": "",
    "citation_count": 46,
    "authors": [
      "Eoin M. Kenny",
      "Mark T Keane"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17378": {
    "title": "How RL Agents Behave When Their Actions Are Modified",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "81d612d385aec3839ab53babfa83081221de22b4",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Eric D. Langlois",
      "Tom Everitt"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17379": {
    "title": "Outlier Impact Characterization for Time Series Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e54f0521300194179f478a11fe0179c084d7f43e",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Jianbo Li",
      "Lecheng Zheng",
      "Yada Zhu",
      "Jingrui He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17380": {
    "title": "Interpreting Deep Neural Networks with Relative Sectional Propagation by Analyzing Comparative Gradients and Hostile Activations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7f05d62928e9d316e5375067f673a590836cd43d",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Woo-Jeoung Nam",
      "Jaesik Choi",
      "Seong-Whan Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17381": {
    "title": "Ethical Dilemmas in Strategic Games",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "08862c139bc616021ef4455abb1b139e7e57ac28",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Pavel Naumov",
      "Rui-Jie Yew"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17382": {
    "title": "Comprehension and Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6328d027618a1247df0780372c695d8f9a658c78",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Pavel Naumov",
      "Kevin Ros"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17383": {
    "title": "Fair Influence Maximization: a Welfare Optimization Approach",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "06fe543ad9ef9d0c91db0dfa0e6f98904a6bb40a",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Aida Rahmattalabi",
      "Shahin Jabbari",
      "Himabindu Lakkaraju",
      "Phebe Vayanos",
      "Max Izenberg",
      "Ryan Brown",
      "Eric Rice",
      "Milind Tambe"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17384": {
    "title": "Explaining Convolutional Neural Networks through Attribution-Based Input Sampling and Block-Wise Feature Aggregation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7a30b3a47c569af89d00baa53021e187ff92fee4",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Sam Sattarzadeh",
      "Mahesh Sudhakar",
      "Anthony Lem",
      "Shervin Mehryar",
      "Konstantinos N Plataniotis",
      "Jongseong Jang",
      "Hyunwoo Kim",
      "Yeonjeong Jeong",
      "Sangmin Lee",
      "Kyunghoon Bae"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17385": {
    "title": "Exploring the Vulnerability of Deep Neural Networks: A Study of Parameter Corruption",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d3db091942ac3c1fe6af69275a318c25d7b4ed11",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Xu Sun",
      "Zhiyuan Zhang",
      "Xuancheng Ren",
      "Ruixuan Luo",
      "Liangyou Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17386": {
    "title": "Ethically Compliant Sequential Decision Making",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "220d40be0c4374b87649fe9c335d3a207dbddccc",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Justin Svegliato",
      "Samer B. Nashed",
      "Shlomo Zilberstein"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17387": {
    "title": "Improving Robustness to Model Inversion Attacks via Mutual Information Regularization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7b26823c1acbc10fadd53c3b71da55a95c8ae576",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Tianhao Wang",
      "Yuheng Zhang",
      "Ruoxi Jia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17388": {
    "title": "Tightening Robustness Verification of Convolutional Neural Networks with Fine-Grained Linear Approximation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dcef28d2d715f1c860aef90e8bc2f3c4223a813d",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Yiting Wu",
      "Min Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17389": {
    "title": "Invertible Concept-based Explanations for CNN Models with Non-negative Concept Activation Vectors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "92902e212cd1408f2bfbefbbb0157abe1b05a18e",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Ruihan Zhang",
      "Prashan Madumal",
      "Tim Miller",
      "Krista A. Ehinger",
      "Benjamin I. P. Rubinstein"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17390": {
    "title": "i-Algebra: Towards Interactive Interpretability of Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "72719a422ce5adf5a1d244ec5ff3e93474b7d7a4",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Xinyang Zhang",
      "Ren Pang",
      "Shouling Ji",
      "Fenglong Ma",
      "Ting Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17391": {
    "title": "Decision-Guided Weighted Automata Extraction from Recurrent Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "acbbcaabaaa7fe2916006f0bf1d92a73e2cc22d7",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Xiyue Zhang",
      "Xiaoning Du",
      "Xiaofei Xie",
      "Lei Ma",
      "Yang Liu",
      "Meng Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17392": {
    "title": "Computing Plan-Length Bounds Using Lengths of Longest Paths",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2c2f88d30d6e545ad736ab3766813af2418ceb92",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Mohammad Abdulaziz",
      "Dominik Berger"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17393": {
    "title": "Constrained Risk-Averse Markov Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7b313679816e3ce1c7153f27c8ab60e1b4b993b0",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Mohamadreza Ahmadi",
      "Ugo Rosolia",
      "Michel D. Ingham",
      "Richard M. Murray",
      "Aaron D. Ames"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17394": {
    "title": "Contract Scheduling With Predictions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2e29a6a3be93ffdfe4699f964ca986bfa1d817f4",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Spyros Angelopoulos",
      "Shahin Kamali"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17395": {
    "title": "Responsibility Attribution in Parameterized Markovian Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "772b29ad063952d023416cb0af8082daa6f05f42",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Christel Baier",
      "Florian Funke",
      "Rupak Majumdar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17396": {
    "title": "Symbolic Search for Optimal Total-Order HTN Planning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f2fa0c85502f92747a19c567979b97bb7afdcc35",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Gregor Behnke",
      "David Speck"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17397": {
    "title": "A Multivariate Complexity Analysis of the Material Consumption Scheduling Problem",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "96406cd3e9c7be4a48d19fd6249e8267526d19f2",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Matthias Bentert",
      "Robert Bredereck",
      "P√©ter Gy√∂rgyi",
      "Andrzej Kaczmarczyk",
      "Rolf Niedermeier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17398": {
    "title": "General Policies, Representations, and Planning Width",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6a9d4cbe2f1bcb8f81eb5eb91dd752e2970664ee",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Blai Bonet",
      "Hector Geffner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17399": {
    "title": "Successor Feature Sets: Generalizing Successor Representations Across Policies",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b1cad9e721444bf95eb280d39eb324e81d3c86b0",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Kiant√© Brantley",
      "Soroush Mehri",
      "Geoff J. Gordon"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17400": {
    "title": "GLIB: Efficient Exploration for Relational Model-Based Reinforcement Learning via Goal-Literal Babbling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2192fcfbd5040d2bb8d7c7ca7c2138d18534ac9b",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Rohan Chitnis",
      "Tom Silver",
      "Joshua B. Tenenbaum",
      "Leslie Pack Kaelbling",
      "Tom√°s Lozano-P√©rez"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17401": {
    "title": "Robust Finite-State Controllers for Uncertain POMDPs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0c301afaf37865ea90352e7488fcfc83c6a7b192",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Murat Cubuktepe",
      "Nils Jansen",
      "Sebastian Junges",
      "Ahmadreza Marandi",
      "Marnix Suilen",
      "Ufuk Topcu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17402": {
    "title": "Learning General Planning Policies from Small Examples Without Supervision",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "42c5c5a8e52e037ceb3e6dfa96fdf134d085d184",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Guillem Franc√®s",
      "Blai Bonet",
      "Hector Geffner"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17403": {
    "title": "Revisiting Dominance Pruning in Decoupled Search",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4e245d17f57bfbfd97319e6961d8d6f69be38c9b",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Gnad"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17404": {
    "title": "Equitable Scheduling on a Single Machine",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2c53677c18fac4f1d129ab345233d2b00a0d2be3",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Klaus Heeger",
      "Dan Hermelin",
      "George B. Mertzios",
      "Hendrik Molter",
      "Rolf Niedermeier",
      "Dvir Shabtay"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17405": {
    "title": "Landmark Generation in HTN Planning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6b1e7b6f881d18a50d472618c00dc1b64a47cb8a",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Daniel H√∂ller",
      "Pascal Bercher"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17406": {
    "title": "Endomorphisms of Classical Planning Tasks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e3a6d18a6a50565a5dbfe142ae16894e77df7aa5",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Rostislav Horƒç√≠k",
      "Daniel Fi≈°er"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17407": {
    "title": "Bike-Repositioning Using Volunteers: Crowd Sourcing with Choice Restriction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "31e986b2bbbd3f388305d9b7e4ab9da042b392c9",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinjia Huang",
      "Mabel C. Chou",
      "Chung-Piaw Teo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17408": {
    "title": "Branch and Price for Bus Driver Scheduling with Complex Break Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6ca8d663a3986f22b50d49ce182f818317f1639a",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Lucas Kletzander",
      "Nysret Musliu",
      "Pascal Van Hentenryck"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17409": {
    "title": "On-line Learning of Planning Domains from Sensor Data in PAL: Scaling up to Large State Spaces",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9dbfe15981311081db7ae576690ed81c1badba92",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Leonardo Lamanna",
      "Alfonso Emilio Gerevini",
      "Alessandro Saetti",
      "Luciano Serafini",
      "Paolo Traverso"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17410": {
    "title": "Progression Heuristics for Planning with Probabilistic LTL Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "62fe21096776dd5277a5161e3d22d2eb4b51fe7f",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Ian Mallett",
      "Sylvie Thiebaux",
      "Felipe Trevizan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17411": {
    "title": "Bayesian Optimized Monte Carlo Planning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "108184c22782466c04890a1bff254a7791e93d2d",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "John Mern",
      "Anil Yildiz",
      "Zachary Sunberg",
      "Tapan Mukerji",
      "Mykel J. Kochenderfer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17412": {
    "title": "Improved POMDP Tree Search Planning with Prioritized Action Branching",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b2eff44100fbda86e403b78af27722e6e2a6fb72",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "John Mern",
      "Anil Yildiz",
      "Lawrence Bush",
      "Tapan Mukerji",
      "Mykel J. Kochenderfer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17413": {
    "title": "Synthesis of Search Heuristics for Temporal Planning via Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e6e6da82a45728da81dadd50d03a59ca0eea7185",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Andrea Micheli",
      "Alessandro Valentini"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17414": {
    "title": "Revealing Hidden Preconditions and Effects of Compound HTN Planning Tasks ‚Äì A Complexity Analysis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d28d2a8b8b1d175da7e141f278460e649b6b6014",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Conny Olz",
      "Susanne Biundo",
      "Pascal Bercher"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17415": {
    "title": "Faster and Better Simple Temporal Problems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "aaa6691fed4709503f69c3e0e3956e65c222107f",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Dario Ostuni",
      "Alice Raffaele",
      "Romeo Rizzi",
      "Matteo Zavatteri"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17416": {
    "title": "Latent Independent Excitation for Generalizable Sensor-based Cross-Person Activity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "266a35c51001be877cc970323ba8c65c7ac60811",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Hangwei Qian",
      "Sinno Jialin Pan",
      "Chunyan Miao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17417": {
    "title": "Minimax Regret Optimisation for Robust Planning in Uncertain Markov Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fd57b053a67826416ec24cea3cf0054770edf897",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Marc Rigter",
      "Bruno Lacerda",
      "Nick Hawes"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17418": {
    "title": "An LP-Based Approach for Goal Recognition as Planning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3e17cd14aca1bd1405d28e673f85fa9c420b30f8",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Lu√≠sa R. A. Santos",
      "Felipe Meneguzzi",
      "Ramon Fraga Pereira",
      "Andr√© Grahl Pereira"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17419": {
    "title": "Saturated Post-hoc Optimization for Classical Planning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "65a793266aedaeccf883cee50026f12f77a49c5c",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jendrik Seipp",
      "Thomas Keller",
      "Malte Helmert"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17420": {
    "title": "Improved Knowledge Modeling and Its Use for Signaling in Multi-Agent Planning with Partial Observability",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9a312bddb3cf8c7ac94f79880526373c58c40ace",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Shashank Shekhar",
      "Ronen I. Brafman",
      "Guy Shani"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17421": {
    "title": "Planning with Learned Object Importance in Large Problem Instances using Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1953f68b785c7ed2a7a61d6bffe4b18f0dff1172",
    "semantic_title": "",
    "citation_count": 36,
    "authors": [
      "Tom Silver",
      "Rohan Chitnis",
      "Aidan Curtis",
      "Joshua B. Tenenbaum",
      "Tom√°s Lozano-P√©rez",
      "Leslie Pack Kaelbling"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17422": {
    "title": "Symbolic Search for Oversubscription Planning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d7473164b88ac661480a9f285148af2a92d76204",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "David Speck",
      "Michael Katz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17423": {
    "title": "Online Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e8d0b7101de9530f358dffb84d75ea037b210d2f",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Alejandro Su√°rez-Hern√°ndez",
      "Javier Segovia-Aguas",
      "Carme Torras",
      "Guillem Aleny√†"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17424": {
    "title": "A Complexity-theoretic Analysis of Green Pickup-and-Delivery Problems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "66ff30ee41f5714f6abc032b2467dd6412ee25cf",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xing Tan",
      "Jimmy Xiangji Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17425": {
    "title": "Faster Stackelberg Planning via Symbolic Search and Information Sharing",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2f3c8bf60984277f22b30a882d6154fc0548065a",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "√Ålvaro Torralba",
      "Patrick Speicher",
      "Robert K√ºnnemann",
      "Marcel Steinmetz",
      "J√∂rg Hoffmann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17426": {
    "title": "On the Optimal Efficiency of A* with Dominance Pruning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "66eb9a0592f5eace71f96974c142060085c914e8",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "√Ålvaro Torralba"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17427": {
    "title": "Dynamic Automaton-Guided Reward Shaping for Monte Carlo Tree Search",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "23ddceb162d6f8b63a0a17ad9a7036b78f4155d9",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Alvaro Velasquez",
      "Brett Bissey",
      "Lior Barak",
      "Andre Beckus",
      "Ismail Alkhouri",
      "Daniel Melcer",
      "George Atia"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17428": {
    "title": "Asking the Right Questions: Learning Interpretable Action Models Through Query Answering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3772cdcdbaccd8c118fc0870557d1bd9ee01a743",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Pulkit Verma",
      "Shashank Rao Marpally",
      "Siddharth Srivastava"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17429": {
    "title": "Competitive Analysis for Two-Level Ski-Rental Problem",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b4d2551574eca4ad85787b8fd950315db0446dec",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Binghan Wu",
      "Wei Bao",
      "Dong Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17430": {
    "title": "Multi-Decoder Attention Model with Embedding Glimpse for Solving Vehicle Routing Problems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "de741d317507e21d3f7d3f8107d5b685db455aff",
    "semantic_title": "",
    "citation_count": 43,
    "authors": [
      "Liang Xin",
      "Wen Song",
      "Zhiguang Cao",
      "Jie Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17431": {
    "title": "Group Fairness by Probabilistic Modeling with Latent Fair Decisions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2399382f0e0fe4e50a10786cd6b304074906d1ee",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "YooJung Choi",
      "Meihua Dang",
      "Guy Van den Broeck"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17432": {
    "title": "GO Hessian for Expectation-Based Objectives",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "fc6f2fddd21f0a638ec8cfd26573ce908dc80e3f",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yulai Cong",
      "Miaoyun Zhao",
      "Jianqiao Li",
      "Junya Chen",
      "Lawrence Carin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17433": {
    "title": "Better Bounds on the Adaptivity Gap of Influence Maximization under Full-adoption Feedback",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1b74f4ac24524bc221a611425b4c77df0cdf79a5",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Gianlorenzo D'Angelo",
      "Debashmita Poddar",
      "Cosimo Vinci"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17434": {
    "title": "Uncertainty Quantification in CNN Through the Bootstrap of Convex Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "39b37e6c3e74907ca3bdb778e4e878f205693c53",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Hongfei Du",
      "Emre Barut",
      "Fang Jin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17435": {
    "title": "Scalable First-Order Methods for Robust MDPs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2b82e54f1620d95e91a8ab240c8081ff9fa889df",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Julien Grand-Cl√©ment",
      "Christian Kroer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17436": {
    "title": "High Dimensional Level Set Estimation with Bayesian Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f7225998cd2c14958701c9c87f5324b88b6237b9",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Huong Ha",
      "Sunil Gupta",
      "Santu Rana",
      "Svetha Venkatesh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17437": {
    "title": "A Generative Adversarial Framework for Bounding Confounded Causal Effects",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f8a27911dff2050b9f0a608bad555df8a0ce34d3",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Yaowei Hu",
      "Yongkai Wu",
      "Lu Zhang",
      "Xintao Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17438": {
    "title": "Estimating Identifiable Causal Effects through Double Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e61043229980ac73333ec8cb9afd75ecc3694895",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Yonghan Jung",
      "Jin Tian",
      "Elias Bareinboim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17439": {
    "title": "Relational Boosted Bandits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "36cfdf79c7140afaeff94f15849ae4774dc7f2c1",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Ashutosh Kakadiya",
      "Sriraam Natarajan",
      "Balaraman Ravindran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17440": {
    "title": "Instrumental Variable-based Identification for Causal Effects using Covariate Information",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9a4df35258c73d1151dc2d249be9cbb3fa42d3cb",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuta Kawakami"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17441": {
    "title": "Learning Continuous High-Dimensional Models using Mutual Information and Copula Bayesian Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e69143d71a1a71df0648d91ecd369df1560931d7",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Marvin Lasserre",
      "R√©gis Lebrun",
      "Pierre-Henri Wuillemin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17442": {
    "title": "Submodel Decomposition Bounds for Influence Diagrams",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4887823ddab3ae231ece6ed10953d6055830115b",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Junkyu Lee",
      "Radu Marinescu",
      "Rina Dechter"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17443": {
    "title": "A New Bounding Scheme for Influence Diagrams",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "480cabaef43a4cebc9b76f32083eaecdec97f630",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Radu Marinescu",
      "Junkyu Lee",
      "Rina Dechter"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17444": {
    "title": "Estimation of Spectral Risk Measures",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "20ab1b5396ce86610301e358e397397bfa0d112e",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Ajay Kumar Pandey",
      "Prashanth L.A.",
      "Sanjay P. Bhat"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17445": {
    "title": "Probabilistic Dependency Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "343e8db7641a839871fbdd99248ac2f4bc11a77c",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oliver Richardson",
      "Joseph Y Halpern"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17446": {
    "title": "Robust Contextual Bandits via Bootstrapping",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "043f436601ab95cf2e85985ef71e413ef6bceb6f",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Qiao Tang",
      "Hong Xie",
      "Yunni Xia",
      "Jia Lee",
      "Qingsheng Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17447": {
    "title": "Learning the Parameters of Bayesian Networks from Uncertain Data",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1f2834023db96d465b99f4b3ff91001122aa7fab",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Segev Wasserkrug",
      "Radu Marinescu",
      "Sergey Zeltyn",
      "Evgeny Shindin",
      "Yishai A Feldman"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17448": {
    "title": "Polynomial-Time Algorithms for Counting and Sampling Markov Equivalent DAGs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6b80dea61e74a65b9ab0b0590932a3dc175f1755",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Marcel Wien√∂bst",
      "Max Bannach",
      "Maciej Liskiewicz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17449": {
    "title": "Bounding Causal Effects on Continuous Outcome",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1e3ce576c8ae00f99cb8195d83248921e7f82eb4",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Junzhe Zhang",
      "Elias Bareinboim"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17450": {
    "title": "A Fast Exact Algorithm for the Resource Constrained Shortest Path Problem",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "76cf81c91246e11cde6ad4d434b529b63a09cc2d",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Saman Ahmadi",
      "Guido Tack",
      "Daniel D. Harabor",
      "Philip Kilby"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17451": {
    "title": "Generalization in Portfolio-Based Algorithm Selection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "96cf13802df40124a8053530187e2879f6137699",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Maria-Florina Balcan",
      "Tuomas Sandholm",
      "Ellen Vitercik"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17452": {
    "title": "Combining Preference Elicitation with Local Search and Greedy Search for Matroid Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5f0ffbe98dbf70951fecde8abf1f631bd4c382a5",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nawal Benabbou",
      "Cassandre Leroy",
      "Thibaut Lust",
      "Patrice Perny"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17453": {
    "title": "f-Aware Conflict Prioritization & Improved Heuristics For Conflict-Based Search",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2c212e5fbe53e1bc2ea7459d571f139281f0a38a",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Eli Boyarski",
      "Ariel Felner",
      "Pierre Le Bodic",
      "Daniel D. Harabor",
      "Peter J. Stuckey",
      "Sven Koenig"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17454": {
    "title": "Parameterized Algorithms for MILPs with Small Treedepth",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cb51f9ec601572e2c5e391534b38f689685a8739",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Cornelius Brand",
      "Martin Kouteck√Ω",
      "Sebastian Ordyniak"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17455": {
    "title": "NuQClq: An Effective Local Search Algorithm for Maximum Quasi-Clique Problem",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2e6201e954c4f2435bb137b2ce387e5a68a3da1d",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Jiejiang Chen",
      "Shaowei Cai",
      "Shiwei Pan",
      "Yiyuan Wang",
      "Qingwei Lin",
      "Mengyu Zhao",
      "Minghao Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17456": {
    "title": "Symmetry Breaking for k-Robust Multi-Agent Path Finding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cdcca6a68b10d2672099e16af035f90dd0792d12",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Zhe Chen",
      "Daniel D. Harabor",
      "Jiaoyang Li",
      "Peter J. Stuckey"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17457": {
    "title": "Escaping Local Optima with Non-Elitist Evolutionary Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "14a49ead8a24423c9598e0c792c696fa3f760d4c",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Duc-Cuong Dang",
      "Anton Eremeev",
      "Per Kristian Lehre"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17458": {
    "title": "Pareto Optimization for Subset Selection with Dynamic Partition Matroid Constraints",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bb150dc58656ab6f495506bee6a187516a430539",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Anh Viet Do",
      "Frank Neumann"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17459": {
    "title": "Theoretical Analyses of Multi-Objective Evolutionary Algorithms on Multi-Modal Objectives",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9ecc5c23d24948c424020207f0d1bf7cfc93c88e",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Benjamin Doerr",
      "Weijie Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17460": {
    "title": "Multi-Objective Submodular Maximization by Regret Ratio Minimization with Theoretical Guarantee",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0ce43f1576466a73472f3adf4bda1ed6cb2a61cb",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Chao Feng",
      "Chao Qian"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17461": {
    "title": "Choosing the Initial State for Online Replanning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e3148251691d6e0441f355d3046d240d31ed25f8",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximilian Fickert",
      "Ivan Gavran",
      "Ivan Fedotov",
      "J√∂rg Hoffmann",
      "Rupak Majumdar",
      "Wheeler Ruml"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17462": {
    "title": "OpEvo: An Evolutionary Method for Tensor Operator Optimization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "41c352407d7d7c2b7fa6c5f16e1dc8aecc9b1bfa",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Xiaotian Gao",
      "Wei Cui",
      "Lintao Zhang",
      "Mao Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17463": {
    "title": "Efficient Bayesian Network Structure Learning via Parameterized Local Search on Topological Orderings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "94a2e73abca47f576aecc4022e51573afdf7a7f7",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Niels Gr√ºttemeier",
      "Christian Komusiewicz",
      "Nils Morawietz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17464": {
    "title": "Enhancing Balanced Graph Edge Partition with Effective Local Search",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b7db8bb8309d420e1a0321888d209ae2d1481c55",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Zhenyu Guo",
      "Mingyu Xiao",
      "Yi Zhou",
      "Dongxiang Zhang",
      "Kian-Lee Tan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17465": {
    "title": "Submodular Span, with Applications to Conditional Data Summarization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "aa9b3a19ed77362e189f45059f7b8f896eda84e2",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Lilly Kumari",
      "Jeff Bilmes"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17466": {
    "title": "EECBS: A Bounded-Suboptimal Search for Multi-Agent Path Finding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0a36a23ec07e9702fc8359a3219cda9f5930d1e3",
    "semantic_title": "",
    "citation_count": 40,
    "authors": [
      "Jiaoyang Li",
      "Wheeler Ruml",
      "Sven Koenig"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17467": {
    "title": "Correlation-Aware Heuristic Search for Intelligent Virtual Machine Provisioning in Cloud Systems",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "346e3de297015181647ff602c81d7f36fdd115a5",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Chuan Luo",
      "Bo Qiao",
      "Wenqian Xing",
      "Xin Chen",
      "Pu Zhao",
      "Chao Du",
      "Randolph Yao",
      "Hongyu Zhang",
      "Wei Wu",
      "Shaowei Cai",
      "Bing He",
      "Saravanakumar Rajmohan",
      "Qingwei Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17468": {
    "title": "Single Player Monte-Carlo Tree Search Based on the Plackett-Luce Model",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e79038eda1a4c1e1209536b4f874d51d05852540",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Felix Mohr",
      "Viktor Bengs",
      "Eyke H√ºllermeier"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17469": {
    "title": "Policy-Guided Heuristic Search with Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "53ae4b740f4a870004f9f840a731a0e051eb2b95",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Laurent Orseau",
      "Levi H. S. Lelis"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17470": {
    "title": "Deep Innovation Protection: Confronting the Credit Assignment Problem in Training Heterogeneous Neural Architectures",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "52a80c8c7c65eb05212fa5bf4c45f5aaf88e2ee3",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sebastian Risi",
      "Kenneth O. Stanley"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17471": {
    "title": "Weighting-based Variable Neighborhood Search for Optimal Camera Placement",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3c6e1d6b759277688087ed0c140446e8fc1d5fe7",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Zhouxing Su",
      "Qingyun Zhang",
      "Zhipeng L√º",
      "Chu-Min Li",
      "Weibo Lin",
      "Fuda Ma"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17472": {
    "title": "Multi-Goal Multi-Agent Path Finding via Decoupled and Integrated Goal Vertex Ordering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d7e67462f756d2a6b759586bb763e2f3934e6f9b",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Pavel Surynek"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17473": {
    "title": "Bayes DistNet - A Robust Neural Network for Algorithm Runtime Distribution Predictions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "07f4a05faca7e8b7879d7e46820db538434a7e35",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jake Tuero",
      "Michael Buro"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17474": {
    "title": "Learning Branching Heuristics for Propositional Model Counting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8411a6d999fbb2e422d954f2fbd0489d78c65a7e",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Pashootan Vaezipoor",
      "Gil Lederman",
      "Yuhuai Wu",
      "Chris Maddison",
      "Roger B Grosse",
      "Sanjit A. Seshia",
      "Fahiem Bacchus"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17475": {
    "title": "Accelerated Combinatorial Search for Outlier Detection with Provable Bound on Sub-Optimality",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "18dea15ad30c38e4324418761e419494e0cff463",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Guihong Wan",
      "Haim Schweitzer"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17476": {
    "title": "Combining Reinforcement Learning with Lin-Kernighan-Helsgaun Algorithm for the Traveling Salesman Problem",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "87fa4e906465fc2d8f8331a3165a9fe3ba05ed91",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Jiongzhi Zheng",
      "Kun He",
      "Jianrong Zhou",
      "Yan Jin",
      "Chu-Min Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17477": {
    "title": "Improving Maximum k-plex Solver via Second-Order Reduction and Graph Color Bounding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d7a47519acc45e50b73f4183ed4d0e2f0d181c21",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Yi Zhou",
      "Shan Hu",
      "Mingyu Xiao",
      "Zhang-Hua Fu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17478": {
    "title": "GATE: Graph Attention Transformer Encoder for Cross-lingual Relation and Event Extraction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9af8f2bba51c76fe7fcc1eec5b57b5445747b5ad",
    "semantic_title": "",
    "citation_count": 48,
    "authors": [
      "Wasi Uddin Ahmad",
      "Nanyun Peng",
      "Kai-Wei Chang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17479": {
    "title": "Empirical Regularization for Synthetic Sentence Pairs in Unsupervised Neural Machine Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "44c7c1d2a845811fca211593006ab88bf2168d14",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Xi Ai",
      "Bin Fang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17480": {
    "title": "Segmentation of Tweets with URLs and its Applications to Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3b001c4708d5634825e14b5c04478b920d677004",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Abdullah Aljebreen",
      "Weiyi Meng",
      "Eduard Dragut"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17481": {
    "title": "Unsupervised Opinion Summarization with Content Planning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ac1154a263a88a0b247c15ebea52992712a379ac",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Reinald Kim Amplayo",
      "Stefanos Angelidis",
      "Mirella Lapata"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17482": {
    "title": "Enhancing Scientific Papers Summarization with Citation Graph",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9791dad11215144aad97bc86a261b926e412cd04",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Chenxin An",
      "Ming Zhong",
      "Yiran Chen",
      "Danqing Wang",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17483": {
    "title": "Multi-Dimensional Explanation of Target Variables from Documents",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2d300be18d703f1583716f81c91cf90e9f830c9a",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Diego Antognini",
      "Claudiu Musat",
      "Boi Faltings"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17484": {
    "title": "Joint Semantic Analysis with Document-Level Cross-Task Coherence Rewards",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "506d05bf93b0807ae17ac990584d7aa5895c0f91",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Rahul Aralikatte",
      "Mostafa Abdou",
      "Heather C Lent",
      "Daniel Hershcovich",
      "Anders S√∏gaard"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17485": {
    "title": "Segatron: Segment-Aware Transformer for Language Modeling and Understanding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "320efa53dea3e8f836790682fbd4196132c49749",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "He Bai",
      "Peng Shi",
      "Jimmy Lin",
      "Yuqing Xie",
      "Luchen Tan",
      "Kun Xiong",
      "Wen Gao",
      "Ming Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17486": {
    "title": "Learning to Copy Coherent Knowledge for Response Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "209e0af76a6eb58dd08fa28e578202d80b1e1a8e",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Jiaqi Bai",
      "Ze Yang",
      "Xinnian Liang",
      "Wei Wang",
      "Zhoujun Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17487": {
    "title": "Contextualized Rewriting for Text Summarization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3fcc7e3e49a352209db9ae2270182a281a997fca",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Guangsheng Bao",
      "Yue Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17488": {
    "title": "Knowledge-driven Natural Language Understanding of English Text and its Applications",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ae3d6eb676079d67068cbef2dcac7bcd220e3803",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Kinjal Basu",
      "Sarat Chandra Varanasi",
      "Farhad Shakerin",
      "Joaqu√≠n Arias",
      "Gopal Gupta"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17489": {
    "title": "One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "25e7c9dcc294d77d184c4c1122c8304cdb58c69d",
    "semantic_title": "",
    "citation_count": 83,
    "authors": [
      "Michele Bevilacqua",
      "Rexhina Blloshmi",
      "Roberto Navigli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17490": {
    "title": "Benchmarking Knowledge-Enhanced Commonsense Question Answering via Knowledge-to-Text Transformation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cc1adf2d74d1392cdba5ffa2841bdf9c6bc52bac",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Ning Bian",
      "Xianpei Han",
      "Bo Chen",
      "Le Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17491": {
    "title": "Multilingual Transfer Learning for QA using Translation as Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "364a25604e054f32924ff08acc234d993da7114f",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Mihaela Bornea",
      "Lin Pan",
      "Sara Rosenthal",
      "Radu Florian",
      "Avirup Sil"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17492": {
    "title": "Learning to Rationalize for Nonmonotonic Reasoning with Distant Supervision",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3a1311fbba348a13857f54b92c24be4ee75d1b41",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Faeze Brahman",
      "Vered Shwartz",
      "Rachel Rudinger",
      "Yejin Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17493": {
    "title": "Brain Decoding Using fNIRS",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e4549cf0815d711c84c91f5b9f097b8b6f9e6282",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Lu Cao",
      "Dandan Huang",
      "Yue Zhang",
      "Xiaowei Jiang",
      "Yanan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17494": {
    "title": "Extracting Zero-shot Structured Information from Form-like Documents: Pretraining with Keys and Triggers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "65f6b1a72305ad9fbccda4016dbba75d2276ac7f",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Rongyu Cao",
      "Ping Luo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17495": {
    "title": "Simple or Complex? Learning to Predict Readability of Bengali Texts",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0174d608bd44ad7148e1c44612f8f31cfd9f3c42",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Susmoy Chakraborty",
      "Mir Tafseer Nayeem",
      "Wasi Uddin Ahmad"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17496": {
    "title": "Lexically Constrained Neural Machine Translation with Explicit Alignment Guidance",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "90fd2506e5b7f51f7ffb4c0d90371555a0d66e11",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Guanhua Chen",
      "Yun Chen",
      "Victor O.K. Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17497": {
    "title": "Aspect-Level Sentiment-Controllable Review Generation with Mutual Learning Framework",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4cf93bb0ed726ecdf74245dae6a24818b39d7c01",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Huimin Chen",
      "Yankai Lin",
      "Fanchao Qi",
      "Jinyi Hu",
      "Peng Li",
      "Jie Zhou",
      "Maosong Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17498": {
    "title": "Weakly-Supervised Hierarchical Models for Predicting Persuasive Strategies in Good-faith Textual Requests",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaao Chen",
      "Diyi Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17499": {
    "title": "A Lightweight Neural Model for Biomedical Entity Linking",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "456384ecaacca4cacce6ffc5a087809b2bde92cf",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Lihu Chen",
      "Ga√´l Varoquaux",
      "Fabian M. Suchanek"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17500": {
    "title": "Bidirectional Machine Reading Comprehension for Aspect Sentiment Triplet Extraction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "13e1a9324351b25de11a102066d804a31963147d",
    "semantic_title": "",
    "citation_count": 46,
    "authors": [
      "Shaowei Chen",
      "Yu Wang",
      "Jie Liu",
      "Yuelin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17501": {
    "title": "Empower Distantly Supervised Relation Extraction with Collaborative Adversarial Training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b8f8740a12b434fad45d9cc71cdbc85f05fc2e73",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Tao Chen",
      "Haochen Shi",
      "Liyuan Liu",
      "Siliang Tang",
      "Jian Shao",
      "Zhigang Chen",
      "Yueting Zhuang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17502": {
    "title": "Reasoning in Dialog: Improving Response Generation by Context Reading Comprehension",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bd64364e7f14086545a968b2291e785b75b4368b",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Xiuying Chen",
      "Zhi Cui",
      "Jiayi Zhang",
      "Chen Wei",
      "Jianwei Cui",
      "Bin Wang",
      "Dongyan Zhao",
      "Rui Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17503": {
    "title": "Meta-Transfer Learning for Low-Resource Abstractive Summarization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b4eb84ca50148be183b6ef235613d6d4b5f2970b",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Yi-Syuan Chen",
      "Hong-Han Shuai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17504": {
    "title": "Adaptive Prior-Dependent Correction Enhanced Reinforcement Learning for Natural Language Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c3f28cf8481e42117a54a243103b38fc3710ba6e",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Wei Cheng",
      "Ziyan Luo",
      "Qiyue Yin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17505": {
    "title": "How Linguistically Fair Are Multilingual Pre-Trained Language Models?",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5d52007c26a88b5754962a6600c3f6cc5b34ac30",
    "semantic_title": "",
    "citation_count": 24,
    "authors": [
      "Monojit Choudhury",
      "Amit Deshpande"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17506": {
    "title": "DirectQE: Direct Pretraining for Machine Translation Quality Estimation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cefc6e55d53a4c46c9be4074e5803bf5e3b3d8c2",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Qu Cui",
      "Shujian Huang",
      "Jiahuan Li",
      "Xiang Geng",
      "Zaixiang Zheng",
      "Guoping Huang",
      "Jiajun Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17507": {
    "title": "We Can Explain Your Research in Layman's Terms: Towards Automating Science Journalism at Scale",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ac4e70290f02dc89b9dfcf6c6dfb7f49fbc6068c",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Rumen Dangovski",
      "Michelle Shen",
      "Dawson Byrd",
      "Li Jing",
      "Desislava Tsvetkova",
      "Preslav Nakov",
      "Marin Soljaƒçiƒá"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17508": {
    "title": "Consecutive Decoding for Speech-to-text Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b23c06dcd89458781de94498522f3624c45bf630",
    "semantic_title": "",
    "citation_count": 23,
    "authors": [
      "Qianqian Dong",
      "Mingxuan Wang",
      "Hao Zhou",
      "Shuang Xu",
      "Bo Xu",
      "Lei Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17509": {
    "title": "Listen, Understand and Translate: Triple Supervision Decouples End-to-end Speech-to-text Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8efacdc573c47a56f2ef43067f602e61e77688d5",
    "semantic_title": "",
    "citation_count": 34,
    "authors": [
      "Qianqian Dong",
      "Rong Ye",
      "Mingxuan Wang",
      "Hao Zhou",
      "Shuang Xu",
      "Bo Xu",
      "Lei Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17510": {
    "title": "MultiTalk: A Highly-Branching Dialog Testbed for Diverse Conversations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b00674d4e14ef655a16e74a24dfef32664064587",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Yao Dou",
      "Maxwell Forbes",
      "Ari Holtzman",
      "Yejin Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17511": {
    "title": "Knowledge-aware Leap-LSTM: Integrating Prior Knowledge into Leap-LSTM towards Faster Long Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c461d1399783a11ffe2056f6bc5955703b26ecdd",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Jinhua Du",
      "Yan Huang",
      "Karo Moilanen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17512": {
    "title": "FILTER: An Enhanced Fusion Method for Cross-lingual Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "738aeff1122e7a10f32b20ab73957f6adb3fadb7",
    "semantic_title": "",
    "citation_count": 42,
    "authors": [
      "Yuwei Fang",
      "Shuohang Wang",
      "Zhe Gan",
      "Siqi Sun",
      "Jingjing Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17513": {
    "title": "Rethinking Boundaries: End-To-End Recognition of Discontinuous Mentions with Pointer Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "24f8c6870af78a65929dcf926691e4cbe95d94e6",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Hao Fei",
      "Donghong Ji",
      "Bobo Li",
      "Yijiang Liu",
      "Yafeng Ren",
      "Fei Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17514": {
    "title": "Encoder-Decoder Based Unified Semantic Role Labeling with Label-Aware Syntax",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c5a2f957e5323962b5ff15703eeeed08b68f8242",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Hao Fei",
      "Fei Li",
      "Bobo Li",
      "Donghong Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17515": {
    "title": "End-to-end Semantic Role Labeling with Neural Transition-based Model",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4ec3ad4df9b5b856184def79404312958d9f0fe5",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Hao Fei",
      "Meishan Zhang",
      "Bobo Li",
      "Donghong Ji"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17516": {
    "title": "Multi-View Feature Representation for Dialogue Generation with Bidirectional Distillation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a117c412a4b7cd379a43f4090d4f188d73ab5c89",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Shaoxiong Feng",
      "Xuancheng Ren",
      "Kan Li",
      "Xu Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17517": {
    "title": "More the Merrier: Towards Multi-Emotion and Intensity Controllable Response Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "03c09f47492c8b9ea04903f85d68279571f6609d",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Mauajama Firdaus",
      "Hardik Chauhan",
      "Asif Ekbal",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17518": {
    "title": "LRC-BERT: Latent-representation Contrastive Knowledge Distillation for Natural Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4c3b044cc98def3defc3d562e5c0d811f7b0d200",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Hao Fu",
      "Shaojun Zhou",
      "Qihong Yang",
      "Junjie Tang",
      "Guiquan Liu",
      "Kaikui Liu",
      "Xiaolong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17519": {
    "title": "Nested Named Entity Recognition with Partially-Observed TreeCRFs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5dfcc1f19a22c3bc081f2ff4410eb1efc7061838",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Yao Fu",
      "Chuanqi Tan",
      "Mosha Chen",
      "Songfang Huang",
      "Fei Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17520": {
    "title": "A Theoretical Analysis of the Repetition Problem in Text Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7ade458d52d2dfe997b8a617a6b524bda12a619d",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Zihao Fu",
      "Wai Lam",
      "Anthony Man-Cho So",
      "Bei Shi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17521": {
    "title": "Paragraph-level Commonsense Transformers with Recurrent Memory",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5dfc43bb697acf5eacf8b8a05d78dba8beb0dd42",
    "semantic_title": "",
    "citation_count": 24,
    "authors": [
      "Saadia Gabriel",
      "Chandra Bhagavatula",
      "Vered Shwartz",
      "Ronan Le Bras",
      "Maxwell Forbes",
      "Yejin Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17522": {
    "title": "Judgment Prediction via Injecting Legal Knowledge into Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "29032fcf25284fb3de81b0db02e4638d2aafb054",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Leilei Gan",
      "Kun Kuang",
      "Yi Yang",
      "Fei Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17523": {
    "title": "Question-Driven Span Labeling Model for Aspect‚ÄìOpinion Pair Extraction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eccf59850f2a2433cc546b3e7e278d42825eec15",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Lei Gao",
      "Yulong Wang",
      "Tongcun Liu",
      "Jingyu Wang",
      "Lei Zhang",
      "Jianxin Liao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17524": {
    "title": "Analogy Training Multilingual Encoders",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d61509614b158961638256b9f007851f3925fc74",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Nicolas Garneau",
      "Mareike Hartmann",
      "Anders Sandholm",
      "Sebastian Ruder",
      "Ivan Vuliƒá",
      "Anders S√∏gaard"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17525": {
    "title": "Fake it Till You Make it: Self-Supervised Semantic Shifts for Monolingual Word Embedding Tasks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "99c74738730ed6a46f609e426b6a02119ef6f54e",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Maur√≠cio Gruppi",
      "Pin-Yu Chen",
      "Sibel Adali"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17526": {
    "title": "Perception Score: A Learned Metric for Open-ended Text Generation Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c21075b86fe0608dee44c11e7667ac5b09cd4b0b",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Jing Gu",
      "Qingyang Wu",
      "Zhou Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17527": {
    "title": "DialogBERT: Discourse-Aware Response Generation via Learning to Recover and Rank Utterances",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "138622fff5cd7c6023a8b874958a0a0c857f9d41",
    "semantic_title": "",
    "citation_count": 45,
    "authors": [
      "Xiaodong Gu",
      "Kang Min Yoo",
      "Jung-Woo Ha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17528": {
    "title": "Read, Retrospect, Select: An MRC Framework to Short Text Entity Linking",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "14c121c8975628653cb635a628aa0d38795437ee",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Yingjie Gu",
      "Xiaoye Qu",
      "Zhefeng Wang",
      "Baoxing Huai",
      "Nicholas Jing Yuan",
      "Xiaolin Gui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17529": {
    "title": "Label Confusion Learning to Enhance Text Classification Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e4f70b3f601eacad372426a572e196034ec940be",
    "semantic_title": "",
    "citation_count": 31,
    "authors": [
      "Biyang Guo",
      "Songqiao Han",
      "Xiao Han",
      "Hailiang Huang",
      "Ting Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17530": {
    "title": "Iterative Utterance Segmentation for Neural Semantic Parsing",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7344ed64d1717780422fd1d58fae85edc544d180",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Yinuo Guo",
      "Zeqi Lin",
      "Jian-Guang Lou",
      "Dongmei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17531": {
    "title": "BERT & Family Eat Word Salad: Experiments with Text Understanding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7defc117a11c16fb70bea6cbc0b58e48244992c8",
    "semantic_title": "",
    "citation_count": 42,
    "authors": [
      "Ashim Gupta",
      "Giorgi Kvernadze",
      "Vivek Srikumar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17532": {
    "title": "Sketch and Customize: A Counterfactual Story Generator",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9e329bc6d33fa31a8f51563ee632e3962d3f624b",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Changying Hao",
      "Liang Pang",
      "Yanyan Lan",
      "Yan Wang",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17533": {
    "title": "Self-Attention Attribution: Interpreting Information Interactions Inside Transformer",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "02465d57f63a2d8ed4082136d8e1b7db300105d2",
    "semantic_title": "",
    "citation_count": 78,
    "authors": [
      "Yaru Hao",
      "Li Dong",
      "Furu Wei",
      "Ke Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17534": {
    "title": "Humor Knowledge Enriched Transformer for Understanding Multimodal Humor",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1f2564e03580d5424cbd65f1b7585e19b665784d",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Md Kamrul Hasan",
      "Sangwu Lee",
      "Wasifur Rahman",
      "Amir Zadeh",
      "Rada Mihalcea",
      "Louis-Philippe Morency",
      "Ehsan Hoque"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17535": {
    "title": "Synchronous Interactive Decoding for Multilingual Neural Machine Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1bf0d2d915600c8204505c012f3a56c0c6a2f898",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Hao He",
      "Qian Wang",
      "Zhipeng Yu",
      "Yang Zhao",
      "Jiajun Zhang",
      "Chengqing Zong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17536": {
    "title": "Show Me How To Revise: Improving Lexically Constrained Sentence Generation with XLNet",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "507b45c939c123cd6c308ba4258287962efc0cd8",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Xingwei He",
      "Victor O.K. Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17537": {
    "title": "Towards Fully Automated Manga Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a8302a61f49bbf1e702d417c4122dfbc729a4985",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Ryota Hinami",
      "Shonosuke Ishiwatari",
      "Kazuhiko Yasuda",
      "Yusuke Matsui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17538": {
    "title": "SMART: A Situation Model for Algebra Story Problems via Attributed Grammar",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "593ca71119fb6ee560926d9b304bde095267432d",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Yining Hong",
      "Qing Li",
      "Ran Gong",
      "Daniel Ciao",
      "Siyuan Huang",
      "Song-Chun Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17539": {
    "title": "It Takes Two to Empathize: One to Seek and One to Provide",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "32b0473e48a29a63bcbbafb4e8f11c4b0392a660",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Mahshid Hosseini",
      "Cornelia Caragea"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17540": {
    "title": "C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot Filling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c326c1d6f154bbc9822f900ddcf42f482ec9c611",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Yutai Hou",
      "Sanyuan Chen",
      "Wanxiang Che",
      "Cheng Chen",
      "Ting Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17541": {
    "title": "Few-shot Learning for Multi-label Intent Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6c6dc8cfda89fb6f90073cbee1ea82e744477460",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Yutai Hou",
      "Yongkui Lai",
      "Yushan Wu",
      "Wanxiang Che",
      "Ting Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17542": {
    "title": "HARGAN: Heterogeneous Argument Attention Network for Persuasiveness Prediction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "596d7047fc2ef773ce19d96c802bc973263e363d",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Kuo-Yu Huang",
      "Hen-Hsen Huang",
      "Hsin-Hsi Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17543": {
    "title": "SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete Utterance Restoration",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "69c515a62403fcc19125d3a6dd8e878aa5cde604",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Mengzuo Huang",
      "Feng Li",
      "Wuhe Zou",
      "Weidong Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17544": {
    "title": "Entity Guided Question Generation with Contextual Structure and Sequence Information Capturing",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "647ae2208f4c40b21979ec9a2a877867b659eb6b",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Qingbao Huang",
      "Mingyi Fu",
      "Linzhang Mo",
      "Yi Cai",
      "Jingyun Xu",
      "Pijian Li",
      "Qing Li",
      "Ho-fung Leung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17545": {
    "title": "Story Ending Generation with Multi-Level Graph Convolutional Networks over Dependency Trees",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "85c92bf6ea10d9ce3993005a869fba4f4ff94993",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Qingbao Huang",
      "Linzhang Mo",
      "Pijian Li",
      "Yi Cai",
      "Qingguang Liu",
      "Jielong Wei",
      "Qing Li",
      "Ho-fung Leung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17546": {
    "title": "Adaptive Beam Search Decoding for Discrete Keyphrase Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cdf612e33935a872ab485d7d7d302d64be258a58",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Xiaoli Huang",
      "Tongge Xu",
      "Lvan Jiao",
      "Yueran Zu",
      "Youmin Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17547": {
    "title": "Distribution Matching for Rationalization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "145cbeaa23e8feba769e74ab2f7ab5b76103bdc1",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Yongfeng Huang",
      "Yujun Chen",
      "Yulun Du",
      "Zhilin Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17548": {
    "title": "Audio-Oriented Multimodal Machine Comprehension via Dynamic Inter- and Intra-modality Attention",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d844cd7ab3e922a49c0d68f83a9c08bf6566e99b",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Zhiqi Huang",
      "Fenglin Liu",
      "Xian Wu",
      "Shen Ge",
      "Helin Wang",
      "Wei Fan",
      "Yuexian Zou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17549": {
    "title": "Unsupervised Learning of Discourse Structures using a Tree Autoencoder",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2f9b4b450983297628b2970f391481875894acf5",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Patrick Huber",
      "Giuseppe Carenini"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17550": {
    "title": "Dynamic Hybrid Relation Exploration Network for Cross-Domain Context-Dependent Semantic Parsing",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "becc21ab34a7858e9bec469c9329ddacf39472fa",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Binyuan Hui",
      "Ruiying Geng",
      "Qiyu Ren",
      "Binhua Li",
      "Yongbin Li",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Pengfei Zhu",
      "Xiaodan Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17551": {
    "title": "DDRel: A New Dataset for Interpersonal Relation Classification in Dyadic Dialogues",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0c52efb0754b3b9af7a87ade7bdd9ca442d78aed",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Qi Jia",
      "Hongru Huang",
      "Kenny Q. Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17552": {
    "title": "Flexible Non-Autoregressive Extractive Summarization with Threshold: How to Extract a Non-Fixed Number of Summary Sentences",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c542d0d906d0fbf7cd14b24c319f504efb2c35b0",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Ruipeng Jia",
      "Yanan Cao",
      "Haichao Shi",
      "Fang Fang",
      "Pengfei Yin",
      "Shi Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17553": {
    "title": "EQG-RACE: Examination-Type Question Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f84b531135acc19191310537065a804c00814cdd",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Xin Jia",
      "Wenjie Zhou",
      "Xu Sun",
      "Yunfang Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17554": {
    "title": "Hierarchical Macro Discourse Parsing Based on Topic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5c0f536db679417201877f0ce1a9621d5e5b93bd",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Feng Jiang",
      "Yaxin Fan",
      "Xiaomin Chu",
      "Peifeng Li",
      "Qiaoming Zhu",
      "Fang Kong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17555": {
    "title": "FIXMYPOSE: Pose Correctional Captioning and Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "647120ebe1dbcb9f96aefe4e86cc2809cb351be4",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Hyounghun Kim",
      "Abhay Zala",
      "Graham Burri",
      "Mohit Bansal"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17556": {
    "title": "Self-supervised Pre-training and Contrastive Representation Learning for Multiple-choice Video QA",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "40e086bd10391913afb53ac2093a25ae550ba0e4",
    "semantic_title": "",
    "citation_count": 20,
    "authors": [
      "Seonhoon Kim",
      "Seohyeong Jeong",
      "Eunbyul Kim",
      "Inho Kang",
      "Nojun Kwak"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17557": {
    "title": "The Gap on Gap: Tackling the Problem of Differing Data Distributions in Bias-Measuring Datasets",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2fdb8a6089cab6901e75ff12c63dd8cc1aa152ca",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Vid Kocijan",
      "Oana-Maria Camburu",
      "Thomas Lukasiewicz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17558": {
    "title": "SALNet: Semi-supervised Few-Shot Text Classification with Attention-based Lexicon Construction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eb23e9a05943f4713bff1640f35ed3c821c93954",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Ju-Hyoung Lee",
      "Sang-Ki Ko",
      "Yo-Sub Han"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17559": {
    "title": "Multi-SpectroGAN: High-Diversity and High-Fidelity Spectrogram Generation with Adversarial Style Combination for Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2989bdc41227742becd0490ac05fdad2bdfec1f4",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Sang-Hoon Lee",
      "Hyun-Wook Yoon",
      "Hyeong-Rae Noh",
      "Ji-Hoon Kim",
      "Seong-Whan Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17560": {
    "title": "Have We Solved The Hard Problem? It's Not Easy! Contextual Lexical Contrast as a Means to Probe Neural Coherence",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4e9e329fdf664bbee97b669650edd2b44a9a5629",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Wenqiang Lei",
      "Yisong Miao",
      "Runpeng Xie",
      "Bonnie Webber",
      "Meichun Liu",
      "Tat-Seng Chua",
      "Nancy F. Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17561": {
    "title": "Learning Light-Weight Translation Models from Deep Transformer",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a817d740f64dcc04734ece08e20e136ccff240e7",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Bei Li",
      "Ziyang Wang",
      "Hui Liu",
      "Quan Du",
      "Tong Xiao",
      "Chunliang Zhang",
      "Jingbo Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17562": {
    "title": "Improving the Efficiency and Effectiveness for BERT-based Entity Resolution",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e1392ce545ecb839e92cf2587161a446c99019e6",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Bing Li",
      "Yukai Miao",
      "Yaoshu Wang",
      "Yifang Sun",
      "Wei Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17563": {
    "title": "Multi-view Inference for Relation Extraction with Uncertain Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3c5cf01eba95d2ada27344b26ef9a9393a53cf84",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Bo Li",
      "Wei Ye",
      "Canming Huang",
      "Shikun Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17564": {
    "title": "Towards Topic-Aware Slide Generation For Academic Papers With Unsupervised Mutual Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a32d3a98d18872c5e3ca6a425683c39ebd2c977f",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Da-Wei Li",
      "Danqing Huang",
      "Tingting Ma",
      "Chin-Yew Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17565": {
    "title": "The Style-Content Duality of Attractiveness: Learning to Write Eye-Catching Headlines via Disentanglement",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9caceb954c06296e7b8c87735e245c559622ee5d",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Mingzhe Li",
      "Xiuying Chen",
      "Min Yang",
      "Shen Gao",
      "Dongyan Zhao",
      "Rui Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17566": {
    "title": "ACT: an Attentive Convolutional Transformer for Efficient Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "40211ddcc2b2ddf88d7f60bb5ded397c601fe970",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Pengfei Li",
      "Peixiang Zhong",
      "Kezhi Mao",
      "Dongzhe Wang",
      "Xuefeng Yang",
      "Yunfeng Liu",
      "Jianxiong Yin",
      "Simon See"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17567": {
    "title": "Quantum-inspired Neural Network for Conversational Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "66c73652e3e249666ae4cc3abad0b22533d7dee3",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Qiuchi Li",
      "Dimitris Gkoumas",
      "Alessandro Sordoni",
      "Jian-Yun Nie",
      "Massimo Melucci"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17568": {
    "title": "HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "64435711f6542aa6b53e95c6e084a0ccd2ec1c16",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Shaobo Li",
      "Xiaoguang Li",
      "Lifeng Shang",
      "Xin Jiang",
      "Qun Liu",
      "Chengjie Sun",
      "Zhenzhou Ji",
      "Bingquan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17569": {
    "title": "Merging Statistical Feature via Adaptive Gate for Improved Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "31948894774ee1e14ca4db9a2deffc53793a4d7f",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Xianming Li",
      "Zongxi Li",
      "Haoran Xie",
      "Qing Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17570": {
    "title": "TSQA: Tabular Scenario Based Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "084c5afc5b16b0c50c53390f550a13f4ed4c7d3c",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Xiao Li",
      "Yawei Sun",
      "Gong Cheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17571": {
    "title": "Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous Rendering Machines",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "243b7fe83c29da8619548d4e8a2379accdf8334e",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Yangming Li",
      "Kaisheng Yao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17572": {
    "title": "An Efficient Transformer Decoder with Compressed Sub-layers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "46cb1ec4aa7810ab89da259e96f46b5db268193b",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Yanyang Li",
      "Ye Lin",
      "Tong Xiao",
      "Jingbo Zhu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17573": {
    "title": "An Unsupervised Sampling Approach for Image-Sentence Matching Using Document-level Structural Information",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a70339875036e618579e1156aa8be630364455d1",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Zejun Li",
      "Zhongyu Wei",
      "Zhihao Fan",
      "Haijun Shan",
      "Xuanjing Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17574": {
    "title": "Finding Sparse Structures for Domain Specific Neural Machine Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e8bf6e0f1a1ea7f7d145cbe8782066a2d977d7e2",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Jianze Liang",
      "Chengqi Zhao",
      "Mingxuan Wang",
      "Xipeng Qiu",
      "Lei Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17575": {
    "title": "Infusing Multi-Source Knowledge with Heterogeneous Graph Neural Network for Emotional Conversation Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1ce3dcfea8ac53981085b17cc0466a1908adf6e0",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Yunlong Liang",
      "Fandong Meng",
      "Ying Zhang",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17576": {
    "title": "Hierarchical Coherence Modeling for Document Quality Assessment",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c81eeb8e657476860b1b76c0a9d0024cab61821b",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Dongliang Liao",
      "Jin Xu",
      "Gongfu Li",
      "Yiru Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17577": {
    "title": "Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2ad565fb0ce9cda15a9e5ce37b5678ec09b134b9",
    "semantic_title": "",
    "citation_count": 23,
    "authors": [
      "Shuai Lin",
      "Pan Zhou",
      "Xiaodan Liang",
      "Jianheng Tang",
      "Ruihui Zhao",
      "Ziliang Chen",
      "Liang Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17578": {
    "title": "Neural Sentence Simplification with Semantic Dependency Information",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0abe0db154f1ce1aea45cbf75f3a36229fff1cba",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Zhe Lin",
      "Xiaojun Wan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17579": {
    "title": "Converse, Focus and Guess - Towards Multi-Document Driven Dialogue",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "76cb4a8e7d5340213297945793367a543d6e55b5",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Han Liu",
      "Caixia Yuan",
      "Xiaojie Wang",
      "Yushu Yang",
      "Huixing Jiang",
      "Zhongyuan Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17580": {
    "title": "Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ffbfce72f12aa0be619be5e49698c2657853409f",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Hanmeng Liu",
      "Leyang Cui",
      "Jian Liu",
      "Yue Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17581": {
    "title": "How to Train Your Agent to Read and Write",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "eae436d899684f2885af7bc68926d490190b6dde",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Li Liu",
      "Mengge He",
      "Guanghui Xu",
      "Mingkui Tan",
      "Qi Wu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17582": {
    "title": "Filling the Gap of Utterance-aware and Speaker-aware Representation for Multi-turn Dialogue",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8f088ede342f2aaaf6de553f4eb741f1585c60c3",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Longxiang Liu",
      "Zhuosheng Zhang",
      "Hai Zhao",
      "Xi Zhou",
      "Xiang Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17583": {
    "title": "Towards Faithfulness in Open Domain Table-to-text Generation from an Entity-centric View",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a8a1ec9fd1ac1a36a256f6b752e21fc2c844cc9c",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Tianyu Liu",
      "Xin Zheng",
      "Baobao Chang",
      "Zhifang Sui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17584": {
    "title": "Faster Depth-Adaptive Transformers",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3e4d4963753f8f1b730bb02eb6cd10aaa83ec4a1",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Yijin Liu",
      "Fandong Meng",
      "Jie Zhou",
      "Yufeng Chen",
      "Jinan Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17585": {
    "title": "A Graph Reasoning Network for Multi-turn Response Selection via Customized Pre-training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9698cff93ec15e4c92b1fccb2332673ef4074899",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Yongkang Liu",
      "Shi Feng",
      "Daling Wang",
      "Kaisong Song",
      "Feiliang Ren",
      "Yifei Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17586": {
    "title": "Generating CCG Categories",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "38cda3ad2e846c89e8972e8bc637741775499dd3",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Yufang Liu",
      "Tao Ji",
      "Yuanbin Wu",
      "Man Lan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17587": {
    "title": "CrossNER: Evaluating Cross-Domain Named Entity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5cb87cd3b1feb8f39e565b1d054d37a3cf38b66c",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Zihan Liu",
      "Yan Xu",
      "Tiezheng Yu",
      "Wenliang Dai",
      "Ziwei Ji",
      "Samuel Cahyawijaya",
      "Andrea Madotto",
      "Pascale Fung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17588": {
    "title": "On the Importance of Word Order Information in Cross-lingual Sequence Labeling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "12cf222b05755a59655a5846f990c2aaf6065086",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Zihan Liu",
      "Genta I Winata",
      "Samuel Cahyawijaya",
      "Andrea Madotto",
      "Zhaojiang Lin",
      "Pascale Fung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17589": {
    "title": "SCRUPLES: A Corpus of Community Ethical Judgments on 32,000 Real-Life Anecdotes",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "090648f65354977762a4624559e7f7b52ae17f58",
    "semantic_title": "",
    "citation_count": 53,
    "authors": [
      "Nicholas Lourie",
      "Ronan Le Bras",
      "Yejin Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17590": {
    "title": "UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "21ec9c0f869bdb33b06c7dbc8880169db0397d08",
    "semantic_title": "",
    "citation_count": 71,
    "authors": [
      "Nicholas Lourie",
      "Ronan Le Bras",
      "Chandra Bhagavatula",
      "Yejin Choi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17591": {
    "title": "Span-Based Event Coreference Resolution",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d7345742e4c3ac99d3dd8087861e6955392276c",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Jing Lu",
      "Vincent Ng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17592": {
    "title": "LET: Linguistic Knowledge Enhanced Graph Transformer for Chinese Short Text Matching",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d8e8e35bf4cf8821ade2d58b34d9ae23a9b08ab2",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Boer Lyu",
      "Lu Chen",
      "Su Zhu",
      "Kai Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17593": {
    "title": "Knowledge-driven Data Construction for Zero-shot Evaluation in Commonsense Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "18e5fb8cec55a75b288a499c57d77ede541dc049",
    "semantic_title": "",
    "citation_count": 52,
    "authors": [
      "Kaixin Ma",
      "Filip Ilievski",
      "Jonathan Francis",
      "Yonatan Bisk",
      "Eric Nyberg",
      "Alessandro Oltramari"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17594": {
    "title": "Generate Your Counterfactuals: Towards Controlled Counterfactual Generation for Text",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "03031d20494b9634b27fc5be6bce203a87383343",
    "semantic_title": "",
    "citation_count": 44,
    "authors": [
      "Nishtha Madaan",
      "Inkit Padhi",
      "Naveen Panwar",
      "Diptikalyan Saha"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17595": {
    "title": "Generating Natural Language Attacks in a Hard Label Black Box Setting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2ef79342ff22661cd7bc18833049085e6b3501c4",
    "semantic_title": "",
    "citation_count": 47,
    "authors": [
      "Rishabh Maheshwary",
      "Saket Maheshwary",
      "Vikram Pudi"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17596": {
    "title": "Bridging Towers of Multi-task Learning with a Gating Mechanism for Aspect-based Sentiment Analysis and Sequential Metaphor Identification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ef8ebdc6892648c61c7803a99373a47d96373294",
    "semantic_title": "",
    "citation_count": 37,
    "authors": [
      "Rui Mao",
      "Xiao Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17597": {
    "title": "A Joint Training Dual-MRC Framework for Aspect Based Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0e021f936adf979f86812d67f32b090acb07d706",
    "semantic_title": "",
    "citation_count": 75,
    "authors": [
      "Yue Mao",
      "Yi Shen",
      "Chao Yu",
      "Longjun Cai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17598": {
    "title": "Variational Inference for Learning Representations of Natural Language Edits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "305cee759c0f62a7568c87754e507d15922f1ade",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Edison Marrese-Taylor",
      "Machel Reid",
      "Yutaka Matsuo"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17599": {
    "title": "How Robust are Model Rankings : A Leaderboard Customization Approach for Equitable Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "656b6de01e9d4ba7e1116bb62d32d76a89078f13",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Swaroop Mishra",
      "Anjana Arunkumar"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17600": {
    "title": "Continual Learning for Named Entity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f4db6705fd899eaf54f700c0bfcea8801ab52a1b",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Natawut Monaikul",
      "Giuseppe Castellucci",
      "Simone Filice",
      "Oleg Rokhlenko"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17601": {
    "title": "MASKER: Masked Keyword Regularization for Reliable Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bdfe6051558414589f8b8b2e0fea596833e845bb",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Seung Jun Moon",
      "Sangwoo Mo",
      "Kimin Lee",
      "Jaeho Lee",
      "Jinwoo Shin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17602": {
    "title": "Disentangled Motif-aware Graph Learning for Phrase Grounding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a83c406324897951013a4128b11b5714bef1f7c5",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Zongshen Mu",
      "Siliang Tang",
      "Jie Tan",
      "Qiang Yu",
      "Yueting Zhuang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17603": {
    "title": "Knowledge-aware Named Entity Recognition with Alleviating Heterogeneity",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dcf03c80c7eeac31401f6b39dd4b3d6d025679fd",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Binling Nie",
      "Ruixue Ding",
      "Pengjun Xie",
      "Fei Huang",
      "Chen Qian",
      "Luo Si"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17604": {
    "title": "Dialog Policy Learning for Joint Clarification and Active Learning Queries",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "551b0d1933254f4f4a47fae81e4990c135ea08eb",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Aishwarya Padmakumar",
      "Raymond J. Mooney"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17605": {
    "title": "The Heads Hypothesis: A Unifying Statistical Approach Towards Understanding Multi-Headed Attention in BERT",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dd24067c396f4b5a6500a71101ff1dc8ccb8811f",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Madhura Pande",
      "Aakriti Budhraja",
      "Preksha Nema",
      "Pratyush Kumar",
      "Mitesh M. Khapra"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17606": {
    "title": "Copy That! Editing Sequences by Copying Spans",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4f985c255a4a0cf76e7bc3c4bd91f16eda0ee9c3",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Sheena Panthaplackel",
      "Miltiadis Allamanis",
      "Marc Brockschmidt"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17607": {
    "title": "Movie Summarization via Sparse Graph Construction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d739bc3eafbac3304be528c706f127dda243dc9c",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Pinelopi Papalampidi",
      "Frank Keller",
      "Mirella Lapata"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17608": {
    "title": "On the Softmax Bottleneck of Recurrent Language Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e124a92d67362dc32d0518b2522f5ae96970916a",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Dwarak Govind  Parthiban",
      "Yongyi Mao",
      "Diana Inkpen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17609": {
    "title": "XL-WSD: An Extra-Large and Cross-Lingual Evaluation Framework for Word Sense Disambiguation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b5b7870f1e565eaba21c056e64fcf4a279b4265b",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Tommaso Pasini",
      "Alessandro Raganato",
      "Roberto Navigli"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17610": {
    "title": "ALP-KD: Attention-Based Layer Projection for Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e339c5d31ffc7029c1f72d567ac07b4606701c72",
    "semantic_title": "",
    "citation_count": 48,
    "authors": [
      "Peyman Passban",
      "Yimeng Wu",
      "Mehdi Rezagholizadeh",
      "Qun Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17611": {
    "title": "Data Augmentation for Abstractive Query-Focused Multi-Document Summarization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "161321ef451d658d66b762cba5c202b12260220e",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Ramakanth Pasunuru",
      "Asli Celikyilmaz",
      "Michel Galley",
      "Chenyan Xiong",
      "Yizhe Zhang",
      "Mohit Bansal",
      "Jianfeng Gao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17612": {
    "title": "Revisiting Mahalanobis Distance for Transformer-Based Out-of-Domain Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9de3e6f471552fade7e17daa9f15df4eb92410af",
    "semantic_title": "",
    "citation_count": 33,
    "authors": [
      "Alexander Podolskiy",
      "Dmitry Lipin",
      "Andrey Bout",
      "Ekaterina Artemova",
      "Irina Piontkovskaya"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17613": {
    "title": "Conceptualized and Contextualized Gaussian Embedding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c0977178c19a2c0f56ae06f3bb89cd24a62daf05",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Chen Qian",
      "Fuli Feng",
      "Lijie Wen",
      "Tat-Seng Chua"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17614": {
    "title": "A Student-Teacher Architecture for Dialog Domain Adaptation Under the Meta-Learning Setting",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f6a8e04e49c2672fe35b2ab99d01445a4c846001",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Kun Qian",
      "Wei Wei",
      "Zhou Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17615": {
    "title": "Exploring Auxiliary Reasoning Tasks for Task-oriented Dialog Systems with Meta Cooperative Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "657edcb784fb9732d53ffd925adb0a41d62aa48b",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Bowen Qin",
      "Min Yang",
      "Lidong Bing",
      "Qingshan Jiang",
      "Chengming Li",
      "Ruifeng Xu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17616": {
    "title": "Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act Recognition and Sentiment Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "af574bff0e9ffd71b0708a22b135012442e33b8d",
    "semantic_title": "",
    "citation_count": 31,
    "authors": [
      "Libo Qin",
      "Zhouyang Li",
      "Wanxiang Che",
      "Minheng Ni",
      "Ting Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17617": {
    "title": "Reinforced History Backtracking for Conversational Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e45404a1787b4633058bd53d318ac9b18c7b5d8d",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Minghui Qiu",
      "Xinjing Huang",
      "Cen Chen",
      "Feng Ji",
      "Chen Qu",
      "Wei Wei",
      "Jun Huang",
      "Yin Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17618": {
    "title": "Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0174a1619b23fd74e6295be4d6231a45c0858f08",
    "semantic_title": "",
    "citation_count": 50,
    "authors": [
      "Qiu Ran",
      "Yankai Lin",
      "Peng Li",
      "Jie Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17619": {
    "title": "Towards Semantics-Enhanced Pre-Training: Can Lexicon Definitions Help Learning Sentence Meanings?",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "50d30457635943b0c54a2d2fa3aba2635cd44f03",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Xuancheng Ren",
      "Xu Sun",
      "Houfeng Wang",
      "Qun Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17620": {
    "title": "Automated Cross-prompt Scoring of Essay Traits",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9cc42b014e7204187f802199e1bbb63ea021c1a2",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Robert Ridley",
      "Liang He",
      "Xin-yu Dai",
      "Shujian Huang",
      "Jiajun Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17621": {
    "title": "Exploring Transfer Learning For End-to-End Spoken Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "95b650f03b0cee507f6bf53f77d81b77bbc06c36",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Subendhu Rongali",
      "Beiye Liu",
      "Liwei Cai",
      "Konstantine Arkoudas",
      "Chengwei Su",
      "Wael Hamza"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17622": {
    "title": "Semantics Altering Modifications for Evaluating Comprehension in Machine Reading",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8c48d08285b78d365741d894aab3bdb2b5ee5dfe",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Viktor Schlegel",
      "Goran Nenadic",
      "Riza Batista-Navarro"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17623": {
    "title": "Learning from the Best: Rationalizing Predictions by Adversarial Information Calibration",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "54c7c7ff7c5ff51f659ad6ad747d505f7d922e0b",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Lei Sha",
      "Oana-Maria Camburu",
      "Thomas Lukasiewicz"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17624": {
    "title": "Nutri-bullets: Summarizing Health Studies by Composing Segments",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e52bf4b4f7d5832abe6436441280a27eea7308ed",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Darsh J Shah",
      "Lili Yu",
      "Tao Lei",
      "Regina Barzilay"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17625": {
    "title": "DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bed629bc6ed311418dc8b870a1ee2b79576066b2",
    "semantic_title": "",
    "citation_count": 72,
    "authors": [
      "Weizhou Shen",
      "Junqing Chen",
      "Xiaojun Quan",
      "Zhixian Xie"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17626": {
    "title": "SongMASS: Automatic Song Writing with Pre-training and Alignment Constraint",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "dc16126c479b8414fa9683709736865485597107",
    "semantic_title": "",
    "citation_count": 29,
    "authors": [
      "Zhonghao Sheng",
      "Kaitao Song",
      "Xu Tan",
      "Yi Ren",
      "Wei Ye",
      "Shikun Zhang",
      "Tao Qin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17627": {
    "title": "Learning Contextual Representations for Semantic Parsing with Generation-Augmented Pre-Training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c75a2ee17056d2b8c14ac25f9f328a09eb4cf040",
    "semantic_title": "",
    "citation_count": 63,
    "authors": [
      "Peng Shi",
      "Patrick Ng",
      "Zhiguo Wang",
      "Henghui Zhu",
      "Alexander Hanbo Li",
      "Jun Wang",
      "Cicero Nogueira dos Santos",
      "Bing Xiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17628": {
    "title": "A Simple and Effective Self-Supervised Contrastive Learning Framework for Aspect Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6a10bba32185c1fa11ebc29ef7a3a814198c2b6c",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Tian Shi",
      "Liuqing Li",
      "Ping Wang",
      "Chandan K. Reddy"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17629": {
    "title": "Fact-Enhanced Synthetic News Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5a36dc9dcb2db5e819c0d433efa5bb670f385266",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Kai Shu",
      "Yichuan Li",
      "Kaize Ding",
      "Huan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17630": {
    "title": "Improving Commonsense Causal Reasoning by Adversarial Training and Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "be5c4cbde12db1c7bb89e3775e41e207aa4f9ed3",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Ieva Stali≈´naitƒó",
      "Philip John Gorinski",
      "Ignacio Iacobacci"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17631": {
    "title": "Re-TACRED: Addressing Shortcomings of the TACRED Dataset",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6b1834da694817f3dfc3c1b48bbe5f9f5fee2854",
    "semantic_title": "",
    "citation_count": 35,
    "authors": [
      "George Stoica",
      "Emmanouil Antonios Platanios",
      "Barnabas Poczos"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17632": {
    "title": "Progressive Multi-task Learning with Controlled Information Flow for Joint Entity and Relation Extraction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4adc6e782e36fd276d7c57a2ae9b36d3585c35f8",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Kai Sun",
      "Richong Zhang",
      "Samuel Mensah",
      "Yongyi Mao",
      "Xudong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17633": {
    "title": "RpBERT: A Text-image Relation Propagation-based BERT Model for Multimodal NER",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b9ad52b670189658851026e03a33063a1b8d47fe",
    "semantic_title": "",
    "citation_count": 27,
    "authors": [
      "Lin  Sun",
      "Jiquan Wang",
      "Kai Zhang",
      "Yindu Su",
      "Fangsheng Weng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17634": {
    "title": "Unsupervised Learning of Deterministic Dialogue Structure with Edge-Enhanced Graph Auto-Encoder",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f2f984eab9e50a73462d1817f91a66c6dab15d77",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Yajing Sun",
      "Yong Shan",
      "Chengguang Tang",
      "Yue Hu",
      "Yinpei Dai",
      "Jing Yu",
      "Jian Sun",
      "Fei Huang",
      "Luo Si"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17635": {
    "title": "VisualMRC: Machine Reading Comprehension on Document Images",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f05126c1a792ea64a7af0c8c68b03bcddec5b297",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Ryota Tanaka",
      "Kyosuke Nishida",
      "Sen Yoshida"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17636": {
    "title": "A Bidirectional Multi-paragraph Reading Model for Zero-shot Entity Linking",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2ec01a0b6dcf2013e108b7b710754ed93a292622",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Hongyin Tang",
      "Xingwu Sun",
      "Beihong Jin",
      "Fuzheng Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17637": {
    "title": "Ideography Leads Us to the Field of Cognition: A Radical-Guided Associative Model for Chinese Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "da154bf3b663b3543ecbd95de136bce3bf29b2af",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Hanqing Tao",
      "Shiwei Tong",
      "Kun Zhang",
      "Tong Xu",
      "Qi Liu",
      "Enhong Chen",
      "Min Hou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17638": {
    "title": "Learning from My Friends: Few-Shot Personalized Conversation Systems via Social Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "763268af8b1bc54754baa885163385980480521c",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Zhiliang Tian",
      "Wei Bi",
      "Zihan Zhang",
      "Dongkyu Lee",
      "Yiping Song",
      "Nevin L. Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17639": {
    "title": "FL-MSRE: A Few-Shot Learning based Approach to Multimodal Social Relation Extraction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cb36a165675613993d9cfbe1a3ec0c5b05ac900b",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Hai Wan",
      "Manrong Zhang",
      "Jianfeng Du",
      "Ziling Huang",
      "Yufei Yang",
      "Jeff Z. Pan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17640": {
    "title": "KEML: A Knowledge-Enriched Meta-Learning Framework for Lexical Relation Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8a6a1ac62b681f4dda5495282b515d111a68cc42",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Chengyu Wang",
      "Minghui Qiu",
      "Jun Huang",
      "Xiaofeng He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17641": {
    "title": "Exploring Explainable Selection to Control Abstractive Summarization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "00f75e193720785c99e26958644e7d6d11960daf",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Haonan Wang",
      "Yang Gao",
      "Yu Bai",
      "Mirella Lapata",
      "Heyan Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17642": {
    "title": "Encoding Syntactic Knowledge in Transformer Encoder for Intent Detection and Slot Filling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c31839ef4294e8b402a79f64e240deba2bd8dc39",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Jixuan  Wang",
      "Kai Wei",
      "Martin Radfar",
      "Weiwei Zhang",
      "Clement Chung"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17643": {
    "title": "Effective Slot Filling via Weakly-Supervised Dual-Model Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c9725862c3db213a6ec70b110342f904298af42d",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Jue Wang",
      "Ke Chen",
      "Lidan Shou",
      "Sai Wu",
      "Gang Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17644": {
    "title": "Tune-In: Training Under Negative Environments with Interference for Attention Networks Simulating Cocktail Party Effect",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3e2940964c67d75903e700efe6c60ac6215603df",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Jun Wang",
      "Max W. Y. Lam",
      "Dan Su",
      "Dong Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17645": {
    "title": "Bridging the Domain Gap: Improve Informal Language Translation via Counterfactual Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "845ca861cb211fefdb49fd3ec4866dc7e93680c3",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Ke Wang",
      "Guandan Chen",
      "Zhongqiang Huang",
      "Xiaojun Wan",
      "Fei Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17646": {
    "title": "Tracking Interaction States for Multi-Turn Text-to-SQL Semantic Parsing",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "849a987959193eed1d0ca9303d2ee9c7359b011a",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Run-Ze Wang",
      "Zhen-Hua Ling",
      "Jingbo Zhou",
      "Yu Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17647": {
    "title": "Generating Diversified Comments via Reader-Aware Topic Modeling and Saliency Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8fa1a99cf07c7d79c12620899f0630e8818cff64",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Wei Wang",
      "Piji Li",
      "Hai-Tao Zheng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17648": {
    "title": "Adversarial Training with Fast Gradient Projection Method against Synonym Substitution Based Text Attacks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2bd24296b8780970ee881d62be9102511b5db99b",
    "semantic_title": "",
    "citation_count": 40,
    "authors": [
      "Xiaosen Wang",
      "Yichen Yang",
      "Yihe Deng",
      "Kun He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17649": {
    "title": "NaturalConv: A Chinese Dialogue Dataset Towards Multi-turn Topic-driven Conversation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bd19fb759a2baca8bb9e998e459954b5a1101981",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Xiaoyang Wang",
      "Chen Li",
      "Jianqiao Zhao",
      "Dong Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17650": {
    "title": "Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "560d4747ed94786cf96ef542a1a3f2b9089f0145",
    "semantic_title": "",
    "citation_count": 34,
    "authors": [
      "Yanlin Wang",
      "Hui Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17651": {
    "title": "Robustness to Spurious Correlations in Text Classification via Automatically Generated Counterfactuals",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a5b1169e536b806c2344261ebbbe3d97bc6e1cdb",
    "semantic_title": "",
    "citation_count": 38,
    "authors": [
      "Zhao Wang",
      "Aron Culotta"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17652": {
    "title": "MLE-Guided Parameter Search for Task Loss Minimization in Neural Sequence Modeling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "459e8c9ce32cc62312813c6704d24cb92a722828",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Sean Welleck",
      "Kyunghyun Cho"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17653": {
    "title": "Do Response Selection Models Really Know What's Next? Utterance Manipulation Strategies for Multi-turn Response Selection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "20d30b57444fc7c236638a89cfc72e58d0d9f322",
    "semantic_title": "",
    "citation_count": 39,
    "authors": [
      "Taesun Whang",
      "Dongyub Lee",
      "Dongsuk Oh",
      "Chanhee Lee",
      "Kijong Han",
      "Dong-hun Lee",
      "Saebyeok Lee"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17654": {
    "title": "On Scalar Embedding of Relative Positions in Attention Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "52d01d9f71caf0d021fccb75b75b7d3dfc7460f5",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Junshuang Wu",
      "Richong Zhang",
      "Yongyi Mao",
      "Junfan Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17655": {
    "title": "Evidence Inference Networks for Interpretable Claim Verification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ab4a0fbf1a12c596c4a5c33c1a34cc1e6459eaf0",
    "semantic_title": "",
    "citation_count": 11,
    "authors": [
      "Lianwei Wu",
      "Yuan Rao",
      "Ling Sun",
      "Wangbo He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17656": {
    "title": "TextGAIL: Generative Adversarial Imitation Learning for Text Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2ff04294838863ec2d2087cbaa36bac48bf0e555",
    "semantic_title": "",
    "citation_count": 25,
    "authors": [
      "Qingyang Wu",
      "Lei Li",
      "Zhou Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17657": {
    "title": "MELINDA: A Multimodal Dataset for Biomedical Experiment Method Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c9074d9719c5ce0dd3a7369dd0749cd08d7f67ed",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Te-Lin Wu",
      "Shikhar Singh",
      "Sayan Paul",
      "Gully Burns",
      "Nanyun Peng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17658": {
    "title": "A Controllable Model of Grounded Response Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2f08f268f3594b875be156c3ab1c78f19791d592",
    "semantic_title": "",
    "citation_count": 53,
    "authors": [
      "Zeqiu Wu",
      "Michel Galley",
      "Chris Brockett",
      "Yizhe Zhang",
      "Xiang Gao",
      "Chris Quirk",
      "Rik Koncel-Kedziorski",
      "Jianfeng Gao",
      "Hannaneh Hajishirzi",
      "Mari Ostendorf",
      "Bill Dolan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17659": {
    "title": "Context-Guided BERT for Targeted Aspect-Based Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a3b395831496bb50fca43317e320c774900c28b2",
    "semantic_title": "",
    "citation_count": 41,
    "authors": [
      "Zhengxuan Wu",
      "Desmond C. Ong"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17660": {
    "title": "Does Head Label Help for Long-Tailed Multi-Label Text Classification",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "05e02090137d496cefecdea86c7aa43a4feebbc7",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Lin Xiao",
      "Xiangliang Zhang",
      "Liping Jing",
      "Chi Huang",
      "Mingyang Song"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17661": {
    "title": "Adversarial Meta Sampling for Multilingual Low-Resource Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "535f1684de5ce59ce2be17e876e55ce9e7692ad9",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Yubei Xiao",
      "Ke Gong",
      "Pan Zhou",
      "Guolin Zheng",
      "Xiaodan Liang",
      "Liang Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17662": {
    "title": "Improving Tree-Structured Decoder Training for Code Generation via Mutual Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9ba5501a22f8e2207280abb997bbea12fbf9027a",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Binbin Xie",
      "Jinsong Su",
      "Yubin Ge",
      "Xiang Li",
      "Jianwei Cui",
      "Junfeng Yao",
      "Bin Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17663": {
    "title": "Enabling Fast and Universal Audio Adversarial Attack Using Generative Model",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ddbeddfe4d4afe5d1cf008447a6d657511c1ca76",
    "semantic_title": "",
    "citation_count": 28,
    "authors": [
      "Yi Xie",
      "Zhuohang Li",
      "Cong Shi",
      "Jian Liu",
      "Yingying Chen",
      "Bo Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17664": {
    "title": "Nystr√∂mformer: A Nystr√∂m-based Algorithm for Approximating Self-Attention",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85",
    "semantic_title": "",
    "citation_count": 196,
    "authors": [
      "Yunyang Xiong",
      "Zhanpeng Zeng",
      "Rudrasis Chakraborty",
      "Mingxing Tan",
      "Glenn Fung",
      "Yin Li",
      "Vikas Singh"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17665": {
    "title": "Entity Structure Within and Throughout: Modeling Mention Dependencies for Document-Level Relation Extraction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "92a21e9ce3f702d0a2b0d619c4c974bdc8ff23cd",
    "semantic_title": "",
    "citation_count": 67,
    "authors": [
      "Benfeng Xu",
      "Quan Wang",
      "Yajuan Lyu",
      "Yong Zhu",
      "Zhendong Mao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17666": {
    "title": "Learning an Effective Context-Response Matching Model with Self-Supervised Tasks for Retrieval-based Dialogues",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "83649fe41651f12c4ced49e8eead447664b422ec",
    "semantic_title": "",
    "citation_count": 46,
    "authors": [
      "Ruijian Xu",
      "Chongyang Tao",
      "Daxin Jiang",
      "Xueliang Zhao",
      "Dongyan Zhao",
      "Rui Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17667": {
    "title": "Document-Level Relation Extraction with Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1e15de9245be9bf8f11c1270f46fb0195caf240d",
    "semantic_title": "",
    "citation_count": 43,
    "authors": [
      "Wang Xu",
      "Kehai Chen",
      "Tiejun Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17668": {
    "title": "Topic-Aware Multi-turn Dialogue Modeling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "40b1ea56c49751366b05f90f91f98d9d4a12e290",
    "semantic_title": "",
    "citation_count": 34,
    "authors": [
      "Yi Xu",
      "Hai Zhao",
      "Zhuosheng Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17669": {
    "title": "A Supervised Multi-Head Self-Attention Network for Nested Named Entity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "50f1b5e8a18103bba492fe8987d75a2fbb8a5b4c",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Yongxiu Xu",
      "Heyan Huang",
      "Chong Feng",
      "Yue Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17670": {
    "title": "GDPNet: Refining Latent Multi-View Graph for Relation Extraction",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c3ee23ae9c6eef53ff8a6ec8169a1ebd25a36b65",
    "semantic_title": "",
    "citation_count": 45,
    "authors": [
      "Fuzhao Xue",
      "Aixin Sun",
      "Hao Zhang",
      "Eng Siong Chng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17671": {
    "title": "Human-Level Interpretable Learning for Aspect-Based Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f1a2a29c6f456e3b9e33fa719003ced4afe33d18",
    "semantic_title": "",
    "citation_count": 50,
    "authors": [
      "Rohan K Yadav",
      "Lei Jiao",
      "Ole-Christoffer Granmo",
      "Morten Goodwin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17672": {
    "title": "Style-transfer and Paraphrase: Looking for a Sensible Semantic Similarity Metric",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b21d23b0bf97c42ad558835b4ab5f0ca224f55f4",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Ivan P. Yamshchikov",
      "Viacheslav Shibaev",
      "Nikolay Khlebnikov",
      "Alexey Tikhonov"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17673": {
    "title": "Multi-Document Transformer for Personality Detection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "618a636df616a642533f7f07cafa6ce8fe8ea1ba",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Feifan Yang",
      "Xiaojun Quan",
      "Yunyi Yang",
      "Jianxing Yu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17674": {
    "title": "UBAR: Towards Fully End-to-End Task-Oriented Dialog System with GPT-2",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "63169665bd592fb818678c47644b29302877d50e",
    "semantic_title": "",
    "citation_count": 89,
    "authors": [
      "Yunyi Yang",
      "Yunhao Li",
      "Xiaojun Quan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17675": {
    "title": "Open Domain Dialogue Generation with Latent Images",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "07411c725cff489da465ed14b99c9d113006aa6c",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Ze Yang",
      "Wei Wu",
      "Huang Hu",
      "Can Xu",
      "Wei Wang",
      "Zhoujun Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17676": {
    "title": "Adversarial Language Games for Advanced Natural Language Intelligence",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8a9a798c56fc83858d7ace0352606d73aeaa204d",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Yuan Yao",
      "Haoxi Zhong",
      "Zhengyan Zhang",
      "Xu Han",
      "Xiaozhi Wang",
      "Kai Zhang",
      "Chaojun Xiao",
      "Guoyang Zeng",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17677": {
    "title": "Contrastive Triple Extraction with Generative Transformer",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "137c719c3e51ed65dcb3a8db373680021b643d45",
    "semantic_title": "",
    "citation_count": 60,
    "authors": [
      "Hongbin Ye",
      "Ningyu Zhang",
      "Shumin Deng",
      "Mosha Chen",
      "Chuanqi Tan",
      "Fei Huang",
      "Huajun Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17678": {
    "title": "Unanswerable Question Correction in Question Answering over Personal Knowledge Base",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "e0dfd6821c34911ca0c4052b9899564d603d86b5",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "An-Zi Yen",
      "Hen-Hsen Huang",
      "Hsin-Hsi Chen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17679": {
    "title": "Simpson's Bias in NLP Training",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "c115e75bd7f17fcf76ad9b1809e445713ff359ff",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Fei Yuan",
      "Longtu Zhang",
      "Huang Bojun",
      "Yaobo Liang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17680": {
    "title": "Reinforced Multi-Teacher Selection for Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "63c966e28b471551f2d9c7a5b4c639de6c8953b0",
    "semantic_title": "",
    "citation_count": 35,
    "authors": [
      "Fei Yuan",
      "Linjun Shou",
      "Jian Pei",
      "Wutao Lin",
      "Ming Gong",
      "Yan Fu",
      "Daxin Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17681": {
    "title": "What's the Best Place for an AI Conference, Vancouver or _______: Why Completing Comparative Questions is Difficult",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8b652c4d7a8d5836925ce0fe28a91dc661778524",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "‚Ä™Avishai Zagoury‚Ä¨‚Äè",
      "Einat Minkov",
      "Idan Szpektor",
      "William W. Cohen"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17682": {
    "title": "Probing Product Description Generation via Posterior Distillation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "29e815c583f62735821e5fab1c743347e8cb3bcc",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Haolan Zhan",
      "Hainan Zhang",
      "Hongshen Chen",
      "Lei Shen",
      "Zhuoye Ding",
      "Yongjun Bao",
      "Weipeng Yan",
      "Yanyan Lan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17683": {
    "title": "Meta-Curriculum Learning for Domain Adaptation in Neural Machine Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b794bafd6e15609fd52bdb5753d9b1b6287a0b8f",
    "semantic_title": "",
    "citation_count": 21,
    "authors": [
      "Runzhe Zhan",
      "Xuebo Liu",
      "Derek F. Wong",
      "Lidia S. Chao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17684": {
    "title": "UWSpeech: Speech to Speech Translation for Unwritten Languages",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b72800358ed41847d181f9a53e88ec9f9f389308",
    "semantic_title": "",
    "citation_count": 22,
    "authors": [
      "Chen Zhang",
      "Xu Tan",
      "Yi Ren",
      "Tao Qin",
      "Kejun Zhang",
      "Tie-Yan Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17685": {
    "title": "Building Interpretable Interaction Trees for Deep NLP Models",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8fc27b2f4c118c50e208a563835fd5e52a522980",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Die Zhang",
      "Hao Zhang",
      "Huilin Zhou",
      "Xiaoyi Bao",
      "Da Huo",
      "Ruizhao Chen",
      "Xu Cheng",
      "Mengyue Wu",
      "Quanshi Zhang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17686": {
    "title": "Multi-modal Multi-label Emotion Recognition with Heterogeneous Hierarchical Message Passing",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cf65400ca1c8865b2b767b59fc5fdb14ddf7fbc5",
    "semantic_title": "",
    "citation_count": 14,
    "authors": [
      "Dong Zhang",
      "Xincheng Ju",
      "Wei Zhang",
      "Junhui Li",
      "Shoushan Li",
      "Qiaoming Zhu",
      "Guodong Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17687": {
    "title": "Multi-modal Graph Fusion for Named Entity Recognition with Targeted Visual Guidance",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0d6f36467bebc829717c2fcca856031b51c706b4",
    "semantic_title": "",
    "citation_count": 31,
    "authors": [
      "Dong Zhang",
      "Suzhong Wei",
      "Shoushan Li",
      "Hanqian Wu",
      "Qiaoming Zhu",
      "Guodong Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17688": {
    "title": "Accelerating Neural Machine Translation with Partial Word Embedding Compression",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1949dff192e4d65af3bce36fca0c20c1f2344bf8",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Fan Zhang",
      "Mei Tu",
      "Jinyao Yan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17689": {
    "title": "Discovering New Intents with Deep Aligned Clustering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "00372193b6a5844c274c8d97097589c7d6a412c4",
    "semantic_title": "",
    "citation_count": 34,
    "authors": [
      "Hanlei Zhang",
      "Hua Xu",
      "Ting-En Lin",
      "Rui Lyu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17690": {
    "title": "Deep Open Intent Classification with Adaptive Decision Boundary",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "25353f47c8699611b6ed008150d75cf54e74d330",
    "semantic_title": "",
    "citation_count": 46,
    "authors": [
      "Hanlei Zhang",
      "Hua Xu",
      "Ting-En Lin"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17691": {
    "title": "Writing Polishment with Simile: Task, Dataset and A Neural Approach",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1a9c195c97036aeb98cab02081d656ed480198b2",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Jiayi Zhang",
      "Zhi Cui",
      "Xiaoqiang Xia",
      "Yalong Guo",
      "Yanran Li",
      "Chen Wei",
      "Jianwei Cui"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17692": {
    "title": "Continuous Self-Attention Models with Neural ODE Networks",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a95b0b5ddca071540c275a59af9118379be457ce",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Jing Zhang",
      "Peng Zhang",
      "Baiwen Kong",
      "Junqiu Wei",
      "Xin Jiang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17693": {
    "title": "TaLNet: Voice Reconstruction from Tongue and Lip Articulation with Transfer Learning from Text-to-Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4eeaf4ee24becd2bb134ac8c1bbdcb1c82ebd462",
    "semantic_title": "",
    "citation_count": 6,
    "authors": [
      "Jing-Xuan Zhang",
      "Korin Richmond",
      "Zhen-Hua Ling",
      "Lirong Dai"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17694": {
    "title": "Making the Relation Matters: Relation of Relation Learning Network for Sentence Semantic Matching",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "78732346553ae992d316c5c5d9c8702bf5756308",
    "semantic_title": "",
    "citation_count": 8,
    "authors": [
      "Kun Zhang",
      "Le Wu",
      "Guangyi Lv",
      "Meng Wang",
      "Enhong Chen",
      "Shulan Ruan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17695": {
    "title": "MERL: Multimodal Event Representation Learning in Heterogeneous Embedding Spaces",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "1a384c1867c0d5c1a06337f536c57f8126bad994",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Linhai Zhang",
      "Deyu Zhou",
      "Yulan He",
      "Zeng Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17696": {
    "title": "Future-Guided Incremental Transformer for Simultaneous Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "cc5afa8f1d35ec8fb3179bf760552da496d2838f",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Shaolei Zhang",
      "Yang Feng",
      "Liangyou Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17697": {
    "title": "Semantics-Aware Inferential Network for Natural Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a11d30682c950a1240552fce03f79407dc5957be",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Shuiliang Zhang",
      "Hai Zhao",
      "Junru Zhou",
      "Xi Zhou",
      "Xiang Zhou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17698": {
    "title": "Learning to Check Contract Inconsistencies",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "890c7548aab4152223235eeff6c067bcccd5f54e",
    "semantic_title": "",
    "citation_count": 3,
    "authors": [
      "Shuo Zhang",
      "Junzhou Zhao",
      "Pinghui Wang",
      "Nuo Xu",
      "Yang Yang",
      "Yiting Liu",
      "Yi Huang",
      "Junlan Feng"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17699": {
    "title": "Self-supervised Bilingual Syntactic Alignment for Neural Machine Translation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7e729166d7cd6b5550bbaa7e80658b06c2f4afb9",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Tianfu Zhang",
      "Heyan Huang",
      "Chong Feng",
      "Longbing Cao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17700": {
    "title": "Graph-Based Tri-Attention Network for Answer Ranking in CQA",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "18981e60887244d898f00ef60738eaeae1453f76",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Wei Zhang",
      "Zeyuan Chen",
      "Chao Dong",
      "Wen Wang",
      "Hongyuan Zha",
      "Jianyong Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17701": {
    "title": "Circles are like Ellipses, or Ellipses are like Circles? Measuring the Degree of Asymmetry of Static and Contextual Word Embeddings and the Implications to Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3e4c16b56dccb1685e8cb0c973242792ce8f8fe3",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Zhang",
      "Murray Campbell",
      "Yang Yu",
      "Sadhana Kumaravel"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17702": {
    "title": "Denoising Distantly Supervised Named Entity Recognition via a Hypergeometric Probabilistic Model",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "72857e8f336c53124acd469190f400466d1f7cfd",
    "semantic_title": "",
    "citation_count": 7,
    "authors": [
      "Wenkai Zhang",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun",
      "Huidan Liu",
      "Zhicheng Wei",
      "Nicholas Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17703": {
    "title": "Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b4b8ae8cb3b7abaffa242d190b04296f7ed9304b",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Xinyuan Zhang",
      "Ruiyi Zhang",
      "Manzil Zaheer",
      "Amr Ahmed"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17704": {
    "title": "News Content Completion with Location-Aware Image Selection",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "b55a03afc6f8e6b27db626a79ff4db00b3881086",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengkun Zhang",
      "Jun Wang",
      "Adam Jatowt",
      "Zhe Sun",
      "Shao-Ping Lu",
      "Zhenglu Yang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17705": {
    "title": "Retrospective Reader for Machine Reading Comprehension",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8d00049c345b9c8cc76ea2ea2565f8bb69f6b683",
    "semantic_title": "",
    "citation_count": 167,
    "authors": [
      "Zhuosheng Zhang",
      "Junjie Yang",
      "Hai Zhao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17706": {
    "title": "Dynamic Modeling Cross- and Self-Lattice Attention Network for Chinese NER",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7ca77377e5f4a2df9f6a02192f26e81ce19517db",
    "semantic_title": "",
    "citation_count": 9,
    "authors": [
      "Shan Zhao",
      "Minghao Hu",
      "Zhiping Cai",
      "Haiwen Chen",
      "Fang Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17707": {
    "title": "A Unified Multi-Task Learning Framework for Joint Extraction of Entities and Relations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "8758f3c992c49b952d253acc9bdbdf5531616862",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Tianyang Zhao",
      "Zhao Yan",
      "Yunbo Cao",
      "Zhoujun Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17708": {
    "title": "LIREx: Augmenting Language Inference with Relevant Explanations",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2f4ea6e0d2a694020c0c5f14843ad39772e13396",
    "semantic_title": "",
    "citation_count": 10,
    "authors": [
      "Xinyan Zhao",
      "V.G.Vinod Vydiswaran"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17709": {
    "title": "Automatic Curriculum Learning With Over-repetition Penalty for Dialogue Policy Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6a60bf27a3d997d373f7536cb6a6c1abf3561e6a",
    "semantic_title": "",
    "citation_count": 12,
    "authors": [
      "Yangyang Zhao",
      "Zhenyu Wang",
      "Zhenhua Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17710": {
    "title": "Interactive Speech and Noise Modeling for Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9511b414fb3a32a9442136e6115f9734ab415f46",
    "semantic_title": "",
    "citation_count": 48,
    "authors": [
      "Chengyu Zheng",
      "Xiulian Peng",
      "Yuan Zhang",
      "Sriram Srinivasan",
      "Yan Lu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17711": {
    "title": "Stylized Dialogue Response Generation Using Stylized Unpaired Texts",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0f8a14f42b82b35abbe5d97dca14ec9ab6bf34e1",
    "semantic_title": "",
    "citation_count": 19,
    "authors": [
      "Yinhe Zheng",
      "Zikai Chen",
      "Rongsheng Zhang",
      "Shilei Huang",
      "Xiaoxi Mao",
      "Minlie Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17712": {
    "title": "Keyword-Guided Neural Conversational Model",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3f8fcf49be5ddd4a950325bc055cc2e159596d6f",
    "semantic_title": "",
    "citation_count": 16,
    "authors": [
      "Peixiang Zhong",
      "Yong Liu",
      "Hao Wang",
      "Chunyan Miao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17713": {
    "title": "CARE: Commonsense-Aware Emotional Response Generation with Latent Concepts",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "ad1a1f910b53d3465a89220a41af1d7069cbee5b",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Peixiang Zhong",
      "Di Wang",
      "Pengfei Li",
      "Chen Zhang",
      "Hao Wang",
      "Chunyan Miao"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17714": {
    "title": "MTAAL: Multi-Task Adversarial Active Learning for Medical Named Entity Recognition and Normalization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3cc19d0e2df1af11a7a62da6533f70865a42ca11",
    "semantic_title": "",
    "citation_count": 4,
    "authors": [
      "Baohang Zhou",
      "Xiangrui Cai",
      "Ying Zhang",
      "Wenya Guo",
      "Xiaojie Yuan"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17715": {
    "title": "A Neural Group-wise Sentiment Analysis Model with Data Sparsity Awareness",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "db5368664b71c203b1b1aa4e28ef081e9a2eeee7",
    "semantic_title": "",
    "citation_count": 1,
    "authors": [
      "Deyu Zhou",
      "Meng Zhang",
      "Linhai Zhang",
      "Yulan He"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17716": {
    "title": "EvaLDA: Efficient Evasion Attacks Towards Latent Dirichlet Allocation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d30ed44df0156000a343e98258e4515534745923",
    "semantic_title": "",
    "citation_count": 2,
    "authors": [
      "Qi Zhou",
      "Haipeng Chen",
      "Yitao Zheng",
      "Zhen Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17717": {
    "title": "Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "276d4e2684eeb7fc4df4c619d0de58160dca8b5e",
    "semantic_title": "",
    "citation_count": 94,
    "authors": [
      "Wenxuan Zhou",
      "Kevin Huang",
      "Tengyu Ma",
      "Jing Huang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17718": {
    "title": "IsoBN: Fine-Tuning BERT with Isotropic Batch Normalization",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2c2cc3decc0d5091965975eb4bb6f5dc802bcbf7",
    "semantic_title": "",
    "citation_count": 13,
    "authors": [
      "Wenxuan Zhou",
      "Bill Yuchen Lin",
      "Xiang Ren"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17719": {
    "title": "An Adaptive Hybrid Framework for Cross-domain Aspect-based Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "34048d8fec3e1f18c20a5047acf3971e33820c00",
    "semantic_title": "",
    "citation_count": 5,
    "authors": [
      "Yan Zhou",
      "Fuqing Zhu",
      "Pu Song",
      "Jizhong Han",
      "Tao Guo",
      "Songlin Hu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17720": {
    "title": "What the Role is vs. What Plays the Role: Semi-Supervised Event Argument Extraction via Dual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "3ddb8a7af5172bbac8cf0344b858324ccf724118",
    "semantic_title": "",
    "citation_count": 23,
    "authors": [
      "Yang Zhou",
      "Yubo Chen",
      "Jun Zhao",
      "Yin Wu",
      "Jiexin Xu",
      "Jinlong Li"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17721": {
    "title": "Clinical Temporal Relation Extraction with Probabilistic Soft Logic Regularization and Global Inference",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "16913a534b1630d33770b392767bb316f4fdb11e",
    "semantic_title": "",
    "citation_count": 18,
    "authors": [
      "Yichao Zhou",
      "Yu Yan",
      "Rujun Han",
      "J. Harry Caufield",
      "Kai-Wei Chang",
      "Yizhou Sun",
      "Peipei Ping",
      "Wei Wang"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17722": {
    "title": "Neural Sentence Ordering Based on Constraint Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "607b61b6b64bec4f97e9e22bc7c670696da9bf91",
    "semantic_title": "",
    "citation_count": 17,
    "authors": [
      "Yutao Zhu",
      "Kun Zhou",
      "Jian-Yun Nie",
      "Shengchao Liu",
      "Zhicheng Dou"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17723": {
    "title": "Topic-Oriented Spoken Dialogue Summarization for Customer Service with Saliency-Aware Topic Modeling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "4adbbb1c61404fe7235bbe704189167d61368629",
    "semantic_title": "",
    "citation_count": 26,
    "authors": [
      "Yicheng Zou",
      "Lujun Zhao",
      "Yangyang Kang",
      "Jun Lin",
      "Minlong Peng",
      "Zhuoren Jiang",
      "Changlong Sun",
      "Qi Zhang",
      "Xuanjing Huang",
      "Xiaozhong Liu"
    ]
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/17724": {
    "title": "Unsupervised Summarization for Chat Logs with Topic-Oriented Ranking and Context-Aware Auto-Encoders",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7792683b78807a7c86c508f4f05bdfad38d3fe0a",
    "semantic_title": "",
    "citation_count": 15,
    "authors": [
      "Yicheng Zou",
      "Jun Lin",
      "Lujun Zhao",
      "Yangyang Kang",
      "Zhuoren Jiang",
      "Changlong Sun",
      "Qi Zhang",
      "Xuanjing Huang",
      "Xiaozhong Liu"
    ]
  }
}