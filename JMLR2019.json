{
  "https://jmlr.org/papers/v20/15-192.html": {
    "title": "Adaptation Based on Generalized Discrepancy",
    "volume": "main",
    "abstract": "We present a new algorithm for domain adaptation improving upon a discrepancy minimization algorithm, (DM), previously shown to outperform a number of algorithms for this problem. Unlike many previously proposed solutions for domain adaptation, our algorithm does not consist of a fixed reweighting of the losses over the training sample. Instead, the reweighting depends on the hypothesis sought. The algorithm is derived from a less conservative notion of discrepancy than the DM algorithm called generalized discrepancy. We present a detailed description of our algorithm and show that it can be formulated as a convex optimization problem. We also give a detailed theoretical analysis of its learning guarantees which helps us select its parameters. Finally, we report the results of experiments demonstrating that it improves upon discrepancy minimization",
    "checked": true,
    "id": "9e4a586a6044385d9b32a13c8e24cfcb4efff79f",
    "semantic_title": "adaptation based on generalized discrepancy",
    "citation_count": 61
  },
  "https://jmlr.org/papers/v20/16-243.html": {
    "title": "Transport Analysis of Infinitely Deep Neural Network",
    "volume": "main",
    "abstract": "We investigated the feature map inside deep neural networks (DNNs) by tracking the transport map. We are interested in the role of depth---why do DNNs perform better than shallow models?---and the interpretation of DNNs---what do intermediate layers do? Despite the rapid development in their application, DNNs remain analytically unexplained because the hidden layers are nested and the parameters are not faithful. Inspired by the integral representation of shallow NNs, which is the continuum limit of the width, or the hidden unit number, we developed the flow representation and transport analysis of DNNs. The flow representation is the continuum limit of the depth, or the hidden layer number, and it is specified by an ordinary differential equation (ODE) with a vector field. We interpret an ordinary DNN as a transport map or an Euler broken line approximation of the flow. Technically speaking, a dynamical system is a natural model for the nested feature maps. In addition, it opens a new way to the coordinate-free treatment of DNNs by avoiding the redundant parametrization of DNNs. Following Wasserstein geometry, we analyze a flow in three aspects: dynamical system, continuity equation, and Wasserstein gradient flow. A key finding is that we specified a series of transport maps of the denoising autoencoder (DAE), which is a cornerstone for the development of deep learning. Starting from the shallow DAE, this paper develops three topics: the transport map of the deep DAE, the equivalence between the stacked DAE and the composition of DAEs, and the development of the double continuum limit or the integral representation of the flow representation. As partial answers to the research questions, we found that deeper DAEs converge faster and the extracted features are better; in addition, a deep Gaussian DAE transports mass to decrease the Shannon entropy of the data distribution. We expect that further investigations on these questions lead to the development of an interpretable and principled alternatives to DNNs",
    "checked": true,
    "id": "c1a8490c168490805bb5a236b497e974ba839fe4",
    "semantic_title": "transport analysis of infinitely deep neural network",
    "citation_count": 32
  },
  "https://jmlr.org/papers/v20/16-585.html": {
    "title": "Parsimonious Online Learning with Kernels via Sparse Projections in Function Space",
    "volume": "main",
    "abstract": "Despite their attractiveness, popular perception is that techniques for nonparametric function approximation do not scale to streaming data due to an intractable growth in the amount of storage they require. To solve this problem in a memory-affordable way, we propose an online technique based on functional stochastic gradient descent in tandem with supervised sparsification based on greedy function subspace projections. The method, called parsimonious online learning with kernels (POLK), provides a controllable tradeoff between its solution accuracy and the amount of memory it requires. We derive conditions under which the generated function sequence converges almost surely to the optimal function, and we establish that the memory requirement remains finite. We evaluate POLK for kernel multi-class logistic regression and kernel hinge-loss classification on three canonical data sets: a synthetic Gaussian mixture model, the MNIST hand-written digits, and the Brodatz texture database. On all three tasks, we observe a favorable trade-off of objective function evaluation, classification performance, and complexity of the nonparametric regressor extracted by the proposed method",
    "checked": true,
    "id": "85beff534a0b88b122e2d6d02757ccb157448b02",
    "semantic_title": "parsimonious online learning with kernels via sparse projections in function space",
    "citation_count": 73
  },
  "https://jmlr.org/papers/v20/16-588.html": {
    "title": "Convergence Rate of a Simulated Annealing Algorithm with Noisy Observations",
    "volume": "main",
    "abstract": "In this paper we propose a modified version of the simulated annealing algorithm for solving a stochastic global optimization problem. More precisely, we address the problem of finding a global minimizer of a function with noisy evaluations. We provide a rate of convergence and its optimized parametrization to ensure a minimal number of evaluations for a given accuracy and a confidence level close to 1. This work is completed with a set of numerical experimentations and assesses the practical performance both on benchmark test cases and on real world examples",
    "checked": true,
    "id": "abbae25a81b4715959da004d3d057d772fc0e970",
    "semantic_title": "convergence rate of a simulated annealing algorithm with noisy observations",
    "citation_count": 20
  },
  "https://jmlr.org/papers/v20/16-607.html": {
    "title": "Non-Convex Projected Gradient Descent for Generalized Low-Rank Tensor Regression",
    "volume": "main",
    "abstract": "In this paper, we consider the problem of learning high-dimensional tensor regression problems with low-rank structure. One of the core challenges associated with learning high-dimensional models is computation since the underlying optimization problems are often non-convex. While convex relaxations could lead to polynomial-time algorithms they are often slow in practice. On the other hand, limited theoretical guarantees exist for non-convex methods. In this paper we provide a general framework that provides theoretical guarantees for learning high-dimensional tensor regression models under different low-rank structural assumptions using the projected gradient descent algorithm applied to a potentially non-convex constraint set $\\Theta$ in terms of its localized Gaussian width (due to Gaussian design). We juxtapose our theoretical results for non-convex projected gradient descent algorithms with previous results on regularized convex approaches. The two main differences between the convex and non-convex approach are: (i) from a computational perspective whether the non-convex projection operator is computable and whether the projection has desirable contraction properties and (ii) from a statistical error bound perspective, the non-convex approach has a superior rate for a number of examples. We provide three concrete examples of low-dimensional structure which address these issues and explain the pros and cons for the non-convex and convex approaches. We supplement our theoretical results with simulations which show that, under several common settings of generalized low rank tensor regression, the projected gradient descent approach is superior both in terms of statistical error and run-time provided the step-sizes of the projected descent algorithm are suitably chosen",
    "checked": true,
    "id": "c9ed43b0ca416f6d4198f11ae73eb9f16c03ee2a",
    "semantic_title": "non-convex projected gradient descent for generalized low-rank tensor regression",
    "citation_count": 54
  },
  "https://jmlr.org/papers/v20/17-100.html": {
    "title": "scikit-multilearn: A Python library for Multi-Label Classification",
    "volume": "MLOSS",
    "abstract": "The scikit-multilearn is a Python library for performing multi-label classification. It is compatible with the scikit-learn and scipy ecosystems and uses sparse matrices for all internal operations; provides native Python implementations of popular multi-label classification methods alongside a novel framework for label space partitioning and division and includes modern algorithm adaptation methods, network-based label space division approaches, which extracts label dependency information and multi-label embedding classifiers. The library provides Python wrapped access to the extensive multi-label method stack from Java libraries and makes it possible to extend deep learning single-label methods for multi-label tasks. The library allows multi-label stratification and data set management. The implementation is more efficient in problem transformation than other established libraries, has good test coverage and follows PEP8. Source code and documentation can be downloaded from http://scikit.ml and also via pip The project is BSD-licensed",
    "checked": true,
    "id": "9aa4ffc4e71e77d6acecffe0e83ada399c409fbe",
    "semantic_title": "scikit-multilearn: a python library for multi-label classification",
    "citation_count": 11
  },
  "https://jmlr.org/papers/v20/17-279.html": {
    "title": "Scalable Approximations for Generalized Linear Problems",
    "volume": "main",
    "abstract": "In stochastic optimization, the population risk is generally approximated by the empirical risk which is in turn minimized by an iterative algorithm. However, in the large-scale setting, empirical risk minimization may be computationally restrictive. In this paper, we design an efficient algorithm to approximate the population risk minimizer in generalized linear problems such as binary classification with surrogate losses and generalized linear regression models. We focus on large-scale problems where the iterative minimization of the empirical risk is computationally intractable, i.e., the number of observations $n$ is much larger than the dimension of the parameter $p$ ($n \\gg p \\gg 1$). We show that under random sub-Gaussian design, the true minimizer of the population risk is approximately proportional to the corresponding ordinary least squares (OLS) estimator. Using this relation, we design an algorithm that achieves the same accuracy as the empirical risk minimizer through iterations that attain up to a quadratic convergence rate, and that are computationally cheaper than any batch optimization algorithm by at least a factor of $\\mathcal{O}(p)$. We provide theoretical guarantees for our algorithm, and analyze the convergence behavior in terms of data dimensions. Finally, we demonstrate the performance of our algorithm on well-known classification and regression problems, through extensive numerical studies on large-scale datasets, and show that it achieves the highest performance compared to several other widely used optimization algorithms",
    "checked": true,
    "id": "033b07e1ae054a6170cb4e66b14adf6c7e9cda91",
    "semantic_title": "scalable approximations for generalized linear problems",
    "citation_count": 11
  },
  "https://jmlr.org/papers/v20/17-334.html": {
    "title": "Forward-Backward Selection with Early Dropping",
    "volume": "main",
    "abstract": "Forward-backward selection is one of the most basic and commonly-used feature selection algorithms available. It is also general and conceptually applicable to many different types of data. In this paper, we propose a heuristic that significantly improves its running time, while preserving predictive performance. The idea is to temporarily discard the variables that are conditionally independent with the outcome given the selected variable set. Depending on how those variables are reconsidered and reintroduced, this heuristic gives rise to a family of algorithms with increasingly stronger theoretical guarantees. In distributions that can be faithfully represented by Bayesian networks or maximal ancestral graphs, members of this algorithmic family are able to correctly identify the Markov blanket in the sample limit. In experiments we show that the proposed heuristic increases computational efficiency by about 1-2 orders of magnitude, while selecting fewer or the same number of variables and retaining predictive performance. Furthermore, we show that the proposed algorithm and feature selection with LASSO perform similarly when restricted to select the same number of variables, making the proposed algorithm an attractive alternative for problems where no (efficient) algorithm for LASSO exists",
    "checked": true,
    "id": "154a0cfed1f48a04dafb20018a5c8b7eb2d52db5",
    "semantic_title": "forward-backward selection with early dropping",
    "citation_count": 60
  },
  "https://jmlr.org/papers/v20/17-357.html": {
    "title": "Dynamic Pricing in High-dimensions",
    "volume": "main",
    "abstract": "We study the pricing problem faced by a firm that sells a large number of products, described via a wide range of features, to customers that arrive over time. Customers independently make purchasing decisions according to a general choice model that includes products features and customers' characteristics, encoded as $d$-dimensional numerical vectors, as well as the price offered. The parameters of the choice model are a priori unknown to the firm, but can be learned as the (binary-valued) sales data accrues over time. The firm's objective is to maximize its revenue. We benchmark the performance using the classic regret minimization framework where the regret is defined as the expected revenue loss against a clairvoyant policy that knows the parameters of the choice model in advance, and always offers the revenue-maximizing price. This setting is motivated in part by the prevalence of online marketplaces that allow for real-time pricing. We assume a structured choice model, parameters of which depend on $s_0$ out of the $d$ product features. Assuming that the market noise distribution is known, we propose a dynamic policy, called Regularized Maximum Likelihood Pricing (RMLP) that leverages the (sparsity) structure of the high-dimensional model and obtains a logarithmic regret in $T$. More specifically, the regret of our algorithm is of $O(s_0 \\log d \\cdot \\log T)$. Furthermore, we show that no policy can obtain regret better than $O(s_0 (\\log d + \\log T))$. {In addition, we propose a generalization of our policy to a setting that the market noise distribution is unknown but belongs to a parametrized family of distributions. This policy obtains regret of $O(\\sqrt{(\\log d)T})$. We further show that no policy can obtain regret better than $\\Omega(\\sqrt{T})$ in such environments.}",
    "checked": true,
    "id": "13cdb5725f15c73578f28358e09a9fbb12e77883",
    "semantic_title": "dynamic pricing in high-dimensions",
    "citation_count": 108
  },
  "https://jmlr.org/papers/v20/17-501.html": {
    "title": "Graphical Lasso and Thresholding: Equivalence and Closed-form Solutions",
    "volume": "main",
    "abstract": "Graphical Lasso (GL) is a popular method for learning the structure of an undirected graphical model, which is based on an $l_1$ regularization technique. The objective of this paper is to compare the computationally-heavy GL technique with a numerically-cheap heuristic method that is based on simply thresholding the sample covariance matrix. To this end, two notions of sign-consistent and inverse-consistent matrices are developed, and then it is shown that the thresholding and GL methods are equivalent if: (i) the thresholded sample covariance matrix is both sign-consistent and inverse-consistent, and (ii) the gap between the largest thresholded and the smallest un-thresholded entries of the sample covariance matrix is not too small. By building upon this result, it is proved that the GL method---as a conic optimization problem---has an explicit closed-form solution if the thresholded sample covariance matrix has an acyclic structure. This result is then generalized to arbitrary sparse support graphs, where a formula is found to obtain an approximate solution of GL. Furthermore, it is shown that the approximation error of the derived explicit formula decreases exponentially fast with respect to the length of the minimum-length cycle of the sparsity graph. The developed results are demonstrated on synthetic data, functional MRI data, traffic flows for transportation networks, and massive randomly generated data sets. We show that the proposed method can obtain an accurate approximation of the GL for instances with the sizes as large as $80,000\\times 80,000$ (more than 3.2 billion variables) in less than 30 minutes on a standard laptop computer running MATLAB, while other state-of-the-art methods do not converge within 4 hours",
    "checked": true,
    "id": "a629308bb90e1bc2980ce52d2276454119fdc317",
    "semantic_title": "graphical lasso and thresholding: equivalence and closed-form solutions",
    "citation_count": 28
  },
  "https://jmlr.org/papers/v20/17-504.html": {
    "title": "An Approach to One-Bit Compressed Sensing Based on Probably Approximately Correct Learning Theory",
    "volume": "main",
    "abstract": "In this paper, the problem of one-bit compressed sensing (OBCS) is formulated as a problem in probably approximately correct (PAC) learning. It is shown that the Vapnik-Chervonenkis (VC-) dimension of the set of half-spaces in $\\R^n$ generated by $k$-sparse vectors is bounded below by $k ( \\lfloor\\lg (n/k) \\rfloor +1 )$ and above by $\\lfloor 2k \\lg (en) \\rfloor $. By coupling this estimate with well-established results in PAC learning theory, we show that a consistent algorithm can recover a $k$-sparse vector with $O(k \\lg n)$ measurements, given only the signs of the measurement vector. This result holds for \\textit{all} probability measures on $\\R^n$. The theory is also applicable to the case of noisy labels, where the signs of the measurements are flipped with some unknown probability",
    "checked": true,
    "id": "518c1119fdfe27c2b359c74160ced525c0b48143",
    "semantic_title": "an approach to one-bit compressed sensing based on probably approximately correct learning theory",
    "citation_count": 10
  },
  "https://jmlr.org/papers/v20/17-517.html": {
    "title": "Scalable Kernel K-Means Clustering with Nystrom Approximation: Relative-Error Bounds",
    "volume": "main",
    "abstract": "Kernel $k$-means clustering can correctly identify and extract a far more varied collection of cluster structures than the linear $k$-means clustering algorithm. However, kernel $k$-means clustering is computationally expensive when the non-linear feature map is high-dimensional and there are many input points. Kernel approximation, e.g., the Nystrom method, has been applied in previous works to approximately solve kernel learning problems when both of the above conditions are present. This work analyzes the application of this paradigm to kernel $k$-means clustering, and shows that applying the linear $k$-means clustering algorithm to $\\frac{k}{\\epsilon} (1 + o(1))$ features constructed using a so-called rank-restricted Nystrom approximation results in cluster assignments that satisfy a $1 + \\epsilon$ approximation ratio in terms of the kernel $k$-means cost function, relative to the guarantee provided by the same algorithm without the use of the Nystrom method. As part of the analysis, this work establishes a novel $1 + \\epsilon$ relative-error trace norm guarantee for low-rank approximation using the rank-restricted Nystrom approximation. Empirical evaluations on the $8.1$ million instance MNIST8M dataset demonstrate the scalability and usefulness of kernel $k$-means clustering with Nystrom approximation. This work argues that spectral clustering using Nystrom approximation---a popular and computationally efficient, but theoretically unsound approach to non-linear clustering---should be replaced with the efficient and theoretically sound combination of kernel $k$-means clustering with Nystrom approximation. The superior performance of the latter approach is empirically verified",
    "checked": true,
    "id": "f1ed3994c1ad04e15675a6817041fcfa019995b1",
    "semantic_title": "scalable kernel k-means clustering with nystrom approximation: relative-error bounds",
    "citation_count": 102
  },
  "https://jmlr.org/papers/v20/17-535.html": {
    "title": "Train and Test Tightness of LP Relaxations in Structured Prediction",
    "volume": "main",
    "abstract": "Structured prediction is used in areas including computer vision and natural language processing to predict structured outputs such as segmentations or parse trees. In these settings, prediction is performed by MAP inference or, equivalently, by solving an integer linear program. Because of the complex scoring functions required to obtain accurate predictions, both learning and inference typically require the use of approximate solvers. We propose a theoretical explanation for the striking observation that approximations based on linear programming (LP) relaxations are often tight (exact) on real-world instances. In particular, we show that learning with LP relaxed inference encourages integrality of training instances, and that this training tightness generalizes to test data",
    "checked": true,
    "id": "fcaf4f8bebe6c875f84166345cbb2bd5cfd7aa92",
    "semantic_title": "train and test tightness of lp relaxations in structured prediction",
    "citation_count": 15
  },
  "https://jmlr.org/papers/v20/17-547.html": {
    "title": "Approximations of the Restless Bandit Problem",
    "volume": "main",
    "abstract": "The multi-armed restless bandit problem is studied in the case where the pay-off distributions are stationary $\\varphi$-mixing. This version of the problem provides a more realistic model for most real-world applications, but cannot be optimally solved in practice, since it is known to be PSPACE-hard. The objective of this paper is to characterize a sub-class of the problem where good approximate solutions can be found using tractable approaches. Specifically, it is shown that under some conditions on the $\\varphi$-mixing coefficients, a modified version of UCB can prove effective. The main challenge is that, unlike in the i.i.d. setting, the distributions of the sampled pay-offs may not have the same characteristics as those of the original bandit arms. In particular, the $\\varphi$-mixing property does not necessarily carry over. This is overcome by carefully controlling the effect of a sampling policy on the pay-off distributions. Some of the proof techniques developed in this paper can be more generally used in the context of online sampling under dependence. Proposed algorithms are accompanied with corresponding regret analysis",
    "checked": true,
    "id": "a3ecaccc96901da655c7ac320309d3739017040f",
    "semantic_title": "approximations of the restless bandit problem",
    "citation_count": 8
  },
  "https://jmlr.org/papers/v20/17-613.html": {
    "title": "Automated Scalable Bayesian Inference via Hilbert Coresets",
    "volume": "main",
    "abstract": "The automation of posterior inference in Bayesian data analysis has enabled experts and nonexperts alike to use more sophisticated models, engage in faster exploratory modeling and analysis, and ensure experimental reproducibility. However, standard automated posterior inference algorithms are not tractable at the scale of massive modern data sets, and modifications to make them so are typically model-specific, require expert tuning, and can break theoretical guarantees on inferential quality. Building on the Bayesian coresets framework, this work instead takes advantage of data redundancy to shrink the data set itself as a preprocessing step, providing fully-automated, scalable Bayesian inference with theoretical guarantees. We begin with an intuitive reformulation of Bayesian coreset construction as sparse vector sum approximation, and demonstrate that its automation and performance-based shortcomings arise from the use of the supremum norm. To address these shortcomings we develop Hilbert coresets, i.e., Bayesian coresets constructed under a norm induced by an inner-product on the log-likelihood function space. We propose two Hilbert coreset construction algorithms---one based on importance sampling, and one based on the Frank-Wolfe algorithm---along with theoretical guarantees on approximation quality as a function of coreset size. Since the exact computation of the proposed inner-products is model-specific, we automate the construction with a random finite-dimensional projection of the log-likelihood functions. The resulting automated coreset construction algorithm is simple to implement, and experiments on a variety of models with real and synthetic data sets show that it provides high-quality posterior approximations and a significant reduction in the computational cost of inference",
    "checked": true,
    "id": "a8da0fcf8130d6d47fa23f754380c0e5785202a5",
    "semantic_title": "automated scalable bayesian inference via hilbert coresets",
    "citation_count": 101
  },
  "https://jmlr.org/papers/v20/17-629.html": {
    "title": "Smooth neighborhood recommender systems",
    "volume": "main",
    "abstract": "Recommender systems predict users' preferences over a large number of items by pooling similar information from other users and/or items in the presence of sparse observations. One major challenge is how to utilize user-item specific covariates and networks describing user-item interactions in a high-dimensional situation, for accurate personalized prediction. In this article, we propose a smooth neighborhood recommender in the framework of the latent factor models. A similarity kernel is utilized to borrow neighborhood information from continuous covariates over a user-item specific network, such as a user's social network, where the grouping information defined by discrete covariates is also integrated through the network. Consequently, user-item specific information is built into the recommender to battle the `cold-start\" issue in the absence of observations in collaborative and content-based filtering. Moreover, we utilize a \"divide-and-conquer\" version of the alternating least squares algorithm to achieve scalable computation, and establish asymptotic results for the proposed method, demonstrating that it achieves superior prediction accuracy. Finally, we illustrate that the proposed method improves substantially over its competitors in simulated examples and real benchmark data--Last.fm music data",
    "checked": true,
    "id": "f77e4f74f5dfc4543f7754a74de4b58ea6fdcd7e",
    "semantic_title": "smooth neighborhood recommender systems",
    "citation_count": 15
  },
  "https://jmlr.org/papers/v20/17-631.html": {
    "title": "Delay and Cooperation in Nonstochastic Bandits",
    "volume": "main",
    "abstract": "We study networks of communicating learning agents that cooperate to solve a common nonstochastic bandit problem. Agents use an underlying communication network to get messages about actions selected by other agents, and drop messages that took more than $d$ hops to arrive, where $d$ is a delay parameter. We introduce Exp3-Coop, a cooperative version of the Exp3 algorithm and prove that with $K$ actions and $N$ agents the average per-agent regret after $T$ rounds is at most of order $\\sqrt{\\bigl(d+1 + \\tfrac{K}{N}\\alpha_{\\le d}\\bigr)(T\\ln K)}$, where $\\alpha_{\\le d}$ is the independence number of the $d$-th power of the communication graph $G$. We then show that for any connected graph, for $d=\\sqrt{K}$ the regret bound is $K^{1/4}\\sqrt{T}$, strictly better than the minimax regret $\\sqrt{KT}$ for noncooperating agents. More informed choices of $d$ lead to bounds which are arbitrarily close to the full information minimax regret $\\sqrt{T\\ln K}$ when $G$ is dense. When $G$ has sparse components, we show that a variant of Exp3-Coop, allowing agents to choose their parameters according to their centrality in $G$, strictly improves the regret. Finally, as a by-product of our analysis, we provide the first characterization of the minimax regret for bandit learning with delay",
    "checked": true,
    "id": "820f16297fbe8b73197eebc7e5bd4d00eeb8d093",
    "semantic_title": "delay and cooperation in nonstochastic bandits",
    "citation_count": 120
  },
  "https://jmlr.org/papers/v20/17-663.html": {
    "title": "Multiplicative local linear hazard estimation and best one-sided cross-validation",
    "volume": "main",
    "abstract": "This paper develops detailed mathematical statistical theory of a new class of cross-validation techniques of local linear kernel hazards and their multiplicative bias corrections. The new class of cross-validation combines principles of local information and recent advances in indirect cross-validation. A few applications of cross-validating multiplicative kernel hazard estimation do exist in the literature. However, detailed mathematical statistical theory and small sample performance are introduced via this paper and further upgraded to our new class of best one-sided cross-validation. Best one-sided cross-validation turns out to have excellent performance in its practical illustrations, in its small sample performance and in its mathematical statistical theoretical performance",
    "checked": true,
    "id": "0ae4fed9d80fd7d308db6304225989cb6410971b",
    "semantic_title": "multiplicative local linear hazard estimation and best one-sided cross-validation",
    "citation_count": 0
  },
  "https://jmlr.org/papers/v20/17-743.html": {
    "title": "spark-crowd: A Spark Package for Learning from Crowdsourced Big Data",
    "volume": "MLOSS",
    "abstract": "As the data sets increase in size, the process of manually labeling data becomes unfeasible by small groups of experts. Thus, it is common to rely on crowdsourcing platforms which provide inexpensive, but noisy, labels. Although implementations of algorithms to tackle this problem exist, none of them focus on scalability, limiting the area of application to relatively small data sets. In this paper, we present spark-crowd, an Apache Spark package for learning from crowdsourced data with scalability in mind",
    "checked": true,
    "id": "da38261e09cb20356e3bdd47d11f4267248b31be",
    "semantic_title": "spark-crowd: a spark package for learning from crowdsourced big data",
    "citation_count": 6
  },
  "https://jmlr.org/papers/v20/18-022.html": {
    "title": "Accelerated Alternating Projections for Robust Principal Component Analysis",
    "volume": "main",
    "abstract": "We study robust PCA for the fully observed setting, which is about separating a low rank matrix $\\BL$ and a sparse matrix $\\BS$ from their sum $\\BD=\\BL+\\BS$. In this paper, a new algorithm, dubbed accelerated alternating projections, is introduced for robust PCA which significantly improves the computational efficiency of the existing alternating projections proposed in (Netrapalli et al., 2014) when updating the low rank factor. The acceleration is achieved by first projecting a matrix onto some low dimensional subspace before obtaining a new estimate of the low rank matrix via truncated SVD. Exact recovery guarantee has been established which shows linear convergence of the proposed algorithm. Empirical performance evaluations establish the advantage of our algorithm over other state-of-the-art algorithms for robust PCA",
    "checked": true,
    "id": "651756a327be547b8b33fc999ec2d6f7e4e1b155",
    "semantic_title": "accelerated alternating projections for robust principal component analysis",
    "citation_count": 43
  },
  "https://jmlr.org/papers/v20/18-027.html": {
    "title": "Spectrum Estimation from a Few Entries",
    "volume": "main",
    "abstract": "Singular values of a data in a matrix form provide insights on the structure of the data, the effective dimensionality, and the choice of hyper-parameters on higher-level data analysis tools. However, in many practical applications such as collaborative filtering and network analysis, we only get a partial observation. Under such scenarios, we consider the fundamental problem of recovering spectral properties of the underlying matrix from a sampling of its entries. In this paper, we address the problem of directly recovering the spectrum, which is the set of singular values, and also in sample-efficient approaches for recovering a spectral sum function, which is an aggregate sum of a fixed function applied to each of the singular values. Our approach is to first estimate the Schatten $k$-norms of a matrix for a small set of values of $k$, and then apply Chebyshev approximation when estimating a spectral sum function or apply moment matching in Wasserstein distance when estimating the singular values directly. The main technical challenge is in accurately estimating the Schatten norms from a sampling of a matrix. We introduce a novel unbiased estimator based on counting small structures called network motifs in a graph and provide guarantees that match its empirical performance. Our theoretical analysis shows that Schatten norms can be recovered accurately from strictly smaller number of samples compared to what is needed to recover the underlying low-rank matrix. Numerical experiments suggest that we significantly improve upon a competing approach of using matrix completion methods, below the matrix completion threshold, above which matrix completion algorithms recover the underlying low-rank matrix exactly",
    "checked": true,
    "id": "9936276d2f250e7d4294bb9840843a2949da4961",
    "semantic_title": "spectrum estimation from a few entries",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v20/18-030.html": {
    "title": "Random Feature-based Online Multi-kernel Learning in Environments with Unknown Dynamics",
    "volume": "main",
    "abstract": "Kernel-based methods exhibit well-documented performance in various nonlinear learning tasks. Most of them rely on a preselected kernel, whose prudent choice presumes task-specific prior information. Especially when the latter is not available, multi-kernel learning has gained popularity thanks to its flexibility in choosing kernels from a prescribed kernel dictionary. Leveraging the random feature approximation and its recent orthogonality-promoting variant, the present contribution develops a scalable multi-kernel learning scheme (termed Raker) to obtain the sought nonlinear learning function `on the fly,' first for static environments. To further boost performance in dynamic environments, an adaptive multi-kernel learning scheme (termed AdaRaker) is developed. AdaRaker accounts not only for data-driven learning of kernel combination, but also for the unknown dynamics. Performance is analyzed in terms of both static and dynamic regrets. AdaRaker is uniquely capable of tracking nonlinear learning functions in environments with unknown dynamics, and with with analytic performance guarantees Tests with synthetic and real datasets are carried out to showcase the effectiveness of the novel algorithms",
    "checked": true,
    "id": "a7c3327eb9835fd785fd1bbc69209dafd99167e2",
    "semantic_title": "random feature-based online multi-kernel learning in environments with unknown dynamics",
    "citation_count": 47
  },
  "https://jmlr.org/papers/v20/18-037.html": {
    "title": "Determining the Number of Latent Factors in Statistical Multi-Relational Learning",
    "volume": "main",
    "abstract": "Statistical relational learning is primarily concerned with learning and inferring relationships between entities in large-scale knowledge graphs. Nickel et al. (2011) proposed a RESCAL tensor factorization model for statistical relational learning, which achieves better or at least comparable results on common benchmark data sets when compared to other state-of-the-art methods. Given a positive integer $s$, RESCAL computes an $s$-dimensional latent vector for each entity. The latent factors can be further used for solving relational learning tasks, such as collective classification, collective entity resolution and link-based clustering. The focus of this paper is to determine the number of latent factors in the RESCAL model. Due to the structure of the RESCAL model, its log-likelihood function is not concave. As a result, the corresponding maximum likelihood estimators (MLEs) may not be consistent. Nonetheless, we design a specific pseudometric, prove the consistency of the MLEs under this pseudometric and establish its rate of convergence. Based on these results, we propose a general class of information criteria and prove their model selection consistencies when the number of relations is either bounded or diverges at a proper rate of the number of entities. Simulations and real data examples show that our proposed information criteria have good finite sample properties",
    "checked": true,
    "id": "bfaed7652d98e91564cf14cdae84d3a858fd261c",
    "semantic_title": "determining the number of latent factors in statistical multi-relational learning",
    "citation_count": 5
  },
  "https://jmlr.org/papers/v20/18-134.html": {
    "title": "Joint PLDA for Simultaneous Modeling of Two Factors",
    "volume": "main",
    "abstract": "Probabilistic linear discriminant analysis (PLDA) is a method used for biometric problems like speaker or face recognition that models the variability of the samples using two latent variables, one that depends on the class of the sample and another one that is assumed independent across samples and models the within-class variability. In this work, we propose a generalization of PLDA that enables joint modeling of two sample-dependent factors: the class of interest and a nuisance condition. The approach does not change the basic form of PLDA but rather modifies the training procedure to consider the dependency across samples of the latent variable that models within-class variability. While the identity of the nuisance condition is needed during training, it is not needed during testing since we propose a scoring procedure that marginalizes over the corresponding latent variable. We show results on a multilingual speaker-verification task, where the language spoken is considered a nuisance condition. The proposed joint PLDA approach leads to significant performance gains in this task for two different data sets, in particular when the training data contains mostly or only monolingual speakers",
    "checked": true,
    "id": "e03dc4dcafecc5f68bdc51bcdc8b6380dfd3fa18",
    "semantic_title": "joint plda for simultaneous modeling of two factors",
    "citation_count": 6
  },
  "https://jmlr.org/papers/v20/18-190.html": {
    "title": "Group Invariance, Stability to Deformations, and Complexity of Deep Convolutional Representations",
    "volume": "main",
    "abstract": "The success of deep convolutional architectures is often attributed in part to their ability to learn multiscale and invariant representations of natural signals. However, a precise study of these properties and how they affect learning guarantees is still missing. In this paper, we consider deep convolutional representations of signals; we study their invariance to translations and to more general groups of transformations, their stability to the action of diffeomorphisms, and their ability to preserve signal information. This analysis is carried by introducing a multilayer kernel based on convolutional kernel networks and by studying the geometry induced by the kernel mapping. We then characterize the corresponding reproducing kernel Hilbert space (RKHS), showing that it contains a large class of convolutional neural networks with homogeneous activation functions. This analysis allows us to separate data representation from learning, and to provide a canonical measure of model complexity, the RKHS norm, which controls both stability and generalization of any learned model. In addition to models in the constructed RKHS, our stability analysis also applies to convolutional networks with generic activations such as rectified linear units, and we discuss its relationship with recent generalization bounds based on spectral norms",
    "checked": true,
    "id": "db30c3bcae718bfa0631aeb4af419afc5899abf6",
    "semantic_title": "group invariance, stability to deformations, and complexity of deep convolutional representations",
    "citation_count": 75
  },
  "https://jmlr.org/papers/v20/18-277.html": {
    "title": "TensorLy: Tensor Learning in Python",
    "volume": "MLOSS",
    "abstract": "Tensors are higher-order extensions of matrices. While matrix methods form the cornerstone of traditional machine learning and data analysis, tensor methods have been gaining increasing traction. However, software support for tensor operations is not on the same footing. In order to bridge this gap, we have developed TensorLy, a Python library that provides a high-level API for tensor methods and deep tensorized neural networks. TensorLy aims to follow the same standards adopted by the main projects of the Python scientific community, and to seamlessly integrate with them. Its BSD license makes it suitable for both academic and commercial applications. TensorLy's backend system allows users to perform computations with several libraries such as NumPy or PyTorch to name but a few. They can be scaled on multiple CPU or GPU machines. In addition, using the deep-learning frameworks as backend allows to easily design and train deep tensorized neural networks. TensorLy is available at https://github.com/tensorly/tensorly",
    "checked": true,
    "id": "28d2503b0f86dd3947bf745efdd609dee7975cd8",
    "semantic_title": "tensorly: tensor learning in python",
    "citation_count": 272
  },
  "https://jmlr.org/papers/v20/18-281.html": {
    "title": "Monotone Learning with Rectified Wire Networks",
    "volume": "main",
    "abstract": "We introduce a new neural network model, together with a tractable and monotone online learning algorithm. Our model describes feed-forward networks for classification, with one output node for each class. The only nonlinear operation is rectification using a ReLU function with a bias. However, there is a rectifier on every edge rather than at the nodes of the network. There are also weights, but these are positive, static, and associated with the nodes. Our rectified wire networks are able to represent arbitrary Boolean functions. Only the bias parameters, on the edges of the network, are learned. Another departure in our approach, from standard neural networks, is that the loss function is replaced by a constraint. This constraint is simply that the value of the output node associated with the correct class should be zero. Our model has the property that the exact norm-minimizing parameter update, required to correctly classify a training item, is the solution to a quadratic program that can be computed with a few passes through the network. We demonstrate a training algorithm using this update, called sequential deactivation (SDA), on MNIST and some synthetic datasets. Upon adopting a natural choice for the nodal weights, SDA has no hyperparameters other than those describing the network structure. Our experiments explore behavior with respect to network size and depth in a family of sparse expander networks",
    "checked": true,
    "id": "bffedee01c334cf39694b70ffd36663e818490b8",
    "semantic_title": "monotone learning with rectified wire networks",
    "citation_count": 0
  },
  "https://jmlr.org/papers/v20/18-403.html": {
    "title": "Pyro: Deep Universal Probabilistic Programming",
    "volume": "MLOSS",
    "abstract": "Pyro is a probabilistic programming language built on Python as a platform for developing advanced probabilistic models in AI research. To scale to large data sets and high-dimensional models, Pyro uses stochastic variational inference algorithms and probability distributions built on top of PyTorch, a modern GPU-accelerated deep learning framework. To accommodate complex or model-specific algorithmic behavior, Pyro leverages Poutine, a library of composable building blocks for modifying the behavior of probabilistic programs",
    "checked": true,
    "id": "11f4765ea4404742dc12dbdb06430873563a0a9d",
    "semantic_title": "pyro: deep universal probabilistic programming",
    "citation_count": 725
  },
  "https://jmlr.org/papers/v20/18-539.html": {
    "title": "Iterated Learning in Dynamic Social Networks",
    "volume": "main",
    "abstract": "A classic finding by (Kalish et al., 2007) shows that no language can be learned iteratively by rational agents in a self-sustained manner. In other words, if $A$ teaches a foreign language to $B$, who then teaches what she learned to $C$, and so on, the language will quickly get lost and agents will wind up teaching their own common native language. If so, how can linguistic novelty ever be sustained? We address this apparent paradox by considering the case of iterated learning in a social network: we show that by varying the lengths of the learning sessions over time or by keeping the networks dynamic, it is possible for iterated learning to endure forever with arbitrarily small loss",
    "checked": true,
    "id": "622b0d5e3edc89eea55b2179e84424b3265c68ff",
    "semantic_title": "iterated learning in dynamic social networks",
    "citation_count": 5
  },
  "https://jmlr.org/papers/v20/16-128.html": {
    "title": "Exact Clustering of Weighted Graphs via Semidefinite Programming",
    "volume": "main",
    "abstract": "As a model problem for clustering, we consider the densest $k$-disjoint-clique problem of partitioning a weighted complete graph into $k$ disjoint subgraphs such that the sum of the densities of these subgraphs is maximized. We establish that such subgraphs can be recovered from the solution of a particular semidefinite relaxation with high probability if the input graph is sampled from a distribution of clusterable graphs. Specifically, the semidefinite relaxation is exact if the graph consists of \\(k\\) large disjoint subgraphs, corresponding to clusters, with weight concentrated within these subgraphs, plus a moderate number of nodes not belonging to any cluster. Further, we establish that if noise is weakly obscuring these clusters, i.e, the between-cluster edges are assigned very small weights, then we can recover significantly smaller clusters. For example, we show that in approximately sparse graphs, where the between-cluster weights tend to zero as the size $n$ of the graph tends to infinity, we can recover clusters of size polylogarithmic in $n$ under certain conditions on the distribution of edge weights. Empirical evidence from numerical simulations is also provided to support these theoretical phase transitions to perfect recovery of the cluster structure",
    "checked": true,
    "id": "17c9cc1c1692641efc0506fad0d087e1aa6ed72e",
    "semantic_title": "exact clustering of weighted graphs via semidefinite programming",
    "citation_count": 3
  },
  "https://jmlr.org/papers/v20/16-314.html": {
    "title": "Kernels for Sequentially Ordered Data",
    "volume": "main",
    "abstract": "We present a novel framework for learning with sequential data of any kind, such as multivariate time series, strings, or sequences of graphs. The main result is a \"sequentialization\" that transforms any kernel on a given domain into a kernel for sequences in that domain. This procedure preserves properties such as positive definiteness, the associated kernel feature map is an ordered variant of sample (cross-)moments, and this sequentialized kernel is consistent in the sense that it converges to a kernel for paths if sequences converge to paths (by discretization). Further, classical kernels for sequences arise as special cases of this method. We use dynamic programming and low-rank techniques for tensors to provide efficient algorithms to compute this sequentialized kernel",
    "checked": true,
    "id": "b295d399d565883f429d2b38c062dc97735542ad",
    "semantic_title": "kernels for sequentially ordered data",
    "citation_count": 97
  },
  "https://jmlr.org/papers/v20/17-066.html": {
    "title": "NetSDM: Semantic Data Mining with Network Analysis",
    "volume": "main",
    "abstract": "Semantic data mining (SDM) is a form of relational data mining that uses annotated data together with complex semantic background knowledge to learn rules that can be easily interpreted. The drawback of SDM is a high computational complexity of existing SDM algorithms, resulting in long run times even when applied to relatively small data sets. This paper proposes an effective SDM approach, named NetSDM, which first transforms the available semantic background knowledge into a network format, followed by network analysis based node ranking and pruning to significantly reduce the size of the original background knowledge. The experimental evaluation of the NetSDM methodology on acute lymphoblastic leukemia and breast cancer data demonstrates that NetSDM achieves radical time efficiency improvements and that learned rules are comparable or better than the rules obtained by the original SDM algorithms",
    "checked": true,
    "id": "5355076389b2d1c99f369623ab55bd2b4677dd19",
    "semantic_title": "netsdm: semantic data mining with network analysis",
    "citation_count": 12
  },
  "https://jmlr.org/papers/v20/17-147.html": {
    "title": "The Relationship Between Agnostic Selective Classification, Active Learning and the Disagreement Coefficient",
    "volume": "main",
    "abstract": "A selective classifier $(f,g)$ comprises a classification function $f$ and a binary selection function $g$, which determines if the classifier abstains from prediction, or uses $f$ to predict. The classifier is called pointwise-competitive if it classifies each point identically to the best classifier in hindsight (from the same class), whenever it does not abstain. The quality of such a classifier is quantified by its rejection mass, defined to be the probability mass of the points it rejects. A \"fast\" rejection rate is achieved if the rejection mass is bounded from above by $\\tilde{O}(1/m)$ where $m$ is the number of labeled examples used to train the classifier (and $\\tilde{O}$ hides logarithmic factors). Pointwise-competitive selective (PCS) classifiers are intimately related to disagreement-based active learning and it is known that in the realizable case, a fast rejection rate of a known PCS algorithm (called Consistent Selective Strategy) is equivalent to an exponential speedup of the well-known CAL active algorithm. We focus on the agnostic setting, for which there is a known algorithm called LESS that learns a PCS classifier and achieves a fast rejection rate (depending on Hannekes disagreement coefficient) under strong assumptions. We present an improved PCS learning algorithm called ILESS for which we show a fast rate (depending on Hanneke's disagreement coefficient) without any assumptions. Our rejection bound smoothly interpolates the realizable and agnostic settings. The main result of this paper is an equivalence between the following three entities: (i) the existence of a fast rejection rate for any PCS learning algorithm (such as ILESS); (ii) a poly-logarithmic bound for Hanneke's disagreement coefficient; and (iii) an exponential speedup for a new disagreement-based active learner called {\\ActiveiLESS}",
    "checked": true,
    "id": "f56e46fdb8b1155b76674cc9b0dfb3efdbd87e06",
    "semantic_title": "the relationship between agnostic selective classification active learning and the disagreement coefficient",
    "citation_count": 10
  },
  "https://jmlr.org/papers/v20/17-153.html": {
    "title": "Matched Bipartite Block Model with Covariates",
    "volume": "main",
    "abstract": "Community detection or clustering is a fundamental task in the analysis of network data. Many real networks have a bipartite structure which makes community detection challenging. In this paper, we consider a model which allows for matched communities in the bipartite setting, in addition to node covariates with information about the matching. We derive a simple fast algorithm for fitting the model based on variational inference ideas and show its effectiveness on both simulated and real data. A variation of the model to allow for degree-correction is also considered, in addition to a novel approach to fitting such degree-corrected models",
    "checked": true,
    "id": "3b7149ed6824f4a7c53caf4e83b7ae3a48087073",
    "semantic_title": "matched bipartite block model with covariates",
    "citation_count": 20
  },
  "https://jmlr.org/papers/v20/17-185.html": {
    "title": "Optimal Policies for Observing Time Series and Related Restless Bandit Problems",
    "volume": "main",
    "abstract": "The trade-off between the cost of acquiring and processing data, and uncertainty due to a lack of data is fundamental in machine learning. A basic instance of this trade-off is the problem of deciding when to make noisy and costly observations of a discrete-time Gaussian random walk, so as to minimise the posterior variance plus observation costs. We present the first proof that a simple policy, which observes when the posterior variance exceeds a threshold, is optimal for this problem. The proof generalises to a wide range of cost functions other than the posterior variance. It is based on a new verification theorem by Nino-Mora that guarantees threshold structure for Markov decision processes, and on the relation between binary sequences known as Christoffel words and the dynamics of discontinuous nonlinear maps, which frequently arise in physics, control and biology. This result implies that optimal policies for linear-quadratic-Gaussian control with costly observations have a threshold structure. It also implies that the restless bandit problem of observing multiple such time series, has a well-defined Whittle index policy. We discuss computation of that index, give closed-form formulae for it, and compare the performance of the associated index policy with heuristic policies",
    "checked": true,
    "id": "c0e566822d38e8808da80a2bf9a9a19ece10c098",
    "semantic_title": "optimal policies for observing time series and related restless bandit problems",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v20/17-286.html": {
    "title": "A New Approach to Laplacian Solvers and Flow Problems",
    "volume": "main",
    "abstract": "This paper investigates the behavior of the Min-Sum message passing scheme to solve systems of linear equations in the Laplacian matrices of graphs and to compute electric flows. Voltage and flow problems involve the minimization of quadratic functions and are fundamental primitives that arise in several domains. Algorithms that have been proposed are typically centralized and involve multiple graph-theoretic constructions or sampling mechanisms that make them difficult to implement and analyze. On the other hand, message passing routines are distributed, simple, and easy to implement. In this paper we establish a framework to analyze Min-Sum to solve voltage and flow problems. We characterize the error committed by the algorithm on general weighted graphs in terms of hitting times of random walks defined on the computation trees that support the operations of the algorithms with time. For $d$-regular graphs with equal weights, we show that the convergence of the algorithms is controlled by the total variation distance between the distributions of non-backtracking random walks defined on the original graph that start from neighboring nodes. The framework that we introduce extends the analysis of Min-Sum to settings where the contraction arguments previously considered in the literature (based on the assumption of walk summability or scaled diagonal dominance) can not be used, possibly in the presence of constraints",
    "checked": true,
    "id": "2af38bc0b96872575320c8c137a4704c5b55be34",
    "semantic_title": "a new approach to laplacian solvers and flow problems",
    "citation_count": 6
  },
  "https://jmlr.org/papers/v20/17-324.html": {
    "title": "A Well-Tempered Landscape for Non-convex Robust Subspace Recovery",
    "volume": "main",
    "abstract": "We present a mathematical analysis of a non-convex energy landscape for robust subspace recovery. We prove that an underlying subspace is the only stationary point and local minimizer in a specified neighborhood under a deterministic condition on a dataset. If the deterministic condition is satisfied, we further show that a geodesic gradient descent method over the Grassmannian manifold can exactly recover the underlying subspace when the method is properly initialized. Proper initialization by principal component analysis is guaranteed with a simple deterministic condition. Under slightly stronger assumptions, the gradient descent method with a piecewise constant step-size scheme achieves linear convergence. The practicality of the deterministic condition is demonstrated on some statistical models of data, and the method achieves almost state-of-the-art recovery guarantees on the Haystack Model for different regimes of sample size and ambient dimension. In particular, when the ambient dimension is fixed and the sample size is large enough, we show that our gradient method can exactly recover the underlying subspace for any fixed fraction of outliers (less than 1)",
    "checked": true,
    "id": "65f233478263b77b48dc435d73bf3647f4ae4027",
    "semantic_title": "a well-tempered landscape for non-convex robust subspace recovery",
    "citation_count": 57
  },
  "https://jmlr.org/papers/v20/17-373.html": {
    "title": "Approximation Hardness for A Class of Sparse Optimization Problems",
    "volume": "main",
    "abstract": "In this paper, we consider three typical optimization problems with a convex loss function and a nonconvex sparse penalty or constraint. For the sparse penalized problem, we prove that finding an $\\mathcal{O}(n^{c_1}d^{c_2})$-optimal solution to an $n\\times d$ problem is strongly NP-hard for any $c_1, c_2\\in [0,1)$ such that $c_1+c_2<1$. For two constrained versions of the sparse optimization problem, we show that it is intractable to approximately compute a solution path associated with increasing values of some tuning parameter. The hardness results apply to a broad class of loss functions and sparse penalties. They suggest that one cannot even approximately solve these three problems in polynomial time, unless P $=$ NP",
    "checked": true,
    "id": "8e1bf761b81ac08fa153bb8fd3eb95cd3dc1f78f",
    "semantic_title": "approximation hardness for a class of sparse optimization problems",
    "citation_count": 16
  },
  "https://jmlr.org/papers/v20/17-451.html": {
    "title": "A Bootstrap Method for Error Estimation in Randomized Matrix Multiplication",
    "volume": "main",
    "abstract": "In recent years, randomized methods for numerical linear algebra have received growing interest as a general approach to large-scale problems. Typically, the essential ingredient of these methods is some form of randomized dimension reduction, which accelerates computations, but also creates random approximation error. In this way, the dimension reduction step encodes a tradeoff between cost and accuracy. However, the exact numerical relationship between cost and accuracy is typically unknown, and consequently, it may be difficult for the user to precisely know (1) how accurate a given solution is, or (2) how much computation is needed to achieve a given level of accuracy. In the current paper, we study randomized matrix multiplication (sketching) as a prototype setting for addressing these general problems. As a solution, we develop a bootstrap method for directly estimating the accuracy as a function of the reduced dimension (as opposed to deriving worst-case bounds on the accuracy in terms of the reduced dimension). From a computational standpoint, the proposed method does not substantially increase the cost of standard sketching methods, and this is made possible by an \"extrapolation\" technique. In addition, we provide both theoretical and empirical results to demonstrate the effectiveness of the proposed method",
    "checked": true,
    "id": "2ffe9c774ad6405d0c3be0cf7ec0eff5320505f3",
    "semantic_title": "a bootstrap method for error estimation in randomized matrix multiplication",
    "citation_count": 12
  },
  "https://jmlr.org/papers/v20/17-526.html": {
    "title": "Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I: Mathematical Foundations",
    "volume": "main",
    "abstract": "We develop the mathematical foundations of the stochastic modified equations (SME) framework for analyzing the dynamics of stochastic gradient algorithms, where the latter is approximated by a class of stochastic differential equations with small noise parameters. We prove that this approximation can be understood mathematically as an weak approximation, which leads to a number of precise and useful results on the approximations of stochastic gradient descent (SGD), momentum SGD and stochastic Nesterov's accelerated gradient method in the general setting of stochastic objectives. We also demonstrate through explicit calculations that this continuous-time approach can uncover important analytical insights into the stochastic gradient algorithms under consideration that may not be easy to obtain in a purely discrete-time setting",
    "checked": true,
    "id": "c0d770fa10b6510828afdde2040e5c63fb61c457",
    "semantic_title": "stochastic modified equations and dynamics of stochastic gradient algorithms i: mathematical foundations",
    "citation_count": 101
  },
  "https://jmlr.org/papers/v20/17-576.html": {
    "title": "Decontamination of Mutual Contamination Models",
    "volume": "main",
    "abstract": "Many machine learning problems can be characterized by \\emph{mutual contamination models}. In these problems, one observes several random samples from different convex combinations of a set of unknown base distributions and the goal is to infer these base distributions. This paper considers the general setting where the base distributions are defined on arbitrary probability spaces. We examine three popular machine learning problems that arise in this general setting: multiclass classification with label noise, demixing of mixed membership models, and classification with partial labels. In each case, we give sufficient conditions for identifiability and present algorithms for the infinite and finite sample settings, with associated performance guarantees",
    "checked": true,
    "id": "a936f7ad56361f0bf48e17fe7e48759aff18b2ac",
    "semantic_title": "decontamination of mutual contamination models",
    "citation_count": 20
  },
  "https://jmlr.org/papers/v20/17-594.html": {
    "title": "Utilizing Second Order Information in Minibatch Stochastic Variance Reduced Proximal Iterations",
    "volume": "main",
    "abstract": "We present a novel minibatch stochastic optimization method for empirical risk minimization of linear predictors. The method efficiently leverages both sub-sampled first-order and higher-order information, by incorporating variance-reduction and acceleration techniques. We prove improved iteration complexity over state-of-the-art methods under suitable conditions. In particular, the approach enjoys global fast convergence for quadratic convex objectives and local fast convergence for general convex objectives. Experiments are provided to demonstrate the empirical advantage of the proposed method over existing approaches in the literature",
    "checked": true,
    "id": "5cc94bfeca4287f750e9c56ff2b21ae68c23ccb3",
    "semantic_title": "utilizing second order information in minibatch stochastic variance reduced proximal iterations",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v20/17-608.html": {
    "title": "DSCOVR: Randomized Primal-Dual Block Coordinate Algorithms for Asynchronous Distributed Optimization",
    "volume": "main",
    "abstract": "Machine learning with big data often involves large optimization models. For distributed optimization over a cluster of machines, frequent communication and synchronization of all model parameters (optimization variables) can be very costly. A promising solution is to use parameter servers to store different subsets of the model parameters, and update them asynchronously at different machines using local datasets. In this paper, we focus on distributed optimization of large linear models with convex loss functions, and propose a family of randomized primal-dual block coordinate algorithms that are especially suitable for asynchronous distributed implementation with parameter servers. In particular, we work with the saddle-point formulation of such problems which allows simultaneous data and model partitioning, and exploit its structure by doubly stochastic coordinate optimization with variance reduction (DSCOVR). Compared with other first-order distributed algorithms, we show that DSCOVR may require less amount of overall computation and communication, and less or no synchronization. We discuss the implementation details of the DSCOVR algorithms, and present numerical experiments on an industrial distributed computing system",
    "checked": true,
    "id": "0fc3bbd5412b2b2b18ea6d411c44675e4c77808e",
    "semantic_title": "dscovr: randomized primal-dual block coordinate algorithms for asynchronous distributed optimization",
    "citation_count": 56
  },
  "https://jmlr.org/papers/v20/17-722.html": {
    "title": "Picasso: A Sparse Learning Library for High Dimensional Data Analysis in R and Python",
    "volume": "MLOSS",
    "abstract": "We describe a new library named picasso, which implements a unified framework of pathwise coordinate optimization for a variety of sparse learning problems (e.g., sparse linear regression, sparse logistic regression, sparse Poisson regression and scaled sparse linear regression) combined with efficient active set selection strategies. Besides, the library allows users to choose different sparsity-inducing regularizers, including the convex $\\ell_1$, nonvoncex MCP and SCAD regularizers. The library is coded in \\texttt{C++} and has user-friendly R and Python wrappers. Numerical experiments demonstrate that picasso can scale up to large problems efficiently",
    "checked": true,
    "id": "53ed5d69c51d0d9825bea17ac2f32a66f6f0424c",
    "semantic_title": "picasso: a sparse learning library for high dimensional data analysis in r and python",
    "citation_count": 33
  },
  "https://jmlr.org/papers/v20/17-773.html": {
    "title": "Robust Frequent Directions with Application in Online Learning",
    "volume": "main",
    "abstract": "The frequent directions (FD) technique is a deterministic approach for online sketching that has many applications in machine learning. The conventional FD is a heuristic procedure that often outputs rank deficient matrices. To overcome the rank deficiency problem, we propose a new sketching strategy called robust frequent directions (RFD) by introducing a regularization term. RFD can be derived from an optimization problem. It updates the sketch matrix and the regularization term adaptively and jointly. RFD reduces the approximation error of FD without increasing the computational cost. We also apply RFD to online learning and propose an effective hyperparameter-free online Newton algorithm. We derive a regret bound for our online Newton algorithm based on RFD, which guarantees the robustness of the algorithm. The experimental studies demonstrate that the proposed method outperforms state-of-the-art second order online learning algorithms",
    "checked": true,
    "id": "693f556a2c3e95c020b47c3847cb4252159fa1c1",
    "semantic_title": "robust frequent directions with application in online learning",
    "citation_count": 17
  },
  "https://jmlr.org/papers/v20/18-063.html": {
    "title": "Boosted Kernel Ridge Regression: Optimal Learning Rates and Early Stopping",
    "volume": "main",
    "abstract": "In this paper, we introduce a learning algorithm, boosted kernel ridge regression (BKRR), that combines $L_2$-Boosting with the kernel ridge regression (KRR). We analyze the learning performance of this algorithm in the framework of learning theory. We show that BKRR provides a new bias-variance trade-off via tuning the number of boosting iterations, which is different from KRR via adjusting the regularization parameter. A (semi-)exponential bias-variance trade-off is derived for BKRR, exhibiting a stable relationship between the generalization error and the number of iterations. Furthermore, an adaptive stopping rule is proposed, with which BKRR achieves the optimal learning rate without saturation",
    "checked": true,
    "id": "58a3d72dd664dd69d779e759d61cdb52158c5ea1",
    "semantic_title": "boosted kernel ridge regression: optimal learning rates and early stopping",
    "citation_count": 18
  },
  "https://jmlr.org/papers/v20/18-170.html": {
    "title": "Analysis of spectral clustering algorithms for community detection: the general bipartite setting",
    "volume": "main",
    "abstract": "We consider spectral clustering algorithms for community detection under a general bipartite stochastic block model (SBM). A modern spectral clustering algorithm consists of three steps: (1) regularization of an appropriate adjacency or Laplacian matrix (2) a form of spectral truncation and (3) a kmeans type algorithm in the reduced spectral domain. We focus on the adjacency-based spectral clustering and for the first step, propose a new data-driven regularization that can restore the concentration of the adjacency matrix even for the sparse networks. This result is based on recent work on regularization of random binary matrices, but avoids using unknown population level parameters, and instead estimates the necessary quantities from the data. We also propose and study a novel variation of the spectral truncation step and show how this variation changes the nature of the misclassification rate in a general SBM. We then show how the consistency results can be extended to models beyond SBMs, such as inhomogeneous random graph models with approximate clusters, including a graphon clustering problem, as well as general sub-Gaussian biclustering. A theme of the paper is providing a better understanding of the analysis of spectral methods for community detection and establishing consistency results, under fairly general clustering models and for a wide regime of degree growths, including sparse cases where the average expected degree grows arbitrarily slowly",
    "checked": true,
    "id": "103f90e9d64ff6c51e797c6084c026096b5b98c8",
    "semantic_title": "analysis of spectral clustering algorithms for community detection: the general bipartite setting",
    "citation_count": 84
  },
  "https://jmlr.org/papers/v20/18-191.html": {
    "title": "Efficient augmentation and relaxation learning for individualized treatment rules using observational data",
    "volume": "main",
    "abstract": "Individualized treatment rules aim to identify if, when, which, and to whom treatment should be applied. A globally aging population, rising healthcare costs, and increased access to patient-level data have created an urgent need for high-quality estimators of individualized treatment rules that can be applied to observational data. A recent and promising line of research for estimating individualized treatment rules recasts the problem of estimating an optimal treatment rule as a weighted classification problem. We consider a class of estimators for optimal treatment rules that are analogous to convex large-margin classifiers. The proposed class applies to observational data and is doubly-robust in the sense that correct specification of either a propensity or outcome model leads to consistent estimation of the optimal individualized treatment rule. Using techniques from semiparametric efficiency theory, we derive rates of convergence for the proposed estimators and use these rates to characterize the bias-variance trade-off for estimating individualized treatment rules with classification-based methods. Simulation experiments informed by these results demonstrate that it is possible to construct new estimators within the proposed framework that significantly outperform existing ones. We illustrate the proposed methods using data from a labor training program and a study of inflammatory bowel syndrome",
    "checked": true,
    "id": "43af272ff85127b91b7319e55bd1198baa764ecf",
    "semantic_title": "efficient augmentation and relaxation learning for individualized treatment rules using observational data",
    "citation_count": 44
  },
  "https://jmlr.org/papers/v20/18-196.html": {
    "title": "Using Simulation to Improve Sample-Efficiency of Bayesian Optimization for Bipedal Robots",
    "volume": "main",
    "abstract": "Learning for control can acquire controllers for novel robotic tasks, paving the path for autonomous agents. Such controllers can be expert-designed policies, which typically require tuning of parameters for each task scenario. In this context, Bayesian optimization (BO) has emerged as a promising approach for automatically tuning controllers. However, sample-efficiency can still be an issue for high-dimensional policies on hardware. Here, we develop an approach that utilizes simulation to learn structured feature transforms that map the original parameter space into a domain-informed space. During BO, similarity between controllers is now calculated in this transformed space. Experiments on the ATRIAS robot hardware and simulation show that our approach succeeds at sample-efficiently learning controllers for multiple robots. Another question arises: What if the simulation significantly differs from hardware? To answer this, we create increasingly approximate simulators and study the effect of increasing simulation-hardware mismatch on the performance of Bayesian optimization. We also compare our approach to other approaches from literature, and find it to be more reliable, especially in cases of high mismatch. Our experiments show that our approach succeeds across different controller types, bipedal robot models and simulator fidelity levels, making it applicable to a wide range of bipedal locomotion problems",
    "checked": true,
    "id": "32c22f315c86abeb50d01aa3fe18d4a3fb28c10d",
    "semantic_title": "using simulation to improve sample-efficiency of bayesian optimization for bipedal robots",
    "citation_count": 23
  },
  "https://jmlr.org/papers/v20/18-213.html": {
    "title": "No-Regret Bayesian Optimization with Unknown Hyperparameters",
    "volume": "main",
    "abstract": "Bayesian optimization (BO) based on Gaussian process models is a powerful paradigm to optimize black-box functions that are expensive to evaluate. While several BO algorithms provably converge to the global optimum of the unknown function, they assume that the hyperparameters of the kernel are known in advance. This is not the case in practice and misspecification often causes these algorithms to converge to poor local optima. In this paper, we present the first BO algorithm that is provably no-regret and converges to the optimum without knowledge of the hyperparameters. During optimization we slowly adapt the hyperparameters of stationary kernels and thereby expand the associated function class over time, so that the BO algorithm considers more complex function candidates. Based on the theoretical insights, we propose several practical algorithms that achieve the empirical sample efficiency of BO with online hyperparameter estimation, but retain theoretical convergence guarantees. We evaluate our method on several benchmark problems",
    "checked": true,
    "id": "cd6cd14021fb5262bd00016ed31f190afd5a6f06",
    "semantic_title": "no-regret bayesian optimization with unknown hyperparameters",
    "citation_count": 43
  },
  "https://jmlr.org/papers/v20/18-241.html": {
    "title": "Bayesian Combination of Probabilistic Classifiers using Multivariate Normal Mixtures",
    "volume": "main",
    "abstract": "Ensemble methods are a powerful tool, often outperforming individual prediction models. Existing Bayesian ensembles either do not model the correlations between sources, or they are only capable of combining non-probabilistic predictions. We propose a new model, which overcomes these disadvantages. Transforming the probabilistic predictions with the inverse additive logistic transformation allows us to model the correlations with multivariate normal mixtures. We derive an efficient Gibbs sampler for the proposed model and implement a regularization method to make it more robust. We compare our method to related work and the classical linear opinion pool. Empirical evaluation on several toy and real-world data sets, including a case study on air-pollution forecasting, shows that the method outperforms other methods, while being robust and easy to use",
    "checked": true,
    "id": "08f5fb023ca39a421c0ec9ef39c350b458d7ab3e",
    "semantic_title": "bayesian combination of probabilistic classifiers using multivariate normal mixtures",
    "citation_count": 11
  },
  "https://jmlr.org/papers/v20/18-263.html": {
    "title": "Thompson Sampling Guided Stochastic Searching on the Line for Deceptive Environments with Applications to Root-Finding Problems",
    "volume": "main",
    "abstract": "The multi-armed bandit problem forms the foundation for solving a wide range of online stochastic optimization problems through a simple, yet effective mechanism. One simply casts the problem as a gambler who repeatedly pulls one out of N slot machine arms, eliciting random rewards. Learning of reward probabilities is then combined with reward maximization, by carefully balancing reward exploration against reward exploitation. In this paper, we address a particularly intriguing variant of the multi-armed bandit problem, referred to as the Stochastic Point Location (SPL) problem. The gambler is here only told whether the optimal arm (point) lies to the \"left\" or to the \"right\" of the arm pulled, with the feedback being erroneous with probability $1-\\pi$. This formulation thus targets optimization in continuous action spaces with both informative and deceptive feedback. To tackle this class of problems, we formulate a compact and scalable Bayesian representation of the solution space that simultaneously captures both the location of the optimal arm as well as the probability of receiving correct feedback. We further introduce the accompanying Thompson Sampling guided Stochastic Point Location (TS-SPL) scheme for balancing exploration against exploitation. By learning $\\pi$, TS-SPL also supports deceptive environments that are lying about the direction of the optimal arm. This, in turn, allows us to address the fundamental Stochastic Root Finding (SRF) problem. Empirical results demonstrate that our scheme deals with both deceptive and informative environments, significantly outperforming competing algorithms both for SRF and SPL",
    "checked": true,
    "id": "e59f26eace988f57cf4415447eccc8395ddc6342",
    "semantic_title": "thompson sampling guided stochastic searching on the line for deceptive environments with applications to root-finding problems",
    "citation_count": 1
  },
  "https://jmlr.org/papers/v20/18-444.html": {
    "title": "Tunability: Importance of Hyperparameters of Machine Learning Algorithms",
    "volume": "main",
    "abstract": "Modern supervised machine learning algorithms involve hyperparameters that have to be set before running them. Options for setting hyperparameters are default values from the software package, manual configuration by the user or configuring them for optimal predictive performance by a tuning procedure. The goal of this paper is two-fold. Firstly, we formalize the problem of tuning from a statistical point of view, define data-based defaults and suggest general measures quantifying the tunability of hyperparameters of algorithms. Secondly, we conduct a large-scale benchmarking study based on 38 datasets from the OpenML platform and six common machine learning algorithms. We apply our measures to assess the tunability of their parameters. Our results yield default values for hyperparameters and enable users to decide whether it is worth conducting a possibly time consuming tuning strategy, to focus on the most important hyperparameters and to choose adequate hyperparameter spaces for tuning",
    "checked": true,
    "id": "64f6dab6b4bcf5cd792e352ea15aeca05572e21e",
    "semantic_title": "tunability: importance of hyperparameters of machine learning algorithms",
    "citation_count": 369
  },
  "https://jmlr.org/papers/v20/18-476.html": {
    "title": "Deep Reinforcement Learning for Swarm Systems",
    "volume": "main",
    "abstract": "Recently, deep reinforcement learning (RL) methods have been applied successfully to multi-agent scenarios. Typically, the observation vector for decentralized decision making is represented by a concatenation of the (local) information an agent gathers about other agents. However, concatenation scales poorly to swarm systems with a large number of homogeneous agents as it does not exploit the fundamental properties inherent to these systems: (i) the agents in the swarm are interchangeable and (ii) the exact number of agents in the swarm is irrelevant. Therefore, we propose a new state representation for deep multi-agent RL based on mean embeddings of distributions, where we treat the agents as samples and use the empirical mean embedding as input for a decentralized policy. We define different feature spaces of the mean embedding using histograms, radial basis functions and neural networks trained end-to-end. We evaluate the representation on two well-known problems from the swarm literature in a globally and locally observable setup. For the local setup we furthermore introduce simple communication protocols. Of all approaches, the mean embedding representation using neural network features enables the richest information exchange between neighboring agents, facilitating the development of complex collective strategies",
    "checked": true,
    "id": "8b2a6808ce5cec406b41a8e77e67570246105bd0",
    "semantic_title": "deep reinforcement learning for swarm systems",
    "citation_count": 144
  },
  "https://jmlr.org/papers/v20/18-598.html": {
    "title": "Neural Architecture Search: A Survey",
    "volume": "main",
    "abstract": "Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated \\emph{neural architecture search} methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy",
    "checked": true,
    "id": "fa0558c947c648e7c80dd2ef449700c7114324bd",
    "semantic_title": "Correction to: Neural Architecture Search",
    "citation_count": 50
  },
  "https://jmlr.org/papers/v20/18-875.html": {
    "title": "Near Optimal Frequent Directions for Sketching Dense and Sparse Matrices",
    "volume": "main",
    "abstract": "Given a large matrix $A\\in\\mathbb{R}^{n\\times d}$, we consider the problem of computing a sketch matrix $B\\in\\mathbb{R}^{\\ell\\times d}$ which is significantly smaller than but still well approximates $A$. We consider the problems in the streaming model, where the algorithm can only make one pass over the input with limited working space, and we are interested in minimizing the covariance error $\\|A^TA-B^TB\\|_2.$ The popular Frequent Directions algorithm of \\cite{liberty2013simple} and its variants achieve optimal space-error tradeoffs. However, whether the running time can be improved remains an unanswered question. In this paper, we almost settle the question by proving that the time complexity of this problem is equivalent to that of matrix multiplication up to lower order terms. Specifically, we provide new space-optimal algorithms with faster running times and also show that the running times of our algorithms can be improved if and only if the state-of-the-art running time of matrix multiplication can be improved significantly",
    "checked": true,
    "id": "ba8f18cb579cebb7e7f8c2f94c81c541f6429f5a",
    "semantic_title": "near optimal frequent directions for sketching dense and sparse matrices",
    "citation_count": 22
  },
  "https://jmlr.org/papers/v20/13-580.html": {
    "title": "Multi-class Heterogeneous Domain Adaptation",
    "volume": "main",
    "abstract": "A crucial issue in heterogeneous domain adaptation (HDA) is the ability to learn a feature mapping between different types of features across domains. Inspired by language translation, a word translated from one language corresponds to only a few words in another language, we present an efficient method named Sparse Heterogeneous Feature Representation (SHFR) in this paper for multi-class HDA to learn a sparse feature transformation between domains with multiple classes. Specifically, we formulate the problem of learning the feature transformation as a compressed sensing problem by building multiple binary classifiers in the target domain as various measurement sensors, which are decomposed from the target multi-class classification problem. We show that the estimation error of the learned transformation decreases with the increasing number of binary classifiers. In other words, for adaptation across heterogeneous domains to be successful, it is necessary to construct a sufficient number of incoherent binary classifiers from the original multi-class classification problem. To achieve this, we propose to apply the error correcting output correcting (ECOC) scheme to generate incoherent classifiers. To speed up the learning of the feature transformation across domains, we apply an efficient batch-mode algorithm to solve the resultant nonnegative sparse recovery problem. Theoretically, we present a generalization error bound of our proposed HDA method under a multi-class setting. Lastly, we conduct extensive experiments on both synthetic and real-world datasets to demonstrate the superiority of our proposed method over existing state-of-the-art HDA methods in terms of prediction accuracy and training efficiency",
    "checked": true,
    "id": "5fac9e6115d8424075bad7ba5660786f2b4421c1",
    "semantic_title": "multi-class heterogeneous domain adaptation",
    "citation_count": 39
  },
  "https://jmlr.org/papers/v20/16-309.html": {
    "title": "The Common-directions Method for Regularized Empirical Risk Minimization",
    "volume": "main",
    "abstract": "State-of-the-art first- and second-order optimization methods are able to achieve either fast global linear convergence rates or quadratic convergence, but not both of them. In this work, we propose an interpolation between first- and second-order methods for regularized empirical risk minimization that exploits the problem structure to efficiently combine multiple update directions. Our method attains both optimal global linear convergence rate for first-order methods, and local quadratic convergence. Experimental results show that our method outperforms state-of-the-art first- and second-order optimization methods in terms of the number of data accesses, while is competitive in training time",
    "checked": true,
    "id": "7b53bbf573d27bfbf901a081da3261dab536ae53",
    "semantic_title": "the common-directions method for regularized empirical risk minimization",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v20/17-026.html": {
    "title": "Kernel Approximation Methods for Speech Recognition",
    "volume": "main",
    "abstract": "We study the performance of kernel methods on the acoustic modeling task for automatic speech recognition, and compare their performance to deep neural networks (DNNs). To scale the kernel methods to large data sets, we use the random Fourier feature method of Rahimi and Recht (2007). We propose two novel techniques for improving the performance of kernel acoustic models. First, we propose a simple but effective feature selection method which reduces the number of random features required to attain a fixed level of performance. Second, we present a number of metrics which correlate strongly with speech recognition performance when computed on the heldout set; we attain improved performance by using these metrics to decide when to stop training. Additionally, we show that the linear bottleneck method of Sainath et al. (2013a) improves the performance of our kernel models significantly, in addition to speeding up training and making the models more compact. Leveraging these three methods, the kernel methods attain token error rates between $0.5\\%$ better and $0.1\\%$ worse than fully-connected DNNs across four speech recognition data sets, including the TIMIT and Broadcast News benchmark tasks",
    "checked": true,
    "id": "9f928c849cd8ea7659b2262fbc50757de9831b78",
    "semantic_title": "kernel approximation methods for speech recognition",
    "citation_count": 41
  },
  "https://jmlr.org/papers/v20/17-340.html": {
    "title": "Robust Estimation of Derivatives Using Locally Weighted Least Absolute Deviation Regression",
    "volume": "main",
    "abstract": "In nonparametric regression, the derivative estimation has attracted much attention in recent years due to its wide applications. In this paper, we propose a new method for the derivative estimation using the locally weighted least absolute deviation regression. Different from the local polynomial regression, the proposed method does not require a finite variance for the error term and so is robust to the presence of heavy-tailed errors. Meanwhile, it does not require a zero median or a positive density at zero for the error term in comparison with the local median regression. We further show that the proposed estimator with random difference is asymptotically equivalent to the (infinitely) composite quantile regression estimator. In other words, running one regression is equivalent to combining infinitely many quantile regressions. In addition, the proposed method is also extended to estimate the derivatives at the boundaries and to estimate higher-order derivatives. For the equidistant design, we derive theoretical results for the proposed estimators, including the asymptotic bias and variance, consistency, and asymptotic normality. Finally, we conduct simulation studies to demonstrate that the proposed method has better performance than the existing methods in the presence of outliers and heavy-tailed errors, and analyze the Chinese house price data for the past ten years to illustrate the usefulness of the proposed method",
    "checked": true,
    "id": "66f943b855e0957343fee59c855d3d3c94cddff1",
    "semantic_title": "robust estimation of derivatives using locally weighted least absolute deviation regression",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v20/17-397.html": {
    "title": "The Sup-norm Perturbation of HOSVD and Low Rank Tensor Denoising",
    "volume": "main",
    "abstract": "The higher order singular value decomposition (HOSVD) of tensors is a generalization of matrix SVD. The perturbation analysis of HOSVD under random noise is more delicate than its matrix counterpart. Recently, polynomial time algorithms have been proposed where statistically optimal estimates of the singular subspaces and the low rank tensors are attainable in the Euclidean norm. In this article, we analyze the sup-norm perturbation bounds of HOSVD and introduce estimators of the singular subspaces with sharp deviation bounds in the sup-norm. We also investigate a low rank tensor denoising estimator and demonstrate its fast convergence rate with respect to the entry-wise errors. The sup-norm perturbation bounds reveal unconventional phase transitions for statistical learning applications such as the exact clustering in high dimensional Gaussian mixture model and the exact support recovery in sub-tensor localizations. In addition, the bounds established for HOSVD also elaborate the one-sided sup-norm perturbation bounds for the singular subspaces of unbalanced (or fat) matrices",
    "checked": true,
    "id": "61fdaa1aa8e5af8ef875130ac811f76d247b99e3",
    "semantic_title": "the sup-norm perturbation of hosvd and low rank tensor denoising",
    "citation_count": 24
  },
  "https://jmlr.org/papers/v20/17-498.html": {
    "title": "Multi-scale Online Learning: Theory and Applications to Online Auctions and Pricing",
    "volume": "main",
    "abstract": "We consider revenue maximization in online auction/pricing problems. A seller sells an identical item in each period to a new buyer, or a new set of buyers. For the online pricing problem, both when the arriving buyer bids or only responds to the posted price, we design algorithms whose regret bounds scale with the best fixed price in-hindsight, rather than the range of the values. Under the bidding model, we further show our algorithms achieve a revenue convergence rate that matches the offline sample complexity of the single-item single-buyer auction. We also show regret bounds that are scale free, and match the offline sample complexity, when comparing to a benchmark that requires a lower bound on the market share. We further expand our results beyond pricing to multi-buyer auctions, and obtain online learning algorithms for auctions, with convergence rates matching the known sample complexity upper bound of online single-item multi-buyer auctions. These results are obtained by generalizing the classical learning from experts and multi-armed bandit problems to their multi-scale versions. In this version, the reward of each action is in a different range, and the regret with respect to a given action scales with its own range, rather than the maximum range. We obtain almost optimal multi-scale regret bounds by introducing a new Online Mirror Descent (OMD) algorithm whose mirror map is the multi-scale version of the negative entropy function. We further generalize to the bandit setting by introducing the stochastic variant of this OMD algorithm",
    "checked": true,
    "id": "e6823924d761ac9ed8b858acdd9471efc4450203",
    "semantic_title": "multi-scale online learning: theory and applications to online auctions and pricing",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v20/17-612.html": {
    "title": "Nearly-tight VC-dimension and Pseudodimension Bounds for Piecewise Linear Neural Networks",
    "volume": "main",
    "abstract": "We prove new upper and lower bounds on the VC-dimension of deep neural networks with the ReLU activation function. These bounds are tight for almost the entire range of parameters. Letting $W$ be the number of weights and $L$ be the number of layers, we prove that the VC-dimension is $O(W L \\log(W))$, and provide examples with VC-dimension $\\Omega( W L \\log(W/L) )$. This improves both the previously known upper bounds and lower bounds. In terms of the number $U$ of non-linear units, we prove a tight bound $\\Theta(W U)$ on the VC-dimension. All of these bounds generalize to arbitrary piecewise linear activation functions, and also hold for the pseudodimensions of these function classes. Combined with previous results, this gives an intriguing range of dependencies of the VC-dimension on depth for networks with different non-linearities: there is no dependence for piecewise-constant, linear dependence for piecewise-linear, and no more than quadratic dependence for general piecewise-polynomial",
    "checked": true,
    "id": "9b464642fabd44ca9891d9ef9cdbd324eb5878f4",
    "semantic_title": "nearly-tight vc-dimension and pseudodimension bounds for piecewise linear neural networks",
    "citation_count": 296
  },
  "https://jmlr.org/papers/v20/17-621.html": {
    "title": "A Representer Theorem for Deep Kernel Learning",
    "volume": "main",
    "abstract": "In this paper we provide a finite-sample and an infinite-sample representer theorem for the concatenation of (linear combinations of) kernel functions of reproducing kernel Hilbert spaces. These results serve as mathematical foundation for the analysis of machine learning algorithms based on compositions of functions. As a direct consequence in the finite-sample case, the corresponding infinite-dimensional minimization problems can be recast into (nonlinear) finite-dimensional minimization problems, which can be tackled with nonlinear optimization algorithms. Moreover, we show how concatenated machine learning problems can be reformulated as neural networks and how our representer theorem applies to a broad class of state-of-the-art deep learning methods",
    "checked": true,
    "id": "546057eef99c59f46295e054a83303f3c972efc5",
    "semantic_title": "a representer theorem for deep kernel learning",
    "citation_count": 39
  },
  "https://jmlr.org/papers/v20/17-681.html": {
    "title": "Active Learning for Cost-Sensitive Classification",
    "volume": "main",
    "abstract": "We design an active learning algorithm for cost-sensitive multiclass classification: problems where different errors have different costs. Our algorithm, COAL, makes predictions by regressing to each label's cost and predicting the smallest. On a new example, it uses a set of regressors that perform well on past data to estimate possible costs for each label. It queries only the labels that could be the best, ignoring the sure losers. We prove COAL can be efficiently implemented for any regression family that admits squared loss optimization; it also enjoys strong guarantees with respect to predictive performance and labeling effort. We empirically compare COAL to passive learning and several active learning baselines, showing significant improvements in labeling effort and test cost on real-world datasets",
    "checked": true,
    "id": "f0bad439c8af545e80991a85bdf6ff27a2850955",
    "semantic_title": "active learning for cost-sensitive classification",
    "citation_count": 66
  },
  "https://jmlr.org/papers/v20/17-687.html": {
    "title": "Proximal Distance Algorithms: Theory and Practice",
    "volume": "main",
    "abstract": "Proximal distance algorithms combine the classical penalty method of constrained minimization with distance majorization. If $f(x)$ is the loss function, and $C$ is the constraint set in a constrained minimization problem, then the proximal distance principle mandates minimizing the penalized loss $f(x)+\\frac{\\rho}{2}dist(x,C)^2$ and following the solution $x_{\\rho}$ to its limit as $\\rho$ tends to $\\infty$. At each iteration the squared Euclidean distance $dist(x,C)^2$ is majorized by the spherical quadratic $\\|x-P_C(x_k)\\|^2$, where $P_C(x_k)$ denotes the projection of the current iterate $x_k$ onto $C$. The minimum of the surrogate function $f(x)+\\frac{\\rho}{2}\\|x-P_C(x_k)\\|^2$ is given by the proximal map $prox_{\\rho^{-1}f}[P_C(x_k)]$. The next iterate $x_{k+1}$ automatically decreases the original penalized loss for fixed $\\rho$. Since many explicit projections and proximal maps are known, it is straightforward to derive and implement novel optimization algorithms in this setting. These algorithms can take hundreds if not thousands of iterations to converge, but the simple nature of each iteration makes proximal distance algorithms competitive with traditional algorithms. For convex problems, proximal distance algorithms reduce to proximal gradient algorithms and therefore enjoy well understood convergence properties. For nonconvex problems, one can attack convergence by invoking Zangwill's theorem. Our numerical examples demonstrate the utility of proximal distance algorithms in various high-dimensional settings, including a) linear programming, b) constrained least squares, c) projection to the closest kinship matrix, d) projection onto a second-order cone constraint, e) calculation of Horn's copositive matrix index, f) linear complementarity programming, and g) sparse principal components analysis. The proximal distance algorithm in each case is competitive or superior in speed to traditional methods such as the interior point method and the alternating direction method of multipliers (ADMM). Source code for the numerical examples can be found at https://github.com/klkeys/proxdist",
    "checked": true,
    "id": "9a72659e37460c0ce0145421bdfbe231ca4fe68f",
    "semantic_title": "proximal distance algorithms: theory and practice",
    "citation_count": 29
  },
  "https://jmlr.org/papers/v20/17-734.html": {
    "title": "Learnability of Solutions to Conjunctive Queries",
    "volume": "main",
    "abstract": "The problem of learning the solution space of an unknown formula has been studied in multiple embodiments in computational learning theory. In this article, we study a family of such learning problems; this family contains, for each relational structure, the problem of learning the solution space of an unknown conjunctive query evaluated on the structure. A progression of results aimed to classify the learnability of each of the problems in this family, and thus far a culmination thereof was a positive learnability result generalizing all previous ones. This article completes the classification program towards which this progression of results strived, by presenting a negative learnability result that complements the mentioned positive learnability result. In addition, a further negative learnability result is exhibited, which indicates a dichotomy within the problems to which the first negative result applies. In order to obtain our negative results, we make use of universal-algebraic concepts",
    "checked": true,
    "id": "40cb4b98b53bf83f755aee87e44b5b5000ba689b",
    "semantic_title": "learnability of solutions to conjunctive queries",
    "citation_count": 5
  },
  "https://jmlr.org/papers/v20/17-750.html": {
    "title": "Variance-based Regularization with Convex Objectives",
    "volume": "main",
    "abstract": "We develop an approach to risk minimization and stochastic optimization that provides a convex surrogate for variance, allowing near-optimal and computationally efficient trading between approximation and estimation error. Our approach builds off of techniques for distributionally robust optimization and Owen's empirical likelihood, and we provide a number of finite-sample and asymptotic results characterizing the theoretical performance of the estimator. In particular, we show that our procedure comes with certificates of optimality, achieving (in some scenarios) faster rates of convergence than empirical risk minimization by virtue of automatically balancing bias and variance. We give corroborating empirical evidence showing that in practice, the estimator indeed trades between variance and absolute performance on a training sample, improving out-of-sample (test) performance over standard empirical risk minimization for a number of classification problems",
    "checked": true,
    "id": "6e77765dd3250fc671c413b44554087bad43ad92",
    "semantic_title": "variance-based regularization with convex objectives",
    "citation_count": 272
  },
  "https://jmlr.org/papers/v20/18-048.html": {
    "title": "On Consistent Vertex Nomination Schemes",
    "volume": "main",
    "abstract": "Given a vertex of interest in a network $G_1$, the vertex nomination problem seeks to find the corresponding vertex of interest (if it exists) in a second network $G_2$. A vertex nomination scheme produces a list of the vertices in $G_2$, ranked according to how likely they are judged to be the corresponding vertex of interest in $G_2$. The vertex nomination problem and related information retrieval tasks have attracted much attention in the machine learning literature, with numerous applications to social and biological networks. However, the current framework has often been confined to a comparatively small class of network models, and the concept of statistically consistent vertex nomination schemes has been only shallowly explored. In this paper, we extend the vertex nomination problem to a very general statistical model of graphs. Further, drawing inspiration from the long-established classification framework in the pattern recognition literature, we provide definitions for the key notions of Bayes optimality and consistency in our extended vertex nomination framework, including a derivation of the Bayes optimal vertex nomination scheme. In addition, we prove that no universally consistent vertex nomination schemes exist. Illustrative examples are provided throughout",
    "checked": true,
    "id": "7e8ebd9f5b7a3af305975a84154ac7b93b8a302e",
    "semantic_title": "on consistent vertex nomination schemes",
    "citation_count": 17
  },
  "https://jmlr.org/papers/v20/18-109.html": {
    "title": "Semi-Analytic Resampling in Lasso",
    "volume": "main",
    "abstract": "An approximate method for conducting resampling in Lasso, the $\\ell_1$ penalized linear regression, in a semi-analytic manner is developed, whereby the average over the resampled datasets is directly computed without repeated numerical sampling, thus enabling an inference free of the statistical fluctuations due to sampling finiteness, as well as a significant reduction of computational time. The proposed method is based on a message passing type algorithm, and its fast convergence is guaranteed by the state evolution analysis, when covariates are provided as zero-mean independently and identically distributed Gaussian random variables. It is employed to implement bootstrapped Lasso (Bolasso) and stability selection, both of which are variable selection methods using resampling in conjunction with Lasso, and resolves their disadvantage regarding computational cost. To examine approximation accuracy and efficiency, numerical experiments were carried out using simulated datasets. Moreover, an application to a real-world dataset, the wine quality dataset, is presented. To process such real-world datasets, an objective criterion for determining the relevance of selected variables is also introduced by the addition of noise variables and resampling. MATLAB codes implementing the proposed method are distributed in (Obuchi, 2018)",
    "checked": true,
    "id": "cabf4f515fc33b33341fe4ad6fddcf669f187714",
    "semantic_title": "semi-analytic resampling in lasso",
    "citation_count": 4
  },
  "https://jmlr.org/papers/v20/18-114.html": {
    "title": "Lazifying Conditional Gradient Algorithms",
    "volume": "main",
    "abstract": "Conditional gradient algorithms (also often called Frank-Wolfe algorithms) are popular due to their simplicity of only requiring a linear optimization oracle and more recently they also gained significant traction for online learning. While simple in principle, in many cases the actual implementation of the linear optimization oracle is costly. We show a general method to lazify various conditional gradient algorithms, which in actual computations leads to several orders of magnitude of speedup in wall-clock time. This is achieved by using a faster separation oracle instead of a linear optimization oracle, relying only on few linear optimization oracle calls",
    "checked": true,
    "id": "805188f5c03e5432eba9b868bf0e901cc51ca5cb",
    "semantic_title": "lazifying conditional gradient algorithms",
    "citation_count": 46
  },
  "https://jmlr.org/papers/v20/18-148.html": {
    "title": "Redundancy Techniques for Straggler Mitigation in Distributed Optimization and Learning",
    "volume": "main",
    "abstract": "Performance of distributed optimization and learning systems is bottlenecked by \"straggler\" nodes and slow communication links, which significantly delay computation. We propose a distributed optimization framework where the dataset is \"encoded\" to have an over-complete representation with built-in redundancy, and the straggling nodes in the system are dynamically treated as missing, or as \"erasures\" at every iteration, whose loss is compensated by the embedded redundancy. For quadratic loss functions, we show that under a simple encoding scheme, many optimization algorithms (gradient descent, L-BFGS, and proximal gradient) operating under data parallelism converge to an approximate solution even when stragglers are ignored. Furthermore, we show a similar result for a wider class of convex loss functions when operating under model parallelism. The applicable classes of objectives covers several popular learning problems such as linear regression, LASSO, support vector machine, collaborative filtering, and generalized linear models including logistic regression. These convergence results are deterministic, i.e., they establish sample path convergence for arbitrary sequences of delay patterns or distributions on the nodes, and are independent of the tail behavior of the delay distribution. We demonstrate that equiangular tight frames have desirable properties as encoding matrices, and propose efficient mechanisms for encoding large-scale data. We implement the proposed technique on Amazon EC2 clusters, and demonstrate its performance over several learning problems, including matrix factorization, LASSO, ridge regression and logistic regression, and compare the proposed method with uncoded, asynchronous, and data replication strategies",
    "checked": true,
    "id": "7d2fb9c0de7c222142a1f351e073008a19ccac5b",
    "semantic_title": "redundancy techniques for straggler mitigation in distributed optimization and learning",
    "citation_count": 48
  },
  "https://jmlr.org/papers/v20/18-173.html": {
    "title": "Analysis of Langevin Monte Carlo via Convex Optimization",
    "volume": "main",
    "abstract": "In this paper, we provide new insights on the Unadjusted Langevin Algorithm. We show that this method can be formulated as the first order optimization algorithm for an objective functional defined on the Wasserstein space of order $2$. Using this interpretation and techniques borrowed from convex optimization, we give a non-asymptotic analysis of this method to sample from log-concave smooth target distribution on $\\mathbb{R}^d$. Based on this interpretation, we propose two new methods for sampling from a non-smooth target distribution. These new algorithms are natural extensions of the Stochastic Gradient Langevin Dynamics (SGLD) algorithm, which is a popular extension of the Unadjusted Langevin Algorithm for largescale Bayesian inference. Using the optimization perspective, we provide non-asymptotic convergence analysis for the newly proposed methods",
    "checked": true,
    "id": "6a071644ee79857c26b6fd718663291d90421e92",
    "semantic_title": "analysis of langevin monte carlo via convex optimization",
    "citation_count": 151
  },
  "https://jmlr.org/papers/v20/18-232.html": {
    "title": "Deep Optimal Stopping",
    "volume": "main",
    "abstract": "In this paper we develop a deep learning method for optimal stopping problems which directly learns the optimal stopping rule from Monte Carlo samples. As such, it is broadly applicable in situations where the underlying randomness can efficiently be simulated. We test the approach on three problems: the pricing of a Bermudan max-call option, the pricing of a callable multi barrier reverse convertible and the problem of optimally stopping a fractional Brownian motion. In all three cases it produces very accurate results in high-dimensional situations with short computing times",
    "checked": true,
    "id": "989fd9d0de8d4f115e65a3cf653026b09eaf6ab6",
    "semantic_title": "deep optimal stopping",
    "citation_count": 149
  },
  "https://jmlr.org/papers/v20/18-262.html": {
    "title": "Fairness Constraints: A Flexible Approach for Fair Classification",
    "volume": "main",
    "abstract": "Algorithmic decision making is employed in an increasing number of real-world applicationstions to aid human decision making. While it has shown considerable promise in terms of improved decision accuracy, in some scenarios, its outcomes have been also shown to impose an unfair (dis)advantage on people from certain social groups (e.g., women, blacks). In this context, there is a need for computational techniques to limit unfairness in algorithmic decision making. In this work, we take a step forward to fulfill that need and introduce a flexible constraint-based framework to enable the design of fair margin-based classifiers. The main technical innovation of our framework is a general and intuitive measure of decision boundary unfairness, which serves as a tractable proxy to several of the most popular computational definitions of unfairness from the literature. Leveraging our measure, we can reduce the design of fair margin-based classifiers to adding tractable constraints on their decision boundaries. Experiments on multiple synthetic and real-world datasets show that our framework is able to successfully limit unfairness, often at a small cost in terms of accuracy",
    "checked": true,
    "id": "8b313c4c045bf3909e418e338b4e076e68955c85",
    "semantic_title": "fairness constraints: a flexible approach for fair classification",
    "citation_count": 227
  },
  "https://jmlr.org/papers/v20/18-278.html": {
    "title": "Generalized Score Matching for Non-Negative Data",
    "volume": "main",
    "abstract": "A common challenge in estimating parameters of probability density functions is the intractability of the normalizing constant. While in such cases maximum likelihood estimation may be implemented using numerical integration, the approach becomes computationally intensive. The score matching method of Hyvrinen (2005) avoids direct calculation of the normalizing constant and yields closed-form estimates for exponential families of continuous distributions over $\\mathbb{R}^m$. Hyvrinen (2007) extended the approach to distributions supported on the non-negative orthant, $\\mathbb{R}_+^m$. In this paper, we give a generalized form of score matching for non-negative data that improves estimation efficiency. As an example, we consider a general class of pairwise interaction models. Addressing an overlooked inexistence problem, we generalize the regularized score matching method of Lin et al. (2016) and improve its theoretical guarantees for non-negative Gaussian graphical models",
    "checked": true,
    "id": "83c8f55b622d82d2ed0bfd82bfd3262ee56aef4e",
    "semantic_title": "generalized score matching for non-negative data",
    "citation_count": 0
  },
  "https://jmlr.org/papers/v20/18-314.html": {
    "title": "Nonuniformity of P-values Can Occur Early in Diverging Dimensions",
    "volume": "main",
    "abstract": "Evaluating the joint significance of covariates is of fundamental importance in a wide range of applications. To this end, p-values are frequently employed and produced by algorithms that are powered by classical large-sample asymptotic theory. It is well known that the conventional p-values in Gaussian linear model are valid even when the dimensionality is a non-vanishing fraction of the sample size, but can break down when the design matrix becomes singular in higher dimensions or when the error distribution deviates from Gaussianity. A natural question is when the conventional p-values in generalized linear models become invalid in diverging dimensions. We establish that such a breakdown can occur early in nonlinear models. Our theoretical characterizations are confirmed by simulation studies",
    "checked": true,
    "id": "f2e01223509292a0e2829046ded30baea2e21a3a",
    "semantic_title": "nonuniformity of p-values can occur early in diverging dimensions",
    "citation_count": 59
  },
  "https://jmlr.org/papers/v20/18-321.html": {
    "title": "Prediction Risk for the Horseshoe Regression",
    "volume": "main",
    "abstract": "We show that prediction performance for global-local shrinkage regression can overcome two major difficulties of global shrinkage regression: (i) the amount of relative shrinkage is monotone in the singular values of the design matrix and (ii) the shrinkage is determined by a single tuning parameter. Specifically, we show that the horseshoe regression, with heavy-tailed component-specific local shrinkage parameters, in conjunction with a global parameter providing shrinkage towards zero, alleviates both these difficulties and consequently, results in an improved risk for prediction. Numerical demonstrations of improved prediction over competing approaches in simulations and in a pharmacogenomics data set confirm our theoretical findings",
    "checked": true,
    "id": "b5695c0250549515554e793172e925151ce5e5b5",
    "semantic_title": "prediction risk for the horseshoe regression",
    "citation_count": 15
  },
  "https://jmlr.org/papers/v20/18-456.html": {
    "title": "Quantification Under Prior Probability Shift: the Ratio Estimator and its Extensions",
    "volume": "main",
    "abstract": "The quantification problem consists of determining the prevalence of a given label in a target population. However, one often has access to the labels in a sample from the training population but not in the target population. A common assumption in this situation is that of prior probability shift, that is, once the labels are known, the distribution of the features is the same in the training and target populations. In this paper, we derive a new lower bound for the risk of the quantification problem under the prior shift assumption. Complementing this lower bound, we present a new approximately minimax class of estimators, ratio estimators, which generalize several previous proposals in the literature. Using a weaker version of the prior shift assumption, which can be tested, we show that ratio estimators can be used to build confidence intervals for the quantification problem. We also extend the ratio estimator so that it can: (i) incorporate labels from the target population, when they are available and (ii) estimate how the prevalence of positive labels varies according to a function of certain covariates",
    "checked": true,
    "id": "50adf7b8fd1274149a195ef4a7b4ab9f84b3dd13",
    "semantic_title": "quantification under prior probability shift: the ratio estimator and its extensions",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v20/18-700.html": {
    "title": "Learning to Match via Inverse Optimal Transport",
    "volume": "main",
    "abstract": "We propose a unified data-driven framework based on inverse optimal transport that can learn adaptive, nonlinear interaction cost function from noisy and incomplete empirical matching matrix and predict new matching in various matching contexts. We emphasize that the discrete optimal transport plays the role of a variational principle which gives rise to an optimization based framework for modeling the observed empirical matching data. Our formulation leads to a non-convex optimization problem which can be solved efficiently by an alternating optimization method. A key novel aspect of our formulation is the incorporation of marginal relaxation via regularized Wasserstein distance, significantly improving the robustness of the method in the face of noisy or missing empirical matching data. Our model falls into the category of prescriptive models, which not only predict potential future matching, but is also able to explain what leads to empirical matching and quantifies the impact of changes in matching factors. The proposed approach has wide applicability including predicting matching in online dating, labor market, college application and crowdsourcing. We back up our claims with numerical experiments on both synthetic data and real world data sets",
    "checked": true,
    "id": "85ef31b2e770825d13d4074b8c2982a459703f39",
    "semantic_title": "learning to match via inverse optimal transport",
    "citation_count": 29
  },
  "https://jmlr.org/papers/v20/18-719.html": {
    "title": "Tight Lower Bounds on the VC-dimension of Geometric Set Systems",
    "volume": "main",
    "abstract": "The VC-dimension of a set system is a way to capture its complexity and has been a key parameter studied extensively in machine learning and geometry communities. In this paper, we resolve two longstanding open problems on bounding the VC-dimension of two fundamental set systems: $k$-fold unions/intersections of half-spaces and the simplices set system. Among other implications, it settles an open question in machine learning that was first studied in the foundational paper of Blumer et al. (1989) as well as by Eisenstat and Angluin (2007) and Johnson (2008)",
    "checked": true,
    "id": "8d49cb7b687f89a9cce91a6505fdac2a42df997e",
    "semantic_title": "tight lower bounds on the vc-dimension of geometric set systems",
    "citation_count": 13
  },
  "https://jmlr.org/papers/v20/18-859.html": {
    "title": "SMART: An Open Source Data Labeling Platform for Supervised Learning",
    "volume": "MLOSS",
    "abstract": "SMART is an open source web application designed to help data scientists and research teams efficiently build labeled training data sets for supervised machine learning tasks. SMART provides users with an intuitive interface for creating labeled data sets, supports active learning to help reduce the required amount of labeled data, and incorporates inter-rater reliability statistics to provide insight into label quality. SMART is designed to be platform agnostic and easily deployable to meet the needs of as many different research teams as possible. The project website https://rtiinternational.github.io/SMART/ contains links to the code repository and extensive user documentation",
    "checked": true,
    "id": "bbb6b74e502bbdc0f837bd9e5fb32cb1d3cebac0",
    "semantic_title": "smart: an open source data labeling platform for supervised learning",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v20/18-869.html": {
    "title": "On the optimality of the Hedge algorithm in the stochastic regime",
    "volume": "main",
    "abstract": "In this paper, we study the behavior of the Hedge algorithm in the online stochastic setting. We prove that anytime Hedge with decreasing learning rate, which is one of the simplest algorithm for the problem of prediction with expert advice, is remarkably both worst-case optimal and adaptive to the easier stochastic and adversarial with a gap problems. This shows that, in spite of its small, non-adaptive learning rate, Hedge possesses the same optimal regret guarantee in the stochastic case as recently introduced adaptive algorithms. Moreover, our analysis exhibits qualitative differences with other versions of the Hedge algorithm, such as the fixed-horizon variant (with constant learning rate) and the one based on the so-called \"doubling trick\", both of which fail to adapt to the easier stochastic setting. Finally, we determine the intrinsic limitations of anytime Hedge in the stochastic case, and discuss the improvements provided by more adaptive algorithms",
    "checked": true,
    "id": "571d681315405d9abea216478bc47693ea4d568b",
    "semantic_title": "on the optimality of the hedge algorithm in the stochastic regime",
    "citation_count": 43
  },
  "https://jmlr.org/papers/v20/19-008.html": {
    "title": "Differentiable Game Mechanics",
    "volume": "main",
    "abstract": "Deep learning is built on the foundational guarantee that gradient descent on an objective function converges to local minima. Unfortunately, this guarantee fails in settings, such as generative adversarial nets, that exhibit multiple interacting losses. The behavior of gradient-based methods in games is not well understood -- and is becoming increasingly important as adversarial and multi-objective architectures proliferate. In this paper, we develop new tools to understand and control the dynamics in $n$-player differentiable games. The key result is to decompose the game Jacobian into two components. The first, symmetric component, is related to potential games, which reduce to gradient descent on an implicit function. The second, antisymmetric component, relates to Hamiltonian games, a new class of games that obey a conservation law akin to conservation laws in classical mechanical systems. The decomposition motivates Symplectic Gradient Adjustment (SGA), a new algorithm for finding stable fixed points in differentiable games. Basic experiments show SGA is competitive with recently proposed algorithms for finding stable fixed points in GANs -- while at the same time being applicable to, and having guarantees in, much more general cases",
    "checked": true,
    "id": "d4f24c06a9366de30dea3965d3579c58b45e3fe4",
    "semantic_title": "differentiable game mechanics",
    "citation_count": 64
  },
  "https://jmlr.org/papers/v20/16-615.html": {
    "title": "Bayesian Space-Time Partitioning by Sampling and Pruning Spanning Trees",
    "volume": "main",
    "abstract": "A typical problem in spatial data analysis is regionalization or spatially constrained clustering, which consists of aggregating small geographical areas into larger regions. A major challenge when partitioning a map is the huge number of possible partitions that compose the search space. This is compounded if we are partitioning spatio-temporal data rather than purely spatial data. We introduce a spatio-temporal product partition model that deals with the regionalization problem in a probabilistic way. Random spanning trees are used as a tool to tackle the problem of searching the space of possible partitions making feasible this exploration. Based on this framework, we propose an efficient Gibbs sampler algorithm to sample from the posterior distribution of the parameters, specially the random partition. The proposed Gibbs sampler scheme carries out a random walk on the space of the spanning trees and the partitions induced by deleting tree edges. In the purely spatial situation, we compare our proposed model with other state-of-art regionalization techniques to partition maps using simulated and real social and health data. To illustrate how the temporal component is handled by the algorithm and to show how the spatial clusters vary along the time we presented an application using human development index data. The analysis shows that our proposed model is better than state-of-art alternatives. Another appealing feature of the method is that the prior distribution for the partition is interpretable with a trivial coin flipping mechanism allowing its easy elicitation",
    "checked": true,
    "id": "6a7d1c6b3a810262929a0f29357a49dc325d0312",
    "semantic_title": "bayesian space-time partitioning by sampling and pruning spanning trees",
    "citation_count": 19
  },
  "https://jmlr.org/papers/v20/16-627.html": {
    "title": "Streaming Principal Component Analysis From Incomplete Data",
    "volume": "main",
    "abstract": "Linear subspace models are pervasive in computational sciences and particularly used for large datasets which are often incomplete due to privacy issues or sampling constraints. Therefore, a critical problem is developing an efficient algorithm for detecting low-dimensional linear structure from incomplete data efficiently, in terms of both computational complexity and storage. In this paper we propose a streaming subspace estimation algorithm called Subspace Navigation via Interpolation from Partial Entries (SNIPE) that efficiently processes blocks of incomplete data to estimate the underlying subspace model. In every iteration, SNIPE finds the subspace that best fits the new data block but remains close to the previous estimate. We show that SNIPE is a streaming solver for the underlying nonconvex matrix completion problem, that it converges globally {to a stationary point of this program} regardless of initialization, and that the convergence is locally linear with high probability. We also find that SNIPE shows state-of-the-art performance in our numerical simulations",
    "checked": true,
    "id": "9b65be55124eb2724a2df2e4ccba8d4880164719",
    "semantic_title": "streaming principal component analysis from incomplete data",
    "citation_count": 6
  },
  "https://jmlr.org/papers/v20/17-666.html": {
    "title": "An asymptotic analysis of distributed nonparametric methods",
    "volume": "main",
    "abstract": "We investigate and compare the fundamental performance of several distributed learning methods that have been proposed recently. We do this in the context of a distributed version of the classical signal-in-Gaussian-white-noise model, which serves as a benchmark model for studying performance in this setting. The results show how the design and tuning of a distributed method can have great impact on convergence rates and validity of uncertainty quantification. Moreover, we highlight the difficulty of designing nonparametric distributed procedures that automatically adapt to smoothness",
    "checked": true,
    "id": "c046988d0c1f89b2933df97863d4f82c78f58845",
    "semantic_title": "an asymptotic analysis of distributed nonparametric methods",
    "citation_count": 35
  },
  "https://jmlr.org/papers/v20/17-669.html": {
    "title": "Model Selection via the VC Dimension",
    "volume": "main",
    "abstract": "We derive an objective function that can be optimized to give an estimator for the Vapnik-Chervonenkis dimension for use in model selection in regression problems. We verify our estimator is consistent. Then, we verify it performs well compared to seven other model selection techniques. We do this for a variety of types of data sets",
    "checked": true,
    "id": "97221c2f9c9468f4d29724e7b4ec131d5014bd38",
    "semantic_title": "model selection via the vc dimension",
    "citation_count": 3
  },
  "https://jmlr.org/papers/v20/17-757.html": {
    "title": "Dependent relevance determination for smooth and structured sparse regression",
    "volume": "main",
    "abstract": "In many problem settings, parameter vectors are not merely sparse but dependent in such a way that non-zero coefficients tend to cluster together. We refer to this form of dependency as \"region sparsity.\" Classical sparse regression methods, such as the lasso and automatic relevance determination (ARD), which model parameters as independent a priori, and therefore do not exploit such dependencies. Here we introduce a hierarchical model for smooth, region-sparse weight vectors and tensors in a linear regression setting. Our approach represents a hierarchical extension of the relevance determination framework, where we add a transformed Gaussian process to model the dependencies between the prior variances of regression weights. We combine this with a structured model of the prior variances of Fourier coefficients, which eliminates unnecessary high frequencies. The resulting prior encourages weights to be region-sparse in two different bases simultaneously. We develop Laplace approximation and Monte Carlo Markov Chain (MCMC) sampling to provide efficient inference for the posterior. Furthermore, a two-stage convex relaxation of the Laplace approximation approach is also provided to relax the inevitable non-convexity during the optimization. We finally show substantial improvements over comparable methods for both simulated and real datasets from brain imaging",
    "checked": true,
    "id": "687dc216769b4d1afdf9d725a268995f699f84fa",
    "semantic_title": "dependent relevance determination for smooth and structured sparse regression",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v20/18-153.html": {
    "title": "A Particle-Based Variational Approach to Bayesian Non-negative Matrix Factorization",
    "volume": "main",
    "abstract": "Bayesian Non-negative Matrix Factorization (BNMF) is a promising approach for understanding uncertainty and structure in matrix data. However, a large volume of applied work optimizes traditional non-Bayesian NMF objectives that fail to provide a principled understanding of the non-identifiability inherent in NMF---an issue ideally addressed by a Bayesian approach. Despite their suitability, current BNMF approaches have failed to gain popularity in an applied setting; they sacrifice flexibility in modeling for tractable computation, tend to get stuck in local modes, and can require many thousands of samples for meaningful uncertainty estimates. We address these issues through a particle-based variational approach to BNMF that only requires the joint likelihood to be differentiable for computational tractability, uses a novel transfer-based initialization technique to identify multiple modes in the posterior, and thus allows domain experts to inspect a small set of factorizations that faithfully represent the posterior. On several real datasets, we obtain better particle approximations to the BNMF posterior in less time than baselines and demonstrate the significant role that multimodality plays in NMF-related tasks",
    "checked": true,
    "id": "bb0cbbaeec2affce83e9007ede9de581cb3cbf59",
    "semantic_title": "a particle-based variational approach to bayesian non-negative matrix factorization",
    "citation_count": 10
  },
  "https://jmlr.org/papers/v20/18-395.html": {
    "title": "Best Arm Identification for Contaminated Bandits",
    "volume": "main",
    "abstract": "This paper studies active learning in the context of robust statistics. Specifically, we propose a variant of the Best Arm Identification problem for contaminated bandits, where each arm pull has probability epsilon of generating a sample from an arbitrary contamination distribution instead of the true underlying distribution. The goal is to identify the best (or approximately best) true distribution with high probability, with a secondary goal of providing guarantees on the quality of this distribution. The primary challenge of the contaminated bandit setting is that the true distributions are only partially identifiable, even with infinite samples. To address this, we develop tight, non-asymptotic sample complexity bounds for high-probability estimation of the first two robust moments (median and median absolute deviation) from contaminated samples. These concentration inequalities are the main technical contributions of the paper and may be of independent interest. Using these results, we adapt several classical Best Arm Identification algorithms to the contaminated bandit setting and derive sample complexity upper bounds for our problem. Finally, we provide matching information-theoretic lower bounds on the sample complexity (up to a small logarithmic factor)",
    "checked": true,
    "id": "5ad0a3d8e5c4e78b049a4f9c3e271f6abcbf5e74",
    "semantic_title": "best arm identification for contaminated bandits",
    "citation_count": 39
  },
  "https://jmlr.org/papers/v20/18-450.html": {
    "title": "AffectiveTweets: a Weka Package for Analyzing Affect in Tweets",
    "volume": "MLOSS",
    "abstract": "AffectiveTweets is a set of programs for analyzing emotion and sentiment of social media messages such as tweets. It is implemented as a package for the Weka machine learning workbench and provides methods for calculating state-of-the-art affect analysis features from tweets that can be fed into machine learning algorithms implemented in Weka. It also implements methods for building affective lexicons and distant supervision methods for training affective models from unlabeled tweets. The package was used by several teams in the shared tasks: EmoInt 2017 and Affect in Tweets SemEval 2018 Task 1",
    "checked": true,
    "id": "ad23f5bd52db690e4006ade31d17e037470a2648",
    "semantic_title": "affectivetweets: a weka package for analyzing affect in tweets",
    "citation_count": 20
  },
  "https://jmlr.org/papers/v20/18-540.html": {
    "title": "iNNvestigate Neural Networks!",
    "volume": "MLOSS",
    "abstract": "In recent years, deep neural networks have revolutionized many application domains of machine learning and are key components of many critical decision or predictive processes. Therefore, it is crucial that domain specialists can understand and analyze actions and predictions, even of the most complex neural network architectures. Despite these arguments neural networks are often treated as black boxes. In the attempt to alleviate this shortcoming many analysis methods were proposed, yet the lack of reference implementations often makes a systematic comparison between the methods a major effort. The presented library innvestigate addresses this by providing a common interface and out-of-the-box implementation for many analysis methods, including the reference implementation for PatternNet and PatternAttribution as well as for LRP-methods. To demonstrate the versatility of innvestigate, we provide an analysis of image classifications for variety of state-of-the-art neural network architectures",
    "checked": true,
    "id": "d5d7b3c75c5a7bbc605236e7c722ecfb2cf8824e",
    "semantic_title": "innvestigate neural networks!",
    "citation_count": 280
  },
  "https://jmlr.org/papers/v20/18-549.html": {
    "title": "Simultaneous Private Learning of Multiple Concepts",
    "volume": "main",
    "abstract": "We investigate the direct-sum problem in the context of differentially private PAC learning: What is the sample complexity of solving $k$ learning tasks simultaneously under differential privacy, and how does this cost compare to that of solving $k$ learning tasks without privacy? In our setting, an individual example consists of a domain element $x$ labeled by $k$ unknown concepts $(c_1,\\ldots,c_k)$. The goal of a multi-learner is to output $k$ hypotheses $(h_1,\\ldots,h_k)$ that generalize the input examples. Without concern for privacy, the sample complexity needed to simultaneously learn $k$ concepts is essentially the same as needed for learning a single concept. Under differential privacy, the basic strategy of learning each hypothesis independently yields sample complexity that grows polynomially with $k$. For some concept classes, we give multi-learners that require fewer samples than the basic strategy. Unfortunately, however, we also give lower bounds showing that even for very simple concept classes, the sample cost of private multi-learning must grow polynomially in $k$",
    "checked": true,
    "id": "5ac576d3beece2d89be0f19bcbd88b142455c4e4",
    "semantic_title": "simultaneous private learning of multiple concepts",
    "citation_count": 74
  },
  "https://jmlr.org/papers/v20/18-819.html": {
    "title": "High-Dimensional Poisson Structural Equation Model Learning via $\\ell_1$-Regularized Regression",
    "volume": "main",
    "abstract": "In this paper, we develop a new approach to learning high-dimensional Poisson structural equation models from only observational data without strong assumptions such as faithfulness and a sparse moralized graph. A key component of our method is to decouple the ordering estimation or parent search where the problems can be efficiently addressed using $\\ell_1$-regularized regression and the moments relation. We show that sample size $n = \\Omega( d^{2} \\log^{9} p)$ is sufficient for our polynomial time Moments Ratio Scoring (MRS) algorithm to recover the true directed graph, where $p$ is the number of nodes and $d$ is the maximum indegree. We verify through simulations that our algorithm is statistically consistent in the high-dimensional $p>n$ setting, and performs well compared to state-of-the-art ODS, GES, and MMHC algorithms. We also demonstrate through multivariate real count data that our MRS algorithm is well-suited to estimating DAG models for multivariate count data in comparison to other methods used for discrete data",
    "checked": true,
    "id": "a7fc28a036ace32cd89cf4c657619bc511926212",
    "semantic_title": "high-dimensional poisson structural equation model learning via $\\ell_1$-regularized regression",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v20/19-011.html": {
    "title": "PyOD: A Python Toolbox for Scalable Outlier Detection",
    "volume": "MLOSS",
    "abstract": "PyOD is an open-source Python toolbox for performing scalable outlier detection on multivariate data. Uniquely, it provides access to a wide range of outlier detection algorithms, including established outlier ensembles and more recent neural network-based approaches, under a single, well-documented API designed for use by both practitioners and researchers. With robustness and scalability in mind, best practices such as unit testing, continuous integration, code coverage, maintainability checks, interactive examples and parallelization are emphasized as core components in the toolbox's development. PyOD is compatible with both Python 2 and 3 and can be installed through Python Package Index (PyPI) or https://github.com/yzhao062/pyod",
    "checked": true,
    "id": "5239f449210b089b75ab335fc74720dbf2e02b58",
    "semantic_title": "pyod: a python toolbox for scalable outlier detection",
    "citation_count": 436
  },
  "https://jmlr.org/papers/v20/15-504.html": {
    "title": "Relative Error Bound Analysis for Nuclear Norm Regularized Matrix Completion",
    "volume": "main",
    "abstract": "In this paper, we develop a relative error bound for nuclear norm regularized matrix completion, with the focus on the completion of full-rank matrices. Under the assumption that the top eigenspaces of the target matrix are incoherent, we derive a relative upper bound for recovering the best low-rank approximation of the unknown matrix. Although multiple works have been devoted to analyzing the recovery error of full-rank matrix completion, their error bounds are usually additive, making it impossible to obtain the perfect recovery case and more generally difficult to leverage the skewed distribution of eigenvalues. Our analysis is built upon the optimality condition of the regularized formulation and existing guarantees for low-rank matrix completion. To the best of our knowledge, this is the first relative bound that has been proved for the regularized formulation of matrix completion",
    "checked": true,
    "id": "e7be98df62efabe655392901a2718c6cae1b0154",
    "semantic_title": "relative error bound analysis for nuclear norm regularized matrix completion",
    "citation_count": 1
  },
  "https://jmlr.org/papers/v20/17-252.html": {
    "title": "Adaptive Geometric Multiscale Approximations for Intrinsically Low-dimensional Data",
    "volume": "main",
    "abstract": "We consider the problem of efficiently approximating and encoding high-dimensional data sampled from a probability distribution $\\rho$ in $\\mathbb{R}^D$, that is nearly supported on a $d$-dimensional set $\\mathcal{M}$ - for example supported on a $d$-dimensional manifold. Geometric Multi-Resolution Analysis (GMRA) provides a robust and computationally efficient procedure to construct low-dimensional geometric approximations of $\\mathcal{M}$ at varying resolutions. We introduce GMRA approximations that adapt to the unknown regularity of $\\mathcal{M}$, by introducing a thresholding algorithm on the geometric wavelet coefficients. We show that these data-driven, empirical geometric approximations perform well, when the threshold is chosen as a suitable universal function of the number of samples $n$, on a large class of measures $\\rho$, that are allowed to exhibit different regularity at different scales and locations, thereby efficiently encoding data from more complex measures than those supported on manifolds. These GMRA approximations are associated to a dictionary, together with a fast transform mapping data to $d$-dimensional coefficients, and an inverse of such a map, all of which are data-driven. The algorithms for both the dictionary construction and the transforms have complexity $C D n \\log n$ with the constant $C$ exponential in $d$. Our work therefore establishes Adaptive GMRA as a fast dictionary learning algorithm, with approximation guarantees, for intrinsically low-dimensional data. We include several numerical experiments on both synthetic and real data, confirming our theoretical results and demonstrating the effectiveness of Adaptive GMRA",
    "checked": true,
    "id": "af700f94f0faf689013b6fb796e5c79957300a0d",
    "semantic_title": "adaptive geometric multiscale approximations for intrinsically low-dimensional data",
    "citation_count": 15
  },
  "https://jmlr.org/papers/v20/17-352.html": {
    "title": "Change Surfaces for Expressive Multidimensional Changepoints and Counterfactual Prediction",
    "volume": "main",
    "abstract": "Identifying changes in model parameters is fundamental in machine learning and statistics. However, standard changepoint models are limited in expressiveness, often addressing unidimensional problems and assuming instantaneous changes. We introduce change surfaces as a multidimensional and highly expressive generalization of changepoints. We provide a model-agnostic formalization of change surfaces, illustrating how they can provide variable, heterogeneous, and non-monotonic rates of change across multiple dimensions. Additionally, we show how change surfaces can be used for counterfactual prediction. As a concrete instantiation of the change surface framework, we develop Gaussian Process Change Surfaces (GPCS). We demonstrate counterfactual prediction with Bayesian posterior mean and credible sets, as well as massive scalability by introducing novel methods for additive non-separable kernels. Using two large spatio-temporal datasets we employ GPCS to discover and characterize complex changes that can provide scientific and policy relevant insights. Specifically, we analyze twentieth century measles incidence across the United States and discover previously unknown heterogeneous changes after the introduction of the measles vaccine. Additionally, we apply the model to requests for lead testing kits in New York City, discovering distinct spatial and demographic patterns",
    "checked": true,
    "id": "ad8d017b0cf8221d69249be99f7e04bfde36c78b",
    "semantic_title": "change surfaces for expressive multidimensional changepoints and counterfactual prediction",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v20/17-452.html": {
    "title": "Hamiltonian Monte Carlo with Energy Conserving Subsampling",
    "volume": "main",
    "abstract": "Hamiltonian Monte Carlo (HMC) samples efficiently from high-dimensional posterior distributions with proposed parameter draws obtained by iterating on a discretized version of the Hamiltonian dynamics. The iterations make HMC computationally costly, especially in problems with large data sets, since it is necessary to compute posterior densities and their derivatives with respect to the parameters. Naively computing the Hamiltonian dynamics on a subset of the data causes HMC to lose its key ability to generate distant parameter proposals with high acceptance probability. The key insight in our article is that efficient subsampling HMC for the parameters is possible if both the dynamics and the acceptance probability are computed from the same data subsample in each complete HMC iteration. We show that this is possible to do in a principled way in a HMC-within-Gibbs framework where the subsample is updated using a pseudo marginal MH step and the parameters are then updated using an HMC step, based on the current subsample. We show that our subsampling methods are fast and compare favorably to two popular sampling algorithms that use gradient estimates from data subsampling. We also explore the current limitations of subsampling HMC algorithms by varying the quality of the variance reducing control variates used in the estimators of the posterior density and its gradients",
    "checked": true,
    "id": "f8bdcc501f853a32c00d44b149062b5db37d3dd8",
    "semantic_title": "hamiltonian monte carlo with energy conserving subsampling",
    "citation_count": 60
  },
  "https://jmlr.org/papers/v20/17-545.html": {
    "title": "Low Permutation-rank Matrices: Structural Properties and Noisy Completion",
    "volume": "main",
    "abstract": "We consider the problem of noisy matrix completion, in which the goal is to reconstruct a structured matrix whose entries are partially observed in noise. Standard approaches to this underdetermined inverse problem are based on assuming that the underlying matrix has low rank, or is well-approximated by a low rank matrix. In this paper, we propose a richer model based on what we term the permutation-rank of a matrix. We first describe how the classical non-negative rank model enforces restrictions that may be undesirable in practice, and how and these restrictions can be avoided by using the richer permutation-rank model. Second, we establish the minimax rates of estimation under the new permutation-based model, and prove that surprisingly, the minimax rates are equivalent up to logarithmic factors to those for estimation under the typical low rank model. Third, we analyze a computationally efficient singular-value-thresholding algorithm, known to be optimal for the low-rank setting, and show that it also simultaneously yields a consistent estimator for the low-permutation rank setting. Finally, we present various structural results characterizing the uniqueness of the permutation-rank decomposition, and characterizing convex approximations of the permutation-rank polytope",
    "checked": true,
    "id": "62763dbdd47f144c73663b6c6b5d95caeb318e43",
    "semantic_title": "low permutation-rank matrices: structural properties and noisy completion",
    "citation_count": 18
  },
  "https://jmlr.org/papers/v20/17-611.html": {
    "title": "Non-Convex Matrix Completion and Related Problems via Strong Duality",
    "volume": "main",
    "abstract": "This work studies the strong duality of non-convex matrix factorization problems: we show that under certain dual conditions, these problems and the dual have the same optimum. This has been well understood for convex optimization, but little was known for non-convex problems. We propose a novel analytical framework and prove that under certain dual conditions, the optimal solution of the matrix factorization program is the same as that of its bi-dual and thus the global optimality of the non-convex program can be achieved by solving its bi-dual which is convex. These dual conditions are satisfied by a wide class of matrix factorization problems, although matrix factorization is hard to solve in full generality. This analytical framework may be of independent interest to non-convex optimization more broadly. We apply our framework to two prototypical matrix factorization problems: matrix completion and robust Principal Component Analysis. These are examples of efficiently recovering a hidden matrix given limited reliable observations. Our framework shows that exact recoverability and strong duality hold with nearly-optimal sample complexity for the two problems",
    "checked": true,
    "id": "4012b6ae2e5a218205ed5e99e4f886cfcc7517bd",
    "semantic_title": "matrix completion and related problems via strong duality",
    "citation_count": 19
  },
  "https://jmlr.org/papers/v20/17-633.html": {
    "title": "Regularization via Mass Transportation",
    "volume": "main",
    "abstract": "The goal of regression and classification methods in supervised learning is to minimize the empirical risk, that is, the expectation of some loss function quantifying the prediction error under the empirical distribution. When facing scarce training data, overfitting is typically mitigated by adding regularization terms to the objective that penalize hypothesis complexity. In this paper we introduce new regularization techniques using ideas from distributionally robust optimization, and we give new probabilistic interpretations to existing techniques. Specifically, we propose to minimize the worst-case expected loss, where the worst case is taken over the ball of all (continuous or discrete) distributions that have a bounded transportation distance from the (discrete) empirical distribution. By choosing the radius of this ball judiciously, we can guarantee that the worst-case expected loss provides an upper confidence bound on the loss on test data, thus offering new generalization bounds. We prove that the resulting regularized learning problems are tractable and can be tractably kernelized for many popular loss functions. The proposed approach to regluarization is also extended to neural networks. We validate our theoretical out-of-sample guarantees through simulated and empirical experiments",
    "checked": true,
    "id": "7bdf0bb4adb6a884303597600398c6ef583f78c4",
    "semantic_title": "regularization via mass transportation",
    "citation_count": 152
  },
  "https://jmlr.org/papers/v20/18-035.html": {
    "title": "Complete Search for Feature Selection in Decision Trees",
    "volume": "main",
    "abstract": "The search space for the feature selection problem in decision tree learning is the lattice of subsets of the available features. We design an exact enumeration procedure of the subsets of features that lead to all and only the distinct decision trees built by a greedy top-down decision tree induction algorithm. The procedure stores, in the worst case, a number of trees linear in the number of features. By exploiting a further pruning of the search space, we design a complete procedure for finding $\\delta$-acceptable feature subsets, which depart by at most $\\delta$ from the best estimated error over any feature subset. Feature subsets with the best estimated error are called best feature subsets. Our results apply to any error estimator function, but experiments are mainly conducted under the wrapper model, in which the misclassification error over a search set is used as an estimator. The approach is also adapted to the design of a computational optimization of the sequential backward elimination heuristic, extending its applicability to large dimensional datasets. The procedures of this paper are implemented in a multi-core data parallel C++ system. We investigate experimentally the properties and limitations of the procedures on a collection of 20 benchmark datasets, showing that oversearching increases both overfitting and instability",
    "checked": true,
    "id": "d81ef9cd2a8f0298cfc886b9aa6d5a0159eb8efe",
    "semantic_title": "complete search for feature selection in decision trees",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v20/18-079.html": {
    "title": "Optimal Transport: Fast Probabilistic Approximation with Exact Solvers",
    "volume": "main",
    "abstract": "We propose a simple subsampling scheme for fast randomized approximate computation of optimal transport distances on finite spaces. This scheme operates on a random subset of the full data and can use any exact algorithm as a black-box back-end, including state-of-the-art solvers and entropically penalized versions. It is based on averaging the exact distances between empirical measures generated from independent samples from the original measures and can easily be tuned towards higher accuracy or shorter computation times. To this end, we give non-asymptotic deviation bounds for its accuracy in the case of discrete optimal transport problems. In particular, we show that in many important instances, including images (2D-histograms), the approximation error is independent of the size of the full problem. We present numerical experiments that demonstrate that a very good approximation in typical applications can be obtained in a computation time that is several orders of magnitude smaller than what is required for exact computation of the full problem",
    "checked": true,
    "id": "62d419b228ffbbba7314a4c61a3c962660f8af3c",
    "semantic_title": "optimal transport: fast probabilistic approximation with exact solvers",
    "citation_count": 38
  },
  "https://jmlr.org/papers/v20/18-172.html": {
    "title": "Solving the OSCAR and SLOPE Models Using a Semismooth Newton-Based Augmented Lagrangian Method",
    "volume": "main",
    "abstract": "The octagonal shrinkage and clustering algorithm for regression (OSCAR), equipped with the $\\ell_1$-norm and a pair-wise $\\ell_{\\infty}$-norm regularizer, is a useful tool for feature selection and grouping in high-dimensional data analysis. The computational challenge posed by OSCAR, for high dimensional and/or large sample size data, has not yet been well resolved due to the non-smoothness and non-separability of the regularizer involved. In this paper, we successfully resolve this numerical challenge by proposing a sparse semismooth Newton-based augmented Lagrangian method to solve the more general SLOPE (the sorted L-one penalized estimation) model. By appropriately exploiting the inherent sparse and low-rank property of the generalized Jacobian of the semismooth Newton system in the augmented Lagrangian subproblem, we show how the computational complexity can be substantially reduced. Our algorithm offers a notable computational advantage in the high-dimensional statistical regression settings. Numerical experiments are conducted on real data sets, and the results demonstrate that our algorithm is far superior, in both speed and robustness, to the existing state-of-the-art algorithms based on first-order iterative schemes, including the widely used accelerated proximal gradient (APG) method and the alternating direction method of multipliers (ADMM)",
    "checked": true,
    "id": "fec2ddf91c371dd8eddea61e68eac9e532154609",
    "semantic_title": "solving the oscar and slope models using a semismooth newton-based augmented lagrangian method",
    "citation_count": 21
  },
  "https://jmlr.org/papers/v20/18-200.html": {
    "title": "Scalable Interpretable Multi-Response Regression via SEED",
    "volume": "main",
    "abstract": "Sparse reduced-rank regression is an important tool for uncovering meaningful dependence structure between large numbers of predictors and responses in many big data applications such as genome-wide association studies and social media analysis. Despite the recent theoretical and algorithmic advances, scalable estimation of sparse reduced-rank regression remains largely unexplored. In this paper, we suggest a scalable procedure called sequential estimation with eigen-decomposition (SEED) which needs only a single top-$r$ sparse singular value decomposition from a generalized eigenvalue problem to find the optimal low-rank and sparse matrix estimate. Our suggested method is not only scalable but also performs simultaneous dimensionality reduction and variable selection. Under some mild regularity conditions, we show that SEED enjoys nice sampling properties including consistency in estimation, rank selection, prediction, and model selection. Moreover, SEED employs only basic matrix operations that can be efficiently parallelized in high performance computing devices. Numerical studies on synthetic and real data sets show that SEED outperforms the state-of-the-art approaches for large-scale matrix estimation problem",
    "checked": true,
    "id": "958f14e868699b507490c8fefaffa22e7613ee23",
    "semantic_title": "scalable interpretable multi-response regression via seed",
    "citation_count": 18
  },
  "https://jmlr.org/papers/v20/18-298.html": {
    "title": "Maximum Likelihood for Gaussian Process Classification and Generalized Linear Mixed Models under Case-Control Sampling",
    "volume": "main",
    "abstract": "Modern data sets in various domains often include units that were sampled non-randomly from the population and have a latent correlation structure. Here we investigate a common form of this setting, where every unit is associated with a latent variable, all latent variables are correlated, and the probability of sampling a unit depends on its response. Such settings often arise in case-control studies, where the sampled units are correlated due to spatial proximity, family relations, or other sources of relatedness. Maximum likelihood estimation in such settings is challenging from both a computational and statistical perspective, necessitating approximations that take the sampling scheme into account. We propose a family of approximate likelihood approaches which combine composite likelihood and expectation propagation. We demonstrate the efficacy of our solutions via extensive simulations. We utilize them to investigate the genetic architecture of several complex disorders collected in case-control genetic association studies, where hundreds of thousands of genetic variants are measured for every individual, and the underlying disease liabilities of individuals are correlated due to genetic similarity. Our work is the first to provide a tractable likelihood-based solution for case-control data with complex dependency structures",
    "checked": true,
    "id": "5a999dd44a64774179d1e1199876419bb7a26760",
    "semantic_title": "maximum likelihood for gaussian process classification and generalized linear mixed models under case-control sampling",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v20/18-329.html": {
    "title": "Learning Unfaithful $K$-separable Gaussian Graphical Models",
    "volume": "main",
    "abstract": "The global Markov property for Gaussian graphical models ensures graph separation implies conditional independence. Specifically if a node set $S$ graph separates nodes $u$ and $v$ then $X_u$ is conditionally independent of $X_v$ given $X_S$. The opposite direction need not be true, that is, $X_u \\perp X_v \\mid X_S$ need not imply $S$ is a node separator of $u$ and $v$. When it does, the relation $X_u \\perp X_v \\mid X_S$ is called faithful. In this paper we provide a characterization of faithful relations and then provide an algorithm to test faithfulness based only on knowledge of other conditional relations of the form $X_i \\perp X_j \\mid X_S$. We study two classes of separable Gaussian graphical models, namely, weakly $K$-separable and strongly $K$-separable Gaussian graphical models. Using the above test for faithfulness, we introduce algorithms to learn the topologies of weakly $K$-separable and strongly $K$-separable Gaussian graphical models with $\\Omega(K\\log p)$ sample complexity. For strongly $K$-separable Gaussian graphical models, we additionally provide a method with error bounds for learning the off-diagonal precision matrix entries",
    "checked": true,
    "id": "587e5a07333345e4f46b002cd2e0e00ba12178c6",
    "semantic_title": "learning unfaithful $k$-separable gaussian graphical models",
    "citation_count": 3
  },
  "https://jmlr.org/papers/v20/18-418.html": {
    "title": "A Representer Theorem for Deep Neural Networks",
    "volume": "main",
    "abstract": "We propose to optimize the activation functions of a deep neural network by adding a corresponding functional regularization to the cost function. We justify the use of a second-order total-variation criterion. This allows us to derive a general representer theorem for deep neural networks that makes a direct connection with splines and sparsity. Specifically, we show that the optimal network configuration can be achieved with activation functions that are nonuniform linear splines with adaptive knots. The bottom line is that the action of each neuron is encoded by a spline whose parameters (including the number of knots) are optimized during the training procedure. The scheme results in a computational structure that is compatible with existing deep-ReLU, parametric ReLU, APL (adaptive piecewise-linear) and MaxOut architectures. It also suggests novel optimization challenges and makes an explicit link with $\\ell_1$ minimization and sparsity-promoting techniques",
    "checked": true,
    "id": "4c25d60c88d395ae815ed0862f89c6484cdd392b",
    "semantic_title": "a representer theorem for deep neural networks",
    "citation_count": 85
  },
  "https://jmlr.org/papers/v20/18-460.html": {
    "title": "An Efficient Two Step Algorithm for High Dimensional Change Point Regression Models Without Grid Search",
    "volume": "main",
    "abstract": "We propose a two step algorithm based on $\\ell_1/\\ell_0$ regularization for the detection and estimation of parameters of a high dimensional change point regression model and provide the corresponding rates of convergence for the change point as well as the regression parameter estimates. Importantly, the computational cost of our estimator is only $2\\cdotp$Lasso$(n,p)$, where Lasso$(n,p)$ represents the computational burden of one Lasso optimization in a model of size $(n,p)$. In comparison, existing grid search based approaches to this problem require a computational cost of at least $n\\cdot Lasso(n,p)$ optimizations. Additionally, the proposed method is shown to be able to consistently detect the case of 'no change', i.e., where no finite change point exists in the model. We allow the true change point parameter $\\tau_0$ to possibly move to the boundaries of its parametric space, and the jump size $\\|b_0-g_0\\|_2$ to possibly diverge as $n$ increases. We then characterize the corresponding effects on the rates of convergence of the change point and regression estimates. In particular, we show that, while an increasing jump size may have a beneficial effect on the change point estimate, however the optimal rate of regression parameter estimates are preserved only upto a certain rate of the increasing jump size. This behavior in the rate of regression parameter estimates is unique to high dimensional change point regression models only. Simulations are performed to empirically evaluate performance of the proposed estimators. The methodology is applied to community level socio-economic data of the U.S., collected from the 1990 U.S. census and other sources",
    "checked": true,
    "id": "f5bd2f3cd05dc0669fe06c2ad392dcc7018372f6",
    "semantic_title": "an efficient two step algorithm for high dimensional change point regression models without grid search",
    "citation_count": 25
  },
  "https://jmlr.org/papers/v20/18-789.html": {
    "title": "Measuring the Effects of Data Parallelism on Neural Network Training",
    "volume": "main",
    "abstract": "Recent hardware developments have dramatically increased the scale of data parallelism available for neural network training. Among the simplest ways to harness next-generation hardware is to increase the batch size in standard mini-batch neural network training algorithms. In this work, we aim to experimentally characterize the effects of increasing the batch size on training time, as measured by the number of steps necessary to reach a goal out-of-sample error. We study how this relationship varies with the training algorithm, model, and data set, and find extremely large variation between workloads. Along the way, we show that disagreements in the literature on how batch size affects model quality can largely be explained by differences in metaparameter tuning and compute budgets at different batch sizes. We find no evidence that larger batch sizes degrade out-of-sample performance. Finally, we discuss the implications of our results on efforts to train neural networks much faster in the future. Our experimental data is publicly available as a database of 71,638,836 loss measurements taken over the course of training for 168,160 individual models across 35 workloads",
    "checked": true,
    "id": "b2c8e834ac5f7be68b9ca3691d39925036dd74a3",
    "semantic_title": "measuring the effects of data parallelism on neural network training",
    "citation_count": 309
  },
  "https://jmlr.org/papers/v20/18-801.html": {
    "title": "Distributed Inference for Linear Support Vector Machine",
    "volume": "main",
    "abstract": "The growing size of modern data brings many new challenges to existing statistical inference methodologies and theories, and calls for the development of distributed inferential approaches. This paper studies distributed inference for linear support vector machine (SVM) for the binary classification task. Despite a vast literature on SVM, much less is known about the inferential properties of SVM, especially in a distributed setting. In this paper, we propose a multi-round distributed linear-type (MDL) estimator for conducting inference for linear SVM. The proposed estimator is computationally efficient. In particular, it only requires an initial SVM estimator and then successively refines the estimator by solving simple weighted least squares problem. Theoretically, we establish the Bahadur representation of the estimator. Based on the representation, the asymptotic normality is further derived, which shows that the MDL estimator achieves the optimal statistical efficiency, i.e., the same efficiency as the classical linear SVM applying to the entire data set in a single machine setup. Moreover, our asymptotic result avoids the condition on the number of machines or data batches, which is commonly assumed in distributed estimation literature, and allows the case of diverging dimension. We provide simulation studies to demonstrate the performance of the proposed MDL estimator",
    "checked": true,
    "id": "40dc2ebc9fac48268a617c9e9a295a943525265f",
    "semantic_title": "distributed inference for linear support vector machine",
    "citation_count": 41
  },
  "https://jmlr.org/papers/v20/19-020.html": {
    "title": "Sharp Restricted Isometry Bounds for the Inexistence of Spurious Local Minima in Nonconvex Matrix Recovery",
    "volume": "main",
    "abstract": "Nonconvex matrix recovery is known to contain no spurious local minima under a restricted isometry property (RIP) with a sufficiently small RIP constant $\\delta$. If $\\delta$ is too large, however, then counterexamples containing spurious local minima are known to exist. In this paper, we introduce a proof technique that is capable of establishing sharp thresholds on $\\delta$ to guarantee the inexistence of spurious local minima. Using the technique, we prove that in the case of a rank-1 ground truth, an RIP constant of $\\delta<1/2$ is both necessary and sufficient for exact recovery from any arbitrary initial point (such as a random point). We also prove a local recovery result: given an initial point $x_{0}$ satisfying $f(x_{0})\\le(1-\\delta)^{2}f(0)$, any descent algorithm that converges to second-order optimality guarantees exact recovery",
    "checked": true,
    "id": "1908bd5541a52965309fc5d3e22364daaf19c43e",
    "semantic_title": "sharp restricted isometry bounds for the inexistence of spurious local minima in nonconvex matrix recovery",
    "citation_count": 44
  },
  "https://jmlr.org/papers/v20/19-197.html": {
    "title": "Learning Attribute Patterns in High-Dimensional Structured Latent Attribute Models",
    "volume": "main",
    "abstract": "Structured latent attribute models (SLAMs) are a special family of discrete latent variable models widely used in social and biological sciences. This paper considers the problem of learning significant attribute patterns from a SLAM with potentially high-dimensional configurations of the latent attributes. We address the theoretical identifiability issue, propose a penalized likelihood method for the selection of the attribute patterns, and further establish the selection consistency in such an overfitted SLAM with a diverging number of latent patterns. The good performance of the proposed methodology is illustrated by simulation studies and two real datasets in educational assessments",
    "checked": true,
    "id": "d24c1b08533aa323e5ebb96351afba2cd32007a8",
    "semantic_title": "learning attribute patterns in high-dimensional structured latent attribute models",
    "citation_count": 23
  },
  "https://jmlr.org/papers/v20/18-680.html": {
    "title": "Graph Reduction with Spectral and Cut Guarantees",
    "volume": "main",
    "abstract": "Can one reduce the size of a graph without significantly altering its basic properties? The graph reduction problem is hereby approached from the perspective of restricted spectral approximation, a modification of the spectral similarity measure used for graph sparsification. This choice is motivated by the observation that restricted approximation carries strong spectral and cut guarantees, and that it implies approximation results for unsupervised learning problems relying on spectral embeddings. The article then focuses on coarsening - the most common type of graph reduction. Sufficient conditions are derived for a small graph to approximate a larger one in the sense of restricted approximation. These findings give rise to algorithms that, compared to both standard and advanced graph reduction methods, find coarse graphs of improved quality, often by a large margin, without sacrificing speed",
    "checked": true,
    "id": "d30c6784b8458d6e602428a6f187c14bf75b2150",
    "semantic_title": "graph reduction with spectral and cut guarantees",
    "citation_count": 84
  },
  "https://jmlr.org/papers/v20/16-437.html": {
    "title": "Generic Inference in Latent Gaussian Process Models",
    "volume": "main",
    "abstract": "We develop an automated variational method for inference in models with Gaussian process (GP) priors and general likelihoods. The method supports multiple outputs and multiple latent functions and does not require detailed knowledge of the conditional likelihood, only needing its evaluation as a black-box function. Using a mixture of Gaussians as the variational distribution, we show that the evidence lower bound and its gradients can be estimated efficiently using samples from univariate Gaussian distributions. Furthermore, the method is scalable to large datasets which is achieved by using an augmented prior via the inducing-variable approach underpinning most sparse GP approximations, along with parallel computation and stochastic optimization. We evaluate our approach quantitatively and qualitatively with experiments on small datasets, medium-scale datasets and large datasets, showing its competitiveness under different likelihood models and sparsity levels. On the large-scale experiments involving prediction of airline delays and classification of handwritten digits, we show that our method is on par with the state-of-the-art hard-coded approaches for scalable GP regression and classification",
    "checked": true,
    "id": "bebc04311ace5c3f358a6462b4ecba6968dfb327",
    "semantic_title": "generic inference in latent gaussian process models",
    "citation_count": 28
  },
  "https://jmlr.org/papers/v20/17-170.html": {
    "title": "Binarsity: a penalization for one-hot encoded features in linear supervised learning",
    "volume": "main",
    "abstract": "This paper deals with the problem of large-scale linear supervised learning in settings where a large number of continuous features are available. We propose to combine the well-known trick of one-hot encoding of continuous features with a new penalization called binarsity. In each group of binary features coming from the one-hot encoding of a single raw continuous feature, this penalization uses total-variation regularization together with an extra linear constraint. This induces two interesting properties on the model weights of the one-hot encoded features: they are piecewise constant, and are eventually block sparse. Non-asymptotic oracle inequalities for generalized linear models are proposed. Moreover, under a sparse additive model assumption, we prove that our procedure matches the state-of-the-art in this setting. Numerical experiments illustrate the good performances of our approach on several datasets. It is also noteworthy that our method has a numerical complexity comparable to standard $\\ell_1$ penalization",
    "checked": true,
    "id": "67a3b217e6c39ef019dfd50a20afd6c6484f1a2e",
    "semantic_title": "binarsity: a penalization for one-hot encoded features in linear supervised learning",
    "citation_count": 23
  },
  "https://jmlr.org/papers/v20/17-525.html": {
    "title": "Layer-Wise Learning Strategy for Nonparametric Tensor Product Smoothing Spline Regression and Graphical Models",
    "volume": "main",
    "abstract": "Nonparametric estimation of multivariate functions is an important problem in statistical machine learning with many applications, ranging from nonparametric regression to nonparametric graphical models. Several authors have proposed to estimate multivariate functions under the smoothing spline analysis of variance (SSANOVA) framework, which assumes that the multivariate function can be decomposed into the summation of main effects, two-way interaction effects, and higher order interaction effects. However, existing methods are not scalable to the dimension of the random variables and the order of interactions. We propose a LAyer-wiSE leaRning strategy (LASER) to estimate multivariate functions under the SSANOVA framework. The main idea is to approximate the multivariate function sequentially starting from a model with only the main effects. Conditioned on the support of the estimated main effects, we estimate the two-way interaction effects only when the corresponding main effects are estimated to be non-zero. This process is continued until no more higher order interaction effects are identified. The proposed strategy provides a data-driven approach for estimating multivariate functions under the SSANOVA framework. Our proposal yields a sequence of estimators. To establish the theoretical properties of the sequence of estimators, we establish the notion of post-selection persistency. Extensive numerical studies are performed to evaluate the performance of our algorithm",
    "checked": true,
    "id": "7f456f969568625f75288917adf25510cf2f3321",
    "semantic_title": "layer-wise learning strategy for nonparametric tensor product smoothing spline regression and graphical models",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v20/17-672.html": {
    "title": "Ivanov-Regularised Least-Squares Estimators over Large RKHSs and Their Interpolation Spaces",
    "volume": "main",
    "abstract": "We study kernel least-squares estimation under a norm constraint. This form of regularisation is known as Ivanov regularisation and it provides better control of the norm of the estimator than the well-established Tikhonov regularisation. Ivanov regularisation can be studied under minimal assumptions. In particular, we assume only that the RKHS is separable with a bounded and measurable kernel. We provide rates of convergence for the expected squared $L^2$ error of our estimator under the weak assumption that the variance of the response variables is bounded and the unknown regression function lies in an interpolation space between $L^2$ and the RKHS. We then obtain faster rates of convergence when the regression function is bounded by clipping the estimator. In fact, we attain the optimal rate of convergence. Furthermore, we provide a high-probability bound under the stronger assumption that the response variables have subgaussian errors and that the regression function lies in an interpolation space between $L^\\infty$ and the RKHS. Finally, we derive adaptive results for the settings in which the regression function is bounded",
    "checked": true,
    "id": "d36b046ecc936605caaff5989f0d06e2e83956b8",
    "semantic_title": "ivanov-regularised least-squares estimators over large rkhss and their interpolation spaces",
    "citation_count": 10
  },
  "https://jmlr.org/papers/v20/17-723.html": {
    "title": "Scaling Up Sparse Support Vector Machines by Simultaneous Feature and Sample Reduction",
    "volume": "main",
    "abstract": "Sparse support vector machine (SVM) is a popular classification technique that can simultaneously learn a small set of the most interpretable features and identify the support vectors. It has achieved great successes in many real-world applications. However, for large-scale problems involving a huge number of samples and ultra-high dimensional features, solving sparse SVMs remains challenging. By noting that sparse SVMs induce sparsities in both feature and sample spaces, we propose a novel approach, which is based on accurate estimations of the primal and dual optima of sparse SVMs, to simultaneously identify the inactive features and samples that are guaranteed to be irrelevant to the outputs. Thus, we can remove the identified inactive samples and features from the training phase, leading to substantial savings in the computational cost without sacrificing the accuracy. Moreover, we show that our method can be extended to multi-class sparse support vector machines. To the best of our knowledge, the proposed method is the first static feature and sample reduction method for sparse SVMs and multi-class sparse SVMs. Experiments on both synthetic and real data sets demonstrate that our approach significantly outperforms state-of-the-art methods and the speedup gained by our approach can be orders of magnitude",
    "checked": true,
    "id": "de79813db667a93b873a9df69eca1f514a1bec3e",
    "semantic_title": "Scaling Up Sparse Support Vector Machine by Simultaneous Feature and Sample Reduction",
    "citation_count": 29
  },
  "https://jmlr.org/papers/v20/18-075.html": {
    "title": "Approximate Profile Maximum Likelihood",
    "volume": "main",
    "abstract": "We propose an efficient algorithm for approximate computation of the profile maximum likelihood (PML), a variant of maximum likelihood maximizing the probability of observing a sufficient statistic rather than the empirical sample. The PML has appealing theoretical properties, but is difficult to compute exactly. Inspired by observations gleaned from exactly solvable cases, we look for an approximate PML solution, which, intuitively, clumps comparably frequent symbols into one symbol. This amounts to lower-bounding a certain matrix permanent by summing over a subgroup of the symmetric group rather than the whole group during the computation. We extensively experiment with the approximate solution, and the empirical performance of our approach is competitive and sometimes significantly better than state-of-the-art performances for various estimation problems",
    "checked": true,
    "id": "f748c47b7211a5da393d191fc084978dbbc6e584",
    "semantic_title": "approximate profile maximum likelihood",
    "citation_count": 46
  },
  "https://jmlr.org/papers/v20/18-227.html": {
    "title": "ADMMBO: Bayesian Optimization with Unknown Constraints using ADMM",
    "volume": "main",
    "abstract": "There exist many problems in science and engineering that involve optimization of an unknown or partially unknown objective function. Recently, Bayesian Optimization (BO) has emerged as a powerful tool for solving optimization problems whose objective functions are only available as a black box and are expensive to evaluate. Many practical problems, however, involve optimization of an unknown objective function subject to unknown constraints. This is an important yet challenging problem for which, unlike optimizing an unknown function, existing methods face several limitations. In this paper, we present a novel constrained Bayesian optimization framework to optimize an unknown objective function subject to unknown constraints. We introduce an equivalent optimization by augmenting the objective function with constraints, introducing auxiliary variables for each constraint, and forcing the new variables to be equal to the main variable. Building on the Alternating Direction Method of Multipliers (ADMM) algorithm, we propose ADMM-Bayesian Optimization (ADMMBO) to solve the problem in an iterative fashion. Our framework leads to multiple unconstrained subproblems with unknown objective functions, which we then solve via BO. Our method resolves several challenges of state-of-the-art techniques: it can start from infeasible points, is insensitive to initialization, can efficiently handle `decoupled problems' and has a concrete stopping criterion. Extensive experiments on a number of challenging BO benchmark problems show that our proposed approach outperforms the state-of-the-art methods in terms of the speed of obtaining a feasible solution and convergence to the global optimum as well as minimizing the number of total evaluations of unknown objective and constraints functions",
    "checked": true,
    "id": "b0554a553547e6f68f8345b5023b19c7fdb31412",
    "semantic_title": "admmbo: bayesian optimization with unknown constraints using admm",
    "citation_count": 34
  },
  "https://jmlr.org/papers/v20/18-339.html": {
    "title": "Deep Exploration via Randomized Value Functions",
    "volume": "main",
    "abstract": "We study the use of randomized value functions to guide deep exploration in reinforcement learning. This offers an elegant means for synthesizing statistically and computationally efficient exploration with common practical approaches to value function learning. We present several reinforcement learning algorithms that leverage randomized value functions and demonstrate their efficacy through computational studies. We also prove a regret bound that establishes statistical efficiency with a tabular representation",
    "checked": true,
    "id": "a441728f9fd6af1946368240162a72c2028c8cb1",
    "semantic_title": "deep exploration via randomized value functions",
    "citation_count": 242
  },
  "https://jmlr.org/papers/v20/18-349.html": {
    "title": "ORCA: A Matlab/Octave Toolbox for Ordinal Regression",
    "volume": "MLOSS",
    "abstract": "Ordinal regression, also named ordinal classification, studies classification problems where there exist a natural order between class labels. This structured order of the labels is crucial in all steps of the learning process in order to take full advantage of the data. ORCA (Ordinal Regression and Classification Algorithms) is a Matlab/Octave framework that implements and integrates different ordinal classification algorithms and specifically designed performance metrics. The framework simplifies the task of experimental comparison to a great extent, allowing the user to: (i) describe experiments by simple configuration files; (ii) automatically run different data partitions; (iii) parallelize the executions; (iv) generate a variety of performance reports and (v) include new algorithms by using its intuitive interface. Source code, binaries, documentation, descriptions and links to data sets and tutorials (including examples of educational purpose) are available at https://github.com/ayrna/orca",
    "checked": true,
    "id": "73a58d45e63e630d91b4ea944e2b164e6b85eb50",
    "semantic_title": "orca: a matlab/octave toolbox for ordinal regression",
    "citation_count": 11
  },
  "https://jmlr.org/papers/v20/18-358.html": {
    "title": "Learning Representations of Persistence Barcodes",
    "volume": "main",
    "abstract": "We consider the problem of supervised learning with summary representations of topological features in data. In particular, we focus on persistent homology, the prevalent tool used in topological data analysis. As the summary representations, referred to as barcodes or persistence diagrams, come in the unusual format of multi sets, equipped with computationally expensive metrics, they can not readily be processed with conventional learning techniques. While different approaches to address this problem have been proposed, either in the context of kernel-based learning, or via carefully designed vectorization techniques, it remains an open problem how to leverage advances in representation learning via deep neural networks. Appropriately handling topological summaries as input to neural networks would address the disadvantage of previous strategies which handle this type of data in a task-agnostic manner. In particular, we propose an approach that is designed to learn a task-specific representation of barcodes. In other words, we aim to learn a representation that adapts to the learning problem while, at the same time, preserving theoretical properties (such as stability). This is done by projecting barcodes into a finite dimensional vector space using a collection of parametrized functionals, so called structure elements, for which we provide a generic construction scheme. A theoretical analysis of this approach reveals sufficient conditions to preserve stability, and also shows that different choices of structure elements lead to great differences with respect to their suitability for numerical optimization. When implemented as a neural network input layer, our approach demonstrates compelling performance on various types of problems, including graph classification and eigenvalue prediction, the classification of 2D/3D object shapes and recognizing activities from EEG signals",
    "checked": true,
    "id": "8061952d38d965efd3011d940c6d219dce2e094e",
    "semantic_title": "learning representations of persistence barcodes",
    "citation_count": 45
  },
  "https://jmlr.org/papers/v20/18-383.html": {
    "title": "Causal Learning via Manifold Regularization",
    "volume": "main",
    "abstract": "This paper frames causal structure estimation as a machine learning task. The idea is to treat indicators of causal relationships between variables as `labels' and to exploit available data on the variables of interest to provide features for the labelling task. Background scientific knowledge or any available interventional data provide labels on some causal relationships and the remainder are treated as unlabelled. To illustrate the key ideas, we develop a distance-based approach (based on bivariate histograms) within a manifold regularization framework. We present empirical results on three different biological data sets (including examples where causal effects can be verified by experimental intervention), that together demonstrate the efficacy and general nature of the approach as well as its simplicity from a user's point of view",
    "checked": true,
    "id": "bf699634ee63b1e016b6e30348acd3db01c25791",
    "semantic_title": "causal learning via manifold regularization",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v20/18-392.html": {
    "title": "Unsupervised Basis Function Adaptation for Reinforcement Learning",
    "volume": "main",
    "abstract": "When using reinforcement learning (RL) algorithms it is common, given a large state space, to introduce some form of approximation architecture for the value function (VF). The exact form of this architecture can have a significant effect on an agent's performance, however, and determining a suitable approximation architecture can often be a highly complex task. Consequently there is currently interest among researchers in the potential for allowing RL algorithms to adaptively generate (i.e. to learn) approximation architectures. One relatively unexplored method of adapting approximation architectures involves using feedback regarding the frequency with which an agent has visited certain states to guide which areas of the state space to approximate with greater detail. In this article we will: (a) informally discuss the potential advantages offered by such methods; (b) introduce a new algorithm based on such methods which adapts a state aggregation approximation architecture on-line and is designed for use in conjunction with SARSA; (c) provide theoretical results, in a policy evaluation setting, regarding this particular algorithm's complexity, convergence properties and potential to reduce VF error; and finally (d) test experimentally the extent to which this algorithm can improve performance given a number of different test problems. Taken together our results suggest that our algorithm (and potentially such methods more generally) can provide a versatile and computationally lightweight means of significantly boosting RL performance given suitable conditions which are commonly encountered in practice",
    "checked": true,
    "id": "c7aa4f55f17043b56b05b75c60de1998ae634593",
    "semantic_title": "unsupervised basis function adaptation for reinforcement learning",
    "citation_count": 3
  },
  "https://jmlr.org/papers/v20/18-424.html": {
    "title": "Time-to-Event Prediction with Neural Networks and Cox Regression",
    "volume": "main",
    "abstract": "New methods for time-to-event prediction are proposed by extending the Cox proportional hazards model with neural networks. Building on methodology from nested case-control studies, we propose a loss function that scales well to large data sets and enables fitting of both proportional and non-proportional extensions of the Cox model. Through simulation studies, the proposed loss function is verified to be a good approximation for the Cox partial log-likelihood. The proposed methodology is compared to existing methodologies on real-world data sets and is found to be highly competitive, typically yielding the best performance in terms of Brier score and binomial log-likelihood. A python package for the proposed methods is available at https://github.com/havakv/pycox",
    "checked": true,
    "id": "c3ab842222ad344873f5aba059169d2718a9bca7",
    "semantic_title": "time-to-event prediction with neural networks and cox regression",
    "citation_count": 194
  },
  "https://jmlr.org/papers/v20/18-517.html": {
    "title": "Logical Explanations for Deep Relational Machines Using Relevance Information",
    "volume": "main",
    "abstract": "Our interest in this paper is in the construction of symbolic explanations for predictions made by a deep neural network. We will focus attention on deep relational machines (DRMs: a term introduced in Lodhi (2013)). A DRM is a deep network in which the input layer consists of Boolean-valued functions (features) that are defined in terms of relations provided as domain, or background, knowledge. Our DRMs differ from those in Lodhi (2013), which uses an Inductive Logic Programming (ILP) engine to first select features (we use random selections from a space of features that satisfies some approximate constraints on logical relevance and non-redundancy). But why do the DRMs predict what they do? One way of answering this was provided in recent work Ribeiro et al. (2016), by constructing readable proxies for a black-box predictor. The proxies are intended only to model the predictions of the black-box in local regions of the instance-space. But readability alone may not be enough: to be understandable, the local models must use relevant concepts in an meaningful manner. We investigate the use of a Bayes-like approach to identify logical proxies for local predictions of a DRM. As a preliminary step, we show that DRM's with our randomised propositionalization method achieve predictive performance that is comparable to the best reports in the ILP literature. Our principal results on logical explanations show: (a) Models in first-order logic can approximate the DRM's prediction closely in a small local region; and (b) Expert-provided relevance information can play the role of a prior to distinguish between logical explanations that perform equivalently on prediction alone",
    "checked": true,
    "id": "c7d48c0e76ea8b272b5d134b3f8a5443c323dc21",
    "semantic_title": "logical explanations for deep relational machines using relevance information",
    "citation_count": 13
  },
  "https://jmlr.org/papers/v20/18-569.html": {
    "title": "Decoupling Sparsity and Smoothness in the Dirichlet Variational Autoencoder Topic Model",
    "volume": "main",
    "abstract": "Recent work on variational autoencoders (VAEs) has enabled the development of generative topic models using neural networks. Topic models based on latent Dirichlet allocation (LDA) successfully use the Dirichlet distribution as a prior for the topic and word distributions to enforce sparseness. However, there is a trade-off between sparsity and smoothness in Dirichlet distributions. Sparsity is important for a low reconstruction error during training of the autoencoder, whereas smoothness enables generalization and leads to a better log-likelihood of the test data. Both of these properties are encoded in the Dirichlet parameter vector. By rewriting this parameter vector into a product of a sparse binary vector and a smoothness vector, we decouple the two properties, leading to a model that features both a competitive topic coherence and a high log-likelihood. Efficient training is enabled using rejection sampling variational inference for the reparameterization of the Dirichlet distribution. Our experiments show that our method is competitive with other recent VAE topic models",
    "checked": true,
    "id": "2898149eb423782ad2211c35eca98fdc4e08780a",
    "semantic_title": "decoupling sparsity and smoothness in the dirichlet variational autoencoder topic model",
    "citation_count": 56
  },
  "https://jmlr.org/papers/v20/18-596.html": {
    "title": "More Efficient Estimation for Logistic Regression with Optimal Subsamples",
    "volume": "main",
    "abstract": "In this paper, we propose improved estimation method for logistic regression based on subsamples taken according the optimal subsampling probabilities developed in Wang et al. (2018). Both asymptotic results and numerical results show that the new estimator has a higher estimation efficiency. We also develop a new algorithm based on Poisson subsampling, which does not require to approximate the optimal subsampling probabilities all at once. This is computationally advantageous when available random-access memory is not enough to hold the full data. Interestingly, asymptotic distributions also show that Poisson subsampling produces a more efficient estimator if the sampling ratio, the ratio of the subsample size to the full data sample size, does not converge to zero. We also obtain the unconditional asymptotic distribution for the estimator based on Poisson subsampling. Pilot estimators are required to calculate subsampling probabilities and to correct biases in un-weighted estimators; interestingly, even if pilot estimators are inconsistent, the proposed method still produce consistent and asymptotically normal estimators",
    "checked": true,
    "id": "2d388c3653cf7af6b16aefdd7851610554362e7e",
    "semantic_title": "more efficient estimation for logistic regression with optimal subsamples",
    "citation_count": 70
  },
  "https://jmlr.org/papers/v20/18-674.html": {
    "title": "Spurious Valleys in One-hidden-layer Neural Network Optimization Landscapes",
    "volume": "main",
    "abstract": "Neural networks provide a rich class of high-dimensional, non-convex optimization problems. Despite their non-convexity, gradient-descent methods often successfully optimize these models. This has motivated a recent spur in research attempting to characterize properties of their loss surface that may explain such success. In this paper, we address this phenomenon by studying a key topological property of the loss: the presence or absence of spurious valleys, defined as connected components of sub-level sets that do not include a global minimum. Focusing on a class of one-hidden-layer neural networks defined by smooth (but generally non-linear) activation functions, we identify a notion of intrinsic dimension and show that it provides necessary and sufficient conditions for the absence of spurious valleys. More concretely, finite intrinsic dimension guarantees that for sufficiently overparametrised models no spurious valleys exist, independently of the data distribution. Conversely, infinite intrinsic dimension implies that spurious valleys do exist for certain data distributions, independently of model overparametrisation. Besides these positive and negative results, we show that, although spurious valleys may exist in general, they are confined to low risk levels and avoided with high probability on overparametrised models",
    "checked": true,
    "id": "b54614f8dd4670556338bdfeb7387f10b2347228",
    "semantic_title": "spurious valleys in one-hidden-layer neural network optimization landscapes",
    "citation_count": 45
  },
  "https://jmlr.org/papers/v20/19-055.html": {
    "title": "Stochastic Variance-Reduced Cubic Regularization Methods",
    "volume": "main",
    "abstract": "We propose a stochastic variance-reduced cubic regularized Newton method (SVRC) for non-convex optimization. At the core of SVRC is a novel semi-stochastic gradient along with a semi-stochastic Hessian, which are specifically designed for cubic regularization method. For a nonconvex function with $n$ component functions, we show that our algorithm is guaranteed to converge to an $(\\epsilon,\\sqrt{\\epsilon})$-approximate local minimum within $\\tilde{O}(n^{4/5}/\\epsilon^{3/2})$\\footnote{Here $\\tilde{O}$ hides poly-logarithmic factors.} second-order oracle calls, which outperforms the state-of-the-art cubic regularization algorithms including subsampled cubic regularization. To further reduce the sample complexity of Hessian matrix computation in cubic regularization based methods, we also propose a sample efficient stochastic variance-reduced cubic regularization (Lite-SVRC) algorithm for finding the local minimum more efficiently. Lite-SVRC converges to an $(\\epsilon,\\sqrt{\\epsilon})$-approximate local minimum within $\\tilde{O}(n+n^{2/3}/\\epsilon^{3/2})$ Hessian sample complexity, which is faster than all existing cubic regularization based methods. Numerical experiments with different nonconvex optimization problems conducted on real datasets validate our theoretical results for both SVRC and Lite-SVRC",
    "checked": true,
    "id": "b2825c6dc777a06a368e80ac8ae0a0cdcd987d60",
    "semantic_title": "stochastic variance-reduced cubic regularization methods",
    "citation_count": 19
  },
  "https://jmlr.org/papers/v20/19-065.html": {
    "title": "Gaussian Processes with Linear Operator Inequality Constraints",
    "volume": "main",
    "abstract": "This paper presents an approach for constrained Gaussian Process (GP) regression where we assume that a set of linear transformations of the process are bounded. It is motivated by machine learning applications for high-consequence engineering systems, where this kind of information is often made available from phenomenological knowledge. We consider a GP $f$ over functions on $\\mathcal{X} \\subset \\mathbb{R}^{n}$ taking values in $\\mathbb{R}$, where the process $linop f$ is still Gaussian when $linop $ is a linear operator. Our goal is to model $f$ under the constraint that realizations of $linop f$ are confined to a convex set of functions. In particular, we require that $a \\leq linop f \\leq b$, given two functions $a$ and $b$ where $a < b$ pointwise. This formulation provides a consistent way of encoding multiple linear constraints, such as shape-constraints based on e.g. boundedness, monotonicity or convexity. We adopt the approach of using a sufficiently dense set of virtual observation locations where the constraint is required to hold, and derive the exact posterior for a conjugate likelihood. The results needed for stable numerical implementation are derived, together with an efficient sampling scheme for estimating the posterior process",
    "checked": true,
    "id": "b41da295e137da25cf3be4d1ce142850c86c7a35",
    "semantic_title": "gaussian processes with linear operator inequality constraints",
    "citation_count": 24
  },
  "https://jmlr.org/papers/v20/19-261.html": {
    "title": "Local Regularization of Noisy Point Clouds: Improved Global Geometric Estimates and Data Analysis",
    "volume": "main",
    "abstract": "Several data analysis techniques employ similarity relationships between data points to uncover the intrinsic dimension and geometric structure of the underlying data-generating mechanism. In this paper we work under the model assumption that the data is made of random perturbations of feature vectors lying on a low-dimensional manifold. We study two questions: how to define the similarity relationships over noisy data points, and what is the resulting impact of the choice of similarity in the extraction of global geometric information from the underlying manifold. We provide concrete mathematical evidence that using a local regularization of the noisy data to define the similarity improves the approximation of the hidden Euclidean distance between unperturbed points. Furthermore, graph-based objects constructed with the locally regularized similarity function satisfy better error bounds in their recovery of global geometric ones. Our theory is supported by numerical experiments that demonstrate that the gain in geometric understanding facilitated by local regularization translates into a gain in classification accuracy in simulated and real data",
    "checked": true,
    "id": "bbbced852c0caa73c3ebe6006854c158f75461fc",
    "semantic_title": "local regularization of noisy point clouds: improved global geometric estimates and data analysis",
    "citation_count": 16
  },
  "https://jmlr.org/papers/v20/17-137.html": {
    "title": "Multiclass Boosting: Margins, Codewords, Losses, and Algorithms",
    "volume": "main",
    "abstract": "The problem of multiclass boosting is considered. A new formulation is presented, combining multi-dimensional predictors, multi-dimensional real-valued codewords, and proper multiclass margin loss functions. This leads to a number of contributions, such as maximum capacity codeword sets, a family of proper and margin enforcing losses, denoted as $\\gamma-\\phi$ losses, and two new multiclass boosting algorithms. These are descent procedures on the functional space spanned by a set of weak learners. The first, CD-MCBoost, is a coordinate descent procedure that updates one predictor component at a time. The second, GD-MCBoost, a gradient descent procedure that updates all components jointly. Both MCBoost algorithms are defined with respect to a $\\gamma-\\phi$ loss and can reduce to classical boosting procedures (such as AdaBoost and LogitBoost) for binary problems. Beyond the algorithms themselves, the proposed formulation enables a unified treatment of many previous multiclass boosting algorithms. This is used to show that the latter implement different combinations of optimization strategy, codewords, weak learners, and loss function, highlighting some of their deficiencies. It is shown that no previous method matches the support of MCBoost for real codewords of maximum capacity, a proper margin-enforcing loss function, and any family of multidimensional predictors and weak learners. Experimental results confirm the superiority of MCBoost, showing that the two proposed MCBoost algorithms outperform comparable prior methods on a number of datasets.\\\\ \\\\ \\textbf{Keywords}: Boosting, Multiclass Boosting, Multiclass Classification, Margin Maximization, Loss Function",
    "checked": true,
    "id": "100a8de76a41563b2679052b9a3d2298bf52736a",
    "semantic_title": "multiclass boosting: margins, codewords, losses, and algorithms",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v20/17-486.html": {
    "title": "Generalized Maximum Entropy Estimation",
    "volume": "main",
    "abstract": "We consider the problem of estimating a probability distribution that maximizes the entropy while satisfying a finite number of moment constraints, possibly corrupted by noise. Based on duality of convex programming, we present a novel approximation scheme using a smoothed fast gradient method that is equipped with explicit bounds on the approximation error. We further demonstrate how the presented scheme can be used for approximating the chemical master equation through the zero-information moment closure method, and for an approximate dynamic programming approach in the context of constrained Markov decision processes with uncountable state and action spaces",
    "checked": true,
    "id": "a8bfcf5af06d3666d674a26b63483cd9e3f0825b",
    "semantic_title": "generalized maximum entropy estimation",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v20/17-534.html": {
    "title": "Decentralized Dictionary Learning Over Time-Varying Digraphs",
    "volume": "main",
    "abstract": "This paper studies Dictionary Learning problems wherein the learning task is distributed over a multi-agent network, modeled as a time-varying directed graph. This formulation is relevant, for instance, in Big Data scenarios where massive amounts of data are collected/stored in different locations (e.g., sensors, clouds) and aggregating and/or processing all data in a fusion center might be inefficient or unfeasible, due to resource limitations, communication overheads or privacy issues. We develop a unified decentralized algorithmic framework for this class of nonconvex problems, which is proved to converge to stationary solutions at a sublinear rate. The new method hinges on Successive Convex Approximation techniques, coupled with a decentralized tracking mechanism aiming at locally estimating the gradient of the smooth part of the sum-utility. To the best of our knowledge, this is the first provably convergent decentralized algorithm for Dictionary Learning and, more generally, bi-convex problems over (time-varying) (di)graphs",
    "checked": true,
    "id": "e54bc0d96445fba2fbc9d639ae623d54e86a4f25",
    "semantic_title": "decentralized dictionary learning over time-varying digraphs",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v20/17-641.html": {
    "title": "Nonparametric Bayesian Aggregation for Massive Data",
    "volume": "main",
    "abstract": "We develop a set of scalable Bayesian inference procedures for a general class of nonparametric regression models. Specifically, nonparametric Bayesian inferences are separately performed on each subset randomly split from a massive dataset, and then the obtained local results are aggregated into global counterparts. This aggregation step is explicit without involving any additional computation cost. By a careful partition, we show that our aggregated inference results obtain an oracle rule in the sense that they are equivalent to those obtained directly from the entire data (which are computationally prohibitive). For example, an aggregated credible ball achieves desirable credibility level and also frequentist coverage while possessing the same radius as the oracle ball",
    "checked": true,
    "id": "ed39769b6d49b72e42e2798baa4298fb751a0db3",
    "semantic_title": "nonparametric bayesian aggregation for massive data",
    "citation_count": 8
  },
  "https://jmlr.org/papers/v20/17-728.html": {
    "title": "Provably Accurate Double-Sparse Coding",
    "volume": "main",
    "abstract": "Sparse coding is a crucial subroutine in algorithms for various signal processing, deep learning, and other machine learning applications. The central goal is to learn an overcomplete dictionary that can sparsely represent a given input dataset. However, a key challenge is that storage, transmission, and processing of the learned dictionary can be untenably high if the data dimension is high. In this paper, we consider the double-sparsity model introduced by Rubinstein et al. (2010b) where the dictionary itself is the product of a fixed, known basis and a data-adaptive sparse component. First, we introduce a simple algorithm for double-sparse coding that can be amenable to efficient implementation via neural architectures. Second, we theoretically analyze its performance and demonstrate asymptotic sample complexity and running time benefits over existing (provable) approaches for sparse coding. To our knowledge, our work introduces the first computationally efficient algorithm for double-sparse coding that enjoys rigorous statistical guarantees. Finally, we corroborate our theory with several numerical experiments on simulated data, suggesting that our method may be useful for problem sizes encountered in practice",
    "checked": true,
    "id": "1fa504b292813d39811c3574b9948450ea1bea75",
    "semantic_title": "provably accurate double-sparse coding",
    "citation_count": 1
  },
  "https://jmlr.org/papers/v20/17-776.html": {
    "title": "Model-free Nonconvex Matrix Completion: Local Minima Analysis and Applications in Memory-efficient Kernel PCA",
    "volume": "main",
    "abstract": "This work studies low-rank approximation of a positive semidefinite matrix from partial entries via nonconvex optimization. We characterized how well local-minimum based low-rank factorization approximates a fixed positive semidefinite matrix without any assumptions on the rank-matching, the condition number or eigenspace incoherence parameter. Furthermore, under certain assumptions on rank-matching and well-boundedness of condition numbers and eigenspace incoherence parameters, a corollary of our main theorem improves the state-of-the-art sampling rate results for nonconvex matrix completion with no spurious local minima in Ge et al. (2016, 2017). In addition, we have investigated when the proposed nonconvex optimization results in accurate low-rank approximations even in presence of large condition numbers, large incoherence parameters, or rank mismatching. We also propose to apply the nonconvex optimization to memory-efficient kernel PCA. Compared to the well-known Nystrm methods, numerical experiments indicate that the proposed nonconvex optimization approach yields more stable results in both low-rank approximation and clustering",
    "checked": true,
    "id": "8bbf29371d99b5bc9496a86160014b01449ec8cf",
    "semantic_title": "model-free nonconvex matrix completion: local minima analysis and applications in memory-efficient kernel pca",
    "citation_count": 18
  },
  "https://jmlr.org/papers/v20/18-084.html": {
    "title": "Minimal Sample Subspace Learning: Theory and Algorithms",
    "volume": "main",
    "abstract": "Subspace segmentation, or subspace learning, is a challenging and complicated task in machine learning. This paper builds a primary frame and solid theoretical bases for the minimal subspace segmentation (MSS) of finite samples. The existence and conditional uniqueness of MSS are discussed with conditions generally satisfied in applications. Utilizing weak prior information of MSS, the minimality inspection of segments is further simplified to the prior detection of partitions. The MSS problem is then modeled as a computable optimization problem via the self-expressiveness of samples. A closed form of the representation matrices is first given for the self-expressiveness, and the connection of diagonal blocks is addressed. The MSS model uses a rank restriction on the sum of segment ranks. Theoretically, it can retrieve the minimal sample subspaces that could be heavily intersected. The optimization problem is solved via a basic manifold conjugate gradient algorithm, alternative optimization and hybrid optimization, therein considering solutions to both the primal MSS problem and its pseudo-dual problem. The MSS model is further modified for handling noisy data and solved by an ADMM algorithm. The reported experiments show the strong ability of the MSS method to retrieve minimal sample subspaces that are heavily intersected",
    "checked": true,
    "id": "8f6905352c4d6f70b20896a64218e15051ed5055",
    "semantic_title": "minimal sample subspace learning: theory and algorithms",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v20/18-133.html": {
    "title": "Convergence of Gaussian Belief Propagation Under General Pairwise Factorization: Connecting Gaussian MRF with Pairwise Linear Gaussian Model",
    "volume": "main",
    "abstract": "Gaussian belief propagation (BP) is a low-complexity and distributed method for computing the marginal distributions of a high-dimensional joint Gaussian distribution. However, Gaussian BP is only guaranteed to converge in singly connected graphs and may fail to converge in loopy graphs. Therefore, convergence analysis is a core topic in Gaussian BP. Existing conditions for verifying the convergence of Gaussian BP are all tailored for one particular pairwise factorization of the distribution in Gaussian Markov random field (MRF) and may not be valid for another pairwise factorization. On the other hand, convergence conditions of Gaussian BP in pairwise linear Gaussian model are developed independently from those in Gaussian MRF, making the convergence results highly scattered with diverse settings. In this paper, the convergence condition of Gaussian BP is investigated under a general pairwise factorization, which includes Gaussian MRF and pairwise linear Gaussian model as special cases. Upon this, existing convergence conditions in Gaussian MRF are extended to any pairwise factorization. Moreover, the newly established link between Gaussian MRF and pairwise linear Gaussian model reveals an easily verifiable sufficient convergence condition in pairwise linear Gaussian model, which provides a unified criterion for assessing the convergence of Gaussian BP in multiple applications. Numerical examples are presented to corroborate the theoretical results of this paper",
    "checked": true,
    "id": "e5f478460b364ff731f7d61e43c30b5f4f9d9b60",
    "semantic_title": "convergence of gaussian belief propagation under general pairwise factorization: connecting gaussian mrf with pairwise linear gaussian model",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v20/18-225.html": {
    "title": "Bayesian Optimization for Policy Search via Online-Offline Experimentation",
    "volume": "main",
    "abstract": "Online field experiments are the gold-standard way of evaluating changes to real-world interactive machine learning systems. Yet our ability to explore complex, multi-dimensional policy spacessuch as those found in recommendation and ranking problemsis often constrained by the limited number of experiments that can be run simultaneously. To alleviate these constraints, we augment online experiments with an offline simulator and apply multi-task Bayesian optimization to tune live machine learning systems. We describe practical issues that arise in these types of applications, including biases that arise from using a simulator and assumptions for the multi-task kernel. We measure empirical learning curves which show substantial gains from including data from biased offline experiments, and show how these learning curves are consistent with theoretical results for multi-task Gaussian process generalization. We find that improved kernel inference is a significant driver of multi-task generalization. Finally, we show several examples of Bayesian optimization efficiently tuning a live machine learning system by combining offline and online experiments",
    "checked": true,
    "id": "c3d2e912b1dc80076b1a1df419825f7f2edfe6fb",
    "semantic_title": "bayesian optimization for policy search via online-offline experimentation",
    "citation_count": 38
  },
  "https://jmlr.org/papers/v20/18-269.html": {
    "title": "Characterizing the Sample Complexity of Pure Private Learners",
    "volume": "main",
    "abstract": "Kasiviswanathan et al. (FOCS 2008) defined private learning as a combination of PAC learning and differential privacy. Informally, a private learner is applied to a collection of labeled individual information and outputs a hypothesis while preserving the privacy of each individual. Kasiviswanathan et al. left open the question of characterizing the sample complexity of private learners. We give a combinatorial characterization of the sample size sufficient and necessary to learn a class of concepts under pure differential privacy. This characterization is analogous to the well known characterization of the sample complexity of non-private learning in terms of the VC dimension of the concept class. We introduce the notion of probabilistic representation of a concept class, and our new complexity measure $RepDim$ corresponds to the size of the smallest probabilistic representation of the concept class. We show that any private learning algorithm for a concept class $C$ with sample complexity $m$ implies $RepDim(C)=O(m)$, and that there exists a private learning algorithm with sample complexity $m=O(RepDim(C))$. We further demonstrate that a similar characterization holds for the database size needed for computing a large class of optimization problems under pure differential privacy, and also for the well studied problem of private data release",
    "checked": true,
    "id": "b4d9eab67c7ef2a35325685b60932a7050e6dfa5",
    "semantic_title": "characterizing the sample complexity of pure private learners",
    "citation_count": 17
  },
  "https://jmlr.org/papers/v20/18-399.html": {
    "title": "Robustifying Independent Component Analysis by Adjusting for Group-Wise Stationary Noise",
    "volume": "main",
    "abstract": "We introduce coroICA, confounding-robust independent component analysis, a novel ICA algorithm which decomposes linearly mixed multivariate observations into independent components that are corrupted (and rendered dependent) by hidden group-wise stationary confounding. It extends the ordinary ICA model in a theoretically sound and explicit way to incorporate group-wise (or environment-wise) confounding. We show that our proposed general noise model allows to perform ICA in settings where other noisy ICA procedures fail. Additionally, it can be used for applications with grouped data by adjusting for different stationary noise within each group. Our proposed noise model has a natural relation to causality and we explain how it can be applied in the context of causal inference. In addition to our theoretical framework, we provide an efficient estimation procedure and prove identifiability of the unmixing matrix under mild assumptions. Finally, we illustrate the performance and robustness of our method on simulated data, provide audible and visual examples, and demonstrate the applicability to real-world scenarios by experiments on publicly available Antarctic ice core data as well as two EEG data sets. We provide a scikit-learn compatible pip-installable Python package coroICA as well as R and Matlab implementations accompanied by a documentation at https://sweichwald.de/coroICA/",
    "checked": true,
    "id": "227eecc5da1eb2d28860bf5194c2441eb80a2ae3",
    "semantic_title": "robustifying independent component analysis by adjusting for group-wise stationary noise",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v20/18-483.html": {
    "title": "Collective Matrix Completion",
    "volume": "main",
    "abstract": "Matrix completion aims to reconstruct a data matrix based on observations of a small number of its entries. Usually in matrix completion a single matrix is considered, which can be, for example, a rating matrix in recommendation system. However, in practical situations, data is often obtained from multiple sources which results in a collection of matrices rather than a single one. In this work, we consider the problem of collective matrix completion with multiple and heterogeneous matrices, which can be count, binary, continuous, etc. We first investigate the setting where, for each source, the matrix entries are sampled from an exponential family distribution. Then, we relax the assumption of exponential family distribution for the noise. In this setting, we do not assume any specific model for the observations. The estimation procedures are based on minimizing the sum of a goodness-of-fit term and the nuclear norm penalization of the whole collective matrix. We prove that the proposed estimators achieve fast rates of convergence under the two considered settings and we corroborate our results with numerical experiments",
    "checked": true,
    "id": "a6a96f95f1ab467593e8403a3a0e17bdc12745d2",
    "semantic_title": "collective matrix completion",
    "citation_count": 6
  },
  "https://jmlr.org/papers/v20/18-512.html": {
    "title": "On Asymptotic and Finite-Time Optimality of Bayesian Predictors",
    "volume": "main",
    "abstract": "The problem is that of sequential probability forecasting for finite-valued time series. The data is generated by an unknown probability distribution over the space of all one-way infinite sequences. Two settings are considered: the realizable and the non-realizable one. Assume first that the probability measure generating the sequence belongs to a given set $C$ (realizable case), but the latter is completely arbitrary (uncountably infinite, without any structure given). It is shown that the minimax asymptotic average loss---which may be positive---is always attainable, and it is attained by a Bayesian predictor whose prior is discrete and concentrated on $C$. Moreover, the finite-time loss of the Bayesian predictor is also optimal up to an additive $\\log n$ term (where $n$ is the time step). This upper bound is complemented by a lower bound that goes to infinity but may do so arbitrarily slow. Passing to the non-realizable setting, let the probability measure generating the data be arbitrary, and consider the given set $C$ as a set of experts to compete with. The goal is to minimize the regret with respect to the experts. It is shown that in this setting it is possible that all Bayesian strategies are strictly suboptimal even asymptotically. In other words, a sublinear regret may be attainable but the regret of every Bayesian predictor is linear. A very general recommendation for choosing a model can be made based on these results: it is better to take a model large enough to make sure it includes the process that generates the data, even if it entails positive asymptotic average loss, for otherwise any combination of predictors in the model class may be useless",
    "checked": true,
    "id": "f33af5d8cdf178b803a9a0f23b1a7ee2159f7932",
    "semantic_title": "on asymptotic and finite-time optimality of bayesian predictors",
    "citation_count": 3
  },
  "https://jmlr.org/papers/v20/18-615.html": {
    "title": "Learning Optimized Risk Scores",
    "volume": "main",
    "abstract": "Risk scores are simple classification models that let users make quick risk predictions by adding and subtracting a few small numbers. These models are widely used in medicine and criminal justice, but are difficult to learn from data because they need to be calibrated, sparse, use small integer coefficients, and obey application-specific constraints. In this paper, we introduce a machine learning method to learn risk scores. We formulate the risk score problem as a mixed integer nonlinear program, and present a cutting plane algorithm to recover its optimal solution. We improve our algorithm with specialized techniques that generate feasible solutions, narrow the optimality gap, and reduce data-related computation. Our algorithm can train risk scores in a way that scales linearly in the number of samples in a dataset, and that allows practitioners to address application-specific constraints without parameter tuning or post-processing. We benchmark the performance of different methods to learn risk scores on publicly available datasets, comparing risk scores produced by our method to risk scores built using methods that are used in practice. We also discuss the practical benefits of our method through a real-world application where we build a customized risk score for ICU seizure prediction in collaboration with the Massachusetts General Hospital",
    "checked": true,
    "id": "ba4b4684cb9040caa682855e49056758f749793f",
    "semantic_title": "learning optimized risk scores",
    "citation_count": 51
  },
  "https://jmlr.org/papers/v20/18-618.html": {
    "title": "Nonparametric Estimation of Probability Density Functions of Random Persistence Diagrams",
    "volume": "main",
    "abstract": "Topological data analysis refers to a broad set of techniques that are used to make inferences about the shape of data. A popular topological summary is the persistence diagram. Through the language of random sets, we describe a notion of global probability density function for persistence diagrams that fully characterizes their behavior and in part provides a noise likelihood model. Our approach encapsulates the number of topological features and considers the appearance or disappearance of those near the diagonal in a stable fashion. In particular, the structure of our kernel individually tracks long persistence features, while considering those near the diagonal as a collective unit. The choice to describe short persistence features as a group reduces computation time while simultaneously retaining accuracy. Indeed, we prove that the associated kernel density estimate converges to the true distribution as the number of persistence diagrams increases and the bandwidth shrinks accordingly. We also establish the convergence of the mean absolute deviation estimate, defined according to the bottleneck metric. Lastly, examples of kernel density estimation are presented for typical underlying datasets as well as for virtual electroencephalographic data related to cognition",
    "checked": true,
    "id": "f3670764334611b3e98e65471c0cf25f460e767c",
    "semantic_title": "nonparametric estimation of probability density functions of random persistence diagrams",
    "citation_count": 25
  },
  "https://jmlr.org/papers/v20/18-705.html": {
    "title": "High-dimensional Varying Index Coefficient Models via Stein's Identity",
    "volume": "main",
    "abstract": "We study the parameter estimation problem for a varying index coefficient model in high dimensions. Unlike the most existing works that iteratively estimate the parameters and link functions, based on the generalized Stein's identity, we propose computationally efficient estimators for the high-dimensional parameters without estimating the link functions. We consider two different setups where we either estimate each sparse parameter vector individually or estimate the parameters simultaneously as a sparse or low-rank matrix. For all these cases, our estimators are shown to achieve optimal statistical rates of convergence (up to logarithmic terms in the low-rank setting). Moreover, throughout our analysis, we only require the covariate to satisfy certain moment conditions, which is significantly weaker than the Gaussian or elliptically symmetric assumptions that are commonly made in the existing literature. Finally, we conduct extensive numerical experiments to corroborate the theoretical results",
    "checked": true,
    "id": "40454c20e193270b73f488dba7066858c820ee8c",
    "semantic_title": "high-dimensional varying index coefficient models via stein's identity",
    "citation_count": 16
  },
  "https://jmlr.org/papers/v20/18-716.html": {
    "title": "Approximation Algorithms for Stochastic Clustering",
    "volume": "main",
    "abstract": "We consider stochastic settings for clustering, and develop provably-good approximation algorithms for a number of these notions. These algorithms yield better approximation ratios compared to the usual deterministic clustering setting. Additionally, they offer a number of advantages including clustering which is fairer and has better long-term behavior for each user. In particular, they ensure that every user is guaranteed to get good service (on average). We also complement some of these with impossibility results",
    "checked": true,
    "id": "458881c817f2a00dd8aaf67f94c4b23255face8c",
    "semantic_title": "approximation algorithms for stochastic clustering",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v20/18-762.html": {
    "title": "Convergence Guarantees for a Class of Non-convex and Non-smooth Optimization Problems",
    "volume": "main",
    "abstract": "We consider the problem of finding critical points of functions that are non-convex and non-smooth. Studying a fairly broad class of such problems, we analyze the behavior of three gradient-based methods (gradient descent, proximal update, and Frank-Wolfe update). For each of these methods, we establish rates of convergence for general problems, and also prove faster rates for continuous sub-analytic functions. We also show that our algorithms can escape strict saddle points for a class of non-smooth functions, thereby generalizing known results for smooth functions. Our analysis leads to a simplification of the popular CCCP algorithm, used for optimizing functions that can be written as a difference of two convex functions. Our simplified algorithm retains all the convergence properties of CCCP, along with a significantly lower cost per iteration. We illustrate our methods and theory via applications to the problems of best subset selection, robust estimation, mixture density estimation, and shape-from-shading reconstruction",
    "checked": true,
    "id": "75984da0cbf2ea6994b6dd8c3ade0278b6300bc9",
    "semantic_title": "convergence guarantees for a class of non-convex and non-smooth optimization problems",
    "citation_count": 66
  },
  "https://jmlr.org/papers/v20/19-006.html": {
    "title": "Quantifying Uncertainty in Online Regression Forests",
    "volume": "main",
    "abstract": "Accurately quantifying uncertainty in predictions is essential for the deployment of machine learning algorithms in critical applications where mistakes are costly. Most approaches to quantifying prediction uncertainty have focused on settings where the data is static, or bounded. In this paper, we investigate methods that quantify the prediction uncertainty in a streaming setting, where the data is potentially unbounded. We propose two meta-algorithms that produce prediction intervals for online regression forests of arbitrary tree models; one based on conformal prediction, and the other based on quantile regression. We show that the approaches are able to maintain specified error rates, with constant computational cost per example and bounded memory usage. We provide empirical evidence that the methods outperform the state-of-the-art in terms of maintaining error guarantees, while being an order of magnitude faster. We also investigate how the algorithms are able to recover from concept drift",
    "checked": true,
    "id": "9477d0fdff319ec97222e25c3c5eb41056d4aa40",
    "semantic_title": "quantifying uncertainty in online regression forests",
    "citation_count": 5
  },
  "https://jmlr.org/papers/v20/19-205.html": {
    "title": "SimpleDet: A Simple and Versatile Distributed Framework for Object Detection and Instance Recognition",
    "volume": "main",
    "abstract": "Object detection and instance recognition play a central role in many AI applications like autonomous driving, video surveillance and medical image analysis. However, training object detection models on large scale datasets remains computationally expensive and time consuming. This paper presents an efficient and open source object detection framework called SimpleDet which enables the training of state-of-the-art detection models on consumer grade hardware at large scale. SimpleDet covers a wide range of models including both high-performance and high-speed ones. SimpleDet is well-optimized for both low precision training and distributed training and achieves 70% higher throughput for the Mask R-CNN detector compared with existing frameworks. Codes, examples and documents of SimpleDet can be found at https://github.com/tusimple/simpledet",
    "checked": true,
    "id": "c10004c6f4962f956c83b026c5189708032fc653",
    "semantic_title": "simpledet: a simple and versatile distributed framework for object detection and instance recognition",
    "citation_count": 28
  },
  "https://jmlr.org/papers/v20/19-332.html": {
    "title": "Simultaneous Phase Retrieval and Blind Deconvolution via Convex Programming",
    "volume": "main",
    "abstract": "We consider the task of recovering two real or complex $m$-vectors from phaseless Fourier measurements of their circular convolution. Our method is a novel convex relaxation that is based on a lifted matrix recovery formulation that allows a non-trivial convex relaxation of the bilinear measurements from convolution. We prove that if the two signals belong to known random subspaces of dimensions $k$ and $n$, then they can be recovered up to the inherent scaling ambiguity with $m \\gg (k+n) \\log^2 m$ phaseless measurements. Our method provides the first theoretical recovery guarantee for this problem by a computationally efficient algorithm and does not require a solution estimate to be computed for initialization. Our proof is based on Rademacher complexity estimates. Additionally, we provide an alternating direction method of multipliers (ADMM) implementation and provide numerical experiments that verify the theory",
    "checked": true,
    "id": "f7722769438b80c70fac210f7076990b13ee47bd",
    "semantic_title": "simultaneous phase retrieval and blind deconvolution via convex programming",
    "citation_count": 3
  },
  "https://jmlr.org/papers/v20/19-490.html": {
    "title": "GraSPy: Graph Statistics in Python",
    "volume": "main",
    "abstract": "We introduce graspy, a Python library devoted to statistical inference, machine learning, and visualization of random graphs and graph populations. This package provides flexible and easy-to-use algorithms for analyzing and understanding graphs with a sklearn compliant API. graspy can be downloaded from Python Package Index (PyPi), and is released under the Apache 2.0 open-source license. The documentation and all releases are available at https://neurodata.io/graspy",
    "checked": true,
    "id": "85cb7f9164310fcf51207e314e159ee8d149838f",
    "semantic_title": "graspy: graph statistics in python",
    "citation_count": 25
  },
  "https://jmlr.org/papers/v20/19-543.html": {
    "title": "Optimal Convergence Rates for Convex Distributed Optimization in Networks",
    "volume": "main",
    "abstract": "This work proposes a theoretical analysis of distributed optimization of convex functions using a network of computing units. We investigate this problem under two communication schemes (centralized and decentralized) and four classical regularity assumptions: Lipschitz continuity, strong convexity, smoothness, and a combination of strong convexity and smoothness. Under the decentralized communication scheme, we provide matching upper and lower bounds of complexity along with algorithms achieving this rate up to logarithmic constants. For non-smooth objective functions, while the dominant term of the error is in $O(1/\\sqrt{t})$, the structure of the communication network only impacts a second-order term in $O(1/t)$, where $t$ is time. In other words, the error due to limits in communication resources decreases at a fast rate even in the case of non-strongly convex objective functions. Such a convergence rate is achieved by the novel multi-step primal-dual (MSPD) algorithm. Under the centralized communication scheme, we show that the naive distribution of standard optimization algorithms is optimal for smooth objective functions, and provide a simple yet efficient algorithm called distributed randomized smoothing (DRS) based on a local smoothing of the objective function for non-smooth functions. We then show that DRS is within a $d^{1/4}$ multiplicative factor of the optimal convergence rate, where $d$ is the underlying dimension",
    "checked": true,
    "id": "97056d5d0759ff3ecec18ab7410cced91aea1e97",
    "semantic_title": "optimal convergence rates for convex distributed optimization in networks",
    "citation_count": 56
  },
  "https://jmlr.org/papers/v20/18-873.html": {
    "title": "Learning by Unsupervised Nonlinear Diffusion",
    "volume": "main",
    "abstract": "This paper proposes and analyzes a novel clustering algorithm, called learning by unsupervised nonlinear diffusion (LUND), that combines graph-based diffusion geometry with techniques based on density and mode estimation. LUND is suitable for data generated from mixtures of distributions with densities that are both multimodal and supported near nonlinear sets. A crucial aspect of this algorithm is the use of time of a data-adapted diffusion process, and associated diffusion distances, as a scale parameter that is different from the local spatial scale parameter used in many clustering algorithms. We prove estimates for the behavior of diffusion distances with respect to this time parameter under a flexible nonparametric data model, identifying a range of times in which the mesoscopic equilibria of the underlying process are revealed, corresponding to a gap between within-cluster and between-cluster diffusion distances. These structures may be missed by the top eigenvectors of the graph Laplacian, commonly used in spectral clustering. This analysis is leveraged to prove sufficient conditions guaranteeing the accuracy of LUND. We implement LUND and confirm its theoretical properties on illustrative data sets, demonstrating its theoretical and empirical advantages over both spectral and density-based clustering",
    "checked": true,
    "id": "1dc088e1ca5538aff0c9912ec63ebba0c961748c",
    "semantic_title": "learning by unsupervised nonlinear diffusion",
    "citation_count": 34
  },
  "https://jmlr.org/papers/v20/13-124.html": {
    "title": "Sparse Kernel Regression with Coefficient-based $\\ell_q-$regularization",
    "volume": "main",
    "abstract": "In this paper, we consider the $\\ell_q-$regularized kernel regression with $0 < q \\leq 1$. In form, the algorithm minimizes a least-square loss functional adding a coefficient-based $\\ell_q-$penalty term over a linear span of features generated by a kernel function. We study the asymptotic behavior of the algorithm under the framework of learning theory. The contribution of this paper is two-fold. First, we derive a tight bound on the $\\ell_2-$empirical covering numbers of the related function space involved in the error analysis. Based on this result, we obtain the convergence rates for the $\\ell_1-$regularized kernel regression which is the best so far. Second, for the case $0 < q < 1$, we show that the regularization parameter plays a role as a trade-off between sparsity and convergence rates. Under some mild conditions, the fraction of non-zero coefficients in a local minimizer of the algorithm will tend to $0$ at a polynomial decay rate when the sample size $m$ becomes large. As the concerned algorithm is non-convex, we also discuss how to generate a minimizing sequence iteratively, which can help us to search a local minimizer around any initial point",
    "checked": true,
    "id": "b12ef9f79a859d30c9a9e684feb0d6d7c3b79e68",
    "semantic_title": "sparse kernel regression with coefficient-based $\\ell_q-$regularization",
    "citation_count": 0
  },
  "https://jmlr.org/papers/v20/16-155.html": {
    "title": "A Kernel Multiple Change-point Algorithm via Model Selection",
    "volume": "main",
    "abstract": "We consider a general formulation of the multiple change-point problem, in which the data is assumed to belong to a set equipped with a positive semidefinite kernel. We propose a model-selection penalty allowing to select the number of change points in Harchaoui and Capp's kernel-based change-point detection method. The model-selection penalty generalizes non-asymptotic model-selection penalties for the change-in-mean problem with univariate data. We prove a non-asymptotic oracle inequality for the resulting kernel-based change-point detection method, whatever the unknown number of change points, thanks to a concentration result for Hilbert-space valued random variables which may be of independent interest. Experiments on synthetic and real data illustrate the proposed method, demonstrating its ability to detect subtle changes in the distribution of data",
    "checked": true,
    "id": "5b1ad97413358a6923520a9aad9b928e1d5f283c",
    "semantic_title": "a kernel multiple change-point algorithm via model selection",
    "citation_count": 100
  },
  "https://jmlr.org/papers/v20/16-383.html": {
    "title": "Two-Layer Feature Reduction for Sparse-Group Lasso via Decomposition of Convex Sets",
    "volume": "main",
    "abstract": "Sparse-Group Lasso (SGL) has been shown to be a powerful regression technique for simultaneously discovering group and within-group sparse patterns by using a combination of the $\\ell_1$ and $\\ell_2$ norms. However, in large-scale applications, the complexity of the regularizers entails great computational challenges. In this paper, we propose a novel two-layer feature reduction method (TLFre) for SGL via a decomposition of its dual feasible set. The two-layer reduction is able to quickly identify the inactive groups and the inactive features, respectively, which are guaranteed to be absent from the sparse representation and can be removed from the optimization. Existing feature reduction methods are only applicable to sparse models with one sparsity-inducing regularizer. To our best knowledge, TLFre is the first one that is capable of dealing with multiple sparsity-inducing regularizers. Moreover, TLFre has a very low computational cost and can be integrated with any existing solvers. We also develop a screening method---called DPC (decomposition of convex set)---for nonnegative Lasso. Experiments on both synthetic and real data sets show that TLFre and DPC improve the efficiency of SGL and nonnegative Lasso by several orders of magnitude",
    "checked": true,
    "id": "8fd8305d5a2acb9c893747faf91695997d5fd938",
    "semantic_title": "two-layer feature reduction for sparse-group lasso via decomposition of convex sets",
    "citation_count": 37
  },
  "https://jmlr.org/papers/v20/17-601.html": {
    "title": "The Reduced PC-Algorithm: Improved Causal Structure Learning in Large Random Networks",
    "volume": "main",
    "abstract": "We consider the task of estimating a high-dimensional directed acyclic graph, given observations from a linear structural equation model with arbitrary noise distribution. By exploiting properties of common random graphs, we develop a new algorithm that requires conditioning only on small sets of variables. The proposed algorithm, which is essentially a modified version of the PC-Algorithm, offers significant gains in both computational complexity and estimation accuracy. In particular, it results in more efficient and accurate estimation in large networks containing hub nodes, which are common in biological systems. We prove the consistency of the proposed algorithm, and show that it also requires a less stringent faithfulness assumption than the PC-Algorithm. Simulations in low and high-dimensional settings are used to illustrate these findings. An application to gene expression data suggests that the proposed algorithm can identify a greater number of clinically relevant genes than current methods",
    "checked": true,
    "id": "10e2b2a5ee5984446465ea66606cfa4d7ec9c2de",
    "semantic_title": "the reduced pc-algorithm: improved causal structure learning in large random networks",
    "citation_count": 18
  },
  "https://jmlr.org/papers/v20/18-040.html": {
    "title": "On the Convergence of Gaussian Belief Propagation with Nodes of Arbitrary Size",
    "volume": "main",
    "abstract": "This paper is concerned with a multivariate extension of Gaussian message passing applied to pairwise Markov graphs (MGs). Gaussian message passing applied to pairwise MGs is often labeled Gaussian belief propagation (GaBP) and can be used to approximate the marginal of each variable contained in the pairwise MG. We propose a multivariate extension of GaBP (we label this GaBP-m) that can be used to estimate higher-dimensional marginals. Beyond the ability to estimate higher-dimensional marginals, GaBP-m exhibits better convergence behavior than GaBP, and can also provide more accurate univariate marginals. The theoretical results of this paper are based on an extension of the computation tree analysis conducted on univariate nodes to the multivariate case. The main contribution of this paper is the development of a convergence condition for GaBP-m that moves beyond the walk-summability of the precision matrix. Based on this convergence condition, we derived an upper bound for the number of iterations required for convergence of the GaBP-m algorithm. An upper bound on the dissimilarity between the approximate and exact marginal covariance matrices was established. We argue that GaBP-m is robust towards a certain change in variables, a property not shared by iterative solvers of linear systems, such as the conjugate gradient (CG) and preconditioned conjugate gradient (PCG) methods. The advantages of using GaBP-m over GaBP are also illustrated empirically",
    "checked": true,
    "id": "e248a67d1dc9f58e0c95122b66612d952ed3b3b4",
    "semantic_title": "on the convergence of gaussian belief propagation with nodes of arbitrary size",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v20/18-094.html": {
    "title": "Unsupervised Evaluation and Weighted Aggregation of Ranked Classification Predictions",
    "volume": "main",
    "abstract": "Ensemble methods that aggregate predictions from a set of diverse base learners consistently outperform individual classifiers. Many such popular strategies have been developed in a supervised setting, where the sample labels have been provided to the ensemble algorithm. However, with the rising interest in unsupervised algorithms for machine learning and growing amounts of uncurated data, the reliance on labeled data precludes the application of ensemble algorithms to many real world problems. To this end we develop a new theoretical framework for ensemble learning, the Strategy for Unsupervised Multiple Method Aggregation (SUMMA), that estimates the performances of base classifiers and uses these estimates to form an ensemble classifier. SUMMA also generates an ensemble ranking of samples based on the confidence score it assigns to each sample. We illustrate the performance of SUMMA using a synthetic example as well as two real world problems",
    "checked": true,
    "id": "6b7de718be892a10f488877d60f09178aef39073",
    "semantic_title": "unsupervised evaluation and weighted aggregation of ranked classification predictions",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v20/18-095.html": {
    "title": "Stochastic Canonical Correlation Analysis",
    "volume": "main",
    "abstract": "We study the sample complexity of canonical correlation analysis (CCA), i.e., the number of samples needed to estimate the population canonical correlation and directions up to arbitrarily small error. With mild assumptions on the data distribution, we show that in order to achieve $\\epsilon$-suboptimality in a properly defined measure of alignment between the estimated canonical directions and the population solution, we can solve the empirical objective exactly with $N(\\epsilon, \\Delta, \\gamma)$ samples, where $\\Delta$ is the singular value gap of the whitened cross-covariance matrix and $1/\\gamma$ is an upper bound of the condition number of auto-covariance matrices. Moreover, we can achieve the same learning accuracy by drawing the same level of samples and solving the empirical objective approximately with a stochastic optimization algorithm; this algorithm is based on the shift-and-invert power iterations and only needs to process the dataset for $\\mathcal{O} \\left(\\log \\frac{1}{\\epsilon} \\right)$ passes. Finally, we show that, given an estimate of the canonical correlation, the streaming version of the shift-and-invert power iterations achieves the same learning accuracy with the same level of sample complexity, by processing the data only once",
    "checked": true,
    "id": "04fbb39a7c30b7c595cd768308bb5cff4558e29d",
    "semantic_title": "stochastic canonical correlation analysis",
    "citation_count": 23
  },
  "https://jmlr.org/papers/v20/18-167.html": {
    "title": "Determinantal Point Processes for Coresets",
    "volume": "main",
    "abstract": "When faced with a data set too large to be processed all at once, an obvious solution is to retain only part of it. In practice this takes a wide variety of different forms, and among them \"coresets\" are especially appealing. A coreset is a (small) weighted sample of the original data that comes with the following guarantee: a cost function can be evaluated on the smaller set instead of the larger one, with low relative error. For some classes of problems, and via a careful choice of sampling distribution (based on the so-called \"sensitivity\" metric), iid random sampling has turned to be one of the most successful methods for building coresets efficiently. However, independent samples are sometimes overly redundant, and one could hope that enforcing diversity would lead to better performance. The difficulty lies in proving coreset properties in non-iid samples. We show that the coreset property holds for samples formed with determinantal point processes (DPP). DPPs are interesting because they are a rare example of repulsive point processes with tractable theoretical properties, enabling us to prove general coreset theorems. We apply our results to both the $k$-means and the linear regression problems, and give extensive empirical evidence that the small additional computational cost of DPP sampling comes with superior performance over its iid counterpart. Of independent interest, we also provide analytical formulas for the sensitivity in the linear regression and $1$-means cases",
    "checked": true,
    "id": "75181582264585e7c9c54b185d9a190eaf61b758",
    "semantic_title": "determinantal point processes for coresets",
    "citation_count": 27
  },
  "https://jmlr.org/papers/v20/18-374.html": {
    "title": "Embarrassingly Parallel Inference for Gaussian Processes",
    "volume": "main",
    "abstract": "Training Gaussian process-based models typically involves an $O(N^3)$ computational bottleneck due to inverting the covariance matrix. Popular methods for overcoming this matrix inversion problem cannot adequately model all types of latent functions, and are often not parallelizable. However, judicious choice of model structure can ameliorate this problem. A mixture-of-experts model that uses a mixture of $K$ Gaussian processes offers modeling flexibility and opportunities for scalable inference. Our embarrassingly parallel algorithm combines low-dimensional matrix inversions with importance sampling to yield a flexible, scalable mixture-of-experts model that offers comparable performance to Gaussian process regression at a much lower computational cost",
    "checked": true,
    "id": "a533048c60daee007ea89d58ef8829defbbc5f7a",
    "semantic_title": "embarrassingly parallel inference for gaussian processes",
    "citation_count": 19
  },
  "https://jmlr.org/papers/v20/18-470.html": {
    "title": "DBSCAN: Optimal Rates For Density-Based Cluster Estimation",
    "volume": "main",
    "abstract": "We study the problem of optimal estimation of the density cluster tree under various smoothness assumptions on the underlying density. Inspired by the seminal work of Chaudhuri et al. (2014), we formulate a new notion of clustering consistency which is better suited to smooth densities, and derive minimax rates for cluster tree estimation under Hlder smooth densities of arbitrary degree. We present a computationally efficient, rate optimal cluster tree estimator based on simple extensions of the popular DBSCAN algorithm of Ester et al. (1996). Our procedure relies on kernel density estimators and returns a sequence of nested random geometric graphs whose connected components form a hierarchy of clusters. The resulting optimal rates for cluster tree estimation depend on the degree of smoothness of the underlying density and, interestingly, match the minimax rates for density estimation under the sup-norm loss. Our results complement and extend the analysis of the DBSCAN algorithm in Sriperumbudur and Steinwart (2012). Finally, we consider level set estimation and cluster consistency for densities with jump discontinuities. We demonstrate that the DBSCAN algorithm attains the minimax rate in terms of the jump size and sample size in this setting as well",
    "checked": true,
    "id": "86b9105ad6c27cb3f8cfe0090db6dd156355094d",
    "semantic_title": "dbscan: optimal rates for density-based cluster estimation",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v20/18-484.html": {
    "title": "Shared Subspace Models for Multi-Group Covariance Estimation",
    "volume": "main",
    "abstract": "We develop a model-based method for evaluating heterogeneity among several $p\\times p$ covariance matrices in the large $p$, small $n$ setting. This is done by assuming a spiked covariance model for each group and sharing information about the space spanned by the group-level eigenvectors. We use an empirical Bayes method to identify a low-dimensional subspace which explains variation across all groups and use an MCMC algorithm to estimate the posterior uncertainty of eigenvectors and eigenvalues on this subspace. The implementation and utility of our model is illustrated with analyses of high-dimensional multivariate gene expression",
    "checked": true,
    "id": "5720a26a61d3d673938ffea3082d09f422bbe019",
    "semantic_title": "shared subspace models for multi-group covariance estimation",
    "citation_count": 15
  },
  "https://jmlr.org/papers/v20/18-616.html": {
    "title": "Optimization with Non-Differentiable Constraints with Applications to Fairness, Recall, Churn, and Other Goals",
    "volume": "main",
    "abstract": "We show that many machine learning goals can be expressed as \"rate constraints\" on a model's predictions. We study the problem of training non-convex models subject to these rate constraints (or other non-convex or non-differentiable constraints). In the non-convex setting, the standard approach of Lagrange multipliers may fail. Furthermore, if the constraints are non-differentiable, then one cannot optimize the Lagrangian with gradient-based methods. To solve these issues, we introduce a new \"proxy-Lagrangian\" formulation. This leads to an algorithm that, assuming access to an optimization oracle, produces a stochastic classifier by playing a two-player non-zero-sum game solving for what we call a semi-coarse correlated equilibrium, which in turn corresponds to an approximately optimal and feasible solution to the constrained optimization problem. We then give a procedure that shrinks the randomized solution down to a mixture of at most $m+1$ deterministic solutions, given $m$ constraints. This culminates in a procedure that can solve non-convex constrained optimization problems with possibly non-differentiable and non-convex constraints, and enjoys theoretical guarantees. We provide extensive experimental results covering a broad range of policy goals, including various fairness metrics, accuracy, coverage, recall, and churn",
    "checked": true,
    "id": "28930f1472417b25ca42d251c772e38c75395d84",
    "semantic_title": "optimization with non-differentiable constraints with applications to fairness, recall, churn, and other goals",
    "citation_count": 108
  },
  "https://jmlr.org/papers/v20/18-659.html": {
    "title": "Fast Automatic Smoothing for Generalized Additive Models",
    "volume": "main",
    "abstract": "Generalized additive models (GAMs) are regression models wherein parameters of probability distributions depend on input variables through a sum of smooth functions, whose degrees of smoothness are selected by $L_2$ regularization. Such models have become the de-facto standard nonlinear regression models when interpretability and flexibility are required, but reliable and fast methods for automatic smoothing in large data sets are still lacking. We develop a general methodology for automatically learning the optimal degree of $L_2$ regularization for GAMs using an empirical Bayes approach. The smooth functions are penalized by hyper-parameters that are learned simultaneously by maximization of a marginal likelihood using an approximate expectation-maximization algorithm. The latter involves a double Laplace approximation at the E-step, and leads to an efficient M-step. Empirical analysis shows that the resulting algorithm is numerically stable, faster than the best existing methods and achieves state-of-the-art accuracy. For illustration, we apply it to an important and challenging problem in the analysis of extremal data",
    "checked": true,
    "id": "ae72d65d1dfcc4b916ca5b217092ab3521ef158b",
    "semantic_title": "fast automatic smoothing for generalized additive models",
    "citation_count": 0
  },
  "https://jmlr.org/papers/v20/18-703.html": {
    "title": "Learning Overcomplete, Low Coherence Dictionaries with Linear Inference",
    "volume": "main",
    "abstract": "Finding overcomplete latent representations of data has applications in data analysis, signal processing, machine learning, theoretical neuroscience and many other fields. In an overcomplete representation, the number of latent features exceeds the data dimensionality, which is useful when the data is undersampled by the measurements (compressed sensing or information bottlenecks in neural systems) or composed from multiple complete sets of linear features, each spanning the data space. Independent Components Analysis (ICA) is a linear technique for learning sparse latent representations, which typically has a lower computational cost than sparse coding, a linear generative model which requires an iterative, nonlinear inference step. While well suited for finding complete representations, we show that overcompleteness poses a challenge to existing ICA algorithms. Specifically, the coherence control used in existing ICA and other dictionary learning algorithms, necessary to prevent the formation of duplicate dictionary features, is ill-suited in the overcomplete case. We show that in the overcomplete case, several existing ICA algorithms have undesirable global minima that maximize coherence. We provide a theoretical explanation of these failures and, based on the theory, propose improved coherence control costs for overcomplete ICA algorithms. Further, by comparing ICA algorithms to the computationally more expensive sparse coding on synthetic data, we show that the limited applicability of overcomplete, linear inference can be extended with the proposed cost functions. Finally, when trained on natural images, we show that the coherence control biases the exploration of the data manifold, sometimes yielding suboptimal, coherent solutions. All told, this study contributes new insights into and methods for coherence control for linear ICA, some of which are applicable to many other nonlinear models",
    "checked": true,
    "id": "279e4d54b936620eed080c1f9eb99de3c944f862",
    "semantic_title": "learning overcomplete, low coherence dictionaries with linear inference",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v20/18-753.html": {
    "title": "DataWig: Missing Value Imputation for Tables",
    "volume": "main",
    "abstract": "With the growing importance of machine learning (ML) algorithms for practical applications, reducing data quality problems in ML pipelines has become a major focus of research. In many cases missing values can break data pipelines which makes completeness one of the most impactful data quality challenges. Current missing value imputation methods are focusing on numerical or categorical data and can be difficult to scale to datasets with millions of rows. We release DataWig, a robust and scalable approach for missing value imputation that can be applied to tables with heterogeneous data types, including unstructured text. DataWig combines deep learning feature extractors with automatic hyperparameter tuning. This enables users without a machine learning background, such as data engineers, to impute missing values with minimal effort in tables with more heterogeneous data types than supported in existing libraries, while requiring less glue code for feature engineering and offering more flexible modelling options. We demonstrate that DataWig compares favourably to existing imputation packages. Source code, documentation, and unit tests for this package are available at: https://github.com/awslabs/datawig",
    "checked": true,
    "id": "d774b0c2462f7620f9055d0b1a6d9465e38c2b16",
    "semantic_title": "datawig: missing value imputation for tables",
    "citation_count": 57
  },
  "https://jmlr.org/papers/v20/18-759.html": {
    "title": "New Convergence Aspects of Stochastic Gradient Algorithms",
    "volume": "main",
    "abstract": "The classical convergence analysis of SGD is carried out under the assumption that the norm of the stochastic gradient is uniformly bounded. While this might hold for some loss functions, it is violated for cases where the objective function is strongly convex. In Bottou et al. (2018), a new analysis of convergence of SGD is performed under the assumption that stochastic gradients are bounded with respect to the true gradient norm. We show that for stochastic problems arising in machine learning such bound always holds; and we also propose an alternative convergence analysis of SGD with diminishing learning rate regime. We then move on to the asynchronous parallel setting, and prove convergence of Hogwild! algorithm in the same regime in the case of diminished learning rate. It is well-known that SGD converges if a sequence of learning rates $\\{\\eta_t\\}$ satisfies $\\sum_{t=0}^\\infty \\eta_t \\rightarrow \\infty$ and $\\sum_{t=0}^\\infty \\eta^2_t < \\infty$. We show the convergence of SGD for strongly convex objective function without using bounded gradient assumption when $\\{\\eta_t\\}$ is a diminishing sequence and $\\sum_{t=0}^\\infty \\eta_t \\rightarrow \\infty$. In other words, we extend the current state-of-the-art class of learning rates satisfying the convergence of SGD",
    "checked": true,
    "id": "3a4644eb61011591af72bf80e8320b65c28c6874",
    "semantic_title": "new convergence aspects of stochastic gradient algorithms",
    "citation_count": 59
  },
  "https://jmlr.org/papers/v20/18-760.html": {
    "title": "All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously",
    "volume": "main",
    "abstract": "Variable importance (VI) tools describe how much covariates contribute to a prediction model's accuracy. However, important variables for one well-performing model (for example, a linear model $f(\\mathbf{x})=\\mathbf{x}^{T}\\beta$ with a fixed coefficient vector $\\beta$) may be unimportant for another model. In this paper, we propose model class reliance (MCR) as the range of VI values across all well-performing model in a prespecified class. Thus, MCR gives a more comprehensive description of importance by accounting for the fact that many prediction models, possibly of different parametric forms, may fit the data well. In the process of deriving MCR, we show several informative results for permutation-based VI estimates, based on the VI measures used in Random Forests. Specifically, we derive connections between permutation importance estimates for a single prediction model, U-statistics, conditional variable importance, conditional causal effects, and linear model coefficients. We then give probabilistic bounds for MCR, using a novel, generalizable technique. We apply MCR to a public data set of Broward County criminal records to study the reliance of recidivism prediction models on sex and race. In this application, MCR can be used to help inform VI for unknown, proprietary models",
    "checked": true,
    "id": "12a6492b48ab5c475615f7ba381b3dcd205041d6",
    "semantic_title": "all models are wrong, but many are useful: learning a variable's importance by studying an entire class of prediction models simultaneously",
    "citation_count": 643
  },
  "https://jmlr.org/papers/v20/19-033.html": {
    "title": "Morpho-MNIST: Quantitative Assessment and Diagnostics for Representation Learning",
    "volume": "main",
    "abstract": "Revealing latent structure in data is an active field of research, having introduced exciting technologies such as variational autoencoders and adversarial networks, and is essential to push machine learning towards unsupervised knowledge discovery. However, a major challenge is the lack of suitable benchmarks for an objective and quantitative evaluation of learned representations. To address this issue we introduce Morpho-MNIST, a framework that aims to answer: \"to what extent has my model learned to represent specific factors of variation in the data? We extend the popular MNIST dataset by adding a morphometric analysis enabling quantitative comparison of trained models, identification of the roles of latent variables, and characterisation of sample diversity. We further propose a set of quantifiable perturbations to assess the performance of unsupervised and supervised methods on challenging tasks such as outlier detection and domain adaptation. Data and code are available at https://github.com/dccastro/Morpho-MNIST",
    "checked": true,
    "id": "0f504de06fa6ed1e57fedad6219a0516808ac4b7",
    "semantic_title": "morpho-mnist: quantitative assessment and diagnostics for representation learning",
    "citation_count": 47
  },
  "https://jmlr.org/papers/v20/19-150.html": {
    "title": "Differentiable reservoir computing",
    "volume": "main",
    "abstract": "Numerous results in learning and approximation theory have evidenced the importance of differentiability at the time of countering the curse of dimensionality. In the context of reservoir computing, much effort has been devoted in the last two decades to characterize the situations in which systems of this type exhibit the so-called echo state (ESP) and fading memory (FMP) properties. These important features amount, in mathematical terms, to the existence and continuity of global reservoir system solutions. That research is complemented in this paper with the characterization of the differentiability of reservoir filters for very general classes of discrete-time deterministic inputs. This constitutes a novel strong contribution to the long line of research on the ESP and the FMP and, in particular, links to existing research on the input-dependence of the ESP. Differentiability has been shown in the literature to be a key feature in the learning of attractors of chaotic dynamical systems. A Volterra-type series representation for reservoir filters with semi-infinite discrete-time inputs is constructed in the analytic case using Taylor's theorem and corresponding approximation bounds are provided. Finally, it is shown as a corollary of these results that any fading memory filter can be uniformly approximated by a finite Volterra series with finite memory",
    "checked": true,
    "id": "a88126e0d45290d182c9d4df08d437f7d9d08746",
    "semantic_title": "differentiable reservoir computing",
    "citation_count": 32
  },
  "https://jmlr.org/papers/v20/19-179.html": {
    "title": "DPPy: DPP Sampling with Python",
    "volume": "main",
    "abstract": "Determinantal point processes (DPPs) are specific probability distributions over clouds of points that are used as models and computational tools across physics, probability, statistics, and more recently machine learning. Sampling from DPPs is a challenge and therefore we present DPPy, a Python toolbox that gathers known exact and approximate sampling algorithms for both finite and continuous DPPs. The project is hosted on GitHub, and equipped with an extensive documentation",
    "checked": true,
    "id": "fc067f723532cf3d01fdb8277921fa1278767b7d",
    "semantic_title": "dppy: dpp sampling with python",
    "citation_count": 29
  },
  "https://jmlr.org/papers/v20/19-216.html": {
    "title": "Neural Empirical Bayes",
    "volume": "main",
    "abstract": "We unify kernel density estimation and empirical Bayes and address a set of problems in unsupervised machine learning with a geometric interpretation of those methods, rooted in the concentration of measure phenomenon. Kernel density is viewed symbolically as $X\\rightharpoonup Y$ where the random variable $X$ is smoothed to $Y= X+N(0,\\sigma^2 I_d)$, and empirical Bayes is the machinery to denoise in a least-squares sense, which we express as $X \\leftharpoondown Y$. A learning objective is derived by combining these two, symbolically captured by $X \\rightleftharpoons Y$. Crucially, instead of using the original nonparametric estimators, we parametrize the energy function with a neural network denoted by $\\phi$; at optimality, $\\nabla \\phi \\approx -\\nabla \\log f$ where $f$ is the density of $Y$. The optimization problem is abstracted as interactions of high-dimensional spheres which emerge due to the concentration of isotropic Gaussians. We introduce two algorithmic frameworks based on this machinery: (i) a \"walk-jump\" sampling scheme that combines Langevin MCMC (walks) and empirical Bayes (jumps), and (ii) a probabilistic framework for associative memory, called NEBULA, defined a la Hopfield by the gradient flow of the learned energy to a set of attractors. We finish the paper by reporting the emergence of very rich \"creative memories\" as attractors of NEBULA for highly-overlapping spheres",
    "checked": true,
    "id": "a853129e0262fa091736e46bb784c2be744e5c05",
    "semantic_title": "neural empirical bayes",
    "citation_count": 44
  },
  "https://jmlr.org/papers/v20/19-236.html": {
    "title": "Model Selection in Bayesian Neural Networks via Horseshoe Priors",
    "volume": "main",
    "abstract": "The promise of augmenting accurate predictions provided by modern neural networks with well-calibrated predictive uncertainties has reinvigorated interest in Bayesian neural networks. However, model selection---even choosing the number of nodes---remains an open question. Poor choices can severely affect the quality of the produced uncertainties. In this paper, we explore continuous shrinkage priors, the horseshoe, and the regularized horseshoe distributions, for model selection in Bayesian neural networks. When placed over node pre-activations and coupled with appropriate variational approximations, we find that the strong shrinkage provided by the horseshoe is effective at turning off nodes that do not help explain the data. We demonstrate that our approach finds compact network structures even when the number of nodes required is grossly over-estimated. Moreover, the model selection over the number of nodes does not come at the expense of predictive or computational performance; in fact, we learn smaller networks with comparable predictive performance to current approaches. These effects are particularly apparent in sample-limited settings, such as small data sets and reinforcement learning",
    "checked": true,
    "id": "8dfea60f2a3f9d3e6eac2484359595edef1f7849",
    "semantic_title": "model selection in bayesian neural networks via horseshoe priors",
    "citation_count": 97
  },
  "https://jmlr.org/papers/v20/19-306.html": {
    "title": "Log-concave sampling: Metropolis-Hastings algorithms are fast",
    "volume": "main",
    "abstract": "We study the problem of sampling from a strongly log-concave density supported on $\\mathbb{R}^d$, and prove a non-asymptotic upper bound on the mixing time of the Metropolis-adjusted Langevin algorithm (MALA). The method draws samples by simulating a Markov chain obtained from the discretization of an appropriate Langevin diffusion, combined with an accept-reject step. Relative to known guarantees for the unadjusted Langevin algorithm (ULA), our bounds show that the use of an accept-reject step in MALA leads to an exponentially improved dependence on the error-tolerance. Concretely, in order to obtain samples with TV error at most $\\delta$ for a density with condition number $\\kappa$, we show that MALA requires $\\mathcal{O} (\\kappa d \\log(1/\\delta) )$ steps from a warm start, as compared to the $\\mathcal{O} (\\kappa^2 d/\\delta^2 )$ steps established in past work on ULA. We also demonstrate the gains of a modified version of MALA over ULA for weakly log-concave densities. Furthermore, we derive mixing time bounds for the Metropolized random walk (MRW) and obtain $\\mathcal{O}(\\kappa)$ mixing time slower than MALA. We provide numerical examples that support our theoretical findings, and demonstrate the benefits of Metropolis-Hastings adjustment for Langevin-type sampling algorithms",
    "checked": true,
    "id": "faeac34337de9dd1cd554870725dd51630ef218e",
    "semantic_title": "log-concave sampling: metropolis-hastings algorithms are fast!",
    "citation_count": 195
  },
  "https://jmlr.org/papers/v20/19-519.html": {
    "title": "Why do deep convolutional networks generalize so poorly to small image transformations?",
    "volume": "main",
    "abstract": "Convolutional Neural Networks (CNNs) are commonly assumed to be invariant to small image transformations: either because of the convolutional architecture or because they were trained using data augmentation. Recently, several authors have shown that this is not the case: small translations or rescalings of the input image can drastically change the network's prediction. In this paper, we quantify this phenomena and ask why neither the convolutional architecture nor data augmentation are sufficient to achieve the desired invariance. Specifically, we show that the convolutional architecture does not give invariance since architectures ignore the classical sampling theorem, and data augmentation does not give invariance because the CNNs learn to be invariant to transformations only for images that are very similar to typical images from the training set. We discuss two possible solutions to this problem: (1) antialiasing the intermediate representations and (2) increasing data augmentation and show that they provide only a partial solution at best. Taken together, our results indicate that the problem of insuring invariance to small image transformations in neural networks while preserving high accuracy remains unsolved",
    "checked": true,
    "id": "6f4afaa1ec7528c59aba86def531df6c524229b2",
    "semantic_title": "why do deep convolutional networks generalize so poorly to small image transformations?",
    "citation_count": 449
  }
}