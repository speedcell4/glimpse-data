{
  "https://aclanthology.org/2017.mtsummit-papers.1": {
    "title": "Empirical Study of Dropout Scheme for Neural Machine Translation",
    "abstract": "Dropout has lately been recognized as an effective method to relieve over-ﬁtting when training deep neural networks. However, there has been little work studying the optimal dropout scheme for neural machine translation (NMT). NMT models usually contain attention mech-anisms and multiple recurrent layers, thus applying dropout becomes a non-trivial task. This paper approached this problem empirically through experiments where dropout were applied to different parts of connections using different dropout rates. The work in this paper not only leads to an improvement over an established baseline, but also provides useful heuristics about using dropout effectively to train NMT models. These heuristics include which part of connections in NMT models have higher priority for dropout than the others, and how to correctly enhance the effect of dropout for difﬁcult translation tasks",
    "volume": "main",
    "checked": true,
    "id": "5547f9eebcd3d8c03f9dbb2e03dba02d7d3edf39",
    "citation_count": 1
  },
  "https://aclanthology.org/2017.mtsummit-papers.2": {
    "title": "A Target Attention Model for Neural Machine Translation",
    "abstract": "Neural Machine Translation (NMT) with an attention mechanism has shown promising results by utilizing word alignments between the source and target sentences. Typically, training of NMT proceeds token-by-token on the target side, where each token is predicted using only a vector representing the current hidden-state, and the previous token. However, this strategy has serious shortcomings originating the lack of information about the partial target sequence hypothesis; speciﬁcally, this can lead to source tokens being translated multiple times or remain-ing untranslated. To alleviate this problem, we introduce a target-side attention mechanism to exploit the generated target sequence of tokens more effectively. We calculate a target-side context vector using a recurrent neural network and feed it to an attention mechanism so that the decoder can pay more or less attention to each token in the partially generated target sequence when predicting the next target token. Experiments on three different English-to-Japanese translation tasks show improvements of 0.6-1.5 BLEU points",
    "volume": "main",
    "checked": true,
    "id": "0d5f73dec2bf757e06aad63c92e2ff2bb2bf99c7",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-papers.3": {
    "title": "Neural Pre-Translation for Hybrid Machine Translation",
    "abstract": "Hybrid machine translation (HMT) takes advantage of different types of machine translation \n(MT) systems to improve translation performance. Neural machine translation (NMT) can \nproduce more fluent translations while phrase-based statistical machine translation (PB-SMT) \ncan produce adequate results primarily due to the contribution of the translation model. In \nthis paper, we propose a cascaded hybrid framework to combine NMT and PB-SMT to improve translation quality. Specifically, we first use the trained NMT system to pre-translate \nthe training data, and then employ the pre-translated training data to build an SMT system and \ntune parameters using the pre-translated development set. Finally, the SMT system is utilised \nas a post-processing step to re-decode the pre-translated test set and produce the final result. \nExperiments conducted on Japanese!English and Chinese!English show that the proposed \ncascaded hybrid framework can significantly improve performance by 2.38 BLEU points and \n4.22 BLEU points, respectively, compared to the baseline NMT system",
    "volume": "main",
    "checked": true,
    "id": "7a01131f7ac59c57bb20ae7d7b7b229e48cd4b1a",
    "citation_count": 14
  },
  "https://aclanthology.org/2017.mtsummit-papers.4": {
    "title": "Neural and Statistical Methods for Leveraging Meta-information in Machine Translation",
    "abstract": "In this paper, we discuss different methods which use meta information and richer context that may accompany source language input to improve machine translation quality. We focus on category information of input text as meta information, but the proposed methods can be extended to all textual and non-textual meta information that might be available for the input text or automatically predicted using the text content. The main novelty of this work is to use state-of-the-art neural network methods to tackle this problem within a statistical machine translation (SMT) framework. We observe translation quality improvements up to 3% in terms of BLEU score in some text categories",
    "volume": "main",
    "checked": true,
    "id": "e1474b9973fc7aa40e8a2de2816d07abccdb8045",
    "citation_count": 2
  },
  "https://aclanthology.org/2017.mtsummit-papers.5": {
    "title": "Translation Quality and Productivity: A Study on Rich Morphology Languages",
    "abstract": "This paper introduces a unique large-scale machine translation dataset with various levels of human annotation combined with automatically recorded productivity features such as time and keystroke logging and manual scoring during the annotation process. The data was collected as part of the EU-funded QT21 project and comprises 20,000–45,000 sentences of industry-generated content with translation into English and three morphologically rich languages: English–German/Latvian/Czech and German–English, in either the information technology or life sciences domain. Altogether, the data consists of 176,476 tuples including a source sentence, the respective machine translation by a statistical system (additionally, by a neural system for two language pairs), a post-edited version of such translation by a native-speaking professional translator, an independently created reference translation, and information on post-editing: time, keystrokes, Likert scores, and annotator identiﬁer. A subset of 2,000 sentences from this data per language pair and system type was also manually annotated with translation errors for deeper linguistic analysis. We describe the data collection process, provide a brief analysis of the resulting annotations and discuss the use of the data in quality estimation and automatic post-editing tasks",
    "volume": "main",
    "checked": true,
    "id": "f03dcd3c5631d1d4d68e22a77147e4869d2e1463",
    "citation_count": 40
  },
  "https://aclanthology.org/2017.mtsummit-papers.6": {
    "title": "The Microsoft Speech Language Translation (MSLT) Corpus for Chinese and Japanese: Conversational Test data for Machine Translation and Speech Recognition",
    "abstract": "Recent years have seen unprecedented growth in the use of MT across industries and domains. Partly this is due to the ready availability of open source MT tools such as Moses or online or customizable services. It is also due to fundamental shifts in the technology, speciﬁcally the move to deep learning, which has dramatically improved the quality of MT engines, including those used by online services. Likewise, improvements in Speech Recognition (SR) technology, also driven by the move to deep learning, are showing signiﬁcant improvements in quality driven by deep learning alone. The improvements of both of these technologies, MT and SR, increase the potential viability for speech translation, since the error cascade caused by daisy-chaining these technologies drops as the quality bar raises. MT is a crucial component in speech translation systems, yet developing conversational MT systems essential to speech translation is not a focus for many working in the Machine Translation discipline. Particularly problematic for many languages is the absence of test and dev data, not any less true for the Chinese and Japanese languages, where forays into conversational MT in and out of these languages are limited by the lack of publicly available conversational test data. In this paper, we seek to address this problem, by providing MT test and dev data that has been built from actual bilingual conversations between English and Japanese and Chinese, test data that can be useful to drive further research in this space for these two languages. Our plan is to make the data described in this paper available to the public by MT Summit",
    "volume": "main",
    "checked": true,
    "id": "f95fae77d14f71de1fdc80887b55a8c7cdb1219a",
    "citation_count": 5
  },
  "https://aclanthology.org/2017.mtsummit-papers.7": {
    "title": "Paying Attention to Multi-Word Expressions in Neural Machine Translation",
    "abstract": "Processing of multi-word expressions (MWEs) is a known problem for any natural language processing task. Even neural machine translation (NMT) struggles to overcome it. This paper presents results of experiments on investigating NMT attention allocation to the MWEs and improving automated translation of sentences that contain MWEs in English->Latvian and English->Czech NMT systems. Two improvement strategies were explored -(1) bilingual pairs of automatically extracted MWE candidates were added to the parallel corpus used to train the NMT system, and (2) full sentences containing the automatically extracted MWE candidates were added to the parallel corpus. Both approaches allowed to increase automated evaluation results. The best result - 0.99 BLEU point increase - has been reached with the first approach, while with the second approach minimal improvements achieved. We also provide open-source software and tools used for MWE extraction and alignment inspection",
    "volume": "main",
    "checked": true,
    "id": "13b79cb62747e817358ff2d6746c1eadae31ffa9",
    "citation_count": 17
  },
  "https://aclanthology.org/2017.mtsummit-papers.8": {
    "title": "Enabling Multi-Source Neural Machine Translation By Concatenating Source Sentences In Multiple Languages",
    "abstract": "In this paper, we explore a simple solution to \"Multi-Source Neural Machine Translation\" (MSNMT) which only relies on preprocessing a N-way multilingual corpus without modifying the Neural Machine Translation (NMT) architecture or training procedure. We simply concatenate the source sentences to form a single long multi-source input sentence while keeping the target side sentence as it is and train an NMT system using this preprocessed corpus. We evaluate our method in resource poor as well as resource rich settings and show its effectiveness (up to 4 BLEU using 2 source languages and up to 6 BLEU using 5 source languages). We also compare against existing methods for MSNMT and show that our solution gives competitive results despite its simplicity. We also provide some insights on how the NMT system leverages multilingual information in such a scenario by visualizing attention",
    "volume": "main",
    "checked": true,
    "id": "f849b4375d824be0f2d8325c1f1d37d3000ec685",
    "citation_count": 26
  },
  "https://aclanthology.org/2017.mtsummit-papers.9": {
    "title": "Learning an Interactive Attention Policy for Neural Machine Translation",
    "abstract": "Interactive machine translation research has focused primarily on predictive typing, which requires a human to type parts of the translation. This paper explores an interactive setting in which humans guide the attention of a neural machine translation system in a manner that requires no text entry at all. The system generates a translation from left to right, but waits periodically for a human to select the word in the source sentence to be translated next. A central technical challenge is that the system must learn when and how often to request guidance from the human. These decisions allow the system to trade off translation speed and accuracy. We cast these decisions as a reinforcement learning task and develop a policy gradient approach to train the system. Critically, the system can be trained on parallel data alone by simulating human guidance at training time. Our experiments demonstrate the viability of this interactive setting to improve translation quality and show that an effective policy for periodically requesting human guidance can be learned automatically. Abstract This paper reports on a comparative evaluation of phrase-based statistical machine translation (PBSMT) and neural machine translation (NMT) for four language pairs, using the PET interface to compare educational domain output from both systems using a variety of metrics, including automatic evaluation as well as human rankings of adequacy and ﬂuency, error-type markup, and post-editing (technical and temporal) effort, performed by professional translators. Our results show a preference for NMT in side-by-side ranking for all language pairs, texts, and segment lengths. In addition, perceived ﬂuency is improved and annotated errors are fewer in the NMT output. Results are mixed for perceived adequacy and for errors of omission, addition, and mistranslation. Despite far fewer segments requiring post-editing, document-level post-editing performance was not found to have signiﬁcantly improved in NMT compared to PBSMT. This evaluation was conducted as part of the TraMOOC project, which aims to create a replicable semi-automated methodology for high-quality machine translation of educational data",
    "volume": "main",
    "checked": true,
    "id": "e4f46cee475db947572c010aea7127c2cd6e44d2",
    "citation_count": 2
  },
  "https://aclanthology.org/2017.mtsummit-papers.10": {
    "title": "A Comparative Quality Evaluation of PBSMT and NMT using Professional Translators",
    "abstract": "This paper reports on a comparative evaluation of phrase-based statistical machine translation \n(PBSMT) and neural machine translation (NMT) for four language pairs, using the PET interface to compare educational domain output from both systems using a variety of metrics, \nincluding automatic evaluation as well as human rankings of adequacy and fluency, error-type \nmarkup, and post-editing (technical and temporal) effort, performed by professional translators. \nOur results show a preference for NMT in side-by-side ranking for all language pairs, texts, and \nsegment lengths. In addition, perceived fluency is improved and annotated errors are fewer in \nthe NMT output. Results are mixed for perceived adequacy and for errors of omission, addition, and mistranslation. Despite far fewer segments requiring post-editing, document-level \npost-editing performance was not found to have significantly improved in NMT compared to \nPBSMT. This evaluation was conducted as part of the TraMOOC project, which aims to create \na replicable semi-automated methodology for high-quality machine translation of educational \ndata",
    "volume": "main",
    "checked": true,
    "id": "6e2139053955e5efc4ac512e1d423133a0499e10",
    "citation_count": 71
  },
  "https://aclanthology.org/2017.mtsummit-papers.11": {
    "title": "One-parameter models for sentence-level post-editing effort estimation",
    "abstract": "Methods to predict the effort needed to post-edit a given machine translation (MT) output are seen as a promising direction to making MT more useful in the translation industry. Despite the wide variety of approaches that have been proposed, with increasing complexity as regards their number of features and parameters, the problem is far from solved. Focusing on post-editing time as effort indicator, this paper takes a step back and analyses the performance of very simple, easy to interpret one-parameter estimators that are based on general properties of the data: (a) a weighted average of measured post-editing times in a training set, where weights are an exponential function of edit distances between the new segment and those in training data; (b) post-editing time as a linear function of the length of the segment; and (c) source and target statistical language models. These simple estimators outperform strong baselines and are surprisingly competitive compared to more complex estimators, which have many more parameters and combine rich features. These results suggest that before blindly attempting sophisticated machine learning approaches to build post-editing effort predictors, one should ﬁrst consider simple, intuitive and interpretable models, and only then incrementally improve them by adding new features and gradually increasing their complexity. In a preliminary analysis, simple linear combinations of estimators of types (b) and (c) do not seem to be able to improve the performance of the single best estimator, which suggests that more complex, non-linear models could indeed be beneﬁcial when multiple indicators are used",
    "volume": "main",
    "checked": true,
    "id": "82f1f9ef3989f2ebf13a5779364dcb7d277420d9",
    "citation_count": 1
  },
  "https://aclanthology.org/2017.mtsummit-papers.12": {
    "title": "A Minimal Cognitive Model for Translating and Post-editing",
    "abstract": "This study investigates the coordination of reading (input) and writing (output) activities in from-scratch translation and post-editing. We segment logged eye movements and keylogging data into minimal units of reading and writing activity and model the process of post-editing and from-scratch translation as a Markov model. We show that the time translators and post-editors spend on source or target text reading predicts with a high degree of accuracy how likely it is that they engage in successive typing. We further show that the typing probability is also conditioned by the degree to which source and target text share semantic and syntactic properties. The minimal cognitive Markov model describes very basic factors which play a role in the processes occurring between input (reading) and output (writing) during translation",
    "volume": "main",
    "checked": true,
    "id": "1c95bfc246613590b7c291d0237072734ba00490",
    "citation_count": 5
  },
  "https://aclanthology.org/2017.mtsummit-papers.13": {
    "title": "Fine-Tuning for Neural Machine Translation with Limited Degradation across In- and Out-of-Domain Data",
    "abstract": "Neural machine translation is a recently proposed approach which has shown competitive results to traditional MT approaches. Similar to other neural network based methods, NMT also suffers from low performance for the domains with less available training data. Domain adaptation deals with improving performance of a model trained on large general domain data over test instances from a new domain. Fine-tuning is a fast and simple domain adaptation method which has demonstrated substantial improvements for various neural network based tasks including NMT. However, it suffers from drastic performance degradation on the general or source domain test sentences, which is undesirable in real-time applications. To address this problem of drastic degradation, in this paper, we propose two simple modiﬁcations to the ﬁne-tuning approach, namely multi-objective learning and multi-output learning which are based on the “Knowledge distillation” framework. Experiments on English-German translations demonstrate that our approaches achieve results comparable to simple ﬁne-tuning on the target domain task with comparatively little loss on the general domain task",
    "volume": "main",
    "checked": true,
    "id": "98d27527c3d764e93bb8850ef11e19d0e538604e",
    "citation_count": 39
  },
  "https://aclanthology.org/2017.mtsummit-papers.14": {
    "title": "Exploiting Relative Frequencies for Data Selection",
    "abstract": "We describe a data selection method for domain adaptation in machine translation, based on relative frequency ratios computed between in-domain and out-of-domain corpora. Our method is compared to a state-of-the-art approach based on cross-entropy differences, outperforming it signiﬁcantly in terms of data sparseness reduction and BLEU scores on the models created from various data slices. This approach is also shown to either perform signiﬁcantly better or provide competitive results in terms of perplexity when compared to a method designed to minimise cross-entropy. A novel method to mine unknown words in out-of-domain datasets is also presented, resulting in the best models across the board when used to weight sentences whose similarity to the primary domain is determined by relative frequency ratios. The proposed method is simple, requiring neither external resources nor complex setups, which makes it highly portable across domain adaptation scenarios",
    "volume": "main",
    "checked": true,
    "id": "8fa0cb13d3a857ac19dc02bd6189edf5b5d849e4",
    "citation_count": 1
  },
  "https://aclanthology.org/2017.mtsummit-papers.15": {
    "title": "Low Resourced Machine Translation via Morpho-syntactic Modeling: The Case of Dialectal Arabic",
    "abstract": "We present the second ever evaluated Arabic dialect-to-dialect machine translation effort, and the first to leverage external resources beyond a small parallel corpus. The subject has not previously received serious attention due to lack of naturally occurring parallel data; yet its importance is evidenced by dialectal Arabic's wide usage and breadth of inter-dialect variation, comparable to that of Romance languages. Our results suggest that modeling morphology and syntax significantly improves dialect-to-dialect translation, though optimizing such data-sparse models requires consideration of the linguistic differences between dialects and the nature of available data and resources. On a single-reference blind test set where untranslated input scores 6.5 BLEU and a model trained only on parallel data reaches 14.6, pivot techniques and morphosyntactic modeling significantly improve performance to 17.5",
    "volume": "main",
    "checked": true,
    "id": "396782243a9d587a48b2a69bd8666c364a535a58",
    "citation_count": 8
  },
  "https://aclanthology.org/2017.mtsummit-papers.16": {
    "title": "Elastic-substitution decoding for Hierarchical SMT: efficiency, richer search and double labels",
    "abstract": "Elastic-substitution decoding (ESD), first introduced by Chiang (2010), can be important for obtaining good results when applying labels to enrich hierarchical statistical machine translation (SMT). However, an efficient implementation is essential for scalable application. We describe how to achieve this, contributing essential details that were missing in the original exposition. We compare ESD to strict matching and show its superiority for both reordering and syntactic labels. To overcome the sub-optimal performance due to the late evaluation of features marking label substitution types, we increase the diversity of the rules explored during cube pruning initialization with respect to labels their labels. This approach gives significant improvements over basic ESD and performs favorably compared to extending the search by increasing the cube pruning pop-limit. Finally, we look at combining multiple labels. The combination of reordering labels and target-side boundary-tags yields a significant improvement in terms of the word-order sensitive metrics Kendall reordering score and METEOR. This confirms our intuition that the combination of reordering labels and syntactic labels can yield improvements over either label by itself, despite increased sparsity",
    "volume": "main",
    "checked": true,
    "id": "5e0e073be489b36375dc474be5535600098a97a5",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-papers.17": {
    "title": "Development of a classifiers/quantifiers dictionary towards French-Japanese MT",
    "abstract": "Although classifiers/quantifiers (CQs) expressions appear frequently in everyday communications or written documents, they are described neither in classical bilingual paper dictionaries , nor in machine-readable dictionaries. The paper describes a CQs dictionary, edited from the corpus we have annotated, and its usage in the framework of French-Japanese machine translation (MT). CQs treatment in MT often causes problems of lexical ambiguity, polylexical phrase recognition difficulties in analysis and doubtful output in transfer-generation, in particular for distant languages pairs like French and Japanese. Our basic treatment of CQs is to annotate the corpus by UNL-UWs (Universal Networking Language-Universal words) 1 , and then to produce a bilingual or multilingual dictionary of CQs, based on synonymy through identity of UWs",
    "volume": "main",
    "checked": true,
    "id": "cd0232f02bcce8c1317d65f58f725e854c3ef9ad",
    "citation_count": 4
  },
  "https://aclanthology.org/2017.mtsummit-papers.18": {
    "title": "Neural Machine Translation Model with a Large Vocabulary Selected by Branching Entropy",
    "abstract": "Neural machine translation (NMT), a new approach to machine translation, has achieved promising results comparable to those of traditional approaches such as statistical machine translation (SMT). Despite its recent success, NMT cannot handle a larger vocabulary because the training complexity and decoding complexity proportionally increase with the number of target words. This problem becomes even more serious when translating patent documents, which contain many technical terms that are observed infrequently. In this paper, we propose to select phrases that contain out-of-vocabulary words using the statistical approach of branching entropy. This allows the proposed NMT system to be applied to a translation task of any language pair without any language-specific knowledge about technical term identification. The selected phrases are then replaced with tokens during training and post-translated by the phrase translation table of SMT. Evaluation on Japanese-to-Chinese, Chinese-to-Japanese, Japanese-to-English and English-to-Japanese patent sentence translation proved the effectiveness of phrases selected with branching entropy, where the proposed NMT model achieves a substantial improvement over a baseline NMT model without our proposed technique. Moreover, the number of translation errors of under-translation by the baseline NMT model without our proposed technique reduces to around half by the proposed NMT model",
    "volume": "main",
    "checked": true,
    "id": "4b28650c43ad6e78b612d80bca0c0f2333b00904",
    "citation_count": 4
  },
  "https://aclanthology.org/2017.mtsummit-papers.19": {
    "title": "Usefulness of MT output for comprehension — an analysis from the point of view of linguistic intercomprehension",
    "abstract": "The present paper describes and presents ongoing research on machine translation (MT) and linguistic intercomprehension. One main goal, although not the only one, is to evaluate three machine translation (MT) systems —Systran, Google Translate and Apertium— through an analysis of the readers’ ability to understand the output generated. We compare the usefulness of MT output for comprehension to that of non-native writing in the readers’ L 1 and that of native writing in languages similar to their L 1 . The methodology used is based on cloze tests and the experiments are carried out using English, French and Italian as source languages and Spanish as the target language. The subjects involved are native Spanish ﬁrst-year-undergraduate students and ﬁnal-year secondary-school students. All of them have only very elementary knowledge, or in some cases no knowledge at all, of English, French and Italian (that is, a level equal to or lower than CEFRL B1 1 ). Although the results suggest that MT output resulting from translating from English and French into Spanish is similar to natively-written Italian texts or texts written in Spanish by non-native speakers in terms of usefulness, that depends quite often on the level of specialty but also on the ﬁeld and on the MT system used",
    "volume": "main",
    "checked": true,
    "id": "22a5f1556d8d1866a39719e7f6045778fe86664e",
    "citation_count": 3
  },
  "https://aclanthology.org/2017.mtsummit-papers.20": {
    "title": "Machine Translation as an Academic Writing Aid for Medical Practitioners",
    "abstract": "In this paper we explore the utility of Machine Translation as a writing aid and its impact on \nthe quality of the text produced. We focus on medical practitioners who are native speakers \nof Spanish and who need to publish their scientific work in English as a foreign language. \nAfter carrying out a general survey to determine whether Spanish-speaking medical practitioners already use MT as a writing aid, we engaged five participants in an experiment where \nwe asked them to write a paper in Spanish that was subsequently machine translated. They \nwere then asked to post-edit the MT output. We analyse their post-edits and further attempt \nto evaluate the overall quality of their texts by engaging a professional proofreader. Our results suggest that the texts produced with the help of MT+post-editing still require many edits \nin order to be considered of acceptable quality. In the conclusion, we identify several avenues \nworthy of future investigation and that could help achieve better quality",
    "volume": "main",
    "checked": true,
    "id": "a3a8b2b5e9a9af23e97f822d304118fcfc96afea",
    "citation_count": 4
  },
  "https://aclanthology.org/2017.mtsummit-papers.21": {
    "title": "A Multilingual Parallel Corpus for Improving Machine Translation on Southeast Asian Languages",
    "abstract": "Current machine translation systems require large bilingual corpora for training data. With large bilingual corpora, phrase-based and neural-based methods can achieve state-of-the-art performance. Nevertheless, such large bilingual corpora are unavailable for most language pairs called low-resource languages, which causes a bottleneck for the development of machine translation on such languages. For Southeast Asian region, there is a large population with more than ﬁve hundred millions people and several languages that can be used popularly in the world, but there are few parallel data for such language pairs. In this work, we built a multilingual parallel corpus for several Southeast Asian languages. Wikipedia articles’ titles and inter-language link records were used to extract parallel titles. Parallel articles were collected based on the parallel titles. For each article pair, parallel sentences were extracted based on a length-based and word correspondences sentence alignment method. A multilingual parallel corpus were built with more than 1.1 million parallel sentences of ten language pairs of Indonesian, Malay, Filipino, Vietnamese and the languages paired with English. Experiments were conducted on the Asian Language Treebank corpus and showed the promising performance. Additionally, the corpus was utilized for the IWSLT 2015 machine translation shared task on English-Vietnamese and achieved a signiﬁcant improvement with +1.7 BLEU point on phrase-based systems and +4.5 BLEU point on a state-of-the-art neural-based system. The corpus can be used to improve machine translation and enhance the development of machine translation on the low-resource Southeast Asian languages",
    "volume": "main",
    "checked": true,
    "id": "9fb313776819aaafd937a0d760d40105497d074f",
    "citation_count": 2
  },
  "https://aclanthology.org/2017.mtsummit-papers.22": {
    "title": "Exploring Hypotheses Spaces in Neural Machine Translation",
    "abstract": "Both statistical (SMT) and neural (NMT) approaches to machine translation (MT) explore large search spaces to produce and score translations. It is however well known that often the top hypothesis as scored by such approaches may not be the best overall translation among those that can be produced. Previous work on SMT has extensively explored re-ranking strategies in attempts to ﬁnd the best possible translation. In this paper, we focus on NMT and provide an in-depth investigation to explore the inﬂuence of beam sizes on information content and translation quality. We gather new insights using oracle experiments on the efﬁcacy of exploiting larger beams and propose a simple, yet novel consensus-based, n -best re-ranking approach that makes use of different automatic evaluation metrics to measure consensus in n -best lists. Our results reveal that NMT is able to cover more of the information content of the references compared to SMT and that this leads to better re-ranked translations (according to human evalu-ation). We further show that the MT evaluation metric used for the consensus-based re-ranking plays a major role, with character-based metrics performing better than BLEU",
    "volume": "main",
    "checked": true,
    "id": "55de993930fa4e3222ec512700162c318d262229",
    "citation_count": 11
  },
  "https://aclanthology.org/2017.mtsummit-papers.23": {
    "title": "Confidence through Attention",
    "abstract": "Attention distributions of the generated translations are a useful bi-product of attention-based recurrent neural network translation models and can be treated as soft alignments between the input and output tokens. In this work, we use attention distributions as a confidence metric for output translations. We present two strategies of using the attention distributions: filtering out bad translations from a large back-translated corpus, and selecting the best translation in a hybrid setup of two different translation systems. While manual evaluation indicated only a weak correlation between our confidence score and human judgments, the use-cases showed improvements of up to 2.22 BLEU points for filtering and 0.99 points for hybrid translation, tested on English German and English Latvian translation",
    "volume": "main",
    "checked": true,
    "id": "e81c458fb5ea3b1f1597e725d97965d662495518",
    "citation_count": 21
  },
  "https://aclanthology.org/2017.mtsummit-papers.24": {
    "title": "Disentangling ASR and MT Errors in Speech Translation",
    "abstract": "The main aim of this paper is to investigate automatic quality assessment for spoken language translation (SLT). More precisely, we investigate SLT errors that can be due to transcription (ASR) or to translation (MT) modules. This paper investigates automatic detection of SLT errors using a single classifier based on joint ASR and MT features. We evaluate both 2-class (good/bad) and 3-class (good/badASR/badMT ) labeling tasks. The 3-class problem necessitates to disentangle ASR and MT errors in the speech translation output and we propose two label extraction methods for this non trivial step. This enables - as a by-product - qualitative analysis on the SLT errors and their origin (are they due to transcription or to translation step?) on our large in-house corpus for French-to-English speech translation",
    "volume": "main",
    "checked": true,
    "id": "5f20495c08280ead1fea14f6c537b3393017cb09",
    "citation_count": 7
  },
  "https://aclanthology.org/2017.mtsummit-papers.25": {
    "title": "Temporality as Seen through Translation: A Case Study on Hindi Texts",
    "abstract": "Temporality has significantly contributed to various aspects of Natural Language \nProcessing applications. In this paper, we determine the extent to which temporal \norientation is preserved when a sentence is translated manually and automatically \nfrom the Hindi language to the English language. We show that the manually and \nautomatically identified temporal orientation in English translated (both manual \nand automatic) sentences provides a good match with the temporal orientation of \nthe Hindi texts. We also find that the task of manual temporal annotation becomes \ndifficult in the translated texts while the automatic temporal processing system manages to correctly capture temporal information from the translations",
    "volume": "main",
    "checked": true,
    "id": "c8413922f5662f9a407cef092a7588af2bfbd300",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-papers.26": {
    "title": "A Neural Network Transliteration Model in Low Resource Settings",
    "abstract": "Transliteration is the process of converting a text in one script to another, guided by phonetic clues. This conversion requires an important set of rules defined by expert linguists to deter-mine how the phonemes are aligned and to take into account the phonology system of the target language. The problem with under-resourced language pairs remains the lack of linguistic resources. In this research, we present a recurrent neural network based approach to overcome the transliteration problem for a low-resource language pair, with an application on the French-Vietnamese language pair. Our system requires a small bilingual learning dataset. We obtained promising results with a large gain of BLEU-score and a reduction in translation errors rate (TER) and phonemes errors rate (PER), compared to other systems",
    "volume": "main",
    "checked": true,
    "id": "81ddd4ee2ada8eeeb3b23d3750a88bf05ee1633c",
    "citation_count": 2
  },
  "https://aclanthology.org/2017.mtsummit-commercial.1": {
    "title": "Zero-Shot Translation for Indian Languages with Sparse Data",
    "abstract": "Neural Machine Translation (NMT) is a recently-emerged paradigm for Machine Translation (MT) that has shown promising results as well as a great potential to solve challenging MT tasks. One such a task is how to provide good MT for languages with sparse training data. In this paper we investigate a Zero Shot Translation (ZST) approach for such language combinations. ZST is a multilingual translation mechanism which uses a single NMT engine to translate between multiple languages, even such languages for which no direct parallel data was provided during training. After assessing ZST feasibility, by training a proof-of-concept engine ZST on French $ English and Italian $ English data, we focus on languages with sparse training data. In particular, we address the Tamil $ Hindi language pair. Our analysis shows the potential and effectiveness of ZST in such scenarios. To train and translate with ZST engines, we extend the training and translation pipelines of a commercial MT provider – KantanMT – with ZST capabilities, making this technology available to all users of the platform",
    "volume": "main",
    "checked": true,
    "id": "ede8e4c43f4a3af66703a7641d990fa93606e616",
    "citation_count": 8
  },
  "https://aclanthology.org/2017.mtsummit-commercial.2": {
    "title": "Feature-rich NMT and SMT post-edited corpora for productivity and evaluation tasks with a subset of MQM-annotated data",
    "abstract": "This presentation will discuss the creation and practical use of a large data set created through an unprecedented large-scale collaboration between MT R&D and translation experts. It contains post-edited and annotated industry data for four morphologically rich language pairs ( EN-DDe, EN-CS, DE-EN, EN-LV ). A subset of “almost perfect” sentences also contains MQM error annotations for further detailed analysis and profiling for recurring error patterns. The post edits were performed by professional translators and the data is freely available for further use. The data used for post-editing comprised 20,000 to 45,000 sentences of industry data (IT, life sciences) depending on the language pair. The post-editing of all four language pairs was performed using PET (Aziz, W. et al ). Several crucial and novel data points were taken during the post-editing: time logging, keystroke logging quality evaluation of the post-editing effort by the translator upon completion of the post-editing. The recording of this information during the post-editing phase allows for specific features and novel combinations of features to be used for a variety of research- and user-oriented purposes, including establishing the actual post-editing effort by translators based on time and keystrokes and comparing these results to the perceived level of quality of the post-edited sentence, establishing correlations between certain characteristics such as sentence length and post-edit time, or post-edit time and human quality evaluation. The datasets also measure post-editing productivity and are used to detect error patterns in the MT output. This would allow users of MT to adequately assess a) the use of MT in general, b) the actual productivity gains achieved in two different systems or across languages, domains and other data subsets such as long sentences or sentences containing certain grammatical constructs or terminology. For two language pairs identical sets of source sentences comprising 30,000 sentences respectively were post-edited for NMT and SMT output, allowing for a variety of innovative comparisons to be done on the results of the two given the unique data points that were collected during post-editing In addition, the",
    "volume": "main",
    "checked": true,
    "id": "3041b7476058f61d0096a5d810416755a3e1b9d7",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-commercial.3": {
    "title": "Usability of web-based MT post-editing environments for screen reader users",
    "abstract": "Beyond the goals of increasing quality and productivity levels or reducing cost, time and cognitive efforts, translation technologies are now designed, more than ever, to be as enjoyable and easy to use and learn as possible. In order to achieve the latter, translation software providers try to account for different end user profiles by designing, among others, cross-device, cross-platform solutions and multimodal interfaces. However, and despite the progress made to date in the area of Human-Computer Interaction (HCI), recent research work has suggested that leading desktop-based CAT tool providers fail to consider the particular needs of blind translators when developing their software. As the translator-tool interaction is based on keyboard-only input and text to-speech or text-to-braille output, common tasks such as consulting the translation suggestion’s provenance can be extremely time consuming or even impossible for screen reader users unless they receive sighted assistance. Taking into account the conclusions drawn in prior research work about the low level of accessibility featured by the most popular desktop-based CAT tools, we conducted a study to explore the potential of web-based CAT tools as a more suitable solution for blind translators. Our study was grounded on the belief that web development techniques are more standardised and, therefore, a higher level of accessibility can be achieved. We followed a classic usability evaluation approach, where a cohort of blind translators were requested (i) to conduct a simple post-editing exercise using two different MT-integrated online CAT tools, and (ii) to provide information about their interaction with the software. More specifically, translators were asked to report any issues encountered while trying to perform the post-editing exercise via a validated frustration experience form, used in prior work for HCI studies of similar nature. Once the interaction finished, participants completed a survey, inspired by the Computer System Usability Questionnaire (CSUQ), including questions about their overall user experience with the software. The two tools chosen were the only ones among a selection of six popular web-based post-editing environments which, during a pre-test, met the basic accessibility requirements needed for the study to be feasible. Findings indicate that, while usability scores are not extremely low, slight changes in the tools tested would be needed for screen reader users to be able to perform a translation job autonomously and efficiently. Data gathered has contributed not only to identify current challenges faced by blind translators when using the two tools evaluated, but also to provide important insights into which general recommendations could be followed by translation technology providers to adopt an accessible design approach when developing their software. Overall, our study suggests that accessibility awareness is still low, and that further research and development is needed in our industry to guarantee equal opportunities for all in the translation market",
    "volume": "main",
    "checked": true,
    "id": "91495574e46cf0dc20cfcc77c95a74726a066506",
    "citation_count": 1
  },
  "https://aclanthology.org/2017.mtsummit-commercial.4": {
    "title": "Live presentations to a multilingual audience: personal universal translator",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "7dfb1a4a8f5470e309ca4d153faa74a23391a7ff",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-commercial.5": {
    "title": "Toward a full-scale neural machine translation in production: the Booking.com use case",
    "abstract": "While some remarkable progress has been made in neural machine translation (NMT) research, there have not been many reports on its development and evaluation in practice. This paper tries to fill this gap by presenting some of our findings from building an in-house travel domain NMT system in a large scale E-commerce setting. The three major topics that we cover are optimization and training (including different optimization strategies and corpus sizes), handling real-world content and evaluating results",
    "volume": "main",
    "checked": true,
    "id": "d91d3dfe4651aaeb5c127df31d2be9b566f38468",
    "citation_count": 16
  },
  "https://aclanthology.org/2017.mtsummit-commercial.6": {
    "title": "The INTERACT Project and Crisis MT",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "942399c79978ca6ccd7435118a8c6ebc89695ae5",
    "citation_count": 1
  },
  "https://aclanthology.org/2017.mtsummit-commercial.7": {
    "title": "A Case Study of Machine Translation in Financial Sentiment Analysis",
    "abstract": "The European research project Social Sentiment Indices powered by X-Scores (SSIX) in-tends to allow Small and Medium-sized Enterprises (SMEs) to take advantage of social media sentiment data for the finance domain. The project aims to overcome language barriers and realize a financial sentiment platform capable of scoring textual data in different languages. Our approach to achieve this goal takes maximum advantage of human translation while keeping costs low by incorporating machine translation. In the long run, we intend to provide a tool that helps SMEs to expand into new markets by analyzing multilingual social contents. In this paper, we investigate how sentiment is preserved after machine translation. We built a sentiment gold standard corpus in English annotated by native financial experts, and then we translated the gold standard corpus into a target corpus (German) using one human translator and three machine translation engines (Microsoft, Google, and Google Neural Network) which are integrated in Geofluent to allow pre-/post-processing. We then conducted two experiments. One meant to evaluate the overall translation quality using the BLEU algorithm. The other intended to investigate which machine translation engines produce translations that preserve sentiment best. Results suggest that sentiment transfer can be successful through machine translation if using Google and Google Neural Network in Geofluent. This is a crucial step towards achiev-ing a multilingual sentiment platform in the domain of finance. Next, we plan to integrate language-specific processing rules to further enhance the performance of machine translation",
    "volume": "main",
    "checked": true,
    "id": "61ca4b4bc9b6246a485e168d04f99bdaeff1c34b",
    "citation_count": 1
  },
  "https://aclanthology.org/2017.mtsummit-commercial.8": {
    "title": "A New Methodology to Maximize the Strength of SMT and NMT",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "f4af3397e8ea681796a583c8aaf8caa435736af8",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-commercial.9": {
    "title": "Rule-based MT and UTX Glossary Management – Honda's Case Dealing with Thousands of Technical Terms",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "0d9efc9c36343e1563823260e2e462cdf9881ed1",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-commercial.10": {
    "title": "A detailed investigation of Bias Errors in Post-editing of MT output",
    "abstract": "The use of post-editing of machine translation output is increasing throughout the language technology community. In this work, we investigate whether the MT system influences the human translator, thereby introducing \"bias\" and potentially leading to errors in the post-editing. We analyze how often a translator accepts an incorrect suggestion from the MT system and determine different types of bias errors. We carry out quantitative analysis on translations of eCommerce data from English into Portuguese, consisting of 713 segments with about 15k words. We observed a higher-than-expected number of bias errors, about 18 bias errors per 1,000 words. Among the most frequent types of bias error we observed ambiguous modifiers, terminology errors, polysemy, and omissions. The goal of this work is to provide quantitative data about bias errors in post-editing that help indicate the existence of bias. We explore some ideas on how to automate the finding of these error patterns and facilitate the quality assurance of post-editing",
    "volume": "main",
    "checked": true,
    "id": "ab4afae6c9b79c1fc98240b67b58bf3429615204",
    "citation_count": 1
  },
  "https://aclanthology.org/2017.mtsummit-commercial.11": {
    "title": "Terminology post-editing of neural MT by UTX glossary data",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "7c27dabc0d1f8a1a415aeaaafb1942a6721aa766",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-commercial.12": {
    "title": "Harvesting Polysemous Terms from e-commerce Data to Enhance QA",
    "abstract": "Polysemous words can be difficult to translate and can affect the quality of Machine Translation (MT) output. Once the MT quality is affected, it has a direct impact on post-editing and on human-assisted machine translation. The presence of these terms increases the risk of errors. We think that these important words can be used to improve and to measure quality of translations. We present three methods for finding these words from e-commerce data, based on Named Entity Recognition, Part of Speech and Search Queries",
    "volume": "main",
    "checked": true,
    "id": "a50ebdf835aa0cb1017c66b11ac31cc2b27a0612",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-commercial.13": {
    "title": "Translation Dictation vs. Post-editing with Cloud-based Voice Recognition: A Pilot Experiment",
    "abstract": "In this paper, we report on a pilot mixed-methods experiment investigating the effects on \nproductivity and on the translator experience of integrating machine translation (MT) postediting (PE) with voice recognition (VR) and translation dictation (TD). The experiment \nwas performed with a sample of native Spanish participants. In the quantitative phase of the \nexperiment, they performed four tasks under four different conditions, namely (1) \nconventional TD; (2) PE in dictation mode; (3) TD with VR; and (4) PE with VR (PEVR). \nIn the follow-on qualitative phase, the participants filled out an online survey, providing \ndetails of their perceptions of the task and of PEVR in general. Our results suggest that \nPEVR may be a usable way to add MT to a translation workflow, with some caveats. When \nasked about their experience with the tasks, our participants preferred translation without the \n‘constraint’ of MT, though the quantitative results show that PE tasks were generally more \nefficient. This paper provides a brief overview of past work exploring VR for from-scratch \ntranslation and PE purposes, describes our pilot experiment in detail, presents an overview \nand analysis of the data collected, and outlines avenues for future work",
    "volume": "main",
    "checked": true,
    "id": "376cb01e0447507d3881dbe2e43187dc7fc1d403",
    "citation_count": 8
  },
  "https://aclanthology.org/2017.mtsummit-commercial.14": {
    "title": "Will neural MT be a breakthrough in English-to-Japanese technical translation?",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "6db7526ecfe304750eb79c430331608cff8ab318",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-commercial.15": {
    "title": "The Impact of MT Quality Estimation on Post-Editing Effort",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "0caa0a5e8d423d9b5316acf92dca1ad998425205",
    "citation_count": 2
  },
  "https://aclanthology.org/2017.mtsummit-commercial.16": {
    "title": "Utilizing Neural MT Engines in Industrial Translation",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "f2d1f17ee781d03b39387427eddd0095017f0678",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-commercial.17": {
    "title": "Comparative Evaluation of NMT with Established SMT Programs",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "20d47f489682d3ac724d282dd853865b7f3deaf2",
    "citation_count": 1
  },
  "https://aclanthology.org/2017.mtsummit-commercial.18": {
    "title": "Journey around Neural Machine Translation quality",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "a4a7756ad08bc28a5fa4a3079aa723fab37b73c5",
    "citation_count": 0
  },
  "https://aclanthology.org/2017.mtsummit-commercial.19": {
    "title": "A Reception Study of Machine Translated Subtitles for MOOCs",
    "abstract": "ABSTRACT As access has grown to online courses in the form of MOOCs (Massive Open Online Courses), the language barrier has become an important issue for users worldwide. Machine translation (MT) appears to offer an alternative or complementary solution to existing forms of MOOC translation. Very little attention has been paid, however, to the use and utility of MT for MOOC content. The main goal of this research is to test the impact machine-translated subtitles have on Chinese viewers’ reception of MOOC content. We are interested in whether there is any difference between viewers’ reception of raw machine-translated subtitles as opposed to fully post-edited machine-translated (PEMT) subtitles and human-translated (HT) subtitles. Based on an eye-tracking experiment conducted at two Chinese universities and survey methods, we show that participants who were offered full PEMT subtitles scored better overall on our reception metrics than those who were offered raw MT subtitles. HT subtitles, on the other hand, did not necessarily lead to better reception as expected; in contrast, the participants who were offered HT subtitles performed the worst in some of our reception metrics",
    "volume": "main",
    "checked": true,
    "id": "172573e0d3726ea19dcfbff1d1457479a7c22310",
    "citation_count": 10
  },
  "https://aclanthology.org/2017.mtsummit-commercial.20": {
    "title": "TraMOOC: Translation for Massive Open Online Courses",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "70bbe2350cb0722e44f7f2f78b092a93dd1a54e4",
    "citation_count": 0
  }
}